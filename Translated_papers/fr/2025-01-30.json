[
  {
    "paper": {
      "id": "2501.17703",
      "authors": [
        {
          "_id": "679ae76cf211c66bd702f5d5",
          "user": {
            "_id": "636a35eff8d9af4aea181608",
            "avatarUrl": "/avatars/d9c5cf3491243d1f2b1c5df1873ee8e7.svg",
            "isPro": false,
            "fullname": "yubo",
            "user": "ubowang",
            "type": "user"
          },
          "name": "Yubo Wang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-01-30T08:39:49.375Z",
          "hidden": false
        },
        {
          "_id": "679ae76cf211c66bd702f5d6",
          "name": "Xiang Yue",
          "hidden": false
        },
        {
          "_id": "679ae76cf211c66bd702f5d7",
          "user": {
            "_id": "6313a86154e6e5d9f0f94e04",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1662232951344-6313a86154e6e5d9f0f94e04.jpeg",
            "isPro": false,
            "fullname": "Wenhu Chen",
            "user": "wenhu",
            "type": "user"
          },
          "name": "Wenhu Chen",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-01-30T02:43:59.302Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-29T15:20:30.000Z",
      "title": "L'Entraînement Critique : L'entraînement critique est plus efficace que l'apprentissage par imitation.",
      "summary": "Supervised Fine-Tuning (SFT) est un méthode générale pour entraîner des modèles de langage qui imiten des réponses selon des signaux données. Dans cet article, nous défions ce modèle et proposons la Critique Fine-Tuning (CFT). La CFT est une stratégie où le modèle apprend à critiquer des réponses avec du bruit, renforçant le pensée critique humaine dans le modèle. Cette méthodologie encourage des caractéristiques telles que l'analyse profonde et la compréhension complexe, qui sont difficiles à atteindre avec le SFT standard. Pour évaluer l'effet de la CFT, nous avons construit un ensemble de données de 50K échantillons dans WebInstruct et nous avons généré des critiques en utilisant GPT-4o comme modèle d'apprentissage (input=[question; réponse avec bruit], output=critique). L'entraînement avec la CFT sur cet ensemble de données a amélioré de 4 à 10% sur 6 benchmarks de mathématiques par rapport au SFT, en utilisant des modèles comme Qwen2.5, Qwen2.5-Math et DeepSeek-Math. De plus, nous avons étendu les ensembles de données MetaMath et NuminaMath pour obtenir le même effet que le SFT. En particulier, le modèle Qwen2.5-Math-CFT a montré des résultats meilleurs avec 2M échantillons, dépassant ou égalant dans de nombreux benchmarks. Les études sur le développement de la logique dans les modèles de langage suggèrent que l'entraînement critique est une alternative plus efficace, basée sur le pensée critique humaine.",
      "upvotes": 12,
      "discussionId": "679ae770f211c66bd702f697"
    },
    "publishedAt": "2025-01-29T21:51:11.227Z",
    "title": "Critique Fine-Tuning: Learning to Critique is More Effective than Learning to Imitate",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.17703.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "636a35eff8d9af4aea181608",
      "avatarUrl": "/avatars/d9c5cf3491243d1f2b1c5df1873ee8e7.svg",
      "fullname": "yubo",
      "name": "ubowang",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 4
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2501.14334",
      "authors": [
        {
          "_id": "679a7546805383520ce065af",
          "user": {
            "_id": "644156da1a80f6d83cb1667c",
            "avatarUrl": "/avatars/106d30a576b0fb58118ac4333b17260b.svg",
            "isPro": false,
            "fullname": "Clement Desroches",
            "user": "clementdesroches",
            "type": "user"
          },
          "name": "Clément Desroches",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-01-29T21:06:17.418Z",
          "hidden": false
        },
        {
          "_id": "679a7546805383520ce065b0",
          "user": {
            "_id": "66221f6295e8f09a668f07f0",
            "avatarUrl": "/avatars/f7c943996c814630ab5dcfaaaba01a83.svg",
            "isPro": false,
            "fullname": "Martin Chauvin",
            "user": "Neyri56",
            "type": "user"
          },
          "name": "Martin Chauvin",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-01-30T09:38:17.235Z",
          "hidden": false
        },
        {
          "_id": "679a7546805383520ce065b1",
          "name": "Louis Ladan",
          "hidden": false
        },
        {
          "_id": "679a7546805383520ce065b2",
          "name": "Caroline Vateau",
          "hidden": false
        },
        {
          "_id": "679a7546805383520ce065b3",
          "name": "Simon Gosset",
          "hidden": false
        },
        {
          "_id": "679a7546805383520ce065b4",
          "name": "Philippe Cordier",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-24T08:58:49.000Z",
      "title": "Exploration de l'escalade durable de l'IA : étude de la prédiction de l'impact environnemental de l'IA pour l'entreprise",
      "summary": "Le rapide développement de l'intelligence artificielle (IA), notamment des grands modèles de langage (LLMs), a augmenté les préoccupations concernant les effets environnementaux, affectant non seulement les émissions de gaz mais également la fabrication et le cycle de vie jusqu'à la fin de la vie de l'objet. L'opacité des principaux fournisseurs rend difficile l'évaluation des impacts environnementaux liés à l'IA et l'atteinte des objectifs de zéro émissions.\n\nDans cet article, nous proposons un méthode pour évaluer l'impact environnemental de la carte IA d'une entreprise, et nous offrons des perspectives qui permettent d'effectuer l'évaluation de l'IA et du cycle de vie (LCA) sans nécessiter des connaissances spécifiques dans ces domaines. Les résultats montrent que les modèles d'IA de génération grands consomment jusqu'à 4.600 fois plus d'énergie que les modèles traditionnels. Notre approche de modélisation prédit la quantité d'électricité consommée par l'IA jusqu'au 2030, en tenant compte de la variation du mélange électrique selon les scénarios du IPCC, l'augmentation de l'utilisation de l'IA, l'efficacité du calcul et l'impact environnemental des émissions de gaz. Dans le scénario de forte introduction, on s'attend à ce que l'utilisation d'électricité par l'IA augmente de 24,4 fois grâce à l'introduction large de l'IA générative et des agents intelligents, ce qui conduit à un augmentation significative de l'utilisation de modèles et de cadres complexes.\n\nPour atténuer l'impact environnemental de l'IA jusqu'au 2030, il est nécessaire une collaboration mondiale tout au long de la chaîne de valeur de l'IA. Les mesures indépendantes pour améliorer l'efficacité du calcul, l'efficacité du modèle et la réduction des émissions de gaz ne sont pas suffisantes. Nous proposons l'implémentation d'un cadre de référence standardisé pour l'évaluation environnementale, une plus grande transparence de tous les propriétaires de la chaîne de valeur, et l'introduction de métriques de \"compensation environnementale\", ainsi que la promotion que le développement de l'IA se conforme aux objectifs de zéro émissions.",
      "upvotes": 11,
      "discussionId": "679a7548805383520ce065f5"
    },
    "publishedAt": "2025-01-30T03:05:08.789Z",
    "title": "Exploring the sustainable scaling of AI dilemma: A projective study of corporations' AI environmental impacts",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.14334.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "644156da1a80f6d83cb1667c",
      "avatarUrl": "/avatars/106d30a576b0fb58118ac4333b17260b.svg",
      "fullname": "Clement Desroches",
      "name": "clementdesroches",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2501.17749",
      "authors": [
        {
          "_id": "679ae5eab898ac90bf4480b6",
          "user": {
            "_id": "657b3a44de028a439ea2ed9d",
            "avatarUrl": "/avatars/9f05e8eb6809a0ce1b50cd1fc9b5a044.svg",
            "isPro": false,
            "fullname": "Aitor Arrieta",
            "user": "aitorarrieta",
            "type": "user"
          },
          "name": "Aitor Arrieta",
          "status": "extracted_confirmed",
          "statusLastChangedAt": "2025-01-30T08:45:20.561Z",
          "hidden": false
        },
        {
          "_id": "679ae5eab898ac90bf4480b7",
          "name": "Miriam Ugarte",
          "hidden": false
        },
        {
          "_id": "679ae5eab898ac90bf4480b8",
          "user": {
            "_id": "65001514f322f9156663f096",
            "avatarUrl": "/avatars/e8712f60d4e8b7c70ac02c532ad547ef.svg",
            "isPro": false,
            "fullname": "Pablo Valle",
            "user": "pablovalle",
            "type": "user"
          },
          "name": "Pablo Valle",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-30T09:39:30.629Z",
          "hidden": false
        },
        {
          "_id": "679ae5eab898ac90bf4480b9",
          "user": {
            "_id": "63527de67e4cc3135fd16651",
            "avatarUrl": "/avatars/5eb8076d448d0b6746e256c24e1440e0.svg",
            "isPro": false,
            "fullname": "José Antonio Parejo Maestre",
            "user": "japarejo",
            "type": "user"
          },
          "name": "José Antonio Parejo",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-30T09:39:06.958Z",
          "hidden": false
        },
        {
          "_id": "679ae5eab898ac90bf4480ba",
          "user": {
            "_id": "6790d642a1863df579840ae3",
            "avatarUrl": "/avatars/a10a6f4af327c1bb67513c56d7f84820.svg",
            "isPro": false,
            "fullname": "Sergio Segura",
            "user": "ssegura",
            "type": "user"
          },
          "name": "Sergio Segura",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-01-30T02:37:35.516Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-29T16:36:53.000Z",
      "title": "OpenAI's o3-mini's initial external safety verification : rétroaction de l'évaluation pré-déploiement",
      "summary": "Les modèles de langage grand (LLMs) jouent un rôle important dans notre vie quotidienne. Cependant, ces modèles peuvent endommager la vie privée des personnes, maintenir des préjugés et diffuser des informations inexactes. Ces risques soulignent la nécessité de structures de sécurité robustes, de directives éthiques et d'une large gamme d'essais pour garantir des fonctions responsables. La sécurité des LLMs est cruciale, car elle doit être évaluée en détail avant que ces modèles ne soient accessibles aux utilisateurs du public. Dans cet article, nous présentons l'expérience des chercheurs de l'université de Stanford et de l'université de Cambridge dans la vérification externe de sécurité d'un nouveau LLM de OpenAI, appelé o3-mini. En particulier, nous utilisons notre outil ASTRAL pour générer automatiquement et systématiquement des entrées de tests instables (par exemple, prompts) et pour évaluer et classer la sécurité des LLMs de manière diverse. Les tests ont été générés et exécutés automatiquement pour la version beta de o3-mini. Les tests instables classés par ASTRAL ont été vérifiés directement et 87 instances de comportement instable des LLMs ont été identifiées. Nous soulignons spécialement les importantes découvertes et observations trouvées avant la mise en œuvre de ces nouvelles fonctionnalités des LLMs.",
      "upvotes": 7,
      "discussionId": "679ae5f0b898ac90bf44826c"
    },
    "publishedAt": "2025-01-29T21:38:42.464Z",
    "title": "Early External Safety Testing of OpenAI's o3-mini: Insights from the Pre-Deployment Evaluation",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.17749.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5860
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.17433",
      "authors": [
        {
          "_id": "679b1319f87b99a2a7c41e36",
          "user": {
            "_id": "67325283b318faa97f7ae5f7",
            "avatarUrl": "/avatars/2f83452768148b323c540c43ad695ee6.svg",
            "isPro": false,
            "fullname": "TianshengHuang",
            "user": "TianshengHuang",
            "type": "user"
          },
          "name": "Tiansheng Huang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-01-30T08:39:47.548Z",
          "hidden": false
        },
        {
          "_id": "679b1319f87b99a2a7c41e37",
          "user": {
            "_id": "6539cab119c3ef6679794706",
            "avatarUrl": "/avatars/a88691ff5a547c7a1384edcc615c8209.svg",
            "isPro": false,
            "fullname": "Sihao Hu",
            "user": "SihaoHu",
            "type": "user"
          },
          "name": "Sihao Hu",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-30T09:39:58.723Z",
          "hidden": false
        },
        {
          "_id": "679b1319f87b99a2a7c41e38",
          "user": {
            "_id": "647615b995a4dc98e58c24f2",
            "avatarUrl": "/avatars/7f73999246526c1aef4d019d5f5595ad.svg",
            "isPro": false,
            "fullname": "Fatih Ilhan",
            "user": "tawreos",
            "type": "user"
          },
          "name": "Fatih Ilhan",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-30T09:40:06.004Z",
          "hidden": false
        },
        {
          "_id": "679b1319f87b99a2a7c41e39",
          "user": {
            "_id": "65aae89948c718a57434db6f",
            "avatarUrl": "/avatars/6c0fae8dafad9b9265098a9bc3bfc102.svg",
            "isPro": false,
            "fullname": "selim tekin",
            "user": "sftekin25",
            "type": "user"
          },
          "name": "Selim Furkan Tekin",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-30T09:40:16.339Z",
          "hidden": false
        },
        {
          "_id": "679b1319f87b99a2a7c41e3a",
          "user": {
            "_id": "65c998005e17dbeaf147db84",
            "avatarUrl": "/avatars/6fb47b1e095971b93ff7dcd10369f926.svg",
            "isPro": false,
            "fullname": "Ling Liu",
            "user": "ling1119",
            "type": "user"
          },
          "name": "Ling Liu",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-30T09:40:37.075Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-29T06:24:58.000Z",
      "title": "Virus : Attaques de micro-ajustes nocifs à travers des modèles de langage à grande échelle",
      "summary": "Selon les derniers études, les modèles de langue de grande échelle (LLMs) sont vulnérables aux attaques mineures et pernicieuses, et lorsqu'ils sont ajustés avec des échantillons dangereux, la capacité d'ajustement de sécurité peut diminuer. Pour réduire le risque, en général, on utilise la technique de filtrage d'échantillons dangereux avant l'ajustement par des lignes de protection. Dans cet article, on concevoit une nouvelle mission de redaction et on soutient que l'on ne peut pas confiance à ce que les données puissent être filtrées par des modèles de lignes de protection. Le méthode d'attaque proposée dans cet article, appelée Virus, permet d'éviter le modèle de lignes de protection en faisant des modifications légères dans les données dangereuses. Les résultats des expérimentations montrent que les données dangereuses optimisées par Virus présentent un taux de détection de 100% en lignes de protection et atteignent en même temps un bon rendement d'attaque. Enfin, la principale message transmis dans cet article est que considérer le modèle de lignes de protection pour résoudre des attaques mineures et dangereuses est dangereux. Le modèle de lignes de protection ne peut pas résoudre les problèmes de sécurité propres aux LLMs pré-entraînés. Le code est disponible sur GitHub : https://github.com/git-disl/Virus.",
      "upvotes": 2,
      "discussionId": "679b131bf87b99a2a7c41ede"
    },
    "publishedAt": "2025-01-30T01:30:18.013Z",
    "title": "Virus: Harmful Fine-tuning Attack for Large Language Models Bypassing Guardrail Moderation",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/67325283b318faa97f7ae5f7/1hJo5gEfGEXAwYB5a6yWY.png",
      "https://cdn-uploads.huggingface.co/production/uploads/67325283b318faa97f7ae5f7/8SaMXA1izw5vcfwtU2Nhj.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.17433.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "67325283b318faa97f7ae5f7",
      "avatarUrl": "/avatars/2f83452768148b323c540c43ad695ee6.svg",
      "fullname": "TianshengHuang",
      "name": "TianshengHuang",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2501.17195",
      "authors": [
        {
          "_id": "679ae7655c55250b48483742",
          "name": "Andrei Alexandru",
          "hidden": false
        },
        {
          "_id": "679ae7655c55250b48483743",
          "user": {
            "_id": "66e184e86048d62cd8fb4e52",
            "avatarUrl": "/avatars/dc459c692fe9fce0911fa1229df0aeee.svg",
            "isPro": false,
            "fullname": "Antonia Calvi",
            "user": "NinaCalvi",
            "type": "user"
          },
          "name": "Antonia Calvi",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-30T09:40:54.827Z",
          "hidden": false
        },
        {
          "_id": "679ae7655c55250b48483744",
          "name": "Henry Broomfield",
          "hidden": false
        },
        {
          "_id": "679ae7655c55250b48483745",
          "name": "Jackson Golden",
          "hidden": false
        },
        {
          "_id": "679ae7655c55250b48483746",
          "name": "Kyle Dai",
          "hidden": false
        },
        {
          "_id": "679ae7655c55250b48483747",
          "name": "Mathias Leys",
          "hidden": false
        },
        {
          "_id": "679ae7655c55250b48483748",
          "name": "Maurice Burger",
          "hidden": false
        },
        {
          "_id": "679ae7655c55250b48483749",
          "name": "Max Bartolo",
          "hidden": false
        },
        {
          "_id": "679ae7655c55250b4848374a",
          "name": "Roman Engeler",
          "hidden": false
        },
        {
          "_id": "679ae7655c55250b4848374b",
          "name": "Sashank Pisupati",
          "hidden": false
        },
        {
          "_id": "679ae7655c55250b4848374c",
          "name": "Toby Drane",
          "hidden": false
        },
        {
          "_id": "679ae7655c55250b4848374d",
          "name": "Young Sun Park",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-27T15:09:08.000Z",
      "title": "Atla Selene Mini : Modèle d'Évaluation Générale",
      "summary": "Atla・Selene・Mini, SLMJ (Petit Modèle de Langue comme Juge) permet l'évaluation des meilleurs petits modèles de langue. Selene・Mini est un évaluateur approprié pour son utilisation générale, dépassant SLMJ et GPT-4o-mini en termes de performance générale sur 11 référentiels. Cela comprend des notations absolues, des classifications de classes et des tâches de préférence de paires. Il a enregistré la note la plus élevée sur RewardBench pour des générateurs de 8B, et dépasse GPT-4o et des évaluateurs spécialisés dans ses critères forts. Pour ce faire, une stratégie de chargement de données a été développée pour générer des jeux de données synthétiques à partir de données publiques, garantissant une qualité élevée grâce à des filtrages et des suppressions. Le modèle a été entraîné en combinant la fonction de perte d'optimisation de préférences directes (DPO) et l'apprentissage des fins de la philosophie (SFT). Selene・Mini améliore significativement l'accord avec les experts dans les jeux de données de financement et de santé, et est résistante aux changements dans le format des prompts. À partir des résultats initiaux, Selene・Mini a été évalué comme le meilleur évaluateur dans le Champ des Juges, en leadership de la communauté et de la vie publique. Le modèle est disponible sur HuggingFace (https://hf.co/AtlaAI/Selene-1-Mini-Llama-3.1-8B) et Ollama, favorisant l'introduction d'une communauté large.",
      "upvotes": 2,
      "discussionId": "679ae76b5c55250b484838e0"
    },
    "publishedAt": "2025-01-29T21:44:37.041Z",
    "title": "Atla Selene Mini: A General Purpose Evaluation Model",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.17195.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5860
    },
    "isAuthorParticipating": false
  }
]