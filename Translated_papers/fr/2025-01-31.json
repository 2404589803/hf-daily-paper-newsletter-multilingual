[
  {
    "paper": {
      "id": "2501.18492",
      "authors": [
        {
          "_id": "679c4ac5e2c0dbf282597d35",
          "user": {
            "_id": "64b708351a4d97b5d7edd369",
            "avatarUrl": "/avatars/960c1033f9cf218220f86de22c06915b.svg",
            "isPro": false,
            "fullname": "Yue Liu",
            "user": "yueliu1998",
            "type": "user"
          },
          "name": "Yue Liu",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-31T08:41:25.697Z",
          "hidden": false
        },
        {
          "_id": "679c4ac5e2c0dbf282597d36",
          "user": {
            "_id": "62728f4f6253fe2068da1021",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62728f4f6253fe2068da1021/KZ65X0EH98AF3zXemPiap.jpeg",
            "isPro": false,
            "fullname": "Hongcheng Gao",
            "user": "HongchengGao",
            "type": "user"
          },
          "name": "Hongcheng Gao",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-01-31T08:35:51.645Z",
          "hidden": false
        },
        {
          "_id": "679c4ac5e2c0dbf282597d37",
          "user": {
            "_id": "6366429195204b4649c658b8",
            "avatarUrl": "/avatars/5d80e9ebe0b57fd815f36796b9187248.svg",
            "isPro": false,
            "fullname": "Shengfang Zhai",
            "user": "zsf",
            "type": "user"
          },
          "name": "Shengfang Zhai",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-31T08:41:32.474Z",
          "hidden": false
        },
        {
          "_id": "679c4ac5e2c0dbf282597d38",
          "user": {
            "_id": "679c68bbfc30f43de85206f5",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/IJWda9ZYtjzlhr2ehsLHu.jpeg",
            "isPro": false,
            "fullname": "Jun Xia",
            "user": "JunXia97",
            "type": "user"
          },
          "name": "Jun Xia",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-31T08:41:53.366Z",
          "hidden": false
        },
        {
          "_id": "679c4ac5e2c0dbf282597d39",
          "name": "Tianyi Wu",
          "hidden": false
        },
        {
          "_id": "679c4ac5e2c0dbf282597d3a",
          "user": {
            "_id": "63f42ca3520c1461892ee929",
            "avatarUrl": "/avatars/095241acfe7c783d2406abf63ff81f65.svg",
            "isPro": false,
            "fullname": "xuezhiwei",
            "user": "lakxtxue",
            "type": "user"
          },
          "name": "Zhiwei Xue",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-31T08:42:30.842Z",
          "hidden": false
        },
        {
          "_id": "679c4ac5e2c0dbf282597d3b",
          "user": {
            "_id": "65efc25828426de60f977dfc",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/u8ZcIoo58JPLdnjm-jZeo.png",
            "isPro": false,
            "fullname": "Yulin Chen",
            "user": "CallMeChen",
            "type": "user"
          },
          "name": "Yulin Chen",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-31T08:42:41.013Z",
          "hidden": false
        },
        {
          "_id": "679c4ac5e2c0dbf282597d3c",
          "name": "Kenji Kawaguchi",
          "hidden": false
        },
        {
          "_id": "679c4ac5e2c0dbf282597d3d",
          "user": {
            "_id": "669e19e5dac1eb34c0f5f505",
            "avatarUrl": "/avatars/bec7d1d1dac2ad6570844d1f00e7df0a.svg",
            "isPro": false,
            "fullname": "Jiaheng Zhang",
            "user": "jiaheng233",
            "type": "user"
          },
          "name": "Jiaheng Zhang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-31T08:37:04.493Z",
          "hidden": false
        },
        {
          "_id": "679c4ac5e2c0dbf282597d3e",
          "user": {
            "_id": "651d8032c50012d33e914f2f",
            "avatarUrl": "/avatars/0a44c9f51fc50ce86582e328c361ea00.svg",
            "isPro": false,
            "fullname": "Bryan Hooi",
            "user": "bhooi",
            "type": "user"
          },
          "name": "Bryan Hooi",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-31T08:42:50.273Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-30T17:06:06.000Z",
      "title": "Gard Ridgerunner: Objectif de la directive de sécurité des LLM basée sur les raisons",
      "summary": "La réflexion des LLMs sur la sécurité des applications devient de plus en plus importante, et la sécurité garantie avec le utilisation de GuardLine est un problème crucial. Dans cet article, nous proposons un nouveau dispositif de sécurité appelé GuardReasoner, qui permet de trainer logiquement GuardModel. Concrètement, nous générons un jeu de données appelé \"GuardReasonerTrain\" constitué de 127K échantillons et de 460K raisons logiques détaillées, et nous introduisons une SFT (Fine-Tuning Supervisé) pour les habiletés d'explication. De plus, nous présentons une DPO (Direct Preference Optimization) pour les échantillons difficiles. De cette manière, GuardReasoner améliore son rendement, sa clarté d'explication et sa capacité à généraliser. À travers d'expériences et d'analyses étendues sur 13 cadres de référence pour 3 tâches de GuardLine, nous démontrons une excellente performance. En particulier, GuardReasoner 8B dépasse, en termes de score F1, GPT-4o+CoT en moyenne de 5,74% et LLaMA Guard 3 8B en moyenne de 20,84%. Les données d'entraînement, le code et les modèles (de tailles 1B, 3B et 8B) de GuardReasoner sont publiés sur : https://github.com/yueliu1999/GuardReasoner/.",
      "upvotes": 29,
      "discussionId": "679c4ac6e2c0dbf282597d80"
    },
    "publishedAt": "2025-01-30T23:01:47.466Z",
    "title": "GuardReasoner: Towards Reasoning-based LLM Safeguards",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/6650c77a74664a42ddfb9187/Kza1q-PVKsgu_6SaQ9Oze.png",
      "https://cdn-uploads.huggingface.co/production/uploads/6650c77a74664a42ddfb9187/rqViZgnFQQJcAfgC1a17n.png",
      "https://cdn-uploads.huggingface.co/production/uploads/6650c77a74664a42ddfb9187/5Dk0HJkhOCoSXoWdVUzBo.png",
      "https://cdn-uploads.huggingface.co/production/uploads/6650c77a74664a42ddfb9187/DWg1wTHDx939H4bZPVj1W.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.18492.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "6650c77a74664a42ddfb9187",
      "avatarUrl": "/avatars/92001bbe0ae9b14309730316b639cede.svg",
      "fullname": "yueliu1999",
      "name": "yueliu1999",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.18362",
      "authors": [
        {
          "_id": "679c5b0034f5df4416915177",
          "name": "Yuxin Zuo",
          "hidden": false
        },
        {
          "_id": "679c5b0034f5df4416915178",
          "user": {
            "_id": "65597738deee83130a1301d5",
            "avatarUrl": "/avatars/9bcc40aebe4db079927675d95c00463c.svg",
            "isPro": false,
            "fullname": "Shang (Lindsay) Qu",
            "user": "lindsay-qu",
            "type": "user"
          },
          "name": "Shang Qu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-01-31T08:35:48.269Z",
          "hidden": false
        },
        {
          "_id": "679c5b0034f5df4416915179",
          "name": "Yifei Li",
          "hidden": false
        },
        {
          "_id": "679c5b0034f5df441691517a",
          "name": "Zhangren Chen",
          "hidden": false
        },
        {
          "_id": "679c5b0034f5df441691517b",
          "name": "Xuekai Zhu",
          "hidden": false
        },
        {
          "_id": "679c5b0034f5df441691517c",
          "name": "Ermo Hua",
          "hidden": false
        },
        {
          "_id": "679c5b0034f5df441691517d",
          "name": "Kaiyan Zhang",
          "hidden": false
        },
        {
          "_id": "679c5b0034f5df441691517e",
          "user": {
            "_id": "60cf4bcb1ce3775ebb86e5d5",
            "avatarUrl": "/avatars/12bcd18d215abf91f297f93007733148.svg",
            "isPro": false,
            "fullname": "Ning Ding",
            "user": "stingning",
            "type": "user"
          },
          "name": "Ning Ding",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-01-31T09:50:45.999Z",
          "hidden": false
        },
        {
          "_id": "679c5b0034f5df441691517f",
          "name": "Bowen Zhou",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-30T14:07:56.000Z",
      "title": "MedXpertQA : Niveau de raisonnement et critères de compréhension professionnelle médicale",
      "summary": "MedXpertQA est un modèle qui offre un haut rendement dans les évaluations de référence, ce qui le rend idéal pour évaluer les connaissances médicales professionnelles et une logique avancée. MedXpertQA comprend 4,460 questions réparties entre 17 domaines professionnels et 11 systèmes d'examen physique, divisées en sous-ensembles d'évaluation de texte et le sous-ensemble MM pour les évaluations multimodales. En particulier, MM introduit des questions de haut niveau professionnel qui incluent des images et une grande quantité d'informations cliniques, ce qui permet une évaluation plus rigoureuse que les marques de référence traditionnelles médicales, qui évaluent simples pairs de réponses générées à partir de captures d'images. Pour aborder la manque de difficulté dans les cadres de référence actuels, MedXpertQA applique une filtration stricte et une extension, ce qui améliore la qualité et la pertinence des questions dans les domaines professionnels, garantissant ainsi une évaluation plus précise et fiable. De plus, des évaluations professionnelles multiples sont effectuées pour garantir la précision et la confiance dans le rendement du modèle. Dans MedXpertQA, 16 modèles avancés sont évalués. De plus, la médecine a une relation profonde avec les décisions réelles et offre des environnements représentatifs qui évaluent des habiletés de logique plus que de mathématiques et de programmation. Par conséquent, des sous-ensembles logiques sont développés pour évaluer mieux le potentiel logique des modèles tels que o1.",
      "upvotes": 7,
      "discussionId": "679c5b0234f5df44169151e9"
    },
    "publishedAt": "2025-01-31T04:14:53.856Z",
    "title": "MedXpertQA: Benchmarking Expert-Level Medical Reasoning and Understanding",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.18362.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "65597738deee83130a1301d5",
      "avatarUrl": "/avatars/9bcc40aebe4db079927675d95c00463c.svg",
      "fullname": "Shang (Lindsay) Qu",
      "name": "lindsay-qu",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2501.18585",
      "authors": [
        {
          "_id": "679c5ca666c379e215bc9e74",
          "name": "Yue Wang",
          "hidden": false
        },
        {
          "_id": "679c5ca666c379e215bc9e75",
          "user": {
            "_id": "63e60ff62d704152abac8af8",
            "avatarUrl": "/avatars/a54c34fb87a7ed5aeba792852747de92.svg",
            "isPro": false,
            "fullname": "Qiuzhi Liu",
            "user": "Dennis364",
            "type": "user"
          },
          "name": "Qiuzhi Liu",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-31T08:45:37.562Z",
          "hidden": false
        },
        {
          "_id": "679c5ca666c379e215bc9e76",
          "user": {
            "_id": "660399710f1fc2f16de18072",
            "avatarUrl": "/avatars/c22a749cc45db693c2d9ea877c7cace4.svg",
            "isPro": false,
            "fullname": "Jiahao Xu",
            "user": "Jiahao004",
            "type": "user"
          },
          "name": "Jiahao Xu",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-31T08:45:31.807Z",
          "hidden": false
        },
        {
          "_id": "679c5ca666c379e215bc9e77",
          "name": "Tian Liang",
          "hidden": false
        },
        {
          "_id": "679c5ca666c379e215bc9e78",
          "name": "Xingyu Chen",
          "hidden": false
        },
        {
          "_id": "679c5ca666c379e215bc9e79",
          "user": {
            "_id": "638439ca834d3558a398d035",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1669609868550-noauth.png",
            "isPro": false,
            "fullname": "Zhiwei He",
            "user": "zwhe99",
            "type": "user"
          },
          "name": "Zhiwei He",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-31T08:44:45.300Z",
          "hidden": false
        },
        {
          "_id": "679c5ca666c379e215bc9e7a",
          "user": {
            "_id": "64c94eddcb2f1bf0e7db5a4d",
            "avatarUrl": "/avatars/f7e2532d3c85d5e5b5a02c579ea68c3a.svg",
            "isPro": false,
            "fullname": "Linfeng Song",
            "user": "freesunshine0316",
            "type": "user"
          },
          "name": "Linfeng Song",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-31T08:44:29.221Z",
          "hidden": false
        },
        {
          "_id": "679c5ca666c379e215bc9e7b",
          "user": {
            "_id": "62d58fd53bf5e059f7cc3245",
            "avatarUrl": "/avatars/7a4f3ee4a37245f67efd26749d66a706.svg",
            "isPro": false,
            "fullname": "Dian Yu",
            "user": "yudian",
            "type": "user"
          },
          "name": "Dian Yu",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-31T08:44:23.114Z",
          "hidden": false
        },
        {
          "_id": "679c5ca666c379e215bc9e7c",
          "user": {
            "_id": "6670e285b0c03c4e9d6e0985",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/uCZHm4gKSHZ2b0hpHWgZv.jpeg",
            "isPro": false,
            "fullname": "Juntao Li",
            "user": "douvleplus",
            "type": "user"
          },
          "name": "Juntao Li",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-31T08:44:12.069Z",
          "hidden": false
        },
        {
          "_id": "679c5ca666c379e215bc9e7d",
          "user": {
            "_id": "5f82f9f7f0801648bf8844b2",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1669627733134-5f82f9f7f0801648bf8844b2.jpeg",
            "isPro": false,
            "fullname": "Zhuosheng Zhang",
            "user": "cooelf",
            "type": "user"
          },
          "name": "Zhuosheng Zhang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-31T08:44:05.749Z",
          "hidden": false
        },
        {
          "_id": "679c5ca666c379e215bc9e7e",
          "name": "Rui Wang",
          "hidden": false
        },
        {
          "_id": "679c5ca666c379e215bc9e7f",
          "user": {
            "_id": "67485743561b1e6f9579389f",
            "avatarUrl": "/avatars/8a4cc63bd7be388010bc329bb74582a1.svg",
            "isPro": false,
            "fullname": "Zhaopeng Tu",
            "user": "zptu",
            "type": "user"
          },
          "name": "Zhaopeng Tu",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-31T08:43:27.683Z",
          "hidden": false
        },
        {
          "_id": "679c5ca666c379e215bc9e80",
          "user": {
            "_id": "65147a1426fbd558dbd08f1b",
            "avatarUrl": "/avatars/86574ee2d5c22e940be1c4e50be88675.svg",
            "isPro": false,
            "fullname": "Haitao Mi",
            "user": "haitaominlp",
            "type": "user"
          },
          "name": "Haitao Mi",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-31T08:43:21.871Z",
          "hidden": false
        },
        {
          "_id": "679c5ca666c379e215bc9e81",
          "name": "Dong Yu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-30T18:58:18.000Z",
      "title": "Les pensées à chaque endroit se dispersent, et une réflexion sur la manque de pensée dans les modèles de type ou1-Like LLMs.",
      "summary": "Par exemple, le modèle de langage grand (LLMs) comme l'o1 d'OpenAI augmente la quantité de calculs dans les tests pour montrer des pensées profondes comme celles d'un être humain et démontrer des habiletés exceptionnelles dans des tâches de théorie de la raison. Cependant, nous avons constaté que les modèles comme l'o1 ne font pas une exploration suffisante pour atteindre des solutions désirées, ce qui nous appelle \"underthinking\" et nous rendons compte de ce phénomène. Cette comportement conduit à une faiblesse dans la théorie de la raison et à une perte de performance. Spécifiquement, ce problème est plus prononcé lorsqu'il s'agit de problèmes mathématiques difficiles.\n\nPour analyser ce problème de manière systématique, nous avons réalisé des expériences avec trois ensembles de tests difficiles et avec deux des principaux modèles de code ouverts similaires à l'o1, révélant ainsi l'association entre le changement fréquent de pensée et les réponses négatives. Nous avons mesuré l'efficacité des tokens des réponses négatives et introduit un nouveau métrique pour quantifier \"underthinking\". Nous avons proposé une stratégie de décodage avec une pénalité pour le changement de pensée, nommée \"TIP\", avec l'objectif d'inhiber le changement de pensée excessif et de promouvoir une exploration profonde à chaque étape de la théorie de la raison.\n\nLes résultats des expériences montrent que notre approche améliore la précision du modèle dans les ensembles de données difficiles, évitant nécessairement des ajustements du modèle. Ce que nous avons trouvé contribue à comprendre l'adéquation de la théorie de la raison dans des modèles comme l'o1 et fournit des solutions pratiques pour améliorer sa capacité à résoudre des problèmes.",
      "upvotes": 6,
      "discussionId": "679c5ca766c379e215bc9eb1"
    },
    "publishedAt": "2025-01-31T00:16:36.453Z",
    "title": "Thoughts Are All Over the Place: On the Underthinking of o1-Like LLMs",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.18585.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5875
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.16411",
      "authors": [
        {
          "_id": "679c4f344061a1ab60ebe6fa",
          "user": {
            "_id": "644b71ddb2e7823a76abcf91",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/644b71ddb2e7823a76abcf91/JPF7Eqeq2jx8i79nQ962K.jpeg",
            "isPro": false,
            "fullname": "zhou wei",
            "user": "WeiChow",
            "type": "user"
          },
          "name": "Wei Chow",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-01-31T08:35:49.674Z",
          "hidden": false
        },
        {
          "_id": "679c4f344061a1ab60ebe6fb",
          "name": "Jiageng Mao",
          "hidden": false
        },
        {
          "_id": "679c4f344061a1ab60ebe6fc",
          "user": {
            "_id": "620dd3888528f797e88cb9b5",
            "avatarUrl": "/avatars/af04728788d78fe7d6375e19e32a535e.svg",
            "isPro": false,
            "fullname": "Boyi Li",
            "user": "Boyiliee",
            "type": "user"
          },
          "name": "Boyi Li",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-31T08:46:09.305Z",
          "hidden": false
        },
        {
          "_id": "679c4f344061a1ab60ebe6fd",
          "name": "Daniel Seita",
          "hidden": false
        },
        {
          "_id": "679c4f344061a1ab60ebe6fe",
          "name": "Vitor Guizilini",
          "hidden": false
        },
        {
          "_id": "679c4f344061a1ab60ebe6ff",
          "name": "Yue Wang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-27T18:59:58.000Z",
      "title": "PhysBench : Marqueur et amélioration pour des modèles de langage visuo-syntaxique pour comprendre le monde physique",
      "summary": "Dans le contexte de l'intelligence artificielle corporelle, la compréhension du monde physique est un problème fondamental, étant cruciale pour l'exécution de tâches complexes dans des environnements réels et la manipulation sécurisée. Les modèles de vision-langage (VLMs) montrent une possibilité exceptionnelle dans la logique et la planification des tâches des agents corporels, mais leur compréhension des phénomènes physiques est très limitée. Pour combler cette lacune, nous présentons PhysBench. Ceci est un cadre d'évaluation détaillé conçu pour évaluer la compréhension du monde physique et évalue la compréhension physique dans diverses tâches. PhysBench est classifié dans quatre domaines principaux : propriétés des objets physiques, relations entre objets physiques, compréhension de l'espace physique et physique de la mécanique, et est développé dans 19 sous-domaines et 8 niveaux de compétence différents. Nos expériences d'extension ont été réalisées avec 75 VLMs représentatifs, démontrant clairement que, bien que ces modèles dépassent la logique générale, ont des difficultés dans la compréhension du monde physique, ce qui est attribué aux déficiences dans les données d'entraînement qui manquent des connaissances physiques. Pour résoudre ces déficiences, nous présentons PhysAgent. Ceci est un nouveau cadre de travail qui intègre la généralisation des VLMs et le savoir spécifique des modèles visuels, améliorant significativement la compréhension physique dans diverses tâches. Une augmentation de 18,4% a été observée dans le cas de GPT-4o. De plus, nos résultats montrent que la compréhension du monde physique de MOKA, comme un agent corporel, peut être améliorée. Nous considérons que PhysBench et PhysAgent fournissent une guidance utile pour combler la lacune entre les VLMs et la compréhension du monde physique, contribuant de manière significative à cet objectif.",
      "upvotes": 6,
      "discussionId": "679c4f394061a1ab60ebe7f0"
    },
    "publishedAt": "2025-01-30T23:19:24.751Z",
    "title": "PhysBench: Benchmarking and Enhancing Vision-Language Models for Physical World Understanding",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.16411.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "644b71ddb2e7823a76abcf91",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/644b71ddb2e7823a76abcf91/JPF7Eqeq2jx8i79nQ962K.jpeg",
      "fullname": "zhou wei",
      "name": "WeiChow",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 3
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2501.18438",
      "authors": [
        {
          "_id": "679c7d0ebd893fb2b7159aa3",
          "user": {
            "_id": "657b3a44de028a439ea2ed9d",
            "avatarUrl": "/avatars/9f05e8eb6809a0ce1b50cd1fc9b5a044.svg",
            "isPro": false,
            "fullname": "Aitor Arrieta",
            "user": "aitorarrieta",
            "type": "user"
          },
          "name": "Aitor Arrieta",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-01-31T07:34:38.875Z",
          "hidden": false
        },
        {
          "_id": "679c7d0ebd893fb2b7159aa4",
          "name": "Miriam Ugarte",
          "hidden": false
        },
        {
          "_id": "679c7d0ebd893fb2b7159aa5",
          "user": {
            "_id": "65001514f322f9156663f096",
            "avatarUrl": "/avatars/e8712f60d4e8b7c70ac02c532ad547ef.svg",
            "isPro": false,
            "fullname": "Pablo Valle",
            "user": "pablovalle",
            "type": "user"
          },
          "name": "Pablo Valle",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-01-31T08:35:44.931Z",
          "hidden": false
        },
        {
          "_id": "679c7d0ebd893fb2b7159aa6",
          "user": {
            "_id": "63527de67e4cc3135fd16651",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63527de67e4cc3135fd16651/bkeQlJEwsPs3E4EsvmmLB.jpeg",
            "isPro": false,
            "fullname": "José Antonio Parejo Maestre",
            "user": "japarejo",
            "type": "user"
          },
          "name": "José Antonio Parejo",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-31T08:49:45.440Z",
          "hidden": false
        },
        {
          "_id": "679c7d0ebd893fb2b7159aa7",
          "user": {
            "_id": "6790d642a1863df579840ae3",
            "avatarUrl": "/avatars/a10a6f4af327c1bb67513c56d7f84820.svg",
            "isPro": false,
            "fullname": "Sergio Segura",
            "user": "ssegura",
            "type": "user"
          },
          "name": "Sergio Segura",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-01-31T07:34:38.876Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-30T15:45:56.000Z",
      "title": "o3-mini vs DeepSeek-R1 : Quelle est la plus sûre ?",
      "summary": "L'entrée de DeepSeek-R1 a jou le rôle de point de transition dans tout le secteur de l'industrie de l'IA, surtout dans le domaine des LLM. Sa capacité a démontré des résultats exceptionnels dans des tâches telles que le pensée créative, la génération de code, les mathématiques et la modification automatique de programmes, mais son coût d'exécution a été considérablement réduit. Cependant, les LLM doivent maintenir des caractéristiques qualitatives importantes. C'est-à-dire, ils doivent conserver les valeurs de sécurité et la conformité aux valeurs humaines. DeepSeek-R1 a un adversaire clair dans le modèle o3-mini d'OpenAI, un état-unien. On espère que ce modèle établira des normes élevées en termes de rendement, sécurité et coût. Dans cet article, nous évaluons de manière systématique le niveau de sécurité de DeepSeek-R1 (version 70b) et o3-mini (version beta d'OpenAI). Pour cela, nous avons utilisé l'outil de tests de sécurité automatisée récemment publié, ASTRAL. En utilisant cet outil, nous avons généré et exécuté automatiquement un total de 1260 entrées de tests insecuris pour les deux modèles. Après avoir évalué de manière semi-automatique les résultats fournis par les deux modèles, nous avons constaté que DeepSeek-R1 montre un niveau de non-sécurité supérieur à o3-mini. Selon notre évaluation, DeepSeek-R1 a répondu non-sécurément à 11,98% des formulaires exécutés, tandis que o3-mini a répondu non-sécurément seulement à 1,19%.",
      "upvotes": 4,
      "discussionId": "679c7d0ebd893fb2b7159af5"
    },
    "publishedAt": "2025-01-31T02:35:40.107Z",
    "title": "o3-mini vs DeepSeek-R1: Which One is Safer?",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.18438.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "65001514f322f9156663f096",
      "avatarUrl": "/avatars/e8712f60d4e8b7c70ac02c532ad547ef.svg",
      "fullname": "Pablo Valle",
      "name": "pablovalle",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2501.18511",
      "authors": [
        {
          "_id": "679c9419a01fd6df443d5729",
          "user": {
            "_id": "62f7f4efe7c1c9bf10c81465",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62f7f4efe7c1c9bf10c81465/AYlOg0fkP1o4GAP-8Y3xt.jpeg",
            "isPro": true,
            "fullname": "Benjamin Feuer",
            "user": "penfever",
            "type": "user"
          },
          "name": "Benjamin Feuer",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-31T09:35:53.653Z",
          "hidden": false
        },
        {
          "_id": "679c9419a01fd6df443d572a",
          "name": "Chinmay Hegde",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-30T17:21:44.000Z",
      "title": "WILDCHAT-50M : Révision Profonde du Role des Données Synthétiques Après l'Entraînement",
      "summary": "Le processus postérieur de modèles de langue (MLL) peut être utilisé pour réviser des actions depuis le DPO jusqu'à la distillation et développer de nouvelles compétences. Cependant, ce type de processus est encore à ses débuts. L'un des facteurs limitants est la difficulté de comparer analytiquement à grande échelle des modèles de données synthétiques et des évaluateurs de MLL. Pour résoudre ce problème, nous présentons WILDCHAT-50M, le plus grand ensemble de données de conversation publique jusqu'à présent. Nous étendons l'ensemble de données actuel de WildChat et nous incluons des réponses de plus de 50 modèles de poids ouverts, en plus de GPT. Nous effectuons un analyse comparative à grande échelle et nous créons RE-WILD, notre mélange d'entraînement ouvert, pour montrer la possibilité de cet ensemble de données. Nous dépassent la mélange d'entraînement Tulu-3 de l'Allen AI récemment publié, avec une proportion de 40% des échantillons. L'ensemble de données, les échantillons et le code sont disponibles sur https://github.com/penfever/wildchat-50m.",
      "upvotes": 2,
      "discussionId": "679c941da01fd6df443d5907"
    },
    "publishedAt": "2025-01-31T04:13:28.061Z",
    "title": "WILDCHAT-50M: A Deep Dive Into the Role of Synthetic Data in Post-Training",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.18511.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60107b385ac3e86b3ea4fc34",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1627505688463-60107b385ac3e86b3ea4fc34.jpeg",
      "fullname": "Daniel van Strien",
      "name": "davanstrien",
      "type": "user",
      "isPro": true,
      "isHf": true,
      "isMod": false,
      "followerCount": 519
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.18009",
      "authors": [
        {
          "_id": "679c5b0259e9218a222ab742",
          "user": {
            "_id": "6689f7fb8c440fe1955a51b5",
            "avatarUrl": "/avatars/9b23ee2f05f55615c6174a678436b30d.svg",
            "isPro": false,
            "fullname": "Lan Pan",
            "user": "louanna",
            "type": "user"
          },
          "name": "Lan Pan",
          "status": "extracted_confirmed",
          "statusLastChangedAt": "2025-01-31T06:33:49.785Z",
          "hidden": false
        },
        {
          "_id": "679c5b0259e9218a222ab743",
          "user": {
            "_id": "63fd543a3c880680af459cad",
            "avatarUrl": "/avatars/2a90a4b002fe0d09e28ce0e111357748.svg",
            "isPro": false,
            "fullname": "Hanbo Xie",
            "user": "xhb120633",
            "type": "user"
          },
          "name": "Hanbo Xie",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-31T08:51:40.573Z",
          "hidden": false
        },
        {
          "_id": "679c5b0259e9218a222ab744",
          "name": "Robert C. Wilson",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-29T21:51:17.000Z",
      "title": "Le langage de la majorité des langages de programmation est stocké de manière efficace pour qu'ils puissent être explorés rapidement.",
      "summary": "Les modèles de langue générale ont développé une grande variété de compétences intelligentes. Pour les évaluer, plusieurs référentiels ont été utilisés, mais leur capacité d'exploration a reçu moins d'attention, et des recherches sur leur capacité à découvrir de nouvelles informations dans des environnements naturels et artificiels ont été omises. Il n'est pas clair à quel point les limites de l'exploration des modèles de langue générale (LLM) sont limitées dans des tâches ouvertes qui dépassent celles des humains. Ce travail étudie si les LLM peuvent explorer plus loin que les humains dans des tâches ouvertes, en utilisant Little Alchemy 2 comme paradigme. Les résultats montrent que la plupart des LLM sont moins efficaces que les humains, avec l'exception du modèle o1. Les modèles traditionnels de LLM principalement utilisent des stratégies basées sur l'incertitude, tandis que les humains équilibrent l'incertitude et la motivation. L'analyse des représentations des modèles utilisant des autoencodeurs sparses montre que l'incertitude et la sélection se manifestent dans les blocs transformers initiaux, et le valeur de la motivation est traitée dans la moitié postérieure. Les LLM font des décisions excessives et empêchent une exploration valide. Ces résultats indiquent que les limites de l'exploration des LLM sont claires et proposent des directions pour améliorer leur adaptabilité.",
      "upvotes": 2,
      "discussionId": "679c5b0359e9218a222ab76f"
    },
    "publishedAt": "2025-01-31T00:09:40.077Z",
    "title": "Large Language Models Think Too Fast To Explore Effectively",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.18009.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5875
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.18512",
      "authors": [
        {
          "_id": "679ca01ecad2402cec0a939a",
          "name": "Arthur Douillard",
          "hidden": false
        },
        {
          "_id": "679ca01ecad2402cec0a939b",
          "name": "Yanislav Donchev",
          "hidden": false
        },
        {
          "_id": "679ca01ecad2402cec0a939c",
          "name": "Keith Rush",
          "hidden": false
        },
        {
          "_id": "679ca01ecad2402cec0a939d",
          "name": "Satyen Kale",
          "hidden": false
        },
        {
          "_id": "679ca01ecad2402cec0a939e",
          "name": "Zachary Charles",
          "hidden": false
        },
        {
          "_id": "679ca01ecad2402cec0a939f",
          "name": "Zachary Garrett",
          "hidden": false
        },
        {
          "_id": "679ca01ecad2402cec0a93a0",
          "name": "Gabriel Teston",
          "hidden": false
        },
        {
          "_id": "679ca01ecad2402cec0a93a1",
          "name": "Dave Lacey",
          "hidden": false
        },
        {
          "_id": "679ca01ecad2402cec0a93a2",
          "name": "Ross McIlroy",
          "hidden": false
        },
        {
          "_id": "679ca01ecad2402cec0a93a3",
          "name": "Jiajun Shen",
          "hidden": false
        },
        {
          "_id": "679ca01ecad2402cec0a93a4",
          "name": "Alexandre Ramé",
          "hidden": false
        },
        {
          "_id": "679ca01ecad2402cec0a93a5",
          "name": "Arthur Szlam",
          "hidden": false
        },
        {
          "_id": "679ca01ecad2402cec0a93a6",
          "name": "Marc'Aurelio Ranzato",
          "hidden": false
        },
        {
          "_id": "679ca01ecad2402cec0a93a7",
          "name": "Paul Barham",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-30T17:23:50.000Z",
      "title": "Streaming Droco et la communication : cherchant le relaxation dans la liberté des systèmes distribués",
      "summary": "L'entraînement de modèles de langage grands (LLMs) se fait généralement avec l'aide de plusieurs accélérateurs pour réduire le temps d'entraînement. En raison du fait que les états internes et les valeurs des gradients des paramètres sont échangés à chaque pas de gradient, tous les dispositifs doivent utiliser des liaisons de communication rapides, comme des bandes larges, pour travailler de manière coordonnée. Récemment, des algorithmes de distribution comme DiLoCo ont atténué ces restrictions, permettant de regrouper les accélérateurs comme des \"workers\" et de réduire la fréquence de la synchronisation entre les workers. Cela a permis que les workers utilisent des liaisons de communication lentes, mais il est nécessaire de s'assurer que cela ne dégrade pas la qualité de l'entraînement. Cependant, ces méthodes continuent de nécessiter de synchroniser tous les paramètres entre tous les workers, ce qui maintient la demande de bande large élevée. Dans cet article, on améliore les trois formes de DiLoCo. Premièrement, on permet de synchroniser partiellement les paramètres sans synchroniser tous, en synchronisant en ordre sous-ensembles de paramètres pour réduire significativement la demande de bande large. Deuxièmement, on permet aux workers de continuer de synchroniser tout en entraînant pour réduire le temps de synchronisation. Troisièmement, on digitalise les données échangées entre les workers pour réduire encore davantage la demande de bande large. En combinant ces améliorations adéquatement, on démontre expérimentalement qu'il est possible d'entraîner un modèle avec 100 millions de paramètres de manière distribuée et d'atteindre la qualité de l'entraînement antérieure, en réduisant la demande de bande large en deux étapes.",
      "upvotes": 1,
      "discussionId": "679ca01fcad2402cec0a9404"
    },
    "publishedAt": "2025-01-31T05:07:14.120Z",
    "title": "Streaming DiLoCo with overlapping communication: Towards a Distributed Free Lunch",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.18512.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "622792366303bf1dc304f49f",
      "avatarUrl": "/avatars/975c1cc3eb2f97cf8e848162056d5bea.svg",
      "fullname": "Arthur Douillard",
      "name": "ArthurDouillard",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": false
  }
]