[
  {
    "paper": {
      "id": "2501.17161",
      "authors": [
        {
          "_id": "6799b39b15f4661561c22968",
          "name": "Tianzhe Chu",
          "hidden": false
        },
        {
          "_id": "6799b39b15f4661561c22969",
          "name": "Yuexiang Zhai",
          "hidden": false
        },
        {
          "_id": "6799b39b15f4661561c2296a",
          "name": "Jihan Yang",
          "hidden": false
        },
        {
          "_id": "6799b39b15f4661561c2296b",
          "name": "Shengbang Tong",
          "hidden": false
        },
        {
          "_id": "6799b39b15f4661561c2296c",
          "name": "Saining Xie",
          "hidden": false
        },
        {
          "_id": "6799b39b15f4661561c2296d",
          "name": "Dale Schuurmans",
          "hidden": false
        },
        {
          "_id": "6799b39b15f4661561c2296e",
          "name": "Quoc V. Le",
          "hidden": false
        },
        {
          "_id": "6799b39b15f4661561c2296f",
          "name": "Sergey Levine",
          "hidden": false
        },
        {
          "_id": "6799b39b15f4661561c22970",
          "name": "Yi Ma",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-28T18:59:44.000Z",
      "title": "SFT Memoria, Généralisation RL : Étude de Comparaison Post-Évaluation des Modèles de Base",
      "summary": "Les modèles d'entraînement de Supervised Fine-Tuning (SFT) et de Reinforcement Learning (RL) sont largement utilisés après l'entraînement initial des modèles de base, bien qu'il n'y ait pas une discussion claire sur comment améliorent la capacité de généralisation des modèles. Dans cet article, nous examinons les différences dans la généralisation et le processus de mémoire de SFT et RL, avec un accent sur les changements de règle et les changements visuels basés sur le contexte. De plus, nous utilisons le jeu de cartes d'inférence arithmétique \"GeneralPoints\" et la configuration V-IRL (environnement de cartographie dans le monde réel) pour évaluer comment les modèles entraînés avec SFT et RL généralisent dans des situations non vues de contexte et de vision. Ces résultats montrent que RL, en particulier, peut généraliser dans des situations basées sur des règles et des visualisations lorsqu'il est entraîné avec des récompenses basées sur les résultats. Par contre, SFT présente des difficultés à généraliser en dehors de la distribution des données d'entraînement. Dans l'analyse effectuée, RL améliore la capacité potentielle de reconnaissance visuelle du modèle et favorise la généralisation dans le domaine visuel. Malgré sa capacité excellente à généraliser, SFT joue un rôle important dans l'entraînement efficace de RL. SFT stabilise le format de sortie du modèle et peut améliorer le rendement dans les prochaines étapes de RL. Ces résultats démontrent la capacité de RL à acquérir des connaissances généralisables dans des tâches multimodales complexes.",
      "upvotes": 11,
      "discussionId": "6799b39d15f4661561c229e6"
    },
    "publishedAt": "2025-01-28T23:50:56.664Z",
    "title": "SFT Memorizes, RL Generalizes: A Comparative Study of Foundation Model Post-training",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.17161.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5850
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.17116",
      "authors": [
        {
          "_id": "6799b367d30dc065a2d51592",
          "name": "Ruizhe Wang",
          "hidden": false
        },
        {
          "_id": "6799b367d30dc065a2d51593",
          "name": "Yeyun Gong",
          "hidden": false
        },
        {
          "_id": "6799b367d30dc065a2d51594",
          "name": "Xiao Liu",
          "hidden": false
        },
        {
          "_id": "6799b367d30dc065a2d51595",
          "name": "Guoshuai Zhao",
          "hidden": false
        },
        {
          "_id": "6799b367d30dc065a2d51596",
          "name": "Ziyue Yang",
          "hidden": false
        },
        {
          "_id": "6799b367d30dc065a2d51597",
          "name": "Baining Guo",
          "hidden": false
        },
        {
          "_id": "6799b367d30dc065a2d51598",
          "name": "Zhengjun Zha",
          "hidden": false
        },
        {
          "_id": "6799b367d30dc065a2d51599",
          "user": {
            "_id": "653feb7ccf1f9c88f4928910",
            "avatarUrl": "/avatars/23a6a6818116683ea9485e1470a0062f.svg",
            "isPro": false,
            "fullname": "Peng Cheng",
            "user": "cp5555",
            "type": "user"
          },
          "name": "Peng Cheng",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-01-29T04:49:44.372Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-28T18:04:50.000Z",
      "title": "Utilisant le type de données FP4 pour optimiser l'entraînement de modèles de langage grands",
      "summary": "Les modèles de langage grands (LLMs) nécessitent une augmentation de la demande de calcul, ce qui entraîne une inefficacité dans leur entraînement. L'entraînement quantifié permet des calculs à faible précision, ce qui constitue une bonne solution pour réduire ces coûts. Il a été démontré la possibilité d'implémenter la précision FP8, bien que l'utilisation de FP4 génère des erreurs significatives et limite l'expression. Cet article présente le premier cadre d'entraînement de LLMs en FP4, abordant deux innovations clés : l'Étude Différenciable et la Capture et Correction de Valeurs Anormales pour éviter la destruction des activations. Pour garantir la stabilité, le cadre combine l'entraînement de précision mixte et la vectorisation de la quantification. Les résultats expérimentaux montrent que notre cadre en FP4 atteint une précision similaire à BF16 et FP8 avec une perte minimale. Il est capable d'entraîner des LLMs de 13B paramètres avec 100B tokens. Dans les futurs générateurs de logiciels qui supportent FP4, notre cadre pourra être la base pour une entraînement efficace en ultra-faible précision.",
      "upvotes": 9,
      "discussionId": "6799b368d30dc065a2d515bf"
    },
    "publishedAt": "2025-01-28T23:50:12.472Z",
    "title": "Optimizing Large Language Model Training Using FP4 Quantization",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.17116.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5850
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.16975",
      "authors": [
        {
          "_id": "6799b345a66ae6b357bef986",
          "name": "Hongzhi Huang",
          "hidden": false
        },
        {
          "_id": "6799b345a66ae6b357bef987",
          "name": "Defa Zhu",
          "hidden": false
        },
        {
          "_id": "6799b345a66ae6b357bef988",
          "name": "Banggu Wu",
          "hidden": false
        },
        {
          "_id": "6799b345a66ae6b357bef989",
          "name": "Yutao Zeng",
          "hidden": false
        },
        {
          "_id": "6799b345a66ae6b357bef98a",
          "name": "Ya Wang",
          "hidden": false
        },
        {
          "_id": "6799b345a66ae6b357bef98b",
          "name": "Qiyang Min",
          "hidden": false
        },
        {
          "_id": "6799b345a66ae6b357bef98c",
          "name": "Xun Zhou",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-28T14:15:42.000Z",
      "title": "Transformer : le Vocabulaire généralement valorise l'échelle",
      "summary": "La tokenización est une composante fondamentale des modèles de langage à grande échelle (LLMs) et son impact n'a pas été entièrement étudié. Dans cet article, nous présentons un nouveau cadre de travail appelé \"Transformers Over-Tokenized\" pour améliorer le rendement de la modélisation du langage. Spécifiquement, notre approche élargit la collection de tokens d'entrée et utilise des bigrammes de tokens pour atteindre l'échelle. A travers des expériences détaillées, nous démontrons une relation logarithmique-linéaire entre le nombre de tokens d'entrée et la perte d'entraînement, et nous montrons que une grande collection de tokens d'entrée améliore constamment le rendement du modèle, indépendamment de son taille. En utilisant une grande collection de tokens d'entrée, il est possible d'atteindre un rendement équivalent à double du taille du modèle de base sans coûts supplémentaires. Nos résultats soulignent l'importance de la tokenisation dans les lois d'échelle et fournissent une orientation pratique pour le design de tokenisateurs, ouvrant des voies pour la création de LLMs plus efficaces et puissants.",
      "upvotes": 6,
      "discussionId": "6799b346a66ae6b357bef9e3"
    },
    "publishedAt": "2025-01-28T23:49:26.959Z",
    "title": "Over-Tokenized Transformer: Vocabulary is Generally Worth Scaling",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.16975.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5850
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.16764",
      "authors": [
        {
          "_id": "6799aa5a311dbfe3c96724cd",
          "name": "Chenguo Lin",
          "hidden": false
        },
        {
          "_id": "6799aa5a311dbfe3c96724ce",
          "name": "Panwang Pan",
          "hidden": false
        },
        {
          "_id": "6799aa5a311dbfe3c96724cf",
          "name": "Bangbang Yang",
          "hidden": false
        },
        {
          "_id": "6799aa5a311dbfe3c96724d0",
          "name": "Zeming Li",
          "hidden": false
        },
        {
          "_id": "6799aa5a311dbfe3c96724d1",
          "name": "Yadong Mu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-28T07:38:59.000Z",
      "title": "DiffSplat : Utilisation de modèles de diffusion d'images pour la génération scalable de Gaussiennes Splats",
      "summary": "Récemment, le développement du contenu 3D a révélé des limitations dans les ensembles de données de haute qualité et des incertitudes dans la génération de polyèdres 2D. Nous présentons un nouveau cadre de génération 3D appelé 'DiffSplat', qui utilise un modèle pour étendre les grandes échelles de texte à des images pour générer des gaussiennes 3D de manière immédiate. Ce modèle, en contraste avec les modèles de génération 3D précédents, utilise effectivement des modèles 2D à l'échelle web et maintient la cohérence 3D grâce à un modèle unifié. Pour initier l'entraînement, nous proposons un modèle de reconstruction léger et une graphique de gaussiennes splats pour la génération instantanée de polyèdres qui s'adaptent à un ensemble de données scalable. Nous ajoutons une perte de diffusion générale pour la graphique et une perte de rendu 3D pour promouvoir la cohérence 3D. En raison de sa bonne compatibilité avec les modèles de diffusion d'images, de nombreuses technologies de génération d'images peuvent être facilement appliquées dans le domaine 3D. Les expériences étendues ont démontré des résultats exceptionnels dans la génération de texte et d'images par DiffSplat et ses applications ultérieures. Les expériences détaillées ont testé l'efficacité de chaque décision de conception cruciale et ont fourni des insights sur les technologies futures.",
      "upvotes": 4,
      "discussionId": "6799aa5c311dbfe3c9672542"
    },
    "publishedAt": "2025-01-29T01:12:02.839Z",
    "title": "DiffSplat: Repurposing Image Diffusion Models for Scalable Gaussian Splat Generation",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/654866e8cd0a5621395f8287/TFJMeKzXxMLOnq8NH8ltZ.mp4",
      "https://cdn-uploads.huggingface.co/production/uploads/654866e8cd0a5621395f8287/6kn1RLEUsUV-W6S0Taylo.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.16764.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "654866e8cd0a5621395f8287",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/654866e8cd0a5621395f8287/4Bccwd1ehn-Ee4T1rId5S.jpeg",
      "fullname": "Panwang Pan",
      "name": "paulpanwang",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 3
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.16496",
      "authors": [
        {
          "_id": "6799b2fbfe3c29ec219d7d99",
          "name": "Lee Sharkey",
          "hidden": false
        },
        {
          "_id": "6799b2fbfe3c29ec219d7d9a",
          "user": {
            "_id": "64ad563f4beffa272de6efac",
            "avatarUrl": "/avatars/f1a4902a95830cc3936058449626f8e4.svg",
            "isPro": false,
            "fullname": "Bilal Chughtai",
            "user": "bilalchughtai",
            "type": "user"
          },
          "name": "Bilal Chughtai",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-01-29T04:47:56.702Z",
          "hidden": false
        },
        {
          "_id": "6799b2fbfe3c29ec219d7d9b",
          "name": "Joshua Batson",
          "hidden": false
        },
        {
          "_id": "6799b2fbfe3c29ec219d7d9c",
          "name": "Jack Lindsey",
          "hidden": false
        },
        {
          "_id": "6799b2fbfe3c29ec219d7d9d",
          "name": "Jeff Wu",
          "hidden": false
        },
        {
          "_id": "6799b2fbfe3c29ec219d7d9e",
          "name": "Lucius Bushnaq",
          "hidden": false
        },
        {
          "_id": "6799b2fbfe3c29ec219d7d9f",
          "name": "Nicholas Goldowsky-Dill",
          "hidden": false
        },
        {
          "_id": "6799b2fbfe3c29ec219d7da0",
          "name": "Stefan Heimersheim",
          "hidden": false
        },
        {
          "_id": "6799b2fbfe3c29ec219d7da1",
          "name": "Alejandro Ortega",
          "hidden": false
        },
        {
          "_id": "6799b2fbfe3c29ec219d7da2",
          "name": "Joseph Bloom",
          "hidden": false
        },
        {
          "_id": "6799b2fbfe3c29ec219d7da3",
          "name": "Stella Biderman",
          "hidden": false
        },
        {
          "_id": "6799b2fbfe3c29ec219d7da4",
          "name": "Adria Garriga-Alonso",
          "hidden": false
        },
        {
          "_id": "6799b2fbfe3c29ec219d7da5",
          "name": "Arthur Conmy",
          "hidden": false
        },
        {
          "_id": "6799b2fbfe3c29ec219d7da6",
          "name": "Neel Nanda",
          "hidden": false
        },
        {
          "_id": "6799b2fbfe3c29ec219d7da7",
          "name": "Jessica Rumbelow",
          "hidden": false
        },
        {
          "_id": "6799b2fbfe3c29ec219d7da8",
          "name": "Martin Wattenberg",
          "hidden": false
        },
        {
          "_id": "6799b2fbfe3c29ec219d7da9",
          "name": "Nandi Schoots",
          "hidden": false
        },
        {
          "_id": "6799b2fbfe3c29ec219d7daa",
          "name": "Joseph Miller",
          "hidden": false
        },
        {
          "_id": "6799b2fbfe3c29ec219d7dab",
          "name": "Eric J. Michaud",
          "hidden": false
        },
        {
          "_id": "6799b2fbfe3c29ec219d7dac",
          "name": "Stephen Casper",
          "hidden": false
        },
        {
          "_id": "6799b2fbfe3c29ec219d7dad",
          "name": "Max Tegmark",
          "hidden": false
        },
        {
          "_id": "6799b2fbfe3c29ec219d7dae",
          "name": "William Saunders",
          "hidden": false
        },
        {
          "_id": "6799b2fbfe3c29ec219d7daf",
          "name": "David Bau",
          "hidden": false
        },
        {
          "_id": "6799b2fbfe3c29ec219d7db0",
          "name": "Eric Todd",
          "hidden": false
        },
        {
          "_id": "6799b2fbfe3c29ec219d7db1",
          "name": "Atticus Geiger",
          "hidden": false
        },
        {
          "_id": "6799b2fbfe3c29ec219d7db2",
          "name": "Mor Geva",
          "hidden": false
        },
        {
          "_id": "6799b2fbfe3c29ec219d7db3",
          "name": "Jesse Hoogland",
          "hidden": false
        },
        {
          "_id": "6799b2fbfe3c29ec219d7db4",
          "name": "Daniel Murfet",
          "hidden": false
        },
        {
          "_id": "6799b2fbfe3c29ec219d7db5",
          "name": "Tom McGrath",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-27T20:57:18.000Z",
      "title": "Description des problèmes ouverts de la description des dispositifs mécaniques",
      "summary": "L'interprétation mécanique dépend de la structure computationnelle des réseaux neuronaux et vise à atteindre des objectifs scientifiques et techniques spécifiques. Le développement de cette domaine confère une grande confiance au comportement des systèmes d'IA et promet de clarifier des questions scientifiques profondes sur les caractéristiques du cerveau. Malgré les avancées récentes, l'domaine reste ouvert à de nombreuses questions, et de nombreux bénéfices scientifiques et pratiques ne peuvent être atteints jusqu'à ce que ces questions soient résolues : notre approche nécessite des améliorations conceptuelles et pratiques, et révèle des profondes insights ; nous devons clairement définir comment appliquer notre approche de manière optimale pour atteindre certains objectifs ; et ce domaine se confronte à des problèmes techniques et sociaux qui peuvent nous affecter ou qui nous affectent. Dans cette revue avancée, les limites actuelles de l'interprétation mécanique et les questions ouvertes qui doivent être abordées prioritairement dans ce domaine sont discutées.",
      "upvotes": 4,
      "discussionId": "6799b2fcfe3c29ec219d7dca"
    },
    "publishedAt": "2025-01-28T23:48:30.888Z",
    "title": "Open Problems in Mechanistic Interpretability",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.16496.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5850
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.15747",
      "authors": [
        {
          "_id": "6799946c18cb282841d42639",
          "name": "Sankalp KJ",
          "hidden": false
        },
        {
          "_id": "6799946c18cb282841d4263a",
          "name": "Ashutosh Kumar",
          "hidden": false
        },
        {
          "_id": "6799946c18cb282841d4263b",
          "user": {
            "_id": "66707b60405252abeefd4c50",
            "avatarUrl": "/avatars/ee2728f115376e234e96820b8b376849.svg",
            "isPro": false,
            "fullname": "Laxmaan Balaji",
            "user": "laxmaanb",
            "type": "user"
          },
          "name": "Laxmaan Balaji",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-01-29T02:37:34.240Z",
          "hidden": false
        },
        {
          "_id": "6799946c18cb282841d4263c",
          "name": "Nikunj Kotecha",
          "hidden": false
        },
        {
          "_id": "6799946c18cb282841d4263d",
          "name": "Vinija Jain",
          "hidden": false
        },
        {
          "_id": "6799946c18cb282841d4263e",
          "user": {
            "_id": "63a4754927f1f64ed7238dac",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63a4754927f1f64ed7238dac/aH-eJF-31g4vof9jv2gmI.jpeg",
            "isPro": false,
            "fullname": "Aman Chadha",
            "user": "amanchadha",
            "type": "user"
          },
          "name": "Aman Chadha",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-01-29T08:55:14.312Z",
          "hidden": false
        },
        {
          "_id": "6799946c18cb282841d4263f",
          "name": "Sreyoshi Bhaduri",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-27T03:19:03.000Z",
      "title": "IndicMMLU-Pro : Base de tests de compréhension multi- tâche de modèles de langage à grande échelle dans les pays asiatiques",
      "summary": "La population de plus de 1,5 milliards de personnes dans le continent des Indes connaît un langue indoue qui offre un riche patrimoine culturel, une grande diversité linguistique et des structures complexes, offrant autant de défis que d'opportunités pour les études de traitement du langage naturel (NLP). IndicMMLU-Pro est un cadre de référence détaillé pour évaluer les modèles de langage grand (LLMs) en langues indoues, conçu en s'appuyant sur le cadre de référence MMLU Pro (Multi-Task Language Understanding). Il se concentre sur les langues principales telles que l'hindi, le bengali, le gujarati, le marathi, le kannada, le punjabi, le tamil, le telugu et l'urdu, abordant spécifiquement les défis issus de la diversité linguistique du continent. Ce cadre de référence vise à maximiser la compréhension des caractéristiques complexes des langues indoues dans une large gamme de tâches, y compris la compréhension du langage, la logique et la génération. IndicMMLU-Pro fournit des rétroactions pour la recherche en IA, soutenant le développement de modèles avec précision, efficacité et sensibilité culturelle, offrant un cadre d'évaluation standard. Cet article présente les principes de conception du cadre de référence, la technologie des tâches, les méthodes de collecte de données et les résultats de référence des modèles multilingues les plus récents.",
      "upvotes": 3,
      "discussionId": "6799946e18cb282841d426d6"
    },
    "publishedAt": "2025-01-28T21:38:17.182Z",
    "title": "IndicMMLU-Pro: Benchmarking Indic Large Language Models on Multi-Task Language Understanding",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.15747.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "63a4754927f1f64ed7238dac",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63a4754927f1f64ed7238dac/aH-eJF-31g4vof9jv2gmI.jpeg",
      "fullname": "Aman Chadha",
      "name": "amanchadha",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2501.16372",
      "authors": [
        {
          "_id": "67999c3dc1e34886f90320ee",
          "name": "J. Pablo Muñoz",
          "hidden": false
        },
        {
          "_id": "67999c3dc1e34886f90320ef",
          "name": "Jinjie Yuan",
          "hidden": false
        },
        {
          "_id": "67999c3dc1e34886f90320f0",
          "name": "Nilesh Jain",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-23T02:14:08.000Z",
      "title": "Bajada de orden de adaptateurs et exploration d'une nouvelle architecture de réseaux neuronaux s'ajoute à la compression de modèles grands.",
      "summary": "Le rapide croissance des modèles de langage profond (LLM) pose aux sociétés des problèmes graves en termes de ressources informatiques nécessaires pour le fine-tuning et le déploiement. Les avancées récentes des Adaptateurs de Rang Faible (Low-Rank Adapters) montrent les avantages d'un fine-tuning paramétrique efficace (PEFT) de ces modèles. Dans cet article, nous discutons en profondeur un approche innovante axée sur la représentation de rang faible et la recherche d'architectures neuronales (Neural Architecture Search, NAS), en particulier, la collaboration avec des réseaux super-réseaux de poids partagés. En intégrant ces méthodologies, des solutions puissantes sont développées pour la compression de modèles pré-entraînés et le fine-tuning. Notre analyse souligne spécialement la possibilité de démocratisation de ces stratégies combinées et les résultats qui favorisent l'utilisation de LLMs plus accessibles dans des environnements avec des limitations en ressources. En conséquence, les modèles obtenus réduisent le consommation de mémoire, le temps d'inférence et connectent la réalisation d'applications pratiques et scalables de LLMs. Les modèles et le code sont disponibles sur https://github.com/IntelLabs/Hardware-Aware-Automated-Machine-Learning.",
      "upvotes": 2,
      "discussionId": "67999c3dc1e34886f9032140"
    },
    "publishedAt": "2025-01-28T22:11:04.472Z",
    "title": "Low-Rank Adapters Meet Neural Architecture Search for LLM Compression",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.16372.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5850
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.17117",
      "authors": [
        {
          "_id": "6799e5f9121155210e4fa48c",
          "name": "Thibaud Leteno",
          "hidden": false
        },
        {
          "_id": "6799e5f9121155210e4fa48d",
          "name": "Irina Proskurina",
          "hidden": false
        },
        {
          "_id": "6799e5f9121155210e4fa48e",
          "name": "Antoine Gourru",
          "hidden": false
        },
        {
          "_id": "6799e5f9121155210e4fa48f",
          "name": "Julien Velcin",
          "hidden": false
        },
        {
          "_id": "6799e5f9121155210e4fa490",
          "name": "Charlotte Laclau",
          "hidden": false
        },
        {
          "_id": "6799e5f9121155210e4fa491",
          "name": "Guillaume Metzler",
          "hidden": false
        },
        {
          "_id": "6799e5f9121155210e4fa492",
          "name": "Christophe Gravier",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-28T18:07:30.000Z",
      "title": "Le dataset français \"MoralNorimar\" pour l'évaluation de la morale alimentaire",
      "summary": "Il est important que les modèles de langue se conforment aux valeurs humaines, surtout lorsqu'ils sont intégrés dans la vie quotidienne. Ces modèles sont généralement conçus pour s'adapter aux préférences des utilisateurs, mais ils doivent également refléter les valeurs et comportements réels de la société. Des progrès significatifs ont été réalisés en anglais et chinois, mais en français, moins d'attention a été accordée à ce domaine. Cela a empêché d'en comprendre comment les modèles de langage grands (LLMs) traitent des valeurs en français. Pour corriger cette situation, nous présentons le jeu de données français \"Les histoires de Mora\". Ceci est une traduction des histoires morales, révisée par des natifs français pour assurer la précision grammaticale et que cela convient au contexte culturel français. De plus, nous vérifions comment les valeurs au sein du jeu de données se conforment aux valeurs de la France. \"Les histoires de Mora\" incluent diverses situations sociales, comme l'inégalité des opportunités, la sincérité dans les relations et la responsabilité envers les animaux. Nous avons effectué des expériences initiales pour promouvoir la recherche future, en explorant des méthodes d'intégration de données dans différents langues et la robustesse de ces méthodes. Les modèles sont généralement influencés par les valeurs et désirs des utilisateurs, ce qui peut affecter l'intégration de données de valeurs.",
      "upvotes": 0,
      "discussionId": "6799e5fb121155210e4fa500"
    },
    "publishedAt": "2025-01-29T03:32:09.927Z",
    "title": "Histoires Morales: A French Dataset for Assessing Moral Alignment",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.17117.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "629a3dbcd496c6dcdebf41cc",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1655113762275-629a3dbcd496c6dcdebf41cc.jpeg",
      "fullname": "Irina Proskurina",
      "name": "iproskurina",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": false
  }
]