[
  {
    "paper": {
      "id": "2501.17161",
      "authors": [
        {
          "_id": "6799b39b15f4661561c22968",
          "name": "Tianzhe Chu",
          "hidden": false
        },
        {
          "_id": "6799b39b15f4661561c22969",
          "name": "Yuexiang Zhai",
          "hidden": false
        },
        {
          "_id": "6799b39b15f4661561c2296a",
          "name": "Jihan Yang",
          "hidden": false
        },
        {
          "_id": "6799b39b15f4661561c2296b",
          "name": "Shengbang Tong",
          "hidden": false
        },
        {
          "_id": "6799b39b15f4661561c2296c",
          "name": "Saining Xie",
          "hidden": false
        },
        {
          "_id": "6799b39b15f4661561c2296d",
          "name": "Dale Schuurmans",
          "hidden": false
        },
        {
          "_id": "6799b39b15f4661561c2296e",
          "name": "Quoc V. Le",
          "hidden": false
        },
        {
          "_id": "6799b39b15f4661561c2296f",
          "name": "Sergey Levine",
          "hidden": false
        },
        {
          "_id": "6799b39b15f4661561c22970",
          "name": "Yi Ma",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-28T18:59:44.000Z",
      "title": "Memoria de SFT, Généralisation de RL : Recherche après l'amélioration des modèles de base",
      "summary": "L'apprentissage initial (SFT) et l'apprentissage par récompense (RL) sont des techniques largement utilisées après l'entraînement de modèles de base, mais il n'est pas clair leur rôle dans l'amélioration de la capacité de généralisation du modèle. Dans cet article, nous explorons les différences en termes de généralisation et de mémoire entre SFT et RL, en nous concentrant sur les changements de règles et les changements visuels basés sur le contexte. Nous évaluons comment les modèles entraînés avec SFT et RL généralisent face à des variables contextuelles et visuelles non vues en utilisant le jeu de l'arithmétique GeneralPoints et l'environnement de navigation V-IRL. Nous montrons que, avec une récompense basée sur les résultats, l'RL, en particulier, réussit à généraliser dans des contextes et des variables visuelles basées sur des règles, tandis que SFT tend à mémoriser les données d'entraînement et est plus difficile à généraliser dans des scénarios hors distribution. Dans un analyse avancée, l'RL améliore la capacité de reconnaissance visuelle du modèle et encourage la généralisation visuelle. Malgré sa capacité excellente à généraliser, SFT est essentiel pour un entraînement efficace de RL, car il établit le format de sortie du modèle et permet à RL d'améliorer son performance. Ces résultats démontrent la capacité de RL à apprendre des connaissances généralisables dans des tâches multimodales complexes.",
      "upvotes": 11,
      "discussionId": "6799b39d15f4661561c229e6"
    },
    "publishedAt": "2025-01-28T23:50:56.664Z",
    "title": "SFT Memorizes, RL Generalizes: A Comparative Study of Foundation Model Post-training",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.17161.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5850
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.17116",
      "authors": [
        {
          "_id": "6799b367d30dc065a2d51592",
          "name": "Ruizhe Wang",
          "hidden": false
        },
        {
          "_id": "6799b367d30dc065a2d51593",
          "name": "Yeyun Gong",
          "hidden": false
        },
        {
          "_id": "6799b367d30dc065a2d51594",
          "name": "Xiao Liu",
          "hidden": false
        },
        {
          "_id": "6799b367d30dc065a2d51595",
          "name": "Guoshuai Zhao",
          "hidden": false
        },
        {
          "_id": "6799b367d30dc065a2d51596",
          "name": "Ziyue Yang",
          "hidden": false
        },
        {
          "_id": "6799b367d30dc065a2d51597",
          "name": "Baining Guo",
          "hidden": false
        },
        {
          "_id": "6799b367d30dc065a2d51598",
          "name": "Zhengjun Zha",
          "hidden": false
        },
        {
          "_id": "6799b367d30dc065a2d51599",
          "user": {
            "_id": "653feb7ccf1f9c88f4928910",
            "avatarUrl": "/avatars/23a6a6818116683ea9485e1470a0062f.svg",
            "isPro": false,
            "fullname": "Peng Cheng",
            "user": "cp5555",
            "type": "user"
          },
          "name": "Peng Cheng",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-01-29T04:49:44.372Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-28T18:04:50.000Z",
      "title": "Utilisant le type de données FP4 pour optimiser l'entraînement de modèles de langage grands",
      "summary": "La nécessité de méthodes plus efficaces pour faire face à l'augmentation de la charge de calcul dans l'entraînement de LLM. L'entraînement quantifié permet des opérations à basse bit, ce qui résulte en une solution adéquate pour réduire ces coûts. La précision FP8 montre la possibilité d'exécution, mais l'utilisation de FP4 présente des défis en raison d'erreurs significatives et de limites de représentation. Dans cet article, nous proposons un premier cadre d'entraînement FP4 de LLM pour résoudre ces problèmes, proposant deux innovations principales : l'actualisation des poids en utilisant des évaluateurs de précision quadratique différenciable et la protection des activations par des stratégies de coupure et de correction de valeurs anormales. Pour garantir la stabilité, le cadre combine l'apprentissage de précision mixte et le format vectoriel de Wiz. En fonction des résultats des expériences, notre cadre FP4 atteint la même précision que BF16 et FP8 avec une perte minimale, et peut entraîner un LLM de 13B paramètres avec 100B tokens. En cas de soutien futur des générateurs de matériel pour FP4, notre cadre fournira la base pour un apprentissage de précision ultrabasse efficace.",
      "upvotes": 9,
      "discussionId": "6799b368d30dc065a2d515bf"
    },
    "publishedAt": "2025-01-28T23:50:12.472Z",
    "title": "Optimizing Large Language Model Training Using FP4 Quantization",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.17116.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5850
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.16975",
      "authors": [
        {
          "_id": "6799b345a66ae6b357bef986",
          "name": "Hongzhi Huang",
          "hidden": false
        },
        {
          "_id": "6799b345a66ae6b357bef987",
          "name": "Defa Zhu",
          "hidden": false
        },
        {
          "_id": "6799b345a66ae6b357bef988",
          "name": "Banggu Wu",
          "hidden": false
        },
        {
          "_id": "6799b345a66ae6b357bef989",
          "name": "Yutao Zeng",
          "hidden": false
        },
        {
          "_id": "6799b345a66ae6b357bef98a",
          "name": "Ya Wang",
          "hidden": false
        },
        {
          "_id": "6799b345a66ae6b357bef98b",
          "name": "Qiyang Min",
          "hidden": false
        },
        {
          "_id": "6799b345a66ae6b357bef98c",
          "name": "Xun Zhou",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-28T14:15:42.000Z",
      "title": "Transformer : Vocabulaire Généralement Valuable pour l'Expansion",
      "summary": "Le tokenisation est un élément fondamental des modèles de langage à grande échelle (LLMs) et son impact n'a pas été entièrement étudié. Dans cet article, nous présentons un nouveau cadre appelé \"Transformers Over-Tokenized\" pour séparer les vecteurs de mots d'entrée et de sortie et améliorer le rendement de la modélisation du langage. Spécifiquement, notre approche élargit les vecteurs de mots d'entrée et utilise les bigrammes comme tokens. À travers de nombreux expérimentations, nous avons démontré qu'il existe une relation logarithmique entre le taille des vecteurs de mots d'entrée et la perte d'entraînement. Ces tailles améliorent constamment le rendement du modèle, indépendamment de son taille. En utilisant de grands vecteurs de mots d'entrée, on peut atteindre un rendement équivalent à celui d'un modèle deux fois plus grand sans augmenter les coûts supplémentaires. Nos résultats soulignent l'importance des lois d'échelle et fournissent une ligne directe pour le design du tokenisation, ouvrant des voies pour des modèles de langage plus efficaces et puissants.",
      "upvotes": 6,
      "discussionId": "6799b346a66ae6b357bef9e3"
    },
    "publishedAt": "2025-01-28T23:49:26.959Z",
    "title": "Over-Tokenized Transformer: Vocabulary is Generally Worth Scaling",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.16975.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5850
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.16764",
      "authors": [
        {
          "_id": "6799aa5a311dbfe3c96724cd",
          "name": "Chenguo Lin",
          "hidden": false
        },
        {
          "_id": "6799aa5a311dbfe3c96724ce",
          "name": "Panwang Pan",
          "hidden": false
        },
        {
          "_id": "6799aa5a311dbfe3c96724cf",
          "name": "Bangbang Yang",
          "hidden": false
        },
        {
          "_id": "6799aa5a311dbfe3c96724d0",
          "name": "Zeming Li",
          "hidden": false
        },
        {
          "_id": "6799aa5a311dbfe3c96724d1",
          "name": "Yadong Mu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-28T07:38:59.000Z",
      "title": "DiffSplat : Méthode d'exploitation réutilisant des modèles de diffusion d'images pour la génération scalable de Gaussian Splats",
      "summary": "Le développement récent du contenu 3D a chuté en raison des limitations des ensembles de données de haute qualité 3D et de l'incertitude dans la génération de polyèdres 2D. Dans ce contexte, nous présentons un nouveau cadre de travail de génération 3D appelé DiffSplat. DiffSplat utilise des modèles qui étend des grands textes à des images pour générer des gaussiennes 3D de manière inédite. A différence des modèles de génération 3D précédents, DiffSplat utilise effectivement des projecteurs 2D de web pour maintenir une cohérence 3D à travers un modèle unique. Un modèle de reconstruction léger est proposé pour initier l'entraînement, permettant la préparation d'ensembles de données scalables ainsi que la génération immédiate de grilles de gaussiennes 3D pour plusieurs angles. En combinant ces grilles avec la perte généralisée, nous introduisons une perte de rendu 3D pour favoriser la cohérence 3D. Cette stratégie est en alignement avec les modèles d'expansion d'images, permettant facilement l'application de nombreuses technologies de génération d'images dans le domaine 3D. Les expériences élargies montrent des résultats exceptionnels en génération basée sur le texte et les images, ainsi que dans les applications ultérieures. La recherche détaillée montre l'efficacité de chaque décision de conception et fournit une compréhension profonde de la technologie.",
      "upvotes": 4,
      "discussionId": "6799aa5c311dbfe3c9672542"
    },
    "publishedAt": "2025-01-29T01:12:02.839Z",
    "title": "DiffSplat: Repurposing Image Diffusion Models for Scalable Gaussian Splat Generation",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/654866e8cd0a5621395f8287/TFJMeKzXxMLOnq8NH8ltZ.mp4",
      "https://cdn-uploads.huggingface.co/production/uploads/654866e8cd0a5621395f8287/6kn1RLEUsUV-W6S0Taylo.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.16764.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "654866e8cd0a5621395f8287",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/654866e8cd0a5621395f8287/4Bccwd1ehn-Ee4T1rId5S.jpeg",
      "fullname": "Panwang Pan",
      "name": "paulpanwang",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 3
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.16496",
      "authors": [
        {
          "_id": "6799b2fbfe3c29ec219d7d99",
          "name": "Lee Sharkey",
          "hidden": false
        },
        {
          "_id": "6799b2fbfe3c29ec219d7d9a",
          "user": {
            "_id": "64ad563f4beffa272de6efac",
            "avatarUrl": "/avatars/f1a4902a95830cc3936058449626f8e4.svg",
            "isPro": false,
            "fullname": "Bilal Chughtai",
            "user": "bilalchughtai",
            "type": "user"
          },
          "name": "Bilal Chughtai",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-01-29T04:47:56.702Z",
          "hidden": false
        },
        {
          "_id": "6799b2fbfe3c29ec219d7d9b",
          "name": "Joshua Batson",
          "hidden": false
        },
        {
          "_id": "6799b2fbfe3c29ec219d7d9c",
          "name": "Jack Lindsey",
          "hidden": false
        },
        {
          "_id": "6799b2fbfe3c29ec219d7d9d",
          "name": "Jeff Wu",
          "hidden": false
        },
        {
          "_id": "6799b2fbfe3c29ec219d7d9e",
          "name": "Lucius Bushnaq",
          "hidden": false
        },
        {
          "_id": "6799b2fbfe3c29ec219d7d9f",
          "name": "Nicholas Goldowsky-Dill",
          "hidden": false
        },
        {
          "_id": "6799b2fbfe3c29ec219d7da0",
          "name": "Stefan Heimersheim",
          "hidden": false
        },
        {
          "_id": "6799b2fbfe3c29ec219d7da1",
          "name": "Alejandro Ortega",
          "hidden": false
        },
        {
          "_id": "6799b2fbfe3c29ec219d7da2",
          "name": "Joseph Bloom",
          "hidden": false
        },
        {
          "_id": "6799b2fbfe3c29ec219d7da3",
          "name": "Stella Biderman",
          "hidden": false
        },
        {
          "_id": "6799b2fbfe3c29ec219d7da4",
          "name": "Adria Garriga-Alonso",
          "hidden": false
        },
        {
          "_id": "6799b2fbfe3c29ec219d7da5",
          "name": "Arthur Conmy",
          "hidden": false
        },
        {
          "_id": "6799b2fbfe3c29ec219d7da6",
          "name": "Neel Nanda",
          "hidden": false
        },
        {
          "_id": "6799b2fbfe3c29ec219d7da7",
          "name": "Jessica Rumbelow",
          "hidden": false
        },
        {
          "_id": "6799b2fbfe3c29ec219d7da8",
          "name": "Martin Wattenberg",
          "hidden": false
        },
        {
          "_id": "6799b2fbfe3c29ec219d7da9",
          "name": "Nandi Schoots",
          "hidden": false
        },
        {
          "_id": "6799b2fbfe3c29ec219d7daa",
          "name": "Joseph Miller",
          "hidden": false
        },
        {
          "_id": "6799b2fbfe3c29ec219d7dab",
          "name": "Eric J. Michaud",
          "hidden": false
        },
        {
          "_id": "6799b2fbfe3c29ec219d7dac",
          "name": "Stephen Casper",
          "hidden": false
        },
        {
          "_id": "6799b2fbfe3c29ec219d7dad",
          "name": "Max Tegmark",
          "hidden": false
        },
        {
          "_id": "6799b2fbfe3c29ec219d7dae",
          "name": "William Saunders",
          "hidden": false
        },
        {
          "_id": "6799b2fbfe3c29ec219d7daf",
          "name": "David Bau",
          "hidden": false
        },
        {
          "_id": "6799b2fbfe3c29ec219d7db0",
          "name": "Eric Todd",
          "hidden": false
        },
        {
          "_id": "6799b2fbfe3c29ec219d7db1",
          "name": "Atticus Geiger",
          "hidden": false
        },
        {
          "_id": "6799b2fbfe3c29ec219d7db2",
          "name": "Mor Geva",
          "hidden": false
        },
        {
          "_id": "6799b2fbfe3c29ec219d7db3",
          "name": "Jesse Hoogland",
          "hidden": false
        },
        {
          "_id": "6799b2fbfe3c29ec219d7db4",
          "name": "Daniel Murfet",
          "hidden": false
        },
        {
          "_id": "6799b2fbfe3c29ec219d7db5",
          "name": "Tom McGrath",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-27T20:57:18.000Z",
      "title": "Description des problèmes ouverts dans l'explication de la machine",
      "summary": "La description de la machine vise à comprendre les fonctions des réseaux neuronaux et à définir clairement la structure computationnelle pour atteindre des objectifs scientifiques et techniques spécifiques. L'avancement de ce domaine peut renforcer la confiance dans le comportement des systèmes d'IA et éclairer des problèmes scientifiques intéressants sur la nature du savoir. Avec les derniers progrès, il est possible d'avancer vers cet objectif. Cependant, avant de pouvoir le réaliser, on ne peut pas obtenir de nombreux bénéfices scientifiques et pratiques, car il faut résoudre de nombreuses problèmes ouverts. Notre approche nécessite des améliorations conceptuelles et pratiques, ainsi qu'une compréhension profonde. De plus, il est nécessaire de clarifier comment notre approche est appliquée de manière optimale pour atteindre certains objectifs. De plus, notre travail n'est pas seulement affecté, mais il affecte également les problèmes technologiques sociaux qui le entourent. Cette revue avancée discute l'état de l'art de la description de la machine et les problèmes ouverts que la discipline doit aborder.",
      "upvotes": 4,
      "discussionId": "6799b2fcfe3c29ec219d7dca"
    },
    "publishedAt": "2025-01-28T23:48:30.888Z",
    "title": "Open Problems in Mechanistic Interpretability",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.16496.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5850
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.15747",
      "authors": [
        {
          "_id": "6799946c18cb282841d42639",
          "name": "Sankalp KJ",
          "hidden": false
        },
        {
          "_id": "6799946c18cb282841d4263a",
          "name": "Ashutosh Kumar",
          "hidden": false
        },
        {
          "_id": "6799946c18cb282841d4263b",
          "user": {
            "_id": "66707b60405252abeefd4c50",
            "avatarUrl": "/avatars/ee2728f115376e234e96820b8b376849.svg",
            "isPro": false,
            "fullname": "Laxmaan Balaji",
            "user": "laxmaanb",
            "type": "user"
          },
          "name": "Laxmaan Balaji",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-01-29T02:37:34.240Z",
          "hidden": false
        },
        {
          "_id": "6799946c18cb282841d4263c",
          "name": "Nikunj Kotecha",
          "hidden": false
        },
        {
          "_id": "6799946c18cb282841d4263d",
          "name": "Vinija Jain",
          "hidden": false
        },
        {
          "_id": "6799946c18cb282841d4263e",
          "user": {
            "_id": "63a4754927f1f64ed7238dac",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63a4754927f1f64ed7238dac/aH-eJF-31g4vof9jv2gmI.jpeg",
            "isPro": false,
            "fullname": "Aman Chadha",
            "user": "amanchadha",
            "type": "user"
          },
          "name": "Aman Chadha",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-01-29T08:55:14.312Z",
          "hidden": false
        },
        {
          "_id": "6799946c18cb282841d4263f",
          "name": "Sreyoshi Bhaduri",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-27T03:19:03.000Z",
      "title": "IndicMMLU-Pro : Évaluation pour le Modèle de Langue Indienne en Compréhension Multi-tâche du Langage",
      "summary": "La population de plus de 1,500 millions de personnes qui parlent des langues indigènes en Inde offre aux études du traitement du langage naturel (NLP) des problèmes caractéristiques et des opportunités, en raison de la riche tradition culturelle, de la diversité et de la complexité structurelle des langues. IndicMMLU-Pro est un cadre de référence détaillé conçu pour évaluer les grands modèles de langage (LLMs) sur une large gamme de langues indigènes. Basé sur le cadre de compréhension multi-tâches magique (Magic Multitask Language Understanding), il est utilisé pour aborder des problèmes spécifiques de la diversité linguistique de l'Inde, y compris les principales langues comme le Handi, le Bengali, le Gujarati, le Marathi, le Kannada, le Punjabi, le Tamil, le Telugu et l'Urdu. Ce cadre de référence détecte la complexité de la compréhension du langage, de la logique et de la génération, et maximise les caractéristiques des langues indigènes. IndicMMLU-Pro fournit un cadre d'évaluation standard pour encourager la recherche sur les langues indigènes avec l'IA, promouvant le développement de modèles précis, efficaces et sensibles à la culture. Cet article explique les principes de conception du cadre de référence, les techniques de tâches et les méthodes de collecte de données, offrant des résultats standard basés sur les modèles multilingues les plus récents.",
      "upvotes": 3,
      "discussionId": "6799946e18cb282841d426d6"
    },
    "publishedAt": "2025-01-28T21:38:17.182Z",
    "title": "IndicMMLU-Pro: Benchmarking Indic Large Language Models on Multi-Task Language Understanding",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.15747.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "63a4754927f1f64ed7238dac",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63a4754927f1f64ed7238dac/aH-eJF-31g4vof9jv2gmI.jpeg",
      "fullname": "Aman Chadha",
      "name": "amanchadha",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2501.16372",
      "authors": [
        {
          "_id": "67999c3dc1e34886f90320ee",
          "name": "J. Pablo Muñoz",
          "hidden": false
        },
        {
          "_id": "67999c3dc1e34886f90320ef",
          "name": "Jinjie Yuan",
          "hidden": false
        },
        {
          "_id": "67999c3dc1e34886f90320f0",
          "name": "Nilesh Jain",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-23T02:14:08.000Z",
      "title": "Les ordinateurs de bas niveau et la recherche d'architectures neuronales s'associent à la compression de modèles grands.",
      "summary": "Le rapide croissance des modèles de langage grands (LLM) révèle des problèmes importants liés aux ressources informatiques nécessaires pour le fine-tuning et la déploiement. L'avancement récent des adaptateurs de faible rang montre son efficacité dans le fine-tuning paramétriquement efficace (PEFT) de ces modèles. Dans cet article, on discute exhaustivement un approche innovante basée sur la représentation de faible rang et la recherche d'architectures neuronales (NAS), en particulier l'utilisation de réseaux super-réseaux de poids et d'interactions. En intégrant ces méthodologies, des solutions robustes ont été développées pour la compression et le fine-tuning de modèles pré-entraînés grands. Notre analyse montre que cette combinaison peut démocratiser l'utilisation des LLM et rendre plus accessibles leur déploiement dans des environnements avec des limitations de ressources. Enfin, les modèles obtenus réduisent le consommation de mémoire, réduisent le temps d'inférence et permettent l'implémentation d'applications pratiques et scalables de LLM. Les modèles et le code sont disponibles sur la suivante URL.\nhttps://github.com/IntelLabs/Hardware-Aware-Automated-Machine-Learning",
      "upvotes": 2,
      "discussionId": "67999c3dc1e34886f9032140"
    },
    "publishedAt": "2025-01-28T22:11:04.472Z",
    "title": "Low-Rank Adapters Meet Neural Architecture Search for LLM Compression",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.16372.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5850
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.17117",
      "authors": [
        {
          "_id": "6799e5f9121155210e4fa48c",
          "name": "Thibaud Leteno",
          "hidden": false
        },
        {
          "_id": "6799e5f9121155210e4fa48d",
          "name": "Irina Proskurina",
          "hidden": false
        },
        {
          "_id": "6799e5f9121155210e4fa48e",
          "name": "Antoine Gourru",
          "hidden": false
        },
        {
          "_id": "6799e5f9121155210e4fa48f",
          "name": "Julien Velcin",
          "hidden": false
        },
        {
          "_id": "6799e5f9121155210e4fa490",
          "name": "Charlotte Laclau",
          "hidden": false
        },
        {
          "_id": "6799e5f9121155210e4fa491",
          "name": "Guillaume Metzler",
          "hidden": false
        },
        {
          "_id": "6799e5f9121155210e4fa492",
          "name": "Christophe Gravier",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-28T18:07:30.000Z",
      "title": "Évaluation de l'Alimentation Morale dans le Dataset Français 'Moral Nomiti'",
      "summary": "Les modèles doivent augmenter leur capacité en fonction de la vie quotidienne, mais il est crucial d'ajuster leur langage en accord avec les valeurs humaines. Bien que les modèles puissent être ajustés en fonction des préférences des utilisateurs, il est essentiel que ceux-ci soient conformes aux normes éthiques et aux comportements de la société réelle. Alors que le développement en anglais et en chinois a été considérable, le français a montré moins d'intérêt dans ce domaine, et il existe une lacune dans la compréhension de la manière dont les modèles de langage grand (LLM) traitent la logique morale en français. Pour aborder cette lacune, nous présentons le jeu de données \"Histoires Morales\" en français. Ce jeu de données comprend des annotations de valeurs morales et est écrit dans le contexte de la culture française. \"Histoires Morales\" couvre diverses situations sociales, telles que l'inégalité des opportunités, l'honesté dans les relations et la responsabilité envers les animaux. Dans le futur, nous réaliserons des expériences initiales pour combiner des modèles multilingues en français et en anglais, ainsi que pour évaluer leur robustesse. Selon ces résultats, les modèles de langage grandes sont souvent facilement influencés par des données morales ou immorales selon les préférences de l'utilisateur.",
      "upvotes": 0,
      "discussionId": "6799e5fb121155210e4fa500"
    },
    "publishedAt": "2025-01-29T03:32:09.927Z",
    "title": "Histoires Morales: A French Dataset for Assessing Moral Alignment",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.17117.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "629a3dbcd496c6dcdebf41cc",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1655113762275-629a3dbcd496c6dcdebf41cc.jpeg",
      "fullname": "Irina Proskurina",
      "name": "iproskurina",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": false
  }
]