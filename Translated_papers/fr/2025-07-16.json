[
  {
    "paper": {
      "id": "2507.07104",
      "authors": [
        {
          "_id": "686f95e9706a6ea4654189ff",
          "user": {
            "_id": "66e0b013733965882099cc37",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/66e0b013733965882099cc37/CkTK2kV2v-TfdYiwsW6Tx.jpeg",
            "isPro": true,
            "fullname": "Tiezheng Zhang",
            "user": "PatZhang11",
            "type": "user"
          },
          "name": "Tiezheng Zhang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-07-11T08:03:27.231Z",
          "hidden": false
        },
        {
          "_id": "686f95e9706a6ea465418a00",
          "name": "Yitong Li",
          "hidden": false
        },
        {
          "_id": "686f95e9706a6ea465418a01",
          "name": "Yu-cheng Chou",
          "hidden": false
        },
        {
          "_id": "686f95e9706a6ea465418a02",
          "name": "Jieneng Chen",
          "hidden": false
        },
        {
          "_id": "686f95e9706a6ea465418a03",
          "name": "Alan Yuille",
          "hidden": false
        },
        {
          "_id": "686f95e9706a6ea465418a04",
          "name": "Chen Wei",
          "hidden": false
        },
        {
          "_id": "686f95e9706a6ea465418a05",
          "user": {
            "_id": "64b5ba6060274cbb296d6288",
            "avatarUrl": "/avatars/67e0343954dda6e92ed3f6e7976f9f87.svg",
            "isPro": true,
            "fullname": "Junfei Xiao",
            "user": "lambertxiao",
            "type": "user"
          },
          "name": "Junfei Xiao",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-07-11T08:03:25.003Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-07-09T17:59:04.000Z",
      "submittedOnDailyAt": "2025-07-16T04:05:40.175Z",
      "title": "Vision-longitud-Vision automatique de codificateur : fourniture de connaissances extensibles\nModèle de diffusion",
      "submittedOnDailyBy": {
        "_id": "64b5ba6060274cbb296d6288",
        "avatarUrl": "/avatars/67e0343954dda6e92ed3f6e7976f9f87.svg",
        "isPro": true,
        "fullname": "Junfei Xiao",
        "user": "lambertxiao",
        "type": "user"
      },
      "summary": "La vision-langage-vision (VLV) marque de codificateurs autonomes est utilisée pour construire des VLMs de haute qualité, mais nécessite de capturer des capacités fortes impliquant l'entraînement avec des millions de paires d'images-texte de haute qualité, ce qui nécessite des millions d'heures de GPU. Dans cet article, une solution est proposée pour réduire ces coûts. Ce cadre de travail utilise un codifieur visuel, un décodage de modèles de diffusion texte à image (T2I) et, plus tard, un modèle de langage à grande échelle (LLM) de manière stratégique. Spécifiquement, les représentations linguistiques sont normalisées et le décodage d'entraînement du modèle de diffusion texte à image est fixé pour générer des balises d'information. Le flux VLV utilise des cartes continuelles pour concevoir efficacement le savoir dans les modèles de diffusion texte à image et fournit des reconstructions de haute qualité avec des détails spécifiques. De plus, un modèle LLM préalablement entraîné est fine-tuné pour convertir les représentations de langage intermédiaires en descriptions détaillées, ce qui permet de construire des modèles de simulation comme GPT-4o ou Gemini 2.0 Flash. Cette méthodologie montre une efficacité de coût spéciale et réduit significativement les exigences de données. Principalement, il est entraîné sur des images d'une seule modalité, maximisant l'utilisation de modèles préalablement entraînés (codifieur visuel, modèle de diffusion T2I, LLM), évitant la nécessité de grands ensembles de données d'images-texte et assurant que les coûts totaux d'entraînement ne dépassent pas les 1,000 USD.",
      "upvotes": 13,
      "discussionId": "686f95e9706a6ea465418a06",
      "projectPage": "https://lambert-x.github.io/Vision-Language-Vision/",
      "githubRepo": "https://github.com/Tiezheng11/Vision-Language-Vision",
      "ai_summary": "The VLV auto-encoder framework uses pretrained vision and text models to create a cost-effective and data-efficient captioning system.",
      "ai_keywords": [
        "Vision-Language Models",
        "VLV auto-encoder",
        "vision encoder",
        "Text-to-Image diffusion model",
        "Large Language Model",
        "information bottleneck",
        "continuous embeddings",
        "semantic understanding",
        "captioning",
        "fine-tuning",
        "GPT-4o",
        "Gemini 2.0 Flash"
      ],
      "githubStars": 19
    },
    "publishedAt": "2025-07-09T13:59:04.000Z",
    "title": "Vision-Language-Vision Auto-Encoder: Scalable Knowledge Distillation\n  from Diffusion Models",
    "summary": "Building state-of-the-art Vision-Language Models (VLMs) with strong\ncaptioning capabilities typically necessitates training on billions of\nhigh-quality image-text pairs, requiring millions of GPU hours. This paper\nintroduces the Vision-Language-Vision (VLV) auto-encoder framework, which\nstrategically leverages key pretrained components: a vision encoder, the\ndecoder of a Text-to-Image (T2I) diffusion model, and subsequently, a Large\nLanguage Model (LLM). Specifically, we establish an information bottleneck by\nregularizing the language representation space, achieved through freezing the\npretrained T2I diffusion decoder. Our VLV pipeline effectively distills\nknowledge from the text-conditioned diffusion model using continuous\nembeddings, demonstrating comprehensive semantic understanding via high-quality\nreconstructions. Furthermore, by fine-tuning a pretrained LLM to decode the\nintermediate language representations into detailed descriptions, we construct\na state-of-the-art (SoTA) captioner comparable to leading models like GPT-4o\nand Gemini 2.0 Flash. Our method demonstrates exceptional cost-efficiency and\nsignificantly reduces data requirements; by primarily utilizing single-modal\nimages for training and maximizing the utility of existing pretrained models\n(image encoder, T2I diffusion model, and LLM), it circumvents the need for\nmassive paired image-text datasets, keeping the total training expenditure\nunder $1,000 USD.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2507.07104.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64b5ba6060274cbb296d6288",
      "avatarUrl": "/avatars/67e0343954dda6e92ed3f6e7976f9f87.svg",
      "fullname": "Junfei Xiao",
      "name": "lambertxiao",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 6
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2507.11407",
      "authors": [
        {
          "_id": "68774564257d4f04353707dc",
          "name": "LG AI Research",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707de",
          "name": "Kyunghoon Bae",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707df",
          "name": "Eunbi Choi",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707e0",
          "name": "Kibong Choi",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707e1",
          "name": "Stanley Jungkyu Choi",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707e2",
          "name": "Yemuk Choi",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707e3",
          "name": "Kyubeen Han",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707e4",
          "name": "Seokhee Hong",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707e5",
          "name": "Junwon Hwang",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707e6",
          "name": "Taewan Hwang",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707e7",
          "name": "Joonwon Jang",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707e8",
          "name": "Hyojin Jeon",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707e9",
          "name": "Kijeong Jeon",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707ea",
          "name": "Gerrard Jeongwon Jo",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707eb",
          "name": "Hyunjik Jo",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707ec",
          "name": "Jiyeon Jung",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707ed",
          "name": "Euisoon Kim",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707ee",
          "name": "Hyosang Kim",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707ef",
          "name": "Jihoon Kim",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707f0",
          "name": "Joonkee Kim",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707f1",
          "name": "Seonghwan Kim",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707f2",
          "name": "Soyeon Kim",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707f3",
          "name": "Sunkyoung Kim",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707f4",
          "name": "Yireun Kim",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707f5",
          "name": "Yongil Kim",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707f6",
          "name": "Youchul Kim",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707f7",
          "name": "Edward Hwayoung Lee",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707f8",
          "name": "Gwangho Lee",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707f9",
          "name": "Haeju Lee",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707fa",
          "name": "Honglak Lee",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707fb",
          "name": "Jinsik Lee",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707fc",
          "name": "Kyungmin Lee",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707fd",
          "name": "Sangha Park",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707fe",
          "name": "Young Min Paik",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707ff",
          "name": "Yongmin Park",
          "hidden": false
        },
        {
          "_id": "68774564257d4f0435370800",
          "name": "Youngyong Park",
          "hidden": false
        },
        {
          "_id": "68774564257d4f0435370801",
          "name": "Sanghyun Seo",
          "hidden": false
        },
        {
          "_id": "68774564257d4f0435370802",
          "name": "Sihoon Yang",
          "hidden": false
        },
        {
          "_id": "68774564257d4f0435370803",
          "name": "Heuiyeen Yeen",
          "hidden": false
        },
        {
          "_id": "68774564257d4f0435370804",
          "name": "Sihyuk Yi",
          "hidden": false
        },
        {
          "_id": "68774564257d4f0435370805",
          "name": "Hyeongu Yun",
          "hidden": false
        }
      ],
      "publishedAt": "2025-07-15T15:24:51.000Z",
      "submittedOnDailyAt": "2025-07-16T07:04:54.982Z",
      "title": "EXAONE 4.0 : Modèle de langage grand avec un taille unifiée qui intègre le mode logique et le mode non logique",
      "submittedOnDailyBy": {
        "_id": "660260cf1737e5cd4a826550",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/660260cf1737e5cd4a826550/AlSfoM2WtqPjLtYR6x7Wf.jpeg",
        "isPro": false,
        "fullname": "Yireun Kim",
        "user": "yireun",
        "type": "user"
      },
      "summary": "Ce rapport technique traite d'intégrer dans EXAONE 4.0 le mode Non-reasoning et le mode Reasoning, pour atteindre les excellentes expériences utilisateur de EXAONE 3.5 et le haut niveau de capacité de Reasoning de EXAONE Deep. EXAONE 4.0, orienté vers l'ère de l'IA des agents, comprend comme fonctionnalités de base l'utilisation d'outils d'agent, en plus d'ajouter l'anglais et le coréen, et maintenant, également le support pour le français. La série de modèles de EXAONE 4.0 consiste en deux tailles : un modèle moyen avec soin de 32B pour des rendements élevés et un petit de 1.2B pour des applications mobiles. EXAONE 4.0 montre des meilleurs rendements que les modèles de la même catégorie ouverts, et se compare favorablement à des modèles avancés. Le modèle peut être utilisé public pour des fins de recherche et est facilement téléchargeable depuis https://huggingface.co/LGAI-EXAONE.",
      "upvotes": 11,
      "discussionId": "68774564257d4f0435370806",
      "ai_summary": "EXAONE 4.0 integrates non-reasoning and reasoning modes, supports multilingualism, and offers models optimized for high performance and on-device use, demonstrating superior performance compared to open-weight models.",
      "ai_keywords": [
        "Non-reasoning mode",
        "Reasoning mode",
        "agentic tool use",
        "multilingual capabilities",
        "mid-size model",
        "small-size model",
        "high performance",
        "on-device applications",
        "open-weight models",
        "frontier-class models"
      ]
    },
    "publishedAt": "2025-07-15T11:24:51.000Z",
    "title": "EXAONE 4.0: Unified Large Language Models Integrating Non-reasoning and\n  Reasoning Modes",
    "summary": "This technical report introduces EXAONE 4.0, which integrates a Non-reasoning\nmode and a Reasoning mode to achieve both the excellent usability of EXAONE 3.5\nand the advanced reasoning abilities of EXAONE Deep. To pave the way for the\nagentic AI era, EXAONE 4.0 incorporates essential features such as agentic tool\nuse, and its multilingual capabilities are extended to support Spanish in\naddition to English and Korean. The EXAONE 4.0 model series consists of two\nsizes: a mid-size 32B model optimized for high performance, and a small-size\n1.2B model designed for on-device applications. The EXAONE 4.0 demonstrates\nsuperior performance compared to open-weight models in its class and remains\ncompetitive even against frontier-class models. The models are publicly\navailable for research purposes and can be easily downloaded via\nhttps://huggingface.co/LGAI-EXAONE.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2507.11407.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "660260cf1737e5cd4a826550",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/660260cf1737e5cd4a826550/AlSfoM2WtqPjLtYR6x7Wf.jpeg",
      "fullname": "Yireun Kim",
      "name": "yireun",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 4
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2507.09404",
      "authors": [
        {
          "_id": "68774155257d4f04353707d3",
          "name": "Mustafa Shukor",
          "hidden": false
        },
        {
          "_id": "68774155257d4f04353707d4",
          "name": "Louis Bethune",
          "hidden": false
        },
        {
          "_id": "68774155257d4f04353707d5",
          "name": "Dan Busbridge",
          "hidden": false
        },
        {
          "_id": "68774155257d4f04353707d6",
          "name": "David Grangier",
          "hidden": false
        },
        {
          "_id": "68774155257d4f04353707d7",
          "name": "Enrico Fini",
          "hidden": false
        },
        {
          "_id": "68774155257d4f04353707d8",
          "name": "Alaaeldin El-Nouby",
          "hidden": false
        },
        {
          "_id": "68774155257d4f04353707d9",
          "name": "Pierre Ablin",
          "hidden": false
        }
      ],
      "publishedAt": "2025-07-12T21:16:08.000Z",
      "submittedOnDailyAt": "2025-07-16T04:39:10.654Z",
      "title": "La loi sur l'escalade optimale de la fusion de données",
      "submittedOnDailyBy": {
        "_id": "62bdeedd01dc22b4d22a371e",
        "avatarUrl": "/avatars/3cc0643feb53bf2e895ec12c275d5483.svg",
        "isPro": false,
        "fullname": "Mustafa Shukor",
        "user": "mshukor",
        "type": "user"
      },
      "summary": "Les modèles de base à grande échelle sont généralement entraînés avec des données provenant de diverses zones. La confusion des données (l'utilisation de chaque zone) joue un rôle important dans le rendement du modèle. La décision de cette confusion a un approche standard qui dépend d'expériences et d'erreurs, ce qui n'est pas pratique pour des entraînements à grande échelle. Nous proposons un méthode pour déterminer la meilleure confusion des données appropriée pour une zone spécifique en utilisant un échelleur. Notre approche permet de prédire précisément la perte d'un modèle de taille N entraîné avec D tokens et un vecteur de poids h d'une zone spécifique. Nous avons démontré la généralité de cet échelleur dans trois scénarios à grande échelle : modèles de langage de grande échelle (LLM), modèles multimodaux naturels (NMM), et modèles visuels de grande échelle (LVM). De plus, cet échelleur peut être appliqué à de nouvelles confusions de données et à des largeurs d'échelle : ses paramètres peuvent être estimés avec précision lors d'entraînements à petite échelle, ce qui permet de prédire le rendement avec des connaissances nouvelles et à grande échelle. L'échelleur permet de trouver les meilleurs poids de zone appropriés pour une zone spécifique, en supposant un ensemble de données d'entraînement (N, D), et de fournir une méthodologie théorique au lieu d'expériences coûteuses et d'erreurs.",
      "upvotes": 8,
      "discussionId": "68774156257d4f04353707da",
      "ai_summary": "Scaling laws predict optimal data mixtures for large foundation models, improving performance across different domains and scales.",
      "ai_keywords": [
        "scaling laws",
        "large language model",
        "native multimodal model",
        "large vision models",
        "domain weights",
        "parameter estimation",
        "performance prediction",
        "training budget"
      ]
    },
    "publishedAt": "2025-07-12T17:16:08.000Z",
    "title": "Scaling Laws for Optimal Data Mixtures",
    "summary": "Large foundation models are typically trained on data from multiple domains,\nwith the data mixture--the proportion of each domain used--playing a critical\nrole in model performance. The standard approach to selecting this mixture\nrelies on trial and error, which becomes impractical for large-scale\npretraining. We propose a systematic method to determine the optimal data\nmixture for any target domain using scaling laws. Our approach accurately\npredicts the loss of a model of size N trained with D tokens and a specific\ndomain weight vector h. We validate the universality of these scaling laws by\ndemonstrating their predictive power in three distinct and large-scale\nsettings: large language model (LLM), native multimodal model (NMM), and large\nvision models (LVM) pretraining. We further show that these scaling laws can\nextrapolate to new data mixtures and across scales: their parameters can be\naccurately estimated using a few small-scale training runs, and used to\nestimate the performance at larger scales and unseen domain weights. The\nscaling laws allow to derive the optimal domain weights for any target domain\nunder a given training budget (N,D), providing a principled alternative to\ncostly trial-and-error methods.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2507.09404.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "62bdeedd01dc22b4d22a371e",
      "avatarUrl": "/avatars/3cc0643feb53bf2e895ec12c275d5483.svg",
      "fullname": "Mustafa Shukor",
      "name": "mshukor",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 59
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2507.10787",
      "authors": [
        {
          "_id": "68771a98257d4f04353707b2",
          "user": {
            "_id": "62f662bcc58915315c4eccea",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62f662bcc58915315c4eccea/zOAQLONfMP88zr70sxHK-.jpeg",
            "isPro": true,
            "fullname": "Yilun Zhao",
            "user": "yilunzhao",
            "type": "user"
          },
          "name": "Yilun Zhao",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-07-16T08:15:45.442Z",
          "hidden": false
        },
        {
          "_id": "68771a98257d4f04353707b3",
          "name": "Chengye Wang",
          "hidden": false
        },
        {
          "_id": "68771a98257d4f04353707b4",
          "name": "Chuhan Li",
          "hidden": false
        },
        {
          "_id": "68771a98257d4f04353707b5",
          "name": "Arman Cohan",
          "hidden": false
        }
      ],
      "publishedAt": "2025-07-14T20:35:25.000Z",
      "submittedOnDailyAt": "2025-07-16T01:51:11.312Z",
      "title": "Le modèle de base DamoDal peut comprendre la structure ? Recherche expérimentale sur l'exploration de l'information et la réponse à des questions liées aux articles scientifiques.",
      "submittedOnDailyBy": {
        "_id": "62f662bcc58915315c4eccea",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62f662bcc58915315c4eccea/zOAQLONfMP88zr70sxHK-.jpeg",
        "isPro": true,
        "fullname": "Yilun Zhao",
        "user": "yilunzhao",
        "type": "user"
      },
      "summary": "Dans cet article, nous présentons le premier benchmark conçu pour évaluer la capacité d'interprétation de diagrammes de flux dans la littérature scientifique, appelé \"MISS-QA\". MISS-QA est composé de 1 500 échantillons expliqués par des experts sur 465 articles scientifiques. Dans ce benchmark, l'objectif est que les modèles interprètent des diagrammes de flux représentant une revue d'une recherche et répondent à des questions qui cherchent des informations pertinentes dans le contexte d'un navigateur d'articles. L'efficacité de 18 modèles de pointe, incluant o4-mini, Gemini-2.5-Flash et Qwen2.5-VL, est évaluée. Ces modèles montrent clairement des différences de performance par rapport aux experts humains dans MISS-QA, permettant une évaluation précise de leur rendement et un analyse des erreurs qui permettent de déterminer clairement les forces et les limites des modèles, ainsi que d'améliorer la compréhension de la littérature scientifique.",
      "upvotes": 4,
      "discussionId": "68771a98257d4f04353707b6",
      "githubRepo": "https://github.com/yilunzhao/MISS-QA",
      "ai_summary": "A benchmark evaluates multimodal models' ability to interpret scientific schematic diagrams and answer related questions, revealing performance gaps and insights for improvement.",
      "ai_keywords": [
        "multimodal foundation models",
        "schematic diagrams",
        "scientific literature",
        "information-seeking questions",
        "error analysis"
      ],
      "githubStars": 0
    },
    "publishedAt": "2025-07-14T16:35:25.000Z",
    "title": "Can Multimodal Foundation Models Understand Schematic Diagrams? An\n  Empirical Study on Information-Seeking QA over Scientific Papers",
    "summary": "This paper introduces MISS-QA, the first benchmark specifically designed to\nevaluate the ability of models to interpret schematic diagrams within\nscientific literature. MISS-QA comprises 1,500 expert-annotated examples over\n465 scientific papers. In this benchmark, models are tasked with interpreting\nschematic diagrams that illustrate research overviews and answering\ncorresponding information-seeking questions based on the broader context of the\npaper. We assess the performance of 18 frontier multimodal foundation models,\nincluding o4-mini, Gemini-2.5-Flash, and Qwen2.5-VL. We reveal a significant\nperformance gap between these models and human experts on MISS-QA. Our analysis\nof model performance on unanswerable questions and our detailed error analysis\nfurther highlight the strengths and limitations of current models, offering key\ninsights to enhance models in comprehending multimodal scientific literature.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2507.10787.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "62f662bcc58915315c4eccea",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62f662bcc58915315c4eccea/zOAQLONfMP88zr70sxHK-.jpeg",
      "fullname": "Yilun Zhao",
      "name": "yilunzhao",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 14
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2507.09411",
      "authors": [
        {
          "_id": "68771a0b257d4f04353707a9",
          "user": {
            "_id": "6159f88235226e98eaa28b39",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1633286253722-noauth.jpeg",
            "isPro": false,
            "fullname": "Md Ajwad Akil",
            "user": "Ajwad",
            "type": "user"
          },
          "name": "Md Ajwad Akil",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-07-16T08:15:48.362Z",
          "hidden": false
        },
        {
          "_id": "68771a0b257d4f04353707aa",
          "name": "Adrian Shuai Li",
          "hidden": false
        },
        {
          "_id": "68771a0b257d4f04353707ab",
          "name": "Imtiaz Karim",
          "hidden": false
        },
        {
          "_id": "68771a0b257d4f04353707ac",
          "name": "Arun Iyengar",
          "hidden": false
        },
        {
          "_id": "68771a0b257d4f04353707ad",
          "name": "Ashish Kundu",
          "hidden": false
        },
        {
          "_id": "68771a0b257d4f04353707ae",
          "name": "Vinny Parla",
          "hidden": false
        },
        {
          "_id": "68771a0b257d4f04353707af",
          "name": "Elisa Bertino",
          "hidden": false
        }
      ],
      "publishedAt": "2025-07-12T22:11:10.000Z",
      "submittedOnDailyAt": "2025-07-16T01:54:43.633Z",
      "title": "LLMalMorph : LLMalMorph explore la possibilité de créer des variantes de Marvel en utilisant des modèles de langage grands.",
      "submittedOnDailyBy": {
        "_id": "6159f88235226e98eaa28b39",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1633286253722-noauth.jpeg",
        "isPro": false,
        "fullname": "Md Ajwad Akil",
        "user": "Ajwad",
        "type": "user"
      },
      "summary": "Les modèles de langage grands (LLMs) jouent un rôle crucial dans l'innovation du développement de logiciels et l'automatisation de la génération de code. Dans cet article, nous explorons la possibilité que les LLMs puissent modifier le code source de logiciels malveillants pour générer des variantes. Nous présentons le cadre non automatique LLMalMorph. LLMalMorph utilise la compréhension sémantique et syntaxique du code par les LLMs pour générer de nouveau code pour la création de variantes de logiciels malveillants. LLMalMorph extrait des informations au niveau de fonction du code source de logiciels malveillants et guide le changement de code en utilisant des transformations de code définies stratégiquement en collaboration avec les LLMs, évitant ainsi le complexe ajustement de rétroaction. Dans l'évaluation de LLMalMorph, nous avons collecté 10 exemples différents de logiciels malveillants Windows et nous avons généré 618 variantes. Les expériences détaillées ont montré que ces variantes de logiciels malveillants peuvent réduire la taux de détection tout en maintenant les fonctions du logiciel malveillant. De plus, tandis que les systèmes de recherche de logiciels malveillants basés sur l'apprentissage automatique (ML) ne sont pas optimisés, la plupart des variantes ont réussi à attaquer les classificateurs de logiciels malveillants basés sur l'ML. De plus, nous discutons des limitations dans la génération de variantes de logiciels malveillants basées sur les fonctionnalités actuelles des LLMs et évaluons la position de cette technologie émergente dans le contexte plus large de la génération de variantes de logiciels malveillants.",
      "upvotes": 2,
      "discussionId": "68771a0c257d4f04353707b0",
      "ai_summary": "A semi-automated framework uses Large Language Models to generate malware variants, demonstrating reduced detection rates and notable attack success against ML classifiers.",
      "ai_keywords": [
        "Large Language Models",
        "LLMalMorph",
        "semantical code comprehension",
        "syntactical code comprehension",
        "function-level information",
        "custom-engineered prompts",
        "code transformations",
        "antivirus engines",
        "ML-based malware detectors",
        "malware variant generation"
      ]
    },
    "publishedAt": "2025-07-12T18:11:10.000Z",
    "title": "LLMalMorph: On The Feasibility of Generating Variant Malware using\n  Large-Language-Models",
    "summary": "Large Language Models (LLMs) have transformed software development and\nautomated code generation. Motivated by these advancements, this paper explores\nthe feasibility of LLMs in modifying malware source code to generate variants.\nWe introduce LLMalMorph, a semi-automated framework that leverages semantical\nand syntactical code comprehension by LLMs to generate new malware variants.\nLLMalMorph extracts function-level information from the malware source code and\nemploys custom-engineered prompts coupled with strategically defined code\ntransformations to guide the LLM in generating variants without\nresource-intensive fine-tuning. To evaluate LLMalMorph, we collected 10 diverse\nWindows malware samples of varying types, complexity and functionality and\ngenerated 618 variants. Our thorough experiments demonstrate that it is\npossible to reduce the detection rates of antivirus engines of these malware\nvariants to some extent while preserving malware functionalities. In addition,\ndespite not optimizing against any Machine Learning (ML)-based malware\ndetectors, several variants also achieved notable attack success rates against\nan ML-based malware classifier. We also discuss the limitations of current LLM\ncapabilities in generating malware variants from source code and assess where\nthis emerging technology stands in the broader context of malware variant\ngeneration.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2507.09411.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6159f88235226e98eaa28b39",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1633286253722-noauth.jpeg",
      "fullname": "Md Ajwad Akil",
      "name": "Ajwad",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2507.09075",
      "authors": [
        {
          "_id": "687731d0257d4f04353707be",
          "name": "Wasi Uddin Ahmad",
          "hidden": false
        },
        {
          "_id": "687731d0257d4f04353707bf",
          "user": {
            "_id": "6254f8e5d21e4cc386b881ad",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1649899774659-6254f8e5d21e4cc386b881ad.jpeg",
            "isPro": false,
            "fullname": "Somshubra Majumdar",
            "user": "smajumdar94",
            "type": "user"
          },
          "name": "Somshubra Majumdar",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-07-16T08:15:41.697Z",
          "hidden": false
        },
        {
          "_id": "687731d0257d4f04353707c0",
          "name": "Aleksander Ficek",
          "hidden": false
        },
        {
          "_id": "687731d0257d4f04353707c1",
          "name": "Sean Narenthiran",
          "hidden": false
        },
        {
          "_id": "687731d0257d4f04353707c2",
          "name": "Mehrzad Samadi",
          "hidden": false
        },
        {
          "_id": "687731d0257d4f04353707c3",
          "name": "Jocelyn Huang",
          "hidden": false
        },
        {
          "_id": "687731d0257d4f04353707c4",
          "name": "Siddhartha Jain",
          "hidden": false
        },
        {
          "_id": "687731d0257d4f04353707c5",
          "name": "Vahid Noroozi",
          "hidden": false
        },
        {
          "_id": "687731d0257d4f04353707c6",
          "name": "Boris Ginsburg",
          "hidden": false
        }
      ],
      "publishedAt": "2025-07-11T23:35:54.000Z",
      "submittedOnDailyAt": "2025-07-16T03:31:02.680Z",
      "title": "OpenCodeReasoning-II : Une approche simple de programmation de tests par critiques sur soi-même",
      "submittedOnDailyBy": {
        "_id": "6254f8e5d21e4cc386b881ad",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1649899774659-6254f8e5d21e4cc386b881ad.jpeg",
        "isPro": false,
        "fullname": "Somshubra Majumdar",
        "user": "smajumdar94",
        "type": "user"
      },
      "summary": "Récemment, le développement de grands modèles de langue basés sur des preuves (LLMs) a ouvert des opportunités importantes dans la génération de code et l'évaluation, notamment grâce à l'échelle des tests. Cependant, ce progrès nécessite une base fondamentale de données de haute qualité. Dans cette étude, nous présentons le jeu de données OpenCodeReasoning-II, qui comprend près de 250 000 tuples de questions-réponses-évaluations (environ 35 000 requêtes de programmation uniques), à une échelle similaire aux jeux de données de code basés sur des preuves plus grands publiés précédemment. Dans cette étude, nous utilisons une stratégie d'ajustement en deux étapes. Dans la première étape, nous nous concentrons sur la génération de code, et dans la deuxième étape, nous effectuons l'entraînement commun du modèle de génération de code et d'évaluation. Le modèle Qwen2.5-Instruct ajusté a atteint des niveaux de performance dans la génération de code qui dépassent ou égalent ceux des modèles de poids extraits ouverts. En particulier, l'intégration du modèle de génération de code et d'évaluation a réalisé un accroissement significatif du rendement compétitif. De plus, nous présentons une extension spécialisée en langage C++ du LiveCodeBench Benchmark et nous promouvons l'utilisation de ce Benchmark pour une évaluation plus détaillée des LLMs.",
      "upvotes": 2,
      "discussionId": "687731d0257d4f04353707c7"
    },
    "publishedAt": "2025-07-11T19:35:54.000Z",
    "title": "OpenCodeReasoning-II: A Simple Test Time Scaling Approach via\n  Self-Critique",
    "summary": "Recent advancements in reasoning-based Large Language Models (LLMs),\nparticularly their potential through test-time scaling, have created\nsignificant opportunities for distillation in code generation and critique.\nHowever, progress in both areas fundamentally depends on large-scale,\nhigh-quality datasets. In this work, we introduce OpenCodeReasoning-II, a\ndataset consists of 2.5M question-solution-critique triples (approx. 35K unique\nprogramming questions), making it nearly twice the size of the previous largest\npublicly available code reasoning dataset. In this work, we employ a two-stage\nsupervised fine-tuning strategy. The first stage focuses on fine-tuning for\ncode generation, while the second stage involves the joint training of models\nfor both code generation and critique. Our resulting finetuned Qwen2.5-Instruct\nmodels achieve performance in code generation that either exceeds or equals the\nbest prior open-weight distilled models. Notably, the integration of our code\ngeneration and critique models leads to significant improvements in competitive\ncoding performance. Furthermore, we present an extension of the LiveCodeBench\nbenchmark to specifically support the C++ programming language, thereby\nfacilitating more comprehensive LLM evaluation using this benchmark.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2507.09075.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6254f8e5d21e4cc386b881ad",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1649899774659-6254f8e5d21e4cc386b881ad.jpeg",
      "fullname": "Somshubra Majumdar",
      "name": "smajumdar94",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 27
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2507.08616",
      "authors": [
        {
          "_id": "687764e0ff8f47a7f86442ad",
          "name": "Florian Grötschla",
          "hidden": false
        },
        {
          "_id": "687764e0ff8f47a7f86442ae",
          "name": "Luis Müller",
          "hidden": false
        },
        {
          "_id": "687764e0ff8f47a7f86442af",
          "name": "Jan Tönshoff",
          "hidden": false
        },
        {
          "_id": "687764e0ff8f47a7f86442b0",
          "name": "Mikhail Galkin",
          "hidden": false
        },
        {
          "_id": "687764e0ff8f47a7f86442b1",
          "name": "Bryan Perozzi",
          "hidden": false
        }
      ],
      "publishedAt": "2025-07-11T14:13:22.000Z",
      "submittedOnDailyAt": "2025-07-16T07:08:39.797Z",
      "title": "AgentsNet : Coopération et Logique de la Collaboration de Multi-Agent LLM",
      "submittedOnDailyBy": {
        "_id": "63c09599dd793d5a62890e7d",
        "avatarUrl": "/avatars/fed51ddd492b98e7cd4c3d1f82998635.svg",
        "isPro": false,
        "fullname": "Michael Galkin",
        "user": "mgalkin",
        "type": "user"
      },
      "summary": "Les modèles de langage grands (LLMs) ont démontré une capacité forte pour résoudre des problèmes dans des systèmes multiagents. Cependant, l'apparition de ces systèmes soulève certaines doutes sur la capacité des réseaux complexes d'agents à organiser et collaborer de manière efficace automatiquement. L'évaluation du rendement dans les référentiels de la théorie de la raison montre que les systèmes multiagents peuvent résoudre des tâches de la théorie de la raison. Cependant, la capacité à utiliser efficacement les thèmes de la réseau des agents est incertaine. Dans ce contexte, nous proposons AgentsNet, un nouveau référentiel de la théorie de la raison multiagente. Inspiré par les problèmes classiques des systèmes distribués et de la théorie des graphes, AgentsNet mesure la capacité des réseaux d'agents à collaborer, à organiser automatiquement et à former des stratégies de communication efficaces. Dans AgentsNet, nous évaluons divers méthodes de référence et incluons des agents uniformes pour conclure les protocoles de base d'organisation et de communication. Nous avons confirmé que différents leaders de LLMs montrent un excellent rendement dans des petites réseaux, mais leur performance diminue quand la réseau s'étend. Les référentiels multiagentes existants se concentrent sur des réseaux avec un maximum de 2-5 agents, mais AgentsNet est scalable sans limites de taille, s'adaptant aux nouvelles générations de LLMs. Par conséquent, nous évaluons également les modèles leaders dans des systèmes de 100 agents.",
      "upvotes": 1,
      "discussionId": "687764e0ff8f47a7f86442b2",
      "projectPage": "https://agentsnet.graphben.ch/",
      "githubRepo": "https://github.com/floriangroetschla/AgentsNet",
      "ai_summary": "AgentsNet is a new benchmark for evaluating multi-agent systems' ability to self-organize, communicate, and solve problems collaboratively across varying network sizes.",
      "ai_keywords": [
        "multi-agent systems",
        "AgentsNet",
        "distributed systems",
        "graph theory",
        "self-organization",
        "communication",
        "network topology",
        "homogeneous networks",
        "protocols",
        "LLMs"
      ],
      "githubStars": 1
    },
    "publishedAt": "2025-07-11T10:13:22.000Z",
    "title": "AgentsNet: Coordination and Collaborative Reasoning in Multi-Agent LLMs",
    "summary": "Large-language models (LLMs) have demonstrated powerful problem-solving\ncapabilities, in particular when organized in multi-agent systems. However, the\nadvent of such systems also raises several questions on the ability of a\ncomplex network of agents to effectively self-organize and collaborate. While\nmeasuring performance on standard reasoning benchmarks indicates how well\nmulti-agent systems can solve reasoning tasks, it is unclear whether these\nsystems are able to leverage their topology effectively. Here, we propose\nAgentsNet, a new benchmark for multi-agent reasoning. By drawing inspiration\nfrom classical problems in distributed systems and graph theory, AgentsNet\nmeasures the ability of multi-agent systems to collaboratively form strategies\nfor problem-solving, self-organization, and effective communication given a\nnetwork topology. We evaluate a variety of baseline methods on AgentsNet\nincluding homogeneous networks of agents which first have to agree on basic\nprotocols for organization and communication. We find that some frontier LLMs\nare already demonstrating strong performance for small networks but begin to\nfall off once the size of the network scales. While existing multi-agent\nbenchmarks cover at most 2-5 agents, AgentsNet is practically unlimited in size\nand can scale with new generations of LLMs. As such, we also probe frontier\nmodels in a setup with up to 100 agents.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2507.08616.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "63c09599dd793d5a62890e7d",
      "avatarUrl": "/avatars/fed51ddd492b98e7cd4c3d1f82998635.svg",
      "fullname": "Michael Galkin",
      "name": "mgalkin",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 13
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2507.07186",
      "authors": [
        {
          "_id": "68708a2ac8391850d609787d",
          "user": {
            "_id": "610c1e1a423fe7d80928aefd",
            "avatarUrl": "/avatars/8591584d678cf7fddace01e223953a63.svg",
            "isPro": true,
            "fullname": "Itay Itzhak",
            "user": "itay1itzhak",
            "type": "user"
          },
          "name": "Itay Itzhak",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-07-16T08:15:57.996Z",
          "hidden": false
        },
        {
          "_id": "68708a2ac8391850d609787e",
          "name": "Yonatan Belinkov",
          "hidden": false
        },
        {
          "_id": "68708a2ac8391850d609787f",
          "name": "Gabriel Stanovsky",
          "hidden": false
        }
      ],
      "publishedAt": "2025-07-09T18:01:14.000Z",
      "submittedOnDailyAt": "2025-07-16T06:16:00.646Z",
      "title": "Prédiction de l'entraînement et tendance à des ajustements micro : Étude de cas sur l'origine de l'inclinaison cognitivienne des modèles de langage d'intelligence artificielle",
      "submittedOnDailyBy": {
        "_id": "610c1e1a423fe7d80928aefd",
        "avatarUrl": "/avatars/8591584d678cf7fddace01e223953a63.svg",
        "isPro": true,
        "fullname": "Itay Itzhak",
        "user": "itay1itzhak",
        "type": "user"
      },
      "summary": "Les modèles de langage grands (LLMs) reflètent un changement systématique dans le développement, un phénomène similaire à celui observé chez les humains. Des recherches antérieures ont découvert que ces déviations ne sont pas exclusives d'un modèle et s'étendent à travers l'apprentissage d'instructions. Cependant, il n'a pas été clairement déterminé si ces déviations sont causées par l'apprentissage préalable, l'apprentissage détaillé ou le bruit aléatoire induit par l'stimulation d'apprentissage. Nous proposons un approche expérimentale en deux étapes pour séparer les causes de ces déviations. Tout d'abord, nous réentraînons le modèle plusieurs fois avec différentes séquences de nombres aléatoires pour étudier si l'aléa de l'apprentissage a un impact plus important que le 30% sur la déviation. Ensuite, nous introduisons l'apprentissage croisé pour échanger des ensembles de données d'instructions entre modèles et séparer le cercle de la déviation. Cet échange permet de vérifier directement si la déviation dépend des ensembles de données. Nos résultats indiquent que l'aléa de l'apprentissage n'est pas suffisant pour causer des changements, mais la déviation principale se forme principalement lors de l'apprentissage préalable : les modèles partageant le même ensemble de données préalables montrent des patrons de déviation similaires à ceux partageant un ensemble de données d'entraînement. Cette conclusion suggère que pour comprendre les déviations de modèles d'apprentissage détaillé, il est nécessaire de considérer la cause de l'apprentissage préalable plutôt que l'effet de l'apprentissage détaillé. Cette perspective peut guider futurs efforts pour développer des stratégies fondamentales pour évaluer et atténuer les déviations dans les LLMs.",
      "upvotes": 1,
      "discussionId": "68708a2bc8391850d6097880",
      "ai_summary": "Research identifies pretraining as the primary source of cognitive biases in large language models, distinguishing its influence from finetuning and training randomness.",
      "ai_keywords": [
        "large language models",
        "cognitive biases",
        "instruction tuning",
        "pretraining",
        "finetuning",
        "training randomness",
        "cross-tuning",
        "dataset-dependent biases"
      ]
    },
    "publishedAt": "2025-07-09T14:01:14.000Z",
    "title": "Planted in Pretraining, Swayed by Finetuning: A Case Study on the\n  Origins of Cognitive Biases in LLMs",
    "summary": "Large language models (LLMs) exhibit cognitive biases -- systematic\ntendencies of irrational decision-making, similar to those seen in humans.\nPrior work has found that these biases vary across models and can be amplified\nby instruction tuning. However, it remains unclear if these differences in\nbiases stem from pretraining, finetuning, or even random noise due to training\nstochasticity. We propose a two-step causal experimental approach to\ndisentangle these factors. First, we finetune models multiple times using\ndifferent random seeds to study how training randomness affects over 30\ncognitive biases. Second, we introduce cross-tuning -- swapping\ninstruction datasets between models to isolate bias sources. This swap uses\ndatasets that led to different bias patterns, directly testing whether biases\nare dataset-dependent. Our findings reveal that while training randomness\nintroduces some variability, biases are mainly shaped by pretraining: models\nwith the same pretrained backbone exhibit more similar bias patterns than those\nsharing only finetuning data. These insights suggest that understanding biases\nin finetuned models requires considering their pretraining origins beyond\nfinetuning effects. This perspective can guide future efforts to develop\nprincipled strategies for evaluating and mitigating bias in LLMs.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2507.07186.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "610c1e1a423fe7d80928aefd",
      "avatarUrl": "/avatars/8591584d678cf7fddace01e223953a63.svg",
      "fullname": "Itay Itzhak",
      "name": "itay1itzhak",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  }
]