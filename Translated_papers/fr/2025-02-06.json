[
  {
    "paper": {
      "id": "2502.01506",
      "authors": [
        {
          "_id": "67a4214f12b90b15dc5a648e",
          "name": "Yuzhe Yang",
          "hidden": false
        },
        {
          "_id": "67a4214f12b90b15dc5a648f",
          "name": "Yifei Zhang",
          "hidden": false
        },
        {
          "_id": "67a4214f12b90b15dc5a6490",
          "name": "Minghao Wu",
          "hidden": false
        },
        {
          "_id": "67a4214f12b90b15dc5a6491",
          "name": "Kaidi Zhang",
          "hidden": false
        },
        {
          "_id": "67a4214f12b90b15dc5a6492",
          "name": "Yunmiao Zhang",
          "hidden": false
        },
        {
          "_id": "67a4214f12b90b15dc5a6493",
          "name": "Honghai Yu",
          "hidden": false
        },
        {
          "_id": "67a4214f12b90b15dc5a6494",
          "name": "Yan Hu",
          "hidden": false
        },
        {
          "_id": "67a4214f12b90b15dc5a6495",
          "name": "Benyou Wang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-03T16:39:48.000Z",
      "title": "Twinmark: Comportement d'échange sur le marché financier et socialisation",
      "summary": "La recherche des phénomènes sociaux a été un centre d'attention centrale dans la sociologie pendant de nombreuses années. Les méthodes traditionnelles de modélisation, comme les modèles basés sur les agents (Agent-Based Models, ABMs) selon des règles, n'ont pas pu capturer la diversité et la complexité des comportements humains, qui comprenaient des éléments irrationnels. Récemment, les modèles de langage de grande taille (LLM) ont été introduits comme des outils de simulation pour modéliser et jouer des rôles dans la sociologie. Ces modèles montrent qu'ils peuvent considérer des effets cognitifs, des changements émotionnels et d'autres facteurs irrationnels, contribuant à la simulation de dynamiques sociales et économiques plus réalistes. Dans cet article, nous présentons un nouveau cadre de travail multi-agent appelé TwinMarket, qui utilise les LLM pour simuler des systèmes socioéconomiques. Plus spécifiquement, nous observons comment les comportements individuels interagissent et forment des structures de rétroaction, générant des phénomènes collectifs. Les expériences réalisées dans un environnement de marché des actions montrent comment les comportements individuels peuvent conduire à l'émergence de comportements collectifs, comme des crises financières et des déséquilibres, fournissant des insights précieux sur la complexe interaction entre les décisions individuelles et les patrons socioéconomiques collectifs.",
      "upvotes": 21,
      "discussionId": "67a4215212b90b15dc5a650a"
    },
    "publishedAt": "2025-02-05T21:44:36.248Z",
    "title": "TwinMarket: A Scalable Behavioral and Social Simulation for Financial Markets",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01506.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "643c047326f177a3e41627b6",
      "avatarUrl": "/avatars/ade75cebd049daf080ba80a80d516240.svg",
      "fullname": "Yifei Zhang",
      "name": "amstrongzyf",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.03373",
      "authors": [
        {
          "_id": "67a42c079a4fb11b11cc4f6f",
          "name": "Edward Yeo",
          "hidden": false
        },
        {
          "_id": "67a42c079a4fb11b11cc4f70",
          "name": "Yuxuan Tong",
          "hidden": false
        },
        {
          "_id": "67a42c079a4fb11b11cc4f71",
          "name": "Morry Niu",
          "hidden": false
        },
        {
          "_id": "67a42c079a4fb11b11cc4f72",
          "name": "Graham Neubig",
          "hidden": false
        },
        {
          "_id": "67a42c079a4fb11b11cc4f73",
          "name": "Xiang Yue",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-05T17:13:32.000Z",
      "title": "Le déchiffrement du mystère de la mémoire du corps humain par un LLM",
      "summary": "Le calcul des influences d'échelle dans l'inférence de modèles de langage grands (LLMs) renforce la base logique de l'inférence. En utilisant des chaînes longues d'objets conscients (CoTs), on peut mettre en œuvre des stratégies comme le retour en arrière ou la correction d'erreurs. L'apprentissage par renforcement (RL) apparaît comme l'un des méthodes importantes pour développer ces capacités, mais les CoTs longs ne se produisent pas toujours. De plus, l'entraînement par RL nécessite des conceptions soigneuses. Dans cette étude, on examine systématiquement la structure de la base logique des CoTs longs et on identifie les causes qui conduisent les modèles à produire leurs trajectoires rétroalimentées longues. À travers de plusieurs expériences d'entraînement supervisé (SFT) et RL, on obtient les quatre principaux résultats suivants : 1. L'SFT n'est pas nécessaire de manière rigoureuse, mais peut simplifier l'entraînement et augmenter l'efficacité. 2. La capacité de base logique se développe à mesure que la quantité de calculs d'entraînement augmente, mais son développement n'est pas sûr. Par conséquent, la régulation de la récompense est cruciale pour maintenir l'stabilité lors de la croissance de la longueur des CoTs. 3. L'échelle de récompenses est un domaine prometteur dans le RL. On utilise des solutions résumées de web qui incluent du bruit pour générer des signaux de récompense et des structures de filtrage pour renforcer cela, particulièrement efficace pour des tâches hors distribution (OOD). 4. Les capacités basiques comme la correction d'erreurs sont intrinsèques au modèle original, mais nécessitent de grands augmentations de calculs pour être développées efficacement dans des tâches complexes, ce qui nécessite un approche complexe. Ces observations fournissent une ligne directrice pratique pour optimiser les stratégies d'entraînement nécessaires pour renforcer la base logique des CoTs longs dans les LLMs. Le code est disponible sur la URL suivante : https://github.com/eddycmu/demystify-long-cot.",
      "upvotes": 15,
      "discussionId": "67a42c089a4fb11b11cc4fae"
    },
    "publishedAt": "2025-02-05T22:27:48.348Z",
    "title": "Demystifying Long Chain-of-Thought Reasoning in LLMs",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.03373.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "6230d750d93e84e233882dbc",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6230d750d93e84e233882dbc/4MGEekLW3oWzqeFWDWvIK.jpeg",
      "fullname": "Xiang Yue",
      "name": "yuexiang96",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 26
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.03387",
      "authors": [
        {
          "_id": "67a445ccbdd74b63b4e52a7d",
          "name": "Yixin Ye",
          "hidden": false
        },
        {
          "_id": "67a445ccbdd74b63b4e52a7e",
          "name": "Zhen Huang",
          "hidden": false
        },
        {
          "_id": "67a445ccbdd74b63b4e52a7f",
          "name": "Yang Xiao",
          "hidden": false
        },
        {
          "_id": "67a445ccbdd74b63b4e52a80",
          "name": "Ethan Chern",
          "hidden": false
        },
        {
          "_id": "67a445ccbdd74b63b4e52a81",
          "name": "Shijie Xia",
          "hidden": false
        },
        {
          "_id": "67a445ccbdd74b63b4e52a82",
          "name": "Pengfei Liu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-05T17:23:45.000Z",
      "title": "Pour des raisons raisonnables, il serait plus judicieux de réduire le nombre de mots.",
      "summary": "Nous abordons le problème de comprendre comment apparaissent les théories complexes dans des modèles de langue à grande échelle. La généralisation est que les tâches de théorie de raisonnement complexe nécessitent de données d'entraînement complexes (supérieures à 100,000 exemples), mais nous avons démontré que l'on peut développer une capacité efficace de raisonnement mathématique complexe avec seulement 817 exemples thématiques. Les expériences spécifiques montrent que le modèle LIMO fournit un rendement mathématique de théorie de raisonnement sans précédent. Avec 817 données d'entraînement, LIMO a atteint une précision de 57.1% sur AIME et de 94.8% sur MATH, améliorant considérablement par rapport aux modèles basés sur SFT antérieurs, qui atteignaient seulement 6.5% et 59.2% sur ces benchmarks, en utilisant seulement 1% des données d'entraînement nécessaires précédemment. LIMO a amélioré absolument de 40.5% sur 10 évaluations différentes et a dépassé des modèles entraînés avec beaucoup plus d'information, soulevant des questions sur si l'apprentissage par réflexion (SFT) est plus efficace que la généralisation. Sur la base de ces résultats, nous présentons deux facteurs clés pour déterminer la précision critique de la théorie de raisonnement complexe : 1) la complétude de la base de connaissance du modèle complètement codifiée avant l'entraînement, et 2) l'efficacité des \"températures de reconnaissance\" pour montrer comment le modèle utilise sa base de connaissance pour résoudre des tâches de théorie de raisonnement complexe.",
      "upvotes": 9,
      "discussionId": "67a445cdbdd74b63b4e52af7"
    },
    "publishedAt": "2025-02-06T00:26:02.483Z",
    "title": "LIMO: Less is More for Reasoning",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.03387.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5956
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.02737",
      "authors": [
        {
          "_id": "67a446a9430e358f5d5ac4c3",
          "name": "Loubna Ben Allal",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4c4",
          "name": "Anton Lozhkov",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4c5",
          "name": "Elie Bakouch",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4c6",
          "name": "Gabriel Martín Blázquez",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4c7",
          "name": "Guilherme Penedo",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4c8",
          "name": "Lewis Tunstall",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4c9",
          "name": "Andrés Marafioti",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4ca",
          "name": "Hynek Kydlíček",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4cb",
          "name": "Agustín Piqueres Lajarín",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4cc",
          "name": "Vaibhav Srivastav",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4cd",
          "name": "Joshua Lochner",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4ce",
          "name": "Caleb Fahlgren",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4cf",
          "name": "Xuan-Son Nguyen",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4d0",
          "name": "Clémentine Fourrier",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4d1",
          "name": "Ben Burtenshaw",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4d2",
          "name": "Hugo Larcher",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4d3",
          "name": "Haojun Zhao",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4d4",
          "name": "Cyril Zakka",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4d5",
          "name": "Mathieu Morlon",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4d6",
          "name": "Colin Raffel",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4d7",
          "user": {
            "_id": "6284b359eac6d6ca13879514",
            "avatarUrl": "/avatars/2dcca0f0d21cbe1a54eedac759adc61c.svg",
            "isPro": false,
            "fullname": "evaluate-bot",
            "user": "evaluate-bot",
            "type": "user"
          },
          "name": "Leandro von Werra",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-02-06T05:20:41.925Z",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4d8",
          "name": "Thomas Wolf",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-04T21:43:16.000Z",
      "title": "Smorl LM2 : Lorsque le Smorl s'étend, il est entraîné au centre des données pour apprendre un petit modèle de langue.",
      "summary": "Dans cet article, on décrit le développement de \"SmolLM2\", le modèle de langage \"petit\" le plus avancé (170 millions de paramètres). SmolLM2 apprend à travers un processus d'apprentissage multiniveau de texte, de mathématiques, de code et de données d'instructions, en apprenant environ 110 milliards de tokens. De plus, lorsque les ensembles de données existants sont problématiquement petits ou de faible qualité, on ajoute de nouveaux ensembles de données spécifiquement conçus (FineMath, Stack-Edu, SmolTalk). Pour mettre à jour la proportion des ensembles de données, on effectue des tests d'élimination à petite échelle basés sur le rendement de chaque étape et des processus de correction manuelle. Enfin, SmolLM2 montre un rendement qui dépasse les autres modèles de langage \"petits\" les plus récents (Qwen2.5-1.5B, Llama3.2-1B). Pour encourager la recherche sur le développement de modèles de langage et les applications des modèles de langage \"petits\", on publie SmolLM2 et tous les ensembles de données préparés dans ce projet.",
      "upvotes": 9,
      "discussionId": "67a446a9430e358f5d5ac4f8"
    },
    "publishedAt": "2025-02-06T00:20:51.704Z",
    "title": "SmolLM2: When Smol Goes Big -- Data-Centric Training of a Small Language Model",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.02737.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5956
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.02339",
      "authors": [
        {
          "_id": "67a3262873bdaf626f1e9eab",
          "name": "Jinyang Wu",
          "hidden": false
        },
        {
          "_id": "67a3262873bdaf626f1e9eac",
          "name": "Mingkuan Feng",
          "hidden": false
        },
        {
          "_id": "67a3262873bdaf626f1e9ead",
          "name": "Shuai Zhang",
          "hidden": false
        },
        {
          "_id": "67a3262873bdaf626f1e9eae",
          "name": "Ruihan Jin",
          "hidden": false
        },
        {
          "_id": "67a3262873bdaf626f1e9eaf",
          "name": "Feihu Che",
          "hidden": false
        },
        {
          "_id": "67a3262873bdaf626f1e9eb0",
          "name": "Zengqi Wen",
          "hidden": false
        },
        {
          "_id": "67a3262873bdaf626f1e9eb1",
          "name": "Jianhua Tao",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-04T14:18:29.000Z",
      "title": "Utilisant MCTS pour améliorer la logique de plusieurs modèles avec pensée structurée",
      "summary": "Les modèles de langage multimodal (MLLMs) montrent des capacités impressionnantes, mais ils encore rencontrent des problèmes dans l'inférence visuelle complexe. Les efforts récents visent à améliorer l'inférence des MLLMs par des structures de pensée explicites comme des recherches structurées ou des séquences d'apprentissage guidées par un professeur, mais ces approches présentent des défis pour maintenir un équilibre entre le rendement et l'efficacité, en mettant l'accent sur des données et des espaces de recherche divers, ce qui limite l'efficacité dans l'extraction d'entrées et l'utilisation de données. Pour résoudre ces problèmes, nous proposons un paradigme de pensée structuré autonome basé sur la Recherche Monte-Carlo Tree Search (MCTS), appelé AStar. AStar utilise MCTS pour déduire des patrons cognitifs d'un haut niveau à partir de données limitées, en utilisant des structures hiérarchiques. En se basant sur ces patrons explicites, nous avons conçu un cadre d'inférence qui intègre de manière autonome les capacités de pensée interne du modèle et les directives de pensée externes, appelé cadre d'inférence unifié. Ce cadre permet des inférences efficaces à travers une petite quantité d'itérations d'arbre. Ce nouveau paradigme maintient fortement l'équilibre entre le rendement et l'efficacité, démontrant son efficacité dans le benchmark MathVerse, en atteignant une précision supérieure à 54.0% et surpassant GPT-4o (50.2%), tout en maintenant l'efficacité avec de grands ensembles de données et de calculs.",
      "upvotes": 7,
      "discussionId": "67a3262973bdaf626f1e9edb"
    },
    "publishedAt": "2025-02-05T21:45:32.304Z",
    "title": "Boosting Multimodal Reasoning with MCTS-Automated Structured Thinking",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.02339.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6747de57f8cab58c22ec94a2",
      "avatarUrl": "/avatars/5bae0341862fac24564781c0fa32aac5.svg",
      "fullname": "Jinyang Wu",
      "name": "Jinyang23",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 4
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.01154",
      "authors": [
        {
          "_id": "67a4609af2e553c1d0da914d",
          "name": "Yu-Ling Hsu",
          "hidden": false
        },
        {
          "_id": "67a4609af2e553c1d0da914e",
          "name": "Hsuan Su",
          "hidden": false
        },
        {
          "_id": "67a4609af2e553c1d0da914f",
          "name": "Shang-Tse Chen",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-03T08:44:24.000Z",
      "title": "Le seul frein avec un seul prompt",
      "summary": "Les modèles de langage grands (LLMs) ont connu un essor rapide récent et ont eu un impact innovant dans diverses domaines d'application, améliorant considérablement la convenance et la productivité. Cependant, ces progrès ont été associés à des préoccupations éthiques et à de nouveaux types d'attaques, comme le \"jailbreaking\". La technologie de prompting se concentre principalement sur l'optimisation des entrées hostiles dans des situations personnelles, ce qui augmente les coûts computationnels lorsqu'il s'agit de grands ensembles de données. D'autre part, l'investigation dans des environnements plus généraux, où un attaquant commun est entraîné et adapté à des tâches non vues, est insuffisante et pas encore étudiée. Dans cet article, nous présentons un méthode basée sur un prompting généralisé pour mener à bien un \"jailbreaking\" dans les LLMs. Ce méthode est appelée DUMP. Grâce aux résultats expérimentaux, nous montrons que notre méthode d'optimisation de prompting généralisé dépasse les techniques existantes.",
      "upvotes": 3,
      "discussionId": "67a4609bf2e553c1d0da9181"
    },
    "publishedAt": "2025-02-06T02:11:41.374Z",
    "title": "Jailbreaking with Universal Multi-Prompts",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01154.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "608abf1272b50b02c4b02865",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1619708309549-608abf1272b50b02c4b02865.jpeg",
      "fullname": "Hsuan Su",
      "name": "jacksukk",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.01105",
      "authors": [
        {
          "_id": "67a45c85e73ad243c0b9529e",
          "name": "Yiren Song",
          "hidden": false
        },
        {
          "_id": "67a45c85e73ad243c0b9529f",
          "name": "Danze Chen",
          "hidden": false
        },
        {
          "_id": "67a45c85e73ad243c0b952a0",
          "user": {
            "_id": "63a55320ce5763e06f78519c",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1671779060549-noauth.jpeg",
            "isPro": false,
            "fullname": "Mike Shou",
            "user": "mikeshou",
            "type": "user"
          },
          "name": "Mike Zheng Shou",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-02-06T06:54:02.195Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-03T06:49:58.000Z",
      "title": "LayerTracer : Implémente la synthèse SVG de structures de couches correspondant à la cognition par division et Transformer.",
      "summary": "La génération de SVGs par des couches par ordinateur est actuellement considérée comme trop simplifiée, ce qui entraîne des sorties de seule couche ou une absence de nécessité de formes dans l'optimisation. Nous proposons LayerTracer pour combler ce vide. Ce cadre de travail est basé sur des transformeurs distribués. Notre approche comprend deux étapes : d'abord, DiT conditionné par texte génère des structures planificatrices multiniveaux qui mimétisent le flux de travail humain. Ensuite, une vectorisation et une réduction de pas par couche sont effectuées pour créer des SVGs nettoyés et éditables. Pendant le processus de vectorisation, les images de référence sont codées en tokens de puissance pour introduire une structure de dispersion conditionnelle qui guide la reconfiguration couche par couche, en maintenant la structure. Les expériences de dispersion montrent des améliorations de la qualité de la génération et de l'éditabilité, et démontrent que les vecteurs générés par l'IA peuvent être reconnus par les concepteurs professionnels.",
      "upvotes": 3,
      "discussionId": "67a45c8ae73ad243c0b953ea"
    },
    "publishedAt": "2025-02-06T01:55:37.207Z",
    "title": "LayerTracer: Cognitive-Aligned Layered SVG Synthesis via Diffusion Transformer",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01105.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64311a95034ecbefddd141ef",
      "avatarUrl": "/avatars/b6dc5ca373bedbaa368208517954c375.svg",
      "fullname": "Yiren Song",
      "name": "yiren98",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.01618",
      "authors": [
        {
          "_id": "67a438d26bb8caaab06f5a5e",
          "user": {
            "_id": "64c2abe8c43875b438efef25",
            "avatarUrl": "/avatars/6efda081f52cf56db2d29a5ec05cb557.svg",
            "isPro": false,
            "fullname": "isha",
            "user": "ishapuri-mit",
            "type": "user"
          },
          "name": "Isha Puri",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-02-06T04:21:39.202Z",
          "hidden": false
        },
        {
          "_id": "67a438d26bb8caaab06f5a5f",
          "name": "Shivchander Sudalairaj",
          "hidden": false
        },
        {
          "_id": "67a438d26bb8caaab06f5a60",
          "name": "Guangxuan Xu",
          "hidden": false
        },
        {
          "_id": "67a438d26bb8caaab06f5a61",
          "name": "Kai Xu",
          "hidden": false
        },
        {
          "_id": "67a438d26bb8caaab06f5a62",
          "name": "Akash Srivastava",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-03T18:50:50.000Z",
      "title": "Méthode d'inférence probabiliste pour l'échelle dans la prédiction de modèles de langage grands basés sur des particules",
      "summary": "Les modèles de langage grands (LLMs) ont réalisé une amélioration notable de leur performance grâce au croissance du taille du modèle et à l'expansion des données. Cependant, des preuves récentes indiquent que l'effet de ces stratégies est en déclin et suggèrent la nécessité d'augmenter le temps de calcul d'inférence. Les méthodes actuelles pour augmenter le temps de calcul d'inférence utilisent généralement des modèles de récompense pour traiter les tâches comme des problèmes de recherche, ce qui les rend peu robustes face aux attaques de récompense dues aux erreurs d'approximation dans les modèles de récompense. Dans cet article, l'augmentation du temps de calcul d'inférence est abordée comme un problème d'inférence probabiliste et un approche basée sur des échantillons est utilisée pour explorer une large gamme de distributions d'état des modèles de l'espace d'état qui utilisent des approximations. De cette manière, on évite d'optimiser directement les modes du modèle. Dans cet article, on applique le méthode de Monte Carlo basée sur des bases tridimensionnelles pour ce problème et on propose un nouvel approche pour augmenter le temps de calcul d'inférence. Les évaluations expérimentales montrent une augmentation de 4 à 16 fois pour différentes tâches mathématiques logiques difficiles, comparativement aux explorations déterministes. Avec cet approche, Qwen2.5-Math-1.5B-Instruct dépasse la précision de GPT-4 avec 4 sorties de rétroaction, et Qwen2.5-Math-7B-Instruct atteint un niveau de précision similaire à o1 avec 32 sorties de rétroaction. Cet article fournit des méthodes efficaces pour augmenter le temps de calcul d'inférence et contribue au développement d'algorithmes plus robustes dans les futures recherches en intégrant la littérature abondante en inférence probabiliste avec l'augmentation du temps de calcul d'inférence dans les LLMs. Les codes et informations supplémentaires sont disponibles sur https://probabilistic-inference-scaling.github.io.",
      "upvotes": 3,
      "discussionId": "67a438d36bb8caaab06f5a87"
    },
    "publishedAt": "2025-02-05T23:23:08.428Z",
    "title": "A Probabilistic Inference Approach to Inference-Time Scaling of LLMs using Particle-Based Monte Carlo Methods",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/648b3f3208c4a9d807a90a99/gwgJD14Bd0fdz7xpcHdHe.mp4",
      "https://cdn-uploads.huggingface.co/production/uploads/648b3f3208c4a9d807a90a99/KHcaqxZL3wiloAm7x-7nA.mp4"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01618.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "648b3f3208c4a9d807a90a99",
      "avatarUrl": "/avatars/03634b4e7f8afe9b589a2d7370e29960.svg",
      "fullname": "Akash Srivastava",
      "name": "akashsri",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 8
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.03275",
      "authors": [
        {
          "_id": "67a448b69ca42c642a723a7d",
          "name": "DiJia Su",
          "hidden": false
        },
        {
          "_id": "67a448b69ca42c642a723a7e",
          "name": "Hanlin Zhu",
          "hidden": false
        },
        {
          "_id": "67a448b69ca42c642a723a7f",
          "name": "Yingchen Xu",
          "hidden": false
        },
        {
          "_id": "67a448b69ca42c642a723a80",
          "name": "Jiantao Jiao",
          "hidden": false
        },
        {
          "_id": "67a448b69ca42c642a723a81",
          "name": "Yuandong Tian",
          "hidden": false
        },
        {
          "_id": "67a448b69ca42c642a723a82",
          "name": "Qinqing Zheng",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-05T15:33:00.000Z",
      "title": "Combinaison de Tokens : Motifs pour Améliorer la Logique Logique du Modèle de Langue à travers la Mixture de Tokens Potentiels et de Texte",
      "summary": "Les modèles de langage grand (LLMs) sont entraînés avec des données de \"chain-of-thought\" (CoT), ce qui permet aux modèles de montrer clairement les processus de pensée à chaque étape, leur conférant une spécialisation en logique et en planification. Cependant, de nombreuses mots contribuent avec des informations logiques essentielles pour la continuité de la phrase, et leur traitement nécessite des ressources informatiques complexes. Dans cet article, nous proposons une représentation hybride pour le traitement de la logique, en utilisant des tokens discrets générés par VQ-VAE pour abstracter partiellement les premiers pas de logique et réduire considérablement la longueur du traitement logique. L'utilisation de l'abstraction des traces potentielles est examinée dans deux scénarios : 1) l'entraînement à partir du début du modèle pour le problème de \"Maze Keys-Finding\", et 2) l'ajustement micro des LLMs pour des données hybrides, les deux qui peuvent inclure des problèmes logiques et mathématiques. Pour promouvoir un apprentissage efficace, nous introduisons un simple procédé d'entraînement qui mélange aléatoirement les tokens potentiels et contextuels, ce qui permet au modèle d'adapter rapidement aux nouveaux tokens potentiels. Notre approche ne coïncide ni ne dépasse pas les méthodes de base linéaires dans différents cadres d'évaluation.",
      "upvotes": 2,
      "discussionId": "67a448b89ca42c642a723ac6"
    },
    "publishedAt": "2025-02-06T00:29:44.686Z",
    "title": "Token Assorted: Mixing Latent and Text Tokens for Improved Language Model Reasoning",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.03275.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5956
    },
    "isAuthorParticipating": false
  }
]