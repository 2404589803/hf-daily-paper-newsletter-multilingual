[
  {
    "paper": {
      "id": "2505.19147",
      "authors": [
        {
          "_id": "68353258d005e45149d2d384",
          "user": {
            "_id": "66a0caa1a7a6ed88ad1c0ddf",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/66a0caa1a7a6ed88ad1c0ddf/WoOP24-ruuHy4ryNhRp0D.jpeg",
            "isPro": false,
            "fullname": "Xuyang Liu",
            "user": "xuyang-liu16",
            "type": "user"
          },
          "name": "Xuyang Liu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T08:23:05.932Z",
          "hidden": false
        },
        {
          "_id": "68353258d005e45149d2d385",
          "user": {
            "_id": "653b8c3e97a4d71d950e2f20",
            "avatarUrl": "/avatars/b68880022e14556d0be58c69615db3be.svg",
            "isPro": false,
            "fullname": "Zichen Wen",
            "user": "zichenwen",
            "type": "user"
          },
          "name": "Zichen Wen",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T07:50:45.710Z",
          "hidden": false
        },
        {
          "_id": "68353258d005e45149d2d386",
          "user": {
            "_id": "66968099c952e09a4cb29f78",
            "avatarUrl": "/avatars/bd3a361fe5315e26e9ae328071704eed.svg",
            "isPro": false,
            "fullname": "Wang",
            "user": "Steven-Shaobo",
            "type": "user"
          },
          "name": "Shaobo Wang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T07:50:41.853Z",
          "hidden": false
        },
        {
          "_id": "68353258d005e45149d2d387",
          "user": {
            "_id": "652f8642338c761caf474169",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/mq5jjqqNaFxVboWGDEocJ.jpeg",
            "isPro": false,
            "fullname": "Junjie Chen",
            "user": "coderchen01",
            "type": "user"
          },
          "name": "Junjie Chen",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T07:50:48.148Z",
          "hidden": false
        },
        {
          "_id": "68353258d005e45149d2d388",
          "user": {
            "_id": "679f280ffb07d74f084520b6",
            "avatarUrl": "/avatars/b378000f68c7faf8d4fee8074dd2db5b.svg",
            "isPro": false,
            "fullname": "Zhishan Tao",
            "user": "Pppeach33",
            "type": "user"
          },
          "name": "Zhishan Tao",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T07:50:43.758Z",
          "hidden": false
        },
        {
          "_id": "68353258d005e45149d2d389",
          "name": "Yubo Wang",
          "hidden": false
        },
        {
          "_id": "68353258d005e45149d2d38a",
          "user": {
            "_id": "64abcbfde144ba0eb9bb8419",
            "avatarUrl": "/avatars/6ccea0e755bad384aaabd5c455bd962e.svg",
            "isPro": false,
            "fullname": "Xiangqi Jin",
            "user": "Lueci4er",
            "type": "user"
          },
          "name": "Xiangqi Jin",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-05-27T08:21:21.961Z",
          "hidden": false
        },
        {
          "_id": "68353258d005e45149d2d38b",
          "name": "Chang Zou",
          "hidden": false
        },
        {
          "_id": "68353258d005e45149d2d38c",
          "name": "Yiyu Wang",
          "hidden": false
        },
        {
          "_id": "68353258d005e45149d2d38d",
          "name": "Chenfei Liao",
          "hidden": false
        },
        {
          "_id": "68353258d005e45149d2d38e",
          "name": "Xu Zheng",
          "hidden": false
        },
        {
          "_id": "68353258d005e45149d2d38f",
          "name": "Honggang Chen",
          "hidden": false
        },
        {
          "_id": "68353258d005e45149d2d390",
          "name": "Weijia Li",
          "hidden": false
        },
        {
          "_id": "68353258d005e45149d2d391",
          "name": "Xuming Hu",
          "hidden": false
        },
        {
          "_id": "68353258d005e45149d2d392",
          "user": {
            "_id": "63f9fca8d4349b157a109eec",
            "avatarUrl": "/avatars/fa1f2ae7972d7cde99dab178136ccbb0.svg",
            "isPro": false,
            "fullname": "Conghui He",
            "user": "conghui",
            "type": "user"
          },
          "name": "Conghui He",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-05-27T08:22:15.329Z",
          "hidden": false
        },
        {
          "_id": "68353258d005e45149d2d393",
          "user": {
            "_id": "642ec9831d1737803dc1c30a",
            "avatarUrl": "/avatars/c9ded838bad09004c15a27200e66a108.svg",
            "isPro": false,
            "fullname": "linfeng zhang",
            "user": "linfengZ",
            "type": "user"
          },
          "name": "Linfeng Zhang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-05-27T08:22:07.787Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-25T13:51:17.000Z",
      "submittedOnDailyAt": "2025-05-27T02:06:05.849Z",
      "title": "Nous changeons l'efficacité de l'IA d'un approche axée sur les modèles vers une approche axée sur les données, en effectuant une compression.",
      "submittedOnDailyBy": {
        "_id": "653b8c3e97a4d71d950e2f20",
        "avatarUrl": "/avatars/b68880022e14556d0be58c69615db3be.svg",
        "isPro": false,
        "fullname": "Zichen Wen",
        "user": "zichenwen",
        "type": "user"
      },
      "summary": "Le développement rapide des modèles de langage grands (LLMs) et des modèles de langage grands multimodal (MLLMs) a été initié par un augmentation des paramètres due à l'échelle modèle-centrée, ce qui a conduit à un croissance du nombre de paramètres à l'échelle des centaines de milliards, entraînant des améliorations du rendement. Cependant, avec l'augmentation du taille du modèle, les limites de l'hardware s'approchent, et le principal tampon de calcul se transforme en une fonction de coût quadratique de l'attention automatique pour des contextes longs, ce qui empêche le traitement de textes longs, d'images de haute résolution et de vidéos continues de longue durée.\n\nDans cet article, nous soutenons que l'approche de l'efficacité de l'IA a changé de modèle-centrée à données-centrée, avec un approche de compression des tokens comme nouvelle ligne de recherche. Nous proposons que la réduction du nombre de tokens du modèle peut améliorer l'efficacité de l'IA. A travers un analyse détaillée, nous examinons le développement récent de l'intelligence artificielle dans plusieurs domaines, nous construisons un cadre mathématique intégral pour l'optimisation des modèles existants, et nous montrons comment la compression des tokens représente une transition paradigmatique pour résoudre le problème de surcharge de contexte long.\n\nEnsuite, nous étudions la situation actuelle de la compression des tokens, nous analysons ses avantages fondamentaux et ses avantages uniques dans différents scénarios. De plus, nous offrons un profond analyse des problèmes actuels dans la recherche de compression des tokens et nous décrivons les directions prometteuses du futur. Enfin, notre travail fournit une nouvelle perspective sur l'efficacité de l'IA, synthétise la recherche existante et promeut le développement innovant qui attaque les problèmes de contexte long, favorisant le développement de la communauté de l'IA.",
      "upvotes": 75,
      "discussionId": "68353259d005e45149d2d3c0",
      "projectPage": "https://github.com/xuyang-liu16/Awesome-Token-level-Model-Compression",
      "githubRepo": "https://github.com/xuyang-liu16/Awesome-Token-level-Model-Compression",
      "ai_summary": "The focus in AI research is shifting from model-centric to data-centric compression, with token compression identified as key to improving efficiency in handling long-context scenarios.",
      "ai_keywords": [
        "large language models",
        "multi-modal LLMs",
        "self-attention",
        "token compression",
        "long-context AI",
        "mathematical framework",
        "model efficiency",
        "long-context overhead",
        "current challenges",
        "future directions"
      ]
    },
    "publishedAt": "2025-05-25T09:51:17.000Z",
    "title": "Shifting AI Efficiency From Model-Centric to Data-Centric Compression",
    "summary": "The rapid advancement of large language models (LLMs) and multi-modal LLMs\n(MLLMs) has historically relied on model-centric scaling through increasing\nparameter counts from millions to hundreds of billions to drive performance\ngains. However, as we approach hardware limits on model size, the dominant\ncomputational bottleneck has fundamentally shifted to the quadratic cost of\nself-attention over long token sequences, now driven by ultra-long text\ncontexts, high-resolution images, and extended videos. In this position paper,\nwe argue that the focus of research for efficient AI is shifting from\nmodel-centric compression to data-centric compression. We position token\ncompression as the new frontier, which improves AI efficiency via reducing the\nnumber of tokens during model training or inference. Through comprehensive\nanalysis, we first examine recent developments in long-context AI across\nvarious domains and establish a unified mathematical framework for existing\nmodel efficiency strategies, demonstrating why token compression represents a\ncrucial paradigm shift in addressing long-context overhead. Subsequently, we\nsystematically review the research landscape of token compression, analyzing\nits fundamental benefits and identifying its compelling advantages across\ndiverse scenarios. Furthermore, we provide an in-depth analysis of current\nchallenges in token compression research and outline promising future\ndirections. Ultimately, our work aims to offer a fresh perspective on AI\nefficiency, synthesize existing research, and catalyze innovative developments\nto address the challenges that increasing context lengths pose to the AI\ncommunity's advancement.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.19147.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "653b8c3e97a4d71d950e2f20",
      "avatarUrl": "/avatars/b68880022e14556d0be58c69615db3be.svg",
      "fullname": "Zichen Wen",
      "name": "zichenwen",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 3
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.19457",
      "authors": [
        {
          "_id": "683536ec70d215849adfc236",
          "user": {
            "_id": "6440f70f1a80f6d83cadfd16",
            "avatarUrl": "/avatars/04790922837dac81747e80bd0ee0a1cf.svg",
            "isPro": false,
            "fullname": "luguilong",
            "user": "guilong",
            "type": "user"
          },
          "name": "Guilong Lu",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-05-27T08:23:29.797Z",
          "hidden": false
        },
        {
          "_id": "683536ec70d215849adfc237",
          "user": {
            "_id": "672b138db4215fd3888e0a8f",
            "avatarUrl": "/avatars/e90fe671a1db66401db88429fae9a763.svg",
            "isPro": false,
            "fullname": "guo",
            "user": "xuntao",
            "type": "user"
          },
          "name": "Xuntao Guo",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-05-27T08:23:39.616Z",
          "hidden": false
        },
        {
          "_id": "683536ec70d215849adfc238",
          "user": {
            "_id": "6555df426947208b7741b637",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6555df426947208b7741b637/b7ply-HyaPKXrPvRNh21K.jpeg",
            "isPro": false,
            "fullname": "Rongjunchen Zhang",
            "user": "Tinker250",
            "type": "user"
          },
          "name": "Rongjunchen Zhang",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-05-27T03:52:17.018Z",
          "hidden": false
        },
        {
          "_id": "683536ec70d215849adfc239",
          "user": {
            "_id": "648add6aff6123185eb185a8",
            "avatarUrl": "/avatars/e37dfa680c1bb86c721165f03eb79e97.svg",
            "isPro": false,
            "fullname": "WNQzhu",
            "user": "Qlisp",
            "type": "user"
          },
          "name": "Wenqiao Zhu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T07:49:28.216Z",
          "hidden": false
        },
        {
          "_id": "683536ec70d215849adfc23a",
          "name": "Ji Liu",
          "hidden": false
        }
      ],
      "mediaUrls": [
        "https://cdn-uploads.huggingface.co/production/uploads/6555df426947208b7741b637/48jI0LlYjRwO4-0kHRV0V.png",
        "https://cdn-uploads.huggingface.co/production/uploads/6555df426947208b7741b637/atuM30TNh72kJtm8zGxoc.png"
      ],
      "publishedAt": "2025-05-26T03:23:02.000Z",
      "submittedOnDailyAt": "2025-05-27T02:28:08.336Z",
      "title": "BizFinBench : Indicateur de performance financière de la réalité entrepriselle pour évaluer les LLM\n\n注意 : Bien que le texte initial ne mentionne pas d'addition de texte supplémentaire, j'ai ajouté cette partie pour préciser la nature de la traduction.",
      "submittedOnDailyBy": {
        "_id": "6555df426947208b7741b637",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6555df426947208b7741b637/b7ply-HyaPKXrPvRNh21K.jpeg",
        "isPro": false,
        "fullname": "Rongjunchen Zhang",
        "user": "Tinker250",
        "type": "user"
      },
      "summary": "Les modèles de langage généraux montrent un excellent rendement sur des tâches courantes, mais leur évaluation en termes de logique et de précision est très complexe. Pour aborder ce problème, nous présentons BizFinBench, le premier cadre de référence pour évaluer les modèles de langage pour des applications financières réelles dans le monde. BizFinBench comprend 5 dimensions : calcul numérique, raisonnement, extraction d'information, reconnaissance de prédictions et de réponses basées sur des connaissances, et est composé de 6,781 questions bien expliquées, classées dans 9 catégories détaillées. Le cadre de référence intègre des métriques subjectives et objectives, et présente IteraJudge, un nouveau méthode d'évaluation de modèles de langage qui réduit les biais dans l'évaluation en utilisant des métriques objectives. 25 modèles ont été évalués, y compris des modèles de paiement et des systèmes source ouverte. Les expériences larges ont démontré une excellence dans tous les aspects. L'évaluation a révélé des patrons clairs : en calcul numérique, Claude-3.5-Sonnet (63.18) et DeepSeek-R1 (64.04) sont les meilleurs, tandis que Qwen2.5-VL-3B (15.92) est significativement affecté. En raisonnement, les modèles de paiement sont supérieurs (ChatGPT-o3 : 83.58, Gemini-2.0-Flash : 81.15) aux source ouvertes (environ 19.49). En extraction d'information, le rendement varie plus, avec DeepSeek-R1 (71.46) et Qwen3-1.7B (11.23). En reconnaissance de prédictions, la variation était la plus faible, avec le meilleur modèle entre 39.16 et 50.00. Actuellement, les modèles de langage général peuvent gérer adéquatement des questions financières générales, mais dans les cas qui nécessitent un raisonnement complexe basé sur des schémas et des concepts critiques, ils rencontrent des difficultés. BizFinBench offre un cadre de référence strict et pertinent pour futures recherches. Les codes et datasets sont disponibles sur https://github.com/HiThink-Research/BizFinBench.",
      "upvotes": 45,
      "discussionId": "683536f170d215849adfc35e",
      "projectPage": "https://hithink-research.github.io/BizFinBench/",
      "githubRepo": "https://github.com/HiThink-Research/BizFinBench",
      "ai_summary": "BizFinBench is a benchmark for evaluating large language models in financial applications, revealing distinct performance patterns across various tasks.",
      "ai_keywords": [
        "large language models",
        "BizFinBench",
        "numerical calculation",
        "reasoning",
        "information extraction",
        "prediction recognition",
        "knowledge-based question answering",
        "IteraJudge",
        "Claude-3.5-Sonnet",
        "DeepSeek-R1",
        "Qwen2.5-VL-3B",
        "ChatGPT-o3",
        "Gemini-2.0-Flash",
        "Qwen3-1.7B"
      ]
    },
    "publishedAt": "2025-05-25T23:23:02.000Z",
    "title": "BizFinBench: A Business-Driven Real-World Financial Benchmark for\n  Evaluating LLMs",
    "summary": "Large language models excel in general tasks, yet assessing their reliability\nin logic-heavy, precision-critical domains like finance, law, and healthcare\nremains challenging. To address this, we introduce BizFinBench, the first\nbenchmark specifically designed to evaluate LLMs in real-world financial\napplications. BizFinBench consists of 6,781 well-annotated queries in Chinese,\nspanning five dimensions: numerical calculation, reasoning, information\nextraction, prediction recognition, and knowledge-based question answering,\ngrouped into nine fine-grained categories. The benchmark includes both\nobjective and subjective metrics. We also introduce IteraJudge, a novel LLM\nevaluation method that reduces bias when LLMs serve as evaluators in objective\nmetrics. We benchmark 25 models, including both proprietary and open-source\nsystems. Extensive experiments show that no model dominates across all tasks.\nOur evaluation reveals distinct capability patterns: (1) In Numerical\nCalculation, Claude-3.5-Sonnet (63.18) and DeepSeek-R1 (64.04) lead, while\nsmaller models like Qwen2.5-VL-3B (15.92) lag significantly; (2) In Reasoning,\nproprietary models dominate (ChatGPT-o3: 83.58, Gemini-2.0-Flash: 81.15), with\nopen-source models trailing by up to 19.49 points; (3) In Information\nExtraction, the performance spread is the largest, with DeepSeek-R1 scoring\n71.46, while Qwen3-1.7B scores 11.23; (4) In Prediction Recognition,\nperformance variance is minimal, with top models scoring between 39.16 and\n50.00. We find that while current LLMs handle routine finance queries\ncompetently, they struggle with complex scenarios requiring cross-concept\nreasoning. BizFinBench offers a rigorous, business-aligned benchmark for future\nresearch. The code and dataset are available at\nhttps://github.com/HiThink-Research/BizFinBench.",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/6555df426947208b7741b637/48jI0LlYjRwO4-0kHRV0V.png",
      "https://cdn-uploads.huggingface.co/production/uploads/6555df426947208b7741b637/atuM30TNh72kJtm8zGxoc.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.19457.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6555df426947208b7741b637",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6555df426947208b7741b637/b7ply-HyaPKXrPvRNh21K.jpeg",
      "fullname": "Rongjunchen Zhang",
      "name": "Tinker250",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.17894",
      "authors": [
        {
          "_id": "683577db7733c0f27e945847",
          "user": {
            "_id": "65276c7911a8a521c91bc10f",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65276c7911a8a521c91bc10f/39dbuUtqQTJERTJ_WkxSh.jpeg",
            "isPro": false,
            "fullname": "Khalil Hennara",
            "user": "Hennara",
            "type": "user"
          },
          "name": "Khalil Hennara",
          "status": "extracted_confirmed",
          "statusLastChangedAt": "2025-05-27T09:23:49.563Z",
          "hidden": false
        },
        {
          "_id": "683577db7733c0f27e945848",
          "user": {
            "_id": "6496df4b3c64d75523a11973",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6496df4b3c64d75523a11973/I_Qn5-3Czngle-NsGmabO.jpeg",
            "isPro": false,
            "fullname": "Muhammad Hreden",
            "user": "hr99",
            "type": "user"
          },
          "name": "Muhammad Hreden",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T10:03:33.725Z",
          "hidden": false
        },
        {
          "_id": "683577db7733c0f27e945849",
          "user": {
            "_id": "63aa7667769a10efc404fbbc",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63aa7667769a10efc404fbbc/tn8ZxUmTEMS0Gze7_F7JL.jpeg",
            "isPro": false,
            "fullname": "Mohamed Motasim Hamed",
            "user": "Moatasem444",
            "type": "user"
          },
          "name": "Mohamed Motaism Hamed",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-05-27T08:29:16.168Z",
          "hidden": false
        },
        {
          "_id": "683577db7733c0f27e94584a",
          "user": {
            "_id": "65704741e1cfce1764ce652e",
            "avatarUrl": "/avatars/9189aaf417426af4ebe381ed364a6c0e.svg",
            "isPro": false,
            "fullname": "Zeina Aldallal",
            "user": "ZeinaD",
            "type": "user"
          },
          "name": "Zeina Aldallal",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-05-27T08:29:16.168Z",
          "hidden": false
        },
        {
          "_id": "683577db7733c0f27e94584b",
          "name": "Sara Chrouf",
          "hidden": false
        },
        {
          "_id": "683577db7733c0f27e94584c",
          "name": "Safwan AlModhayan",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-23T13:42:21.000Z",
      "submittedOnDailyAt": "2025-05-27T07:07:04.517Z",
      "title": "Avancement de la traduction bidirectionnelle arabe-anglaise à l'aide de modèles de langue à petite échelle",
      "submittedOnDailyBy": {
        "_id": "65276c7911a8a521c91bc10f",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65276c7911a8a521c91bc10f/39dbuUtqQTJERTJ_WkxSh.jpeg",
        "isPro": false,
        "fullname": "Khalil Hennara",
        "user": "Hennara",
        "type": "user"
      },
      "summary": "Dans le modèle universel, Mutarjim est présenté comme un petit mais puissant modèle de langue bidirectionnelle arabe-anglais. Les grands modèles de LLM ont démontré une évolution impressionnante dans les tâches de traitement du langage, notamment en traduction automatique, mais il existe également des modèles plus petits. En utilisant ce guide, Mutarjim a été développé en se basant sur un modèle de langue approprié pour l'arabe et l'anglais, appelé Kuwain-1.5B. Mutarjim dépasse les grands modèles dans les évaluations de performance établies, malgré son taille réduite. Ce résultat a été atteint grâce à un approche d'entraînement optimisée en deux étapes et à la sélection d'un corpus d'entraînement de haute qualité. Les résultats expérimentaux montrent que Mutarjim présente un rendement similaire à ceux des modèles 20 fois plus grands, réduisant significativement les coûts de calcul et les exigences d'entraînement. De plus, Tarjama-25 est présenté comme un nouveau benchmark conçu pour surmonter les limites actuelles des jeux de données de benchmark arabe-anglais. Ces limites comprennent un champ d'activité restreint, des questions courtes et une tendance vers l'anglais dans la source. Tarjama-25 comprend 5 000 pairs de questions révisées par des experts et offre une large extension de domaines d'activité et un cadre d'évaluation plus détaillé et équilibré. En particulier, Mutarjim atteint le meilleur rendement dans les tâches arabe-anglais dans Tarjama-25, dépassant les modèles comme GPT-4o mini et les modèles plus grands propriétaires. Tarjama-25 est publié pour soutenir futures recherches et le développement de systèmes de traduction arabe-anglais.",
      "upvotes": 38,
      "discussionId": "683577dc7733c0f27e94588d",
      "ai_summary": "Mutarjim is a compact Arabic-English translation model that outperforms larger models on established benchmarks and achieves state-of-the-art performance on a new comprehensive Tarjama-25 benchmark.",
      "ai_keywords": [
        "language model",
        "bidirectional Arabic-English translation",
        "LLMs",
        "Kuwain-1.5B",
        "two-phase training",
        "high-quality training corpus",
        "Tarjama-25",
        "domain narrowness",
        "English-source bias",
        "GPT-4"
      ]
    },
    "publishedAt": "2025-05-23T09:42:21.000Z",
    "title": "Mutarjim: Advancing Bidirectional Arabic-English Translation with a\n  Small Language Model",
    "summary": "We introduce Mutarjim, a compact yet powerful language model for\nbidirectional Arabic-English translation. While large-scale LLMs have shown\nimpressive progress in natural language processing tasks, including machine\ntranslation, smaller models. Leveraging this insight, we developed Mutarjim\nbased on Kuwain-1.5B , a language model tailored for both Arabic and English.\nDespite its modest size, Mutarjim outperforms much larger models on several\nestablished benchmarks, achieved through an optimized two-phase training\napproach and a carefully curated, high-quality training corpus.. Experimental\nresults show that Mutarjim rivals models up to 20 times larger while\nsignificantly reducing computational costs and training requirements. We also\nintroduce Tarjama-25, a new benchmark designed to overcome limitations in\nexisting Arabic-English benchmarking datasets, such as domain narrowness, short\nsentence lengths, and English-source bias. Tarjama-25 comprises 5,000\nexpert-reviewed sentence pairs and spans a wide range of domains, offering a\nmore comprehensive and balanced evaluation framework. Notably, Mutarjim\nachieves state-of-the-art performance on the English-to-Arabic task in\nTarjama-25, surpassing even significantly larger and proprietary models like\nGPT-4o mini. We publicly release Tarjama-25 to support future research and\nadvance the evaluation of Arabic-English translation systems.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.17894.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "65276c7911a8a521c91bc10f",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65276c7911a8a521c91bc10f/39dbuUtqQTJERTJ_WkxSh.jpeg",
      "fullname": "Khalil Hennara",
      "name": "Hennara",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 12
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.16348",
      "authors": [
        {
          "_id": "6835365d2925bc8bb23a57c7",
          "user": {
            "_id": "636b529ef796304dd67d139c",
            "avatarUrl": "/avatars/7a64d5095fcb1da558b52ad48177ad76.svg",
            "isPro": false,
            "fullname": "Taeyoon Kwon",
            "user": "Connoriginal",
            "type": "user"
          },
          "name": "Taeyoon Kwon",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T07:50:26.210Z",
          "hidden": false
        },
        {
          "_id": "6835365d2925bc8bb23a57c8",
          "name": "Dongwook Choi",
          "hidden": false
        },
        {
          "_id": "6835365d2925bc8bb23a57c9",
          "name": "Sunghwan Kim",
          "hidden": false
        },
        {
          "_id": "6835365d2925bc8bb23a57ca",
          "name": "Hyojun Kim",
          "hidden": false
        },
        {
          "_id": "6835365d2925bc8bb23a57cb",
          "user": {
            "_id": "6420f4f55bccaa42484496e5",
            "avatarUrl": "/avatars/4996ba26955f8423c946b1ecd3989964.svg",
            "isPro": false,
            "fullname": "Seung Jun Moon",
            "user": "Lune-Blue",
            "type": "user"
          },
          "name": "Seungjun Moon",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-05-27T08:24:40.306Z",
          "hidden": false
        },
        {
          "_id": "6835365d2925bc8bb23a57cc",
          "user": {
            "_id": "64b72a408ba7d6c922c73054",
            "avatarUrl": "/avatars/6d9797430bc36f05fb950b84aa6a9374.svg",
            "isPro": false,
            "fullname": "Beong Woo Kwak",
            "user": "bwookwak",
            "type": "user"
          },
          "name": "Beong-woo Kwak",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-05-27T08:24:46.911Z",
          "hidden": false
        },
        {
          "_id": "6835365d2925bc8bb23a57cd",
          "user": {
            "_id": "658a57b4126b8d7eae07b983",
            "avatarUrl": "/avatars/8d908cb3da697793564d24206a333782.svg",
            "isPro": false,
            "fullname": "Kuan-Hao Huang",
            "user": "ej0cl6",
            "type": "user"
          },
          "name": "Kuan-Hao Huang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-05-27T08:24:53.502Z",
          "hidden": false
        },
        {
          "_id": "6835365d2925bc8bb23a57ce",
          "user": {
            "_id": "682e91865fa8c5df85b3d8e5",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/XWTfZoOjCdMnqaFEBBYWe.png",
            "isPro": false,
            "fullname": "Jinyoung Yeo",
            "user": "jinyeo",
            "type": "user"
          },
          "name": "Jinyoung Yeo",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-05-27T08:25:01.610Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-22T08:00:10.000Z",
      "submittedOnDailyAt": "2025-05-27T02:20:10.067Z",
      "title": "Les Agents Embodied sont en train de réexaminer l'utilisation de la mémoire pour offrir une assistance personnalisée.",
      "submittedOnDailyBy": {
        "_id": "636b529ef796304dd67d139c",
        "avatarUrl": "/avatars/7a64d5095fcb1da558b52ad48177ad76.svg",
        "isPro": false,
        "fullname": "Taeyoon Kwon",
        "user": "Connoriginal",
        "type": "user"
      },
      "summary": "Les modèles de langage général (LLMs) sont soutenus par des agents concrets qui montrent un excellent rendement dans des tâches de changement d'ordre de l'hypothèse. Cependant, ces tâches se concentrent principalement sur des commandes simples et une interaction, ce qui ne reflète pas adéquatement les problèmes auxquels les utilisateurs ont besoin d'aide significative. Pour fournir une aide personnalisée, les agents concrets doivent utiliser les enregistrements des interactions précédentes pour que les significations uniques que les utilisateurs fournissent soient compris dans le monde réel. Cependant, l'effet de l'utilisation de la mémoire pour fournir une aide personnalisée de manière efficace n'a pas encore été largement étudié. Pour compléter cela, nous présentons MEMENTO, un cadre d'évaluation d'agents concrets personnalisés. Ce cadre introduit un processus d'évaluation de la mémoire en deux étapes pour évaluer l'effet de l'utilisation de la mémoire. Ce processus met l'accent sur l'évaluation de la compréhension personnalisée dans des tâches de changement d'ordre, soulignant la capacité de : 1) spécifier des objets basés sur des significations personnelles et 2) inférer la position des objets à partir des motifs de l'utilisateur. Des expériences avec différents types de LLMs ont révélé des limitations significatives dans l'utilisation de la mémoire. En particulier, des modèles avancés comme GPT-4 expérimentent une perte de 30,5% de rendement lorsqu'il est nécessaire de se référer à plusieurs mémoires. Ces résultats et l'analyse détaillée, ainsi que des études de cas, fournissent des conseils précieux pour le développement d'agents concrets personnalisés dans des futures recherches. Site web du projet : https://connoriginal.github.io/MEMENTO",
      "upvotes": 38,
      "discussionId": "683536612925bc8bb23a58e1",
      "projectPage": "https://connoriginal.github.io/MEMENTO/",
      "githubRepo": "https://github.com/Connoriginal/MEMENTO",
      "ai_summary": "MEMENTO evaluates personalized memory utilization in embodied agents, revealing limitations in understanding user semantics and routines.",
      "ai_keywords": [
        "embodied agents",
        "large language models (LLMs)",
        "object rearrangement tasks",
        "user semantics",
        "prior interaction history",
        "memory utilization",
        "personalized assistance",
        "goal interpretation",
        "object semantics",
        "user patterns"
      ]
    },
    "publishedAt": "2025-05-22T04:00:10.000Z",
    "title": "Embodied Agents Meet Personalization: Exploring Memory Utilization for\n  Personalized Assistance",
    "summary": "Embodied agents empowered by large language models (LLMs) have shown strong\nperformance in household object rearrangement tasks. However, these tasks\nprimarily focus on single-turn interactions with simplified instructions, which\ndo not truly reflect the challenges of providing meaningful assistance to\nusers. To provide personalized assistance, embodied agents must understand the\nunique semantics that users assign to the physical world (e.g., favorite cup,\nbreakfast routine) by leveraging prior interaction history to interpret\ndynamic, real-world instructions. Yet, the effectiveness of embodied agents in\nutilizing memory for personalized assistance remains largely underexplored. To\naddress this gap, we present MEMENTO, a personalized embodied agent evaluation\nframework designed to comprehensively assess memory utilization capabilities to\nprovide personalized assistance. Our framework consists of a two-stage memory\nevaluation process design that enables quantifying the impact of memory\nutilization on task performance. This process enables the evaluation of agents'\nunderstanding of personalized knowledge in object rearrangement tasks by\nfocusing on its role in goal interpretation: (1) the ability to identify target\nobjects based on personal meaning (object semantics), and (2) the ability to\ninfer object-location configurations from consistent user patterns, such as\nroutines (user patterns). Our experiments across various LLMs reveal\nsignificant limitations in memory utilization, with even frontier models like\nGPT-4o experiencing a 30.5% performance drop when required to reference\nmultiple memories, particularly in tasks involving user patterns. These\nfindings, along with our detailed analyses and case studies, provide valuable\ninsights for future research in developing more effective personalized embodied\nagents. Project website: https://connoriginal.github.io/MEMENTO",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.16348.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "636b529ef796304dd67d139c",
      "avatarUrl": "/avatars/7a64d5095fcb1da558b52ad48177ad76.svg",
      "fullname": "Taeyoon Kwon",
      "name": "Connoriginal",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.20258",
      "authors": [
        {
          "_id": "68352b5803548b71276c1a6f",
          "user": {
            "_id": "64f2a228f40f35cfa3e8edfd",
            "avatarUrl": "/avatars/0671cb4df8f3d3bcaaa95aad3d0a46c2.svg",
            "isPro": false,
            "fullname": "Siye Wu",
            "user": "Siye01",
            "type": "user"
          },
          "name": "Siye Wu",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-05-27T08:25:16.627Z",
          "hidden": false
        },
        {
          "_id": "68352b5803548b71276c1a70",
          "user": {
            "_id": "62d65139667051e0a29bffe7",
            "avatarUrl": "/avatars/0252aa2bcd4cf1c8e4b87e5f164b6da5.svg",
            "isPro": false,
            "fullname": "Jian Xie",
            "user": "hsaest",
            "type": "user"
          },
          "name": "Jian Xie",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T07:50:53.006Z",
          "hidden": false
        },
        {
          "_id": "68352b5803548b71276c1a71",
          "user": {
            "_id": "63e8b792ca4fc7d30de6975b",
            "avatarUrl": "/avatars/57237f54d61d479df15209497a3f531e.svg",
            "isPro": false,
            "fullname": "Yikai Zhang",
            "user": "Arist12",
            "type": "user"
          },
          "name": "Yikai Zhang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-05-27T08:25:41.797Z",
          "hidden": false
        },
        {
          "_id": "68352b5803548b71276c1a72",
          "name": "Aili Chen",
          "hidden": false
        },
        {
          "_id": "68352b5803548b71276c1a73",
          "name": "Kai Zhang",
          "hidden": false
        },
        {
          "_id": "68352b5803548b71276c1a74",
          "name": "Yu Su",
          "hidden": false
        },
        {
          "_id": "68352b5803548b71276c1a75",
          "name": "Yanghua Xiao",
          "hidden": false
        }
      ],
      "mediaUrls": [
        "https://cdn-uploads.huggingface.co/production/uploads/62d65139667051e0a29bffe7/W2uaapL3hKBPi-TA-KDef.mp4"
      ],
      "publishedAt": "2025-05-26T17:38:50.000Z",
      "submittedOnDailyAt": "2025-05-27T01:44:27.885Z",
      "title": "ARM: ARM (Module Neuronal de Reseau)",
      "submittedOnDailyBy": {
        "_id": "62d65139667051e0a29bffe7",
        "avatarUrl": "/avatars/0252aa2bcd4cf1c8e4b87e5f164b6da5.svg",
        "isPro": false,
        "fullname": "Jian Xie",
        "user": "hsaest",
        "type": "user"
      },
      "summary": "Les modèles d'inférence à grande échelle montrent un excellent rendement dans des tâches complexes, mais leur capacité à ajuster l'utilisation des tokens de justification dépend de la difficulté de la tâche. Cela est lié au problème de \"surabondance d'explications\" — explications inutiles — qui, bien que les humains puissent contrôler l'effacement de tokens, se trouve fondamentalement en désaccord avec les objectifs d'une information complètement automatique. Dans cet article, nous proposons un modèle de raisonnement adaptatif (Adaptive Reasoning Model, ARM). L'ARM peut sélectionner des formes de justification appropriées de manière progressive. Ces formes comprennent Direct Answer, Short CoT, Code, entre autres trois formes efficaces, et Long CoT, qui fournit une explication plus détaillée. Pour l'entraînement de l'ARM, nous introduisons une version adaptative du Policy Optimization de Groupe Relatif (Group Relative Policy Optimization, GRPO), appelée Ada-GRPO. Cette solution aborde les problèmes de destruction de la structure dans la GRPO traditionnelle. Grâce à Ada-GRPO, l'ARM peut réduire l'utilisation de tokens d'un moyen de 30%, réduisant cette utilisation de 70% par rapport aux modèles Long CoT, tout en maintenant son rendement. De plus, la réduction de la génération de tokens améliore l'efficacité de l'inférence et peut augmenter la vitesse d'entraînement de deux fois. En plus du mode adaptatif de base, l'ARM offre deux modes de justification supplémentaires : 1) Mode guide d'instructions, où l'utilisateur peut spécifier explicitement la forme de justification en utilisant des tokens spéciaux, ce qui est idéal pour des formes de justification connues pour des tâches de charge de travail. 2) Mode guide de consensus, qui intègre les résultats de 3 formes efficaces et utilise Long CoT lorsque des différences apparaissent, prioritisant l'utilisation de tokens dans les cas d'utilisation élevée.",
      "upvotes": 32,
      "discussionId": "68352b5903548b71276c1a9f",
      "projectPage": "https://team-arm.github.io/arm/",
      "githubRepo": "https://github.com/TEAM-ARM/arm",
      "ai_summary": "Adaptive Reasoning Model (ARM) uses Ada-GRPO to reduce token usage and improve efficiency across different reasoning modes.",
      "ai_keywords": [
        "Adaptive Reasoning Model",
        "ARM",
        "Ada-GRPO",
        "Group Relative Policy Optimization",
        "GRPO",
        "format collapse",
        "token efficiency",
        "inference efficiency",
        "Direct Answer",
        "Short CoT",
        "Code",
        "Long CoT",
        "Adaptive Mode",
        "Instruction-Guided Mode",
        "Consensus-Guided Mode"
      ]
    },
    "publishedAt": "2025-05-26T13:38:50.000Z",
    "title": "ARM: Adaptive Reasoning Model",
    "summary": "While large reasoning models demonstrate strong performance on complex tasks,\nthey lack the ability to adjust reasoning token usage based on task difficulty.\nThis often leads to the \"overthinking\" problem -- excessive and unnecessary\nreasoning -- which, although potentially mitigated by human intervention to\ncontrol the token budget, still fundamentally contradicts the goal of achieving\nfully autonomous AI. In this work, we propose Adaptive Reasoning Model (ARM), a\nreasoning model capable of adaptively selecting appropriate reasoning formats\nbased on the task at hand. These formats include three efficient ones -- Direct\nAnswer, Short CoT, and Code -- as well as a more elaborate format, Long CoT. To\ntrain ARM, we introduce Ada-GRPO, an adaptation of Group Relative Policy\nOptimization (GRPO), which addresses the format collapse issue in traditional\nGRPO. Ada-GRPO enables ARM to achieve high token efficiency, reducing tokens by\nan average of 30%, and up to 70%, while maintaining performance comparable to\nthe model that relies solely on Long CoT. Furthermore, not only does it improve\ninference efficiency through reduced token generation, but it also brings a 2x\nspeedup in training. In addition to the default Adaptive Mode, ARM supports two\nadditional reasoning modes: 1) Instruction-Guided Mode, which allows users to\nexplicitly specify the reasoning format via special tokens -- ideal when the\nappropriate format is known for a batch of tasks. 2) Consensus-Guided Mode,\nwhich aggregates the outputs of the three efficient formats and resorts to Long\nCoT in case of disagreement, prioritizing performance with higher token usage.",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/62d65139667051e0a29bffe7/W2uaapL3hKBPi-TA-KDef.mp4"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.20258.png",
    "numComments": 3,
    "submittedBy": {
      "_id": "62d65139667051e0a29bffe7",
      "avatarUrl": "/avatars/0252aa2bcd4cf1c8e4b87e5f164b6da5.svg",
      "fullname": "Jian Xie",
      "name": "hsaest",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 9
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.19914",
      "authors": [
        {
          "_id": "68353e41f995630ab88c198b",
          "user": {
            "_id": "606ed1884ffe81d1e03e81e5",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1639375346654-606ed1884ffe81d1e03e81e5.png",
            "isPro": false,
            "fullname": "Jiangjie Chen",
            "user": "jiangjiechen",
            "type": "user"
          },
          "name": "Jiangjie Chen",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T07:49:21.006Z",
          "hidden": false
        },
        {
          "_id": "68353e41f995630ab88c198c",
          "user": {
            "_id": "636b36351340f879a2ec2bb1",
            "avatarUrl": "/avatars/260a1c15f9c14c967125469072020946.svg",
            "isPro": false,
            "fullname": "QianyuHe",
            "user": "Abbey4799",
            "type": "user"
          },
          "name": "Qianyu He",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T07:49:23.290Z",
          "hidden": false
        },
        {
          "_id": "68353e41f995630ab88c198d",
          "name": "Siyu Yuan",
          "hidden": false
        },
        {
          "_id": "68353e41f995630ab88c198e",
          "name": "Aili Chen",
          "hidden": false
        },
        {
          "_id": "68353e41f995630ab88c198f",
          "name": "Zhicheng Cai",
          "hidden": false
        },
        {
          "_id": "68353e41f995630ab88c1990",
          "name": "Weinan Dai",
          "hidden": false
        },
        {
          "_id": "68353e41f995630ab88c1991",
          "name": "Hongli Yu",
          "hidden": false
        },
        {
          "_id": "68353e41f995630ab88c1992",
          "name": "Qiying Yu",
          "hidden": false
        },
        {
          "_id": "68353e41f995630ab88c1993",
          "name": "Xuefeng Li",
          "hidden": false
        },
        {
          "_id": "68353e41f995630ab88c1994",
          "name": "Jiaze Chen",
          "hidden": false
        },
        {
          "_id": "68353e41f995630ab88c1995",
          "name": "Hao Zhou",
          "hidden": false
        },
        {
          "_id": "68353e41f995630ab88c1996",
          "name": "Mingxuan Wang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-26T12:40:31.000Z",
      "submittedOnDailyAt": "2025-05-27T02:57:13.989Z",
      "title": "Anigmata : Un puzzle complexe pour l'expansion de l'inférence logique dans des modèles de langage à grande échelle",
      "submittedOnDailyBy": {
        "_id": "62d62b333bf5e059f7d2b286",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1668513815771-62d62b333bf5e059f7d2b286.jpeg",
        "isPro": false,
        "fullname": "Siyu Yuan",
        "user": "siyuyuan",
        "type": "user"
      },
      "summary": "Les modèles de langage grand (LLMs) comme o1 de OpenAI et R1 de DeepSeek ont démontré des résultats exceptionnels dans des tâches logiques avancées, comme les mathématiques et la programmation, grâce à l'apprentissage par renforcement et à la compensation vérifiable (RLVR). Cependant, lorsqu'il s'agit de problèmes inconnus nécessitant des connaissances familières, les humains rencontrent des difficultés. Nous présentons ici une première série détaillée pour améliorer les tâches logiques dans des problèmes inconnus. Cette collection comprend 36 tâches réparties sur 7 catégories, avec des exemples infinitésimaux structurés et des difficultés contrôlables, ainsi qu'un système d'évaluation automatique basé sur des règles. Ce design de générateur-évaluateur offre une scalabilité, un apprentissage par renforcement multi-tâche, un analysage détaillé et une intégration continue de RLVR. De plus, nous proposons un benchmark strict comme Enigmata-Eval et développons des RLVR stéréotypes optimisés. Notre modèle entraîné, Qwen2.5-32B-Enigmata, dépasse o3-mini-high et o1 sur le benchmark de problèmes logiques inconnus, et montre une performance constante sur ARC-AGI (32,8%) et ARC-AGI 2 (0,6%). De plus, nous observons une meilleure généralisation dans des problèmes inconnus de domaines autres et en logique mathématique. Pendant l'entraînement, l'utilisation de grands modèles comme Seed1.5-Thinking (20B paramètres actifs et 200B paramètres totaux) a démontré que les données d'enigmat-problèmes inconnus peuvent atteindre un niveau de rendement supérieur dans des tâches logiques avancées en mathématiques et STEM, comme AIME (2024-2025), BeyondAIME et GPQA (Diamante). Cette étude fournit un cadre contrôlable pour améliorer l'évolution des tâches logiques dans les LLMs. Les ressources de cette étude peuvent être trouvées sur https://seed-enigmata.github.io.",
      "upvotes": 26,
      "discussionId": "68353e42f995630ab88c19dc",
      "ai_summary": "Enigmata is a comprehensive suite for improving LLMs in puzzle reasoning through scalable multi-task RL training, leading to better performance on benchmarks and advanced math tasks.",
      "ai_keywords": [
        "Large Language Models",
        "OpenAI's o1",
        "DeepSeek's R1",
        "Reinforcement Learning with Verifiable Rewards",
        "Enigmata",
        "Enigmata-Eval",
        "multi-task RL training",
        "puzzle reasoning",
        "rule-based verifier",
        "ARC-AGI",
        "Qwen2.5-32B-Enigmata",
        "Seed1.5-Thinking",
        "AIME",
        "BeyondAIME",
        "GPQA"
      ]
    },
    "publishedAt": "2025-05-26T08:40:31.000Z",
    "title": "Enigmata: Scaling Logical Reasoning in Large Language Models with\n  Synthetic Verifiable Puzzles",
    "summary": "Large Language Models (LLMs), such as OpenAI's o1 and DeepSeek's R1, excel at\nadvanced reasoning tasks like math and coding via Reinforcement Learning with\nVerifiable Rewards (RLVR), but still struggle with puzzles solvable by humans\nwithout domain knowledge. We introduce Enigmata, the first comprehensive suite\ntailored for improving LLMs with puzzle reasoning skills. It includes 36 tasks\nacross seven categories, each with 1) a generator that produces unlimited\nexamples with controllable difficulty and 2) a rule-based verifier for\nautomatic evaluation. This generator-verifier design supports scalable,\nmulti-task RL training, fine-grained analysis, and seamless RLVR integration.\nWe further propose Enigmata-Eval, a rigorous benchmark, and develop optimized\nmulti-task RLVR strategies. Our trained model, Qwen2.5-32B-Enigmata,\nconsistently surpasses o3-mini-high and o1 on the puzzle reasoning benchmarks\nlike Enigmata-Eval, ARC-AGI (32.8%), and ARC-AGI 2 (0.6%). It also generalizes\nwell to out-of-domain puzzle benchmarks and mathematical reasoning, with little\nmulti-tasking trade-off. When trained on larger models like Seed1.5-Thinking\n(20B activated parameters and 200B total parameters), puzzle data from Enigmata\nfurther boosts SoTA performance on advanced math and STEM reasoning tasks such\nas AIME (2024-2025), BeyondAIME and GPQA (Diamond), showing nice generalization\nbenefits of Enigmata. This work offers a unified, controllable framework for\nadvancing logical reasoning in LLMs. Resources of this work can be found at\nhttps://seed-enigmata.github.io.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.19914.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "62d62b333bf5e059f7d2b286",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1668513815771-62d62b333bf5e059f7d2b286.jpeg",
      "fullname": "Siyu Yuan",
      "name": "siyuyuan",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 4
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2505.19297",
      "authors": [
        {
          "_id": "68354c05f7b44d5d505262c7",
          "user": {
            "_id": "63725a2eacef705233c62876",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63725a2eacef705233c62876/QlRm8oq7O8THzUhATYQlH.jpeg",
            "isPro": false,
            "fullname": "Valerii",
            "user": "sharfikeg",
            "type": "user"
          },
          "name": "Valerii Startsev",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T07:51:23.082Z",
          "hidden": false
        },
        {
          "_id": "68354c05f7b44d5d505262c8",
          "name": "Alexander Ustyuzhanin",
          "hidden": false
        },
        {
          "_id": "68354c05f7b44d5d505262c9",
          "name": "Alexey Kirillov",
          "hidden": false
        },
        {
          "_id": "68354c05f7b44d5d505262ca",
          "name": "Dmitry Baranchuk",
          "hidden": false
        },
        {
          "_id": "68354c05f7b44d5d505262cb",
          "name": "Sergey Kastryulin",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-25T20:08:20.000Z",
      "submittedOnDailyAt": "2025-05-27T07:55:09.983Z",
      "title": "Le Alchimiste : Créer un générateur d'or pour la génération d'images à partir de textes publics.",
      "submittedOnDailyBy": {
        "_id": "63725a2eacef705233c62876",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63725a2eacef705233c62876/QlRm8oq7O8THzUhATYQlH.jpeg",
        "isPro": false,
        "fullname": "Valerii",
        "user": "sharfikeg",
        "type": "user"
      },
      "summary": "L'apprentissage préalable transmet largement le savoir mondial du texte aux modèles d'image à partir du texte (T2I), mais cela n'est pas suffisant pour atteindre un haut niveau d'artistique et de cohérence. Par conséquent, la fine-tuning (SFT) est nécessaire pour améliorer progressivement, mais son efficacité dépend significativement de la qualité du jeu de données de fine-tuning. Les jeux de données publiques actuels se concentrent principalement sur des zones restreintes (par exemple, l'animation ou des styles artistiques spécifiques). La production de jeux de données de fine-tuning de haute qualité pour des usages généraux est un problème d'importance considérable. Les méthodes actuelles de caractérisation du rendement sont généralement coûteuses et difficiles à appliquer pour identifier des échantillons qui ont un impact réel. Ce problème se complique encore plus par la rareté des jeux de données publiques pour des usages généraux. Les modèles leaders dépendent principalement de données internes à grande échelle et de propriétés, ce qui empêche des avancées plus larges dans la recherche. Dans cet article, nous présentons un nouveau méthode pour la production de jeux de données de fine-tuning d'utilisation générale, en étendant les générateurs d'apprentissage préalable évalués comme évaluateurs pour identifier des échantillons de fort impact. Ce méthode s'appelle Alchemist (3,350 échantillons) et a été construit et publié de manière réduite. Les expérimentations montrent que Alchemist améliore significativement la qualité de la génération des modèles d'image à partir du texte à partir de cinq textes publics, en maintenant la diversité et l'esthétique. De plus, les jeux de poids des modèles de fine-tuning ont été publiés.",
      "upvotes": 26,
      "discussionId": "68354c07f7b44d5d50526322",
      "ai_summary": "A new method using a pre-trained generative model helps construct a high-impact SFT dataset, Alchemist, which improves the generative quality of text-to-image models while maintaining diversity.",
      "ai_keywords": [
        "text-to-image",
        "fine-tuning",
        "pre-trained generative model",
        "general-purpose datasets",
        "aesthetic quality",
        "alignment",
        "curated datasets"
      ]
    },
    "publishedAt": "2025-05-25T16:08:20.000Z",
    "title": "Alchemist: Turning Public Text-to-Image Data into Generative Gold",
    "summary": "Pre-training equips text-to-image (T2I) models with broad world knowledge,\nbut this alone is often insufficient to achieve high aesthetic quality and\nalignment. Consequently, supervised fine-tuning (SFT) is crucial for further\nrefinement. However, its effectiveness highly depends on the quality of the\nfine-tuning dataset. Existing public SFT datasets frequently target narrow\ndomains (e.g., anime or specific art styles), and the creation of high-quality,\ngeneral-purpose SFT datasets remains a significant challenge. Current curation\nmethods are often costly and struggle to identify truly impactful samples. This\nchallenge is further complicated by the scarcity of public general-purpose\ndatasets, as leading models often rely on large, proprietary, and poorly\ndocumented internal data, hindering broader research progress. This paper\nintroduces a novel methodology for creating general-purpose SFT datasets by\nleveraging a pre-trained generative model as an estimator of high-impact\ntraining samples. We apply this methodology to construct and release Alchemist,\na compact (3,350 samples) yet highly effective SFT dataset. Experiments\ndemonstrate that Alchemist substantially improves the generative quality of\nfive public T2I models while preserving diversity and style. Additionally, we\nrelease the fine-tuned models' weights to the public.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.19297.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "63725a2eacef705233c62876",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63725a2eacef705233c62876/QlRm8oq7O8THzUhATYQlH.jpeg",
      "fullname": "Valerii",
      "name": "sharfikeg",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.18545",
      "authors": [
        {
          "_id": "6835217ee759f596d018f72c",
          "user": {
            "_id": "6631fd5961a4305e5610d403",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6631fd5961a4305e5610d403/P1Dtxzn-KIbYDDsiw60nr.jpeg",
            "isPro": true,
            "fullname": "An Vo",
            "user": "anvo25",
            "type": "user"
          },
          "name": "An Vo",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T07:52:08.994Z",
          "hidden": false
        },
        {
          "_id": "6835217ee759f596d018f72d",
          "user": {
            "_id": "6039478ab3ecf716b1a5fd4d",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg",
            "isPro": true,
            "fullname": "taesiri",
            "user": "taesiri",
            "type": "user"
          },
          "name": "Mohammad Reza Taesiri",
          "status": "extracted_confirmed",
          "statusLastChangedAt": "2025-05-27T02:21:46.082Z",
          "hidden": false
        },
        {
          "_id": "6835217ee759f596d018f72e",
          "name": "Daeyoung Kim",
          "hidden": false
        },
        {
          "_id": "6835217ee759f596d018f72f",
          "user": {
            "_id": "60e85b3fcd1cf4e418fff651",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1645625108920-60e85b3fcd1cf4e418fff651.jpeg",
            "isPro": false,
            "fullname": "Anh (Totti) Nguyen",
            "user": "anhng8",
            "type": "user"
          },
          "name": "Anh Totti Nguyen",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-05-27T02:20:46.958Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-24T06:23:52.000Z",
      "submittedOnDailyAt": "2025-05-27T00:50:49.797Z",
      "title": "B-score : Utilisation de registres de réponses pour la détection de biais dans les langues similaires",
      "submittedOnDailyBy": {
        "_id": "6039478ab3ecf716b1a5fd4d",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg",
        "isPro": true,
        "fullname": "taesiri",
        "user": "taesiri",
        "type": "user"
      },
      "summary": "Les modèles de langage grand (LLMs) montrent de nombreux préjugés, comme concernant les femmes ou le nombre 7. Nous avons étudié si les LLMs peuvent réduire ces préjugés en examinant leurs réponses à la même question. Pour comprendre le type de question, nous avons élargi 9 thèmes et avons testé les LLMs avec 3 types de questions : subjectives, aléatoires et axées sur des objectifs. Intéressantment, nous avons constaté que les LLMs peuvent \"éliminer\" leurs préjugés lorsqu'ils sont questionnés avec des réponses aléatoires sans préjugis. De plus, nous proposons un nouveau métrique appelé B-score pour détecter efficacement les préjugés dans des questions subjectives, aléatoires, faciles et difficiles. En utilisant B-score dans MMLU, HLE et CSQA, la précision dans la vérification des réponses des LLMs a considérablement augmenté par rapport à la fréquence des réponses dans un seul tour ou aux scores de confiance linguistique. Les codes et les données sont disponibles sur https://b-score.github.io.",
      "upvotes": 23,
      "discussionId": "6835217ee759f596d018f794",
      "projectPage": "https://b-score.github.io/",
      "githubRepo": "https://github.com/anvo25/b-score",
      "ai_summary": "LLMs can reduce biases in multi-turn conversations for certain types of questions, and a novel B-score metric improves the accuracy of verifying LLM answers.",
      "ai_keywords": [
        "large language models",
        "biases",
        "multi-turn conversation",
        "B-score",
        "MMLU",
        "HLE",
        "CSQA",
        "verification accuracy",
        "verbalized confidence scores"
      ]
    },
    "publishedAt": "2025-05-24T02:23:52.000Z",
    "title": "B-score: Detecting biases in large language models using response\n  history",
    "summary": "Large language models (LLMs) often exhibit strong biases, e.g, against women\nor in favor of the number 7. We investigate whether LLMs would be able to\noutput less biased answers when allowed to observe their prior answers to the\nsame question in a multi-turn conversation. To understand which types of\nquestions invite more biased answers, we test LLMs on our proposed set of\nquestions that span 9 topics and belong to three types: (1) Subjective; (2)\nRandom; and (3) Objective. Interestingly, LLMs are able to \"de-bias\" themselves\nin a multi-turn conversation in response to questions that seek an Random,\nunbiased answer. Furthermore, we propose B-score, a novel metric that is\neffective in detecting biases to Subjective, Random, Easy, and Hard questions.\nOn MMLU, HLE, and CSQA, leveraging B-score substantially improves the\nverification accuracy of LLM answers (i.e, accepting LLM correct answers and\nrejecting incorrect ones) compared to using verbalized confidence scores or the\nfrequency of single-turn answers alone. Code and data are available at:\nhttps://b-score.github.io.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.18545.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6039478ab3ecf716b1a5fd4d",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg",
      "fullname": "taesiri",
      "name": "taesiri",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 84
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.19815",
      "authors": [
        {
          "_id": "683523b21a2911c0774a1dc5",
          "user": {
            "_id": "643d26979347842571bc9613",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/3heFf7h3jbhhJWJ4JfGfh.jpeg",
            "isPro": false,
            "fullname": "Junnan Liu",
            "user": "jnanliu",
            "type": "user"
          },
          "name": "Junnan Liu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T07:51:56.495Z",
          "hidden": false
        },
        {
          "_id": "683523b21a2911c0774a1dc6",
          "name": "Hongwei Liu",
          "hidden": false
        },
        {
          "_id": "683523b21a2911c0774a1dc7",
          "name": "Linchen Xiao",
          "hidden": false
        },
        {
          "_id": "683523b21a2911c0774a1dc8",
          "user": {
            "_id": "654ce87af0b05673196a9f45",
            "avatarUrl": "/avatars/7b9c854eb98e487e3057479b1c7860ac.svg",
            "isPro": false,
            "fullname": "Shudong Liu",
            "user": "Sudanl",
            "type": "user"
          },
          "name": "Shudong Liu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T08:15:12.824Z",
          "hidden": false
        },
        {
          "_id": "683523b21a2911c0774a1dc9",
          "name": "Taolin Zhang",
          "hidden": false
        },
        {
          "_id": "683523b21a2911c0774a1dca",
          "name": "Zihan Ma",
          "hidden": false
        },
        {
          "_id": "683523b21a2911c0774a1dcb",
          "user": {
            "_id": "630716d11801ecc7d2595021",
            "avatarUrl": "/avatars/2d36a880ce4a3cf7efc5ff3987dbeaf3.svg",
            "isPro": false,
            "fullname": "Songyang Zhang",
            "user": "zsytony",
            "type": "user"
          },
          "name": "Songyang Zhang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T07:51:54.358Z",
          "hidden": false
        },
        {
          "_id": "683523b21a2911c0774a1dcc",
          "name": "Kai Chen",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-26T10:52:17.000Z",
      "submittedOnDailyAt": "2025-05-27T01:00:26.595Z",
      "title": "Analyse de l'interprétation des modèles de langage profond (LLM) avec coopération dans les projets à partir de l'optimisation",
      "submittedOnDailyBy": {
        "_id": "630716d11801ecc7d2595021",
        "avatarUrl": "/avatars/2d36a880ce4a3cf7efc5ff3987dbeaf3.svg",
        "isPro": false,
        "fullname": "Songyang Zhang",
        "user": "zsytony",
        "type": "user"
      },
      "summary": "Nous proposons un nouveau cadre pour comprendre la capacité d'inférence des modèles de langage de grande échelle (LLM) à partir de la perspective de la méta-apprentissage. Nous considérons les paramètres d'un LLM sous une mise à jour de descente de gradients pseudo, identifiant ainsi la similitude entre l'inférence du modèle et différents paradigmes de méta-apprentissage. Nous formulons le processus d'entraînement de tâches d'inférence comme un environnement de méta-apprentissage, traitant chaque question comme une tâche individuelle et utilisant la tâche d'inférence comme optimisation de la boucle interne. Après avoir été entraînés sur différents ensembles de questions, un LLM peut généraliser sa capacité d'inférence pour des questions qui n'ont jamais été vues avant. Une large évaluation empirique démontre la forte connexion entre l'inférence d'un LLM et la méta-apprentissage, explorant plusieurs problèmes importants à partir de la perspective de la méta-apprentissage. Notre étude aide à comprendre l'inférence d'un LLM et offre une vision pratique de comment améliorer des modèles en utilisant des techniques de méta-apprentissage.",
      "upvotes": 22,
      "discussionId": "683523b41a2911c0774a1e78",
      "githubRepo": "https://github.com/open-compass/RaML",
      "ai_summary": "LLM reasoning is understood through a meta-learning framework, treating reasoning as pseudo-gradient descent and questions as individual tasks, which enhances generalization and provides practical insights for improvement.",
      "ai_keywords": [
        "large language models",
        "meta-learning",
        "pseudo-gradient descent",
        "inner loop optimization",
        "generalization",
        "fundamental reasoning capabilities"
      ]
    },
    "publishedAt": "2025-05-26T06:52:17.000Z",
    "title": "Deciphering Trajectory-Aided LLM Reasoning: An Optimization Perspective",
    "summary": "We propose a novel framework for comprehending the reasoning capabilities of\nlarge language models (LLMs) through the perspective of meta-learning. By\nconceptualizing reasoning trajectories as pseudo-gradient descent updates to\nthe LLM's parameters, we identify parallels between LLM reasoning and various\nmeta-learning paradigms. We formalize the training process for reasoning tasks\nas a meta-learning setup, with each question treated as an individual task, and\nreasoning trajectories serving as the inner loop optimization for adapting\nmodel parameters. Once trained on a diverse set of questions, the LLM develops\nfundamental reasoning capabilities that can generalize to previously unseen\nquestions. Extensive empirical evaluations substantiate the strong connection\nbetween LLM reasoning and meta-learning, exploring several issues of\nsignificant interest from a meta-learning standpoint. Our work not only\nenhances the understanding of LLM reasoning but also provides practical\ninsights for improving these models through established meta-learning\ntechniques.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.19815.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "630716d11801ecc7d2595021",
      "avatarUrl": "/avatars/2d36a880ce4a3cf7efc5ff3987dbeaf3.svg",
      "fullname": "Songyang Zhang",
      "name": "zsytony",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 17
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.19250",
      "authors": [
        {
          "_id": "68355ce06a9c239ada09f97b",
          "user": {
            "_id": "66e0404662d6ab4f1107580f",
            "avatarUrl": "/avatars/ef71694fea5482078a637a3869e30d19.svg",
            "isPro": false,
            "fullname": "Yi Wang",
            "user": "Yi53",
            "type": "user"
          },
          "name": "Yi Wang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T07:49:06.169Z",
          "hidden": false
        },
        {
          "_id": "68355ce06a9c239ada09f97c",
          "user": {
            "_id": "68356f5db243fb809813a715",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/68356f5db243fb809813a715/grhHvANfDRp75rMJxWlQo.jpeg",
            "isPro": false,
            "fullname": "LiuJunxiao",
            "user": "master-lan",
            "type": "user"
          },
          "name": "Junxiao Liu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T07:55:01.261Z",
          "hidden": false
        },
        {
          "_id": "68355ce06a9c239ada09f97d",
          "name": "Shimao Zhang",
          "hidden": false
        },
        {
          "_id": "68355ce06a9c239ada09f97e",
          "name": "Jiajun Chen",
          "hidden": false
        },
        {
          "_id": "68355ce06a9c239ada09f97f",
          "name": "Shujian Huang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-25T17:58:50.000Z",
      "submittedOnDailyAt": "2025-05-27T07:16:47.391Z",
      "title": "PATS: Processus niveau de pensée adaptatif de changement",
      "submittedOnDailyBy": {
        "_id": "66e0404662d6ab4f1107580f",
        "avatarUrl": "/avatars/ef71694fea5482078a637a3869e30d19.svg",
        "isPro": false,
        "fullname": "Yi Wang",
        "user": "Yi53",
        "type": "user"
      },
      "summary": "Actuellement, les grands modèles de langue (LLMs) appliquent une stratégie logique fixe à tous les problèmes, mais sa complexité ne dépend pas de la difficulté du problème. Omettre cette variabilité en complexité logique peut générer des imbalances entre le rendement et l'efficacité. Les méthodes actuelles essaient de se transformer en systèmes de pensée rapide et lente sans entraînement en changeant la difficulté du problème, mais sont limitées à un ajustement simple de stratégies. Pour résoudre ces problèmes, nous proposons un nouveau paradigme logique : le Modèle d'État de Pensée Adaptatif de Niveau de Processus (PATS). Celui-ci permettra que les LLMs ajustent dynamiquement leurs stratégies logiques selon la difficulté de chaque étape, optimisant ainsi l'équilibre entre précision et efficacité de calcul. Notre approche intègre le Modèle de Répétition de Processus (PRMs) et la Recherche de Rayons, incluant également la transition de modes évolutifs et la structure de pénalités pour les étapes maltraitées. Les résultats d'expériences dans différents cadres de référence mathématiques montrent que notre méthode maintient une précision constante tout en réduisant l'utilisation de tokens. Cette recherche met en avant l'importance de la transition des stratégies logiques en fonction du niveau de difficulté au niveau de processus, et offre des conseils précieux pour l'inférence efficace des LLMs.",
      "upvotes": 22,
      "discussionId": "68355ce16a9c239ada09f9a9",
      "ai_summary": "PATS enhances LLM efficiency by dynamically adjusting reasoning strategies based on task difficulty, leveraging PRMs and Beam Search.",
      "ai_keywords": [
        "large-language models (LLMs)",
        "reasoning strategy",
        "task and reasoning process complexity",
        "training-free fast-slow thinking system switching",
        "Process-Level Adaptive Thinking Mode Switching (PATS)",
        "Process Reward Models (PRMs)",
        "Beam Search",
        "progressive mode switching",
        "bad-step penalty mechanisms",
        "mathematical benchmarks",
        "process-level",
        "difficulty-aware reasoning strategy adaptation"
      ]
    },
    "publishedAt": "2025-05-25T13:58:50.000Z",
    "title": "PATS: Process-Level Adaptive Thinking Mode Switching",
    "summary": "Current large-language models (LLMs) typically adopt a fixed reasoning\nstrategy, either simple or complex, for all questions, regardless of their\ndifficulty. This neglect of variation in task and reasoning process complexity\nleads to an imbalance between performance and efficiency. Existing methods\nattempt to implement training-free fast-slow thinking system switching to\nhandle problems of varying difficulty, but are limited by coarse-grained\nsolution-level strategy adjustments. To address this issue, we propose a novel\nreasoning paradigm: Process-Level Adaptive Thinking Mode Switching (PATS),\nwhich enables LLMs to dynamically adjust their reasoning strategy based on the\ndifficulty of each step, optimizing the balance between accuracy and\ncomputational efficiency. Our approach integrates Process Reward Models (PRMs)\nwith Beam Search, incorporating progressive mode switching and bad-step penalty\nmechanisms. Experiments on diverse mathematical benchmarks demonstrate that our\nmethodology achieves high accuracy while maintaining moderate token usage. This\nstudy emphasizes the significance of process-level, difficulty-aware reasoning\nstrategy adaptation, offering valuable insights into efficient inference for\nLLMs.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.19250.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "66e0404662d6ab4f1107580f",
      "avatarUrl": "/avatars/ef71694fea5482078a637a3869e30d19.svg",
      "fullname": "Yi Wang",
      "name": "Yi53",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.20259",
      "authors": [
        {
          "_id": "6835346b2fdc5f8e8ea1e3cf",
          "name": "Haoyu Wang",
          "hidden": false
        },
        {
          "_id": "6835346b2fdc5f8e8ea1e3d0",
          "name": "Zeyu Qin",
          "hidden": false
        },
        {
          "_id": "6835346b2fdc5f8e8ea1e3d1",
          "name": "Yifei Zhao",
          "hidden": false
        },
        {
          "_id": "6835346b2fdc5f8e8ea1e3d2",
          "name": "Chao Du",
          "hidden": false
        },
        {
          "_id": "6835346b2fdc5f8e8ea1e3d3",
          "name": "Min Lin",
          "hidden": false
        },
        {
          "_id": "6835346b2fdc5f8e8ea1e3d4",
          "name": "Xueqian Wang",
          "hidden": false
        },
        {
          "_id": "6835346b2fdc5f8e8ea1e3d5",
          "name": "Tianyu Pang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-26T17:40:40.000Z",
      "submittedOnDailyAt": "2025-05-27T02:13:04.341Z",
      "title": "La sécurité de la vie en cycle et l'alignement langagier",
      "submittedOnDailyBy": {
        "_id": "63d91b6d255ef6add20e1b38",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1675921369867-63d91b6d255ef6add20e1b38.jpeg",
        "isPro": false,
        "fullname": "Tianyu Pang",
        "user": "P2333",
        "type": "user"
      },
      "summary": "Les LLMs ont réalisé une transition impressionnante, mais leur capacité croissante les rend vulnérables aux attaques jailbreaking flexibles qui évitent la sécurité. La stratégie de défense actuelle se concentre sur des attaques connues, mais il est crucial de répondre à des attaques imprévisibles qui peuvent émerger dans l'environnement. Pour aborder ce défi, nous proposons un cadre de sécurité à long terme pour les LLMs qui peuvent s'adapter de manière continue aux nouvelles et évolutives stratégies de jailbreaking. Dans ce cadre, nous introduisons deux éléments pour la stratégie : Meta-Attacker est entraîné pour trouver de nouvelles stratégies de jailbreaking de manière proactive, tandis que Defender est entraîné pour résister à celles-ci. Pour activer Meta-Attacker efficacement, nous extrayons d'abord des points clés de grandes recherches sur le jailbreaking en utilisant l'API de GPT-4o. Au travers d'entraînements répétés, dans la première itération, Meta-Attacker atteint un succès de 73% dans l'Attaque de Succession de Rétrospectifs (RR) et un 57% de mouvement dans l'Attaque de Succession de Rétrospectifs en un tour (LAT). D'autre part, Defender augmente sa résistance, restreignant enfin le succès de Meta-Attacker à un 7% et permettant que les LLMs puissent être sûrs et fiables dans des environnements ouverts. Le code est disponible sur https://github.com/sail-sg/LifelongSafetyAlignment.",
      "upvotes": 21,
      "discussionId": "6835346c2fdc5f8e8ea1e407",
      "githubRepo": "https://github.com/sail-sg/LifelongSafetyAlignment",
      "ai_summary": "A lifecycle safety alignment framework employs a Meta-Attacker and Defender to adapt LLMs to novel jailbreaking strategies, improving robustness in deployment.",
      "ai_keywords": [
        "LLMs",
        "jailbreaking attacks",
        "safety alignment",
        "lifelong safety alignment framework",
        "Meta-Attacker",
        "Defender",
        "GPT-4o API",
        "attack success rate",
        "transfer attack success rate",
        "single-turn attacks"
      ]
    },
    "publishedAt": "2025-05-26T13:40:40.000Z",
    "title": "Lifelong Safety Alignment for Language Models",
    "summary": "LLMs have made impressive progress, but their growing capabilities also\nexpose them to highly flexible jailbreaking attacks designed to bypass safety\nalignment. While many existing defenses focus on known types of attacks, it is\nmore critical to prepare LLMs for unseen attacks that may arise during\ndeployment. To address this, we propose a lifelong safety alignment framework\nthat enables LLMs to continuously adapt to new and evolving jailbreaking\nstrategies. Our framework introduces a competitive setup between two\ncomponents: a Meta-Attacker, trained to actively discover novel jailbreaking\nstrategies, and a Defender, trained to resist them. To effectively warm up the\nMeta-Attacker, we first leverage the GPT-4o API to extract key insights from a\nlarge collection of jailbreak-related research papers. Through iterative\ntraining, the first iteration Meta-Attacker achieves a 73% attack success rate\n(ASR) on RR and a 57% transfer ASR on LAT using only single-turn attacks.\nMeanwhile, the Defender progressively improves its robustness and ultimately\nreduces the Meta-Attacker's success rate to just 7%, enabling safer and more\nreliable deployment of LLMs in open-ended environments. The code is available\nat https://github.com/sail-sg/LifelongSafetyAlignment.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.20259.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "63d91b6d255ef6add20e1b38",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1675921369867-63d91b6d255ef6add20e1b38.jpeg",
      "fullname": "Tianyu Pang",
      "name": "P2333",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 3
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2505.18675",
      "authors": [
        {
          "_id": "68351dde0c0aff775f3933ee",
          "user": {
            "_id": "67a4a26d5e65aa63c6d30e68",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/67a4a26d5e65aa63c6d30e68/GtodlJGw-_IL2DTXQTucz.jpeg",
            "isPro": false,
            "fullname": "FENG SICHENG",
            "user": "FSCCS",
            "type": "user"
          },
          "name": "Sicheng Feng",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T07:52:13.406Z",
          "hidden": false
        },
        {
          "_id": "68351dde0c0aff775f3933ef",
          "name": "Song Wang",
          "hidden": false
        },
        {
          "_id": "68351dde0c0aff775f3933f0",
          "name": "Shuyi Ouyang",
          "hidden": false
        },
        {
          "_id": "68351dde0c0aff775f3933f1",
          "name": "Lingdong Kong",
          "hidden": false
        },
        {
          "_id": "68351dde0c0aff775f3933f2",
          "name": "Zikai Song",
          "hidden": false
        },
        {
          "_id": "68351dde0c0aff775f3933f3",
          "name": "Jianke Zhu",
          "hidden": false
        },
        {
          "_id": "68351dde0c0aff775f3933f4",
          "user": {
            "_id": "62b624f3b52bef716e248fd7",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62b624f3b52bef716e248fd7/AllcccKH-eBWduA8KVnOQ.png",
            "isPro": false,
            "fullname": "Huan Wang",
            "user": "Huan-WhoRegisteredMyName",
            "type": "user"
          },
          "name": "Huan Wang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T07:52:11.085Z",
          "hidden": false
        },
        {
          "_id": "68351dde0c0aff775f3933f5",
          "name": "Xinchao Wang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-24T12:33:52.000Z",
      "submittedOnDailyAt": "2025-05-27T00:35:52.585Z",
      "title": "Les MLLMs, est-ce qu'ils reviennent ? Benchmark de logique visuelle depuis la guidée de transport jusqu'aux détails spécifiques.",
      "submittedOnDailyBy": {
        "_id": "67a4a26d5e65aa63c6d30e68",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/67a4a26d5e65aa63c6d30e68/GtodlJGw-_IL2DTXQTucz.jpeg",
        "isPro": false,
        "fullname": "FENG SICHENG",
        "user": "FSCCS",
        "type": "user"
      },
      "summary": "Les modèles de langage multimodal de Damo (MLLMs) ont réalisé des progrès remarquables récents dans des tâches visuelles, comprenant mieux l'échelle significative et l'organisation de texte et d'image. Pour améliorer leur performance dans des tâches complexes liées à la mathématique ou à la logique, des variables logiques ont été introduites. Cependant, leur capacité à comprendre de manière détaillée la vision n'a pas été suffisamment évaluée dans des tâches logiques.\n\nPour aborder cette limite, nous présentons le benchmark ReasonMap pour évaluer la compréhension visuelle détaillée et le pouvoir logique spatial des MLLMs. ReasonMap comprend des cartes de transport à haute résolution de 30 villes dans 13 pays, avec 1,008 couples de questions et réponses, en utilisant deux types de questions et trois templates. De plus, nous avons conçu un plug-in d'évaluation en deux étapes pour évaluer précisément l'exactitude et la qualité des réponses. Nous avons évalué de manière détaillée 15 MLLMs (y compris des modèles de base et des variables logiques), découvrant des patterns intuitifs : les modèles open-source dépassent les modèles de base en logique, tandis que les modèles propriétaires montrent un comportement opposé. De plus, la perte de la vision visuelle entraîne une diminution de performance générale, ce qui démontre que, bien que les MLLMs puissent utiliser leur connaissance, ils nécessitent une perception visuelle réelle pour montrer un excellent rendement dans des tâches logiques spatiales. Notre étude de benchmark offre un nouveau point de vue sur la logique visuelle et explore les différences entre modèles open-source et propriétaires.",
      "upvotes": 21,
      "discussionId": "68351de10c0aff775f39347a",
      "projectPage": "https://fscdc.github.io/Reason-Map/",
      "githubRepo": "https://github.com/fscdc/ReasonMap",
      "ai_summary": "ReasonMap evaluates the fine-grained visual understanding and spatial reasoning abilities of multimodal large language models, revealing that base models often outperform reasoning variants and highlighting the importance of genuine visual perception for complex tasks.",
      "ai_keywords": [
        "multimodal large language models",
        "MLLMs",
        "semantic scene understanding",
        "text-image alignment",
        "reasoning variants",
        "ReasonMap",
        "high-resolution transit maps",
        "question-answer pairs",
        "two-level evaluation pipeline",
        "open-source models",
        "closed-source models",
        "visual reasoning"
      ]
    },
    "publishedAt": "2025-05-24T08:33:52.000Z",
    "title": "Can MLLMs Guide Me Home? A Benchmark Study on Fine-Grained Visual\n  Reasoning from Transit Maps",
    "summary": "Multimodal large language models (MLLMs) have recently achieved significant\nprogress in visual tasks, including semantic scene understanding and text-image\nalignment, with reasoning variants enhancing performance on complex tasks\ninvolving mathematics and logic. However, their capacity for reasoning tasks\ninvolving fine-grained visual understanding remains insufficiently evaluated.\nTo address this gap, we introduce ReasonMap, a benchmark designed to assess the\nfine-grained visual understanding and spatial reasoning abilities of MLLMs.\nReasonMap encompasses high-resolution transit maps from 30 cities across 13\ncountries and includes 1,008 question-answer pairs spanning two question types\nand three templates. Furthermore, we design a two-level evaluation pipeline\nthat properly assesses answer correctness and quality. Comprehensive\nevaluations of 15 popular MLLMs, including both base and reasoning variants,\nreveal a counterintuitive pattern: among open-source models, base models\noutperform reasoning ones, while the opposite trend is observed in\nclosed-source models. Additionally, performance generally degrades when visual\ninputs are masked, indicating that while MLLMs can leverage prior knowledge to\nanswer some questions, fine-grained visual reasoning tasks still require\ngenuine visual perception for strong performance. Our benchmark study offers\nnew insights into visual reasoning and contributes to investigating the gap\nbetween open-source and closed-source models.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.18675.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "67a4a26d5e65aa63c6d30e68",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/67a4a26d5e65aa63c6d30e68/GtodlJGw-_IL2DTXQTucz.jpeg",
      "fullname": "FENG SICHENG",
      "name": "FSCCS",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 0
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.19209",
      "authors": [
        {
          "_id": "683529e8ddbf19d1df9038fb",
          "user": {
            "_id": "646a11791556443f24b582e9",
            "avatarUrl": "/avatars/b54d416ddca2f124492ba51bc4b95fd2.svg",
            "isPro": false,
            "fullname": "Zonglin Yang",
            "user": "ZonglinY",
            "type": "user"
          },
          "name": "Zonglin Yang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T07:50:55.453Z",
          "hidden": false
        },
        {
          "_id": "683529e8ddbf19d1df9038fc",
          "name": "Wanhao Liu",
          "hidden": false
        },
        {
          "_id": "683529e8ddbf19d1df9038fd",
          "name": "Ben Gao",
          "hidden": false
        },
        {
          "_id": "683529e8ddbf19d1df9038fe",
          "name": "Yujie Liu",
          "hidden": false
        },
        {
          "_id": "683529e8ddbf19d1df9038ff",
          "name": "Wei Li",
          "hidden": false
        },
        {
          "_id": "683529e8ddbf19d1df903900",
          "name": "Tong Xie",
          "hidden": false
        },
        {
          "_id": "683529e8ddbf19d1df903901",
          "name": "Lidong Bing",
          "hidden": false
        },
        {
          "_id": "683529e8ddbf19d1df903902",
          "name": "Wanli Ouyang",
          "hidden": false
        },
        {
          "_id": "683529e8ddbf19d1df903903",
          "name": "Erik Cambria",
          "hidden": false
        },
        {
          "_id": "683529e8ddbf19d1df903904",
          "name": "Dongzhan Zhou",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-25T16:13:46.000Z",
      "submittedOnDailyAt": "2025-05-27T01:30:07.083Z",
      "title": "MOOSE-Chem2 : Exploration d'hypothèses scientifiques sur les limites des modèles de langage d'intelligence artificielle : par l'intermédiaire de recherches hiérarchiques.",
      "submittedOnDailyBy": {
        "_id": "646a11791556443f24b582e9",
        "avatarUrl": "/avatars/b54d416ddca2f124492ba51bc4b95fd2.svg",
        "isPro": false,
        "fullname": "Zonglin Yang",
        "user": "ZonglinY",
        "type": "user"
      },
      "summary": "Les modèles de langage grands (LLMs) montrent de bons résultats dans l'automatisation de la génération d'hypothèses scientifiques, mais l'approche actuelle principalement génère des hypothèses courtes, avec peu de détails méthodologiques et expérimentaux. Nous présentons une nouvelle tâche de détection d'hypothèses scientifiques détaillées et la définissons formellement. Cela implique de générer des hypothèses détaillées et opérationnelles à partir de directions initiales courtes. Cela est combiné dans un problème d'optimisation, en investiguant si cela peut être résolu avec le maximum de potentiel de capacité des LLMs. Nous expliquons spécifiquement quatre problèmes fondamentaux : (1) Comment les heuristiques internes des LLMs sont utilisées pour déterminer l'hypothèse la plus pertinente parmi celles qui peuvent être générées ; (2) Si l'hypothèse la plus valeureuse évaluée par l'LLM coïncide fortement avec l'hypothèse réelle ; (3) Si des résultats meilleurs sont obtenus en formant un paysage de récompenses (REWARD Landscape) avec un ensemble de plusieurs LLMs de la même capacité que les meilleures instances itératives ; (4) Si un paysage de récompenses plus fiable est fourni avec un ensemble d'un seul LLM par rapport à un seul LLM. Pour résoudre ces problèmes, nous proposons un méthode de recherche heuristique qui évolue des concepts généraux vers des configurations expérimentales spécifiques, en ajoutant des détails aux hypothèses et en évoluant des concepts généraux vers des configurations expérimentales spécifiques. Ce processus hiérarchique lisse le paysage de récompenses et facilite une optimisation plus efficace. Nos méthodes ont été évaluées expérimentalement sur un nouveau benchmark d'hypothèses détaillées basé sur la littérature chimique, annoté par des experts, et ont été démontrées constamment excellentes par rapport à des références robustes.",
      "upvotes": 20,
      "discussionId": "683529e9ddbf19d1df903939",
      "ai_summary": "A method is proposed to generate detailed scientific hypotheses using LLMs by defining and optimizing a latent reward landscape, outperforming baselines in benchmark evaluations.",
      "ai_keywords": [
        "large language models",
        "fine-grained scientific hypothesis discovery",
        "combinatorial optimization",
        "latent reward landscape",
        "hierarchical search method"
      ]
    },
    "publishedAt": "2025-05-25T12:13:46.000Z",
    "title": "MOOSE-Chem2: Exploring LLM Limits in Fine-Grained Scientific Hypothesis\n  Discovery via Hierarchical Search",
    "summary": "Large language models (LLMs) have shown promise in automating scientific\nhypothesis generation, yet existing approaches primarily yield coarse-grained\nhypotheses lacking critical methodological and experimental details. We\nintroduce and formally define the novel task of fine-grained scientific\nhypothesis discovery, which entails generating detailed, experimentally\nactionable hypotheses from coarse initial research directions. We frame this as\na combinatorial optimization problem and investigate the upper limits of LLMs'\ncapacity to solve it when maximally leveraged. Specifically, we explore four\nfoundational questions: (1) how to best harness an LLM's internal heuristics to\nformulate the fine-grained hypothesis it itself would judge as the most\npromising among all the possible hypotheses it might generate, based on its own\ninternal scoring-thus defining a latent reward landscape over the hypothesis\nspace; (2) whether such LLM-judged better hypotheses exhibit stronger alignment\nwith ground-truth hypotheses; (3) whether shaping the reward landscape using an\nensemble of diverse LLMs of similar capacity yields better outcomes than\ndefining it with repeated instances of the strongest LLM among them; and (4)\nwhether an ensemble of identical LLMs provides a more reliable reward landscape\nthan a single LLM. To address these questions, we propose a hierarchical search\nmethod that incrementally proposes and integrates details into the hypothesis,\nprogressing from general concepts to specific experimental configurations. We\nshow that this hierarchical process smooths the reward landscape and enables\nmore effective optimization. Empirical evaluations on a new benchmark of\nexpert-annotated fine-grained hypotheses from recent chemistry literature show\nthat our method consistently outperforms strong baselines.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.19209.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "646a11791556443f24b582e9",
      "avatarUrl": "/avatars/b54d416ddca2f124492ba51bc4b95fd2.svg",
      "fullname": "Zonglin Yang",
      "name": "ZonglinY",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.18536",
      "authors": [
        {
          "_id": "68351f7a06b4dae20a214442",
          "name": "Haoyuan Sun",
          "hidden": false
        },
        {
          "_id": "68351f7a06b4dae20a214443",
          "name": "Jiaqi Wu",
          "hidden": false
        },
        {
          "_id": "68351f7a06b4dae20a214444",
          "name": "Bo Xia",
          "hidden": false
        },
        {
          "_id": "68351f7a06b4dae20a214445",
          "name": "Yifu Luo",
          "hidden": false
        },
        {
          "_id": "68351f7a06b4dae20a214446",
          "name": "Yifei Zhao",
          "hidden": false
        },
        {
          "_id": "68351f7a06b4dae20a214447",
          "name": "Kai Qin",
          "hidden": false
        },
        {
          "_id": "68351f7a06b4dae20a214448",
          "name": "Xufei Lv",
          "hidden": false
        },
        {
          "_id": "68351f7a06b4dae20a214449",
          "name": "Tiantian Zhang",
          "hidden": false
        },
        {
          "_id": "68351f7a06b4dae20a21444a",
          "name": "Yongzhe Chang",
          "hidden": false
        },
        {
          "_id": "68351f7a06b4dae20a21444b",
          "name": "Xueqian Wang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-24T06:01:48.000Z",
      "submittedOnDailyAt": "2025-05-27T00:43:18.404Z",
      "title": "Renforcer les capacités d'inférence d'un modèle multi-type et multi-langue par ajustement de renforcement.",
      "submittedOnDailyBy": {
        "_id": "65e2d43f9fb58a5115253049",
        "avatarUrl": "/avatars/46bd4ae27eaa23802cef3d91626897b5.svg",
        "isPro": false,
        "fullname": "Haoyuan Sun",
        "user": "xiaonengmiao",
        "type": "user"
      },
      "summary": "En 2025, on se trouve dans une période importante liée à la persécution de l'IAG, et RFT montre le potentiel crucial pour élever l'intelligence artificielle des modèles de langage d'entrée (LLMs), en association avec le développement de modèles avancés comme OpenAI-o1 et DeepSeek-R1. De plus, il a reçu un respect large dans la communauté pour son application efficace pour élever l'intelligence artificielle des MLLMs. Cet article affirme que RFT soutient l'intelligence artificielle des MLLMs et offre une introduction détaillée des connaissances basiques nécessaires pour les chercheurs intéressés par ce domaine, résumant les points clés dans lesquels RFT peut améliorer l'intelligence artificielle des MLLMs : modules divers, tâches et domaines divers, algorithmes d'apprentissage plus efficaces, référentiels riches et cadres de travail actifs d'ingénierie. Enfin, il propose cinq directions potentielles de recherche que la communauté doit considérer. On espère que cet article soit une étape importante dans le développement de l'IAG et offre des conseils précieux à la communauté. Un résumé du étude de l'application de RFT dans les MLLMs peut être trouvé sur : https://github.com/Sun-Haoyuan23/Awesome-RL-based-Reasoning-MLLMs.",
      "upvotes": 16,
      "discussionId": "68351f7b06b4dae20a2144b5",
      "projectPage": "https://github.com/Sun-Haoyuan23/Awesome-RL-based-Reasoning-MLLMs",
      "githubRepo": "https://github.com/Sun-Haoyuan23/Awesome-RL-based-Reasoning-MLLMs",
      "ai_summary": "Reinforcement fine-tuning significantly enhances the reasoning capabilities of multimodal large language models through diverse modalities, tasks, algorithms, benchmarks, and frameworks.",
      "ai_keywords": [
        "reinforcement fine-tuning",
        "multimodal large language models",
        "OpenAI-o1",
        "DeepSeek-R1",
        "diverse modalities",
        "diverse tasks and domains",
        "better training algorithms",
        "abundant benchmarks",
        "thriving engineering frameworks"
      ]
    },
    "publishedAt": "2025-05-24T02:01:48.000Z",
    "title": "Reinforcement Fine-Tuning Powers Reasoning Capability of Multimodal\n  Large Language Models",
    "summary": "Standing in 2025, at a critical juncture in the pursuit of Artificial General\nIntelligence (AGI), reinforcement fine-tuning (RFT) has demonstrated\nsignificant potential in enhancing the reasoning capability of large language\nmodels (LLMs) and has led to the development of cutting-edge AI models such as\nOpenAI-o1 and DeepSeek-R1. Moreover, the efficient application of RFT to\nenhance the reasoning capability of multimodal large language models (MLLMs)\nhas attracted widespread attention from the community. In this position paper,\nwe argue that reinforcement fine-tuning powers the reasoning capability of\nmultimodal large language models. To begin with, we provide a detailed\nintroduction to the fundamental background knowledge that researchers\ninterested in this field should be familiar with. Furthermore, we meticulously\nsummarize the improvements of RFT in powering reasoning capability of MLLMs\ninto five key points: diverse modalities, diverse tasks and domains, better\ntraining algorithms, abundant benchmarks and thriving engineering frameworks.\nFinally, we propose five promising directions for future research that the\ncommunity might consider. We hope that this position paper will provide\nvaluable insights to the community at this pivotal stage in the advancement\ntoward AGI. Summary of works done on RFT for MLLMs is available at\nhttps://github.com/Sun-Haoyuan23/Awesome-RL-based-Reasoning-MLLMs.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.18536.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "65e2d43f9fb58a5115253049",
      "avatarUrl": "/avatars/46bd4ae27eaa23802cef3d91626897b5.svg",
      "fullname": "Haoyuan Sun",
      "name": "xiaonengmiao",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2505.19439",
      "authors": [
        {
          "_id": "68355784bb7d114755346770",
          "name": "Rihui Xin",
          "hidden": false
        },
        {
          "_id": "68355784bb7d114755346771",
          "name": "Han Liu",
          "hidden": false
        },
        {
          "_id": "68355784bb7d114755346772",
          "name": "Zecheng Wang",
          "hidden": false
        },
        {
          "_id": "68355784bb7d114755346773",
          "name": "Yupeng Zhang",
          "hidden": false
        },
        {
          "_id": "68355784bb7d114755346774",
          "name": "Dianbo Sui",
          "hidden": false
        },
        {
          "_id": "68355784bb7d114755346775",
          "name": "Xiaolin Hu",
          "hidden": false
        },
        {
          "_id": "68355784bb7d114755346776",
          "name": "Bingning Wang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-26T02:56:22.000Z",
      "submittedOnDailyAt": "2025-05-27T04:41:46.037Z",
      "title": "\"Signals de remplacement sur forme et longueur : Apprentissage par renforcement pour résoudre l'effet de la proximité de la barre\"",
      "submittedOnDailyBy": {
        "_id": "62e52483a944e2a56cd2c6ca",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62e52483a944e2a56cd2c6ca/pG44O-1qD00q5CEJMMyFQ.jpeg",
        "isPro": false,
        "fullname": "Jiejun Tan",
        "user": "zstanjj",
        "type": "user"
      },
      "summary": "Les modèles de langage généraux ont réussi à obtenir un succès notable dans les tâches de traitement du langage naturel, et l'apprentissage par renforcement joue un rôle important lorsqu'ils sont appliqués à des applications spécifiques. Cependant, obtenir des données de réponses correctes pour l'entraînement des modèles de langage général dans des problèmes de mathématiques est généralement difficile et coûteux, ce qui rend cela pratiquement impossible. Dans cette étude, nous examinons la méthodologie d'utilisation de la syntaxe et de la longueur comme signaux de rétroaction pour entraîner des modèles de langage général dans des problèmes de mathématiques, évitant la dépendance des données de réponses correctes existantes. Nous avons observé un amélioration du rendement dans les étapes initiales en se concentrant sur la précision de la syntaxe et en configurant la fonction de récompense. Nous avons reconnu les limitations de la récompense de la syntaxe et nous avons utilisée une récompense basée sur la longueur. De cette manière, l'approche GRPO qui utilise la syntaxe et la longueur comme signaux de rétroaction a dépassé l'approche GRPO basée sur des données de réponses correctes, et dans certains scénarios, a atteint une précision de 40%. Cette étude fournit une solution pratique pour l'entraînement des modèles de langage général dans des problèmes de mathématiques, réduisant la dépendance excessive de la collecte de données de réponses correctes. De plus, elle éclaire pourquoi l'approche sans étiquette peut être réussie : le modèle de base est considéré comme un excellent étudiant qui a déjà appris les mathématiques et les habiletés d'inférence logique, mais sa représentation dans l'examen peut être insuffisante pour obtenir de bons résultats, ce qui signifie que l'entraînement dans la résolution de problèmes est crucial pour atteindre de bons résultats dans l'examen.",
      "upvotes": 15,
      "discussionId": "68355785bb7d1147553467b8",
      "ai_summary": "The research demonstrates that using format and length as surrogate signals can improve LLMs' performance in mathematical problem-solving, matching or surpassing traditional methods without extensive ground truth data.",
      "ai_keywords": [
        "Large Language Models",
        "Reinforcement Learning",
        "mathematical problem-solving",
        "GRPO algorithm",
        "format correctness",
        "length-based rewards",
        "AIME2024"
      ]
    },
    "publishedAt": "2025-05-25T22:56:22.000Z",
    "title": "Surrogate Signals from Format and Length: Reinforcement Learning for\n  Solving Mathematical Problems without Ground Truth Answers",
    "summary": "Large Language Models have achieved remarkable success in natural language\nprocessing tasks, with Reinforcement Learning playing a key role in adapting\nthem to specific applications. However, obtaining ground truth answers for\ntraining LLMs in mathematical problem-solving is often challenging, costly, and\nsometimes unfeasible. This research delves into the utilization of format and\nlength as surrogate signals to train LLMs for mathematical problem-solving,\nbypassing the need for traditional ground truth answers.Our study shows that a\nreward function centered on format correctness alone can yield performance\nimprovements comparable to the standard GRPO algorithm in early phases.\nRecognizing the limitations of format-only rewards in the later phases, we\nincorporate length-based rewards. The resulting GRPO approach, leveraging\nformat-length surrogate signals, not only matches but surpasses the performance\nof the standard GRPO algorithm relying on ground truth answers in certain\nscenarios, achieving 40.0\\% accuracy on AIME2024 with a 7B base model. Through\nsystematic exploration and experimentation, this research not only offers a\npractical solution for training LLMs to solve mathematical problems and\nreducing the dependence on extensive ground truth data collection, but also\nreveals the essence of why our label-free approach succeeds: base model is like\nan excellent student who has already mastered mathematical and logical\nreasoning skills, but performs poorly on the test paper, it simply needs to\ndevelop good answering habits to achieve outstanding results in exams , in\nother words, to unlock the capabilities it already possesses.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.19439.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "62e52483a944e2a56cd2c6ca",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62e52483a944e2a56cd2c6ca/pG44O-1qD00q5CEJMMyFQ.jpeg",
      "fullname": "Jiejun Tan",
      "name": "zstanjj",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 10
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2505.18601",
      "authors": [
        {
          "_id": "6835268212dd354d6acdacbf",
          "name": "Jongwoo Ko",
          "hidden": false
        },
        {
          "_id": "6835268212dd354d6acdacc0",
          "user": {
            "_id": "63f0c2ac9cf89c9ed1bdd25c",
            "avatarUrl": "/avatars/856b2cb482250fb83c6fe793e29dfd74.svg",
            "isPro": false,
            "fullname": "Sungnyun Kim",
            "user": "sungnyun",
            "type": "user"
          },
          "name": "Sungnyun Kim",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T08:15:10.751Z",
          "hidden": false
        },
        {
          "_id": "6835268212dd354d6acdacc1",
          "name": "Sungwoo Cho",
          "hidden": false
        },
        {
          "_id": "6835268212dd354d6acdacc2",
          "name": "Se-Young Yun",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-24T08:50:53.000Z",
      "submittedOnDailyAt": "2025-05-27T01:14:15.443Z",
      "title": "Flex-Judge : Pense un momento, vous pouvez juger partout.",
      "submittedOnDailyBy": {
        "_id": "63f0c2ac9cf89c9ed1bdd25c",
        "avatarUrl": "/avatars/856b2cb482250fb83c6fe793e29dfd74.svg",
        "isPro": false,
        "fullname": "Sungnyun Kim",
        "user": "sungnyun",
        "type": "user"
      },
      "summary": "Les signaux de récompense générés par des êtres humains sont essentiels pour aligner les modèles génératifs avec les préférences humaines et peuvent fournir des orientations dans l'évaluation pendant l'apprentissage et l'inférence. En utilisant des modèles de langage à grande échelle (LLM) comme évaluateurs délégués, il est possible de réduire significativement les coûts associés aux commentaires manuels. Cependant, ces modèles généralement nécessitent un entraînement avec des données de modélisation large pour généraliser aux problèmes de diversité, et leur efficacité pratique est limitée. Dans cet article, nous proposons un modèle d'évaluation de diversité \"Flex-Judge\" qui guide l'évaluation avec des raisons contextuelles minimales et permet une généralisation large des modèles et des formes d'évaluation. La conclusion centrale de l'article est que les patrons de jugement qui peuvent être généralisés aux contextes structurés sont incorporés, ce qui permet un excellent rendement dans les évaluations de diversité qui incluent des images ou des vidéos. Les résultats des expérimentations montrent que Flex-Judge atteint des rendements compétitifs ou excellents, même lorsque la quantité de données contextuelles est significativement faible, par rapport aux modèles d'évaluation de diversité largement entraînés et aux APIs commerciales les plus avancées. En particulier, il a également un impact significatif sur des modèles comme les molécules, où les cadres d'évaluation détaillés sont rares. Ce cadre est une solution puissante et rentable qui remplace la méthode traditionnelle des commentaires et améliore significativement l'évaluation des modèles de diversité.",
      "upvotes": 15,
      "discussionId": "6835268312dd354d6acdad1e",
      "projectPage": "https://flex-judge.github.io/",
      "githubRepo": "https://github.com/jongwooko/flex-judge",
      "ai_summary": "Flex-Judge uses minimal textual reasoning data to generalize across multiple modalities and evaluation formats, outperforming state-of-the-art models in multimodal evaluations.",
      "ai_keywords": [
        "reasoning-guided multimodal judge model",
        "structured textual reasoning explanations",
        "generalizable decision-making patterns",
        "multimodal judgments",
        "molecule evaluations",
        "reasoning-based text supervision",
        "scalable multimodal model-as-a-judge"
      ]
    },
    "publishedAt": "2025-05-24T04:50:53.000Z",
    "title": "Flex-Judge: Think Once, Judge Anywhere",
    "summary": "Human-generated reward signals are critical for aligning generative models\nwith human preferences, guiding both training and inference-time evaluations.\nWhile large language models (LLMs) employed as proxy evaluators, i.e.,\nLLM-as-a-Judge, significantly reduce the costs associated with manual\nannotations, they typically require extensive modality-specific training data\nand fail to generalize well across diverse multimodal tasks. In this paper, we\npropose Flex-Judge, a reasoning-guided multimodal judge model that leverages\nminimal textual reasoning data to robustly generalize across multiple\nmodalities and evaluation formats. Our core intuition is that structured\ntextual reasoning explanations inherently encode generalizable decision-making\npatterns, enabling an effective transfer to multimodal judgments, e.g., with\nimages or videos. Empirical results demonstrate that Flex-Judge, despite being\ntrained on significantly fewer text data, achieves competitive or superior\nperformance compared to state-of-the-art commercial APIs and extensively\ntrained multimodal evaluators. Notably, Flex-Judge presents broad impact in\nmodalities like molecule, where comprehensive evaluation benchmarks are scarce,\nunderscoring its practical value in resource-constrained domains. Our framework\nhighlights reasoning-based text supervision as a powerful, cost-effective\nalternative to traditional annotation-intensive approaches, substantially\nadvancing scalable multimodal model-as-a-judge.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.18601.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "63f0c2ac9cf89c9ed1bdd25c",
      "avatarUrl": "/avatars/856b2cb482250fb83c6fe793e29dfd74.svg",
      "fullname": "Sungnyun Kim",
      "name": "sungnyun",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.19949",
      "authors": [
        {
          "_id": "68352aac38e5ca9eb5349c2f",
          "name": "Siqi Kou",
          "hidden": false
        },
        {
          "_id": "68352aac38e5ca9eb5349c30",
          "name": "Qingyuan Tian",
          "hidden": false
        },
        {
          "_id": "68352aac38e5ca9eb5349c31",
          "name": "Hanwen Xu",
          "hidden": false
        },
        {
          "_id": "68352aac38e5ca9eb5349c32",
          "name": "Zihao Zeng",
          "hidden": false
        },
        {
          "_id": "68352aac38e5ca9eb5349c33",
          "name": "Zhijie Deng",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-26T13:15:26.000Z",
      "submittedOnDailyAt": "2025-05-27T01:30:37.130Z",
      "title": "Les caractéristiques des données peuvent-elles pousser la logique de la mathématique et le code ? Recherche en utilisant des fonctions d'influence.",
      "submittedOnDailyBy": {
        "_id": "654e330f350abceb30a1390b",
        "avatarUrl": "/avatars/e54a8be788fa1bdc7acefecc208215bb.svg",
        "isPro": false,
        "fullname": "KouSiqi",
        "user": "karrykkk",
        "type": "user"
      },
      "summary": "Les modèles de langage grands (LLMs) développent une capacité logique extraordinaire dans les domaines de la mathématique et du code en utilisant des modèles d'apprentissage par répétition qui génèrent des pensées logiques (CoTs) et s'adaptent ultérieurement. Cependant, la stratégie actuelle de coloration de données se fonde principalement sur des heuristiques, ce qui limite sa généralisation et ne capture pas les détails délicats des données. Pour résoudre ces limitations, nous utilisons des fonctions d'influence pour attribuer de manière systématique les habiletés logiques en mathématiques et en code aux modèles de LLMs, en fonction des échantillons d'apprentissage, des séquences et des tokens. Cet approche systématique a permis que notre système d'attribution logique basé sur des fonctions d'influence (Infra) révèle des effets non linéaires dans les tâches de mathématiques et de code : des échantillons de haut niveau de difficulté améliorent à la fois la logique mathématique et la logique du code, tandis que des tâches de bas niveau de difficulté du code maximisent la logique du code. Avec ces observations, nous présentons une stratégie simple et efficace pour remplacer le degré de difficulté dans les ensembles de données : cela a augmenté la précision de AIME24 de 10% à 20% et la précision de Qwen2.5-7B-Instruct sur LiveCodeBench de 33.8% à 35.3%. De plus, notre approche détaillée améliore le rendement logique en mathématiques et en code par des actions exploratoires au niveau de séquence et de motifs d'influence au niveau de token, qui diffèrent entre mathématiques et code : le premier préfère les connecteurs logiques du langage naturel, tandis que le second met l'accent sur la structure.",
      "upvotes": 13,
      "discussionId": "68352aad38e5ca9eb5349c6f",
      "ai_summary": "Influence functions are used to attribute LLMs' reasoning in math and coding to individual training elements, revealing cross-domain effects and enabling a reweighting strategy that improves model accuracy.",
      "ai_keywords": [
        "Large language models (LLMs)",
        "chain-of-thoughts (CoTs)",
        "influence functions",
        "attribution",
        "data curation",
        "reasoning ability",
        "high-difficulty math examples",
        "low-difficulty code tasks",
        "dataset reweighting strategy",
        "AIME24 accuracy",
        "LiveCodeBench accuracy",
        "sequence-level exploratory behaviors",
        "token-level influence patterns",
        "natural language logic connectors",
        "structural syntax",
        "parameter-efficient fine-tuning"
      ]
    },
    "publishedAt": "2025-05-26T09:15:26.000Z",
    "title": "Which Data Attributes Stimulate Math and Code Reasoning? An\n  Investigation via Influence Functions",
    "summary": "Large language models (LLMs) have demonstrated remarkable reasoning\ncapabilities in math and coding, often bolstered by post-training on the\nchain-of-thoughts (CoTs) generated by stronger models. However, existing\nstrategies for curating such training data predominantly rely on heuristics,\nlimiting generalizability and failing to capture subtleties underlying in data.\nTo address these limitations, we leverage influence functions to systematically\nattribute LLMs' reasoning ability on math and coding to individual training\nexamples, sequences, and tokens, enabling deeper insights into effective data\ncharacteristics. Our Influence-based Reasoning Attribution (Infra) uncovers\nnontrivial cross-domain effects across math and coding tasks: high-difficulty\nmath examples improve both math and code reasoning, while low-difficulty code\ntasks most effectively benefit code reasoning. Based on these findings, we\nintroduce a simple yet effective dataset reweighting strategy by flipping task\ndifficulty, which doubles AIME24 accuracy from 10\\% to 20\\% and boosts\nLiveCodeBench accuracy from 33.8\\% to 35.3\\% for Qwen2.5-7B-Instruct. Moreover,\nour fine-grained attribution reveals that the sequence-level exploratory\nbehaviors enhance reasoning performance in both math and code, and the\ntoken-level influence patterns are distinct for math and code reasoning: the\nformer prefers natural language logic connectors and the latter emphasizes\nstructural syntax.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.19949.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "654e330f350abceb30a1390b",
      "avatarUrl": "/avatars/e54a8be788fa1bdc7acefecc208215bb.svg",
      "fullname": "KouSiqi",
      "name": "karrykkk",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 4
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2505.20256",
      "authors": [
        {
          "_id": "68352e44c829f2ea1e0484b5",
          "name": "Hao Zhong",
          "hidden": false
        },
        {
          "_id": "68352e44c829f2ea1e0484b6",
          "name": "Muzhi Zhu",
          "hidden": false
        },
        {
          "_id": "68352e44c829f2ea1e0484b7",
          "name": "Zongze Du",
          "hidden": false
        },
        {
          "_id": "68352e44c829f2ea1e0484b8",
          "name": "Zheng Huang",
          "hidden": false
        },
        {
          "_id": "68352e44c829f2ea1e0484b9",
          "user": {
            "_id": "646efd223dd912a539e0bd46",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/EOFAv5xvOgJOzuDgh4nSb.png",
            "isPro": false,
            "fullname": "Canyu Zhao",
            "user": "Canyu",
            "type": "user"
          },
          "name": "Canyu Zhao",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T07:50:50.579Z",
          "hidden": false
        },
        {
          "_id": "68352e44c829f2ea1e0484ba",
          "name": "Mingyu Liu",
          "hidden": false
        },
        {
          "_id": "68352e44c829f2ea1e0484bb",
          "name": "Wen Wang",
          "hidden": false
        },
        {
          "_id": "68352e44c829f2ea1e0484bc",
          "name": "Hao Chen",
          "hidden": false
        },
        {
          "_id": "68352e44c829f2ea1e0484bd",
          "name": "Chunhua Shen",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-26T17:34:06.000Z",
      "submittedOnDailyAt": "2025-05-27T01:47:33.260Z",
      "title": "Omni-R1 : L'apprentissage de l'intelligence artificielle en mode Omni par collaboration de deux systèmes",
      "submittedOnDailyBy": {
        "_id": "632179745fc60c44fd91fc33",
        "avatarUrl": "/avatars/37d4fefbcc19f091dccffefec9706de2.svg",
        "isPro": false,
        "fullname": "zhumuzhi",
        "user": "Z-MU-Z",
        "type": "user"
      },
      "summary": "La prédiction de vidéos et d'audio à long terme et la compréhension pixel par pixel posent des exigences différentes pour des modèles visuels complets : une couverture temporelle dense nécessite plusieurs cadences de faible résolution, tandis que une compréhension précise du fond nécessite des entrées de haute résolution. Nous résolvons cet équilibre grâce à deux architectures de système : le système de prédiction global sélectionne des cadences clés riches en information et adapte le coût spatial à la tâche, tandis que le système de compréhension de détails réalise une compréhension du fond pixel par pixel dans des fragments de haute résolution sélectionnés. Étant donné que la sélection de \"meilleurs\" cadences clés et l'adaptation ne sont pas claires ni normatives, il est difficile d'apprendre. Par conséquent, nous proposons un problème d'apprentissage par renforcement basé sur le résultat (RL) et nous optimisons le méthode en utilisant le Group Relative d'Optimisation de Politique, appelé Omni-R1. Omni-R1 apprend le système de prédiction global en utilisant des récompenses par étape obtenues en collaboration en ligne par le système de compréhension de détails, nécessitant seulement une tour de l'apprentissage par renforcement dans chaque fragment de tâche petit.\n\nLes expérimentations réalisées en référence aux normes de segmentation audiovisuelle (RefAVS) et de segmentation d'objets vidéo par raisonnement (REVOS) montrent que Omni-R1 dépasse les modèles d'apprentissage par force de base et les modèles avancés spécialisés, démontrant une amélioration significative en inhibant l'expansion de la discrimination et la capacité multimodale de Harlow. Nos résultats indiquent que pour la première fois, l'apprentissage par renforcement a été appliqué avec succès à la prédiction visuelle complète à grande échelle, montrant un chemin d'expansion.",
      "upvotes": 11,
      "discussionId": "68352e47c829f2ea1e048539",
      "projectPage": "https://aim-uofa.github.io/OmniR1/",
      "githubRepo": "https://github.com/aim-uofa/Omni-R1",
      "ai_summary": "An end-to-end reinforcement learning framework, Omni-R1, achieves superior performance in long-horizon video-audio reasoning and fine-grained pixel understanding tasks by combining global reasoning and detail understanding systems.",
      "ai_keywords": [
        "reinforcement learning",
        "Group Relative Policy Optimization",
        "hierarchical rewards",
        "Referring Audio-Visual Segmentation",
        "Reasoning Video Object Segmentation",
        "out-of-domain generalization",
        "multimodal hallucination",
        "universally foundation models"
      ]
    },
    "publishedAt": "2025-05-26T13:34:06.000Z",
    "title": "Omni-R1: Reinforcement Learning for Omnimodal Reasoning via Two-System\n  Collaboration",
    "summary": "Long-horizon video-audio reasoning and fine-grained pixel understanding\nimpose conflicting requirements on omnimodal models: dense temporal coverage\ndemands many low-resolution frames, whereas precise grounding calls for\nhigh-resolution inputs. We tackle this trade-off with a two-system\narchitecture: a Global Reasoning System selects informative keyframes and\nrewrites the task at low spatial cost, while a Detail Understanding System\nperforms pixel-level grounding on the selected high-resolution snippets.\nBecause ``optimal'' keyframe selection and reformulation are ambiguous and hard\nto supervise, we formulate them as a reinforcement learning (RL) problem and\npresent Omni-R1, an end-to-end RL framework built on Group Relative Policy\nOptimization. Omni-R1 trains the Global Reasoning System through hierarchical\nrewards obtained via online collaboration with the Detail Understanding System,\nrequiring only one epoch of RL on small task splits.\n  Experiments on two challenging benchmarks, namely Referring Audio-Visual\nSegmentation (RefAVS) and Reasoning Video Object Segmentation (REVOS), show\nthat Omni-R1 not only surpasses strong supervised baselines but also\noutperforms specialized state-of-the-art models, while substantially improving\nout-of-domain generalization and mitigating multimodal hallucination. Our\nresults demonstrate the first successful application of RL to large-scale\nomnimodal reasoning and highlight a scalable path toward universally foundation\nmodels.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.20256.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "632179745fc60c44fd91fc33",
      "avatarUrl": "/avatars/37d4fefbcc19f091dccffefec9706de2.svg",
      "fullname": "zhumuzhi",
      "name": "Z-MU-Z",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 3
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2505.19788",
      "authors": [
        {
          "_id": "68352630363d6fd2fff5d07f",
          "name": "Zihao Zeng",
          "hidden": false
        },
        {
          "_id": "68352630363d6fd2fff5d080",
          "user": {
            "_id": "6721dacfc5309c08451d21d5",
            "avatarUrl": "/avatars/ac8be5ac8b8ee5b5533214e526b72dad.svg",
            "isPro": false,
            "fullname": "Huang Xuyao",
            "user": "ElysiaTrue",
            "type": "user"
          },
          "name": "Xuyao Huang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T07:51:44.216Z",
          "hidden": false
        },
        {
          "_id": "68352630363d6fd2fff5d081",
          "name": "Boxiu Li",
          "hidden": false
        },
        {
          "_id": "68352630363d6fd2fff5d082",
          "name": "Hao Zhang",
          "hidden": false
        },
        {
          "_id": "68352630363d6fd2fff5d083",
          "name": "Zhijie Deng",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-26T10:18:57.000Z",
      "submittedOnDailyAt": "2025-05-27T01:59:02.853Z",
      "title": "Le meilleur complètement : la libération de la raison efficace par la décomposition structurée par étapes",
      "submittedOnDailyBy": {
        "_id": "6721dacfc5309c08451d21d5",
        "avatarUrl": "/avatars/ac8be5ac8b8ee5b5533214e526b72dad.svg",
        "isPro": false,
        "fullname": "Huang Xuyao",
        "user": "ElysiaTrue",
        "type": "user"
      },
      "summary": "Les modèles logiques de grande portée (LRMs) sont critiqués pour utiliser une chaîne de pensée (CoT) trop longue pour obtenir la réponse finale, avec un début de token et un retard élevés. En général, la CoT des LRMs mélange plusieurs unités de mémoire. Chaque unité génère des candidats de réponse pour une question de base. Une idée naturelle pour augmenter l'efficacité est de réduire le nombre d'unités. Cependant, dans la CoT de BERT, les unités de mémoire ne sont pas gérées clairement, ce qui complique ce processus. Cet article introduit la Décomposition Multi-Turn (MinD) pour transformer un seul CoT en une séquence structurée et interactive de tours, avec l'objectif de corriger cet erreur. Dans MinD, le modèle fournit des réponses multi-tour pour une requête, où chaque tour comprend des unités de mémoire et permet la génération de réponses. Les tours suivants peuvent réfléchir, vérifier, modifier ou remplacer les réponses précédentes. Cela permet de fournir des réponses plus rapides et de mieux contrôler le processus logique (par exemple, l'utilisateur peut arrêter ou continuer à n'importe quel tour). Nous appliquons le modèle d'apprentissage par renforcement (RL) pour implémenter MinD à travers un fine-tuning supervisé (SFT). Tout d'abord, nous réprogrammons un modèle de langage de haut rendement (LLM) pour générer des réponses sous format multi-tour, et nous ajustons le LRM avec ces données. Le modèle ajusté peut utiliser plus de tokens que le modèle original, démontrant que le format multi-tour peut créer des réponses plus étendues. En utilisant des algorithmes d'apprentissage par renforcement comme GRPO (Generalized Proximal Policy Optimization), nous priorisons la génération de réponses précises en moins de tours. Le modèle MinD entraîné avec le jeu de données MATH, comme R1-Distill, réduit la quantité de tokens utilisés et le temps du premier token (TTFT) d'environ 70%, tout en maintenant de très bons résultats sur les benchmarks logiques comme MATH-500, AIME24, AMC23 et GPQA-Diamond.",
      "upvotes": 11,
      "discussionId": "68352631363d6fd2fff5d0b9",
      "ai_summary": "Multi-Turn Decomposition improves efficiency in large reasoning models by breaking down chain-of-thought into manageable turns, reducing token usage and latency while maintaining performance.",
      "ai_keywords": [
        "Chain-of-Thought",
        "large reasoning models",
        "multi-turn decomposition",
        "thinking units",
        "iterative reasoning process",
        "supervised fine-tuning",
        "reinforcement learning",
        "MATH dataset",
        "R1-Distill models",
        "MATH-500",
        "AIME24",
        "AMC23",
        "GPQA-Diamond"
      ]
    },
    "publishedAt": "2025-05-26T06:18:57.000Z",
    "title": "Done Is Better than Perfect: Unlocking Efficient Reasoning by Structured\n  Multi-Turn Decomposition",
    "summary": "Large Reasoning Models (LRMs) are criticized for the excessively lengthy\nChain-of-Thought (CoT) to derive the final answer, suffering from high\nfirst-token and overall latency. Typically, the CoT of LRMs mixes multiple\nthinking units; each unit attempts to produce a candidate answer to the\noriginal query. Hence, a natural idea to improve efficiency is to reduce the\nunit number. Yet, the fact that the thinking units in vanilla CoT cannot be\nexplicitly managed renders doing so challenging. This paper introduces\nMulti-Turn Decomposition (MinD) to decode conventional CoT into a sequence of\nexplicit, structured, and turn-wise interactions to bridge the gap. In MinD,\nthe model provides a multi-turn response to the query, where each turn embraces\na thinking unit and yields a corresponding answer. The subsequent turns can\nreflect, verify, revise, or explore alternative approaches to both the thinking\nand answer parts of earlier ones. This not only makes the answer delivered more\nswiftly, but also enables explicit controls over the iterative reasoning\nprocess (i.e., users may halt or continue at any turn). We follow a supervised\nfine-tuning (SFT) then reinforcement learning (RL) paradigm to realize MinD. We\nfirst rephrase the outputs of an LRM into multi-turn formats by prompting\nanother LLM, and then tune the LRM with such data. Observing that the tuned\nmodel tends to consume even more tokens than the original one (probably due to\nthat the multi-turn formats introduce additional answer tokens), we advocate\nleveraging RL algorithms like GRPO to prioritize correct outputs with fewer\nturns. Trained on the MATH dataset using R1-Distill models, MinD can achieve up\nto ~70% reduction in both output token usage and time to first token (TTFT),\nwhile maintaining competitive performance on reasoning benchmarks such as\nMATH-500, AIME24, AMC23, and GPQA-Diamond.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.19788.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6721dacfc5309c08451d21d5",
      "avatarUrl": "/avatars/ac8be5ac8b8ee5b5533214e526b72dad.svg",
      "fullname": "Huang Xuyao",
      "name": "ElysiaTrue",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.19752",
      "authors": [
        {
          "_id": "683527ba3762eb8b3ea1de34",
          "user": {
            "_id": "62649e2b1ed8d81e47ad9b4e",
            "avatarUrl": "/avatars/f33a0b727822fd2ea99dce37fbda3d17.svg",
            "isPro": false,
            "fullname": "Li",
            "user": "henry12348",
            "type": "user"
          },
          "name": "Hengli Li",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T07:51:37.403Z",
          "hidden": false
        },
        {
          "_id": "683527ba3762eb8b3ea1de35",
          "user": {
            "_id": "60b9e6837946aff342f734ae",
            "avatarUrl": "/avatars/a711a6aa35757dfd7b78b26098a964fc.svg",
            "isPro": false,
            "fullname": "Yuxuan Wang",
            "user": "ColorfulAI",
            "type": "user"
          },
          "name": "Yuxuan Wang",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-05-27T02:47:22.991Z",
          "hidden": false
        },
        {
          "_id": "683527ba3762eb8b3ea1de36",
          "name": "Song-Chun Zhu",
          "hidden": false
        },
        {
          "_id": "683527ba3762eb8b3ea1de37",
          "name": "Ying Nian Wu",
          "hidden": false
        },
        {
          "_id": "683527ba3762eb8b3ea1de38",
          "user": {
            "_id": "63a95a6a7930fa8c7dd63d4e",
            "avatarUrl": "/avatars/d9d0420f7ddfe2f3a7e029fb05f1c89f.svg",
            "isPro": false,
            "fullname": "Zilong Zheng",
            "user": "zlzheng",
            "type": "user"
          },
          "name": "Zilong Zheng",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-05-27T02:47:22.991Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-26T09:32:12.000Z",
      "submittedOnDailyAt": "2025-05-27T01:18:56.411Z",
      "title": "Discrete Markov Bridge",
      "submittedOnDailyBy": {
        "_id": "62649e2b1ed8d81e47ad9b4e",
        "avatarUrl": "/avatars/f33a0b727822fd2ea99dce37fbda3d17.svg",
        "isPro": false,
        "fullname": "Li",
        "user": "henry12348",
        "type": "user"
      },
      "summary": "La discretisation différentielle a été récemment introduite comme un paradigme souhaitable dans le modèle de données discrètes. Cependant, les méthodes actuelles utilisent généralement des matrices de transition avec des vitesses fixes pendant l'entraînement. Cette approche limite la capacité de représentation des représentations potentielles et également l'espace de conception total. Pour résoudre ces limitations, nous proposons un nouveau cadre de travail appelé Discrete Markov Bridge. Ce cadre est spécialement conçu pour l'apprentissage de représentations discrètes. Notre approche se base sur deux éléments essentiels : l'apprentissage des matrices et l'apprentissage des points. Nous avons effectué un analyse théorique rigoureuse, présentons une garantie formelle du rendement de l'apprentissage des matrices et démontrons la convergence de ce cadre de travail en totalité. De plus, nous avons abordé les restrictions pratiques identifiées dans des études précédentes et analysons la complexité spatiale de cette méthode. Une évaluation expérimentale large montre l'efficacité du Discrete Markov Bridge, atteignant un ELBO (borne inférieure de probabilité) de 1,38 sur le jeu de données Text8 et dépassant les baselines existants. De plus, le modèle proposé montre un rendement relatif sur le jeu de données CIFAR-10, obtenant des résultats similaires à ceux d'un approche générative spécialisée dans les images.",
      "upvotes": 11,
      "discussionId": "683527bb3762eb8b3ea1de6c",
      "projectPage": "https://github.com/Henry839/Discrete-Markov-Bridge/tree/main",
      "githubRepo": "https://github.com/Henry839/Discrete-Markov-Bridge/tree/main",
      "ai_summary": "A novel framework, Discrete Markov Bridge, is introduced for discrete data modeling with Matrix Learning and Score Learning components, demonstrating superior performance compared to existing methods on Text8 and CIFAR-10 datasets.",
      "ai_keywords": [
        "discrete diffusion",
        "variational methods",
        "Discrete Markov Bridge",
        "Matrix Learning",
        "Score Learning",
        "Evidence Lower Bound",
        "ELBO"
      ]
    },
    "publishedAt": "2025-05-26T05:32:12.000Z",
    "title": "Discrete Markov Bridge",
    "summary": "Discrete diffusion has recently emerged as a promising paradigm in discrete\ndata modeling. However, existing methods typically rely on a fixed rate\ntransition matrix during training, which not only limits the expressiveness of\nlatent representations, a fundamental strength of variational methods, but also\nconstrains the overall design space. To address these limitations, we propose\nDiscrete Markov Bridge, a novel framework specifically designed for discrete\nrepresentation learning. Our approach is built upon two key components: Matrix\nLearning and Score Learning. We conduct a rigorous theoretical analysis,\nestablishing formal performance guarantees for Matrix Learning and proving the\nconvergence of the overall framework. Furthermore, we analyze the space\ncomplexity of our method, addressing practical constraints identified in prior\nstudies. Extensive empirical evaluations validate the effectiveness of the\nproposed Discrete Markov Bridge, which achieves an Evidence Lower Bound (ELBO)\nof 1.38 on the Text8 dataset, outperforming established baselines. Moreover,\nthe proposed model demonstrates competitive performance on the CIFAR-10\ndataset, achieving results comparable to those obtained by image-specific\ngeneration approaches.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.19752.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "62649e2b1ed8d81e47ad9b4e",
      "avatarUrl": "/avatars/f33a0b727822fd2ea99dce37fbda3d17.svg",
      "fullname": "Li",
      "name": "henry12348",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.20152",
      "authors": [
        {
          "_id": "6835385ebd4d4208167d15ac",
          "name": "Kai Sun",
          "hidden": false
        },
        {
          "_id": "6835385ebd4d4208167d15ad",
          "name": "Yushi Bai",
          "hidden": false
        },
        {
          "_id": "6835385ebd4d4208167d15ae",
          "name": "Zhen Yang",
          "hidden": false
        },
        {
          "_id": "6835385ebd4d4208167d15af",
          "name": "Jiajie Zhang",
          "hidden": false
        },
        {
          "_id": "6835385ebd4d4208167d15b0",
          "name": "Ji Qi",
          "hidden": false
        },
        {
          "_id": "6835385ebd4d4208167d15b1",
          "name": "Lei Hou",
          "hidden": false
        },
        {
          "_id": "6835385ebd4d4208167d15b2",
          "name": "Juanzi Li",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-26T15:55:28.000Z",
      "submittedOnDailyAt": "2025-05-27T02:29:13.927Z",
      "title": "Pour comprendre les limites, il faut un grand modèle multimodal pour comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il faut comprendre les limites. Pour comprendre les limites, il",
      "submittedOnDailyBy": {
        "_id": "66cdd285c51a915bd5f2d017",
        "avatarUrl": "/avatars/14e5794307e4672b1b51d26b31227e0f.svg",
        "isPro": false,
        "fullname": "Jiajie Zhang",
        "user": "NeoZ123",
        "type": "user"
      },
      "summary": "Utilisant une vision visuelle trouvée à travers un apprentissage contrastif en images de grande échelle naturelle, les grands modèles multimodal (LMMs) ont démontré un rendement impressionnant dans diverses tâches de reconnaissance visuelle. Cependant, l'apprentissage contrastif a des limites intrinsèques au résumé des explications, qui limitent la capacité d'inférence minutieuse et, en particulier, affectent significativement la résolution de problèmes géométriques. Pour améliorer la compréhension géométrique, nous proposons un nouveau cadre d'apprentissage contrastif pour des cas d'haut défi, en combinant un apprentissage contrastif basé sur les images et le contexte. Ceci est réalisé en utilisant des exemples négatifs difficiles générés par des codes de génération de formes, des exemples négatifs basés sur des règles d'explications géométriques changeantes, et des exemples négatifs basés sur des similitudes de captions. Nous utilisons ce méthode d'apprentissage fort pour entraîner CLIP et un LMM pour la résolution de problèmes géométriques. Nos expériences montrent que notre modèle entraîné, MMGeoLM, dépasse considérablement d'autres modèles open-source. Même à une échelle de 7B, MMGeoLM peut concourir avec des modèles puissants comme GPT-4o. De plus, nous avons étudié l'influence de différents méthodes de construction d'exemples négatifs et du nombre d'exemples négatifs sur le rendement des LMMs en termes d'inférence géométrique. Notre code et ensemble de données sont disponibles sur https://github.com/THU-KEG/MMGeoLM.",
      "upvotes": 10,
      "discussionId": "6835385fbd4d4208167d15f0",
      "ai_summary": "A novel hard negative contrastive learning framework improves geometric reasoning in Large Multimodal Models, significantly enhancing their performance compared to existing models.",
      "ai_keywords": [
        "contrastively trained visual encoders",
        "Large Multimodal Models",
        "geometric problem-solving",
        "hard negative contrastive learning",
        "generation-based hard negatives",
        "rule-based negatives",
        "retrieval-based negatives",
        "CLIP",
        "MMCLIP",
        "multimodal math clip",
        "MMGeoLM",
        "geometric reasoning benchmarks"
      ]
    },
    "publishedAt": "2025-05-26T11:55:28.000Z",
    "title": "Hard Negative Contrastive Learning for Fine-Grained Geometric\n  Understanding in Large Multimodal Models",
    "summary": "Benefiting from contrastively trained visual encoders on large-scale natural\nscene images, Large Multimodal Models (LMMs) have achieved remarkable\nperformance across various visual perception tasks. However, the inherent\nlimitations of contrastive learning upon summarized descriptions fundamentally\nrestrict the capabilities of models in meticulous reasoning, particularly in\ncrucial scenarios of geometric problem-solving. To enhance geometric\nunderstanding, we propose a novel hard negative contrastive learning framework\nfor the vision encoder, which combines image-based contrastive learning using\ngeneration-based hard negatives created by perturbing diagram generation code,\nand text-based contrastive learning using rule-based negatives derived from\nmodified geometric descriptions and retrieval-based negatives selected based on\ncaption similarity. We train CLIP using our strong negative learning method,\nnamely MMCLIP (Multimodal Math CLIP), and subsequently train an LMM for\ngeometric problem-solving. Experiments show that our trained model, MMGeoLM,\nsignificantly outperforms other open-source models on three geometric reasoning\nbenchmarks. Even with a size of 7B, it can rival powerful closed-source models\nlike GPT-4o. We further study the impact of different negative sample\nconstruction methods and the number of negative samples on the geometric\nreasoning performance of LMM, yielding fruitful conclusions. The code and\ndataset are available at https://github.com/THU-KEG/MMGeoLM.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.20152.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "66cdd285c51a915bd5f2d017",
      "avatarUrl": "/avatars/14e5794307e4672b1b51d26b31227e0f.svg",
      "fullname": "Jiajie Zhang",
      "name": "NeoZ123",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2505.18759",
      "authors": [
        {
          "_id": "683551c54f3166e8677b43bb",
          "name": "Ruichen Zhang",
          "hidden": false
        },
        {
          "_id": "683551c54f3166e8677b43bc",
          "name": "Rana Muhammad Shahroz Khan",
          "hidden": false
        },
        {
          "_id": "683551c54f3166e8677b43bd",
          "name": "Zhen Tan",
          "hidden": false
        },
        {
          "_id": "683551c54f3166e8677b43be",
          "user": {
            "_id": "6474e1afb68461d5cf7c41cc",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6474e1afb68461d5cf7c41cc/bcoiD_qPrjHUBlB259djg.png",
            "isPro": false,
            "fullname": "Dawei Li",
            "user": "wjldw",
            "type": "user"
          },
          "name": "Dawei Li",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T07:49:14.749Z",
          "hidden": false
        },
        {
          "_id": "683551c54f3166e8677b43bf",
          "name": "Song Wang",
          "hidden": false
        },
        {
          "_id": "683551c54f3166e8677b43c0",
          "name": "Tianlong Chen",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-24T15:54:19.000Z",
      "submittedOnDailyAt": "2025-05-27T04:17:34.631Z",
      "title": "Exploration des raisons efficaces : combinaison de modèles de référence centrés sur les données et CoT",
      "submittedOnDailyBy": {
        "_id": "6474e1afb68461d5cf7c41cc",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6474e1afb68461d5cf7c41cc/bcoiD_qPrjHUBlB259djg.png",
        "isPro": false,
        "fullname": "Dawei Li",
        "user": "wjldw",
        "type": "user"
      },
      "summary": "Le déclin des centres de données, l'édition des données, la sélection et la mélange, incluant potentiellement des méthodes pour créer des modèles de langage plus efficaces (LLMs) pour les étudiants, est un sujet important. Cependant, il n'existe pas encore de cadres de référence détaillés pour évaluer efficacement chaque méthode de déclin. Dans cet article, nous présentons le premier cadre de référence pour les centres de données, DC-CoT, qui étudie la manipulation des données de déclin de la pensée en chaîne (CoT) depuis trois aspects : méthodes, modèles et données, avec l'objectif d'évaluer efficacement. Nous utilisons différents modèles d'apprentissage (par exemple : o4-mini, Gemini-Pro, Claude-3.5) et architectures d'étudiants (par exemple : 3B, 7B paramètres) pour évaluer rigoureusement l'influence de ces manipulations sur le rendement des modèles d'étudiants. En particulier, nous nous concentrons sur la généralisation en interne (IID) et en dehors de la distribution (OOD), et sur la mobilité des domaines de données. L'objectif de cette étude est de fournir une vision pratique et efficace de l'optimisation du déclin de la pensée en chaîne basée sur les données, ce qui favorise le développement de modèles d'apprentissage plus accessibles et puissants. Les données sont disponibles sur https://huggingface.co/datasets/rana-shahroz/DC-COT et le code sur https://anonymous.4open.science/r/DC-COT-FF4C/.",
      "upvotes": 10,
      "discussionId": "683551c64f3166e8677b4424",
      "ai_summary": "DC-CoT provides a comprehensive benchmark for assessing data-centric distillation techniques in chain-of-thought distillation, focusing on performance and generalization across different models and datasets.",
      "ai_keywords": [
        "data-centric distillation",
        "data augmentation",
        "data selection",
        "data mixing",
        "chain-of-thought (CoT)",
        "in-distribution (IID)",
        "out-of-distribution (OOD)",
        "cross-domain transfer"
      ]
    },
    "publishedAt": "2025-05-24T11:54:19.000Z",
    "title": "The Quest for Efficient Reasoning: A Data-Centric Benchmark to CoT\n  Distillation",
    "summary": "Data-centric distillation, including data augmentation, selection, and\nmixing, offers a promising path to creating smaller, more efficient student\nLarge Language Models (LLMs) that retain strong reasoning abilities. However,\nthere still lacks a comprehensive benchmark to systematically assess the effect\nof each distillation approach. This paper introduces DC-CoT, the first\ndata-centric benchmark that investigates data manipulation in chain-of-thought\n(CoT) distillation from method, model and data perspectives. Utilizing various\nteacher models (e.g., o4-mini, Gemini-Pro, Claude-3.5) and student\narchitectures (e.g., 3B, 7B parameters), we rigorously evaluate the impact of\nthese data manipulations on student model performance across multiple reasoning\ndatasets, with a focus on in-distribution (IID) and out-of-distribution (OOD)\ngeneralization, and cross-domain transfer. Our findings aim to provide\nactionable insights and establish best practices for optimizing CoT\ndistillation through data-centric techniques, ultimately facilitating the\ndevelopment of more accessible and capable reasoning models. The dataset can be\nfound at https://huggingface.co/datasets/rana-shahroz/DC-COT, while our code is\nshared in https://anonymous.4open.science/r/DC-COT-FF4C/.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.18759.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "6474e1afb68461d5cf7c41cc",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6474e1afb68461d5cf7c41cc/bcoiD_qPrjHUBlB259djg.png",
      "fullname": "Dawei Li",
      "name": "wjldw",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.19602",
      "authors": [
        {
          "_id": "6835239e7309025530c85ba3",
          "user": {
            "_id": "6540ef0e733c1ce6a6fc989a",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6540ef0e733c1ce6a6fc989a/lyDLbmJ-h4nUmkWZCvWtg.jpeg",
            "isPro": false,
            "fullname": "Kunjun Li",
            "user": "stargazerx0",
            "type": "user"
          },
          "name": "Kunjun Li",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T07:51:58.885Z",
          "hidden": false
        },
        {
          "_id": "6835239e7309025530c85ba4",
          "name": "Zigeng Chen",
          "hidden": false
        },
        {
          "_id": "6835239e7309025530c85ba5",
          "name": "Cheng-Yen Yang",
          "hidden": false
        },
        {
          "_id": "6835239e7309025530c85ba6",
          "name": "Jenq-Neng Hwang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-26T07:11:42.000Z",
      "submittedOnDailyAt": "2025-05-27T01:00:44.064Z",
      "title": "Efficacité mémoire pour le modélisation visuelle avec restauration automatique et réduction adaptative de la cache KV en échelle",
      "submittedOnDailyBy": {
        "_id": "65811eeaa2284a018e51f1ba",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/dH8UZj6Kk5HJkI1DItCNm.jpeg",
        "isPro": true,
        "fullname": "Zigeng Chen",
        "user": "Zigeng",
        "type": "user"
      },
      "summary": "Le modèle autorégressif visuel (VAR) a apporté des améliorations significatives en termes d'efficience, de scalabilité et de génération zero-shot, ce qui a attiré une attention accrue. Cependant, dans les modèles VAR, les techniques spécifiques, à grande échelle et à petite échelle, génèrent une augmentation exponentielle de la cache KV, ce qui implique un consommation significative de mémoire et une grande quantité de calculs. Pour faire face à cette limitation, nous présentons ScaleKV, un nouveau cadre de travail de compression de cache KV adapté pour les modèles VAR. ScaleKV a été conçu sur la base de deux observations clés : la demande de cache différente entre les couches de Transformer et les motifs d'attention différents à différentes échelles. Sur la base de ces données, ScaleKV divise les couches de Transformer en deux groupes fonctionnels : le Désintegrateur et le Réfinateur. Le Désintegrateur montre une attention distribuée sur plusieurs échelles et nécessite un plus grand taille de cache. D'autre part, le Réfinateur se concentre sur le mapping des tokens actuels et traite les détails locaux, ce qui nécessite une cache réduite. ScaleKV identifie le Désintegrateur et le Réfinateur en fonction de l'échelle et optimise le flux de travail d'inférence multi-échelle pour réaliser une gestion de cache différenciée à chaque échelle. Dans l'évaluation de la famille de modèles VAR, Infinity, notre approche montre que la mémoire de cache KV nécessaire pour maintenir la précision au niveau de pixels peut être réduite, ce qui est de 10% du valeur initiale.",
      "upvotes": 9,
      "discussionId": "683523a07309025530c85c45",
      "ai_summary": "ScaleKV compresses the KV cache in Visual Autoregressive models by differentiating drafters and refiners across transformer layers, reducing memory consumption while maintaining high fidelity.",
      "ai_keywords": [
        "Visual Autoregressive",
        "VAR",
        "KV cache",
        "transformer layers",
        "drafters",
        "refiners",
        "memory consumption",
        "Infinity",
        "pixel-level fidelity"
      ]
    },
    "publishedAt": "2025-05-26T03:11:42.000Z",
    "title": "Memory-Efficient Visual Autoregressive Modeling with Scale-Aware KV\n  Cache Compression",
    "summary": "Visual Autoregressive (VAR) modeling has garnered significant attention for\nits innovative next-scale prediction approach, which yields substantial\nimprovements in efficiency, scalability, and zero-shot generalization.\nNevertheless, the coarse-to-fine methodology inherent in VAR results in\nexponential growth of the KV cache during inference, causing considerable\nmemory consumption and computational redundancy. To address these bottlenecks,\nwe introduce ScaleKV, a novel KV cache compression framework tailored for VAR\narchitectures. ScaleKV leverages two critical observations: varying cache\ndemands across transformer layers and distinct attention patterns at different\nscales. Based on these insights, ScaleKV categorizes transformer layers into\ntwo functional groups: drafters and refiners. Drafters exhibit dispersed\nattention across multiple scales, thereby requiring greater cache capacity.\nConversely, refiners focus attention on the current token map to process local\ndetails, consequently necessitating substantially reduced cache capacity.\nScaleKV optimizes the multi-scale inference pipeline by identifying\nscale-specific drafters and refiners, facilitating differentiated cache\nmanagement tailored to each scale. Evaluation on the state-of-the-art\ntext-to-image VAR model family, Infinity, demonstrates that our approach\neffectively reduces the required KV cache memory to 10% while preserving\npixel-level fidelity.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.19602.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "65811eeaa2284a018e51f1ba",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/dH8UZj6Kk5HJkI1DItCNm.jpeg",
      "fullname": "Zigeng Chen",
      "name": "Zigeng",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 5
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2505.19590",
      "authors": [
        {
          "_id": "683523bcb0f9c65224abd710",
          "user": {
            "_id": "6275a465597c70eb8949fce5",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6275a465597c70eb8949fce5/ph4UogqMurMB0hSXZC38w.png",
            "isPro": false,
            "fullname": "Xuandong Zhao",
            "user": "Xuandong",
            "type": "user"
          },
          "name": "Xuandong Zhao",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T07:51:51.514Z",
          "hidden": false
        },
        {
          "_id": "683523bcb0f9c65224abd711",
          "name": "Zhewei Kang",
          "hidden": false
        },
        {
          "_id": "683523bcb0f9c65224abd712",
          "name": "Aosong Feng",
          "hidden": false
        },
        {
          "_id": "683523bcb0f9c65224abd713",
          "name": "Sergey Levine",
          "hidden": false
        },
        {
          "_id": "683523bcb0f9c65224abd714",
          "name": "Dawn Song",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-26T07:01:06.000Z",
      "submittedOnDailyAt": "2025-05-27T01:00:44.089Z",
      "title": "L'objectif de l'apprentissage n'est pas fondé sur la récompense externe.",
      "submittedOnDailyBy": {
        "_id": "6275a465597c70eb8949fce5",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6275a465597c70eb8949fce5/ph4UogqMurMB0hSXZC38w.png",
        "isPro": false,
        "fullname": "Xuandong Zhao",
        "user": "Xuandong",
        "type": "user"
      },
      "summary": "Les méthodes d'apprentissage par renforcement (RL) pour les modèles de langage grands (LLMs) sont efficaces, mais coûteuses et limitées par la dépendance à des normes de développement spécifiques. Nous examinons un cadre d'apprentissage par renforcement avec rétroaction interne (RLIF), qui permet aux LLMs d'apprendre à partir de signaux internes sans nécessiter de données externes ou étiquetées. Nous proposons Intuitor, un méthode de RLIF qui utilise la confiance en soi, appelée \"autoconfiance\", comme le seul signal de niveau. Intuitor remplace le niveau externe par la note d'autoconfiance dans l'apprentissage de politiques de groupe relatives (GRPO), facilitant un apprentissage complet sans dépendance à des normes. Les expériences montrent que Intuitor dépasse le rendement de GRPO dans des cadres de test mathématiques et atteint une généralisation améliorée dans des tâches étranges, comme la génération de code, sans nécessité de solutions de haut rendement ou de cas de test. Notre résultat démontre que les signaux propres du modèle peuvent encourager un apprentissage efficace dans l'expansion du domaine, et que Intuitor est une alternative échellable et compatible avec RLVR, offrant une solution échellable et compatible dans les systèmes d'intelligence artificielle pour des projets autonomes.",
      "upvotes": 8,
      "discussionId": "683523bcb0f9c65224abd736",
      "githubRepo": "https://github.com/sunblaze-ucb/Intuitor",
      "ai_summary": "Intuitor, a Reinforcement Learning from Internal Feedback method, uses self-certainty as a reward signal to enable unsupervised learning of large language models, achieving performance comparable to GRPO on benchmarks and superior generalization.",
      "ai_keywords": [
        "Reinforcement Learning with Verifiable Rewards",
        "Reinforcement Learning from Internal Feedback",
        "Group Relative Policy Optimization",
        "self-certainty",
        "unsupervised learning"
      ]
    },
    "publishedAt": "2025-05-26T03:01:06.000Z",
    "title": "Learning to Reason without External Rewards",
    "summary": "Training large language models (LLMs) for complex reasoning via Reinforcement\nLearning with Verifiable Rewards (RLVR) is effective but limited by reliance on\ncostly, domain-specific supervision. We explore Reinforcement Learning from\nInternal Feedback (RLIF), a framework that enables LLMs to learn from intrinsic\nsignals without external rewards or labeled data. We propose Intuitor, an RLIF\nmethod that uses a model's own confidence, termed self-certainty, as its sole\nreward signal. Intuitor replaces external rewards in Group Relative Policy\nOptimization (GRPO) with self-certainty scores, enabling fully unsupervised\nlearning. Experiments demonstrate that Intuitor matches GRPO's performance on\nmathematical benchmarks while achieving superior generalization to\nout-of-domain tasks like code generation, without requiring gold solutions or\ntest cases. Our findings show that intrinsic model signals can drive effective\nlearning across domains, offering a scalable alternative to RLVR for autonomous\nAI systems where verifiable rewards are unavailable. Code is available at\nhttps://github.com/sunblaze-ucb/Intuitor",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.19590.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6275a465597c70eb8949fce5",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6275a465597c70eb8949fce5/ph4UogqMurMB0hSXZC38w.png",
      "fullname": "Xuandong Zhao",
      "name": "Xuandong",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.16972",
      "authors": [
        {
          "_id": "68351e269f4e0a0f048ea664",
          "name": "Tianduo Wang",
          "hidden": false
        },
        {
          "_id": "68351e269f4e0a0f048ea665",
          "name": "Lu Xu",
          "hidden": false
        },
        {
          "_id": "68351e269f4e0a0f048ea666",
          "name": "Wei Lu",
          "hidden": false
        },
        {
          "_id": "68351e269f4e0a0f048ea667",
          "name": "Shanbo Cheng",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-22T17:51:05.000Z",
      "submittedOnDailyAt": "2025-05-27T00:36:56.992Z",
      "title": "Tensophorus Tensors Toutenso Phoenix : Amélioration par Traduction Back pour le Reconnaissance de Vocalisations",
      "submittedOnDailyBy": {
        "_id": "6352aa7b6cfb8f149814de5e",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1666361939036-noauth.jpeg",
        "isPro": false,
        "fullname": "Tianduo Wang",
        "user": "Tianduo",
        "type": "user"
      },
      "summary": "Le développement récent du reconnaissance de la langue (ASR) a été principalement impulsé par l'utilisation de grands corpus de langue. Cependant, l'expansion de la couverture pour plusieurs langues avec des ressources limitées est un défi extrêmement strict. Dans cet article, nous présentons un processus échelonnable appelé \"Speech Back-Translation\" (SBT) qui utilise des modèles de TTS (Text-to-Speech) pour convertir des grands corpus de texte en audio synthétique, améliorant ainsi les modèles de ASR multilingues. Nous montrons que, en entraînant des modèles de TTS avec environ une douzaine d'heures d'audio réel, on peut augmenter la quantité d'audio synthétisé dans plusieurs centaines de fois, tout en maintenant une haute qualité. Un cadre d'évaluation basé sur la lisibilité a été développé pour évaluer la qualité des audios synthétisés et des étapes claires ont été définies pour déterminer quand les données synthétisées peuvent être utiles pour l'entraînement d'un modèle de ASR. En utilisant SBT, plus de 500 000 heures d'audio synthétisé dans 10 langues ont été générées, ce qui, lors de l'entraînement supplémentaire de Whisper-large-v3, a entraîné une réduction de 30% ou plus du taux d'erreur de lecture moyen. Ces résultats clairement démontrent que SBT démontre l'échelle et l'efficacité dans l'amélioration des systèmes de ASR multilingues.",
      "upvotes": 8,
      "discussionId": "68351e279f4e0a0f048ea689",
      "githubRepo": "https://github.com/TianduoWang/Speech-BT",
      "ai_summary": "Speech Back-Translation enhances multilingual ASR systems by generating high-quality synthetic speech from text corpora, significantly reducing transcription errors.",
      "ai_keywords": [
        "Automatic Speech Recognition",
        "Speech Back-Translation",
        "multilingual ASR",
        "text-to-speech",
        "synthetic speech",
        "intelligibility-based assessment",
        "Whisper-large-v3",
        "transcription error reduction"
      ]
    },
    "publishedAt": "2025-05-22T13:51:05.000Z",
    "title": "From Tens of Hours to Tens of Thousands: Scaling Back-Translation for\n  Speech Recognition",
    "summary": "Recent advances in Automatic Speech Recognition (ASR) have been largely\nfueled by massive speech corpora. However, extending coverage to diverse\nlanguages with limited resources remains a formidable challenge. This paper\nintroduces Speech Back-Translation, a scalable pipeline that improves\nmultilingual ASR models by converting large-scale text corpora into synthetic\nspeech via off-the-shelf text-to-speech (TTS) models. We demonstrate that just\ntens of hours of real transcribed speech can effectively train TTS models to\ngenerate synthetic speech at hundreds of times the original volume while\nmaintaining high quality. To evaluate synthetic speech quality, we develop an\nintelligibility-based assessment framework and establish clear thresholds for\nwhen synthetic data benefits ASR training. Using Speech Back-Translation, we\ngenerate more than 500,000 hours of synthetic speech in ten languages and\ncontinue pre-training Whisper-large-v3, achieving average transcription error\nreductions of over 30\\%. These results highlight the scalability and\neffectiveness of Speech Back-Translation for enhancing multilingual ASR\nsystems.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.16972.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6352aa7b6cfb8f149814de5e",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1666361939036-noauth.jpeg",
      "fullname": "Tianduo Wang",
      "name": "Tianduo",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 6
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2505.13426",
      "authors": [
        {
          "_id": "682c641925f124206513d14d",
          "name": "Liang Chen",
          "hidden": false
        },
        {
          "_id": "682c641925f124206513d14e",
          "name": "Hongcheng Gao",
          "hidden": false
        },
        {
          "_id": "682c641925f124206513d14f",
          "name": "Tianyu Liu",
          "hidden": false
        },
        {
          "_id": "682c641925f124206513d150",
          "name": "Zhiqi Huang",
          "hidden": false
        },
        {
          "_id": "682c641925f124206513d151",
          "name": "Flood Sung",
          "hidden": false
        },
        {
          "_id": "682c641925f124206513d152",
          "name": "Xinyu Zhou",
          "hidden": false
        },
        {
          "_id": "682c641925f124206513d153",
          "name": "Yuxin Wu",
          "hidden": false
        },
        {
          "_id": "682c641925f124206513d154",
          "name": "Baobao Chang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-19T17:54:39.000Z",
      "submittedOnDailyAt": "2025-05-27T00:09:52.653Z",
      "title": "Le apprentissage commence à renforcer les compétences de reconnaissance et d'inférence du modèle de langage visuel.",
      "submittedOnDailyBy": {
        "_id": "61b0a4ce1b3d95b3d1ed9251",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/Wwjr26vdudX5KYVTb8Q0a.png",
        "isPro": false,
        "fullname": "Liang Chen",
        "user": "leonardPKU",
        "type": "user"
      },
      "summary": "Les modèles Vision-Langue (VLMs) montrent des résultats exceptionnels dans diverses tâches multimodales directes, mais dans des environnements interactifs et riches en vision, ils rencontrent des difficultés pour prendre des décisions efficaces. Cette différence signifie que le potentiel des agents autonomes de conduite est considérablement limité. Les leaders des VLMs également échouent dans des jeux simples. D'autre part, nous présentons VLM-Gym. VLM-Gym est un environnement d'apprentissage par renforcement (RL) qui adopte une interface unifiée et des niveaux d'difficulté ajustables et combinables dans plusieurs jeux visuels. En utilisant VLM-Gym, le modèle G0 est entraîné par une auto-évolution dirigée par RL, démontrant des connaissances visuelles impressionnantes et des patrons logiques. Pour atténuer les problèmes générés par la diversité des jeux, nous développons le modèle G1. G1 adopte un état initial renforcé avec des connaissances visuelles avant la configuration du RL. En conséquence, le modèle G1 dépasse tous les jeux et dépasse les modèles de pointe tels que Claude-3.7-Sonnet-Thinking. Des résultats intéressants ont été découverts lors d'une analyse systématique. La capacité des connaissances visuelles et logiques se renforcent mutuellement lors du processus d'entraînement par RL. Le code source incluant VLM-Gym et l'entraînement par RL est disponible sur https://github.com/chenllliang/G1, et connecte avec des futures recherches visant à transformer les VLMs en agents interactifs efficaces.",
      "upvotes": 7,
      "discussionId": "682c641a25f124206513d1d5",
      "githubRepo": "https://github.com/chenllliang/G1",
      "ai_summary": "VLM-Gym addresses the \"knowing-doing\" gap in Vision-Language Models by training them in a diverse RL environment, leading to enhanced perception and reasoning abilities that surpass existing models in interactive games.",
      "ai_keywords": [
        "Vision-Language Models",
        "VLM-Gym",
        "reinforcement learning",
        "RL",
        "G0 models",
        "self-evolution",
        "G1 models",
        "perception-enhanced cold start",
        "RL fine-tuning"
      ]
    },
    "publishedAt": "2025-05-19T13:54:39.000Z",
    "title": "G1: Bootstrapping Perception and Reasoning Abilities of Vision-Language\n  Model via Reinforcement Learning",
    "summary": "Vision-Language Models (VLMs) excel in many direct multimodal tasks but\nstruggle to translate this prowess into effective decision-making within\ninteractive, visually rich environments like games. This ``knowing-doing'' gap\nsignificantly limits their potential as autonomous agents, as leading VLMs\noften performing badly in simple games. To address this, we introduce VLM-Gym,\na curated reinforcement learning (RL) environment featuring diverse visual\ngames with unified interfaces and adjustable, compositional difficulty,\nspecifically designed for scalable multi-game parallel training. Leveraging\nVLM-Gym, we train G0 models using pure RL-driven self-evolution, which\ndemonstrate emergent perception and reasoning patterns. To further mitigate\nchallenges arising from game diversity, we develop G1 models. G1 incorporates a\nperception-enhanced cold start prior to RL fine-tuning. Our resulting G1 models\nconsistently surpass their teacher across all games and outperform leading\nproprietary models like Claude-3.7-Sonnet-Thinking. Systematic analysis reveals\nan intriguing finding: perception and reasoning abilities mutually bootstrap\neach other throughout the RL training process. Source code including VLM-Gym\nand RL training are released at https://github.com/chenllliang/G1 to foster\nfuture research in advancing VLMs as capable interactive agents.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.13426.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "61b0a4ce1b3d95b3d1ed9251",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/Wwjr26vdudX5KYVTb8Q0a.png",
      "fullname": "Liang Chen",
      "name": "leonardPKU",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 16
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2505.19731",
      "authors": [
        {
          "_id": "683588a1650d51732cab05de",
          "user": {
            "_id": "6262880c5eb4fa93219f0064",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6262880c5eb4fa93219f0064/6yyBvRK4Oh7OhjaaweaVN.jpeg",
            "isPro": false,
            "fullname": "Daniil Tiapkin",
            "user": "dtiapkin",
            "type": "user"
          },
          "name": "Daniil Tiapkin",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T10:03:29.430Z",
          "hidden": false
        },
        {
          "_id": "683588a1650d51732cab05df",
          "name": "Daniele Calandriello",
          "hidden": false
        },
        {
          "_id": "683588a1650d51732cab05e0",
          "name": "Denis Belomestny",
          "hidden": false
        },
        {
          "_id": "683588a1650d51732cab05e1",
          "name": "Eric Moulines",
          "hidden": false
        },
        {
          "_id": "683588a1650d51732cab05e2",
          "name": "Alexey Naumov",
          "hidden": false
        },
        {
          "_id": "683588a1650d51732cab05e3",
          "user": {
            "_id": "629f3b18ee05727ce328ccbe",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1669189789447-629f3b18ee05727ce328ccbe.jpeg",
            "isPro": false,
            "fullname": "Kashif Rasul",
            "user": "kashif",
            "type": "user"
          },
          "name": "Kashif Rasul",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-05-27T09:40:50.326Z",
          "hidden": false
        },
        {
          "_id": "683588a1650d51732cab05e4",
          "user": {
            "_id": "651e97156d92456bdf5ace6b",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/651e97156d92456bdf5ace6b/KKfdZGPAcWPdqycp9SulH.jpeg",
            "isPro": false,
            "fullname": "Michal Valko",
            "user": "misovalko",
            "type": "user"
          },
          "name": "Michal Valko",
          "status": "extracted_confirmed",
          "statusLastChangedAt": "2025-05-27T10:00:09.731Z",
          "hidden": false
        },
        {
          "_id": "683588a1650d51732cab05e5",
          "name": "Pierre Menard",
          "hidden": false
        }
      ],
      "mediaUrls": [
        "https://cdn-uploads.huggingface.co/production/uploads/6262880c5eb4fa93219f0064/F7nWvm2sO5QXTLRnB1k6e.png",
        "https://cdn-uploads.huggingface.co/production/uploads/6262880c5eb4fa93219f0064/Fuzzt-cOiMSOCevLVjkW-.png"
      ],
      "publishedAt": "2025-05-26T09:17:32.000Z",
      "submittedOnDailyAt": "2025-05-27T08:13:23.799Z",
      "title": "Mira à l'avenir pour accélérer l'apprentissage naturel grâce à la rétroaction humaine",
      "submittedOnDailyBy": {
        "_id": "6262880c5eb4fa93219f0064",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6262880c5eb4fa93219f0064/6yyBvRK4Oh7OhjaaweaVN.jpeg",
        "isPro": false,
        "fullname": "Daniil Tiapkin",
        "user": "dtiapkin",
        "type": "user"
      },
      "summary": "L'apprentissage des valeurs par l'apprentissage par récompense (RLHF) se concentre sur les modèles de récompense, en supposant des structures de préférences comme le modèle de Brady-Terry, mais il est difficile de préciser la complexe préférence réelle que les humains possèdent (par exemple, non transmissible). L'apprentissage des valeurs basé sur les jeux de Nash (NLHF) aborde l'équilibre des jeux de préférences complexes et résout ces problèmes directement. Dans cette étude, on présente un algorithme d'apprentissage en ligne basé sur Nash-MP utilisant l'algorithme d'optimisation de Nash-MP. L'analyse théorique montre que Nash-MP converge linéairement à l'équilibre de Nash beta-normalisé. Spécifiquement, la variance KL par rapport à la politique optimale diminue à une vitesse de (1+2beta)^{-N/2}. De plus, on montre une convergence linéaire uniforme sur l'erreur de calcul et sur l'espace des logarithmes de probabilités, sans dépendre du taille de l'espace d'actions. On propose une version approximative de Nash-MP évaluée par des méthodes de descente de gradient et on effectue des tests d'application. Enfin, on décrit des stratégies pratiques pour le fine-tuning de modèles de langage grands et on réalise des expériences qui ont démontré la compatibilité avec des méthodes existantes et un rendement fort.",
      "upvotes": 5,
      "discussionId": "683588a2650d51732cab0612",
      "ai_summary": "Nash Mirror Prox is an online algorithm for Nash Learning from Human Feedback that achieves linear convergence to the Nash equilibrium and is applicable for fine-tuning language models.",
      "ai_keywords": [
        "Nash Learning from Human Feedback",
        "Nash Mirror Prox",
        "Mirror Prox",
        "KL-divergence",
        "Nash equilibrium",
        "exploitability gap",
        "span semi-norm",
        "log-probabilities",
        "stochastic policy gradients",
        "fine-tuning",
        "large language models"
      ]
    },
    "publishedAt": "2025-05-26T05:17:32.000Z",
    "title": "Accelerating Nash Learning from Human Feedback via Mirror Prox",
    "summary": "Traditional Reinforcement Learning from Human Feedback (RLHF) often relies on\nreward models, frequently assuming preference structures like the Bradley-Terry\nmodel, which may not accurately capture the complexities of real human\npreferences (e.g., intransitivity). Nash Learning from Human Feedback (NLHF)\noffers a more direct alternative by framing the problem as finding a Nash\nequilibrium of a game defined by these preferences. In this work, we introduce\nNash Mirror Prox (Nash-MP), an online NLHF algorithm that leverages\nthe Mirror Prox optimization scheme to achieve fast and stable convergence to\nthe Nash equilibrium. Our theoretical analysis establishes that Nash-MP\nexhibits last-iterate linear convergence towards the beta-regularized Nash\nequilibrium. Specifically, we prove that the KL-divergence to the optimal\npolicy decreases at a rate of order (1+2beta)^{-N/2}, where N is a number\nof preference queries. We further demonstrate last-iterate linear convergence\nfor the exploitability gap and uniformly for the span semi-norm of\nlog-probabilities, with all these rates being independent of the size of the\naction space. Furthermore, we propose and analyze an approximate version of\nNash-MP where proximal steps are estimated using stochastic policy gradients,\nmaking the algorithm closer to applications. Finally, we detail a practical\nimplementation strategy for fine-tuning large language models and present\nexperiments that demonstrate its competitive performance and compatibility with\nexisting methods.",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/6262880c5eb4fa93219f0064/F7nWvm2sO5QXTLRnB1k6e.png",
      "https://cdn-uploads.huggingface.co/production/uploads/6262880c5eb4fa93219f0064/Fuzzt-cOiMSOCevLVjkW-.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.19731.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6262880c5eb4fa93219f0064",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6262880c5eb4fa93219f0064/6yyBvRK4Oh7OhjaaweaVN.jpeg",
      "fullname": "Daniil Tiapkin",
      "name": "dtiapkin",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 4
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.19640",
      "authors": [
        {
          "_id": "68353e3f9f4e0a0f0496d0c6",
          "name": "Roy Xie",
          "hidden": false
        },
        {
          "_id": "68353e3f9f4e0a0f0496d0c7",
          "name": "David Qiu",
          "hidden": false
        },
        {
          "_id": "68353e3f9f4e0a0f0496d0c8",
          "name": "Deepak Gopinath",
          "hidden": false
        },
        {
          "_id": "68353e3f9f4e0a0f0496d0c9",
          "name": "Dong Lin",
          "hidden": false
        },
        {
          "_id": "68353e3f9f4e0a0f0496d0ca",
          "name": "Yanchao Sun",
          "hidden": false
        },
        {
          "_id": "68353e3f9f4e0a0f0496d0cb",
          "name": "Chong Wang",
          "hidden": false
        },
        {
          "_id": "68353e3f9f4e0a0f0496d0cc",
          "name": "Saloni Potdar",
          "hidden": false
        },
        {
          "_id": "68353e3f9f4e0a0f0496d0cd",
          "name": "Bhuwan Dhingra",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-26T07:58:17.000Z",
      "submittedOnDailyAt": "2025-05-27T02:56:39.316Z",
      "title": "Intralíquido Residencia de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de Riesgo de",
      "submittedOnDailyBy": {
        "_id": "6555a124a6554059711b58a2",
        "avatarUrl": "/avatars/222bb6b8f252d6c2bbd4cf35a54fc1c9.svg",
        "isPro": false,
        "fullname": "Roy",
        "user": "RRoy233",
        "type": "user"
      },
      "summary": "La théorie de la logique continue (CoT) améliore considérablement la capacité d'inférence des modèles de langage grands (LLM). Cependant, la théorie de la logique continue augmente l'inefficacité et le temps de réponse initial (TTFT), ce qui affecte l'efficacité. Nous proposons un nouvel approche d'apprentissage pour des modèles de logique qui combine la théorie de la logique continue et la réponse par apprentissage par renforcement (RL). Nous observons que les modèles peuvent effectuer des logiques de manière croisée et confirmons qu'ils peuvent encore s'améliorer. Nous introduisons une récompense basée sur des règles simples et efficaces pour guider le modèle de politique vers une voie logique précise en utilisant des signaux intermédiaires générés par la logique croisée. Une étude extensive sur cinq ensembles de données différents et trois algorithmes d'apprentissage par renforcement (PPO, GRPO, REINFORCE++) montre un amélioration uniforme dans la théorie de la logique et la réponse, sans nécessité de tools externes. Spécifiquement, notre approche réduit en moyenne le TTFT de plus de 80% et améliore la précision de Pass@1 de 19,3%. De plus, notre méthode montre une forte capacité de généralisation dans des ensembles de données complexes de logique (par exemple, MATH, GPQA, MMLU), car elle a été entraînée uniquement sur des ensembles de données de réponse et de théorie de la logique. De plus, nous avons effectué un analyse détaillée sur la modélisation des récompenses conditionnelles et nous avons fourni de nombreux feedbacks précieux.",
      "upvotes": 5,
      "discussionId": "68353e409f4e0a0f0496d0fb",
      "ai_summary": "A reinforcement learning-guided training paradigm enhances large language models' reasoning efficiency and performance for multi-hop questions by interleaving thinking and answering.",
      "ai_keywords": [
        "chain-of-thought",
        "large language models",
        "reasoning capabilities",
        "time-to-first-token",
        "reinforcement learning",
        "interleaved reasoning",
        "rule-based reward",
        "reward modeling",
        "multi-hop questions",
        "think-answer reasoning",
        "Pass@1 accuracy",
        "MATH",
        "GPQA",
        "MMLU",
        "PPO",
        "GRPO",
        "REINFORCE++"
      ]
    },
    "publishedAt": "2025-05-26T03:58:17.000Z",
    "title": "Interleaved Reasoning for Large Language Models via Reinforcement\n  Learning",
    "summary": "Long chain-of-thought (CoT) significantly enhances large language models'\n(LLM) reasoning capabilities. However, the extensive reasoning traces lead to\ninefficiencies and an increased time-to-first-token (TTFT). We propose a novel\ntraining paradigm that uses reinforcement learning (RL) to guide reasoning LLMs\nto interleave thinking and answering for multi-hop questions. We observe that\nmodels inherently possess the ability to perform interleaved reasoning, which\ncan be further enhanced through RL. We introduce a simple yet effective\nrule-based reward to incentivize correct intermediate steps, which guides the\npolicy model toward correct reasoning paths by leveraging intermediate signals\ngenerated during interleaved reasoning. Extensive experiments conducted across\nfive diverse datasets and three RL algorithms (PPO, GRPO, and REINFORCE++)\ndemonstrate consistent improvements over traditional think-answer reasoning,\nwithout requiring external tools. Specifically, our approach reduces TTFT by\nover 80% on average and improves up to 19.3% in Pass@1 accuracy. Furthermore,\nour method, trained solely on question answering and logical reasoning\ndatasets, exhibits strong generalization ability to complex reasoning datasets\nsuch as MATH, GPQA, and MMLU. Additionally, we conduct in-depth analysis to\nreveal several valuable insights into conditional reward modeling.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.19640.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6555a124a6554059711b58a2",
      "avatarUrl": "/avatars/222bb6b8f252d6c2bbd4cf35a54fc1c9.svg",
      "fullname": "Roy",
      "name": "RRoy233",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2505.19427",
      "authors": [
        {
          "_id": "683525ac1c31d709ba52273e",
          "name": "Sihan Chen",
          "hidden": false
        },
        {
          "_id": "683525ac1c31d709ba52273f",
          "name": "Dan Zhao",
          "hidden": false
        },
        {
          "_id": "683525ac1c31d709ba522740",
          "name": "Jongwoo Ko",
          "hidden": false
        },
        {
          "_id": "683525ac1c31d709ba522741",
          "name": "Colby Banbury",
          "hidden": false
        },
        {
          "_id": "683525ac1c31d709ba522742",
          "name": "Huiping Zhuang",
          "hidden": false
        },
        {
          "_id": "683525ac1c31d709ba522743",
          "name": "Luming Liang",
          "hidden": false
        },
        {
          "_id": "683525ac1c31d709ba522744",
          "user": {
            "_id": "64ad94f05a4a60156925ec96",
            "avatarUrl": "/avatars/643bdb076e703bfcc89cec6fccb756c6.svg",
            "isPro": false,
            "fullname": "Tianyi Chen",
            "user": "tianyic",
            "type": "user"
          },
          "name": "Tianyi Chen",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T07:51:46.088Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-26T02:37:32.000Z",
      "submittedOnDailyAt": "2025-05-27T01:10:19.909Z",
      "title": "WINA : Amélioration de la vitesse d'inférence des modèles de langage grands en utilisant l'activation de neurones avec des informations de poids",
      "submittedOnDailyBy": {
        "_id": "64ad94f05a4a60156925ec96",
        "avatarUrl": "/avatars/643bdb076e703bfcc89cec6fccb756c6.svg",
        "isPro": false,
        "fullname": "Tianyi Chen",
        "user": "tianyic",
        "type": "user"
      },
      "summary": "Avec l'augmentation de la charge de calcul des modèles de langage grands (LLMs), l'efficacité dans l'inférence et la stratégie d'activation ont pris une importance croissante. Dans les derniers méthodes, des stratégies d'activation sélectives comme Mixture-of-Experts (MoE) sont utilisées, mais ces méthodes nécessitent un entraînement spécial. Les méthodes d'activation rares, sans entraînement, peuvent être largement appliquées via des conceptions \"plug-and-play\" et présentent une efficacité élevée en ressources. Cependant, la plupart des méthodes actuelles décident uniquement l'activation en fonction du taille des états cachés, ce qui conduit à des erreurs d'approximation élevées et à une infériorité de la précision de l'inférence. Pour résoudre ces limitations, nous proposons un nouveau cadre d'activation rare sans entraînement appelé Weight Informed Neuron Activation (WINA). Ce méthode considère à la fois le taille des états cachés et la norme ell_2 des colonnes de la matrice de poids. De cette manière, on peut atteindre une stratégie d'activation rare avec des garanties théoriques offrant un seuil supérieur plus proche de la meilleure approximation que la technologie actuelle. Expérimentalement, WINA dépasse les méthodes les plus avancées (comme TEAL) à la même niveau d'activation rare et améliore l'efficacité moyenne de 2,94% ou plus. Ces résultats montrent que WINA établit une nouvelle frontière de performance pour l'activation rare sans entraînement dans l'inférence des LLMs, et définit un nouveau standard pour le développement de méthodes rares sans entraînement et l'efficacité dans l'inférence. Le code source est disponible sur https://github.com/microsoft/wina.",
      "upvotes": 5,
      "discussionId": "683525ac1c31d709ba52277c",
      "ai_summary": "WINA, a training-free sparse activation framework for large language models, improves inference accuracy by considering hidden state magnitudes and weight matrix norms, outperforming existing methods.",
      "ai_keywords": [
        "Mixture-of-Experts (MoE)",
        "sparse activation",
        "hidden state magnitudes",
        "column-wise $\\ell_2$-norms",
        "weight matrices",
        "sparsification strategy",
        "approximation error bounds",
        "training-free sparse activation",
        "large language models"
      ]
    },
    "publishedAt": "2025-05-25T22:37:32.000Z",
    "title": "WINA: Weight Informed Neuron Activation for Accelerating Large Language\n  Model Inference",
    "summary": "The growing computational demands of large language models (LLMs) make\nefficient inference and activation strategies increasingly critical. While\nrecent approaches, such as Mixture-of-Experts (MoE), leverage selective\nactivation but require specialized training, training-free sparse activation\nmethods offer broader applicability and superior resource efficiency through\ntheir plug-and-play design. However, many existing methods rely solely on\nhidden state magnitudes to determine activation, resulting in high\napproximation errors and suboptimal inference accuracy. To address these\nlimitations, we propose WINA (Weight Informed Neuron Activation), a novel,\nsimple, and training-free sparse activation framework that jointly considers\nhidden state magnitudes and the column-wise ell_2-norms of weight matrices.\nWe show that this leads to a sparsification strategy that obtains optimal\napproximation error bounds with theoretical guarantees tighter than existing\ntechniques. Empirically, WINA also outperforms state-of-the-art methods (e.g.,\nTEAL) by up to 2.94% in average performance at the same sparsity levels,\nacross a diverse set of LLM architectures and datasets. These results position\nWINA as a new performance frontier for training-free sparse activation in LLM\ninference, advancing training-free sparse activation methods and setting a\nrobust baseline for efficient inference. The source code is available at\nhttps://github.com/microsoft/wina.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.19427.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64ad94f05a4a60156925ec96",
      "avatarUrl": "/avatars/643bdb076e703bfcc89cec6fccb756c6.svg",
      "fullname": "Tianyi Chen",
      "name": "tianyic",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.18822",
      "authors": [
        {
          "_id": "683528d8c682e155a8b9a80f",
          "user": {
            "_id": "64ce05c631c655ff8a2e183c",
            "avatarUrl": "/avatars/f2de7f8a1348b05f46946085e3e9718e.svg",
            "isPro": false,
            "fullname": "Shijue Huang",
            "user": "JoeYing",
            "type": "user"
          },
          "name": "Shijue Huang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T10:03:37.508Z",
          "hidden": false
        },
        {
          "_id": "683528d8c682e155a8b9a810",
          "name": "Hongru Wang",
          "hidden": false
        },
        {
          "_id": "683528d8c682e155a8b9a811",
          "name": "Wanjun Zhong",
          "hidden": false
        },
        {
          "_id": "683528d8c682e155a8b9a812",
          "name": "Zhaochen Su",
          "hidden": false
        },
        {
          "_id": "683528d8c682e155a8b9a813",
          "name": "Jiazhan Feng",
          "hidden": false
        },
        {
          "_id": "683528d8c682e155a8b9a814",
          "name": "Bowen Cao",
          "hidden": false
        },
        {
          "_id": "683528d8c682e155a8b9a815",
          "name": "Yi R. Fung",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-24T18:46:50.000Z",
      "submittedOnDailyAt": "2025-05-27T07:17:54.612Z",
      "title": "AdaCtrl : Adaptation à la Difficulté à travers la Théorie du Contrôle et l'Adaptation de Buzz Dining",
      "submittedOnDailyBy": {
        "_id": "64ce05c631c655ff8a2e183c",
        "avatarUrl": "/avatars/f2de7f8a1348b05f46946085e3e9718e.svg",
        "isPro": false,
        "fullname": "Shijue Huang",
        "user": "JoeYing",
        "type": "user"
      },
      "summary": "Les modèles logiques d'échelle modernes montrent la capacité de résoudre des problèmes impressionnants en utilisant des stratégies logiques complexes. Cependant, ils souvent rencontrent des difficultés à équilibrer l'efficience et l'efficacité, générant des chaînes de raisonnement longues même pour des problèmes simples. Dans cet article, nous proposons un nouveau cadre appelé AdaCtrl. Ce cadre soutient l'équilibre cognitif de la difficulté logique et permet que l'analyse logique profonde soit contrôlée explicitement par l'utilisateur. AdaCtrl ajuste la longueur de la raison logique de manière dynamique en fonction de la difficulté du problème, permettant à l'utilisateur de contrôler directement l'équilibre logique pour choisir entre efficience et efficacité. Ce méthode est mise en œuvre par une chaîne d'entraînement en deux étapes : la première se concentre sur l'ajustement initial micro, où l'on entraîne la capacité d'ajustement de la difficulté cognitive et l'équilibre logique, et la seconde sur l'étape d'apprentissage par renforcement (RL), où la stratégie logique adaptative du modèle est refinée et l'évaluation de la difficulté de l'utilisateur est ajustée. Pour encourager un mode interactif intuitif de l'utilisateur, des étiquettes explicites basées sur la longueur sont conçues. Les résultats des expériences montrent que AdaCtrl modifie la longueur de la raison logique en fonction de la difficulté évaluée, améliorant le rendement par rapport aux lignes d'entraînement basées sur des standards, réduisant de 10,06% et 12,14% la longueur des réponses dans les jeux de données AIME2024 et AIME2025 respectivement, et de 62,05% et 91,04% dans les jeux de données MATH500 et GSM8K. De plus, AdaCtrl permet un contrôle précis de l'équilibre logique par l'utilisateur et fournit des réponses adaptées aux besoins spécifiques.",
      "upvotes": 5,
      "discussionId": "683528d9c682e155a8b9a852",
      "ai_summary": "AdaCtrl, a novel framework, dynamically adjusts reasoning length based on problem difficulty and user control, improving performance and reducing response length across various datasets compared to standard training methods.",
      "ai_keywords": [
        "AdaCtrl",
        "adaptive reasoning budget allocation",
        "self-assessed problem difficulty",
        "difficulty-aware reinforcement learning",
        "two-stage training pipeline",
        "cold-start fine-tuning"
      ]
    },
    "publishedAt": "2025-05-24T14:46:50.000Z",
    "title": "AdaCtrl: Towards Adaptive and Controllable Reasoning via\n  Difficulty-Aware Budgeting",
    "summary": "Modern large reasoning models demonstrate impressive problem-solving\ncapabilities by employing sophisticated reasoning strategies. However, they\noften struggle to balance efficiency and effectiveness, frequently generating\nunnecessarily lengthy reasoning chains for simple problems. In this work, we\npropose AdaCtrl, a novel framework to support both difficulty-aware adaptive\nreasoning budget allocation and explicit user control over reasoning depth.\nAdaCtrl dynamically adjusts its reasoning length based on self-assessed problem\ndifficulty, while also allowing users to manually control the budget to\nprioritize either efficiency or effectiveness. This is achieved through a\ntwo-stage training pipeline: an initial cold-start fine-tuning phase to instill\nthe ability to self-aware difficulty and adjust reasoning budget, followed by a\ndifficulty-aware reinforcement learning (RL) stage that refines the model's\nadaptive reasoning strategies and calibrates its difficulty assessments based\non its evolving capabilities during online training. To enable intuitive user\ninteraction, we design explicit length-triggered tags that function as a\nnatural interface for budget control. Empirical results show that AdaCtrl\nadapts reasoning length based on estimated difficulty, compared to the standard\ntraining baseline that also incorporates fine-tuning and RL, it yields\nperformance improvements and simultaneously reduces response length by 10.06%\nand 12.14% on the more challenging AIME2024 and AIME2025 datasets, which\nrequire elaborate reasoning, and by 62.05% and 91.04% on the MATH500 and GSM8K\ndatasets, where more concise responses are sufficient. Furthermore, AdaCtrl\nenables precise user control over the reasoning budget, allowing for tailored\nresponses to meet specific needs.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.18822.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64ce05c631c655ff8a2e183c",
      "avatarUrl": "/avatars/f2de7f8a1348b05f46946085e3e9718e.svg",
      "fullname": "Shijue Huang",
      "name": "JoeYing",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 9
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.20278",
      "authors": [
        {
          "_id": "68353261bc28496925a185c9",
          "name": "Hoyeon Chang",
          "hidden": false
        },
        {
          "_id": "68353261bc28496925a185ca",
          "name": "Jinho Park",
          "hidden": false
        },
        {
          "_id": "68353261bc28496925a185cb",
          "name": "Hanseul Cho",
          "hidden": false
        },
        {
          "_id": "68353261bc28496925a185cc",
          "name": "Sohee Yang",
          "hidden": false
        },
        {
          "_id": "68353261bc28496925a185cd",
          "name": "Miyoung Ko",
          "hidden": false
        },
        {
          "_id": "68353261bc28496925a185ce",
          "name": "Hyeonbin Hwang",
          "hidden": false
        },
        {
          "_id": "68353261bc28496925a185cf",
          "name": "Seungpil Won",
          "hidden": false
        },
        {
          "_id": "68353261bc28496925a185d0",
          "name": "Dohaeng Lee",
          "hidden": false
        },
        {
          "_id": "68353261bc28496925a185d1",
          "name": "Youbin Ahn",
          "hidden": false
        },
        {
          "_id": "68353261bc28496925a185d2",
          "name": "Minjoon Seo",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-26T17:55:15.000Z",
      "submittedOnDailyAt": "2025-05-27T02:04:40.615Z",
      "title": "Le Principe de Caballejo : Marco de Compréhension de l'Échelonnabilité Composite",
      "submittedOnDailyBy": {
        "_id": "64d0d6684dfd5df70744b237",
        "avatarUrl": "/avatars/4ea57bfd407e8cb727c624f64af75478.svg",
        "isPro": false,
        "fullname": "Chang",
        "user": "Hoyeon",
        "type": "user"
      },
      "summary": "Les modèles de langue générale sont spécialisés dans le reconnaissance de motifs, tandis que leur faiblesse réside dans leur capacité à généraliser de manière systématique. Nous proposons le principe de couverture : dans un cadre de données, les modèles qui dépendent principalement du reconnaissance de motifs peuvent échouer à la généralisation fiable en ne remplaçant pas le cadre qui fournit les mêmes résultats dans le même contexte. Nous démontrons que ce cadre renforce la capacité de généralisation des transformers. Tout d'abord, le taille de la collection de tokens nécessaire pour la généralisation à la deuxième étape augmente au carré minimal, et bien que les paramètres soient multipliés par 20, l'efficacité des données ne s'améliore pas. De plus, dans des tâches structurelles où les chemins sont incertains, une variable influence le résultat par des multiples chemins de calcul. Les transformers apprennent des représentations contextuelles qui détruisent l'échangabilité et l'efficacité des deux côtés. Troisièmement, les sous-objets de la \"Cohérence de la pensée\" améliorent l'efficacité des données dans des tâches de plusieurs étapes, mais font face à des difficultés liées à l'incertitude des chemins. Enfin, nous expliquons l'algorithme basé sur la structure et nous distinguons trois méthodes de généralisation des réseaux neuronaux : structurale (limitée par la couverture), attribut-basée (utilisant l'invariance des algorithmes) et opérateurs partagés (réutilisation de fonctions). Dans ce cadre conceptuel, nos résultats contextualisent les résultats et révèlent la nécessité d'une nouvelle architecture. En résumé, le principe de couverture fournit une vision intégrale pour comprendre les raisons structurales, ce qui nécessite des innovations fondamentales dans l'architecture ou dans l'entraînement.",
      "upvotes": 4,
      "discussionId": "68353261bc28496925a185ef",
      "ai_summary": "The coverage principle highlights limitations in Transformers' compositional generalization, emphasizing the need for new architectures or training methods to achieve systematic compositionality by distinguishing different mechanisms of generalization.",
      "ai_keywords": [
        "coverage principle",
        "data-centric framework",
        "sequential application",
        "pattern matching",
        "compositional generalization",
        "Transformers",
        "two-hop generalization",
        "token set size",
        "training data efficiency",
        "context-dependent state representations",
        "performance",
        "interoperability",
        "Chain-of-Thought supervision",
        "multi-hop tasks",
        "path ambiguity",
        "structure-based",
        "property-based",
        "shared-operator",
        "architectural innovations"
      ]
    },
    "publishedAt": "2025-05-26T13:55:15.000Z",
    "title": "The Coverage Principle: A Framework for Understanding Compositional\n  Generalization",
    "summary": "Large language models excel at pattern matching, yet often fall short in\nsystematic compositional generalization. We propose the coverage principle: a\ndata-centric framework showing that models relying primarily on pattern\nmatching for compositional tasks cannot reliably generalize beyond substituting\nfragments that yield identical results when used in the same contexts. We\ndemonstrate that this framework has a strong predictive power for the\ngeneralization capabilities of Transformers. First, we derive and empirically\nconfirm that the training data required for two-hop generalization grows at\nleast quadratically with the token set size, and the training data efficiency\ndoes not improve with 20x parameter scaling. Second, for compositional tasks\nwith path ambiguity where one variable affects the output through multiple\ncomputational paths, we show that Transformers learn context-dependent state\nrepresentations that undermine both performance and interoperability. Third,\nChain-of-Thought supervision improves training data efficiency for multi-hop\ntasks but still struggles with path ambiguity. Finally, we outline a\nmechanism-based taxonomy that distinguishes three ways neural networks\ncan generalize: structure-based (bounded by coverage), property-based\n(leveraging algebraic invariances), and shared-operator (through function\nreuse). This conceptual lens contextualizes our results and highlights where\nnew architectural ideas are needed to achieve systematic compositionally.\nOverall, the coverage principle provides a unified lens for understanding\ncompositional reasoning, and underscores the need for fundamental architectural\nor training innovations to achieve truly systematic compositionality.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.20278.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64d0d6684dfd5df70744b237",
      "avatarUrl": "/avatars/4ea57bfd407e8cb727c624f64af75478.svg",
      "fullname": "Chang",
      "name": "Hoyeon",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 4
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2505.20254",
      "authors": [
        {
          "_id": "683528109f968fc5c604495f",
          "user": {
            "_id": "5f12485c0c833276f61f1afb",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1595033594228-noauth.jpeg",
            "isPro": false,
            "fullname": "Xiangchen Song",
            "user": "xiangchensong",
            "type": "user"
          },
          "name": "Xiangchen Song",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-05-27T02:48:53.929Z",
          "hidden": false
        },
        {
          "_id": "683528109f968fc5c6044960",
          "user": {
            "_id": "64755a83e0b188d3cb2579d8",
            "avatarUrl": "/avatars/2c50590905f4bd398a4c9991e1b4b5bb.svg",
            "isPro": false,
            "fullname": "Aashiq Muhamed",
            "user": "aashiqmuhamed",
            "type": "user"
          },
          "name": "Aashiq Muhamed",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T07:51:25.328Z",
          "hidden": false
        },
        {
          "_id": "683528109f968fc5c6044961",
          "name": "Yujia Zheng",
          "hidden": false
        },
        {
          "_id": "683528109f968fc5c6044962",
          "name": "Lingjing Kong",
          "hidden": false
        },
        {
          "_id": "683528109f968fc5c6044963",
          "name": "Zeyu Tang",
          "hidden": false
        },
        {
          "_id": "683528109f968fc5c6044964",
          "name": "Mona T. Diab",
          "hidden": false
        },
        {
          "_id": "683528109f968fc5c6044965",
          "name": "Virginia Smith",
          "hidden": false
        },
        {
          "_id": "683528109f968fc5c6044966",
          "name": "Kun Zhang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-26T17:31:36.000Z",
      "submittedOnDailyAt": "2025-05-27T01:20:40.055Z",
      "title": "La description du dispositif doit mettre l'accent sur la concordance des vecteurs de caractéristiques des SAEs.",
      "submittedOnDailyBy": {
        "_id": "64755a83e0b188d3cb2579d8",
        "avatarUrl": "/avatars/2c50590905f4bd398a4c9991e1b4b5bb.svg",
        "isPro": false,
        "fullname": "Aashiq Muhamed",
        "user": "aashiqmuhamed",
        "type": "user"
      },
      "summary": "Les Autoencodeurs Spatiaux (AEs) sont une outil important pour l'explicabilité mécanique (MI), permettant la décomposition de l'activation de la réseau neuronal en caractéristiques interprétables. Cependant, il a été confirmé que les caractéristiques apprises par un AE sont discontinues dans d'autres ensembles d'entraînement, ce qui affecte la confiance et l'efficacité de la recherche en MI. Dans cet article, nous argumentons que l'explicabilité mécanique doit prioritiser la consistence des caractéristiques d'un AE, avec l'objectif de réaliser une convergence fiable de caractéristiques équivalentes dans des entraînements indépendants. Nous proposons ici l'utilisation pratique du Coefficient de Corrélation de la Moyenne du Dictionnaire Partiel (PW-MCC) comme métrique, montrant que nous pouvons atteindre un haut niveau de consistence (0,80 dans les AE de TopK d'activations d'un LLM). Notre contribution met en avant les avantages de la prioritisation de la consistence et fournit une base théorique et une validation synthétique par l'organisation du modèle, prouvant la fiabilité de PW-MCC comme proxy pour la récupération de valeurs réelles. De plus, nous étendons ces résultats aux données d'un LLM à grande échelle, montrant que une haute consistence des caractéristiques a une forte association avec la similitude significative de l'interprétation des caractéristiques apprises. Nous encourageons la communauté à mesurer systématiquement la consistence des caractéristiques et à promouvoir un développement solide et accumulatif de la MI.",
      "upvotes": 4,
      "discussionId": "683528159f968fc5c6044aff",
      "githubRepo": "https://github.com/xiangchensong/sae-feature-consistency",
      "ai_summary": "Prioritizing feature consistency in sparse autoencoders improves mechanistic interpretability of neural networks by ensuring reliable and interpretable features.",
      "ai_keywords": [
        "Sparse Autoencoders (SAEs)",
        "mechanistic interpretability (MI)",
        "feature consistency",
        "Pairwise Dictionary Mean Correlation Coefficient (PW-MCC)",
        "TopK SAEs",
        "LLM activations",
        "synthetic validation",
        "semantic similarity",
        "learned feature explanations"
      ]
    },
    "publishedAt": "2025-05-26T13:31:36.000Z",
    "title": "Position: Mechanistic Interpretability Should Prioritize Feature\n  Consistency in SAEs",
    "summary": "Sparse Autoencoders (SAEs) are a prominent tool in mechanistic\ninterpretability (MI) for decomposing neural network activations into\ninterpretable features. However, the aspiration to identify a canonical set of\nfeatures is challenged by the observed inconsistency of learned SAE features\nacross different training runs, undermining the reliability and efficiency of\nMI research. This position paper argues that mechanistic interpretability\nshould prioritize feature consistency in SAEs -- the reliable convergence to\nequivalent feature sets across independent runs. We propose using the Pairwise\nDictionary Mean Correlation Coefficient (PW-MCC) as a practical metric to\noperationalize consistency and demonstrate that high levels are achievable\n(0.80 for TopK SAEs on LLM activations) with appropriate architectural choices.\nOur contributions include detailing the benefits of prioritizing consistency;\nproviding theoretical grounding and synthetic validation using a model\norganism, which verifies PW-MCC as a reliable proxy for ground-truth recovery;\nand extending these findings to real-world LLM data, where high feature\nconsistency strongly correlates with the semantic similarity of learned feature\nexplanations. We call for a community-wide shift towards systematically\nmeasuring feature consistency to foster robust cumulative progress in MI.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.20254.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64755a83e0b188d3cb2579d8",
      "avatarUrl": "/avatars/2c50590905f4bd398a4c9991e1b4b5bb.svg",
      "fullname": "Aashiq Muhamed",
      "name": "aashiqmuhamed",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.19955",
      "authors": [
        {
          "_id": "68354470650d51732c992a4e",
          "user": {
            "_id": "61166c4328c98bfd5b92e7c5",
            "avatarUrl": "/avatars/f4bb0f0cc2c5b84428c28bddaa479b61.svg",
            "isPro": false,
            "fullname": "Hui Chen",
            "user": "chchenhui",
            "type": "user"
          },
          "name": "Hui Chen",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T08:47:12.560Z",
          "hidden": false
        },
        {
          "_id": "68354470650d51732c992a4f",
          "user": {
            "_id": "6530cf34e7535baecd9620a7",
            "avatarUrl": "/avatars/e6058a932d88e42b4957734f653cbcfd.svg",
            "isPro": false,
            "fullname": "Miao Xiong",
            "user": "happymio",
            "type": "user"
          },
          "name": "Miao Xiong",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T10:03:35.714Z",
          "hidden": false
        },
        {
          "_id": "68354470650d51732c992a50",
          "name": "Yujie Lu",
          "hidden": false
        },
        {
          "_id": "68354470650d51732c992a51",
          "name": "Wei Han",
          "hidden": false
        },
        {
          "_id": "68354470650d51732c992a52",
          "name": "Ailin Deng",
          "hidden": false
        },
        {
          "_id": "68354470650d51732c992a53",
          "name": "Yufei He",
          "hidden": false
        },
        {
          "_id": "68354470650d51732c992a54",
          "name": "Jiaying Wu",
          "hidden": false
        },
        {
          "_id": "68354470650d51732c992a55",
          "name": "Yibo Li",
          "hidden": false
        },
        {
          "_id": "68354470650d51732c992a56",
          "name": "Yue Liu",
          "hidden": false
        },
        {
          "_id": "68354470650d51732c992a57",
          "name": "Bryan Hooi",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-26T13:18:37.000Z",
      "submittedOnDailyAt": "2025-05-27T07:30:37.766Z",
      "title": "MLR-Bench : Évaluation d'Agents AI dans la Recherche en Apprentissage Automatique Open",
      "submittedOnDailyBy": {
        "_id": "61166c4328c98bfd5b92e7c5",
        "avatarUrl": "/avatars/f4bb0f0cc2c5b84428c28bddaa479b61.svg",
        "isPro": false,
        "fullname": "Hui Chen",
        "user": "chchenhui",
        "type": "user"
      },
      "summary": "Le développement récent des agents IA a démontré un potentiel dans les découvertes de la science. Dans cette étude, on présente MLR-Bench, une marque de référence détaillée pour évaluer les recherches en apprentissage automatique ouvertes. MLR-Bench comprend trois composants principaux : (1) On collecte 201 tâches de recherche provenant de cours de NeurIPS, ICLR et ICML, couvrant divers thèmes de ML ; (2) MLR-Judge, un marqueur d'évaluation automatique basé sur des LLM qui combine des réviseurs et un étiquetage de qualité soigneusement conçu, pour évaluer la qualité de la recherche ; (3) MLR-Agent, un schéma d'agent modulaire qui complète les tâches de recherche en quatre étapes : génération d'idées, formulation de propositions, expérimentation et écriture d'articles. Le marqueur soutient l'évaluation de ces étapes de recherche et de l'article final. De plus, on utilise MLR-Bench pour évaluer six avancés LLM et agents de haute capacité de codification, en investiguant comment les LLM génèrent effectivement des idées connectées et structurées d'articles, tandis que les agents de codification actuels généralement (par exemple, dans 80% des cas) produisent des résultats expérimentaux fabricés ou invalidés, constituant un obstacle grave pour la confiance scientifique. MLR-Judge a été évalué selon des critères humains et montre un haut accord avec les réviseurs professionnels, démontrant sa possibilité d'être une outil scalable pour l'évaluation de la recherche. MLR-Bench est accessible comme source de code pour être un cadre de référence, diagnostique et amélioration d'agents IA pour la recherche de découvertes scientifiques fiables.",
      "upvotes": 4,
      "discussionId": "68354471650d51732c992a81",
      "githubRepo": "https://github.com/chchenhui/mlrbench",
      "ai_summary": "MLR-Bench evaluates AI agents in scientific research through modular stages, revealing that while LLMs perform well in ideation and writing, coding agents often produce unreliable experimental results.",
      "ai_keywords": [
        "MLR-Bench",
        "MLR-Judge",
        "MLR-Agent",
        "LLM-based reviewers",
        "review rubrics",
        "research evaluation",
        "idea generation",
        "proposal formulation",
        "experimentation",
        "paper writing"
      ]
    },
    "publishedAt": "2025-05-26T09:18:37.000Z",
    "title": "MLR-Bench: Evaluating AI Agents on Open-Ended Machine Learning Research",
    "summary": "Recent advancements in AI agents have demonstrated their growing potential to\ndrive and support scientific discovery. In this work, we introduce MLR-Bench, a\ncomprehensive benchmark for evaluating AI agents on open-ended machine learning\nresearch. MLR-Bench includes three key components: (1) 201 research tasks\nsourced from NeurIPS, ICLR, and ICML workshops covering diverse ML topics; (2)\nMLR-Judge, an automated evaluation framework combining LLM-based reviewers with\ncarefully designed review rubrics to assess research quality; and (3)\nMLR-Agent, a modular agent scaffold capable of completing research tasks\nthrough four stages: idea generation, proposal formulation, experimentation,\nand paper writing. Our framework supports both stepwise assessment across these\ndistinct research stages, and end-to-end evaluation of the final research\npaper. We then use MLR-Bench to evaluate six frontier LLMs and an advanced\ncoding agent, finding that while LLMs are effective at generating coherent\nideas and well-structured papers, current coding agents frequently (e.g., in\n80% of the cases) produce fabricated or invalidated experimental\nresults--posing a major barrier to scientific reliability. We validate\nMLR-Judge through human evaluation, showing high agreement with expert\nreviewers, supporting its potential as a scalable tool for research evaluation.\nWe open-source MLR-Bench to help the community benchmark, diagnose, and improve\nAI research agents toward trustworthy and transparent scientific discovery.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.19955.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "61166c4328c98bfd5b92e7c5",
      "avatarUrl": "/avatars/f4bb0f0cc2c5b84428c28bddaa479b61.svg",
      "fullname": "Hui Chen",
      "name": "chchenhui",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.19443",
      "authors": [
        {
          "_id": "683517bf6bb42c7e99bd3b5c",
          "user": {
            "_id": "67ddd80896ac367438d400a6",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/C1NY6Nv5i0erwLnzCrTUM.png",
            "isPro": false,
            "fullname": "Ranjan Sapkota",
            "user": "RanjanSapkota",
            "type": "user"
          },
          "name": "Ranjan Sapkota",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T07:53:14.365Z",
          "hidden": false
        },
        {
          "_id": "683517bf6bb42c7e99bd3b5d",
          "name": "Konstantinos I. Roumeliotis",
          "hidden": false
        },
        {
          "_id": "683517bf6bb42c7e99bd3b5e",
          "name": "Manoj Karkee",
          "hidden": false
        }
      ],
      "mediaUrls": [
        "https://cdn-uploads.huggingface.co/production/uploads/67ddd80896ac367438d400a6/ASTag4z8Os01guAbKpxI6.jpeg",
        "https://cdn-uploads.huggingface.co/production/uploads/67ddd80896ac367438d400a6/EgtU3Vsfc22Hko-FbRQ51.jpeg"
      ],
      "publishedAt": "2025-05-26T03:00:21.000Z",
      "submittedOnDailyAt": "2025-05-27T00:12:16.499Z",
      "title": "Bivboing vs. Azeneicoding : La base et l'impact pratique de l'IA Azeneic",
      "submittedOnDailyBy": {
        "_id": "67ddd80896ac367438d400a6",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/C1NY6Nv5i0erwLnzCrTUM.png",
        "isPro": false,
        "fullname": "Ranjan Sapkota",
        "user": "RanjanSapkota",
        "type": "user"
      },
      "summary": "Cette revue fournit un analyse détaillée de deux nouveaux paradigmes dans le développement de logiciels soutenus par l'IA : le Beevboarding et l'Agencyboarding. Les deux utilisent des modèles de langage à grande échelle (LLMs), mais présentent des différences fondamentales en termes d'autonomie, de conception architecturale et du rôle du développeur. Le Beevboarding est intuitif et met l'accent sur l'interaction humaine au sein d'un espace, soutenant l'idée, l'expérimentation et la recherche créative à travers des flux de conversation basés sur des prompts. Par contre, l'Agencyboarding permet le développement de logiciels autonomes sans la participation humaine minimale, en utilisant des objectifs pour planifier, exécuter, tester et répéter. Nous proposons une technique de travail détaillée qui inclut des fondements conceptuels, des modèles d'exécution, des cycles de rétroaction, des structures de sécurité, des stratégies de débogage et l'intégration de l'écosystème des outils de la réalité. A travers un analyse des flux de travail relatifs et 20 cas d'utilisation spécifiques, on constate que les systèmes Beevboarding sont actifs dans la fabrication de prototypes initiaux et l'éducation, tandis que les systèmes Agencyboarding excellent dans l'automatisation entrepriselle, la réfactorisation basée sur le code et l'intégration de CI/CD. Nous avons également examiné la tendance émergente d'une architecture hybride qui combine des interfaces de langage naturel et des flux d'exécution autonomes. Enfin, nous établissons une cartographie claire de l'avenir de l'Agencyboarding AI, expliquant les infrastructures nécessaires pour des systèmes fiables, explicables et collaboratifs. Nos résultats montrent que le succès dans l'ingénierie logicielle AI ne dépend pas de choisir un seul paradigme, mais de l'harmonisation de ses forces dans un cycle de développement humain centré et unifié.",
      "upvotes": 4,
      "discussionId": "683517c06bb42c7e99bd3b92",
      "ai_summary": "A review contrasts vibe coding and agentic coding paradigms, highlighting their differences in interaction, autonomy, and application areas in AI-assisted software development.",
      "ai_keywords": [
        "large language models",
        "vibe coding",
        "agentic coding",
        "prompt-based",
        "conversational workflows",
        "goal-driven agents",
        "execution models",
        "feedback loops",
        "safety mechanisms",
        "debugging strategies",
        "tool ecosystems",
        "hybrid architectures",
        "autonomous execution pipelines",
        "trustworthy",
        "explainable",
        "collaborative systems",
        "unified",
        "human-centered development lifecycle"
      ]
    },
    "publishedAt": "2025-05-25T23:00:21.000Z",
    "title": "Vibe Coding vs. Agentic Coding: Fundamentals and Practical Implications\n  of Agentic AI",
    "summary": "This review presents a comprehensive analysis of two emerging paradigms in\nAI-assisted software development: vibe coding and agentic coding. While both\nleverage large language models (LLMs), they differ fundamentally in autonomy,\narchitectural design, and the role of the developer. Vibe coding emphasizes\nintuitive, human-in-the-loop interaction through prompt-based, conversational\nworkflows that support ideation, experimentation, and creative exploration. In\ncontrast, agentic coding enables autonomous software development through\ngoal-driven agents capable of planning, executing, testing, and iterating tasks\nwith minimal human intervention. We propose a detailed taxonomy spanning\nconceptual foundations, execution models, feedback loops, safety mechanisms,\ndebugging strategies, and real-world tool ecosystems. Through comparative\nworkflow analysis and 20 detailed use cases, we illustrate how vibe systems\nthrive in early-stage prototyping and education, while agentic systems excel in\nenterprise-grade automation, codebase refactoring, and CI/CD integration. We\nfurther examine emerging trends in hybrid architectures, where natural language\ninterfaces are coupled with autonomous execution pipelines. Finally, we\narticulate a future roadmap for agentic AI, outlining the infrastructure needed\nfor trustworthy, explainable, and collaborative systems. Our findings suggest\nthat successful AI software engineering will rely not on choosing one paradigm,\nbut on harmonizing their strengths within a unified, human-centered development\nlifecycle.",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/67ddd80896ac367438d400a6/ASTag4z8Os01guAbKpxI6.jpeg",
      "https://cdn-uploads.huggingface.co/production/uploads/67ddd80896ac367438d400a6/EgtU3Vsfc22Hko-FbRQ51.jpeg"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.19443.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "67ddd80896ac367438d400a6",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/C1NY6Nv5i0erwLnzCrTUM.png",
      "fullname": "Ranjan Sapkota",
      "name": "RanjanSapkota",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.17652",
      "authors": [
        {
          "_id": "6835264edf7cbb5c08ce28a5",
          "user": {
            "_id": "65a0aade5fafc248c2156e95",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65a0aade5fafc248c2156e95/S9YjJMTuKc-U1cFizqUMA.jpeg",
            "isPro": false,
            "fullname": "DeyangKong",
            "user": "DeyangKong",
            "type": "user"
          },
          "name": "Deyang Kong",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T07:51:42.197Z",
          "hidden": false
        },
        {
          "_id": "6835264edf7cbb5c08ce28a6",
          "name": "Qi Guo",
          "hidden": false
        },
        {
          "_id": "6835264edf7cbb5c08ce28a7",
          "user": {
            "_id": "63edb098679c2cc40abc6c2e",
            "avatarUrl": "/avatars/288c7229937c2c3f29fda6d17c7df2eb.svg",
            "isPro": false,
            "fullname": "Xiangyu",
            "user": "xixy",
            "type": "user"
          },
          "name": "Xiangyu Xi",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T07:51:39.843Z",
          "hidden": false
        },
        {
          "_id": "6835264edf7cbb5c08ce28a8",
          "name": "Wei Wang",
          "hidden": false
        },
        {
          "_id": "6835264edf7cbb5c08ce28a9",
          "name": "Jingang Wang",
          "hidden": false
        },
        {
          "_id": "6835264edf7cbb5c08ce28aa",
          "name": "Xunliang Cai",
          "hidden": false
        },
        {
          "_id": "6835264edf7cbb5c08ce28ab",
          "name": "Shikun Zhang",
          "hidden": false
        },
        {
          "_id": "6835264edf7cbb5c08ce28ac",
          "name": "Wei Ye",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-23T09:15:26.000Z",
      "submittedOnDailyAt": "2025-05-27T01:12:37.832Z",
      "title": "Pensées sur l'échantillonnage et la critique de l'apprentissage par renforcement\nThéorie axée sur l'équilibre entre habiletés et difficulté",
      "submittedOnDailyBy": {
        "_id": "65a0aade5fafc248c2156e95",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65a0aade5fafc248c2156e95/S9YjJMTuKc-U1cFizqUMA.jpeg",
        "isPro": false,
        "fullname": "DeyangKong",
        "user": "DeyangKong",
        "type": "user"
      },
      "summary": "L'apprentissage par référence se concentre sur la possibilité d'améliorer la capacité d'apprentissage de modèles de langage à grande échelle, mais lors de la phase d'exécution, la perte d'efficacité des échantillons rend l'expansion difficile. Les méthodes actuelles essaient d'améliorer l'efficacité en programmant la tâche en fonction de son difficulté, mais cette approche est souvent conditionnée par des estimations imprévisibles et des biais dans la difficulté de la tâche. De plus, on ne considère pas que l'apprentissage par référence ne peut pas atteindre des résultats optimaux en raison de la manque de compréhension de la cohérence entre la capacité du modèle et la difficulté de la tâche. Pour surmonter ces limitations, cet article présente l'Introduction de la Sampling de Capacité-Difficulté (CDAS), qui utilise la différence dans le rendement des problèmes avec des effets cumulés de passés pour garantir la cohérence entre la capacité et la difficulté des problèmes. Ensuite, la capacité du modèle est quantifiée et un système de points fixes est utilisé pour sélectionner de manière adaptative des problèmes de difficulté correspondant au niveau de capacité du modèle actuel. Les résultats des expérimentations sur des marqueurs de mathématiques montrent un grand améliorament en précision et efficacité grâce à la CDAS. La CDAS atteint une précision moyenne plus élevée que la référence, et comparée à la stratégie compétitive de DAPO, Dynamic Sampling, démontre une avantage de vitesse de 2,33 fois.",
      "upvotes": 4,
      "discussionId": "6835264fdf7cbb5c08ce28f9",
      "ai_summary": "CDAS addresses low sample efficiency in reinforcement learning by aligning model competence with problem difficulty, improving both accuracy and efficiency in mathematical benchmarks.",
      "ai_keywords": [
        "reinforcement learning",
        "competence-difficulty alignment sampling",
        "CDAS",
        "historical performance discrepancies",
        "fixed-point system",
        "dynamic sampling",
        "DAPO"
      ]
    },
    "publishedAt": "2025-05-23T05:15:26.000Z",
    "title": "Rethinking the Sampling Criteria in Reinforcement Learning for LLM\n  Reasoning: A Competence-Difficulty Alignment Perspective",
    "summary": "Reinforcement learning exhibits potential in enhancing the reasoning\nabilities of large language models, yet it is hard to scale for the low sample\nefficiency during the rollout phase. Existing methods attempt to improve\nefficiency by scheduling problems based on problem difficulties. However, these\napproaches suffer from unstable and biased estimations of problem difficulty\nand fail to capture the alignment between model competence and problem\ndifficulty in RL training, leading to suboptimal results. To tackle these\nlimitations, this paper introduces Competence-Difficulty\nAlignment Sampling (CDAS), which enables accurate\nand stable estimation of problem difficulties by aggregating historical\nperformance discrepancies of problems. Then the model competence is quantified\nto adaptively select problems whose difficulty is in alignment with the model's\ncurrent competence using a fixed-point system. Experimental results across a\nrange of challenging mathematical benchmarks show that CDAS achieves great\nimprovements in both accuracy and efficiency. CDAS attains the highest average\naccuracy against baselines and exhibits significant speed advantages compared\nto Dynamic Sampling, a competitive strategy in DAPO, which is 2.33\ntimes slower than CDAS.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.17652.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "65a0aade5fafc248c2156e95",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65a0aade5fafc248c2156e95/S9YjJMTuKc-U1cFizqUMA.jpeg",
      "fullname": "DeyangKong",
      "name": "DeyangKong",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 3
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.10887",
      "authors": [
        {
          "_id": "682b5387f1e88185bddb0643",
          "user": {
            "_id": "648a2042e8bee533291da413",
            "avatarUrl": "/avatars/83b918ddd7e2130a1c72ae74606068dc.svg",
            "isPro": false,
            "fullname": "Bin Lei",
            "user": "Bin12345",
            "type": "user"
          },
          "name": "Bin Lei",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-20T07:22:15.514Z",
          "hidden": false
        },
        {
          "_id": "682b5387f1e88185bddb0644",
          "name": "Weitai Kang",
          "hidden": false
        },
        {
          "_id": "682b5387f1e88185bddb0645",
          "name": "Zijian Zhang",
          "hidden": false
        },
        {
          "_id": "682b5387f1e88185bddb0646",
          "name": "Winson Chen",
          "hidden": false
        },
        {
          "_id": "682b5387f1e88185bddb0647",
          "name": "Xi Xie",
          "hidden": false
        },
        {
          "_id": "682b5387f1e88185bddb0648",
          "name": "Shan Zuo",
          "hidden": false
        },
        {
          "_id": "682b5387f1e88185bddb0649",
          "name": "Mimi Xie",
          "hidden": false
        },
        {
          "_id": "682b5387f1e88185bddb064a",
          "name": "Ali Payani",
          "hidden": false
        },
        {
          "_id": "682b5387f1e88185bddb064b",
          "name": "Mingyi Hong",
          "hidden": false
        },
        {
          "_id": "682b5387f1e88185bddb064c",
          "name": "Yan Yan",
          "hidden": false
        },
        {
          "_id": "682b5387f1e88185bddb064d",
          "name": "Caiwen Ding",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-16T05:43:27.000Z",
      "submittedOnDailyAt": "2025-05-27T01:07:44.773Z",
      "title": "InfantAgent-Next : Agent Multimodal Généraliste pour l'Interaction Automatique avec les Ordinateurs",
      "submittedOnDailyBy": {
        "_id": "648a2042e8bee533291da413",
        "avatarUrl": "/avatars/83b918ddd7e2130a1c72ae74606068dc.svg",
        "isPro": false,
        "fullname": "Bin Lei",
        "user": "Bin12345",
        "type": "user"
      },
      "summary": "Dans cet article, nous présentons InfantAgent-Next, un agent général. Cet agent permet l'interaction avec la machine à travers différents modèles de texte, d'images, de son et de vidéo. Au contraire des méthodes existantes, il ne se concentre pas sur la construction de flux de travail complexes centrés sur un grand modèle unique ou sur la modularité des flux de travail. Notre agent intègre un agent basé sur les outils et un agent visuel simple, en se basant sur une architecture modulaire de haut niveau, ce qui permet de résoudre des tâches séparées et résolubles en étapes grâce à la connexion de différents modèles. Notre généralité est démontrée tant dans des évaluations basées sur un monde réel visuel (par exemple, OSWorld) que dans des évaluations plus générales qui privilégient les outils (par exemple, GAIA et SWE-Bench). En particulier, dans OSWorld, nous avons atteint une précision de 7.27%, surpassant Claude-Computer-Use. Le code et les scripts d'évaluation sont disponibles sur https://github.com/bin123apple/InfantAgent.",
      "upvotes": 3,
      "discussionId": "682b5389f1e88185bddb070d",
      "githubRepo": "https://github.com/bin123apple/InfantAgent",
      "ai_summary": "InfantAgent-Next is a multimodal agent that integrates tool-based and vision models in a modular architecture to solve various benchmarks, including OSWorld, GAIA, and SWE-Bench.",
      "ai_keywords": [
        "multimodal agent",
        "tool-based agents",
        "pure vision agents",
        "modular architecture",
        "OSWorld",
        "GAIA",
        "SWE-Bench"
      ]
    },
    "publishedAt": "2025-05-16T01:43:27.000Z",
    "title": "InfantAgent-Next: A Multimodal Generalist Agent for Automated Computer\n  Interaction",
    "summary": "This paper introduces InfantAgent-Next, a generalist agent capable\nof interacting with computers in a multimodal manner, encompassing text,\nimages, audio, and video. Unlike existing approaches that either build\nintricate workflows around a single large model or only provide workflow\nmodularity, our agent integrates tool-based and pure vision agents within a\nhighly modular architecture, enabling different models to collaboratively solve\ndecoupled tasks in a step-by-step manner. Our generality is demonstrated by our\nability to evaluate not only pure vision-based real-world benchmarks (i.e.,\nOSWorld), but also more general or tool-intensive benchmarks (e.g., GAIA and\nSWE-Bench). Specifically, we achieve 7.27% accuracy on OSWorld,\nhigher than Claude-Computer-Use. Codes and evaluation scripts are open-sourced\nat https://github.com/bin123apple/InfantAgent.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.10887.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "648a2042e8bee533291da413",
      "avatarUrl": "/avatars/83b918ddd7e2130a1c72ae74606068dc.svg",
      "fullname": "Bin Lei",
      "name": "Bin12345",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 20
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.20294",
      "authors": [
        {
          "_id": "683552b7d34b8e5da4d9dfe3",
          "user": {
            "_id": "653cb25c394886efebf9971a",
            "avatarUrl": "/avatars/bca0a20c305e178a3f316581a2636cb6.svg",
            "isPro": false,
            "fullname": "Xiao Chen",
            "user": "Xiao-HF",
            "type": "user"
          },
          "name": "Xiao Chen",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T07:49:12.484Z",
          "hidden": false
        },
        {
          "_id": "683552b7d34b8e5da4d9dfe4",
          "name": "Tai Wang",
          "hidden": false
        },
        {
          "_id": "683552b7d34b8e5da4d9dfe5",
          "name": "Quanyi Li",
          "hidden": false
        },
        {
          "_id": "683552b7d34b8e5da4d9dfe6",
          "name": "Tao Huang",
          "hidden": false
        },
        {
          "_id": "683552b7d34b8e5da4d9dfe7",
          "name": "Jiangmiao Pang",
          "hidden": false
        },
        {
          "_id": "683552b7d34b8e5da4d9dfe8",
          "name": "Tianfan Xue",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-26T17:59:52.000Z",
      "submittedOnDailyAt": "2025-05-27T06:49:31.312Z",
      "title": "GLEAM : Police de recherche apprenante pour le cartographage actif dans les espaces 3D complexes d'intérieurs",
      "submittedOnDailyBy": {
        "_id": "653cb25c394886efebf9971a",
        "avatarUrl": "/avatars/bca0a20c305e178a3f316581a2636cb6.svg",
        "isPro": false,
        "fullname": "Xiao Chen",
        "user": "Xiao-HF",
        "type": "user"
      },
      "summary": "Les méthodes précédentes étaient limitées par une quantité insuffisante de données d'entraînement et des stratégies exploratoires conservatrices, ce qui les confinèrent à un cartographage actif approprié dans des environnements 3D complexes avec des connexions diverses. Pour résoudre ces problèmes, on introduit le premier cadre de référence à grande échelle, GLEAM-Bench, qui permet un entraînement échelonné et une évaluation fiable. Ce cadre de référence est conçu pour aborder 1,152 types de scènes 3D diverses, tant synthétiques que réels, pour un cartographage actif généralisable. En se basant sur ce cadre, on propose GLEAM, une politique d'exploration généralisable pour le cartographage actif. Son rendement général repose principalement sur la représentation sémantique, l'étendue de l'exploration à long terme et des stratégies aléatoires. Dans 128 scènes complexes jamais vues avant, on atteint un couverture de situations de 66,50% (+9,49%), réalisant des projets efficaces et des améliorations de la précision du cartographage. Page du projet : https://xiao-chen.tech/gleam/",
      "upvotes": 2,
      "discussionId": "683552b9d34b8e5da4d9e050",
      "ai_summary": "A new benchmark and policy, GLEAM-Bench and GLEAM, improve the scalability and reliability of active mapping in complex environments through semantic representations and efficient exploration strategies.",
      "ai_keywords": [
        "active mapping",
        "generalizable exploration",
        "semantic representations",
        "navigable goals",
        "randomized strategies",
        "3D scenes",
        "synthetic datasets",
        "real-scan datasets",
        "benchmark",
        "mapping accuracy",
        "coverage",
        "trajectories"
      ]
    },
    "publishedAt": "2025-05-26T13:59:52.000Z",
    "title": "GLEAM: Learning Generalizable Exploration Policy for Active Mapping in\n  Complex 3D Indoor Scenes",
    "summary": "Generalizable active mapping in complex unknown environments remains a\ncritical challenge for mobile robots. Existing methods, constrained by\ninsufficient training data and conservative exploration strategies, exhibit\nlimited generalizability across scenes with diverse layouts and complex\nconnectivity. To enable scalable training and reliable evaluation, we introduce\nGLEAM-Bench, the first large-scale benchmark designed for generalizable active\nmapping with 1,152 diverse 3D scenes from synthetic and real-scan datasets.\nBuilding upon this foundation, we propose GLEAM, a unified generalizable\nexploration policy for active mapping. Its superior generalizability comes\nmainly from our semantic representations, long-term navigable goals, and\nrandomized strategies. It significantly outperforms state-of-the-art methods,\nachieving 66.50% coverage (+9.49%) with efficient trajectories and improved\nmapping accuracy on 128 unseen complex scenes. Project page:\nhttps://xiao-chen.tech/gleam/.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.20294.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "653cb25c394886efebf9971a",
      "avatarUrl": "/avatars/bca0a20c305e178a3f316581a2636cb6.svg",
      "fullname": "Xiao Chen",
      "name": "Xiao-HF",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.20139",
      "authors": [
        {
          "_id": "6835744884d4600675a4449c",
          "name": "Jialin Yang",
          "hidden": false
        },
        {
          "_id": "6835744884d4600675a4449d",
          "name": "Dongfu Jiang",
          "hidden": false
        },
        {
          "_id": "6835744884d4600675a4449e",
          "name": "Lipeng He",
          "hidden": false
        },
        {
          "_id": "6835744884d4600675a4449f",
          "name": "Sherman Siu",
          "hidden": false
        },
        {
          "_id": "6835744884d4600675a444a0",
          "name": "Yuxuan Zhang",
          "hidden": false
        },
        {
          "_id": "6835744884d4600675a444a1",
          "name": "Disen Liao",
          "hidden": false
        },
        {
          "_id": "6835744884d4600675a444a2",
          "name": "Zhuofeng Li",
          "hidden": false
        },
        {
          "_id": "6835744884d4600675a444a3",
          "name": "Huaye Zeng",
          "hidden": false
        },
        {
          "_id": "6835744884d4600675a444a4",
          "name": "Yiming Jia",
          "hidden": false
        },
        {
          "_id": "6835744884d4600675a444a5",
          "name": "Haozhe Wang",
          "hidden": false
        },
        {
          "_id": "6835744884d4600675a444a6",
          "name": "Benjamin Schneider",
          "hidden": false
        },
        {
          "_id": "6835744884d4600675a444a7",
          "name": "Chi Ruan",
          "hidden": false
        },
        {
          "_id": "6835744884d4600675a444a8",
          "name": "Wentao Ma",
          "hidden": false
        },
        {
          "_id": "6835744884d4600675a444a9",
          "name": "Zhiheng Lyu",
          "hidden": false
        },
        {
          "_id": "6835744884d4600675a444aa",
          "name": "Yifei Wang",
          "hidden": false
        },
        {
          "_id": "6835744884d4600675a444ab",
          "name": "Yi Lu",
          "hidden": false
        },
        {
          "_id": "6835744884d4600675a444ac",
          "name": "Quy Duc Do",
          "hidden": false
        },
        {
          "_id": "6835744884d4600675a444ad",
          "name": "Ziyan Jiang",
          "hidden": false
        },
        {
          "_id": "6835744884d4600675a444ae",
          "name": "Ping Nie",
          "hidden": false
        },
        {
          "_id": "6835744884d4600675a444af",
          "name": "Wenhu Chen",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-26T15:40:42.000Z",
      "submittedOnDailyAt": "2025-05-27T06:46:45.076Z",
      "title": "StructEval : Outil pour évaluer la capacité de génération de sorties structurées par un modèle de langage grand (LLM)",
      "submittedOnDailyBy": {
        "_id": "62567c86d444a9b5a0ec51c1",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62567c86d444a9b5a0ec51c1/1vXJf2uGztPcXpkwyTBr6.png",
        "isPro": false,
        "fullname": "Dongfu Jiang",
        "user": "DongfuJiang",
        "type": "user"
      },
      "summary": "Le modèle de large portée de Jungle (LLMs) a acquis une importance cruciale dans le flux de travail de développement de logiciels. La capacité à générer des sorties structurées a devenue une compétence très importante. StructureEval présente un benchmark détaillé pour évaluer la capacité de génération de formats structurés dans les LLMs. À différence des benchmarks précédents, StructureEval évalue la précision structurale de manière systématique dans deux paradigmes : 1) la génération de tâches à partir du langage naturel vers des sorties structurées et 2) la traduction de formats structurés entre eux. Le benchmark inclut 18 formats et 44 types de tâches, utilisant de nouvelles métriques pour l'adéquation du format et la précision structurale. Enfin, une différence notable a été observée dans le rendement. Par exemple, le modèle de pointe, o1-mini, a atteint un taux moyen de 75,58 points, tandis que ses substituts open-source ont chuté à environ 10 points. Les tâches de génération sont plus difficiles que celles de transformation, car créer seulement la structure d'un texte est beaucoup plus simple que créer un contenu visuel précis.",
      "upvotes": 2,
      "discussionId": "6835744884d4600675a444d3",
      "ai_summary": "StructEval benchmarks Large Language Models for generating and converting structured outputs, highlighting performance gaps and challenges in producing visual content.",
      "ai_keywords": [
        "Large Language Models (LLMs)",
        "StructEval",
        "structured outputs",
        "JSON",
        "YAML",
        "CSV",
        "HTML",
        "React",
        "SVG",
        "generation tasks",
        "conversion tasks",
        "format adherence",
        "structural correctness"
      ]
    },
    "publishedAt": "2025-05-26T11:40:42.000Z",
    "title": "StructEval: Benchmarking LLMs' Capabilities to Generate Structural\n  Outputs",
    "summary": "As Large Language Models (LLMs) become integral to software development\nworkflows, their ability to generate structured outputs has become critically\nimportant. We introduce StructEval, a comprehensive benchmark for evaluating\nLLMs' capabilities in producing both non-renderable (JSON, YAML, CSV) and\nrenderable (HTML, React, SVG) structured formats. Unlike prior benchmarks,\nStructEval systematically evaluates structural fidelity across diverse formats\nthrough two paradigms: 1) generation tasks, producing structured output from\nnatural language prompts, and 2) conversion tasks, translating between\nstructured formats. Our benchmark encompasses 18 formats and 44 types of task,\nwith novel metrics for format adherence and structural correctness. Results\nreveal significant performance gaps, even state-of-the-art models like o1-mini\nachieve only 75.58 average score, with open-source alternatives lagging\napproximately 10 points behind. We find generation tasks more challenging than\nconversion tasks, and producing correct visual content more difficult than\ngenerating text-only structures.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.20139.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "62567c86d444a9b5a0ec51c1",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62567c86d444a9b5a0ec51c1/1vXJf2uGztPcXpkwyTBr6.png",
      "fullname": "Dongfu Jiang",
      "name": "DongfuJiang",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 22
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2505.19706",
      "authors": [
        {
          "_id": "6835182873a16b09c94ac4d2",
          "name": "Tej Deep Pala",
          "hidden": false
        },
        {
          "_id": "6835182873a16b09c94ac4d3",
          "name": "Panshul Sharma",
          "hidden": false
        },
        {
          "_id": "6835182873a16b09c94ac4d4",
          "name": "Amir Zadeh",
          "hidden": false
        },
        {
          "_id": "6835182873a16b09c94ac4d5",
          "name": "Chuan Li",
          "hidden": false
        },
        {
          "_id": "6835182873a16b09c94ac4d6",
          "name": "Soujanya Poria",
          "hidden": false
        }
      ],
      "mediaUrls": [
        "https://cdn-uploads.huggingface.co/production/uploads/626b626405fe1cb65725aca1/OPFuTq1oRiXqqwJPyKgUx.png",
        "https://cdn-uploads.huggingface.co/production/uploads/626b626405fe1cb65725aca1/VsJ0SH2BgYbBQTS55nWSB.png",
        "https://cdn-uploads.huggingface.co/production/uploads/626b626405fe1cb65725aca1/qreWH-gdINsiHnTwLQcOL.png"
      ],
      "publishedAt": "2025-05-26T08:56:36.000Z",
      "submittedOnDailyAt": "2025-05-27T00:29:18.345Z",
      "title": "Erreur de saisie pour être plus intelligemment récompensée : Utilisant l'hyper-asymétrie stratifiée intéressée par les erreurs pour améliorer les modèles de récompenses de processus.",
      "submittedOnDailyBy": {
        "_id": "626b626405fe1cb65725aca1",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/626b626405fe1cb65725aca1/aa-Lata46I3fXOmMetvXH.jpeg",
        "isPro": false,
        "fullname": "Soujanya Poria",
        "user": "soujanyaporia",
        "type": "user"
      },
      "summary": "Les modèles de langage grand (LLMs) se distinguent particulièrement dans les tâches mathématiques, qui sont très structurées et logiques. Les modèles de récompense finale (FRMs) vérifient uniquement la réponse finale, tandis que les modèles de récompense par étape (PRMs) évaluent chaque étape et contrôlent la génération de solutions uniformes. Nous présentons PathFinder-PRM, un nouveau PRM à couche, qui est sensible aux erreurs et répond précisément à chaque étape. Ce modèle classe les erreurs mathématiques ou les inconsistances dans chaque étape et estime la précision de l'étape par l'intégration de ces micro-signals. Pour l'entraînement de PathFinder-PRM, nous avons construit un ensemble de données de 400K échantillons avec des étiquettes d'étape, en utilisant le corpus PRM800K expliqué par humains et les traces de RLHFlow Mistral. Dans PRMBench, PathFinder-PRM a atteint un nouveau record de score PRMScore (67.7), dépassant le précédent record (65.5) avec une quantité de données trois fois plus faible. Lorsqu'il est appliqué à des recherches greedies guidées par récompense, notre modèle atteint un prm@8 de 48.3, avec un gain de 1.5 points sur le meilleur modèle de référence. Ces résultats montrent que la détection séparée d'erreurs et l'estimation de la récompense stimulent la détection plus précise d'erreurs et améliorent significativement la compréhension mathématique guidée par récompense dans les étapes finales.",
      "upvotes": 2,
      "discussionId": "6835182973a16b09c94ac514",
      "githubRepo": "https://github.com/declare-lab/PathFinder-PRM",
      "ai_summary": "PathFinder-PRM, a hierarchical and error-aware Process Reward Model, improves mathematical problem-solving by fine-grained error classification and step correctness estimation, achieving state-of-the-art PRMScore with reduced data usage.",
      "ai_keywords": [
        "Large Language Models",
        "hallucination",
        "mathematical problem solving",
        "Outcome Reward Models",
        "Process Reward Models",
        "PathFinder-PRM",
        "hierarchical",
        "error-aware",
        "discriminative PRM",
        "math errors",
        "consistency errors",
        "step correctness",
        "PRMBench",
        "PRMScore",
        "reward guided greedy search",
        "prm@8",
        "data efficiency"
      ]
    },
    "publishedAt": "2025-05-26T04:56:36.000Z",
    "title": "Error Typing for Smarter Rewards: Improving Process Reward Models with\n  Error-Aware Hierarchical Supervision",
    "summary": "Large Language Models (LLMs) are prone to hallucination, especially during\nmulti-hop and reasoning-intensive tasks such as mathematical problem solving.\nWhile Outcome Reward Models verify only final answers, Process Reward Models\n(PRMs) score each intermediate step to steer generation toward coherent\nsolutions. We introduce PathFinder-PRM, a novel hierarchical, error-aware\ndiscriminative PRM that first classifies math and consistency errors at each\nstep, then combines these fine-grained signals to estimate step correctness. To\ntrain PathFinder-PRM, we construct a 400K-sample dataset by enriching the\nhuman-annotated PRM800K corpus and RLHFlow Mistral traces with\nthree-dimensional step-level labels. On PRMBench, PathFinder-PRM achieves a new\nstate-of-the-art PRMScore of 67.7, outperforming the prior best (65.5) while\nusing 3 times less data. When applied to reward guided greedy search, our model\nyields prm@8 48.3, a +1.5 point gain over the strongest baseline. These results\ndemonstrate that decoupled error detection and reward estimation not only boost\nfine-grained error detection but also substantially improve end-to-end,\nreward-guided mathematical reasoning with greater data efficiency.",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/626b626405fe1cb65725aca1/OPFuTq1oRiXqqwJPyKgUx.png",
      "https://cdn-uploads.huggingface.co/production/uploads/626b626405fe1cb65725aca1/VsJ0SH2BgYbBQTS55nWSB.png",
      "https://cdn-uploads.huggingface.co/production/uploads/626b626405fe1cb65725aca1/qreWH-gdINsiHnTwLQcOL.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.19706.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "626b626405fe1cb65725aca1",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/626b626405fe1cb65725aca1/aa-Lata46I3fXOmMetvXH.jpeg",
      "fullname": "Soujanya Poria",
      "name": "soujanyaporia",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 7
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2505.19630",
      "authors": [
        {
          "_id": "683522abd68b329aeb799c46",
          "name": "Yichun Feng",
          "hidden": false
        },
        {
          "_id": "683522abd68b329aeb799c47",
          "user": {
            "_id": "64060b49a577649430bf6974",
            "avatarUrl": "/avatars/74d0d6ed656b593e4c101b09edf18c7a.svg",
            "isPro": false,
            "fullname": "Jiawei Wang",
            "user": "Jarvis1111",
            "type": "user"
          },
          "name": "Jiawei Wang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T07:52:01.364Z",
          "hidden": false
        },
        {
          "_id": "683522abd68b329aeb799c48",
          "name": "Lu Zhou",
          "hidden": false
        },
        {
          "_id": "683522abd68b329aeb799c49",
          "name": "Yixue Li",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-26T07:48:14.000Z",
      "submittedOnDailyAt": "2025-05-27T00:56:34.903Z",
      "title": "DoctorAgent-RL : Le système d'apprentissage par renforcement collaboratif d'agents de ClinicalKDIALOG pour la ré-information continue",
      "submittedOnDailyBy": {
        "_id": "64060b49a577649430bf6974",
        "avatarUrl": "/avatars/74d0d6ed656b593e4c101b09edf18c7a.svg",
        "isPro": false,
        "fullname": "Jiawei Wang",
        "user": "Jarvis1111",
        "type": "user"
      },
      "summary": "Les modèles de langage grand (LLMs) ont démontré des capacités exceptionnelles dans le domaine de la consultation médicale, mais ils ne résolvent pas encore les problèmes essentiels dans les conversations de traitement réels. Les systèmes actuels exigent que les patients expliquent complètement leurs symptômes en une seule occasion, utilisent des modes de transmission d'information et proposent des recommandations de diagnostic général lorsque les symptômes sont incertains. Les méthodes de dialogue traditionnelles basées sur l'apprentissage supervisé sont limitées par un paradigme dynamique de données, ce qui diminue leur capacité de généralisation et difficile l'extraction d'informations cliniques appropriées. Pour faire face à ces limitations, nous proposons un cadre de collaboration de multiples agents basé sur l'apprentissage par renforcement (RL), nommé \"DoctorAgent-RL\", qui modélise des processus de prise de décision dynamique. Les agents médicaux optimisent des stratégies de questions dans un cadre de RL grâce à des interactions multiples avec les agents de patients, ajustant l'information de manière dynamique en fonction de récompenses détaillées des évaluateurs de diagnostic. Cette structure de régulation micro par RL permet aux LLMs de développer des stratégies d'interaction automatiquement adaptées à la logique clinique, sans nécessité de modéliser des patrons explicites dans les données de dialogue actuelle. En particulier, nous avons construit le premier ensemble de données de dialogue médical en anglais \"MTMedDialog\". Les expériences montrent que DoctorAgent-RL dépasse les modèles actuels en termes de raisonnement multi-tour et de performance finale du diagnostic. Nous démontrons ainsi la valeur pratique importante de soutenir les conversations de traitement. https://github.com/JarvisUSTC/DoctorAgent-RL",
      "upvotes": 2,
      "discussionId": "683522add68b329aeb799cc4",
      "githubRepo": "https://github.com/JarvisUSTC/DoctorAgent-RL",
      "ai_summary": "DoctorAgent-RL, a reinforcement learning-based multi-agent framework, enhances multi-turn reasoning and diagnostic performance in medical consultations compared to existing systems.",
      "ai_keywords": [
        "reinforcement learning",
        "multi-agent collaborative framework",
        "dynamic decision-making",
        "uncertainty",
        "questioning strategy",
        "interaction strategy",
        "clinical reasoning",
        "multi-turn medical consultation dataset",
        "diagnostic performance"
      ]
    },
    "publishedAt": "2025-05-26T03:48:14.000Z",
    "title": "DoctorAgent-RL: A Multi-Agent Collaborative Reinforcement Learning\n  System for Multi-Turn Clinical Dialogue",
    "summary": "Large language models (LLMs) have demonstrated excellent capabilities in the\nfield of biomedical question answering, but their application in real-world\nclinical consultations still faces core challenges. Existing systems rely on a\none-way information transmission mode where patients must fully describe their\nsymptoms in a single round, leading to nonspecific diagnostic recommendations\nwhen complaints are vague. Traditional multi-turn dialogue methods based on\nsupervised learning are constrained by static data-driven paradigms, lacking\ngeneralizability and struggling to intelligently extract key clinical\ninformation. To address these limitations, we propose DoctorAgent-RL, a\nreinforcement learning (RL)-based multi-agent collaborative framework that\nmodels medical consultations as a dynamic decision-making process under\nuncertainty. The doctor agent continuously optimizes its questioning strategy\nwithin the RL framework through multi-turn interactions with the patient agent,\ndynamically adjusting its information-gathering path based on comprehensive\nrewards from the Consultation Evaluator. This RL fine-tuning mechanism enables\nLLMs to autonomously develop interaction strategies aligned with clinical\nreasoning logic, rather than superficially imitating patterns in existing\ndialogue data. Notably, we constructed MTMedDialog, the first English\nmulti-turn medical consultation dataset capable of simulating patient\ninteractions. Experiments demonstrate that DoctorAgent-RL outperforms existing\nmodels in both multi-turn reasoning capability and final diagnostic\nperformance, demonstrating practical value in assisting clinical consultations.\nhttps://github.com/JarvisUSTC/DoctorAgent-RL",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.19630.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64060b49a577649430bf6974",
      "avatarUrl": "/avatars/74d0d6ed656b593e4c101b09edf18c7a.svg",
      "fullname": "Jiawei Wang",
      "name": "Jarvis1111",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.19223",
      "authors": [
        {
          "_id": "68357a21d0fbc64a8e829088",
          "name": "Fengqi Zhu",
          "hidden": false
        },
        {
          "_id": "68357a21d0fbc64a8e829089",
          "name": "Rongzhen Wang",
          "hidden": false
        },
        {
          "_id": "68357a21d0fbc64a8e82908a",
          "name": "Shen Nie",
          "hidden": false
        },
        {
          "_id": "68357a21d0fbc64a8e82908b",
          "user": {
            "_id": "67513d6d3b8586521cda5d76",
            "avatarUrl": "/avatars/0f95cc5c23a0a1da289aa785bd33b616.svg",
            "isPro": false,
            "fullname": "Xiaolu  Zhang",
            "user": "xiaolu0714",
            "type": "user"
          },
          "name": "Xiaolu Zhang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-05-27T08:45:40.970Z",
          "hidden": false
        },
        {
          "_id": "68357a21d0fbc64a8e82908c",
          "name": "Chunwei Wu",
          "hidden": false
        },
        {
          "_id": "68357a21d0fbc64a8e82908d",
          "name": "Jun Hu",
          "hidden": false
        },
        {
          "_id": "68357a21d0fbc64a8e82908e",
          "name": "Jun Zhou",
          "hidden": false
        },
        {
          "_id": "68357a21d0fbc64a8e82908f",
          "user": {
            "_id": "65fcad0ba0d7adc40b54fac2",
            "avatarUrl": "/avatars/7564b5642378fddb46ec3b5ae57c0402.svg",
            "isPro": false,
            "fullname": "Jianfei Chen",
            "user": "surfingtomchen",
            "type": "user"
          },
          "name": "Jianfei Chen",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-05-27T08:45:00.594Z",
          "hidden": false
        },
        {
          "_id": "68357a21d0fbc64a8e829090",
          "user": {
            "_id": "657a651e1433ea7d44de6397",
            "avatarUrl": "/avatars/ccfc76f94595a38ff4a80f77c911eabf.svg",
            "isPro": false,
            "fullname": "Yankai Lin",
            "user": "lyk423",
            "type": "user"
          },
          "name": "Yankai Lin",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-05-27T08:44:53.835Z",
          "hidden": false
        },
        {
          "_id": "68357a21d0fbc64a8e829091",
          "user": {
            "_id": "64b8c89052b7353d8c6a1013",
            "avatarUrl": "/avatars/cd59fffe81f6b07b4519540b8ff3d95f.svg",
            "isPro": false,
            "fullname": "Ji-Rong Wen",
            "user": "jrwen",
            "type": "user"
          },
          "name": "Ji-Rong Wen",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-05-27T08:44:47.347Z",
          "hidden": false
        },
        {
          "_id": "68357a21d0fbc64a8e829092",
          "user": {
            "_id": "64c07b488e2612254361153b",
            "avatarUrl": "/avatars/ade0f783cc4c2d3e73f402637f595471.svg",
            "isPro": false,
            "fullname": "chongxuan li",
            "user": "zhenxuan00",
            "type": "user"
          },
          "name": "Chongxuan Li",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-05-27T08:44:37.114Z",
          "hidden": false
        }
      ],
      "mediaUrls": [
        "https://cdn-uploads.huggingface.co/production/uploads/63a369d98c0c89dcae3b8329/HQWTRZ5gL3-RFJ6PSJ3NC.jpeg"
      ],
      "publishedAt": "2025-05-25T16:36:20.000Z",
      "submittedOnDailyAt": "2025-05-27T07:14:06.300Z",
      "title": "LLaDA 1.5 : Modèle d'optimisation de la réduction de la variation linguistique",
      "submittedOnDailyBy": {
        "_id": "63a369d98c0c89dcae3b8329",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63a369d98c0c89dcae3b8329/6OUJ7Hc9T1jXynYH3FGaf.png",
        "isPro": false,
        "fullname": "Adina Yakefu",
        "user": "AdinaY",
        "type": "user"
      },
      "summary": "Le module d'héritage génétique de la masque (MDM) comme le modèle LLaDA propose un nouveau paradigme dans le modélisation du langage, bien qu'il ne laisse pas de côté l'effort relativement moindre en apprentissage par renforcement pour s'adapter aux préférences humaines. La principale question est la forte variabilité dans l'estimation des probabilités basée sur le ELBO (borne inférieure de vérification) pour optimiser les préférences. Pour aborder ce problème, nous proposons l'Optimisation de Préférences avec Réduction de Variance (VRPO). VRPO analyse formellement la variabilité dans l'estimation de l'ELBO et fournit un cadre qui limite à la fois le biais et la variabilité dans l'optimisation des préférences. Sur la base de cette théorie, nous introduisons des stratégies pour réduire la variabilité et améliorer considérablement le rendement de la MDM, y compris la distribution optimale de Monte Carlo et le sampling inverse. Nous démontrons les avantages de VRPO en l'appliquant à LLaDA, où le modèle résultant, LLaDA 1.5, montre des résultats nettement améliorés dans des domaines comme les mathématiques (GSM8K +4.7), le code (HumanEval +3.0, MBPP +1.8) et les benchmarks d'ajustement (IFEval +4.0, Arena-Hard +4.3) par rapport aux modèles SFT précédents. De plus, LLaDA 1.5 démontre une forte compétence dans le langage MDM et ARM, montrant une excellente performance mathématique. Page du projet : https://ml-gsai.github.io/LLaDA-1.5-Demo/",
      "upvotes": 2,
      "discussionId": "68357a21d0fbc64a8e8290ba",
      "ai_summary": "VRPO is a variance-reduced preference optimization framework for Masked Diffusion Models that significantly enhances their alignment with human preferences and performance across various benchmarks.",
      "ai_keywords": [
        "Masked Diffusion Models",
        "LLaDA",
        "Variance-Reduced Preference Optimization",
        "VRPO",
        "Evidence Lower Bound",
        "ELBO",
        "bias",
        "variance",
        "preference optimization",
        "unbiased variance reduction",
        "optimal Monte Carlo budget allocation",
        "antithetic sampling",
        "GSM8K",
        "HumanEval",
        "MBPP",
        "IFEval",
        "Arena-Hard",
        "ARMs"
      ]
    },
    "publishedAt": "2025-05-25T12:36:20.000Z",
    "title": "LLaDA 1.5: Variance-Reduced Preference Optimization for Large Language\n  Diffusion Models",
    "summary": "While Masked Diffusion Models (MDMs), such as LLaDA, present a promising\nparadigm for language modeling, there has been relatively little effort in\naligning these models with human preferences via reinforcement learning. The\nchallenge primarily arises from the high variance in Evidence Lower Bound\n(ELBO)-based likelihood estimates required for preference optimization. To\naddress this issue, we propose Variance-Reduced Preference Optimization (VRPO),\na framework that formally analyzes the variance of ELBO estimators and derives\nbounds on both the bias and variance of preference optimization gradients.\nBuilding on this theoretical foundation, we introduce unbiased variance\nreduction strategies, including optimal Monte Carlo budget allocation and\nantithetic sampling, that significantly improve the performance of MDM\nalignment. We demonstrate the effectiveness of VRPO by applying it to LLaDA,\nand the resulting model, LLaDA 1.5, outperforms its SFT-only predecessor\nconsistently and significantly across mathematical (GSM8K +4.7), code\n(HumanEval +3.0, MBPP +1.8), and alignment benchmarks (IFEval +4.0, Arena-Hard\n+4.3). Furthermore, LLaDA 1.5 demonstrates a highly competitive mathematical\nperformance compared to strong language MDMs and ARMs. Project page:\nhttps://ml-gsai.github.io/LLaDA-1.5-Demo/.",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/63a369d98c0c89dcae3b8329/HQWTRZ5gL3-RFJ6PSJ3NC.jpeg"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.19223.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "63a369d98c0c89dcae3b8329",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63a369d98c0c89dcae3b8329/6OUJ7Hc9T1jXynYH3FGaf.png",
      "fullname": "Adina Yakefu",
      "name": "AdinaY",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 702
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2505.19084",
      "authors": [
        {
          "_id": "6835334e0c0aff775f3eb6e2",
          "user": {
            "_id": "640c64779e5247967ff1e0b2",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1678533946170-640c64779e5247967ff1e0b2.jpeg",
            "isPro": false,
            "fullname": "Yifeng Xu",
            "user": "xyfJASON",
            "type": "user"
          },
          "name": "Yifeng Xu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T08:15:08.170Z",
          "hidden": false
        },
        {
          "_id": "6835334e0c0aff775f3eb6e3",
          "name": "Zhenliang He",
          "hidden": false
        },
        {
          "_id": "6835334e0c0aff775f3eb6e4",
          "name": "Meina Kan",
          "hidden": false
        },
        {
          "_id": "6835334e0c0aff775f3eb6e5",
          "name": "Shiguang Shan",
          "hidden": false
        },
        {
          "_id": "6835334e0c0aff775f3eb6e6",
          "name": "Xilin Chen",
          "hidden": false
        }
      ],
      "mediaUrls": [
        "https://cdn-uploads.huggingface.co/production/uploads/640c64779e5247967ff1e0b2/Mqa2jx5wM-f5Fc1pdd6sz.jpeg",
        "https://cdn-uploads.huggingface.co/production/uploads/640c64779e5247967ff1e0b2/-ubqvKPbhrxAjIKnj7dPU.jpeg",
        "https://cdn-uploads.huggingface.co/production/uploads/640c64779e5247967ff1e0b2/Y4ub2WOy0Adp1TfcT90R3.jpeg",
        "https://cdn-uploads.huggingface.co/production/uploads/640c64779e5247967ff1e0b2/lvdM2FUHFI2ut7cgELTh9.jpeg"
      ],
      "publishedAt": "2025-05-25T10:40:52.000Z",
      "submittedOnDailyAt": "2025-05-27T07:40:01.653Z",
      "title": "Jordi : Modéliser la génération et la compréhension visuelles ensemble",
      "submittedOnDailyBy": {
        "_id": "640c64779e5247967ff1e0b2",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1678533946170-640c64779e5247967ff1e0b2.jpeg",
        "isPro": false,
        "fullname": "Yifeng Xu",
        "user": "xyfJASON",
        "type": "user"
      },
      "summary": "La génération visuelle et la compréhension sont deux aspects profondément liés de l'intelligence humaine, et dans l'apprentissage automatique, elles ont été traitées de manière indépendante. Dans cet article, nous présentons un cadre de travail distribué proposé pour l'intégration de la génération visuelle et de la compréhension, appelé \"Jodi\". Jodi modélise l'aire des images et plusieurs domaines de marqueurs pour intégrer la génération et la compréhension d'images. En particulier, Jodi introduit la transformateur linéaire distribué et la fonction de rôle échangé pour réaliser les tâches suivantes avec des caractéristiques : la génération commune d'images et de marqueurs, la génération contrôlable basée sur la combinaison de marqueurs arbitraires, et la prédiction simultanée de plusieurs marqueurs dans une image. De plus, nous présentons le jeu de données \"Joint-1.6M\", qui comprend 200 000 images de haute qualité, des marqueurs automatiques dans 7 domaines visuels et des résumés générés par un modèle de langage grand, pour démontrer les fonctions de Jodi. En raison de son extensibilité, Jodi a démontré des résultats excellents dans les deux tâches de génération visuelle et de compréhension, et également dans un large éventail de domaines visuels. Le code est disponible sur https://github.com/VIPL-GENUN/Jodi.",
      "upvotes": 2,
      "discussionId": "683533510c0aff775f3eb7ab",
      "ai_summary": "Jodi, a diffusion framework using a linear diffusion transformer and role switch mechanism, unifies visual generation and understanding, performing joint, controllable, and perceptual tasks effectively across multiple visual domains.",
      "ai_keywords": [
        "diffusion framework",
        "linear diffusion transformer",
        "role switch mechanism",
        "joint generation",
        "controllable generation",
        "image perception",
        "Joint-1.6M dataset",
        "visual domains",
        "LLM-generated captions"
      ]
    },
    "publishedAt": "2025-05-25T06:40:52.000Z",
    "title": "Jodi: Unification of Visual Generation and Understanding via Joint\n  Modeling",
    "summary": "Visual generation and understanding are two deeply interconnected aspects of\nhuman intelligence, yet they have been traditionally treated as separate tasks\nin machine learning. In this paper, we propose Jodi, a diffusion framework that\nunifies visual generation and understanding by jointly modeling the image\ndomain and multiple label domains. Specifically, Jodi is built upon a linear\ndiffusion transformer along with a role switch mechanism, which enables it to\nperform three particular types of tasks: (1) joint generation, where the model\nsimultaneously generates images and multiple labels; (2) controllable\ngeneration, where images are generated conditioned on any combination of\nlabels; and (3) image perception, where multiple labels can be predicted at\nonce from a given image. Furthermore, we present the Joint-1.6M dataset, which\ncontains 200,000 high-quality images collected from public sources, automatic\nlabels for 7 visual domains, and LLM-generated captions. Extensive experiments\ndemonstrate that Jodi excels in both generation and understanding tasks and\nexhibits strong extensibility to a wider range of visual domains. Code is\navailable at https://github.com/VIPL-GENUN/Jodi.",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/640c64779e5247967ff1e0b2/Mqa2jx5wM-f5Fc1pdd6sz.jpeg",
      "https://cdn-uploads.huggingface.co/production/uploads/640c64779e5247967ff1e0b2/-ubqvKPbhrxAjIKnj7dPU.jpeg",
      "https://cdn-uploads.huggingface.co/production/uploads/640c64779e5247967ff1e0b2/Y4ub2WOy0Adp1TfcT90R3.jpeg",
      "https://cdn-uploads.huggingface.co/production/uploads/640c64779e5247967ff1e0b2/lvdM2FUHFI2ut7cgELTh9.jpeg"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.19084.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "640c64779e5247967ff1e0b2",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1678533946170-640c64779e5247967ff1e0b2.jpeg",
      "fullname": "Yifeng Xu",
      "name": "xyfJASON",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 3
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.18773",
      "authors": [
        {
          "_id": "6835727f9da2b91fb4e30473",
          "name": "Jamie Hayes",
          "hidden": false
        },
        {
          "_id": "6835727f9da2b91fb4e30474",
          "name": "Ilia Shumailov",
          "hidden": false
        },
        {
          "_id": "6835727f9da2b91fb4e30475",
          "name": "Christopher A. Choquette-Choo",
          "hidden": false
        },
        {
          "_id": "6835727f9da2b91fb4e30476",
          "name": "Matthew Jagielski",
          "hidden": false
        },
        {
          "_id": "6835727f9da2b91fb4e30477",
          "name": "George Kaissis",
          "hidden": false
        },
        {
          "_id": "6835727f9da2b91fb4e30478",
          "name": "Katherine Lee",
          "hidden": false
        },
        {
          "_id": "6835727f9da2b91fb4e30479",
          "name": "Milad Nasr",
          "hidden": false
        },
        {
          "_id": "6835727f9da2b91fb4e3047a",
          "name": "Sahra Ghalebikesabi",
          "hidden": false
        },
        {
          "_id": "6835727f9da2b91fb4e3047b",
          "name": "Niloofar Mireshghallah",
          "hidden": false
        },
        {
          "_id": "6835727f9da2b91fb4e3047c",
          "name": "Meenatchi Sundaram Mutu Selva Annamalai",
          "hidden": false
        },
        {
          "_id": "6835727f9da2b91fb4e3047d",
          "name": "Igor Shilov",
          "hidden": false
        },
        {
          "_id": "6835727f9da2b91fb4e3047e",
          "name": "Matthieu Meeus",
          "hidden": false
        },
        {
          "_id": "6835727f9da2b91fb4e3047f",
          "name": "Yves-Alexandre de Montjoye",
          "hidden": false
        },
        {
          "_id": "6835727f9da2b91fb4e30480",
          "name": "Franziska Boenisch",
          "hidden": false
        },
        {
          "_id": "6835727f9da2b91fb4e30481",
          "name": "Adam Dziedzic",
          "hidden": false
        },
        {
          "_id": "6835727f9da2b91fb4e30482",
          "user": {
            "_id": "663c3b587e7bc3d3e4a54ffb",
            "avatarUrl": "/avatars/681abf7e4a85184667015cefefa226c6.svg",
            "isPro": false,
            "fullname": "A. Feder Cooper",
            "user": "pasta41",
            "type": "user"
          },
          "name": "A. Feder Cooper",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-05-27T08:06:24.708Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-24T16:23:43.000Z",
      "submittedOnDailyAt": "2025-05-27T06:39:29.837Z",
      "title": "Grandes ensembles de données et attaques de membership fortes contre modèles de langage grands (intermédiaires)",
      "submittedOnDailyBy": {
        "_id": "6475c2794766357252e69e9f",
        "avatarUrl": "/avatars/db428715dfd2239df2aeaaff1282323f.svg",
        "isPro": false,
        "fullname": "i",
        "user": "iliashum",
        "type": "user"
      },
      "summary": "La meilleure inférence des membres (MIA) avancée nécessite l'entraînement de plusieurs modèles de référence, ce qui est impossible à mettre à l'échelle pour des modèles de langage prédéfinis (LLM) à grande échelle, ce qui a conduit les études précédentes à éviter l'entraînement de modèles de référence (par exemple, les attaques de fine-tuning) ou à se concentrer sur l'application de fortes attaques sur des petits modèles ou des ensembles de données. Cependant, ces attaques faibles ont montré être faibles et approximativement réussies, et l'évasion des fortes attaques dans des configurations simplifiées ne se maintient pas pour les LLM actuels. Cela a généré une question importante : sont les limites observées dans les études précédentes des conséquences des décisions de conception de l'attaque ou est-ce que la MIA est inhéremment inadéquate pour les LLM ? Pour aborder cette question, nous avons mis à l'échelle LiRA (l'un des plus puissants MIA) à l'architecture de GPT-2 (avec un nombre de paramètres entre 10M et 1B) et nous avons entraîné des modèles de référence avec 200 millions de tokens dans l'ensemble de données C4. Nos résultats ont conduit à une amélioration de l'compréhension de la MIA dans les LLM dans trois points clés : (1) une MIA forte peut avoir succès avec des modèles LLM pré-entraînés ; (2) sa efficacité est limitée dans des configurations réelles (par exemple, AUC < 0.7) ; (3) la relation entre le succès de l'attaque et les métriques de confidentialité est différente de ce qui a été présenté dans les études précédentes.",
      "upvotes": 2,
      "discussionId": "683572809da2b91fb4e30513",
      "ai_summary": "Scaling LiRA membership inference attacks to large pre-trained language models shows that while these attacks can succeed, their effectiveness is limited and does not definitively correlate with privacy metrics.",
      "ai_keywords": [
        "membership inference attacks",
        "MIAs",
        "reference models",
        "fine-tuning attacks",
        "pre-trained language models",
        "LLMs",
        "LiRA",
        "GPT-2",
        "tokens",
        "C4 dataset",
        "AUC",
        "privacy metrics"
      ]
    },
    "publishedAt": "2025-05-24T12:23:43.000Z",
    "title": "Strong Membership Inference Attacks on Massive Datasets and (Moderately)\n  Large Language Models",
    "summary": "State-of-the-art membership inference attacks (MIAs) typically require\ntraining many reference models, making it difficult to scale these attacks to\nlarge pre-trained language models (LLMs). As a result, prior research has\neither relied on weaker attacks that avoid training reference models (e.g.,\nfine-tuning attacks), or on stronger attacks applied to small-scale models and\ndatasets. However, weaker attacks have been shown to be brittle - achieving\nclose-to-arbitrary success - and insights from strong attacks in simplified\nsettings do not translate to today's LLMs. These challenges have prompted an\nimportant question: are the limitations observed in prior work due to attack\ndesign choices, or are MIAs fundamentally ineffective on LLMs? We address this\nquestion by scaling LiRA - one of the strongest MIAs - to GPT-2 architectures\nranging from 10M to 1B parameters, training reference models on over 20B tokens\nfrom the C4 dataset. Our results advance the understanding of MIAs on LLMs in\nthree key ways: (1) strong MIAs can succeed on pre-trained LLMs; (2) their\neffectiveness, however, remains limited (e.g., AUC<0.7) in practical settings;\nand, (3) the relationship between MIA success and related privacy metrics is\nnot as straightforward as prior work has suggested.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.18773.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6475c2794766357252e69e9f",
      "avatarUrl": "/avatars/db428715dfd2239df2aeaaff1282323f.svg",
      "fullname": "i",
      "name": "iliashum",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 4
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2505.18384",
      "authors": [
        {
          "_id": "68354f30d795fadab0623699",
          "user": {
            "_id": "65319bd7f85995389d4f019c",
            "avatarUrl": "/avatars/657858b8435b220c9a29918c0dae9c6d.svg",
            "isPro": false,
            "fullname": "Boyi Wei",
            "user": "boyiwei",
            "type": "user"
          },
          "name": "Boyi Wei",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T07:49:18.459Z",
          "hidden": false
        },
        {
          "_id": "68354f30d795fadab062369a",
          "name": "Benedikt Stroebl",
          "hidden": false
        },
        {
          "_id": "68354f30d795fadab062369b",
          "name": "Jiacen Xu",
          "hidden": false
        },
        {
          "_id": "68354f30d795fadab062369c",
          "name": "Joie Zhang",
          "hidden": false
        },
        {
          "_id": "68354f30d795fadab062369d",
          "name": "Zhou Li",
          "hidden": false
        },
        {
          "_id": "68354f30d795fadab062369e",
          "name": "Peter Henderson",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-23T21:18:59.000Z",
      "submittedOnDailyAt": "2025-05-27T04:06:40.688Z",
      "title": "Suivre l'approche de la sécurité contre les attaques dans les évaluations dynamiques des risques",
      "submittedOnDailyBy": {
        "_id": "65319bd7f85995389d4f019c",
        "avatarUrl": "/avatars/657858b8435b220c9a29918c0dae9c6d.svg",
        "isPro": false,
        "fullname": "Boyi Wei",
        "user": "boyiwei",
        "type": "user"
      },
      "summary": "Le modèle de base améliore son capacité en tant que programmeur automatique, ce qui augmente la probabilité que les opérations cybernétiques agressives soient automatisées. Les évaluations des modèles les plus avancés examinent actuellement le risque de sécurité cybernétique de ces entités de sortie, mais la plupart ne considèrent pas la liberté que l'adversaire a dans le monde réel. En particulier, si un vérificateur fort et une récompense financière sont offertes, les entités de sortie pour la sécurité cybernétique peuvent être améliorées par l'adversaire à travers des expériences et des erreurs. Nous argumentons que nous devons considérer un modèle d'amenagement des menaces élargi dans le contexte de la sécurité cybernétique et mettre l'accent sur la liberté de l'adversaire dans les états et les environnements d'urgence. Nous montrons que l'adversaire peut améliorer en dehors de 40% sa capacité en sécurité cybernétique dans une CTF de codification interactive avec un temps fixe de 8 GPU H100. Ces résultats soulignent la nécessité d'évaluer dynamiquement le risque des entités de sortie et de représenter de manière représentative la menace.",
      "upvotes": 2,
      "discussionId": "68354f30d795fadab06236fe",
      "githubRepo": "https://github.com/boyiwei/Dynamic-Risk-Assessment",
      "ai_summary": "Adversaries can significantly enhance foundation model capabilities in offensive cybersecurity with limited computational resources, underscoring the need for dynamic threat model assessments.",
      "ai_keywords": [
        "foundation models",
        "autonomous programmers",
        "offensive cybersecurity",
        "model audits",
        "cybersecurity risks",
        "verifiers",
        "financial incentives",
        "iterative improvement",
        "threat model",
        "stateful environments",
        "non-stateful environments",
        "compute budget",
        "InterCode CTF"
      ]
    },
    "publishedAt": "2025-05-23T17:18:59.000Z",
    "title": "Dynamic Risk Assessments for Offensive Cybersecurity Agents",
    "summary": "Foundation models are increasingly becoming better autonomous programmers,\nraising the prospect that they could also automate dangerous offensive\ncyber-operations. Current frontier model audits probe the cybersecurity risks\nof such agents, but most fail to account for the degrees of freedom available\nto adversaries in the real world. In particular, with strong verifiers and\nfinancial incentives, agents for offensive cybersecurity are amenable to\niterative improvement by would-be adversaries. We argue that assessments should\ntake into account an expanded threat model in the context of cybersecurity,\nemphasizing the varying degrees of freedom that an adversary may possess in\nstateful and non-stateful environments within a fixed compute budget. We show\nthat even with a relatively small compute budget (8 H100 GPU Hours in our\nstudy), adversaries can improve an agent's cybersecurity capability on\nInterCode CTF by more than 40\\% relative to the baseline -- without any\nexternal assistance. These results highlight the need to evaluate agents'\ncybersecurity risk in a dynamic manner, painting a more representative picture\nof risk.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.18384.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "65319bd7f85995389d4f019c",
      "avatarUrl": "/avatars/657858b8435b220c9a29918c0dae9c6d.svg",
      "fullname": "Boyi Wei",
      "name": "boyiwei",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.16312",
      "authors": [
        {
          "_id": "6830109ea20ebb4738e76931",
          "user": {
            "_id": "6747d38098fe79433a8c4580",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/BrcsTfusqfu9p9uv1NeX6.png",
            "isPro": false,
            "fullname": "Jiawei Liu",
            "user": "Jiawei1222",
            "type": "user"
          },
          "name": "Jiawei Liu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-26T08:15:09.111Z",
          "hidden": false
        },
        {
          "_id": "6830109ea20ebb4738e76932",
          "name": "Qisi Chen",
          "hidden": false
        },
        {
          "_id": "6830109ea20ebb4738e76933",
          "name": "Jianshu Zhang",
          "hidden": false
        },
        {
          "_id": "6830109ea20ebb4738e76934",
          "name": "Quan Liu",
          "hidden": false
        },
        {
          "_id": "6830109ea20ebb4738e76935",
          "name": "Defu Lian",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-22T07:07:43.000Z",
      "submittedOnDailyAt": "2025-05-27T05:04:30.217Z",
      "title": "EquivPruner : Optimisation de la recherche basée sur des modèles de bibliothèque et amélioration de la requête pour le réduction des actions",
      "submittedOnDailyBy": {
        "_id": "6747d38098fe79433a8c4580",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/BrcsTfusqfu9p9uv1NeX6.png",
        "isPro": false,
        "fullname": "Jiawei Liu",
        "user": "Jiawei1222",
        "type": "user"
      },
      "summary": "Les modèles de langage grand (LLMs) dépassent les algorithmes d'exploration pour des raisons complexes mais, la stratégie actuelle implique d'explorer des étapes équivalentes de manière inefficace, ce qui augmente considérablement le consommation de labels. Les méthodes de similarité sémantique existantes ont des difficultés à reconnaître l'équivalence exacte dans des contextes spécifiques tels que la mathématique ou la logique mathématique. Dans ce sens, nous proposons EquivPruner. EquivPruner est un approche simple et efficace pour identifier et supprimer les actions sémantiquement équivalentes lors de l'exploration de raisonnement d'un LLM. De plus, nous avons créé pour la première fois le jeu de données MathEquiv pour entraîner un détecteur d'équivalence dans des expressions mathématiques. Cela permet l'entraînement d'un détecteur d'équivalence léger. La validation sur une large gamme de modèles et de tâches montre que EquivPruner réduit considérablement le consommation de labels, améliore l'efficacité de l'exploration et renforce la précision de la raison. Par exemple, lorsqu'il est appliqué à Qwen2.5-Math-7B-Instruct sur GSM8K, EquivPruner réduit le consommation de labels de 48.1% et améliore la précision. Notre code est disponible sur https://github.com/Lolo1222/EquivPruner.",
      "upvotes": 2,
      "discussionId": "6830109fa20ebb4738e769a3",
      "githubRepo": "https://github.com/Lolo1222/EquivPruner",
      "ai_summary": "EquivPruner reduces token consumption and improves reasoning accuracy by pruning semantically equivalent actions in LLM searches, leveraging a new dataset for mathematical equivalence.",
      "ai_keywords": [
        "Large Language Models (LLMs)",
        "semantic similarity",
        "semantically equivalent actions",
        "EquivPruner",
        "MathEquiv",
        "equivalence detector",
        "GSM8K"
      ]
    },
    "publishedAt": "2025-05-22T03:07:43.000Z",
    "title": "EquivPruner: Boosting Efficiency and Quality in LLM-Based Search via\n  Action Pruning",
    "summary": "Large Language Models (LLMs) excel at complex reasoning through search\nalgorithms, yet current strategies often suffer from massive token consumption\ndue to redundant exploration of semantically equivalent steps. Existing\nsemantic similarity methods struggle to accurately identify such equivalence in\ndomain-specific contexts like mathematical reasoning. To address this, we\npropose EquivPruner, a simple yet effective approach that identifies and prunes\nsemantically equivalent actions during LLM reasoning search. We also introduce\nMathEquiv, the first dataset we created for mathematical statement equivalence,\nwhich enables the training of a lightweight equivalence detector. Extensive\nexperiments across various models and tasks demonstrate that EquivPruner\nsignificantly reduces token consumption, improving searching efficiency and\noften bolstering reasoning accuracy. For instance, when applied to\nQwen2.5-Math-7B-Instruct on GSM8K, EquivPruner reduced token consumption by\n48.1\\% while also improving accuracy. Our code is available at\nhttps://github.com/Lolo1222/EquivPruner.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.16312.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "6747d38098fe79433a8c4580",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/BrcsTfusqfu9p9uv1NeX6.png",
      "fullname": "Jiawei Liu",
      "name": "Jiawei1222",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.19800",
      "authors": [
        {
          "_id": "68356e736bb42c7e99d2d266",
          "user": {
            "_id": "5f04bd384ec31d33a72116d1",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1594145966049-noauth.jpeg",
            "isPro": false,
            "fullname": "Zaid Alyafeai",
            "user": "Zaid",
            "type": "user"
          },
          "name": "Zaid Alyafeai",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T08:47:10.858Z",
          "hidden": false
        },
        {
          "_id": "68356e736bb42c7e99d2d267",
          "name": "Maged S. Al-Shaibani",
          "hidden": false
        },
        {
          "_id": "68356e736bb42c7e99d2d268",
          "name": "Bernard Ghanem",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-26T10:31:26.000Z",
      "submittedOnDailyAt": "2025-05-27T07:09:18.429Z",
      "title": "\"Non se : Modèles de langage basés sur les modèles de grande taille (LLMs) utilisant l'extraction et la validation de bases de données dans les articles scientifiques\"",
      "submittedOnDailyBy": {
        "_id": "5f04bd384ec31d33a72116d1",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1594145966049-noauth.jpeg",
        "isPro": false,
        "fullname": "Zaid Alyafeai",
        "user": "Zaid",
        "type": "user"
      },
      "summary": "L'extraction de métadonnées est essentielle pour la classification et l'archivage de ensembles de données, et elle est nécessaire pour favoriser l'efficacité dans la recherche scientifique et sa reproductibilité. Dans le contexte du croissance exponentielle de la recherche scientifique, cet aspect est particulièrement important. De plus, Masader (Alyafeai et al., 2021) a établi une base fondamentale pour extraire de larges propriétés de métadonnées d'articles académiques d'ensembles de données de langues arabes, mais dépendait de la manuelité. Dans cet article, on propose le cadre MOLE pour que les propriétés de métadonnées d'articles scientifiques qui incluent ensembles de données d'autres langues puissent être extraites automatiquement en utilisant des modèles de langage grands (LLMs). On introduit une structure de validation forte pour traiter des documents de multiples formats et garantir un output cohérent. De plus, on introduit un nouveau benchmark pour évaluer l'avancement de cette tâche. À travers un analyse systématique de la longueur du contexte, l'apprentissage avec peu d'exemples et l'intégration avec le navigateur, on démontre que les actuels LLMs ne montrent pas les résultats souhaités pour l'automatisation de cette tâche, ce qui souligne la nécessité d'améliorations futures. On fournit le code pour la communauté de chercheurs : https://github.com/IVUL-KAUST/MOLE, et on fournit l'ensemble de données : https://huggingface.co/datasets/IVUL-KAUST/MOLE.",
      "upvotes": 1,
      "discussionId": "68356e746bb42c7e99d2d2af",
      "projectPage": "https://ivul-kaust.github.io/MOLE/blog",
      "githubRepo": "https://github.com/IVUL-KAUST/MOLE",
      "ai_summary": "A framework leveraging Large Language Models (LLMs) is introduced for automatic metadata extraction from scientific papers, with a focus on datasets from languages other than Arabic.",
      "ai_keywords": [
        "Large Language Models (LLMs)",
        "schema-driven methodology",
        "benchmark",
        "few-shot learning",
        "web browsing integration"
      ]
    },
    "publishedAt": "2025-05-26T06:31:26.000Z",
    "title": "MOLE: Metadata Extraction and Validation in Scientific Papers Using LLMs",
    "summary": "Metadata extraction is essential for cataloging and preserving datasets,\nenabling effective research discovery and reproducibility, especially given the\ncurrent exponential growth in scientific research. While Masader (Alyafeai et\nal.,2021) laid the groundwork for extracting a wide range of metadata\nattributes from Arabic NLP datasets' scholarly articles, it relies heavily on\nmanual annotation. In this paper, we present MOLE, a framework that leverages\nLarge Language Models (LLMs) to automatically extract metadata attributes from\nscientific papers covering datasets of languages other than Arabic. Our\nschema-driven methodology processes entire documents across multiple input\nformats and incorporates robust validation mechanisms for consistent output.\nAdditionally, we introduce a new benchmark to evaluate the research progress on\nthis task. Through systematic analysis of context length, few-shot learning,\nand web browsing integration, we demonstrate that modern LLMs show promising\nresults in automating this task, highlighting the need for further future work\nimprovements to ensure consistent and reliable performance. We release the\ncode: https://github.com/IVUL-KAUST/MOLE and dataset:\nhttps://huggingface.co/datasets/IVUL-KAUST/MOLE for the research community.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.19800.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "5f04bd384ec31d33a72116d1",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1594145966049-noauth.jpeg",
      "fullname": "Zaid Alyafeai",
      "name": "Zaid",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 48
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.19056",
      "authors": [
        {
          "_id": "68357c8ef0b7aba41a858b61",
          "name": "Harethah Abu Shairah",
          "hidden": false
        },
        {
          "_id": "68357c8ef0b7aba41a858b62",
          "name": "Hasan Abed Al Kader Hammoud",
          "hidden": false
        },
        {
          "_id": "68357c8ef0b7aba41a858b63",
          "name": "Bernard Ghanem",
          "hidden": false
        },
        {
          "_id": "68357c8ef0b7aba41a858b64",
          "name": "George Turkiyyah",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-25T09:18:24.000Z",
      "submittedOnDailyAt": "2025-05-27T07:21:18.247Z",
      "title": "Les Défenses Simples contre les Attaques des LLM",
      "submittedOnDailyBy": {
        "_id": "642b51385bf2355d02a23d15",
        "avatarUrl": "/avatars/87985347643b2647555f2453fa4d94fb.svg",
        "isPro": true,
        "fullname": "Hasan Abed Al Kader Hammoud",
        "user": "hammh0a",
        "type": "user"
      },
      "summary": "Les modèles de langage grand (LLMs) répondent généralement à des instructions potentiellement dangereuses en suivant les directives de sécurité. Dans les attaques récentes, on a identifié que l'attaque appelée \"abliteration\" sépare et restreint une seule direction potentielle, ce qui a été responsable de la majorité des refus. Nous proposons des mesures de défense pour changer la façon dont les modèles génèrent des refus. Nous avons construit un ensemble de données qui explique pourquoi ils ont refusé des réponses complètes et des messages potentiellement dangereux. Ensuite, nous avons utilisé cet ensemble de données de refus pour des fins d'apprentissage pour ajuster la version de Llama-2-7B-Chat et Qwen2.5-Instruct (avec 150M et 3B paramètres), et nous avons évalué les résultats avec un ensemble de messages potentiellement dangereux. Dans nos expériences, les modèles de refus élargis maintiennent une taux de refus élevé, avec un déclin maximum de 10%, tandis que le taux de refus des modèles de référence diminue jusqu'à 70-80% après l'abliteration. Selon une évaluation large de sécurité et d'utilité, l'ajustement des modèles de refus élargis neutralise l'attaque abliteration et maintient un rendement général.",
      "upvotes": 1,
      "discussionId": "68357c8ff0b7aba41a858b96",
      "ai_summary": "Modifying models to generate justified refusals through fine-tuning on an extended-refusal dataset mitigates ablation attacks while maintaining high refusal rates and general performance.",
      "ai_keywords": [
        "large language models",
        "LLMs",
        "ablation",
        "latent direction",
        "refusal behavior",
        "extended-refusal dataset",
        "Llama-2-7B-Chat",
        "Qwen2.5-Instruct",
        "parameter-efficient fine-tuning"
      ]
    },
    "publishedAt": "2025-05-25T05:18:24.000Z",
    "title": "An Embarrassingly Simple Defense Against LLM Abliteration Attacks",
    "summary": "Large language models (LLMs) are typically aligned to comply with safety\nguidelines by refusing harmful instructions. A recent attack, termed\nabliteration, isolates and suppresses the single latent direction most\nresponsible for refusal behavior, enabling the model to generate unethical\ncontent. We propose a defense that modifies how models generate refusals. We\nconstruct an extended-refusal dataset that contains harmful prompts with a full\nresponse that justifies the reason for refusal. We then fine-tune\nLlama-2-7B-Chat and Qwen2.5-Instruct (1.5B and 3B parameters) on our\nextended-refusal dataset, and evaluate the resulting systems on a set of\nharmful prompts. In our experiments, extended-refusal models maintain high\nrefusal rates, dropping at most by 10%, whereas baseline models' refusal rates\ndrop by 70-80% after abliteration. A broad evaluation of safety and utility\nshows that extended-refusal fine-tuning neutralizes the abliteration attack\nwhile preserving general performance.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.19056.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "642b51385bf2355d02a23d15",
      "avatarUrl": "/avatars/87985347643b2647555f2453fa4d94fb.svg",
      "fullname": "Hasan Abed Al Kader Hammoud",
      "name": "hammh0a",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 5
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2505.18323",
      "authors": [
        {
          "_id": "683573bc0830dfc67834f1b5",
          "name": "Nicolas Küchler",
          "hidden": false
        },
        {
          "_id": "683573bc0830dfc67834f1b6",
          "name": "Ivan Petrov",
          "hidden": false
        },
        {
          "_id": "683573bc0830dfc67834f1b7",
          "name": "Conrad Grobler",
          "hidden": false
        },
        {
          "_id": "683573bc0830dfc67834f1b8",
          "name": "Ilia Shumailov",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-23T19:28:45.000Z",
      "submittedOnDailyAt": "2025-05-27T06:44:57.820Z",
      "title": "Basé sur l'architecture, la gestion des données de localisation des feuilles de papier et les opérations d'inférence des modèles",
      "submittedOnDailyBy": {
        "_id": "6475c2794766357252e69e9f",
        "avatarUrl": "/avatars/db428715dfd2239df2aeaaff1282323f.svg",
        "isPro": false,
        "fullname": "i",
        "user": "iliashum",
        "type": "user"
      },
      "summary": "Au cours des 10 dernières années, l'académie a mis l'accent sur le \"backdoor\" des réseaux neuronaux, en particulier en observant comment les adversaires manipulent les prédictions du modèle. Ces attaques de changement de prédiction ont un objectif malicieux clair, mais leur impact réel n'était pas clair. Dans cet article, basé sur les derniers développements dans l'architecture des réseaux neuronaux, nous proposons une nouvelle classe plus puissante de \"backdoor\", qui utilise l'architecture pour manipuler et endommager les données des utilisateurs à grande échelle. Cette architecture permet que les informations des utilisateurs soient traitées en groupes, ce qui favorise l'information des autres utilisateurs dans la même instance et permet aux attaquants de contrôler complètement la réponse du modèle à d'autres utilisateurs dans la même instance. Par conséquent, un attaquant capable de modifier l'architecture du modèle peut configurer les entrées et sorties d'autres utilisateurs dans la même instance pour causer des dommages. Ces attaques nécessitent l'attention et sont vraiment menaçantes, car peuvent être facilement introduites dans les modèles actuels et représentent une menace réelle à la confidentialité des utilisateurs et à la stabilité du système. Un point clé est que pour faire face à ces nouvelles vulnérabilités, nous proposons une stratégie de réponse basée sur l'analyse du graphe du modèle et la mise en place d'une nouvelle structure de contrôle du flux d'information qui garantit la non-interférence entre les utilisateurs dans la même instance. Avec cette stratégie, nous avons effectué un analyse à grande échelle sur des modèles hébergés sur Hugging Face et nous avons constaté que plus de 200 modèles peuvent causer l'information des données entre instances.",
      "upvotes": 1,
      "discussionId": "683573bc0830dfc67834f212",
      "ai_summary": "A novel class of backdoors in neural network architectures exploits batched inference to enable large-scale data manipulation, demonstrating information leakage and control over user inputs and outputs, with a proposed mitigation strategy using Information Flow Control.",
      "ai_keywords": [
        "backdoors",
        "neural networks",
        "classification tasks",
        "batched inference",
        "hardware utilization",
        "information leakage",
        "mitagation strategy",
        "Information Flow Control",
        "Hugging Face",
        "dynamic quantization"
      ]
    },
    "publishedAt": "2025-05-23T15:28:45.000Z",
    "title": "Architectural Backdoors for Within-Batch Data Stealing and Model\n  Inference Manipulation",
    "summary": "For nearly a decade the academic community has investigated backdoors in\nneural networks, primarily focusing on classification tasks where adversaries\nmanipulate the model prediction. While demonstrably malicious, the immediate\nreal-world impact of such prediction-altering attacks has remained unclear. In\nthis paper we introduce a novel and significantly more potent class of\nbackdoors that builds upon recent advancements in architectural backdoors. We\ndemonstrate how these backdoors can be specifically engineered to exploit\nbatched inference, a common technique for hardware utilization, enabling\nlarge-scale user data manipulation and theft. By targeting the batching\nprocess, these architectural backdoors facilitate information leakage between\nconcurrent user requests and allow attackers to fully control model responses\ndirected at other users within the same batch. In other words, an attacker who\ncan change the model architecture can set and steal model inputs and outputs of\nother users within the same batch. We show that such attacks are not only\nfeasible but also alarmingly effective, can be readily injected into prevalent\nmodel architectures, and represent a truly malicious threat to user privacy and\nsystem integrity. Critically, to counteract this new class of vulnerabilities,\nwe propose a deterministic mitigation strategy that provides formal guarantees\nagainst this new attack vector, unlike prior work that relied on Large Language\nModels to find the backdoors. Our mitigation strategy employs a novel\nInformation Flow Control mechanism that analyzes the model graph and proves\nnon-interference between different user inputs within the same batch. Using our\nmitigation strategy we perform a large scale analysis of models hosted through\nHugging Face and find over 200 models that introduce (unintended) information\nleakage between batch entries due to the use of dynamic quantization.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.18323.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6475c2794766357252e69e9f",
      "avatarUrl": "/avatars/db428715dfd2239df2aeaaff1282323f.svg",
      "fullname": "i",
      "name": "iliashum",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 4
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2505.15957",
      "authors": [
        {
          "_id": "6830745670e219f5de8ad360",
          "user": {
            "_id": "646fa3016441111304fec68d",
            "avatarUrl": "/avatars/923629340f3785ae8c6e52cf3674d5c2.svg",
            "isPro": false,
            "fullname": "Chih-Kai Yang",
            "user": "zenyn",
            "type": "user"
          },
          "name": "Chih-Kai Yang",
          "status": "extracted_confirmed",
          "statusLastChangedAt": "2025-05-23T13:21:28.397Z",
          "hidden": false
        },
        {
          "_id": "6830745670e219f5de8ad361",
          "name": "Neo S. Ho",
          "hidden": false
        },
        {
          "_id": "6830745670e219f5de8ad362",
          "name": "Hung-yi Lee",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-21T19:17:29.000Z",
      "submittedOnDailyAt": "2025-05-27T01:41:21.824Z",
      "title": "Évaluation historique des modèles de langage vocal : Recherche cohérente",
      "submittedOnDailyBy": {
        "_id": "646fa3016441111304fec68d",
        "avatarUrl": "/avatars/923629340f3785ae8c6e52cf3674d5c2.svg",
        "isPro": false,
        "fullname": "Chih-Kai Yang",
        "user": "zenyn",
        "type": "user"
      },
      "summary": "L'évolution des modèles de langage vocal grand (LALM) attend que les modèles qui ajoutent des habiletés vocales démontrent un excellent rendement sur diverses tâches vocales. Pour évaluer ces modèles, plusieurs benchmarks ont été présentés, mais ils sont séparés et n'ont pas une structure organisée. Pour corriger cela, nous avons effectué une recherche détaillée et proposons une technologie systématique appropriée pour l'évaluation des LALM. Cette technologie est classée en quatre dimensions selon leur objectif : (1) reconnaissance et traitement général du langage vocal, (2) connaissance et logique, (3) capacités diaphoniques, (4) équité, sécurité et confiance. Des résumés détaillés sont fournis dans chaque catégorie pour clarifier les problèmes et donner des conseils sur les possibilités futures. En raison de nos limites de connaissances, ceci est la première recherche spécialisée dans l'évaluation des LALM et fournit à la communauté une ligne claire. Nous publions le ensemble des articles recherchés et continuons d'actualiser pour soutenir le développement de cette domaine.",
      "upvotes": 1,
      "discussionId": "6830745770e219f5de8ad38b",
      "projectPage": "https://github.com/ckyang1124/LALM-Evaluation-Survey",
      "githubRepo": "https://github.com/ckyang1124/LALM-Evaluation-Survey",
      "ai_summary": "A survey proposes a systematic taxonomy for evaluating large audio-language models across dimensions including auditory awareness, knowledge reasoning, dialogue ability, and fairness, to address fragmented benchmarks in the field.",
      "ai_keywords": [
        "large audio-language models",
        "LALMs",
        "large language models",
        "LLMs",
        "auditory capabilities",
        "general auditory awareness",
        "processing",
        "knowledge and reasoning",
        "dialogue-oriented ability",
        "fairness",
        "safety",
        "trustworthiness",
        "taxonomy",
        "evaluations",
        "benchmark",
        "survey",
        "guidelines"
      ]
    },
    "publishedAt": "2025-05-21T15:17:29.000Z",
    "title": "Towards Holistic Evaluation of Large Audio-Language Models: A\n  Comprehensive Survey",
    "summary": "With advancements in large audio-language models (LALMs), which enhance large\nlanguage models (LLMs) with auditory capabilities, these models are expected to\ndemonstrate universal proficiency across various auditory tasks. While numerous\nbenchmarks have emerged to assess LALMs' performance, they remain fragmented\nand lack a structured taxonomy. To bridge this gap, we conduct a comprehensive\nsurvey and propose a systematic taxonomy for LALM evaluations, categorizing\nthem into four dimensions based on their objectives: (1) General Auditory\nAwareness and Processing, (2) Knowledge and Reasoning, (3) Dialogue-oriented\nAbility, and (4) Fairness, Safety, and Trustworthiness. We provide detailed\noverviews within each category and highlight challenges in this field, offering\ninsights into promising future directions. To the best of our knowledge, this\nis the first survey specifically focused on the evaluations of LALMs, providing\nclear guidelines for the community. We will release the collection of the\nsurveyed papers and actively maintain it to support ongoing advancements in the\nfield.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.15957.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "646fa3016441111304fec68d",
      "avatarUrl": "/avatars/923629340f3785ae8c6e52cf3674d5c2.svg",
      "fullname": "Chih-Kai Yang",
      "name": "zenyn",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": true
  }
]