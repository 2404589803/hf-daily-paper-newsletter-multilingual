[
  {
    "paper": {
      "id": "2502.03032",
      "authors": [
        {
          "_id": "67a59c4e7ffacd843a56404a",
          "user": {
            "_id": "634c5f8cfb80cc6bcaf42c03",
            "avatarUrl": "/avatars/1f37db0e70cbaf9707f4c8cbcee37ca0.svg",
            "isPro": false,
            "fullname": "Daniil Laptev",
            "user": "dlaptev",
            "type": "user"
          },
          "name": "Daniil Laptev",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-07T09:58:04.546Z",
          "hidden": false
        },
        {
          "_id": "67a59c4e7ffacd843a56404b",
          "user": {
            "_id": "60b364e7f88532cd79eaff7b",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1654185363389-60b364e7f88532cd79eaff7b.jpeg",
            "isPro": false,
            "fullname": "Nikita Balagansky",
            "user": "elephantmipt",
            "type": "user"
          },
          "name": "Nikita Balagansky",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-07T09:58:02.693Z",
          "hidden": false
        },
        {
          "_id": "67a59c4e7ffacd843a56404c",
          "name": "Yaroslav Aksenov",
          "hidden": false
        },
        {
          "_id": "67a59c4e7ffacd843a56404d",
          "user": {
            "_id": "62a9c8edc19f92ae443ab37f",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1669110208492-62a9c8edc19f92ae443ab37f.png",
            "isPro": false,
            "fullname": "Daniil Gavrilov",
            "user": "kefirski",
            "type": "user"
          },
          "name": "Daniil Gavrilov",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-07T09:58:06.718Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-05T09:39:34.000Z",
      "title": "Caractéristiques d'analyse de flux pour améliorer l'interprétation du modèle de langue et la guide pour l'utilisateur.",
      "summary": "Un nouvel approche permet de cartographier systématiquement les caractéristiques détectées par un codificateur automatique sparse dans les couches continues de modèles de langage grands. Dans des études précédentes, les connexions entre caractéristiques entre couches ont été examinées, et la manière dont une caractéristique spécifique est maintenue, déformée ou apparaît pour la première fois a été suivie en utilisant des méthodes de similarité cosinus sans données. Ce méthode génère des graphiques qui décrivent détaillément l'évolution des caractéristiques et fournit une compréhension structurale du calcul du modèle. Il est important de souligner que ce cartographie des caractéristiques entre couches permet de contrôler directement le comportement du modèle en renforçant ou en inhibant des caractéristiques sélectionnées, ce qui permet de contrôler le thème dans la génération de textes. Ces résultats clarifient l'utilité de structures explicatives causales et intermédiaires entre couches, et aident à comprendre comment les caractéristiques se développent lors du processus de propagation, offrant de nouvelles façons de comprendre le comportement transparent des modèles de langage grands.",
      "upvotes": 34,
      "discussionId": "67a59c4f7ffacd843a56408f"
    },
    "publishedAt": "2025-02-07T01:29:53.798Z",
    "title": "Analyze Feature Flow to Enhance Interpretation and Steering in Language Models",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.03032.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "62a9c8edc19f92ae443ab37f",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1669110208492-62a9c8edc19f92ae443ab37f.png",
      "fullname": "Daniil Gavrilov",
      "name": "kefirski",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 10
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.04153",
      "authors": [
        {
          "_id": "67a57b1fdea89ffe80d9fe56",
          "user": {
            "_id": "66c89152d33e34fbc29497d7",
            "avatarUrl": "/avatars/bbddabf6532393951c4759e5915a065b.svg",
            "isPro": false,
            "fullname": "KaikaiAn",
            "user": "kkk-an",
            "type": "user"
          },
          "name": "Kaikai An",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-07T09:58:18.320Z",
          "hidden": false
        },
        {
          "_id": "67a57b1fdea89ffe80d9fe57",
          "name": "Li Sheng",
          "hidden": false
        },
        {
          "_id": "67a57b1fdea89ffe80d9fe58",
          "name": "Ganqu Cui",
          "hidden": false
        },
        {
          "_id": "67a57b1fdea89ffe80d9fe59",
          "user": {
            "_id": "637c99bbfe115289cfedfb44",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/637c99bbfe115289cfedfb44/344NN9KKF_XXTlVYaGaMW.png",
            "isPro": false,
            "fullname": "ssz",
            "user": "ssz1111",
            "type": "user"
          },
          "name": "Shuzheng Si",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-07T09:58:16.229Z",
          "hidden": false
        },
        {
          "_id": "67a57b1fdea89ffe80d9fe5a",
          "name": "Ning Ding",
          "hidden": false
        },
        {
          "_id": "67a57b1fdea89ffe80d9fe5b",
          "name": "Yu Cheng",
          "hidden": false
        },
        {
          "_id": "67a57b1fdea89ffe80d9fe5c",
          "name": "Baobao Chang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-06T15:39:16.000Z",
      "title": "UltraIF : On promeut la trace des commandes de la nature.",
      "summary": "Les instructions suivantes jouent le rôle d'assistant pour utiliser des modèles de langage grands et modernes (LLMs). Cependant, le contrôle de LLMs par des commandes complexes nécessite un secret crucial, et il existe un grand écart entre les modèles entraînés par des communautés ouvertes et les entreprises de pointe. Pour combler cet écart, nous proposons une approche simple et extensible basée sur des données ouvertes pour construire des LLMs capables de suivre des commandes complexes, appelée \"UltraIF\". UltraIF commence par décomposer les instructions utilisateurs en termes de recherche simples, conditions de restriction et questions d'évaluation correspondantes à ces conditions. Ensuite, nous entraînons UltraComposer pour configurer des instructions et des questions d'évaluation liées aux conditions de restriction. Cette configuration des instructions permet la synthèse de commandes complexes et la filtration des réponses par des questions d'évaluation. Dans nos expériences, nous montrons d'abord que nous pouvons suivre 5 commandes avec le modèle LLaMA-3.1-8B-Base, le convertissant en une version d'instructions. Cela a permis de générer des réponses sans utiliser de l'information du benchmark, en utilisant le modèle comme générateur de réponses et évaluateur. Le modèle associé a obtenu des scores compétitifs dans d'autres benchmarks. De plus, UltraIF montre que il peut améliorer le modèle LLaMA-3.1-8B-Instruct par autoconnexion, promouvant largement l'utilisation de cette méthode. Notre code est disponible sur https://github.com/kkk-an/UltraIF.",
      "upvotes": 13,
      "discussionId": "67a57b1fdea89ffe80d9fe93"
    },
    "publishedAt": "2025-02-06T22:27:51.425Z",
    "title": "UltraIF: Advancing Instruction Following from the Wild",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.04153.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "66c89152d33e34fbc29497d7",
      "avatarUrl": "/avatars/bbddabf6532393951c4759e5915a065b.svg",
      "fullname": "KaikaiAn",
      "name": "kkk-an",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.04328",
      "authors": [
        {
          "_id": "67a586fad177de2eeba7de7b",
          "user": {
            "_id": "64f001bfabd9fb1914398bd5",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64f001bfabd9fb1914398bd5/9teH82hkBI4csIz_WQh5q.jpeg",
            "isPro": false,
            "fullname": "liuzuyan",
            "user": "Zuyan",
            "type": "user"
          },
          "name": "Zuyan Liu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-07T09:58:10.679Z",
          "hidden": false
        },
        {
          "_id": "67a586fad177de2eeba7de7c",
          "name": "Yuhao Dong",
          "hidden": false
        },
        {
          "_id": "67a586fad177de2eeba7de7d",
          "name": "Jiahui Wang",
          "hidden": false
        },
        {
          "_id": "67a586fad177de2eeba7de7e",
          "name": "Ziwei Liu",
          "hidden": false
        },
        {
          "_id": "67a586fad177de2eeba7de7f",
          "name": "Winston Hu",
          "hidden": false
        },
        {
          "_id": "67a586fad177de2eeba7de80",
          "name": "Jiwen Lu",
          "hidden": false
        },
        {
          "_id": "67a586fad177de2eeba7de81",
          "name": "Yongming Rao",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-06T18:59:55.000Z",
      "title": "Ora: Transcende les frontières d'un modèle de langage 360 degrés en utilisant une tête de modèle avancée de diversité.",
      "summary": "Récemment, l'intérêt pour le développement de grands modèles de langage, notamment après GPT-4, a augmenté en raison de leur capacité à comprendre et à traiter différents types d'informations. Cependant, le progrès en termes de performance a été plus lent par rapport aux modèles spécialisés. Dans cet article, nous présentons le modèle de langage Omni-modal appelé Ola. Ola atteint un rendement comparable à des modèles spécialisés en images, vidéos et sons. Le design central d'Ola est une stratégie avancée pour la configuration de modèles. Dans cette stratégie, on commence avec des modèles plus différents et on élargit progressivement l'ensemble des compétences du modèle à travers des données de dialogue qui relient le langage et le son, ou des données de vidéo qui relient tout le modèle. Ce système d'apprentissage en ligne permet de maintenir le taille des données d'entraînement croisée entre modèles et facilite le développement de modèles Omni-modal de manière efficace et rentable, par rapport aux modèles visuels linguistiques actuels. De plus, pour atteindre des expériences interactifs de haute dimension comme GPT-4, Ola développe une stratégie de résolution de langage à l'échelle de la phrase. Les expériences distribuées dépassent les modèles opensource actuels dans tous les modèles et atteignent des rendements comparables à ceux des modèles les plus avancés de rendement spécialisé de la même dimension. Ola propose de devenir une solution complètement opensource de compréhension Omni-modal pour pousser l'investigation future dans ce domaine émergeant. Les poids du modèle, le code et les données sont opensource sur GitHub à l'adresse https://github.com/Ola-Omni/Ola.",
      "upvotes": 8,
      "discussionId": "67a586fbd177de2eeba7deae"
    },
    "publishedAt": "2025-02-07T00:54:43.254Z",
    "title": "Ola: Pushing the Frontiers of Omni-Modal Language Model with Progressive Modality Alignment",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.04328.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64f001bfabd9fb1914398bd5",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64f001bfabd9fb1914398bd5/9teH82hkBI4csIz_WQh5q.jpeg",
      "fullname": "liuzuyan",
      "name": "Zuyan",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.03621",
      "authors": [
        {
          "_id": "67a59e5298f41a0460ee5282",
          "name": "Danah Yatim",
          "hidden": false
        },
        {
          "_id": "67a59e5298f41a0460ee5283",
          "name": "Rafail Fridman",
          "hidden": false
        },
        {
          "_id": "67a59e5298f41a0460ee5284",
          "name": "Omer Bar-Tal",
          "hidden": false
        },
        {
          "_id": "67a59e5298f41a0460ee5285",
          "name": "Tali Dekel",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-05T21:14:55.000Z",
      "title": "DynVFX : Contenu dynamique ajouté dans les vidéos réelles",
      "summary": "Nous proposons un méthode pour ajouter de nouveaux contenus dynamiques à des vidéos réelles lors de leur création. Étant donné un vidéo d'entrée et une indication textuelle brève du contenu désiré par l'utilisateur, notre méthode synthétise des objets dynamiques qui interagissent avec l'espace existant ou des espaces complexes au fur et à mesure du temps. La position, l'apparence et le mouvement du nouveau contenu sont intégrés sans distorsion avec l'image originale, en tenant compte du mouvement de la caméra, de l'occultation et de l'interaction avec d'autres objets dynamiques dans l'espace. De cette manière, on obtient une sortie vidéo réaliste cohérente. Cette méthode est implémentée en utilisant des transformeurs d'expansion de vidéo à partir de texte pré-entraînés et des modèles de langage visuo-linguistique pré-entraînés, permettant un approche 0-shot et sans entraînement. Pour faciliter l'attribution précise de la position et l'intégration sans distorsion du nouveau contenu, nous introduisons un méthode d'inférence basée sur des caractéristiques manipulées dans des structures d'attention. Cette méthode est entièrement automatisée mais nécessite seulement des instructions simples de l'utilisateur. Nous montrons les résultats de l'application de cette méthode à des vidéos réelles, qui comprennent divers scénarios avec des objets et des scénarios variés selon le mouvement de la caméra et les objets.",
      "upvotes": 8,
      "discussionId": "67a59e5798f41a0460ee5389"
    },
    "publishedAt": "2025-02-07T00:48:49.217Z",
    "title": "DynVFX: Augmenting Real Videos with Dynamic Content",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.03621.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6181c72cdcc1df2c9de8a4d8",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1655248010394-6181c72cdcc1df2c9de8a4d8.jpeg",
      "fullname": "Hila Chefer",
      "name": "Hila",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 9
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.02358",
      "authors": [
        {
          "_id": "67a43546f6caedc30f9d8c71",
          "user": {
            "_id": "659faf1d874e583fed79d09b",
            "avatarUrl": "/avatars/178a18686426908b9496ce71f6550655.svg",
            "isPro": false,
            "fullname": "Ziyan Guo",
            "user": "ZiyanGuo",
            "type": "user"
          },
          "name": "Ziyan Guo",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-06T14:15:01.599Z",
          "hidden": false
        },
        {
          "_id": "67a43546f6caedc30f9d8c72",
          "name": "Zeyu Hu",
          "hidden": false
        },
        {
          "_id": "67a43546f6caedc30f9d8c73",
          "name": "Na Zhao",
          "hidden": false
        },
        {
          "_id": "67a43546f6caedc30f9d8c74",
          "name": "De Wen Soh",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-04T14:43:26.000Z",
      "title": "MotionLab : Génération et édition de mouvements humains par un paradigme dynamique de conditions unifiées dynamique",
      "summary": "La génération et l'édition de mouvements humains sont des éléments essentiels de la graphique informatique et de la vision. Cependant, la manière dont ce domaine est actuellement abordé offre des solutions séparées pour des tâches spécifiques, qui ne s'adaptent pas bien aux applications réelles. D'autre part, certains efforts visent à intégrer des tâches liées au mouvement, mais ces méthodologies se concentrent uniquement sur la guidage du mouvement par des modèles différents, sans fonctionnalités d'édition et de contrôle détaillés, et ne favorisent pas la partage de connaissances entre les tâches. Pour surmonter ces limitations et fournir un cadre fonctionnel et uniforme qui aborde à la fois la génération et l'édition de mouvements humains, on propose un nouveau paradigme : « Motion Condition Motion ». Avec ce paradigme, on propose « Movement Lab ». Movement Lab apprend à cartographier des mouvements sources vers des mouvements cibles en utilisant des flux de flux normalisés guidés par des conditions spécifiques. Dans Movement Lab, 1) on introduit le Motion Flow Channel Setter pour renforcer la génération et l'édition sans nécessiter de modules de tâche spécifique, 2) on utilise l'Encodage de Position d'Alignement pour garantir la synchronisation temporelle entre les mouvements sources et cibles, 3) on modélise l'instruction de tâche spécifique, et 4) on apprend le noyau de mouvement pour promouvoir un apprentissage efficace de multiples tâches et la partage de connaissances entre eux. En particulier, notre Movement Lab montre un bon rendement de généralisation et une efficacité d'inférence dans plusieurs benchmarks de mouvements humains. Notre code et nos résultats supplémentaires en vidéo sont disponibles sur la suivante URL : https://diouo.github.io/motionlab.github.io/.",
      "upvotes": 8,
      "discussionId": "67a43547f6caedc30f9d8c9b"
    },
    "publishedAt": "2025-02-06T23:38:19.926Z",
    "title": "MotionLab: Unified Human Motion Generation and Editing via the Motion-Condition-Motion Paradigm",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.02358.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "659faf1d874e583fed79d09b",
      "avatarUrl": "/avatars/178a18686426908b9496ce71f6550655.svg",
      "fullname": "Ziyan Guo",
      "name": "ZiyanGuo",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.04313",
      "authors": [
        {
          "_id": "67a5b9107897c8f5406155e0",
          "name": "Shashwat Goel",
          "hidden": false
        },
        {
          "_id": "67a5b9107897c8f5406155e1",
          "name": "Joschka Struber",
          "hidden": false
        },
        {
          "_id": "67a5b9107897c8f5406155e2",
          "name": "Ilze Amanda Auzina",
          "hidden": false
        },
        {
          "_id": "67a5b9107897c8f5406155e3",
          "name": "Karuna K Chandra",
          "hidden": false
        },
        {
          "_id": "67a5b9107897c8f5406155e4",
          "name": "Ponnurangam Kumaraguru",
          "hidden": false
        },
        {
          "_id": "67a5b9107897c8f5406155e5",
          "name": "Douwe Kiela",
          "hidden": false
        },
        {
          "_id": "67a5b9107897c8f5406155e6",
          "name": "Ameya Prabhu",
          "hidden": false
        },
        {
          "_id": "67a5b9107897c8f5406155e7",
          "name": "Matthias Bethge",
          "hidden": false
        },
        {
          "_id": "67a5b9107897c8f5406155e8",
          "name": "Jonas Geiping",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-06T18:56:01.000Z",
      "title": "Le modèle pense de la même manière, cela réduit la vision et l'audition de l'IA.",
      "summary": "Avec le développement des capacités d'un modèle de langage (LM), on a constaté que l'évaluation et la supervision scalaires sont des tâches difficiles pour l'humanité. D'autres LM ont été considérés comme capables de automatiser ces tâches, ce qui a été considéré souhaitable, et ils ont été nommés \"Surveillance Artificielle\". Pour étudier comment la similitude entre LM affecte les deux aspects de la Surveillance Artificielle, on propose une mesure de probabilité de similitude basée sur le répétition d'erreurs de modèle. En utilisant cette mesure, on montre d'abord que les scores d'un jury d'un modèle de langage acte de manière plus favorable pour des modèles similaires au jury, et on généralise les résultats automatiques de préférence récentes. Ensuite, on étudie l'entraînement de LM avec des notes de modèles, et on observe que le point moyen entre un superviseur faible et un modèle étudiant fort a un effet de \"la faiblesse est importante pour une forte généralisation\". Avec l'augmentation de la capacité du modèle, on s'attend à ce que la recherche d'erreurs dans le modèle devienne plus difficile, et que les demandes de la Surveillance Artificielle augmentent. Cependant, on observe une tendance de préoccupation. Les erreurs du modèle deviennent plus similaires à mesure qu'elles augmentent en capacité, et il y a un risque de défaillance dans la corrélation. Dans cet article, on rapporte la similitude entre modèles dans le nouveau paradigme de la Surveillance Artificielle et on souligne l'importance de la correction.",
      "upvotes": 7,
      "discussionId": "67a5b9137897c8f540615673"
    },
    "publishedAt": "2025-02-07T02:46:29.675Z",
    "title": "Great Models Think Alike and this Undermines AI Oversight",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/6506832221ac448013f94995/pXBCc2dpWXCw6JinTbiFP.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.04313.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6506832221ac448013f94995",
      "avatarUrl": "/avatars/0a86f64cb502a04ab1487d78f63bf3fd.svg",
      "fullname": "Shashwat Goel",
      "name": "shash42",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.03544",
      "authors": [
        {
          "_id": "67a589ebb16fabcdd2dea1eb",
          "name": "Yuri Chervonyi",
          "hidden": false
        },
        {
          "_id": "67a589ebb16fabcdd2dea1ec",
          "name": "Trieu H. Trinh",
          "hidden": false
        },
        {
          "_id": "67a589ebb16fabcdd2dea1ed",
          "name": "Miroslav Olšák",
          "hidden": false
        },
        {
          "_id": "67a589ebb16fabcdd2dea1ee",
          "name": "Xiaomeng Yang",
          "hidden": false
        },
        {
          "_id": "67a589ebb16fabcdd2dea1ef",
          "name": "Hoang Nguyen",
          "hidden": false
        },
        {
          "_id": "67a589ebb16fabcdd2dea1f0",
          "name": "Marcelo Menegali",
          "hidden": false
        },
        {
          "_id": "67a589ebb16fabcdd2dea1f1",
          "name": "Junehyuk Jung",
          "hidden": false
        },
        {
          "_id": "67a589ebb16fabcdd2dea1f2",
          "name": "Vikas Verma",
          "hidden": false
        },
        {
          "_id": "67a589ebb16fabcdd2dea1f3",
          "name": "Quoc V. Le",
          "hidden": false
        },
        {
          "_id": "67a589ebb16fabcdd2dea1f4",
          "name": "Thang Luong",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-05T19:02:03.000Z",
      "title": "Le problème de la géométrie des Olympiades résolu par AlphaGeometry2 : les réalisations du classement des médailles d'or",
      "summary": "AlphaGeometry2 est une version considérablement améliorée de AlphaGeometry, introduite par Trinh et al. (2024). Ce système a atteint des résultats supérieurs à ceux des meilleurs joueurs du tournoi olympique de géométrie. Initialement, AlphaGeometry a été étendu pour aborder des problèmes plus complexes. Cela a permis de résoudre des problèmes qui incluaient des équations linéaires, des ratios et des distances. Avec ces extensions et d'autres fonctionnalités, la couverture du langage d'AlphaGeometry sur les problèmes de la Conférence Internationale de Mathématiques Olympiades (CIMO) de 2000 à 2024 a augmenté de 66% à 88%. De plus, l'amélioration du modèle du langage en utilisant l'architecture Gemini et l'introduction d'un nouveau mécanisme de partage de connaissances (combinant plusieurs arbres de recherche) a considérablement amélioré le processus d'exploration de AlphaGeometry2. De plus, l'amélioration du moteur d'opérations avec des symboles et la génération de données synthétiques ont augmenté la taux de réponses complètes de AlphaGeometry2, qui maintenant résout 84% de tous les problèmes développés sur les 25 ans (précédemment, 54%). AlphaGeometry2 a été partie d'un système qui a atteint le niveau pour la médaille d'argent de la CIMO 2024 (voir plus d'informations sur https://dpmd.ai/imo-silver). Enfin, un rapport sur le développement d'un système entièrement automatique pour résoudre des problèmes de géométrie entrés naturellement est présenté.",
      "upvotes": 7,
      "discussionId": "67a589ecb16fabcdd2dea259"
    },
    "publishedAt": "2025-02-06T23:20:09.641Z",
    "title": "Gold-medalist Performance in Solving Olympiad Geometry with AlphaGeometry2",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.03544.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5968
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.04306",
      "authors": [
        {
          "_id": "67a57f334e50b2956b13f4e0",
          "user": {
            "_id": "6730dc8df84c8aac97451e57",
            "avatarUrl": "/avatars/4f2cf5363b17744daca41d2a18ddfeb8.svg",
            "isPro": false,
            "fullname": "Yinjie Wang",
            "user": "yinjiewang",
            "type": "user"
          },
          "name": "Yinjie Wang",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-02-07T03:34:13.176Z",
          "hidden": false
        },
        {
          "_id": "67a57f334e50b2956b13f4e1",
          "name": "Ling Yang",
          "hidden": false
        },
        {
          "_id": "67a57f334e50b2956b13f4e2",
          "name": "Guohao Li",
          "hidden": false
        },
        {
          "_id": "67a57f334e50b2956b13f4e3",
          "name": "Mengdi Wang",
          "hidden": false
        },
        {
          "_id": "67a57f334e50b2956b13f4e4",
          "name": "Bryon Aragam",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-06T18:47:49.000Z",
      "title": "Score Flow : Comprendre le flux de scores pour optimiser le flux de préférences basées sur les scores dans le flux de travail de l'agent de la langue de l'intelligence artificielle (LLM).",
      "summary": "Les derniers études ont souligné l'utilisation de systèmes de modèles de langue grands avec plusieurs agents pour réduire l'effort nécessaire pour la construction automatique de modèles dans des problèmes complexes. Cela a conduit au développement de méthodes d'optimisation des flux de travail d'agents automatiques. Cependant, les méthodes actuelles présentent des problèmes tels que des limitations de représentation, une faible adaptabilité et une faible scalabilité dues aux méthodes d'optimisation discrètes, ce qui limite leur flexibilité. ScoreFlow, un cadre de travail simple et hautement efficace, aborde ces défis. ScoreFlow utilise une optimisation basée sur les gradients efficaces. De plus, il introduit une variante de la nouvelle méthodologie d'optimisation de préférences directes, Score-DPO, en considérant la rétroaction quantitative. Grâce à six tests de benchmark, ScoreFlow a réalisé des améliorations de 8,2% par rapport aux base lines existants. De plus, ces petits modèles peuvent surpasser les grands modèles avec un coût d'inférence réduit. Projet : https://github.com/Gen-Verse/ScoreFlow",
      "upvotes": 7,
      "discussionId": "67a57f354e50b2956b13f53d"
    },
    "publishedAt": "2025-02-06T22:34:42.483Z",
    "title": "ScoreFlow: Mastering LLM Agent Workflows via Score-based Preference Optimization",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.04306.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64fde4e252e82dd432b74ce9",
      "avatarUrl": "/avatars/061a69d858b86d1600be916122cae7fc.svg",
      "fullname": "Ling Yang",
      "name": "Lingaaaaaaa",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 6
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.04128",
      "authors": [
        {
          "_id": "67a5894db16fabcdd2de5459",
          "user": {
            "_id": "645f172d7c6bff8577353d1a",
            "avatarUrl": "/avatars/a83682e1343809257b082b78d58c582a.svg",
            "isPro": false,
            "fullname": "ZhenYE",
            "user": "ZhenYe234",
            "type": "user"
          },
          "name": "Zhen Ye",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-07T09:58:08.787Z",
          "hidden": false
        },
        {
          "_id": "67a5894db16fabcdd2de545a",
          "name": "Xinfa Zhu",
          "hidden": false
        },
        {
          "_id": "67a5894db16fabcdd2de545b",
          "name": "Chi-Min Chan",
          "hidden": false
        },
        {
          "_id": "67a5894db16fabcdd2de545c",
          "name": "Xinsheng Wang",
          "hidden": false
        },
        {
          "_id": "67a5894db16fabcdd2de545d",
          "name": "Xu Tan",
          "hidden": false
        },
        {
          "_id": "67a5894db16fabcdd2de545e",
          "name": "Jiahe Lei",
          "hidden": false
        },
        {
          "_id": "67a5894db16fabcdd2de545f",
          "name": "Yi Peng",
          "hidden": false
        },
        {
          "_id": "67a5894db16fabcdd2de5460",
          "name": "Haohe Liu",
          "hidden": false
        },
        {
          "_id": "67a5894db16fabcdd2de5461",
          "name": "Yizhu Jin",
          "hidden": false
        },
        {
          "_id": "67a5894db16fabcdd2de5462",
          "name": "Zheqi DAI",
          "hidden": false
        },
        {
          "_id": "67a5894db16fabcdd2de5463",
          "name": "Hongzhan Lin",
          "hidden": false
        },
        {
          "_id": "67a5894db16fabcdd2de5464",
          "name": "Jianyi Chen",
          "hidden": false
        },
        {
          "_id": "67a5894db16fabcdd2de5465",
          "name": "Xingjian Du",
          "hidden": false
        },
        {
          "_id": "67a5894db16fabcdd2de5466",
          "name": "Liumeng Xue",
          "hidden": false
        },
        {
          "_id": "67a5894db16fabcdd2de5467",
          "name": "Yunlin Chen",
          "hidden": false
        },
        {
          "_id": "67a5894db16fabcdd2de5468",
          "name": "Zhifei Li",
          "hidden": false
        },
        {
          "_id": "67a5894db16fabcdd2de5469",
          "name": "Lei Xie",
          "hidden": false
        },
        {
          "_id": "67a5894db16fabcdd2de546a",
          "name": "Qiuqiang Kong",
          "hidden": false
        },
        {
          "_id": "67a5894db16fabcdd2de546b",
          "name": "Yike Guo",
          "hidden": false
        },
        {
          "_id": "67a5894db16fabcdd2de546c",
          "user": {
            "_id": "6628adb14277eae0da5eee28",
            "avatarUrl": "/avatars/6cb41b80cc5e014e455dfc2a22682e64.svg",
            "isPro": true,
            "fullname": "HKUST Audio",
            "user": "HKUST-Audio",
            "type": "user"
          },
          "name": "Wei Xue",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-02-07T04:17:17.888Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-06T15:04:00.000Z",
      "title": "Razna: Expansion de la computation pour l'entraînement et l'inférence dans la synthèse de voix basée sur le RAM",
      "summary": "Récemment, le développement de grands modèles de langue basés sur des documents (LLMs) a reçu beaucoup d'attention, notamment les séries GPT et le modèle o1, en raison de leur capacité à échelonner le calcul pendant l'entraînement et l'inférence. Cependant, les systèmes de TTS qui utilisent les plus avancés LLMs actuels sont composés de plusieurs étapes, ce qui complique la décision sur l'échellabilité des modèles spécifiques pendant l'entraînement et le test. Dans cette étude, nous présentons les contributions suivantes : premièrement, nous appliquons l'échelle du calcul pendant l'entraînement et l'inférence à la synthèse de voix. Deuxièmement, nous proposons un cadre simple appelé Llasa, qui utilise une couche de quantification vectorielle (VQ) et une architecture Transformer, et est ajusté aux modèles de LLMs standards (par exemple, Llama). Les expérimentations montrent que l'échelle du calcul pendant l'entraînement de Llasa améliore constamment la nature de la voix synthétisée et permet la génération de patrons de voix complexes et précis. De plus, à la lumière de l'échelle du calcul pendant l'inférence, nous utilisons un modèle de compréhension de la voix comme évaluateur pour effectuer des recherches, et nous confirmons que l'échelle du calcul pendant l'inférence peut se transformer en mode de rééchantillonnage selon la préférence d'un évaluateur spécifique, améliorant l'expression émotionnelle, la consistance de la tonalité et la précision du contenu. De plus, nous publions les modèles de TTS (1B, 3B, 8B) et les checkpoints et codes d'entraînement des modèles de code.",
      "upvotes": 5,
      "discussionId": "67a5894db16fabcdd2de54d3"
    },
    "publishedAt": "2025-02-06T23:17:40.725Z",
    "title": "Llasa: Scaling Train-Time and Inference-Time Compute for Llama-based Speech Synthesis",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.04128.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5968
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.04299",
      "authors": [
        {
          "_id": "67a591234020a3bfdb8cb2e5",
          "name": "Jinbo Xing",
          "hidden": false
        },
        {
          "_id": "67a591234020a3bfdb8cb2e6",
          "name": "Long Mai",
          "hidden": false
        },
        {
          "_id": "67a591234020a3bfdb8cb2e7",
          "name": "Cusuh Ham",
          "hidden": false
        },
        {
          "_id": "67a591234020a3bfdb8cb2e8",
          "name": "Jiahui Huang",
          "hidden": false
        },
        {
          "_id": "67a591234020a3bfdb8cb2e9",
          "name": "Aniruddha Mahapatra",
          "hidden": false
        },
        {
          "_id": "67a591234020a3bfdb8cb2ea",
          "name": "Chi-Wing Fu",
          "hidden": false
        },
        {
          "_id": "67a591234020a3bfdb8cb2eb",
          "name": "Tien-Tsin Wong",
          "hidden": false
        },
        {
          "_id": "67a591234020a3bfdb8cb2ec",
          "name": "Feng Liu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-06T18:41:04.000Z",
      "title": "MotionCanvas : Conception de résumés de films et génération d'animation à partir d'images contrôlables",
      "summary": "Dans cet article, nous proposons un méthode pour concevoir des photos de vidéo dans le contexte d'un système qui génère des vidéos à partir d'images. La conception des photos est un aspect important dans la production de films, car elle implique de planifier soigneusement le mouvement de la caméra et les mouvements des objets sur l'écran. Cependant, il existe deux problèmes principaux qui empêchent que la conception des photos soit intuitive dans les systèmes actuels qui génèrent des vidéos à partir d'images : 1. Il est nécessaire de spécifier, conjointement au mouvement de la caméra, le mouvement des objets dans l'espace de l'écran pour comprendre correctement les intérêts du utilisateur. 2. Il est nécessaire que le modèle de diffusion de vidéo puisse représenter des informations de mouvement utiles pour l'animation des images synthétiques. Pour résoudre ces problèmes, nous proposons la technique appelée \"MotionCanvas\". Cette technique intègre le contrôle utilisateur dans les modèles qui génèrent des vidéos à partir d'images, permettant de contrôler le mouvement des objets et de la caméra en fonction du contexte de l'écran. En intégrant la vision classique de graphiques computationnels avec les technologies modernes de génération de vidéo, MotionCanvas montre comment peut être mis en place le contrôle de mouvement lié à 3D sans nécessiter de données d'entraînement coûteuses, réduisant ainsi les coûts associés au contrôle de mouvement 3D dans la composition de vidéos. Dans MotionCanvas, les utilisateurs peuvent exprimer de manière intuitive le mouvement dans l'espace de l'écran, ce qui peut être traduit en des signaux de conditions de mouvement espace-temporelles que le modèle de diffusion de vidéo peut utiliser. Dans des contenus réels et dans différents scénarios de conception des photos, nous montrons l'efficacité de notre méthode, améliorant le flux de travail créatif dans la production de contenu numérique et montrant son application dans des applications d'édition d'images et de vidéos.",
      "upvotes": 3,
      "discussionId": "67a5912b4020a3bfdb8cb4d5"
    },
    "publishedAt": "2025-02-06T23:50:54.836Z",
    "title": "MotionCanvas: Cinematic Shot Design with Controllable Image-to-Video Generation",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.04299.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5968
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.03860",
      "authors": [
        {
          "_id": "67a5880c886a1e223b1d57ec",
          "name": "Bo Pang",
          "hidden": false
        },
        {
          "_id": "67a5880c886a1e223b1d57ed",
          "name": "Hanze Dong",
          "hidden": false
        },
        {
          "_id": "67a5880c886a1e223b1d57ee",
          "name": "Jiacheng Xu",
          "hidden": false
        },
        {
          "_id": "67a5880c886a1e223b1d57ef",
          "name": "Silvio Savarese",
          "hidden": false
        },
        {
          "_id": "67a5880c886a1e223b1d57f0",
          "name": "Yingbo Zhou",
          "hidden": false
        },
        {
          "_id": "67a5880c886a1e223b1d57f1",
          "name": "Caiming Xiong",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-06T08:19:59.000Z",
      "title": "BOLT : Conception d'un modèle de langage qui ne réduit pas l'arrêt de décélération dans les chaînes de pensée longues",
      "summary": "Les modèles de langage grand (LLMs) sont connus pour leur puissance exceptionnelle, comme démontré par OpenAI's o1. Le modèle o1 génère une longue chaîne de pensée (LongCoT) avant de présenter une réponse. La LongCoT permet aux LLMs d'analyser des problèmes, de planifier, de réfléchir et de se rétracter, améliorant ainsi leur capacité à résoudre des problèmes complexes. Après la publication de o1, de nombreux équipes ont essayé de reproduire sa logique et sa LongCoT. Pour cela, il a principalement dépendu de l'expérience de modèles déjà dotés de cette capacité (comme OpenAI-o1, Qwen-QwQ, DeepSeek-R1-Preview), mais il reste encore de l'incertitude sur le développement systématique de cette logique. En termes de données, l'accent est principalement mis sur les mathématiques, parfois incluant du code, limitant la capacité de généralisation. Dans cet article, nous présentons un nouvel approche pour développer la capacité de LongCoT dans les LLMs, indépendamment de l'expérience du modèle ou de l'annotations humaines coûteuses, comme dans le cas d'o1. Cette approche commence avec le modèle instrumental standard. BOLT est configuré en trois étapes : 1) initiation des données de LongCoT dans le modèle instrumental standard ; 2) ajustement de sous-ensembles de LongCoT ; 3) amélioration progressive de la capacité de LongCoT par apprentissage en ligne. Dans le premier pas, il suffit de construire quelques exemples d'entrée et de sortie, mais nos expérimentations ont démontré la possibilité de créer 10 exemples, montrant la viabilité de cet approche. En utilisant Llama-3.1-70B-Instruct, nous avons initié le LongCoT et appliqué ce méthode à différentes échelles de modèles (7B, 8B, 70B). Nous avons évalué la capacité de résolution de tâches et de logique dans différents cadres de référence comme Arena-Hard, MT-Bench, WildBench, ZebraLogic, et MATH500, atteignant des résultats notables.",
      "upvotes": 3,
      "discussionId": "67a5880e886a1e223b1d58ca"
    },
    "publishedAt": "2025-02-06T23:12:15.874Z",
    "title": "BOLT: Bootstrap Long Chain-of-Thought in Language Models without Distillation",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.03860.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5968
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.04295",
      "authors": [
        {
          "_id": "67a57d32bc587f5b57a3f24f",
          "name": "Yuanye Liu",
          "hidden": false
        },
        {
          "_id": "67a57d32bc587f5b57a3f250",
          "user": {
            "_id": "62abdf657b037eafffc48808",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1655430982462-noauth.jpeg",
            "isPro": false,
            "fullname": "Jiahang Xu",
            "user": "Jiahang",
            "type": "user"
          },
          "name": "Jiahang Xu",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-02-07T03:25:39.760Z",
          "hidden": false
        },
        {
          "_id": "67a57d32bc587f5b57a3f251",
          "name": "Li Lyna Zhang",
          "hidden": false
        },
        {
          "_id": "67a57d32bc587f5b57a3f252",
          "name": "Qi Chen",
          "hidden": false
        },
        {
          "_id": "67a57d32bc587f5b57a3f253",
          "name": "Xuan Feng",
          "hidden": false
        },
        {
          "_id": "67a57d32bc587f5b57a3f254",
          "name": "Yang Chen",
          "hidden": false
        },
        {
          "_id": "67a57d32bc587f5b57a3f255",
          "name": "Zhongxin Guo",
          "hidden": false
        },
        {
          "_id": "67a57d32bc587f5b57a3f256",
          "name": "Yuqing Yang",
          "hidden": false
        },
        {
          "_id": "67a57d32bc587f5b57a3f257",
          "name": "Cheng Peng",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-06T18:36:44.000Z",
      "title": "Optimisation du Prompt Intégré pour Amélioration du Rendement de la LLM à l'Aide de Formats de Contenu",
      "summary": "Les modèles de langue de grande échelle (LLMs) montrent des capacités significatives dans diverses tâches, et leur efficacité réelle dans le monde est généralement gérée par le design des prompts. Les études récentes se concentrent sur l'optimisation du contenu des prompts, mais la formation des prompts, essentielle mais peu soulignée, nécessite davantage d'attention. La formation des prompts est cruciale pour le rendement des modèles, bien qu'elle soit souvent oubliée. La formation des prompts est un aspect fondamental mais souvent oublié. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale mais souvent oubliée. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked. La formation des prompts est une question cruciale but often overlooked.",
      "upvotes": 3,
      "discussionId": "67a57d33bc587f5b57a3f29d"
    },
    "publishedAt": "2025-02-06T22:27:24.284Z",
    "title": "Beyond Prompt Content: Enhancing LLM Performance via Content-Format Integrated Prompt Optimization",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.04295.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "62abdf657b037eafffc48808",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1655430982462-noauth.jpeg",
      "fullname": "Jiahang Xu",
      "name": "Jiahang",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 8
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.00989",
      "authors": [
        {
          "_id": "67a5c7601e6db426653ebc3d",
          "name": "Kanika Goswami",
          "hidden": false
        },
        {
          "_id": "67a5c7601e6db426653ebc3e",
          "name": "Puneet Mathur",
          "hidden": false
        },
        {
          "_id": "67a5c7601e6db426653ebc3f",
          "name": "Ryan Rossi",
          "hidden": false
        },
        {
          "_id": "67a5c7601e6db426653ebc40",
          "name": "Franck Dernoncourt",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-03T02:00:51.000Z",
      "title": "ChartCitor: Responsabilité de la visualisation de graphiques de céntricos dans un cadre d'agents de détail",
      "summary": "Les modèles de langage grands (LLMs) peuvent répondre à des questions dans un chatbot, mais souvent génèrent des mots sans fondement. Les méthodes actuelles d'évaluation des réponses ne peuvent pas s'adapter aux contextes visuels et sémantiques limités du chatbot, ce qui rend difficile la réponse à des phrases visuelles complexes et la prédiction de cadres dans des layouts complexes. Nous présentons un cadre multi-agentiel appelé \"ChartCitor\" qui identifie des preuves dans les images des chatbots et fournit des références détaillées sur les cadres. Ce système collabore les agents de LLM pour extraire des tables, réorganiser les réponses, élargir les tables, prédirer et échelonner, cherchant des preuves et cartographier les réponses sur les tables. \"ChartCitor\" est faisable sur différents types de chatbots et peut surmonter les limites actuelles. Dans un environnement utilisateur, \"ChartCitor\" améliore la compréhension des réponses des chatbots basées sur les LLMs, augmentant la confiance en l'IA et la productivité des experts.",
      "upvotes": 2,
      "discussionId": "67a5c7621e6db426653ebc8a"
    },
    "publishedAt": "2025-02-07T03:42:17.799Z",
    "title": "ChartCitor: Multi-Agent Framework for Fine-Grained Chart Visual Attribution",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.00989.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "62c5947524171688a9feb992",
      "avatarUrl": "/avatars/5a151713b9eae8dc566f5957acee3475.svg",
      "fullname": "Franck Dernoncourt",
      "name": "Franck-Dernoncourt",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 7
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.04322",
      "authors": [
        {
          "_id": "67a5a9357415f9155e9b4b58",
          "name": "Yik Siu Chan",
          "hidden": false
        },
        {
          "_id": "67a5a9357415f9155e9b4b59",
          "user": {
            "_id": "64698ed0dcbb937d56b9dd02",
            "avatarUrl": "/avatars/835ce9bf6e2cd1d4b7a709cf41a884e2.svg",
            "isPro": false,
            "fullname": "Edward Ri",
            "user": "narutatsuri",
            "type": "user"
          },
          "name": "Narutatsu Ri",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-07T09:57:58.519Z",
          "hidden": false
        },
        {
          "_id": "67a5a9357415f9155e9b4b5a",
          "user": {
            "_id": "64bf072bae436c8813494ba3",
            "avatarUrl": "/avatars/afb96d2bbf90411f4b1a030ebebff300.svg",
            "isPro": false,
            "fullname": "Yuxin Xiao",
            "user": "YuxinXiao",
            "type": "user"
          },
          "name": "Yuxin Xiao",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-07T09:58:00.910Z",
          "hidden": false
        },
        {
          "_id": "67a5a9357415f9155e9b4b5b",
          "name": "Marzyeh Ghassemi",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-06T18:59:02.000Z",
      "title": "\"Discours IEEE : Extraction de Brakes de Utensiles Pésimes à Partir d'Interactions Simples dans les LLM\"",
      "summary": "Un ajuste large-scale de sécurité a rendu facilement accessibles les comportements perjudiciels et les attaques malicieuses pour les modèles de langage de grande taille (LLMs). La plupart des études actuelles se concentrent sur des méthodes d'attaque nécessitant des connaissances techniques, mais deux problèmes importants n'ont pas été suffisamment étudiés : 1) Les comportements perjudiciels peuvent-ils être réalisés par des attaques malicieuses pour des utilisateurs ordinaires ? 2) Y a-t-il des vulnérabilités communes et simples dans l'interaction humain-LLM ? Dans cet article, nous présentons les deux propriétés clés que les réponses d'un LLM doivent avoir pour promouvoir des comportements perjudiciels. En se basant sur cette perspective, nous proposons un indice d'attaque \"HarmScore\" pour évaluer comment promeut des comportements perjudiciels et un cadre d'attaque multi-étape et multilingue simple appelé \"Speak Easy\". En particulier, lorsque \"Speak Easy\" est utilisé directement comme requête et qu'un benchmark d'attaque malicieuse est ajouté, les modèles open-source et les modèles commercials subissent une augmentation moyenne de 0,319 dans la taux de succès de l'attaque et une augmentation de 0,426 dans le \"HarmScore\" sur quatre tests de sécurité. Notre étude révèle des vulnérabilités importantes de sécurité : les utilisateurs malicieux peuvent facilement exploiter des motifs communs d'interaction pour atteindre des objectifs perjudiciels.",
      "upvotes": 2,
      "discussionId": "67a5a9367415f9155e9b4bbb"
    },
    "publishedAt": "2025-02-07T01:37:25.953Z",
    "title": "Speak Easy: Eliciting Harmful Jailbreaks from LLMs with Simple Interactions",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.04322.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64bf072bae436c8813494ba3",
      "avatarUrl": "/avatars/afb96d2bbf90411f4b1a030ebebff300.svg",
      "fullname": "Yuxin Xiao",
      "name": "YuxinXiao",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.04235",
      "authors": [
        {
          "_id": "67a56af6d7c26c7497a86308",
          "user": {
            "_id": "64b764bffdb702b3d8640610",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64b764bffdb702b3d8640610/lpHg0AX_NOmzw-ZxeOa1s.png",
            "isPro": false,
            "fullname": "haoxintong",
            "user": "haoxintong",
            "type": "user"
          },
          "name": "Xintong Hao",
          "status": "extracted_confirmed",
          "statusLastChangedAt": "2025-02-07T04:41:11.249Z",
          "hidden": false
        },
        {
          "_id": "67a56af6d7c26c7497a86309",
          "name": "Ke Shen",
          "hidden": false
        },
        {
          "_id": "67a56af6d7c26c7497a8630a",
          "name": "Chenggang Li",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-06T17:19:55.000Z",
      "title": "MAGA: MA Granjeador Administrador Formador Técnico de la Formación Previa y Extensión del Conjunto de Datos Previos",
      "summary": "Le modèle de langue générale montre une excellente capacité dans diverses tâches, mais sa scalabilité continue est limitée par la rareté des données d'entraînement de haute qualité. Bien que l'architecture du modèle continue d'évoluer, la scalabilité des données de langue nature se retarde. Pour résoudre ces problèmes, nous proposons un méthode de redéfinition appelée MAassive Genre-Audience (MAGA). Cette méthode permet la synthèse systématique de données d'entraînement riches en contexte et variées à partir des corpus actuels. Cette étude résume trois contributions principales : (1) la proposition du méthode de redéfinition MAGA, la construction d'une approche légère et scalable pour l'expansion des corpus d'entraînement préalable, et la création d'un corpus MAGA de 770B tokens. (2) L'évaluation du corpus MAGA en utilisant différentes stratégies de scalabilité de bases de données, montrant des améliorations constantes sur différents tailles de modèle (134M-13B) et démontrant la nécessité de modèles de langue d'entraînement préalable à grande échelle dans les futurs générations. (3) Une analyse détaillée qui investigate l'influence de l'ingénierie du traitement sur le fatigue d'entraînement et révèle les limitations des métriques traditionnelles de détection de fatigue basées sur les pertes d'évaluation. Notre étude montre que MAGA peut considérablement augmenter la quantité de données d'entraînement tout en maintenant la qualité. Il offre une clé de scalabilité pour les modèles, surmontant les limitations des données.",
      "upvotes": 1,
      "discussionId": "67a56af8d7c26c7497a86359"
    },
    "publishedAt": "2025-02-07T00:56:20.873Z",
    "title": "MAGA: MAssive Genre-Audience Reformulation to Pretraining Corpus Expansion",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.04235.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64b764bffdb702b3d8640610",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64b764bffdb702b3d8640610/lpHg0AX_NOmzw-ZxeOa1s.png",
      "fullname": "haoxintong",
      "name": "haoxintong",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.04270",
      "authors": [
        {
          "_id": "67a5882fa8e877ef10b8d1fd",
          "name": "Yunzhen Feng",
          "hidden": false
        },
        {
          "_id": "67a5882fa8e877ef10b8d1fe",
          "name": "Ariel Kwiatkowski",
          "hidden": false
        },
        {
          "_id": "67a5882fa8e877ef10b8d1ff",
          "name": "Kunhao Zheng",
          "hidden": false
        },
        {
          "_id": "67a5882fa8e877ef10b8d200",
          "name": "Julia Kempe",
          "hidden": false
        },
        {
          "_id": "67a5882fa8e877ef10b8d201",
          "name": "Yaqi Duan",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-06T18:09:00.000Z",
      "title": "PILAF : Modèle de récompense par échantillonnage d'intérêts humains appropriés",
      "summary": "Le langage de langage général a devenu une tâche importante pour que les applications réalistes soient exécutées de manière cohérente avec les valeurs humaines. L'apprentissage par renforcement avec rétroalimentation humaine (RLHF) a émergé comme une technologie cruciale, et il est nécessaire de traduire les données de préférence en modèles de récompense lorsque les valeurs humaines ne sont pas accessibles. Pratiquement, l'RLHF se base principalement sur des modèles de récompense approximés, mais ces modèles ne peuvent pas guider des politiques qui maximisent les valeurs utilisateur de manière cohérente. Nous proposons PILAF (Apprentissage de Politiques Interpolates pour la Rétroalimentation Alinée). PILAF utilise des échantillons de réponses de marques de préférence pour offrir un nouvel approfondissement clair qui maximise explicitement les valeurs humaines, alignant clairement l'apprentissage des préférences. PILAF est construit théoriquement et son optimalité est démontrée à partir des angles de vue de l'optimalité et de la statistique. Ce méthode est simple à mettre en œuvre et montre un rendement fort dans des environnements RLHF en ligne et itératifs où l'édition de la rétroalimentation est cruciale.",
      "upvotes": 1,
      "discussionId": "67a58830a8e877ef10b8d226"
    },
    "publishedAt": "2025-02-06T23:13:23.158Z",
    "title": "PILAF: Optimal Human Preference Sampling for Reward Modeling",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.04270.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "65cbfa6c968742be942e6cba",
      "avatarUrl": "/avatars/1a6cc0983edc28fa92178d3abc283ba1.svg",
      "fullname": "Feng",
      "name": "Yunzhen",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.03639",
      "authors": [
        {
          "_id": "67a59193f86e1b9d7ae7cd55",
          "name": "Yunuo Chen",
          "hidden": false
        },
        {
          "_id": "67a59193f86e1b9d7ae7cd56",
          "name": "Junli Cao",
          "hidden": false
        },
        {
          "_id": "67a59193f86e1b9d7ae7cd57",
          "name": "Anil Kag",
          "hidden": false
        },
        {
          "_id": "67a59193f86e1b9d7ae7cd58",
          "name": "Vidit Goel",
          "hidden": false
        },
        {
          "_id": "67a59193f86e1b9d7ae7cd59",
          "name": "Sergei Korolev",
          "hidden": false
        },
        {
          "_id": "67a59193f86e1b9d7ae7cd5a",
          "name": "Chenfanfu Jiang",
          "hidden": false
        },
        {
          "_id": "67a59193f86e1b9d7ae7cd5b",
          "name": "Sergey Tulyakov",
          "hidden": false
        },
        {
          "_id": "67a59193f86e1b9d7ae7cd5c",
          "name": "Jian Ren",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-05T21:49:06.000Z",
      "title": "Le méthode de normalisation de points 3D pour la compréhension physique",
      "summary": "Voici la traduction en français :\n\nCi-dessous est présenté un nouveau cadre de travail pour la génération de vidéos. Ce cadre intègre l'arbre tridimensionnel et la reconnaissance dynamique. Pour cela, on ajoute à la vidéo bidimensionnelle une trajectoire de points en trois dimensions et on ajuste cette dernière dans l'espace de pixels en fonction de l'objectif. De cette manière, on obtient un ensemble de vidéos à reconnaissance tridimensionnelle, nommé PointVid, qui est utilisé pour affiner les modèles de différenciation potentiel et pour suivre des objets bidimensionnels en coordonnées cartésiennes tridimensionnelles. En se basant sur cela, on normalise la forme et le comportement des objets dans la vidéo et on élimine des zones inadéquates, comme par exemple, les transformations physiques. De cette manière, on améliore la qualité de la vidéo RGB et on résout des problèmes communs comme la déformation de la forme des objets en raison de la manque de reconnaissance de forme dans les modèles de vidéo actuels. Grâce à l'ajout tridimensionnel et la normalisation, le modèle peut gérer des scénarios riches en contact. Ces vidéos incluent des interactions complexes nécessaires pour la compréhension de la forme et le reconnaissance du contact. De plus, le modèle promeut la cohérence dynamique, réduit les rapides transformations de forme et d'action, et améliore la qualité générale de la génération de vidéo.",
      "upvotes": 0,
      "discussionId": "67a59195f86e1b9d7ae7cd97"
    },
    "publishedAt": "2025-02-06T23:52:49.331Z",
    "title": "Towards Physical Understanding in Video Generation: A 3D Point Regularization Approach",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.03639.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5968
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.04296",
      "authors": [
        {
          "_id": "67a57a4637e2abc28667ec1b",
          "name": "Lirui Wang",
          "hidden": false
        },
        {
          "_id": "67a57a4637e2abc28667ec1c",
          "name": "Kevin Zhao",
          "hidden": false
        },
        {
          "_id": "67a57a4637e2abc28667ec1d",
          "name": "Chaoqi Liu",
          "hidden": false
        },
        {
          "_id": "67a57a4637e2abc28667ec1e",
          "name": "Xinlei Chen",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-06T18:38:26.000Z",
      "title": "Apprendre la dynamique des vidéos d'actions avec des masques hybrides",
      "summary": "HMA (Homojonion Masked Autoencoder) propose de modéliser la dynamique des vidéos d'actions pour générer et évaluer des données de haute qualité dans l'apprentissage de robots. La construction de modèles vidéo monde interactifs et de politiques pour les robots est difficile car ils doivent rester efficaces en termes de calcul temporel tout en travaillant dans différentes configurations. HMA utilise un prétraining hétérogène à partir de séquences d'observations et d'actions d'observations et d'actions de différents robots, domaines et tâches. HMA utilise l'auto-régression avec masque pour caractériser ou générer des tokens doux. Comparé aux modèles précédents de génération de vidéos de robots, HMA atteint une précision visuelle maximale et une possibilité de contrôle, et fonctionne 15 fois plus rapidement dans le monde réel. Après l'apprentissage supplémentaire, ce modèle peut être utilisé comme simulateur vidéo à partir d'entrées d'actions de bas niveau, aidant à l'évaluation de politiques et à la génération de données synthétiques. Pour plus d'informations, consultez : https://liruiw.github.io/hma",
      "upvotes": 0,
      "discussionId": "67a57a4737e2abc28667ec58"
    },
    "publishedAt": "2025-02-06T22:17:36.193Z",
    "title": "Learning Real-World Action-Video Dynamics with Heterogeneous Masked Autoregression",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.04296.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "63151385b031f7b1c7c0871c",
      "avatarUrl": "/avatars/0088eb929866face5f95218943e3f478.svg",
      "fullname": "Lirui Wang",
      "name": "liruiw",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 4
    },
    "isAuthorParticipating": false
  }
]