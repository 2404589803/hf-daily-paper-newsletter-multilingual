[
  {
    "paper": {
      "id": "2504.02605",
      "authors": [
        {
          "_id": "67ef4d92c1e251f239495a13",
          "name": "Daoguang Zan",
          "hidden": false
        },
        {
          "_id": "67ef4d92c1e251f239495a14",
          "name": "Zhirong Huang",
          "hidden": false
        },
        {
          "_id": "67ef4d92c1e251f239495a15",
          "name": "Wei Liu",
          "hidden": false
        },
        {
          "_id": "67ef4d92c1e251f239495a16",
          "name": "Hanwu Chen",
          "hidden": false
        },
        {
          "_id": "67ef4d92c1e251f239495a17",
          "name": "Linhao Zhang",
          "hidden": false
        },
        {
          "_id": "67ef4d92c1e251f239495a18",
          "name": "Shulin Xin",
          "hidden": false
        },
        {
          "_id": "67ef4d92c1e251f239495a19",
          "name": "Lu Chen",
          "hidden": false
        },
        {
          "_id": "67ef4d92c1e251f239495a1a",
          "name": "Qi Liu",
          "hidden": false
        },
        {
          "_id": "67ef4d92c1e251f239495a1b",
          "name": "Xiaojian Zhong",
          "hidden": false
        },
        {
          "_id": "67ef4d92c1e251f239495a1c",
          "name": "Aoyan Li",
          "hidden": false
        },
        {
          "_id": "67ef4d92c1e251f239495a1d",
          "name": "Siyao Liu",
          "hidden": false
        },
        {
          "_id": "67ef4d92c1e251f239495a1e",
          "name": "Yongsheng Xiao",
          "hidden": false
        },
        {
          "_id": "67ef4d92c1e251f239495a1f",
          "name": "Liangqiang Chen",
          "hidden": false
        },
        {
          "_id": "67ef4d92c1e251f239495a20",
          "name": "Yuyu Zhang",
          "hidden": false
        },
        {
          "_id": "67ef4d92c1e251f239495a21",
          "name": "Jing Su",
          "hidden": false
        },
        {
          "_id": "67ef4d92c1e251f239495a22",
          "name": "Tianyu Liu",
          "hidden": false
        },
        {
          "_id": "67ef4d92c1e251f239495a23",
          "name": "Rui Long",
          "hidden": false
        },
        {
          "_id": "67ef4d92c1e251f239495a24",
          "name": "Kai Shen",
          "hidden": false
        },
        {
          "_id": "67ef4d92c1e251f239495a25",
          "name": "Liang Xiang",
          "hidden": false
        }
      ],
      "mediaUrls": [
        "https://cdn-uploads.huggingface.co/production/uploads/61527edf8b55dbdae72874fa/PS_Q49kWYAB6DdJy5YY9k.png",
        "https://cdn-uploads.huggingface.co/production/uploads/61527edf8b55dbdae72874fa/GhnnOocFnA-YN2oyeNjPB.png"
      ],
      "publishedAt": "2025-04-03T14:06:17.000Z",
      "submittedOnDailyAt": "2025-04-07T02:30:50.286Z",
      "title": "Multi-SWE-bench : Marqueur de tests pour la résolution de problèmes multilingues",
      "submittedOnDailyBy": {
        "_id": "61527edf8b55dbdae72874fa",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/61527edf8b55dbdae72874fa/ZGWSBf_KSrDof6WyMoDMU.jpeg",
        "isPro": false,
        "fullname": "Daoguang Zan",
        "user": "Daoguang",
        "type": "user"
      },
      "summary": "La tâche de la résolution de problèmes est d'orienter l'approche du code pour créer un formulaire pour résoudre un problème donné. Cependant, le cadre de référence actuel, SWE-bench, se concentre sur Python, ce qui n'est pas suffisant pour évaluer les modèles de langage grande échelle (LLMs) dans une large écosystème de logiciels. En réponse à cette question, nous présentons Multi-SWE-bench, un cadre de référence de résolution de problèmes multilingue qui inclut Java, TypeScript, JavaScript, Go, Rust, C et C++. Ce cadre de référence a été généré par un panel de 68 experts qui ont sélectionné 2,456 candidats pour créer 1,632 instances de haute qualité, assurant une évaluation avec confiance. En se basant sur Multi-SWE-bench, nous évaluons les modèles les plus récents en utilisant trois méthodes représentatives : Agentless, SWE-agent et OpenHands, et nous fournissons un analyse détaillée et des preuves cruciales. De plus, nous avons initié la communauté ouverte de Multi-SWE-RL pour construire un ensemble de données d'entraînement pour la RL de tâches de résolution de problèmes. Comme contribution initiale, nous avons étendu 4,723 instances de bonne structure dans 7 langages de programmation, établissant une base solide pour la recherche en RL. Plus important encore, nous avons ouvert la production de données et des tutoriels détaillés en code open pour encourager la contribution continue de la communauté ouverte et l'expansion de l'ensemble de données. Nous voir Multi-SWE-bench et sa communauté d'expansion comme un défi pour la capacité de la RL et nous imaginons le lever du jour de l'intelligence artificielle.",
      "upvotes": 28,
      "discussionId": "67ef4d93c1e251f239495a9b",
      "projectPage": "https://multi-swe-bench.github.io",
      "githubRepo": "https://github.com/multi-swe-bench/multi-swe-bench",
      "ai_keywords": [
        "Large Language Models (LLMs)",
        "Multi-SWE-bench",
        "Agentless",
        "SWE-agent",
        "OpenHands",
        "Multi-SWE-RL",
        "reinforcement learning (RL)",
        "AGI"
      ]
    },
    "publishedAt": "2025-04-03T10:06:17.000Z",
    "title": "Multi-SWE-bench: A Multilingual Benchmark for Issue Resolving",
    "summary": "The task of issue resolving is to modify a codebase to generate a patch that\naddresses a given issue. However, existing benchmarks, such as SWE-bench, focus\nalmost exclusively on Python, making them insufficient for evaluating Large\nLanguage Models (LLMs) across diverse software ecosystems. To address this, we\nintroduce a multilingual issue-resolving benchmark, called Multi-SWE-bench,\ncovering Java, TypeScript, JavaScript, Go, Rust, C, and C++. It includes a\ntotal of 1,632 high-quality instances, which were carefully annotated from\n2,456 candidates by 68 expert annotators, ensuring that the benchmark can\nprovide an accurate and reliable evaluation. Based on Multi-SWE-bench, we\nevaluate a series of state-of-the-art models using three representative methods\n(Agentless, SWE-agent, and OpenHands) and present a comprehensive analysis with\nkey empirical insights. In addition, we launch a Multi-SWE-RL open-source\ncommunity, aimed at building large-scale reinforcement learning (RL) training\ndatasets for issue-resolving tasks. As an initial contribution, we release a\nset of 4,723 well-structured instances spanning seven programming languages,\nlaying a solid foundation for RL research in this domain. More importantly, we\nopen-source our entire data production pipeline, along with detailed tutorials,\nencouraging the open-source community to continuously contribute and expand the\ndataset. We envision our Multi-SWE-bench and the ever-growing Multi-SWE-RL\ncommunity as catalysts for advancing RL toward its full potential, bringing us\none step closer to the dawn of AGI.",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/61527edf8b55dbdae72874fa/PS_Q49kWYAB6DdJy5YY9k.png",
      "https://cdn-uploads.huggingface.co/production/uploads/61527edf8b55dbdae72874fa/GhnnOocFnA-YN2oyeNjPB.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.02605.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "61527edf8b55dbdae72874fa",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/61527edf8b55dbdae72874fa/ZGWSBf_KSrDof6WyMoDMU.jpeg",
      "fullname": "Daoguang Zan",
      "name": "Daoguang",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 6
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2504.03553",
      "authors": [
        {
          "_id": "67f345c983edbd64f15deeb3",
          "name": "Shuofei Qiao",
          "hidden": false
        },
        {
          "_id": "67f345c983edbd64f15deeb4",
          "name": "Zhisong Qiu",
          "hidden": false
        },
        {
          "_id": "67f345c983edbd64f15deeb5",
          "name": "Baochang Ren",
          "hidden": false
        },
        {
          "_id": "67f345c983edbd64f15deeb6",
          "name": "Xiaobin Wang",
          "hidden": false
        },
        {
          "_id": "67f345c983edbd64f15deeb7",
          "name": "Xiangyuan Ru",
          "hidden": false
        },
        {
          "_id": "67f345c983edbd64f15deeb8",
          "name": "Ningyu Zhang",
          "hidden": false
        },
        {
          "_id": "67f345c983edbd64f15deeb9",
          "name": "Xiang Chen",
          "hidden": false
        },
        {
          "_id": "67f345c983edbd64f15deeba",
          "name": "Yong Jiang",
          "hidden": false
        },
        {
          "_id": "67f345c983edbd64f15deebb",
          "name": "Pengjun Xie",
          "hidden": false
        },
        {
          "_id": "67f345c983edbd64f15deebc",
          "name": "Fei Huang",
          "hidden": false
        },
        {
          "_id": "67f345c983edbd64f15deebd",
          "name": "Huajun Chen",
          "hidden": false
        }
      ],
      "publishedAt": "2025-04-04T16:03:38.000Z",
      "submittedOnDailyAt": "2025-04-07T02:45:21.106Z",
      "title": "AGENTIC CONOCIDO AUTOCONSCIENCIA",
      "submittedOnDailyBy": {
        "_id": "620b3bbb0668e435407c8d0a",
        "avatarUrl": "/avatars/e0fccbb2577d76088e09f054c35cffbc.svg",
        "isPro": false,
        "fullname": "Ningyu Zhang",
        "user": "Ningyu",
        "type": "user"
      },
      "summary": "Les modèles de langage grands (LLMs) ont réalisé un rendement significatif dans de nombreuses tâches de planification d'agents. Cependant, l'approche traditionnelle de planification d'agents fonctionne comme un \"champ de batata\" mécanique, comme la cartomancie d'or, la rétroaction externe, la connaissance connue de la campus de DrivenCampus et est injectée de manière non spécifique dans les modèles d'agents. Cette pratique dépasse les principes fondamentaux de l'auto-connaissance humaine, qui impliquent la réconciliation de la ville de la pensée avec le moi. Cela évalue la capacité de l'évaluation dynamique des situations et de l'utilisation stratégique des ressources. Nous proposons de combler cette lacune avec un auto-connaissance cognitif pour les agents. C'est un nouveau paradigme pour que les agents basés sur les LLMs puissent ajuster automatiquement l'utilisation de l'information. Concrètement, nous proposons l'approche data-centric KnowSelf, qui vise à atteindre un auto-connaissance cognitif similaire au humain. En fait, nous avons conçu des critères heuristiques pour marquer des tokens spéciaux sur la tâche d'auto-exploration des agents. Par un processus d'apprentissage en deux étapes, les modèles d'agents peuvent générer des tokens spéciaux pour changer différents états et atteindre un résultat optimal avec le moindre coût. Nos expériences montrent que KnowSelf peut dépasser des références fortes dans différentes tâches et modèles, en utilisant le savoir externe au minimum. Le code est disponible sur https://github.com/zjunlp/KnowSelf.",
      "upvotes": 14,
      "discussionId": "67f345cd83edbd64f15def73",
      "githubRepo": "https://github.com/zjunlp/KnowSelf",
      "ai_keywords": [
        "agentic planning",
        "flood irrigation methodology",
        "gold trajectories",
        "external feedback",
        "domain knowledge",
        "self-awareness",
        "decision-making",
        "agentic knowledgeable self-awareness",
        "KnowSelf",
        "data-centric approach",
        "situation judgement criterion",
        "special tokens",
        "two-stage training process",
        "trajectory-based training"
      ]
    },
    "publishedAt": "2025-04-04T12:03:38.000Z",
    "title": "Agentic Knowledgeable Self-awareness",
    "summary": "Large Language Models (LLMs) have achieved considerable performance across\nvarious agentic planning tasks. However, traditional agent planning approaches\nadopt a \"flood irrigation\" methodology that indiscriminately injects gold\ntrajectories, external feedback, and domain knowledge into agent models. This\npractice overlooks the fundamental human cognitive principle of situational\nself-awareness during decision-making-the ability to dynamically assess\nsituational demands and strategically employ resources during decision-making.\nWe propose agentic knowledgeable self-awareness to address this gap, a novel\nparadigm enabling LLM-based agents to autonomously regulate knowledge\nutilization. Specifically, we propose KnowSelf, a data-centric approach that\napplies agents with knowledgeable self-awareness like humans. Concretely, we\ndevise a heuristic situation judgement criterion to mark special tokens on the\nagent's self-explored trajectories for collecting training data. Through a\ntwo-stage training process, the agent model can switch between different\nsituations by generating specific special tokens, achieving optimal planning\neffects with minimal costs. Our experiments demonstrate that KnowSelf can\noutperform various strong baselines on different tasks and models with minimal\nuse of external knowledge. Code is available at\nhttps://github.com/zjunlp/KnowSelf.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.03553.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "620b3bbb0668e435407c8d0a",
      "avatarUrl": "/avatars/e0fccbb2577d76088e09f054c35cffbc.svg",
      "fullname": "Ningyu Zhang",
      "name": "Ningyu",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 21
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2504.03561",
      "authors": [
        {
          "_id": "67f351f068751b2bb84cc751",
          "name": "Runnan Fang",
          "hidden": false
        },
        {
          "_id": "67f351f068751b2bb84cc752",
          "name": "Xiaobin Wang",
          "hidden": false
        },
        {
          "_id": "67f351f068751b2bb84cc753",
          "name": "Yuan Liang",
          "hidden": false
        },
        {
          "_id": "67f351f068751b2bb84cc754",
          "name": "Shuofei Qiao",
          "hidden": false
        },
        {
          "_id": "67f351f068751b2bb84cc755",
          "name": "Jialong Wu",
          "hidden": false
        },
        {
          "_id": "67f351f068751b2bb84cc756",
          "name": "Zekun Xi",
          "hidden": false
        },
        {
          "_id": "67f351f068751b2bb84cc757",
          "name": "Ningyu Zhang",
          "hidden": false
        },
        {
          "_id": "67f351f068751b2bb84cc758",
          "name": "Yong Jiang",
          "hidden": false
        },
        {
          "_id": "67f351f068751b2bb84cc759",
          "name": "Pengjun Xie",
          "hidden": false
        },
        {
          "_id": "67f351f068751b2bb84cc75a",
          "name": "Fei Huang",
          "hidden": false
        },
        {
          "_id": "67f351f068751b2bb84cc75b",
          "name": "Huajun Chen",
          "hidden": false
        }
      ],
      "publishedAt": "2025-04-04T16:10:57.000Z",
      "submittedOnDailyAt": "2025-04-07T02:48:19.567Z",
      "title": "SynWorld : Amélioration du connaissance des actions de sortie par la synthèse d'environnements de sortie",
      "submittedOnDailyBy": {
        "_id": "620b3bbb0668e435407c8d0a",
        "avatarUrl": "/avatars/e0fccbb2577d76088e09f054c35cffbc.svg",
        "isPro": false,
        "fullname": "Ningyu Zhang",
        "user": "Ningyu",
        "type": "user"
      },
      "summary": "Dans l'interaction efficace entre agents et environnement, les agents élargissent leurs capacités en planifiant et en exécutant des actions stratégiques. Cependant, les agents basés sur des modèles de langage profond (LLM) rencontrent des problèmes importants lorsqu'ils essaient de gérer des structures non standards d'espace d'action ou des nouveaux environnements. Pour que les agents puissent explorer automatiquement l'environnement, optimiser le flux de travail et améliorer la compréhension de leurs actions, on propose le cadre de travail SynWorld. Dans ce cadre, des actions multiniveaux sont combinées dans l'espace d'action et une exploration par Monte Carlo (MCTS) est effectuée pour raffiner efficacement le savoir sur les actions dans l'environnement actuel. Les résultats des expérimentations montrent clairement que SynWorld est un approche efficace et générale pour l'apprentissage du savoir sur les actions dans de nouveaux environnements. Le code est disponible sur https://github.com/zjunlp/SynWorld.",
      "upvotes": 9,
      "discussionId": "67f351f168751b2bb84cc789",
      "ai_keywords": [
        "LLM-based agents",
        "multi-step action invocation",
        "Monte Carlo Tree Search (MCTS)"
      ]
    },
    "publishedAt": "2025-04-04T12:10:57.000Z",
    "title": "SynWorld: Virtual Scenario Synthesis for Agentic Action Knowledge\n  Refinement",
    "summary": "In the interaction between agents and their environments, agents expand their\ncapabilities by planning and executing actions. However, LLM-based agents face\nsubstantial challenges when deployed in novel environments or required to\nnavigate unconventional action spaces. To empower agents to autonomously\nexplore environments, optimize workflows, and enhance their understanding of\nactions, we propose SynWorld, a framework that allows agents to synthesize\npossible scenarios with multi-step action invocation within the action space\nand perform Monte Carlo Tree Search (MCTS) exploration to effectively refine\ntheir action knowledge in the current environment. Our experiments demonstrate\nthat SynWorld is an effective and general approach to learning action knowledge\nin new environments. Code is available at https://github.com/zjunlp/SynWorld.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.03561.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "620b3bbb0668e435407c8d0a",
      "avatarUrl": "/avatars/e0fccbb2577d76088e09f054c35cffbc.svg",
      "fullname": "Ningyu Zhang",
      "name": "Ningyu",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 21
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2504.02949",
      "authors": [
        {
          "_id": "67f350a5e11bd4b05575a831",
          "name": "Xianwei Zhuang",
          "hidden": false
        },
        {
          "_id": "67f350a5e11bd4b05575a832",
          "name": "Yuxin Xie",
          "hidden": false
        },
        {
          "_id": "67f350a5e11bd4b05575a833",
          "name": "Yufan Deng",
          "hidden": false
        },
        {
          "_id": "67f350a5e11bd4b05575a834",
          "name": "Dongchao Yang",
          "hidden": false
        },
        {
          "_id": "67f350a5e11bd4b05575a835",
          "name": "Liming Liang",
          "hidden": false
        },
        {
          "_id": "67f350a5e11bd4b05575a836",
          "name": "Jinghan Ru",
          "hidden": false
        },
        {
          "_id": "67f350a5e11bd4b05575a837",
          "name": "Yuguo Yin",
          "hidden": false
        },
        {
          "_id": "67f350a5e11bd4b05575a838",
          "name": "Yuexian Zou",
          "hidden": false
        }
      ],
      "publishedAt": "2025-04-03T18:06:28.000Z",
      "submittedOnDailyAt": "2025-04-07T02:42:39.671Z",
      "title": "VARGPT-v1.1 : Modèle intégré de récupération visuelle automatique amélioré par l'entraînement structuré itératif et l'apprentissage par renforcement.",
      "submittedOnDailyBy": {
        "_id": "63468720dd6d90d82ccf3450",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63468720dd6d90d82ccf3450/tVBFlmZNz8FRMkOrDaDID.jpeg",
        "isPro": false,
        "fullname": "YSH",
        "user": "BestWishYsh",
        "type": "user"
      },
      "summary": "Dans cette étude, nous proposons un modèle d'auto-restauration visuelle basé sur VARGPT, le VARGPT-v1.1, qui a évolué depuis le modèle précédemment présenté. Ce modèle est composé d'un double paradigme pour la compréhension visuelle et la génération d'images, la prédiction de tokens suivants et la génération d'échelles. Spécifiquement, le VARGPT-v1.1 intègre les cinq fonctionnalités suivantes : (1) une nouvelle stratégie d'apprentissage, combinaison de la mise à jour visuelle des instances itératives et de l'Optimisation des Préférences Directes (DPO) pour l'apprentissage par renforcement, (2) un corpus d'apprentissage étendu qui comprend 8,3M paires d'instances de génération visuelle, (3) un panel de modèle de langue mis à jour avec Qwen2, (4) amélioration de la résolution de la génération d'images, et (5) amélioration de la fonctionnalité d'édition d'images sans changement d'architecture. Ces avancées permettent que le VARGPT-v1.1 atteigne le meilleur rendement dans des tâches de compréhension de différents types d'images et de génération d'images à partir de texte, montrant des améliorations statistiquement significatives tant en compréhension que en génération. En particulier, le modèle réussit à obtenir la fonctionnalité d'édition d'images tout en maintenant l'architecture, révélant la possibilité d'un compréhension visuelle, génération et édition unifiés. Nos résultats montrent que des modèles d'auto-restauration visuelle efficaces peuvent appliquer des stratégies d'apprentissage flexibles à partir de grands modèles de langue (LLMs) et montrent une scalabilité attendue. Le code de base et les poids du modèle sont disponibles sur https://github.com/VARGPT-family/VARGPT-v1.1.",
      "upvotes": 8,
      "discussionId": "67f350a9e11bd4b05575a921",
      "githubRepo": "https://github.com/VARGPT-family/VARGPT-v1.1",
      "ai_keywords": [
        "unified visual autoregressive model",
        "next-token prediction",
        "next-scale generation",
        "iterative visual instruction tuning",
        "reinforcement learning",
        "Direct Preference Optimization (DPO)",
        "visual-generative instruction pairs",
        "Qwen2",
        "image generation resolution",
        "emergent image editing capabilities",
        "multimodal understanding",
        "text-to-image instruction-following tasks",
        "comprehension and generation metrics",
        "large language models (LLMs)"
      ]
    },
    "publishedAt": "2025-04-03T14:06:28.000Z",
    "title": "VARGPT-v1.1: Improve Visual Autoregressive Large Unified Model via\n  Iterative Instruction Tuning and Reinforcement Learning",
    "summary": "In this work, we present VARGPT-v1.1, an advanced unified visual\nautoregressive model that builds upon our previous framework VARGPT. The model\npreserves the dual paradigm of next-token prediction for visual understanding\nand next-scale generation for image synthesis. Specifically, VARGPT-v1.1\nintegrates: (1) a novel training strategy combining iterative visual\ninstruction tuning with reinforcement learning through Direct Preference\nOptimization (DPO), (2) an expanded training corpus containing 8.3M\nvisual-generative instruction pairs, (3) an upgraded language model backbone\nusing Qwen2, (4) enhanced image generation resolution, and (5) emergent image\nediting capabilities without architectural modifications. These advancements\nenable VARGPT-v1.1 to achieve state-of-the-art performance in multimodal\nunderstanding and text-to-image instruction-following tasks, demonstrating\nsignificant improvements in both comprehension and generation metrics. Notably,\nthrough visual instruction tuning, the model acquires image editing\nfunctionality while maintaining architectural consistency with its predecessor,\nrevealing the potential for unified visual understanding, generation, and\nediting. Our findings suggest that well-designed unified visual autoregressive\nmodels can effectively adopt flexible training strategies from large language\nmodels (LLMs), exhibiting promising scalability. The codebase and model weights\nare publicly available at https://github.com/VARGPT-family/VARGPT-v1.1.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.02949.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "63468720dd6d90d82ccf3450",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63468720dd6d90d82ccf3450/tVBFlmZNz8FRMkOrDaDID.jpeg",
      "fullname": "YSH",
      "name": "BestWishYsh",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 43
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2504.03641",
      "authors": [
        {
          "_id": "67f34f5dfb6d8a613926ac2b",
          "name": "Wulin Xie",
          "hidden": false
        },
        {
          "_id": "67f34f5dfb6d8a613926ac2c",
          "name": "Yi-Fan Zhang",
          "hidden": false
        },
        {
          "_id": "67f34f5dfb6d8a613926ac2d",
          "name": "Chaoyou Fu",
          "hidden": false
        },
        {
          "_id": "67f34f5dfb6d8a613926ac2e",
          "name": "Yang Shi",
          "hidden": false
        },
        {
          "_id": "67f34f5dfb6d8a613926ac2f",
          "name": "Bingyan Nie",
          "hidden": false
        },
        {
          "_id": "67f34f5dfb6d8a613926ac30",
          "name": "Hongkai Chen",
          "hidden": false
        },
        {
          "_id": "67f34f5dfb6d8a613926ac31",
          "name": "Zhang Zhang",
          "hidden": false
        },
        {
          "_id": "67f34f5dfb6d8a613926ac32",
          "name": "Liang Wang",
          "hidden": false
        },
        {
          "_id": "67f34f5dfb6d8a613926ac33",
          "name": "Tieniu Tan",
          "hidden": false
        }
      ],
      "publishedAt": "2025-04-04T17:59:55.000Z",
      "submittedOnDailyAt": "2025-04-07T02:38:07.467Z",
      "title": "MME-Unify : Marqueur de performance fondamental pour l'compréhension monomodale et la génération de modèles de type norme",
      "submittedOnDailyBy": {
        "_id": "623d8ca4c29adf5ef6175615",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/623d8ca4c29adf5ef6175615/q7lHao7UPwU1u7YLSP56m.jpeg",
        "isPro": false,
        "fullname": "Yi-Fan Zhang",
        "user": "yifanzhang114",
        "type": "user"
      },
      "summary": "Les marqueurs actuels de rendement pour MLLM ont deux problèmes cruciaux dans l'évaluation des U-MLLM (modèles intégrés) : 1) l'insuffisance de marqueurs de rendement standardisés pour des tâches traditionnelles qui crée des inégalités dans la comparaison, et 2) l'insuffisance de marqueurs de rendement pour la génération de modèles mixtes qui empêche l'évaluation de la capacité à justifier plusieurs modèles. Dans ce document, on présente un marqueur de rendement systématique pour U-MLLM. Ce marqueur est composé de trois parties : 1) évaluation de tâches traditionnelles standardisées, 2) évaluation de tâches intégrées, et 3) marqueur de rendement pour modèles informatiques. Dans l'évaluation de tâches traditionnelles standardisées, on utilise 30 sous-tâches de 10 tâches sur 12 ensembles de données pour garantir une comparaison inter-recherche cohérente. Dans l'évaluation de tâches intégrées, on introduit 5 nouvelles tâches, y compris l'édition d'images, la génération d'images, les questions générales et les questions de raisonnement géométrique. De plus, dans le marqueur de rendement pour modèles informatiques, on évalue 12 modèles avancés de U-MLLM (par exemple, Janus-Pro, EMU3, VILA-U, Gemini2-flash), modèles de domaine spécialisé (par exemple, Claude-3.5-Sonnet) et modèles de génération (par exemple, DALL-E-3). Ces résultats clairement montrent les grandes différences de rendement dans les U-MLLM actuels et soulignent la nécessité de modèles plus robustes pour gérer efficacement les tâches de modèle mixte. Le code et les données d'évaluation sont disponibles pour télécharger sur https://mme-unify.github.io/.",
      "upvotes": 7,
      "discussionId": "67f34f64fb6d8a613926ada9",
      "projectPage": "https://mme-unify.github.io/",
      "githubRepo": "https://github.com/MME-Benchmarks/MME-Unify"
    },
    "publishedAt": "2025-04-04T13:59:55.000Z",
    "title": "MME-Unify: A Comprehensive Benchmark for Unified Multimodal\n  Understanding and Generation Models",
    "summary": "Existing MLLM benchmarks face significant challenges in evaluating Unified\nMLLMs (U-MLLMs) due to: 1) lack of standardized benchmarks for traditional\ntasks, leading to inconsistent comparisons; 2) absence of benchmarks for\nmixed-modality generation, which fails to assess multimodal reasoning\ncapabilities. We present a comprehensive evaluation framework designed to\nsystematically assess U-MLLMs. Our benchmark includes: Standardized Traditional\nTask Evaluation. We sample from 12 datasets, covering 10 tasks with 30\nsubtasks, ensuring consistent and fair comparisons across studies.\" 2. Unified\nTask Assessment. We introduce five novel tasks testing multimodal reasoning,\nincluding image editing, commonsense QA with image generation, and geometric\nreasoning. 3. Comprehensive Model Benchmarking. We evaluate 12 leading U-MLLMs,\nsuch as Janus-Pro, EMU3, VILA-U, and Gemini2-flash, alongside specialized\nunderstanding (e.g., Claude-3.5-Sonnet) and generation models (e.g., DALL-E-3).\nOur findings reveal substantial performance gaps in existing U-MLLMs,\nhighlighting the need for more robust models capable of handling mixed-modality\ntasks effectively. The code and evaluation data can be found in\nhttps://mme-unify.github.io/.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.03641.png",
    "numComments": 3,
    "submittedBy": {
      "_id": "623d8ca4c29adf5ef6175615",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/623d8ca4c29adf5ef6175615/q7lHao7UPwU1u7YLSP56m.jpeg",
      "fullname": "Yi-Fan Zhang",
      "name": "yifanzhang114",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 8
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2504.03601",
      "authors": [
        {
          "_id": "67f36505e11bd4b05579afbf",
          "name": "Akshara Prabhakar",
          "hidden": false
        },
        {
          "_id": "67f36505e11bd4b05579afc0",
          "name": "Zuxin Liu",
          "hidden": false
        },
        {
          "_id": "67f36505e11bd4b05579afc1",
          "name": "Weiran Yao",
          "hidden": false
        },
        {
          "_id": "67f36505e11bd4b05579afc2",
          "name": "Jianguo Zhang",
          "hidden": false
        },
        {
          "_id": "67f36505e11bd4b05579afc3",
          "name": "Ming Zhu",
          "hidden": false
        },
        {
          "_id": "67f36505e11bd4b05579afc4",
          "name": "Shiyu Wang",
          "hidden": false
        },
        {
          "_id": "67f36505e11bd4b05579afc5",
          "name": "Zhiwei Liu",
          "hidden": false
        },
        {
          "_id": "67f36505e11bd4b05579afc6",
          "name": "Tulika Awalgaonkar",
          "hidden": false
        },
        {
          "_id": "67f36505e11bd4b05579afc7",
          "name": "Haolin Chen",
          "hidden": false
        },
        {
          "_id": "67f36505e11bd4b05579afc8",
          "name": "Thai Hoang",
          "hidden": false
        },
        {
          "_id": "67f36505e11bd4b05579afc9",
          "name": "Juan Carlos Niebles",
          "hidden": false
        },
        {
          "_id": "67f36505e11bd4b05579afca",
          "name": "Shelby Heinecke",
          "hidden": false
        },
        {
          "_id": "67f36505e11bd4b05579afcb",
          "name": "Huan Wang",
          "hidden": false
        },
        {
          "_id": "67f36505e11bd4b05579afcc",
          "name": "Silvio Savarese",
          "hidden": false
        },
        {
          "_id": "67f36505e11bd4b05579afcd",
          "name": "Caiming Xiong",
          "hidden": false
        }
      ],
      "publishedAt": "2025-04-04T17:13:57.000Z",
      "submittedOnDailyAt": "2025-04-07T04:10:25.529Z",
      "title": "APIGen-MT : APIGen-MT génère des données en arrière par la simulation de l'interaction humain-IA de Agantuki dans son pipeline.",
      "submittedOnDailyBy": {
        "_id": "60f1abe7544c2adfd699860c",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
        "isPro": false,
        "fullname": "AK",
        "user": "akhaliq",
        "type": "user"
      },
      "summary": "La formation d'agents AI valides pour l'interaction en multi-agente transformé nécessite de données de haute qualité pour comprendre la dynamique entre les personnes et les agents, mais ces données sont insuffisantes, difficiles à collecter manuellement et coûteuses. Nous présentons un cadre à deux étapes, APIGen-MT, pour générer des données d'agents multi-agente transformé. Dans la première étape, notre flux de travail d'agent utilise un comité de réviseurs de LLM et un cycle de rétroaction itératif pour générer des tâches spécifiques. Ces tâches sont complétées avec des interactions enregistrées entre les personnes et les agents, générant des données d'agents multi-agente transformé. Nous entraînons des familles de modèles de xLAM-2-fc-r dans une gamme de paramètres de 1B à 70B. Nos modèles dépassent GPT-4o et Claude 3.5 sur tau-bench et BFCL, montrant une consistence élevée et une efficacité dans la configuration de multi-agente transformé. Les expériences détaillées dans nos centres de probabilité montrent que notre approche d'accès fournit des données d'entraînement de haute qualité, reliant le développement d'agents fiables, efficaces et capables. Nous fournissons des données synthétiques et des modèles entraînés de xLAM-2-fc-r sous licence ouverte, contribuant au progrès de la recherche sur les agents AI. Les modèles sont disponibles sur HuggingFace : https://huggingface.co/collections/Salesforce/xlam-2-67ef5be12949d8dcdae354c4. Le site web du projet est https://apigen-mt.github.io.",
      "upvotes": 5,
      "discussionId": "67f36507e11bd4b05579b020",
      "ai_keywords": [
        "agentic pipeline",
        "task blueprints",
        "ground-truth actions",
        "LLM reviewers",
        "iterative feedback loops",
        "simulated human-agent interplay",
        "xLAM-2-fc-r series",
        "$\\tau$-bench",
        "BFCL benchmarks",
        "multi-turn settings",
        "verified blueprint-to-details approach"
      ]
    },
    "publishedAt": "2025-04-04T13:13:57.000Z",
    "title": "APIGen-MT: Agentic Pipeline for Multi-Turn Data Generation via Simulated\n  Agent-Human Interplay",
    "summary": "Training effective AI agents for multi-turn interactions requires\nhigh-quality data that captures realistic human-agent dynamics, yet such data\nis scarce and expensive to collect manually. We introduce APIGen-MT, a\ntwo-phase framework that generates verifiable and diverse multi-turn agent\ndata. In the first phase, our agentic pipeline produces detailed task\nblueprints with ground-truth actions, leveraging a committee of LLM reviewers\nand iterative feedback loops. These blueprints are then transformed into\ncomplete interaction trajectories through simulated human-agent interplay. We\ntrain a family of models -- the xLAM-2-fc-r series with sizes ranging from 1B\nto 70B parameters. Our models outperform frontier models such as GPT-4o and\nClaude 3.5 on tau-bench and BFCL benchmarks, with the smaller models\nsurpassing their larger counterparts, particularly in multi-turn settings,\nwhile maintaining superior consistency across multiple trials. Comprehensive\nexperiments demonstrate that our verified blueprint-to-details approach yields\nhigh-quality training data, enabling the development of more reliable,\nefficient, and capable agents. We open-source both the synthetic data collected\nand the trained xLAM-2-fc-r models to advance research in AI agents. Models are\navailable on HuggingFace at\nhttps://huggingface.co/collections/Salesforce/xlam-2-67ef5be12949d8dcdae354c4\nand project website is https://apigen-mt.github.io",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.03601.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 6594
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2504.03011",
      "authors": [
        {
          "_id": "67f35d8bdb1a843e1ceff38f",
          "name": "Junying Wang",
          "hidden": false
        },
        {
          "_id": "67f35d8bdb1a843e1ceff390",
          "name": "Jingyuan Liu",
          "hidden": false
        },
        {
          "_id": "67f35d8bdb1a843e1ceff391",
          "name": "Xin Sun",
          "hidden": false
        },
        {
          "_id": "67f35d8bdb1a843e1ceff392",
          "name": "Krishna Kumar Singh",
          "hidden": false
        },
        {
          "_id": "67f35d8bdb1a843e1ceff393",
          "name": "Zhixin Shu",
          "hidden": false
        },
        {
          "_id": "67f35d8bdb1a843e1ceff394",
          "name": "He Zhang",
          "hidden": false
        },
        {
          "_id": "67f35d8bdb1a843e1ceff395",
          "name": "Jimei Yang",
          "hidden": false
        },
        {
          "_id": "67f35d8bdb1a843e1ceff396",
          "name": "Nanxuan Zhao",
          "hidden": false
        },
        {
          "_id": "67f35d8bdb1a843e1ceff397",
          "name": "Tuanfeng Y. Wang",
          "hidden": false
        },
        {
          "_id": "67f35d8bdb1a843e1ceff398",
          "name": "Simon S. Chen",
          "hidden": false
        },
        {
          "_id": "67f35d8bdb1a843e1ceff399",
          "name": "Ulrich Neumann",
          "hidden": false
        },
        {
          "_id": "67f35d8bdb1a843e1ceff39a",
          "name": "Jae Shin Yoon",
          "hidden": false
        }
      ],
      "publishedAt": "2025-04-03T20:10:50.000Z",
      "submittedOnDailyAt": "2025-04-07T03:39:50.539Z",
      "title": "「Remplacement total : Remplacement du rythme monolithique listeable qui s'ajuste à la liste et à l'harmonie」",
      "submittedOnDailyBy": {
        "_id": "60f1abe7544c2adfd699860c",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
        "isPro": false,
        "fullname": "AK",
        "user": "akhaliq",
        "type": "user"
      },
      "summary": "Dans cet article, nous présentons un premier approche 360 degrés pour contrôler et harmoniser l'illumination dans des images ou des vidéos qui comprennent des parties du corps humain, appelée « Complete Relighting ». La construction de modèles généralisables dans ce cas est très difficile en raison de la rareté des données, ce qui a limité actuellement les modèles de reconstruction d'illumination basés sur les images à des scénarios spécifiques (par exemple, des visages ou des personnages fixes). Pour aborder ces défis, nous avons reprogrammé des modèles diffusants préalablement entraînés comme générateurs d'images générales, permettant de modéliser la reconstruction de l'illumination humaine et l'harmonie avec le fond à des niveaux très détaillés. De plus, pour améliorer la consistance temporelle de l'illumination, nous avons introduit un modèle d'illumination temporelle qui apprend la consistance cyclique de l'illumination dans différents vidéos de la vie réelle. Pendant l'inférence, le modèle d'illumination temporelle est combiné avec l'algorithme de branding de caractéristiques spatio-temporelles à travers le modèle diffusant, sans nécessité d'entraînement supplémentaire. De plus, pour préserver l'information de haute fréquence dans les images d'entrée, nous appliquons un nouveau traitement de rinfarilization guidée. Les résultats des expériences montrent que le « Complete Relighting » démontre une forte capacité de généralisation et une consistance temporelle de l'illumination, dépassant les niveaux actuels de la reconstruction d'illumination humaine basée sur les images et les méthodes d'harmonie.",
      "upvotes": 4,
      "discussionId": "67f35d91db1a843e1ceff47c",
      "ai_keywords": [
        "diffusion models",
        "image prior",
        "coarse-to-fine framework",
        "temporal lighting model",
        "lighting cycle consistency",
        "spatio-temporal feature blending",
        "guided refinement"
      ]
    },
    "publishedAt": "2025-04-03T16:10:50.000Z",
    "title": "Comprehensive Relighting: Generalizable and Consistent Monocular Human\n  Relighting and Harmonization",
    "summary": "This paper introduces Comprehensive Relighting, the first all-in-one approach\nthat can both control and harmonize the lighting from an image or video of\nhumans with arbitrary body parts from any scene. Building such a generalizable\nmodel is extremely challenging due to the lack of dataset, restricting existing\nimage-based relighting models to a specific scenario (e.g., face or static\nhuman). To address this challenge, we repurpose a pre-trained diffusion model\nas a general image prior and jointly model the human relighting and background\nharmonization in the coarse-to-fine framework. To further enhance the temporal\ncoherence of the relighting, we introduce an unsupervised temporal lighting\nmodel that learns the lighting cycle consistency from many real-world videos\nwithout any ground truth. In inference time, our temporal lighting module is\ncombined with the diffusion models through the spatio-temporal feature blending\nalgorithms without extra training; and we apply a new guided refinement as a\npost-processing to preserve the high-frequency details from the input image. In\nthe experiments, Comprehensive Relighting shows a strong generalizability and\nlighting temporal coherence, outperforming existing image-based human\nrelighting and harmonization methods.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.03011.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 6594
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2504.02402",
      "authors": [
        {
          "_id": "67f0a09a2c873f5ba90cd14a",
          "user": {
            "_id": "67ee782979018bf61e2522a4",
            "avatarUrl": "/avatars/819318421eb40b9ba7e4054770823a8a.svg",
            "isPro": false,
            "fullname": "HaoYin",
            "user": "yyzqy",
            "type": "user"
          },
          "name": "Hao Yin",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-04-06T08:11:07.967Z",
          "hidden": false
        },
        {
          "_id": "67f0a09a2c873f5ba90cd14b",
          "name": "Shi Guo",
          "hidden": false
        },
        {
          "_id": "67f0a09a2c873f5ba90cd14c",
          "name": "Xu Jia",
          "hidden": false
        },
        {
          "_id": "67f0a09a2c873f5ba90cd14d",
          "name": "Xudong XU",
          "hidden": false
        },
        {
          "_id": "67f0a09a2c873f5ba90cd14e",
          "name": "Lu Zhang",
          "hidden": false
        },
        {
          "_id": "67f0a09a2c873f5ba90cd14f",
          "name": "Si Liu",
          "hidden": false
        },
        {
          "_id": "67f0a09a2c873f5ba90cd150",
          "name": "Dong Wang",
          "hidden": false
        },
        {
          "_id": "67f0a09a2c873f5ba90cd151",
          "name": "Huchuan Lu",
          "hidden": false
        },
        {
          "_id": "67f0a09a2c873f5ba90cd152",
          "name": "Tianfan Xue",
          "hidden": false
        }
      ],
      "publishedAt": "2025-04-03T08:51:17.000Z",
      "submittedOnDailyAt": "2025-04-07T05:44:25.380Z",
      "title": "Modèle spatio-temporel efficace de la récupération du son en modèles basés sur des événements acoustiques non en contact",
      "submittedOnDailyBy": {
        "_id": "67ee782979018bf61e2522a4",
        "avatarUrl": "/avatars/819318421eb40b9ba7e4054770823a8a.svg",
        "isPro": false,
        "fullname": "HaoYin",
        "user": "yyzqy",
        "type": "user"
      },
      "summary": "Le moment où l'ultrasonde rencontre un objet provoque des vibrations qui produisent des changements de fréquence élevée et des changements visuels minimaux, ce qui peut être utilisé pour récupérer l'ultrasonde. Dans les premiers études, on a considéré la fréquence d'échantillonnage, l'onde de bande, l'objet de champ et la simplicité des étapes optiques pour améliorer le processus. Le développement récent du matériel des caméras d'événements a augmenté la sensibilité aux signaux de fréquence élevée et a démontré un bon potentiel également pour la récupération visuelle de l'ultrasonde. Cependant, le méthode actuelle de récupération des vibrations basée sur les événements n'est pas la plus appropriée pour la récupération de l'ultrasonde. Dans cet article, on propose un nouveau modèle de traitement pour la récupération de l'ultrasonde non-contactante qui utilise complètement l'information spatio-temporelle obtenue des flux d'événements. Tout d'abord, on utilise un nouveau modèle de simulation pour générer de grands ensembles d'entraînement. Ensuite, on exploite la fréquence rare des événements pour identifier l'information spatiale et on conceve une réseau qui modélise l'information temporelle à long terme en utilisant Mamba. Enfin, on entraîne un bloc d'agrégation spectral pour intégrer l'information spatiale et améliorer la qualité de la signaux. Pour détecter la signaux d'événements avec l'ultrasonde, on conceve un système d'image en utilisant Raspberry Pi et on collecte plusieurs séquences de données pour les tests. Les résultats des expériences avec les données synthétiques et de la réalité montrent l'effet du méthode proposée et encouragent le développement de la récupération de l'ultrasonde.",
      "upvotes": 4,
      "discussionId": "67f0a09e2c873f5ba90cd26c",
      "projectPage": "https://yyzq1.github.io/EvMic/",
      "githubRepo": "https://github.com/yyzq1/EvMic",
      "ai_keywords": [
        "event camera",
        "high-frequency signals",
        "event stream",
        "spatial-temporal information",
        "novel simulation pipeline",
        "Mamba",
        "spatial aggregation block",
        "laser matrix"
      ]
    },
    "publishedAt": "2025-04-03T04:51:17.000Z",
    "title": "EvMic: Event-based Non-contact sound recovery from effective\n  spatial-temporal modeling",
    "summary": "When sound waves hit an object, they induce vibrations that produce\nhigh-frequency and subtle visual changes, which can be used for recovering the\nsound. Early studies always encounter trade-offs related to sampling rate,\nbandwidth, field of view, and the simplicity of the optical path. Recent\nadvances in event camera hardware show good potential for its application in\nvisual sound recovery, because of its superior ability in capturing\nhigh-frequency signals. However, existing event-based vibration recovery\nmethods are still sub-optimal for sound recovery. In this work, we propose a\nnovel pipeline for non-contact sound recovery, fully utilizing spatial-temporal\ninformation from the event stream. We first generate a large training set using\na novel simulation pipeline. Then we designed a network that leverages the\nsparsity of events to capture spatial information and uses Mamba to model\nlong-term temporal information. Lastly, we train a spatial aggregation block to\naggregate information from different locations to further improve signal\nquality. To capture event signals caused by sound waves, we also designed an\nimaging system using a laser matrix to enhance the gradient and collected\nmultiple data sequences for testing. Experimental results on synthetic and\nreal-world data demonstrate the effectiveness of our method.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.02402.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "67ee782979018bf61e2522a4",
      "avatarUrl": "/avatars/819318421eb40b9ba7e4054770823a8a.svg",
      "fullname": "HaoYin",
      "name": "yyzqy",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2503.24067",
      "authors": [
        {
          "_id": "67ecb89d0210bff02fd3591e",
          "user": {
            "_id": "66b4e3d850b87d84498bbc89",
            "avatarUrl": "/avatars/526c0cabf3a2c019a13bb82fcc7b43e9.svg",
            "isPro": false,
            "fullname": "YixingLi",
            "user": "Yixinglee",
            "type": "user"
          },
          "name": "Yixing Li",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-04-02T04:10:06.783Z",
          "hidden": false
        },
        {
          "_id": "67ecb89d0210bff02fd3591f",
          "name": "Ruobing Xie",
          "hidden": false
        },
        {
          "_id": "67ecb89d0210bff02fd35920",
          "user": {
            "_id": "62c4057732fa66fedacca0db",
            "avatarUrl": "/avatars/813e8c9fcd14dde1fdd415408f61bec2.svg",
            "isPro": false,
            "fullname": "AndyYang",
            "user": "andyyang",
            "type": "user"
          },
          "name": "Zhen Yang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-04-02T08:21:39.891Z",
          "hidden": false
        },
        {
          "_id": "67ecb89d0210bff02fd35921",
          "name": "Xingwu Sun",
          "hidden": false
        },
        {
          "_id": "67ecb89d0210bff02fd35922",
          "name": "Shuaipeng Li",
          "hidden": false
        },
        {
          "_id": "67ecb89d0210bff02fd35923",
          "name": "Weidong Han",
          "hidden": false
        },
        {
          "_id": "67ecb89d0210bff02fd35924",
          "name": "Zhanhui Kang",
          "hidden": false
        },
        {
          "_id": "67ecb89d0210bff02fd35925",
          "name": "Yu Cheng",
          "hidden": false
        },
        {
          "_id": "67ecb89d0210bff02fd35926",
          "name": "Chengzhong Xu",
          "hidden": false
        },
        {
          "_id": "67ecb89d0210bff02fd35927",
          "name": "Di Wang",
          "hidden": false
        },
        {
          "_id": "67ecb89d0210bff02fd35928",
          "name": "Jie Jiang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-03-31T13:26:24.000Z",
      "submittedOnDailyAt": "2025-04-07T07:35:17.947Z",
      "title": "TransMamba : Sélectionnez de manière appropriée facilement la transformer et Mamba.",
      "submittedOnDailyBy": {
        "_id": "62c4057732fa66fedacca0db",
        "avatarUrl": "/avatars/813e8c9fcd14dde1fdd415408f61bec2.svg",
        "isPro": false,
        "fullname": "AndyYang",
        "user": "andyyang",
        "type": "user"
      },
      "summary": "Transformers occupent une position fondamentale dans les modèles de langage à grande échelle modernes, présentant une complexité de calcul d'ordre second dans le traitement de séquences de longueur, ce qui limite l'efficacité. Récemment, l'évolution la plus récente des modèles espace-état (SSM) comme Mamba, avec sa complexité linéaire, a démontré des efficacités significatives, mais présente des limitations dans la perception du contexte instable et la capacité d'extension à plusieurs tâches. Dans ce travail, on propose un nouveau cadre de travail appelé TransMamba, qui intègre Transformers et Mamba en utilisant des matrices de paramètres partagés (par exemple, QKV et CBx), et montre la capacité de changer dynamiquement l'architecture de l'attention et les outils de SSM en fonction de la longueur et des couches. De plus, on conceve un convertisseur de mémoire pour connecter Transformers et Mamba, assurant un flux continu d'information au point de transition TransPoint. On étudie en détail l'échelle de TransPoint et on propose une extension. À travers des expériences larges, TransMamba atteint un haut rendement en termes d'efficacité d'apprentissage et de performance, démontrant une profonde consistance avec les paradigmes de Transformers et Mamba et fournissant une solution scalable pour le modèle de séquences de générations futures.",
      "upvotes": 4,
      "discussionId": "67ecb89e0210bff02fd3596b",
      "ai_keywords": [
        "Transformers",
        "state space model (SSM)",
        "attention",
        "QKV",
        "CBx",
        "TransMamba",
        "parameter matrices",
        "Memory converter",
        "TransPoints",
        "TransPoint scheduling",
        "next-generation sequence modeling"
      ]
    },
    "publishedAt": "2025-03-31T09:26:24.000Z",
    "title": "TransMamba: Flexibly Switching between Transformer and Mamba",
    "summary": "Transformers are the cornerstone of modern large language models, but their\nquadratic computational complexity limits efficiency in long-sequence\nprocessing. Recent advancements in Mamba, a state space model (SSM) with linear\ncomplexity, offer promising efficiency gains but suffer from unstable\ncontextual learning and multitask generalization. This paper proposes\nTransMamba, a novel framework that unifies Transformer and Mamba through shared\nparameter matrices (e.g., QKV and CBx), and thus could dynamically switch\nbetween attention and SSM mechanisms at different token lengths and layers. We\ndesign the Memory converter to bridge Transformer and Mamba by converting\nattention outputs into SSM-compatible states, ensuring seamless information\nflow at TransPoints where the transformation happens. The TransPoint scheduling\nis also thoroughly explored for further improvements. We conducted extensive\nexperiments demonstrating that TransMamba achieves superior training efficiency\nand performance compared to baselines, and validated the deeper consistency\nbetween Transformer and Mamba paradigms, offering a scalable solution for\nnext-generation sequence modeling.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.24067.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "62c4057732fa66fedacca0db",
      "avatarUrl": "/avatars/813e8c9fcd14dde1fdd415408f61bec2.svg",
      "fullname": "AndyYang",
      "name": "andyyang",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2504.03536",
      "authors": [
        {
          "_id": "67f364118188d683931bec4a",
          "name": "Boyuan Wang",
          "hidden": false
        },
        {
          "_id": "67f364118188d683931bec4b",
          "name": "Runqi Ouyang",
          "hidden": false
        },
        {
          "_id": "67f364118188d683931bec4c",
          "name": "Xiaofeng Wang",
          "hidden": false
        },
        {
          "_id": "67f364118188d683931bec4d",
          "user": {
            "_id": "656e9b562cd7a3e348011d26",
            "avatarUrl": "/avatars/bcca51bdc27c664f8f132420e6ed99fa.svg",
            "isPro": false,
            "fullname": "Zheng Zhu",
            "user": "ZhengZhu",
            "type": "user"
          },
          "name": "Zheng Zhu",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-04-07T05:35:15.515Z",
          "hidden": false
        },
        {
          "_id": "67f364118188d683931bec4e",
          "name": "Guosheng Zhao",
          "hidden": false
        },
        {
          "_id": "67f364118188d683931bec4f",
          "name": "Chaojun Ni",
          "hidden": false
        },
        {
          "_id": "67f364118188d683931bec50",
          "name": "Guan Huang",
          "hidden": false
        },
        {
          "_id": "67f364118188d683931bec51",
          "name": "Lihong Liu",
          "hidden": false
        },
        {
          "_id": "67f364118188d683931bec52",
          "name": "Xingang Wang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-04-04T15:35:14.000Z",
      "submittedOnDailyAt": "2025-04-07T04:06:19.815Z",
      "title": "HumanDreamer-X: photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos photos",
      "submittedOnDailyBy": {
        "_id": "60f1abe7544c2adfd699860c",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
        "isPro": false,
        "fullname": "AK",
        "user": "akhaliq",
        "type": "user"
      },
      "summary": "Reconstruire l'humanité dans une seule image est un élément crucial mais extrêmement difficile dans les applications de modélisation numérique de l'humanité. Les méthodes actuelles dépendent de modèles génératifs pour combiner des images polyédriques pour la reconstruction 3D et l'animation. Cependant, générer directement des images polyédriques à partir d'une seule image de l'humanité implique des discontinuités géométriques et des problèmes comme la faible séparation ou la concentration des parties dans les modèles de reconstruction. Pour surmonter ces limitations, nous proposons le nouveau cadre de travail HumanDreamer-X. Dans ce cadre, la génération et la reconstruction polyédriques de l'humanité sont intégrées dans une seule chaîne de travail, ce qui signifie une amélioration significative de la cohérence géométrique et de la fiabilité visuelle des modèles 3D reconstruits. Dans HumanDreamer-X, le split 3D gaussien fournit une représentation explicite 3D avec les caractéristiques initiales et les priorités d'application. Ainsi, HumanFixer apprend à récupérer des images de rendu 3DGS et s'assure des résultats réalistes. De plus, nous abordons profondément les problèmes inhérents à la génération polyédrique de l'humanité, proposant des stratégies d'ajustement pour la fonction d'attention pour améliorer efficacement les détails géométriques et la cohérence. Les résultats des expériences montrent que notre approche améliore la qualité de la génération et de la reconstruction en PSNR d'environ 16,45% et 12,65% respectivement, et atteint un PSNR de 25,62 dB, en plus de sa capacité à s'adapter aux données en ligne et à être appliquée à divers modèles de reconstruction basés sur l'humanité.",
      "upvotes": 3,
      "discussionId": "67f364138188d683931beca2",
      "ai_keywords": [
        "3D Gaussian Splatting",
        "HumanDreamer-X",
        "HumanFixer",
        "attention modulation",
        "PSNR"
      ]
    },
    "publishedAt": "2025-04-04T11:35:14.000Z",
    "title": "HumanDreamer-X: Photorealistic Single-image Human Avatars Reconstruction\n  via Gaussian Restoration",
    "summary": "Single-image human reconstruction is vital for digital human modeling\napplications but remains an extremely challenging task. Current approaches rely\non generative models to synthesize multi-view images for subsequent 3D\nreconstruction and animation. However, directly generating multiple views from\na single human image suffers from geometric inconsistencies, resulting in\nissues like fragmented or blurred limbs in the reconstructed models. To tackle\nthese limitations, we introduce HumanDreamer-X, a novel framework that\nintegrates multi-view human generation and reconstruction into a unified\npipeline, which significantly enhances the geometric consistency and visual\nfidelity of the reconstructed 3D models. In this framework, 3D Gaussian\nSplatting serves as an explicit 3D representation to provide initial geometry\nand appearance priority. Building upon this foundation, HumanFixer is\ntrained to restore 3DGS renderings, which guarantee photorealistic results.\nFurthermore, we delve into the inherent challenges associated with attention\nmechanisms in multi-view human generation, and propose an attention modulation\nstrategy that effectively enhances geometric details identity consistency\nacross multi-view. Experimental results demonstrate that our approach markedly\nimproves generation and reconstruction PSNR quality metrics by 16.45% and\n12.65%, respectively, achieving a PSNR of up to 25.62 dB, while also showing\ngeneralization capabilities on in-the-wild data and applicability to various\nhuman reconstruction backbone models.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.03536.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 6594
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2503.24310",
      "authors": [
        {
          "_id": "67ecb513c8ae971f9ad15bd1",
          "user": {
            "_id": "6478fc1512ae749b62ebbbd5",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6478fc1512ae749b62ebbbd5/zw-wYy1vEWnG9-t6c9W_x.jpeg",
            "isPro": false,
            "fullname": "Alok Abhishek",
            "user": "alokabhishek",
            "type": "user"
          },
          "name": "Alok Abhishek",
          "status": "extracted_confirmed",
          "statusLastChangedAt": "2025-04-02T03:59:10.671Z",
          "hidden": false
        },
        {
          "_id": "67ecb513c8ae971f9ad15bd2",
          "name": "Lisa Erickson",
          "hidden": false
        },
        {
          "_id": "67ecb513c8ae971f9ad15bd3",
          "user": {
            "_id": "657372396da136b50f5489a0",
            "avatarUrl": "/avatars/57a693058e9a05a2c32f02bab1d8e819.svg",
            "isPro": false,
            "fullname": "Tushar Bandopadhyay",
            "user": "tbandopa",
            "type": "user"
          },
          "name": "Tushar Bandopadhyay",
          "status": "extracted_confirmed",
          "statusLastChangedAt": "2025-04-02T08:13:38.947Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-03-31T16:56:52.000Z",
      "submittedOnDailyAt": "2025-04-07T03:47:34.752Z",
      "title": "BEATS : Évaluation des biais dans les modèles de langue et système de tests d'évaluation",
      "submittedOnDailyBy": {
        "_id": "6478fc1512ae749b62ebbbd5",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6478fc1512ae749b62ebbbd5/zw-wYy1vEWnG9-t6c9W_x.jpeg",
        "isPro": false,
        "fullname": "Alok Abhishek",
        "user": "alokabhishek",
        "type": "user"
      },
      "summary": "Dans cette étude, un nouveau cadre de référence appelé \"BEATS\" est présenté pour l'évaluation des biais, l'éthique, l'équité et la véracité dans les modèles de langage grands (LLMs). En s'appuyant sur le cadre BEATS, un cadre de référence des biais pour les LLMs est proposé et son performance est mesurée avec 29 métriques différentes. Ces métriques comprennent les biais populationnels, cognitifs et sociaux, les raisons éthiques, l'équité des groupes et les risques d'information non scientifique liés à la vérité. Ces métriques permettent d'évaluer dans quelle mesure les réponses générées par un LLM peuvent propager des biais sociaux et amplifier l'inégalité du système. Pour atteindre de hauts scores dans ce cadre de référence, il est nécessaire que les réponses d'un LLM démontrent des comportements très équitables. Cela représente un standard strict d'évaluation de l'IA responsable. Les résultats des expériences basées sur les données montrent clairement que le 37,65% des sorties incluent des biais, et si ces modèles sont utilisés dans des systèmes de prise de décision importantes, il existe un risque considérable. Le cadre BEATS et le cadre de référence fournissent des méthodes scalables et statistiquement strictes pour l'évaluation des LLMs, le diagnostic des causes des biais et le développement de stratégies d'action. Notre objectif, basé sur le cadre BEATS, est d'aider à la création de modèles d'IA plus responsables et éthiques qui reflètent mieux la société.",
      "upvotes": 2,
      "discussionId": "67ecb513c8ae971f9ad15c02",
      "ai_keywords": [
        "Large Language Models (LLMs)",
        "Bias benchmark",
        "Bias",
        "Ethics",
        "Fairness",
        "Factuality",
        "Demographic biases",
        "Cognitive biases",
        "Social biases",
        "Ethical reasoning",
        "Group fairness",
        "Factuality related misinformation risk",
        "Equitable behavior",
        "Responsible AI evaluation",
        "Critical decision making systems",
        "Scalable methodology",
        "Statistically rigorous methodology",
        "Diagnose factors driving biases",
        "Mitigation strategies",
        "Socially responsible AI models",
        "Ethically aligned AI models"
      ]
    },
    "publishedAt": "2025-03-31T12:56:52.000Z",
    "title": "BEATS: Bias Evaluation and Assessment Test Suite for Large Language\n  Models",
    "summary": "In this research, we introduce BEATS, a novel framework for evaluating Bias,\nEthics, Fairness, and Factuality in Large Language Models (LLMs). Building upon\nthe BEATS framework, we present a bias benchmark for LLMs that measure\nperformance across 29 distinct metrics. These metrics span a broad range of\ncharacteristics, including demographic, cognitive, and social biases, as well\nas measures of ethical reasoning, group fairness, and factuality related\nmisinformation risk. These metrics enable a quantitative assessment of the\nextent to which LLM generated responses may perpetuate societal prejudices that\nreinforce or expand systemic inequities. To achieve a high score on this\nbenchmark a LLM must show very equitable behavior in their responses, making it\na rigorous standard for responsible AI evaluation. Empirical results based on\ndata from our experiment show that, 37.65\\% of outputs generated by industry\nleading models contained some form of bias, highlighting a substantial risk of\nusing these models in critical decision making systems. BEATS framework and\nbenchmark offer a scalable and statistically rigorous methodology to benchmark\nLLMs, diagnose factors driving biases, and develop mitigation strategies. With\nthe BEATS framework, our goal is to help the development of more socially\nresponsible and ethically aligned AI models.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.24310.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6478fc1512ae749b62ebbbd5",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6478fc1512ae749b62ebbbd5/zw-wYy1vEWnG9-t6c9W_x.jpeg",
      "fullname": "Alok Abhishek",
      "name": "alokabhishek",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 5
    },
    "isAuthorParticipating": true
  }
]