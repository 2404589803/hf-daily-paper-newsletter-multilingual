[
  {
    "paper": {
      "id": "2506.14429",
      "authors": [
        {
          "_id": "68521a9a0164cd131671045c",
          "name": "Xiaoran Liu",
          "hidden": false
        },
        {
          "_id": "68521a9a0164cd131671045d",
          "name": "Zhigeng Liu",
          "hidden": false
        },
        {
          "_id": "68521a9a0164cd131671045e",
          "name": "Zengfeng Huang",
          "hidden": false
        },
        {
          "_id": "68521a9a0164cd131671045f",
          "name": "Qipeng Guo",
          "hidden": false
        },
        {
          "_id": "68521a9a0164cd1316710460",
          "name": "Ziwei He",
          "hidden": false
        },
        {
          "_id": "68521a9a0164cd1316710461",
          "name": "Xipeng Qiu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-06-17T11:45:37.000Z",
      "submittedOnDailyAt": "2025-06-18T00:18:23.135Z",
      "title": "LongLLaMA : Libération de la capacité de contexte long dans un LLM distribué",
      "submittedOnDailyBy": {
        "_id": "64f033ef82c6eea604c4da8b",
        "avatarUrl": "/avatars/51b93fea7fd68b4274ee03701245dcca.svg",
        "isPro": false,
        "fullname": "Liu Xiaoran",
        "user": "LiuXR",
        "type": "user"
      },
      "summary": "Les Modèles de Diffusion de Langage Grands (Large Language Diffusion Models, LLMs) ont émergé comme un important point de focalisation dans la recherche en NLP, avec un grand effort axé sur l'échelle et le rendement dans les tâches de décodage. Cependant, leur capacité à gérer des contextes longs n'a pas été explorée et existent peu de méthodes systématiques pour leur analyse et l'élargissement. Dans cette étude, une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des contextes longs. Une première recherche systématique est menée pour comparer le rendement avec des context",
      "upvotes": 27,
      "discussionId": "68521a9a0164cd1316710462",
      "ai_summary": "This study investigates long-context performance of diffusion LLMs compared to auto-regressive LLMs, identifies their unique characteristics, and proposes LongLLaDA, a training-free method for extending context windows.",
      "ai_keywords": [
        "diffusion LLMs",
        "auto-regressive LLMs",
        "stable perplexity",
        "local perception",
        "Rotary Position Embedding (RoPE) scaling theory",
        "LongLLaDA",
        "NTK-based RoPE extrapolation",
        "context extrapolation scaling laws",
        "long-context tasks"
      ]
    },
    "publishedAt": "2025-06-17T07:45:37.000Z",
    "title": "LongLLaDA: Unlocking Long Context Capabilities in Diffusion LLMs",
    "summary": "Large Language Diffusion Models, or diffusion LLMs, have emerged as a\nsignificant focus in NLP research, with substantial effort directed toward\nunderstanding their scalability and downstream task performance. However, their\nlong-context capabilities remain unexplored, lacking systematic analysis or\nmethods for context extension. In this work, we present the first systematic\ninvestigation comparing the long-context performance of diffusion LLMs and\ntraditional auto-regressive LLMs. We first identify a unique characteristic of\ndiffusion LLMs, unlike auto-regressive LLMs, they maintain remarkably\n\\textit{stable perplexity} during direct context extrapolation.\nFurthermore, where auto-regressive models fail outright during the\nNeedle-In-A-Haystack task with context exceeding their pretrained length, we\ndiscover diffusion LLMs exhibit a distinct \\textit{local perception}\nphenomenon, enabling successful retrieval from recent context segments. We\nexplain both phenomena through the lens of Rotary Position Embedding (RoPE)\nscaling theory. Building on these observations, we propose LongLLaDA, a\ntraining-free method that integrates LLaDA with the NTK-based RoPE\nextrapolation. Our results validate that established extrapolation scaling laws\nremain effective for extending the context windows of diffusion LLMs.\nFurthermore, we identify long-context tasks where diffusion LLMs outperform\nauto-regressive LLMs and others where they fall short. Consequently, this study\nestablishes the first context extrapolation method for diffusion LLMs while\nproviding essential theoretical insights and empirical benchmarks critical for\nadvancing future research on long-context diffusion LLMs.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.14429.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64f033ef82c6eea604c4da8b",
      "avatarUrl": "/avatars/51b93fea7fd68b4274ee03701245dcca.svg",
      "fullname": "Liu Xiaoran",
      "name": "LiuXR",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 4
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2506.12928",
      "authors": [
        {
          "_id": "6851dd060164cd13167103d7",
          "name": "King Zhu",
          "hidden": false
        },
        {
          "_id": "6851dd060164cd13167103d8",
          "name": "Hanhao Li",
          "hidden": false
        },
        {
          "_id": "6851dd060164cd13167103d9",
          "name": "Siwei Wu",
          "hidden": false
        },
        {
          "_id": "6851dd060164cd13167103da",
          "name": "Tianshun Xing",
          "hidden": false
        },
        {
          "_id": "6851dd060164cd13167103db",
          "name": "Dehua Ma",
          "hidden": false
        },
        {
          "_id": "6851dd060164cd13167103dc",
          "name": "Xiangru Tang",
          "hidden": false
        },
        {
          "_id": "6851dd060164cd13167103dd",
          "name": "Minghao Liu",
          "hidden": false
        },
        {
          "_id": "6851dd060164cd13167103de",
          "name": "Jian Yang",
          "hidden": false
        },
        {
          "_id": "6851dd060164cd13167103df",
          "name": "Jiaheng Liu",
          "hidden": false
        },
        {
          "_id": "6851dd060164cd13167103e0",
          "name": "Yuchen Eleanor Jiang",
          "hidden": false
        },
        {
          "_id": "6851dd060164cd13167103e1",
          "name": "Changwang Zhang",
          "hidden": false
        },
        {
          "_id": "6851dd060164cd13167103e2",
          "name": "Chenghua Lin",
          "hidden": false
        },
        {
          "_id": "6851dd060164cd13167103e3",
          "name": "Jun Wang",
          "hidden": false
        },
        {
          "_id": "6851dd060164cd13167103e4",
          "name": "Ge Zhang",
          "hidden": false
        },
        {
          "_id": "6851dd060164cd13167103e5",
          "name": "Wangchunshu Zhou",
          "hidden": false
        }
      ],
      "publishedAt": "2025-06-15T17:59:47.000Z",
      "submittedOnDailyAt": "2025-06-18T04:21:02.464Z",
      "title": "Tests de Scalabilité en Temps du Réseau de Neurones Largement Modèle",
      "submittedOnDailyBy": {
        "_id": "638efcf4c67af472d316d424",
        "avatarUrl": "/avatars/97a57859d7d87a3a8f1bb41d32a72bc2.svg",
        "isPro": false,
        "fullname": "Ge Zhang",
        "user": "zhangysk",
        "type": "user"
      },
      "summary": "Lorsqu'on monte dans le temps pour mesurer, le calcul de la montée en échelle s'étend considérablement, ce qui est utilisé avec succès pour améliorer considérablement la capacité d'inférence de grands modèles de langage (LLMs). Dans cette étude, une recherche systématique initiale est effectuée sur l'application de méthodes d'échelle en temps pour les agents de langage et leurs effets sont évalués. En particulier, on étudie les suivantes stratégies d'échelle en temps : 1. Algorithmes de sampling parallèle ; 2. Stratégies de modification séquentielle ; 3. Méthodes d'intégration de données de validation et de résultats ; 4. Stratégies pour diversifier le sampling. On analyse en détail l'influence de différentes stratégies de conception lorsqu'on applique l'échelle en temps à des agents de langage, obtenant les résultats suivants : 1. Extender le calcul de l'échelle en temps peut améliorer le rendement de l'agent. 2. Le moment de réflexion est très important pour l'agent. 3. Le méthode de liste pour intégrer différentes formes de validation et de résultats est la plus efficace. 4. La diversification du sampling a un impact positif sur la capacité de tâches de l'agent.",
      "upvotes": 26,
      "discussionId": "6851dd060164cd13167103e6",
      "ai_summary": "Systematic exploration of test-time scaling methods in large language agents reveals that computational scaling improves performance, especially through parallel sampling, sequential revision, effective verification, and increased rollout diversity.",
      "ai_keywords": [
        "parallel sampling algorithms",
        "sequential revision strategies",
        "verifiers",
        "merging methods",
        "diversified rollouts",
        "test-time scaling",
        "large language models"
      ]
    },
    "publishedAt": "2025-06-15T13:59:47.000Z",
    "title": "Scaling Test-time Compute for LLM Agents",
    "summary": "Scaling test time compute has shown remarkable success in improving the\nreasoning abilities of large language models (LLMs). In this work, we conduct\nthe first systematic exploration of applying test-time scaling methods to\nlanguage agents and investigate the extent to which it improves their\neffectiveness. Specifically, we explore different test-time scaling strategies,\nincluding: (1) parallel sampling algorithms; (2) sequential revision\nstrategies; (3) verifiers and merging methods; (4)strategies for diversifying\nrollouts.We carefully analyze and ablate the impact of different design\nstrategies on applying test-time scaling on language agents, and have follow\nfindings: 1. Scaling test time compute could improve the performance of agents.\n2. Knowing when to reflect is important for agents. 3. Among different\nverification and result merging approaches, the list-wise method performs best.\n4. Increasing diversified rollouts exerts a positive effect on the agent's task\nperformance.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.12928.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "638efcf4c67af472d316d424",
      "avatarUrl": "/avatars/97a57859d7d87a3a8f1bb41d32a72bc2.svg",
      "fullname": "Ge Zhang",
      "name": "zhangysk",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 49
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2506.13642",
      "authors": [
        {
          "_id": "685129448a68fee7f6ba4c04",
          "name": "Shaolei Zhang",
          "hidden": false
        },
        {
          "_id": "685129448a68fee7f6ba4c05",
          "name": "Shoutao Guo",
          "hidden": false
        },
        {
          "_id": "685129448a68fee7f6ba4c06",
          "name": "Qingkai Fang",
          "hidden": false
        },
        {
          "_id": "685129448a68fee7f6ba4c07",
          "name": "Yan Zhou",
          "hidden": false
        },
        {
          "_id": "685129448a68fee7f6ba4c08",
          "name": "Yang Feng",
          "hidden": false
        }
      ],
      "mediaUrls": [
        "https://cdn-uploads.huggingface.co/production/uploads/64803e5dc57f629056c601f1/MBm95m2RAX6iKKBaKTma8.mp4",
        "https://cdn-uploads.huggingface.co/production/uploads/64803e5dc57f629056c601f1/PoLupV32gI1iLxILZccQS.mp4"
      ],
      "publishedAt": "2025-06-16T16:06:45.000Z",
      "submittedOnDailyAt": "2025-06-18T00:16:02.465Z",
      "title": "Stream Omni : Interaction Multimodale Interactive et Modèles de Langage-Vision-Audio à Grande Échelle",
      "submittedOnDailyBy": {
        "_id": "64803e5dc57f629056c601f1",
        "avatarUrl": "/avatars/a9e9c97c70714e3a29bef2cf929ee6b3.svg",
        "isPro": false,
        "fullname": "Shaolei Zhang",
        "user": "zhangshaolei",
        "type": "user"
      },
      "summary": "La présence de modèles grands comme GPT-4 encourage l'intégration de modèles de texte, vision et voix, tout en favorisant la recherche sur les interactions multimodales plus flexibles. Actuellement, les modèles grands (LMMs) se connectent généralement à la dimension de séquence du modèle et à sa représentation, ce qui les relie à une base de modèle de langage de grande échelle (LLM). Cette connexion est simple mais nécessite de grands volumes de données pour entraîner la réponse du modèle. Dans cet article, nous proposons une modélisation plus objective des relations entre modèles et l'implémentation de réponses plus efficaces et flexibles. Pour cela, nous proposons Stream-Omni, un modèle grand de langage-vision-voix qui utilise un LLM comme base. La vision et le voix s'adaptent à la texture, et Stream-Omni effectue la correspondance vision-texte en utilisant la connexion de dimensions de séquence lorsque la vision complète le texte. Pour la correspondance voix-texte, Stream-Omni utilise un mapping de dimensions de couches basé sur CTC lorsque la voix est significativement similaire au texte. De cette manière, Stream-Omni peut implémenter des réponses avec peu de données (en particulier de voix), et les fonctions de texte peuvent être transmises à d'autres modèles. Les expériences dans différents cadres de référence montrent que Stream-Omni présente des résultats exceptionnels en compréhension visuelle, interaction vocale et tâches d'interaction vocale basées sur la vision. Grâce au mapping de dimensions de couches, Stream-Omni peut fournir à l'utilisateur une expérience multimodale détaillée, y compris des traductions d'ASR ou des réponses du modèle lors de l'interaction vocale.",
      "upvotes": 18,
      "discussionId": "685129458a68fee7f6ba4c09",
      "projectPage": "https://github.com/ictnlp/Stream-Omni",
      "githubRepo": "https://github.com/ictnlp/Stream-Omni",
      "ai_summary": "Stream-Omni, a large multimodal model, integrates text, vision, and speech by efficiently aligning modalities using sequence-dimension concatenation for vision and layer-dimension mapping for speech, achieving strong performance with less data.",
      "ai_keywords": [
        "GPT-4o-like",
        "large multimodal models",
        "LLM backbone",
        "modality alignments",
        "sequence-dimension concatenation",
        "CTC-based layer-dimension mapping",
        "visual understanding",
        "speech interaction",
        "vision-grounded speech interaction",
        "ASR transcriptions",
        "model responses"
      ]
    },
    "publishedAt": "2025-06-16T12:06:45.000Z",
    "title": "Stream-Omni: Simultaneous Multimodal Interactions with Large\n  Language-Vision-Speech Model",
    "summary": "The emergence of GPT-4o-like large multimodal models (LMMs) has raised the\nexploration of integrating text, vision, and speech modalities to support more\nflexible multimodal interaction. Existing LMMs typically concatenate\nrepresentation of modalities along the sequence dimension and feed them into a\nlarge language model (LLM) backbone. While sequence-dimension concatenation is\nstraightforward for modality integration, it often relies heavily on\nlarge-scale data to learn modality alignments. In this paper, we aim to model\nthe relationships between modalities more purposefully, thereby achieving more\nefficient and flexible modality alignments. To this end, we propose\nStream-Omni, a large language-vision-speech model with efficient modality\nalignments, which can simultaneously support interactions under various\nmodality combinations. Stream-Omni employs LLM as the backbone and aligns the\nvision and speech to the text based on their relationships. For vision that is\nsemantically complementary to text, Stream-Omni uses sequence-dimension\nconcatenation to achieve vision-text alignment. For speech that is semantically\nconsistent with text, Stream-Omni introduces a CTC-based layer-dimension\nmapping to achieve speech-text alignment. In this way, Stream-Omni can achieve\nmodality alignments with less data (especially speech), enabling the transfer\nof text capabilities to other modalities. Experiments on various benchmarks\ndemonstrate that Stream-Omni achieves strong performance on visual\nunderstanding, speech interaction, and vision-grounded speech interaction\ntasks. Owing to the layer-dimensional mapping, Stream-Omni can simultaneously\nprovide intermediate text outputs (such as ASR transcriptions and model\nresponses) during speech interaction, offering users a comprehensive multimodal\nexperience.",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/64803e5dc57f629056c601f1/MBm95m2RAX6iKKBaKTma8.mp4",
      "https://cdn-uploads.huggingface.co/production/uploads/64803e5dc57f629056c601f1/PoLupV32gI1iLxILZccQS.mp4"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.13642.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64803e5dc57f629056c601f1",
      "avatarUrl": "/avatars/a9e9c97c70714e3a29bef2cf929ee6b3.svg",
      "fullname": "Shaolei Zhang",
      "name": "zhangshaolei",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2506.14234",
      "authors": [
        {
          "_id": "68522d7f0164cd13167104ee",
          "name": "Md Tanzib Hosain",
          "hidden": false
        },
        {
          "_id": "68522d7f0164cd13167104ef",
          "name": "Salman Rahman",
          "hidden": false
        },
        {
          "_id": "68522d7f0164cd13167104f0",
          "name": "Md Kishor Morol",
          "hidden": false
        },
        {
          "_id": "68522d7f0164cd13167104f1",
          "name": "Md Rizwan Parvez",
          "hidden": false
        }
      ],
      "publishedAt": "2025-06-17T06:47:19.000Z",
      "submittedOnDailyAt": "2025-06-18T01:39:00.207Z",
      "title": "Solution : Nous utilisons une logique efficace de coopération pour exploiter des expériences holistiques d'apprentissage qui permettent de résoudre des problèmes comme un équipe olympique.",
      "submittedOnDailyBy": {
        "_id": "65ae1c4468139e3c42973fe4",
        "avatarUrl": "/avatars/b065a857dd763410caadea37a2dc01c4.svg",
        "isPro": false,
        "fullname": "Md Rizwan Parvez",
        "user": "mparvez",
        "type": "user"
      },
      "summary": "Ahora, dans le contexte complexe de la théorie logique, bien que des révolutions surprenantes soient présentées, les grands modèles de langue (LLMs) fonctionnent généralement de manière indépendante, traitant des problèmes de manière indépendante et sans accumuler ou intégrer des connaissances expérimentales. En contraste, les équipes de résolution de problèmes comme celles des Jeux Olympiques ou de la programmation, qui sont expertes dans leur domaine, utilisent une grande quantité d'expérience, reçoivent une orientation nécessitant une formation, sont entraînées à travers des problèmes passés, utilisent des outils et des connaissances de bibliothèques, changent des stratégies basées sur l'expérience et la technologie de leurs collègues experts, et améliorent leur logique par des répétitions d'essais et d'échecs, en apprenant également des autres problèmes liés pendant la compétition. On présente Xolver, un cadre logique de multiples agents sans entraînement. Xolver considère les LLMs comme un objet noir et leur attribue une mémoire représentant une image complète et évolutive d'expériences. Xolver intègre diverses expériences, y compris des recherches externes, l'utilisation d'outils, le traitement collectif, l'évaluation d'agents, et les améliorations itératives. Xolver apprend des stratégies, des motifs de code et des motifs logiques abstraits d'inférence, évitant la génération de solutions depuis le début et montrant la transition des agents de langue basés sur l'inférence indépendante vers des agents de langue basés sur l'expérience. Xolver s'appuie autant sur des modèles ouverts que sur des modèles privés, mais maintient un rendement expérimental qui dépasse les agents de logique. Dans des modèles avancés comme Qwen3-235B, Gemini 2.5 Pro, o3, o4-mini-high, Xolver dépasse de nombreux agents en conditions légères (par exemple, QWQ-32B). En utilisant o3-mini-high, Xolver obtient de nouveaux rendements sur GSM8K (98,1%), AIME'24 (94,4%), AIME'25 (93,7%), Math-500 (99,8%), et LiveCodeBench-V5 (91,6%), démontrant le développement d'agents généraux basés sur l'apprentissage expérimental et montrant que les codes et les données sont disponibles à https://kagnlp.github.io/xolver.github.io/.",
      "upvotes": 17,
      "discussionId": "68522d7f0164cd13167104f2",
      "ai_summary": "Xolver, a multi-agent reasoning framework, enhances large language models with persistent memory and diverse experience modalities, improving performance on complex reasoning tasks by avoiding generating solutions from scratch.",
      "ai_keywords": [
        "large language models",
        "LLMs",
        "multi-agent reasoning framework",
        "persistent memory",
        "experience-aware language agents",
        "external and self-retrieval",
        "tool use",
        "collaborative interactions",
        "agent-driven evaluation",
        "iterative refinement",
        "GSM8K",
        "AIME'24",
        "AIME'25",
        "Math-500",
        "LiveCodeBench-V5",
        "generalist agents",
        "expert-level reasoning"
      ]
    },
    "publishedAt": "2025-06-17T02:47:19.000Z",
    "title": "Xolver: Multi-Agent Reasoning with Holistic Experience Learning Just\n  Like an Olympiad Team",
    "summary": "Despite impressive progress on complex reasoning, current large language\nmodels (LLMs) typically operate in isolation - treating each problem as an\nindependent attempt, without accumulating or integrating experiential\nknowledge. In contrast, expert problem solvers - such as Olympiad or\nprogramming contest teams - leverage a rich tapestry of experiences: absorbing\nmentorship from coaches, developing intuition from past problems, leveraging\nknowledge of tool usage and library functionality, adapting strategies based on\nthe expertise and experiences of peers, continuously refining their reasoning\nthrough trial and error, and learning from other related problems even during\ncompetition. We introduce Xolver, a training-free multi-agent reasoning\nframework that equips a black-box LLM with a persistent, evolving memory of\nholistic experience. Xolver integrates diverse experience modalities, including\nexternal and self-retrieval, tool use, collaborative interactions, agent-driven\nevaluation, and iterative refinement. By learning from relevant strategies,\ncode fragments, and abstract reasoning patterns at inference time, Xolver\navoids generating solutions from scratch - marking a transition from isolated\ninference toward experience-aware language agents. Built on both open-weight\nand proprietary models, Xolver consistently outperforms specialized reasoning\nagents. Even with lightweight backbones (e.g., QWQ-32B), it often surpasses\nadvanced models including Qwen3-235B, Gemini 2.5 Pro, o3, and o4-mini-high.\nWith o3-mini-high, it achieves new best results on GSM8K (98.1%), AIME'24\n(94.4%), AIME'25 (93.7%), Math-500 (99.8%), and LiveCodeBench-V5 (91.6%) -\nhighlighting holistic experience learning as a key step toward generalist\nagents capable of expert-level reasoning. Code and data are available at\nhttps://kagnlp.github.io/xolver.github.io/.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.14234.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "65ae1c4468139e3c42973fe4",
      "avatarUrl": "/avatars/b065a857dd763410caadea37a2dc01c4.svg",
      "fullname": "Md Rizwan Parvez",
      "name": "mparvez",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2506.13363",
      "authors": [
        {
          "_id": "685234100164cd1316710508",
          "name": "Lijun Liu",
          "hidden": false
        },
        {
          "_id": "685234100164cd1316710509",
          "name": "Ruiyang Li",
          "hidden": false
        },
        {
          "_id": "685234100164cd131671050a",
          "name": "Zhaocheng Liu",
          "hidden": false
        },
        {
          "_id": "685234100164cd131671050b",
          "name": "Chenglin Zhu",
          "hidden": false
        },
        {
          "_id": "685234100164cd131671050c",
          "name": "Chong Li",
          "hidden": false
        },
        {
          "_id": "685234100164cd131671050d",
          "name": "Jiehan Cheng",
          "hidden": false
        },
        {
          "_id": "685234100164cd131671050e",
          "name": "Qiang Ju",
          "hidden": false
        },
        {
          "_id": "685234100164cd131671050f",
          "name": "Jian Xie",
          "hidden": false
        }
      ],
      "mediaUrls": [
        "https://cdn-uploads.huggingface.co/production/uploads/633e570be7d5ce7bfe037a53/-7W-jpcvZwQ046FQHgVdY.qt"
      ],
      "publishedAt": "2025-06-16T11:10:25.000Z",
      "submittedOnDailyAt": "2025-06-18T02:12:29.534Z",
      "title": "Efficace VIH Médica par l'Apprentissage par Renforcement",
      "submittedOnDailyBy": {
        "_id": "633e570be7d5ce7bfe037a53",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/633e570be7d5ce7bfe037a53/zV8ULv4Mu7YIGZ8D3JtmK.jpeg",
        "isPro": false,
        "fullname": "Zhaocheng Liu",
        "user": "zhaocheng",
        "type": "user"
      },
      "summary": "L'Extraction d'Information Visuelle (EIV) nécessite transformer des documents non structurés en formats structurés tels que JSON pour l'analyse de rapports médicaux ou les consultations en ligne. Les méthodes existantes basées sur OCR et modèles de langage ne peuvent générer directement un JSON. Cependant, des modèles multimodal à l'apprentissage continu peuvent le faire, mais l'efficacité de l'EIV médicale est limitée par des schémas propres au domaine et des coûts d'annotation élevés. Notre approche se base sur le cadre de Récompenses Vérifiables (RLVR), utilisant 100 échantillons d'annotation pour résoudre ces problèmes. Notre approche fournit une diversité dans le jeu de données, maintient un équilibre entre précision et récupération par une structure de récompenses provable, et propose une nouvelle stratégie d'échantillonnage pour réduire le bruit, améliorer la couverture des domaines et renforcer la théorie. Qwen2.5-VL-7B a été fine-tuné avec RLVR pour atteindre les meilleurs résultats sur des tâches médicales, améliorant significativement la F1, la précision et la récupération. Notre modèle est exceptionnel dans des tâches de données médicales similaires, mais son rendement diminue dans d'autres tâches, ce qui souligne la nécessité d'une optimisation propre au domaine. Un cas d'étude met en avant l'importance de la théorie dans l'entraînement et l'inférence de l'EIV.",
      "upvotes": 17,
      "discussionId": "685234100164cd1316710510",
      "ai_summary": "An RLVR framework using fine-tuned Qwen2.5-VL-7B achieves state-of-the-art performance in medical VIE with limited annotated samples, enhancing reasoning and balance between precision and recall.",
      "ai_keywords": [
        "Reinforcement Learning with Verifiable Rewards (RLVR)",
        "JSON generation",
        "multimodal models",
        "dataset diversity",
        "precision-recall reward mechanism",
        "hallucinations",
        "field coverage",
        "sampling strategies",
        "fine-tuning",
        "Qwen2.5-VL-7B",
        "F1 score",
        "case studies"
      ]
    },
    "publishedAt": "2025-06-16T07:10:25.000Z",
    "title": "Efficient Medical VIE via Reinforcement Learning",
    "summary": "Visual Information Extraction (VIE) converts unstructured document images\ninto structured formats like JSON, critical for medical applications such as\nreport analysis and online consultations. Traditional methods rely on OCR and\nlanguage models, while end-to-end multimodal models offer direct JSON\ngeneration. However, domain-specific schemas and high annotation costs limit\ntheir effectiveness in medical VIE. We base our approach on the Reinforcement\nLearning with Verifiable Rewards (RLVR) framework to address these challenges\nusing only 100 annotated samples. Our approach ensures dataset diversity, a\nbalanced precision-recall reward mechanism to reduce hallucinations and improve\nfield coverage, and innovative sampling strategies to enhance reasoning\ncapabilities. Fine-tuning Qwen2.5-VL-7B with our RLVR method, we achieve\nstate-of-the-art performance on medical VIE tasks, significantly improving F1,\nprecision, and recall. While our models excel on tasks similar to medical\ndatasets, performance drops on dissimilar tasks, highlighting the need for\ndomain-specific optimization. Case studies further demonstrate the value of\nreasoning during training and inference for VIE.",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/633e570be7d5ce7bfe037a53/-7W-jpcvZwQ046FQHgVdY.qt"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.13363.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "633e570be7d5ce7bfe037a53",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/633e570be7d5ce7bfe037a53/zV8ULv4Mu7YIGZ8D3JtmK.jpeg",
      "fullname": "Zhaocheng Liu",
      "name": "zhaocheng",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 4
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2506.14758",
      "authors": [
        {
          "_id": "685239610164cd1316710553",
          "user": {
            "_id": "649e6761f9134a06ed1e0cea",
            "avatarUrl": "/avatars/00b5dcb744c54a4aa18fe08efd70d6ff.svg",
            "isPro": false,
            "fullname": "Daixuan Cheng",
            "user": "daixuancheng",
            "type": "user"
          },
          "name": "Daixuan Cheng",
          "status": "extracted_confirmed",
          "statusLastChangedAt": "2025-06-18T06:57:21.864Z",
          "hidden": false
        },
        {
          "_id": "685239610164cd1316710554",
          "name": "Shaohan Huang",
          "hidden": false
        },
        {
          "_id": "685239610164cd1316710555",
          "name": "Xuekai Zhu",
          "hidden": false
        },
        {
          "_id": "685239610164cd1316710556",
          "name": "Bo Dai",
          "hidden": false
        },
        {
          "_id": "685239610164cd1316710557",
          "name": "Wayne Xin Zhao",
          "hidden": false
        },
        {
          "_id": "685239610164cd1316710558",
          "name": "Zhenliang Zhang",
          "hidden": false
        },
        {
          "_id": "685239610164cd1316710559",
          "name": "Furu Wei",
          "hidden": false
        }
      ],
      "mediaUrls": [
        "https://cdn-uploads.huggingface.co/production/uploads/649e6761f9134a06ed1e0cea/UekvaawzSgcb5I120mngD.png",
        "https://cdn-uploads.huggingface.co/production/uploads/649e6761f9134a06ed1e0cea/UbAwRMdcT31OV6ORPZG52.png"
      ],
      "publishedAt": "2025-06-17T17:54:03.000Z",
      "submittedOnDailyAt": "2025-06-18T02:33:04.259Z",
      "title": "Explication : Le motif de la recherche : Vision à partir de l'entropie",
      "submittedOnDailyBy": {
        "_id": "649e6761f9134a06ed1e0cea",
        "avatarUrl": "/avatars/00b5dcb744c54a4aa18fe08efd70d6ff.svg",
        "isPro": false,
        "fullname": "Daixuan Cheng",
        "user": "daixuancheng",
        "type": "user"
      },
      "summary": "L'équilibre entre exploration et exploitation est le cœur du développement d'apprentissage par renforcement (RL). Avec l'avancement de la théorie logique des modèles de langage (LM) récentes, de nombreux méthodes ont concentré leurs efforts sur l'exploitation, souvent rencontrent des problèmes de performance. Dans cet article, nous réévaluons l'entropie comme signal d'exploration dans le RL et nous explorons la relation entre la théorie logique d'exploration dans les LM. A travers une analyse expérimentale, nous avons découvert une forte corrélation positive entre les zones d'haute entropie et trois types d'actions logiques d'exploration : (1) les points de token pour décider ou combiner logiquement, (2) des actions réflexives comme ajustements de vérification et de correction, et (3) des actions rares que les LM exploraient avec une fréquence réduite. Cela offre une solution simple au RL avec un minimum de changements : ajouter un terme d'entropie à une fonction de priorité. Le méthode traditionnelle de maximisation de l'entropie incite l'exploration en augmentant l'incertitude, ce qui peut conduire à l'exploration de longs ou profonds liens logiques. En particulier, notre méthode atteint des gains significatifs lorsqu'elle est évaluée avec la métrique Pass@K, qui évalue le limite de la capacité logique des LM, et peut dépasser les limites d'exploration logique des LM, même pour de grands valeurs de K.",
      "upvotes": 16,
      "discussionId": "685239610164cd131671055a",
      "ai_summary": "Introducing an entropy-based term to the advantage function in reinforcement learning enhances exploratory reasoning in language models, leading to improved performance on complex reasoning tasks.",
      "ai_keywords": [
        "reinforcement learning",
        "entropy",
        "exploratory reasoning",
        "pivotal tokens",
        "reflective actions",
        "rare behaviors",
        "advantage function",
        "Pass@K"
      ]
    },
    "publishedAt": "2025-06-17T13:54:03.000Z",
    "title": "Reasoning with Exploration: An Entropy Perspective",
    "summary": "Balancing exploration and exploitation is a central goal in reinforcement\nlearning (RL). Despite recent advances in enhancing language model (LM)\nreasoning, most methods lean toward exploitation, and increasingly encounter\nperformance plateaus. In this work, we revisit entropy -- a signal of\nexploration in RL -- and examine its relationship to exploratory reasoning in\nLMs. Through empirical analysis, we uncover strong positive correlations\nbetween high-entropy regions and three types of exploratory reasoning actions:\n(1) pivotal tokens that determine or connect logical steps, (2) reflective\nactions such as self-verification and correction, and (3) rare behaviors\nunder-explored by the base LMs. Motivated by this, we introduce a minimal\nmodification to standard RL with only one line of code: augmenting the\nadvantage function with an entropy-based term. Unlike traditional\nmaximum-entropy methods which encourage exploration by promoting uncertainty,\nwe encourage exploration by promoting longer and deeper reasoning chains.\nNotably, our method achieves significant gains on the Pass@K metric -- an\nupper-bound estimator of LM reasoning capabilities -- even when evaluated with\nextremely large K values, pushing the boundaries of LM reasoning.",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/649e6761f9134a06ed1e0cea/UekvaawzSgcb5I120mngD.png",
      "https://cdn-uploads.huggingface.co/production/uploads/649e6761f9134a06ed1e0cea/UbAwRMdcT31OV6ORPZG52.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.14758.png",
    "numComments": 3,
    "submittedBy": {
      "_id": "649e6761f9134a06ed1e0cea",
      "avatarUrl": "/avatars/00b5dcb744c54a4aa18fe08efd70d6ff.svg",
      "fullname": "Daixuan Cheng",
      "name": "daixuancheng",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 9
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2506.14245",
      "authors": [
        {
          "_id": "68521c2a0164cd131671046b",
          "name": "Xumeng Wen",
          "hidden": false
        },
        {
          "_id": "68521c2a0164cd131671046c",
          "name": "Zihan Liu",
          "hidden": false
        },
        {
          "_id": "68521c2a0164cd131671046d",
          "user": {
            "_id": "64a7a2bad001860e0c34f7f2",
            "avatarUrl": "/avatars/2433104071e4ae1c3e2d755d81d7964b.svg",
            "isPro": false,
            "fullname": "Shun Zheng",
            "user": "shun-zheng",
            "type": "user"
          },
          "name": "Shun Zheng",
          "status": "extracted_confirmed",
          "statusLastChangedAt": "2025-06-18T02:37:06.379Z",
          "hidden": false
        },
        {
          "_id": "68521c2a0164cd131671046e",
          "name": "Zhijian Xu",
          "hidden": false
        },
        {
          "_id": "68521c2a0164cd131671046f",
          "name": "Shengyu Ye",
          "hidden": false
        },
        {
          "_id": "68521c2a0164cd1316710470",
          "name": "Zhirong Wu",
          "hidden": false
        },
        {
          "_id": "68521c2a0164cd1316710471",
          "name": "Xiao Liang",
          "hidden": false
        },
        {
          "_id": "68521c2a0164cd1316710472",
          "name": "Yang Wang",
          "hidden": false
        },
        {
          "_id": "68521c2a0164cd1316710473",
          "name": "Junjie Li",
          "hidden": false
        },
        {
          "_id": "68521c2a0164cd1316710474",
          "name": "Ziming Miao",
          "hidden": false
        },
        {
          "_id": "68521c2a0164cd1316710475",
          "name": "Jiang Bian",
          "hidden": false
        },
        {
          "_id": "68521c2a0164cd1316710476",
          "name": "Mao Yang",
          "hidden": false
        }
      ],
      "mediaUrls": [
        "https://cdn-uploads.huggingface.co/production/uploads/64a7a2bad001860e0c34f7f2/zpklFaaRznQyEa0t9Ji70.png"
      ],
      "publishedAt": "2025-06-17T07:06:56.000Z",
      "submittedOnDailyAt": "2025-06-18T01:24:22.712Z",
      "title": "L'apprentissage par renforcement avec des récompenses expérimentales apprises de manière vérifiable est recommandé pour l'inférence précise dans les modèles de Langue Naturelle Basiques (LLM).",
      "submittedOnDailyBy": {
        "_id": "64a7a2bad001860e0c34f7f2",
        "avatarUrl": "/avatars/2433104071e4ae1c3e2d755d81d7964b.svg",
        "isPro": false,
        "fullname": "Shun Zheng",
        "user": "shun-zheng",
        "type": "user"
      },
      "summary": "RLVR (Reinforcement Learning con Rewards Vérifiables) a apparu comme un nouveau paradigme attendu pour le développement de la capacité logique des Grands Modèles de Langue (LLMs). Cependant, il existe des contradictions importantes dans son efficacité : les modèles entraînés avec RLVR tombent sous le modèle de base d'exploration de décisions selon la mesure Pass@K, et il a été supposé que RLVR ne perd pas la diversité logique lorsqu'il réévalue les chemins logiques existants. Dans cette étude, nous avons identifié une cause spécifique pour résoudre cette contradiction : la mesure Pass@K n'évalue pas correctement la logique. Cela se doit au fait que la logique peut être inaccurate ou incomplète, ce qui peut conduire à des contextes imprécis ou à des CoTs (Contenu de Tâches). En réponse à cela, nous avons introduit une mesure d'évaluation plus précise, CoT-Pass@K, qui évalue à la fois les chemins logiques et les réponses finales. Nous avons démontré que RLVR offre une nouvelle base théorique, différente du RL traditionnel, qui encourage la cohérence logique. Nos résultats expérimentaux montrent que RLVR, en utilisant CoT-Pass@K, encourage la généralisation logique correcte pour tous les valeurs de K. De plus, en analysant la dynamique d'apprentissage, nous avons observé que cette amélioration apparaît aux premiers stades du processus d'apprentissage et se généralise de manière douce. Notre recherche a clarifié le rôle de RLVR et confirmé des méthodes d'évaluation fiables et la véritable capacité de cette approche.",
      "upvotes": 12,
      "discussionId": "68521c2a0164cd1316710477",
      "ai_summary": "RLVR advances machine reasoning by incentivizing correct and logical thought chains, addressing limitations identified by a more precise evaluation metric, $CoT$-$Pass@K$.",
      "ai_keywords": [
        "Reinforcement Learning with Verifiable Rewards",
        "LLMS",
        "Pass@K",
        "chains of thought",
        "CoT-Pass@K",
        "logical integrity",
        "machine reasoning",
        "training dynamics"
      ]
    },
    "publishedAt": "2025-06-17T03:06:56.000Z",
    "title": "Reinforcement Learning with Verifiable Rewards Implicitly Incentivizes\n  Correct Reasoning in Base LLMs",
    "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a\npromising paradigm for advancing the reasoning capabilities of Large Language\nModels (LLMs). However, a critical paradox clouds its efficacy: RLVR-tuned\nmodels often underperform their base models on the Pass@K metric for\nsolution-finding, leading to the hypothesis that RLVR merely re-weights\nexisting reasoning paths at the cost of reasoning diversity. In this work, we\nresolve this contradiction by identifying the source of the problem: the\nPass@K metric itself is a flawed measure of reasoning, as it credits correct\nfinal answers that probably arise from inaccurate or incomplete chains of\nthought (CoTs). To address this, we introduce a more precise evaluation metric,\nCoT-Pass@K, which mandates that both the reasoning path and the final\nanswer be correct. We provide a new theoretical foundation that formalizes how\nRLVR, unlike traditional RL, is uniquely structured to incentivize logical\nintegrity. Our empirical results are supportive: using CoT-Pass@K, we\nobserve that RLVR can incentivize the generalization of correct reasoning for\nall values of K. Furthermore, by analyzing the training dynamics, we find\nthat this enhanced reasoning capability emerges early in the training process\nand smoothly generalizes. Our work provides a clear perspective on the role of\nRLVR, offers a more reliable method for its evaluation, and confirms its\npotential to genuinely advance machine reasoning.",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/64a7a2bad001860e0c34f7f2/zpklFaaRznQyEa0t9Ji70.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.14245.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64a7a2bad001860e0c34f7f2",
      "avatarUrl": "/avatars/2433104071e4ae1c3e2d755d81d7964b.svg",
      "fullname": "Shun Zheng",
      "name": "shun-zheng",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 3
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2506.12860",
      "authors": [
        {
          "_id": "685226a40164cd13167104bd",
          "name": "Wanlong Liu",
          "hidden": false
        },
        {
          "_id": "685226a40164cd13167104be",
          "name": "Junxiao Xu",
          "hidden": false
        },
        {
          "_id": "685226a40164cd13167104bf",
          "name": "Fei Yu",
          "hidden": false
        },
        {
          "_id": "685226a40164cd13167104c0",
          "name": "Yukang Lin",
          "hidden": false
        },
        {
          "_id": "685226a40164cd13167104c1",
          "name": "Ke Ji",
          "hidden": false
        },
        {
          "_id": "685226a40164cd13167104c2",
          "name": "Wenyu Chen",
          "hidden": false
        },
        {
          "_id": "685226a40164cd13167104c3",
          "name": "Yan Xu",
          "hidden": false
        },
        {
          "_id": "685226a40164cd13167104c4",
          "name": "Yasheng Wang",
          "hidden": false
        },
        {
          "_id": "685226a40164cd13167104c5",
          "name": "Lifeng Shang",
          "hidden": false
        },
        {
          "_id": "685226a40164cd13167104c6",
          "name": "Benyou Wang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-06-15T14:21:28.000Z",
      "submittedOnDailyAt": "2025-06-18T02:06:38.533Z",
      "title": "QFFT, raisons sans problèmes de lubrification sans lubrification des raisons d'ajustement micro adaptatif",
      "submittedOnDailyBy": {
        "_id": "64eb333e6878d90b031fa5c5",
        "avatarUrl": "/avatars/a0d875b49d1c56be88f34854647306da.svg",
        "isPro": false,
        "fullname": "Wanlong Liu",
        "user": "lwl-uestc",
        "type": "user"
      },
      "summary": "L'évolution des modèles de long CoT (Chain of Thought) a amélioré les performances dans des tâches complexes, mais a généré des étapes avec des raisons longues en raison de pensées excessives, surtout pour des questions simples. Dans cet article, on examine le modèle de raisonnement des modèles de long et court CoT, et on constate que le modèle de court CoT fournit des raisons efficaces et concises, tandis que le modèle de long CoT montre une excellence dans des scénarios complexes où le modèle de court CoT est difficile à appliquer. L'objectif est que le modèle utilise de manière efficace les deux modèles, et on propose une micro-correction sans problèmes (QFFT) pour y parvenir. La QFFT élimine la question de l'input lors de l'entraînement et se concentre sur l'apprentissage des réponses de long CoT. Cette approche permet au modèle d'adapter de manière efficace aux deux modèles : prioritise le modèle de court CoT et active le modèle de long CoT lorsque cela est nécessaire. Dans des expériences avec des ensembles de données mathématiques, la QFFT a réduit significativement la longueur moyenne des réponses (plus de 50%) et a maintenu un rendement standard. De plus, la QFFT a démontré un excellent rendement dans des scénarios avec une grande quantité de bruit, hors du domaine et avec des ressources limitées, comparé au SFT.",
      "upvotes": 12,
      "discussionId": "685226a40164cd13167104c7",
      "githubRepo": "https://github.com/LWL-cpu/Question-Free-Fine-Tuning",
      "ai_summary": "Question-Free Fine-Tuning (QFFT) improves efficiency and adaptability in cognitive models by leveraging both short and long chain-of-thought patterns, reducing response length while maintaining performance across various scenarios.",
      "ai_keywords": [
        "Long Chain-of-Thought",
        "Short Chain-of-Thought",
        "Question-Free Fine-Tuning",
        "fine-tuning",
        "Supervised Fine-Tuning"
      ]
    },
    "publishedAt": "2025-06-15T10:21:28.000Z",
    "title": "QFFT, Question-Free Fine-Tuning for Adaptive Reasoning",
    "summary": "Recent advancements in Long Chain-of-Thought (CoT) reasoning models have\nimproved performance on complex tasks, but they suffer from overthinking, which\ngenerates redundant reasoning steps, especially for simple questions. This\npaper revisits the reasoning patterns of Long and Short CoT models, observing\nthat the Short CoT patterns offer concise reasoning efficiently, while the Long\nCoT patterns excel in challenging scenarios where the Short CoT patterns\nstruggle. To enable models to leverage both patterns, we propose Question-Free\nFine-Tuning (QFFT), a fine-tuning approach that removes the input question\nduring training and learns exclusively from Long CoT responses. This approach\nenables the model to adaptively employ both reasoning patterns: it prioritizes\nthe Short CoT patterns and activates the Long CoT patterns only when necessary.\nExperiments on various mathematical datasets demonstrate that QFFT reduces\naverage response length by more than 50\\%, while achieving performance\ncomparable to Supervised Fine-Tuning (SFT). Additionally, QFFT exhibits\nsuperior performance compared to SFT in noisy, out-of-domain, and low-resource\nscenarios.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.12860.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64eb333e6878d90b031fa5c5",
      "avatarUrl": "/avatars/a0d875b49d1c56be88f34854647306da.svg",
      "fullname": "Wanlong Liu",
      "name": "lwl-uestc",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 3
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2506.12278",
      "authors": [
        {
          "_id": "685234030164cd1316710502",
          "name": "Zheyuan Yang",
          "hidden": false
        },
        {
          "_id": "685234030164cd1316710503",
          "name": "Zexi Kuang",
          "hidden": false
        },
        {
          "_id": "685234030164cd1316710504",
          "name": "Xue Xia",
          "hidden": false
        },
        {
          "_id": "685234030164cd1316710505",
          "name": "Yilun Zhao",
          "hidden": false
        }
      ],
      "publishedAt": "2025-06-13T23:56:17.000Z",
      "submittedOnDailyAt": "2025-06-18T02:08:35.444Z",
      "title": "LLMs peuvent générer des cas de test de haute qualité pour des problèmes algorithmiques ?  \nÉvaluation de Cas de Test : Système d'évaluation systématique de Folterkaboration et d'Exporacion.",
      "submittedOnDailyBy": {
        "_id": "62f662bcc58915315c4eccea",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62f662bcc58915315c4eccea/zOAQLONfMP88zr70sxHK-.jpeg",
        "isPro": true,
        "fullname": "Yilun Zhao",
        "user": "yilunzhao",
        "type": "user"
      },
      "summary": "TestCase-Eval est un nouveau référentiel pour l'évaluation systématique de la génération de cas de tests dans les modèles de langage de machine (LLM). Il inclut 500 problèmes d'algorithmes et 100 000 solutions humaines disponibles sur le plateforme Codeforces. Il se concentre sur deux tâches principales : 1) Vérification équitable, évaluant si l'ensemble de cas de tests généré par l'LLM détecte une large gamme d'échantillons d'entrée et couvre un large éventail de scénarios de défaillances potentiels. 2) Vérification équitable, évaluant la capacité de l'LLM à générer des entrées de test conçues pour détecter des implémentations de code anormales. Dans TestCase-Eval, l'évaluation est détaillée des forces et des limites dans la génération efficace de cas de tests de 19 modèles LLM d'origine ou propriété ouverte.",
      "upvotes": 12,
      "discussionId": "685234030164cd1316710506",
      "githubRepo": "https://github.com/FlowRays/TestCase-Eval",
      "ai_summary": "TestCase-Eval is a benchmark for evaluating LLMs in generating comprehensive and targeted test cases for algorithm problems.",
      "ai_keywords": [
        "test-case generation",
        "Fault Coverage",
        "Fault Exposure",
        "LLMs",
        "algorithm problems",
        "human-crafted solutions",
        "Codeforces",
        "test sets",
        "failure modes",
        "incorrect code implementation"
      ]
    },
    "publishedAt": "2025-06-13T19:56:17.000Z",
    "title": "Can LLMs Generate High-Quality Test Cases for Algorithm Problems?\n  TestCase-Eval: A Systematic Evaluation of Fault Coverage and Exposure",
    "summary": "We introduce TestCase-Eval, a new benchmark for systematic evaluation of LLMs\nin test-case generation. TestCase-Eval includes 500 algorithm problems and\n100,000 human-crafted solutions from the Codeforces platform. It focuses on two\npivotal tasks: (1) Fault Coverage, which measures how well LLM-generated test\nsets probe diverse input scenarios and cover a wide range of potential failure\nmodes. (2) Fault Exposure, which evaluates whether LLMs can craft a tailored\ntest input that reveals a specific incorrect code implementation. We provide a\ncomprehensive assessment of 19 state-of-the-art open-source and proprietary\nLLMs on TestCase-Eval, offering insights into their strengths and limitations\nin generating effective test cases for algorithm problems.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.12278.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "62f662bcc58915315c4eccea",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62f662bcc58915315c4eccea/zOAQLONfMP88zr70sxHK-.jpeg",
      "fullname": "Yilun Zhao",
      "name": "yilunzhao",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 13
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2506.14606",
      "authors": [
        {
          "_id": "68521f240164cd131671047a",
          "name": "Ahmed Heakl",
          "hidden": false
        },
        {
          "_id": "68521f240164cd131671047b",
          "name": "Sarim Hashmi",
          "hidden": false
        },
        {
          "_id": "68521f240164cd131671047c",
          "name": "Chaimaa Abi",
          "hidden": false
        },
        {
          "_id": "68521f240164cd131671047d",
          "name": "Celine Lee",
          "hidden": false
        },
        {
          "_id": "68521f240164cd131671047e",
          "name": "Abdulrahman Mahmoud",
          "hidden": false
        }
      ],
      "mediaUrls": [
        "https://cdn-uploads.huggingface.co/production/uploads/656864e12d73834278a8dea7/G_EGzMfb1C6fX_o-yLFbl.png",
        "https://cdn-uploads.huggingface.co/production/uploads/656864e12d73834278a8dea7/G2UhoU9mbZ8tQ0VzmKLV5.png"
      ],
      "publishedAt": "2025-06-17T15:06:54.000Z",
      "submittedOnDailyAt": "2025-06-18T00:38:14.336Z",
      "title": "Claro, voici la traduction en français :\n\n**Prédiction Certaine : Modélisation des langages dans le changement de CISC vers RISC**\n**Test de fonctionnement avec étiquetages dans le Transpiler**\n\nJ'espère que cela répond à vos attentes en termes de précision et de professionnalisme.",
      "submittedOnDailyBy": {
        "_id": "656864e12d73834278a8dea7",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/656864e12d73834278a8dea7/sfAWS2eyPtFHb_2GZIypp.jpeg",
        "isPro": true,
        "fullname": "Ahmed Heakl",
        "user": "ahmedheakl",
        "type": "user"
      },
      "summary": "Le système d'écosystème de logiciel est en train de se développer rapidement, et il y a un intérêt croissant pour traduire les codes de bas niveau de programmation entre différentes architectures d'ensemble de instructions (ISA) de manière rapide et flexible, avec l'objectif d'améliorer la portabilité et la stabilité à long terme du code existant. Une des classes particulièrement difficiles pour cette tâche est la traduction entre architectures complexes de logiciel (CISC) et architectures réduites de logiciel (RISC). Cela se complique en raison des différences fondamentales en termes de complexité des commandes, du modèle de mémoire et des paradigmes d'exécution. Dans cette étude, nous résolvons ce problème en intégrant la capacité de traduction de modèles de langage naturel grand (LLM) et la précision de la structure de tests de logiciel, proposant une chaîne de traduction axée sur l'ISA appelée GG (Guaranteed Guess). Notre méthode utilise un LLM pour générer des traductions candidates d'un ISA à un autre, et évalue la fiabilité de ces traductions quantitativement en les intégrant dans un cadre de tests de logiciel. Notre approche GG a été évaluée à travers deux ensembles de données différents, atteignant une haute couverture de tests unitaires (>98%) et une précision fonctionnelle/sémantique de 99% dans le programme HumanEval, et 49% dans le programme BringupBench. De plus, comparé au framework Rosetta 2 de l'Apple Silicon, notre approche améliore l'efficacité énergétique de 1,47 fois, le rendement d'exécution de 1,73 fois et l'utilisation de la mémoire de 2,41 fois, démontrant les avantages de la GG dans la traduction réelle de CISC vers RISC. Nous publions du code, des données, des modèles et des référentiels, avec l'objectif de mettre en place une base commune pour l'étude de la traduction de code au niveau de l'ISA.",
      "upvotes": 10,
      "discussionId": "68521f240164cd131671047f",
      "projectPage": "https://ahmedheakl.github.io/Guaranteed-Guess/",
      "githubRepo": "https://github.com/ahmedheakl/Guaranteed-Guess",
      "ai_summary": "A novel ISA-centric transpilation pipeline using LLMs and software testing achieves high correctness and efficiency in translating between complex and reduced hardware architectures.",
      "ai_keywords": [
        "pre-trained large language models",
        "software testing constructs",
        "ISA-centric transpilation",
        "complex-instruction set computing (CISC)",
        "reduced-instruction set computing (RISC)",
        "instruction set architecture (ISA)",
        "HumanEval",
        "BringupBench",
        "Rosetta 2 framework",
        "functional/semantic correctness",
        "real-world CISC-to-RISC translation",
        "memory models",
        "execution paradigms",
        "transpilation",
        "hardware ecosystem",
        "low-level programs",
        "code portability",
        "longevity"
      ]
    },
    "publishedAt": "2025-06-17T11:06:54.000Z",
    "title": "Guaranteed Guess: A Language Modeling Approach for CISC-to-RISC\n  Transpilation with Testing Guarantees",
    "summary": "The hardware ecosystem is rapidly evolving, with increasing interest in\ntranslating low-level programs across different instruction set architectures\n(ISAs) in a quick, flexible, and correct way to enhance the portability and\nlongevity of existing code. A particularly challenging class of this\ntranspilation problem is translating between complex- (CISC) and reduced-\n(RISC) hardware architectures, due to fundamental differences in instruction\ncomplexity, memory models, and execution paradigms. In this work, we introduce\nGG (Guaranteed Guess), an ISA-centric transpilation pipeline that combines the\ntranslation power of pre-trained large language models (LLMs) with the rigor of\nestablished software testing constructs. Our method generates candidate\ntranslations using an LLM from one ISA to another, and embeds such translations\nwithin a software-testing framework to build quantifiable confidence in the\ntranslation. We evaluate our GG approach over two diverse datasets, enforce\nhigh code coverage (>98%) across unit tests, and achieve functional/semantic\ncorrectness of 99% on HumanEval programs and 49% on BringupBench programs,\nrespectively. Further, we compare our approach to the state-of-the-art Rosetta\n2 framework on Apple Silicon, showcasing 1.73x faster runtime performance,\n1.47x better energy efficiency, and 2.41x better memory usage for our\ntranspiled code, demonstrating the effectiveness of GG for real-world\nCISC-to-RISC translation tasks. We will open-source our codes, data, models,\nand benchmarks to establish a common foundation for ISA-level code translation\nresearch.",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/656864e12d73834278a8dea7/G_EGzMfb1C6fX_o-yLFbl.png",
      "https://cdn-uploads.huggingface.co/production/uploads/656864e12d73834278a8dea7/G2UhoU9mbZ8tQ0VzmKLV5.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.14606.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "656864e12d73834278a8dea7",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/656864e12d73834278a8dea7/sfAWS2eyPtFHb_2GZIypp.jpeg",
      "fullname": "Ahmed Heakl",
      "name": "ahmedheakl",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 41
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2506.14603",
      "authors": [
        {
          "_id": "68521f8a0164cd1316710481",
          "name": "Amirmojtaba Sabour",
          "hidden": false
        },
        {
          "_id": "68521f8a0164cd1316710482",
          "name": "Sanja Fidler",
          "hidden": false
        },
        {
          "_id": "68521f8a0164cd1316710483",
          "name": "Karsten Kreis",
          "hidden": false
        }
      ],
      "mediaUrls": [
        "https://cdn-uploads.huggingface.co/production/uploads/656015f28138827138c70858/_yuUKzjzngNZzaUJCVwjR.jpeg",
        "https://cdn-uploads.huggingface.co/production/uploads/656015f28138827138c70858/2FmUhOtaDCtAzFkNEx6Di.jpeg",
        "https://cdn-uploads.huggingface.co/production/uploads/656015f28138827138c70858/MC_ZLBqT81dOpANroMLrm.jpeg",
        "https://cdn-uploads.huggingface.co/production/uploads/656015f28138827138c70858/degPI6Z5IEf4v_y2_UL9V.jpeg"
      ],
      "publishedAt": "2025-06-17T15:06:07.000Z",
      "submittedOnDailyAt": "2025-06-18T00:42:20.168Z",
      "title": "**Titre :** Alignez votre flux : Extension et expérience du flux continu en temps réel\n\n**Mots-clés principales :**\n- Alignez votre flux\n- Flux continu en temps réel\n- Extension\n- Expérience\n\n**Traduction :**\n- \"Alignez votre flux\" signifie la technique d'ajustement et d'optimisation du flux de travail pour augmenter l'efficacité des tâches.\n- \"Flux continu en temps réel\" est un outil qui permet une gestion efficace de l'exécution des tâches en considérant à la fois le temps et le flux.\n- \"Extension\" se réfère à l'amplification ou au statut amplifié de cet outil.\n- \"Expérience\" se réfère aux expériences ou aux résultats obtenus par les utilisateurs en utilisant cet outil.",
      "submittedOnDailyBy": {
        "_id": "656015f28138827138c70858",
        "avatarUrl": "/avatars/b8471ae4d80f078c7c928fc3d8f49126.svg",
        "isPro": false,
        "fullname": "Amirmojtaba Sabour",
        "user": "amsabour",
        "type": "user"
      },
      "summary": "La différenciation et les modèles basés sur le flux sont les méthodes les plus avancées de modélisation générative qui apparaissent, mais nécessitent plusieurs étapes de sampling. Les modèles de convergence peuvent intégrer ces modèles comme générateurs efficaces en un seul pas, mais lorsque le nombre de pas augmente, l'efficacité diminue. Cela a été démontré tant analytiquement que expérimentalement. Les cartes de flux peuvent relier deux niveaux de bruit et sont efficaces pour tout nombre de pas. Dans cet article, nous présentons une nouvelle méthodologie d'entraînement qui étend les objectifs de convergence et de carte de flux pour inclure deux nouveaux objectifs de temps continu. De plus, nous démontrons que le design avec auto-supervision améliore le rendement et permet un accroissement de l'efficacité avec un minimum de perte de diversité de données, même dans la régulation relative. Nous avons construit un puissant modèle de carte de flux \"Ajustable\" sur un benchmark d'images difficiles, et nous avons atteint les meilleurs rendements avec peu de pas sur ImageNet 64x64 et 512x512. Enfin, nous présentons un modèle de flux de texte à image qui dépasse tous les émetteurs entraînés avec peu de pas jusqu'à présent.",
      "upvotes": 8,
      "discussionId": "68521f8a0164cd1316710484",
      "projectPage": "https://research.nvidia.com/labs/toronto-ai/AlignYourFlow/",
      "ai_summary": "Flow maps, introduced with new continuous-time objectives and training techniques, achieve state-of-the-art performance in few-step image and text-to-image generation.",
      "ai_keywords": [
        "diffusion models",
        "flow-based models",
        "consistency models",
        "flow maps",
        "noise levels",
        "autoguidance",
        "adversarial finetuning",
        "Align Your Flow",
        "ImageNet",
        "text-to-image synthesis"
      ]
    },
    "publishedAt": "2025-06-17T11:06:07.000Z",
    "title": "Align Your Flow: Scaling Continuous-Time Flow Map Distillation",
    "summary": "Diffusion- and flow-based models have emerged as state-of-the-art generative\nmodeling approaches, but they require many sampling steps. Consistency models\ncan distill these models into efficient one-step generators; however, unlike\nflow- and diffusion-based methods, their performance inevitably degrades when\nincreasing the number of steps, which we show both analytically and\nempirically. Flow maps generalize these approaches by connecting any two noise\nlevels in a single step and remain effective across all step counts. In this\npaper, we introduce two new continuous-time objectives for training flow maps,\nalong with additional novel training techniques, generalizing existing\nconsistency and flow matching objectives. We further demonstrate that\nautoguidance can improve performance, using a low-quality model for guidance\nduring distillation, and an additional boost can be achieved by adversarial\nfinetuning, with minimal loss in sample diversity. We extensively validate our\nflow map models, called Align Your Flow, on challenging image generation\nbenchmarks and achieve state-of-the-art few-step generation performance on both\nImageNet 64x64 and 512x512, using small and efficient neural networks. Finally,\nwe show text-to-image flow map models that outperform all existing\nnon-adversarially trained few-step samplers in text-conditioned synthesis.",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/656015f28138827138c70858/_yuUKzjzngNZzaUJCVwjR.jpeg",
      "https://cdn-uploads.huggingface.co/production/uploads/656015f28138827138c70858/2FmUhOtaDCtAzFkNEx6Di.jpeg",
      "https://cdn-uploads.huggingface.co/production/uploads/656015f28138827138c70858/MC_ZLBqT81dOpANroMLrm.jpeg",
      "https://cdn-uploads.huggingface.co/production/uploads/656015f28138827138c70858/degPI6Z5IEf4v_y2_UL9V.jpeg"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.14603.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "656015f28138827138c70858",
      "avatarUrl": "/avatars/b8471ae4d80f078c7c928fc3d8f49126.svg",
      "fullname": "Amirmojtaba Sabour",
      "name": "amsabour",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2506.13977",
      "authors": [
        {
          "_id": "68524ff90164cd13167105aa",
          "name": "Shiting Huang",
          "hidden": false
        },
        {
          "_id": "68524ff90164cd13167105ab",
          "name": "Zhen Fang",
          "hidden": false
        },
        {
          "_id": "68524ff90164cd13167105ac",
          "name": "Zehui Chen",
          "hidden": false
        },
        {
          "_id": "68524ff90164cd13167105ad",
          "name": "Siyu Yuan",
          "hidden": false
        },
        {
          "_id": "68524ff90164cd13167105ae",
          "name": "Junjie Ye",
          "hidden": false
        },
        {
          "_id": "68524ff90164cd13167105af",
          "name": "Yu Zeng",
          "hidden": false
        },
        {
          "_id": "68524ff90164cd13167105b0",
          "name": "Lin Chen",
          "hidden": false
        },
        {
          "_id": "68524ff90164cd13167105b1",
          "name": "Qi Mao",
          "hidden": false
        },
        {
          "_id": "68524ff90164cd13167105b2",
          "name": "Feng Zhao",
          "hidden": false
        }
      ],
      "publishedAt": "2025-06-11T17:59:18.000Z",
      "submittedOnDailyAt": "2025-06-18T04:10:42.444Z",
      "title": "CRITICTOOL: Erreurs de Appel de l'Outil dans l'Évaluation de la Capacité d'Autocritique des Modèles de Langue de Grande Taille",
      "submittedOnDailyBy": {
        "_id": "64b0a5037a475fba70a7260d",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64b0a5037a475fba70a7260d/MauBbb6raMA23yrR1Zq21.jpeg",
        "isPro": false,
        "fullname": "Zhen Fang",
        "user": "CostaliyA",
        "type": "user"
      },
      "summary": "Les langages de programmation grands (LLMs) ont la capacité de utiliser des outils externes pour réaliser diverses tâches. Cependant, lorsque ces tâches deviennent plus complexes et à long terme, l'utilisation de ces outils peut entraîner des erreurs non souhaitées. Par conséquent, des méthodes efficaces ont été développées pour gérer ces erreurs, en particulier pour les reconnaître, diagnostiquer et résoudre, ce qui a été une direction de recherche importante dans le développement de ces outils. Dans cet article, nous examinons les différentes catégories d'erreurs qui peuvent apparaître dans un cadre d'évaluation de ces outils. En se basant sur cette analyse, nous présentons CRITICTOOL, un cadre d'évaluation détaillé et spécifique pour l'apprentissage de ces outils. À partir d'une stratégie évolutive pour la construction de nouveaux ensembles de données, CRITICTOOL dispose d'outils avec des erreurs diverses et sa complexité peut varier. Des expériences larges ont été réalisées dans CRITICTOOL, démontrant la généralisation et l'efficacité de la stratégie de benchmark. De plus, nous effectuons un analyse approfondie de la capacité de réflexion des outils de chaque LLM, offrant une nouvelle perspective dans le domaine de l'apprentissage de ces outils par les LLMs. Le code est disponible sur https://github.com/Shellorley0513/CriticTool.",
      "upvotes": 7,
      "discussionId": "68524ff90164cd13167105b3",
      "githubRepo": "https://github.com/Shellorley0513/CriticTool",
      "ai_summary": "A comprehensive benchmark, CRITICTOOL, evaluates and enhances the robustness of large language models in handling errors during tool usage.",
      "ai_keywords": [
        "large language models",
        "tool learning",
        "function-calling process",
        "error identification",
        "error diagnosis",
        "error recovery",
        "evolutionary strategy",
        "dataset construction",
        "tool reflection ability",
        "critique evaluation benchmark"
      ]
    },
    "publishedAt": "2025-06-11T13:59:18.000Z",
    "title": "CRITICTOOL: Evaluating Self-Critique Capabilities of Large Language\n  Models in Tool-Calling Error Scenarios",
    "summary": "The ability of large language models (LLMs) to utilize external tools has\nenabled them to tackle an increasingly diverse range of tasks. However, as the\ntasks become more complex and long-horizon, the intricate tool utilization\nprocess may trigger various unexpected errors. Therefore, how to effectively\nhandle such errors, including identifying, diagnosing, and recovering from\nthem, has emerged as a key research direction for advancing tool learning. In\nthis work, we first extensively analyze the types of errors encountered during\nthe function-calling process on several competitive tool evaluation benchmarks.\nBased on it, we introduce CRITICTOOL, a comprehensive critique evaluation\nbenchmark specialized for tool learning. Building upon a novel evolutionary\nstrategy for dataset construction, CRITICTOOL holds diverse tool-use errors\nwith varying complexities, which better reflects real-world scenarios. We\nconduct extensive experiments on CRITICTOOL, and validate the generalization\nand effectiveness of our constructed benchmark strategy. We also provide an\nin-depth analysis of the tool reflection ability on various LLMs, offering a\nnew perspective on the field of tool learning in LLMs. The code is available at\nhttps://github.com/Shellorley0513/CriticTool{https://github.com/Shellorley0513/CriticTool}.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.13977.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64b0a5037a475fba70a7260d",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64b0a5037a475fba70a7260d/MauBbb6raMA23yrR1Zq21.jpeg",
      "fullname": "Zhen Fang",
      "name": "CostaliyA",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2506.13651",
      "authors": [
        {
          "_id": "6850cf555e07650ecce88fe2",
          "name": "Kaiyuan Chen",
          "hidden": false
        },
        {
          "_id": "6850cf555e07650ecce88fe3",
          "name": "Yixin Ren",
          "hidden": false
        },
        {
          "_id": "6850cf555e07650ecce88fe4",
          "name": "Yang Liu",
          "hidden": false
        },
        {
          "_id": "6850cf555e07650ecce88fe5",
          "name": "Xiaobo Hu",
          "hidden": false
        },
        {
          "_id": "6850cf555e07650ecce88fe6",
          "name": "Haotong Tian",
          "hidden": false
        },
        {
          "_id": "6850cf555e07650ecce88fe7",
          "name": "Tianbao Xie",
          "hidden": false
        },
        {
          "_id": "6850cf555e07650ecce88fe8",
          "name": "Fangfu Liu",
          "hidden": false
        },
        {
          "_id": "6850cf555e07650ecce88fe9",
          "name": "Haoye Zhang",
          "hidden": false
        },
        {
          "_id": "6850cf555e07650ecce88fea",
          "name": "Hongzhang Liu",
          "hidden": false
        },
        {
          "_id": "6850cf555e07650ecce88feb",
          "name": "Yuan Gong",
          "hidden": false
        },
        {
          "_id": "6850cf555e07650ecce88fec",
          "name": "Chen Sun",
          "hidden": false
        },
        {
          "_id": "6850cf555e07650ecce88fed",
          "name": "Han Hou",
          "hidden": false
        },
        {
          "_id": "6850cf555e07650ecce88fee",
          "name": "Hui Yang",
          "hidden": false
        },
        {
          "_id": "6850cf555e07650ecce88fef",
          "name": "James Pan",
          "hidden": false
        },
        {
          "_id": "6850cf555e07650ecce88ff0",
          "name": "Jianan Lou",
          "hidden": false
        },
        {
          "_id": "6850cf555e07650ecce88ff1",
          "name": "Jiayi Mao",
          "hidden": false
        },
        {
          "_id": "6850cf555e07650ecce88ff2",
          "name": "Jizheng Liu",
          "hidden": false
        },
        {
          "_id": "6850cf555e07650ecce88ff3",
          "name": "Jinpeng Li",
          "hidden": false
        },
        {
          "_id": "6850cf555e07650ecce88ff4",
          "name": "Kangyi Liu",
          "hidden": false
        },
        {
          "_id": "6850cf555e07650ecce88ff5",
          "name": "Kenkun Liu",
          "hidden": false
        },
        {
          "_id": "6850cf555e07650ecce88ff6",
          "name": "Rui Wang",
          "hidden": false
        },
        {
          "_id": "6850cf555e07650ecce88ff7",
          "name": "Run Li",
          "hidden": false
        },
        {
          "_id": "6850cf555e07650ecce88ff8",
          "name": "Tong Niu",
          "hidden": false
        },
        {
          "_id": "6850cf555e07650ecce88ff9",
          "name": "Wenlong Zhang",
          "hidden": false
        },
        {
          "_id": "6850cf555e07650ecce88ffa",
          "name": "Wenqi Yan",
          "hidden": false
        },
        {
          "_id": "6850cf555e07650ecce88ffb",
          "name": "Xuanzheng Wang",
          "hidden": false
        },
        {
          "_id": "6850cf555e07650ecce88ffc",
          "name": "Yuchen Zhang",
          "hidden": false
        },
        {
          "_id": "6850cf555e07650ecce88ffd",
          "name": "Yi-Hsin Hung",
          "hidden": false
        },
        {
          "_id": "6850cf555e07650ecce88ffe",
          "name": "Yuan Jiang",
          "hidden": false
        },
        {
          "_id": "6850cf555e07650ecce88fff",
          "name": "Zexuan Liu",
          "hidden": false
        },
        {
          "_id": "6850cf555e07650ecce89000",
          "name": "Zihan Yin",
          "hidden": false
        },
        {
          "_id": "6850cf555e07650ecce89001",
          "name": "Zijian Ma",
          "hidden": false
        },
        {
          "_id": "6850cf555e07650ecce89002",
          "name": "Zhiwen Mo",
          "hidden": false
        }
      ],
      "publishedAt": "2025-06-16T16:16:14.000Z",
      "submittedOnDailyAt": "2025-06-18T04:38:47.336Z",
      "title": "xbench : Amélioration de la Productivité des Agents à l'aide d'Évaluations Réalistes et Professionnelles",
      "submittedOnDailyBy": {
        "_id": "6505a02f9310ce8c400edc63",
        "avatarUrl": "/avatars/bbf781594fc8c812316711aa8e2797aa.svg",
        "isPro": false,
        "fullname": "Fangfu Liu",
        "user": "Liuff23",
        "type": "user"
      },
      "summary": "Dinamim présente un système d'évaluation \"xbench\" conçu pour évaluer les agents intelligents de l'IA en fonction de leur capacité et de leur productivité dans le monde réel. Actuellement, l'évaluation se concentre principalement sur des compétences techniques indépendantes, ce qui ne reflète pas précisément le rendement économique que les agents offrent dans des environnements professionnels. Pour résoudre ce problème, \"xbench\" se concentre sur des tâches d'évaluation établies par des experts du secteur, ciblant des zones d'importance pour l'entreprise. Notre cadre de travail relie des métriques de productivité et génère des prédictions de conformité techno-commerciale (CTM), promouvant ainsi l'évaluation du développement de la capacité du produit au fil du temps. Dans sa mise en œuvre initiale, nous proposons deux référentiels : \"Contratation\" et \"Marketing\". Dans \"Contratation\", nous collectons 50 tâches d'un scénario de hyper-promotion réel pour évaluer la capacité de cartographie commerciale, de recherche d'information et de sélection de compétences des agents. Dans \"Marketing\", nous évaluons la capacité des agents de chatbot de 836 candidats influenciers pour créer des publicités qui répondent aux besoins des clients des annonceurs. Nous offrons les résultats initiaux d'évaluation des agents de haut niveau modernes et établissons les normes pour cette spécialisation. Pour plus d'informations, visitez https://xbench.org, où vous trouverez des ensembles d'évaluation mis à jour et des évaluations.",
      "upvotes": 5,
      "discussionId": "6850cf555e07650ecce89003",
      "projectPage": "https://xbench.org/",
      "githubRepo": "https://github.com/xbench-ai/xbench-evals"
    },
    "publishedAt": "2025-06-16T12:16:14.000Z",
    "title": "xbench: Tracking Agents Productivity Scaling with Profession-Aligned\n  Real-World Evaluations",
    "summary": "We introduce xbench, a dynamic, profession-aligned evaluation suite designed\nto bridge the gap between AI agent capabilities and real-world productivity.\nWhile existing benchmarks often focus on isolated technical skills, they may\nnot accurately reflect the economic value agents deliver in professional\nsettings. To address this, xbench targets commercially significant domains with\nevaluation tasks defined by industry professionals. Our framework creates\nmetrics that strongly correlate with productivity value, enables prediction of\nTechnology-Market Fit (TMF), and facilitates tracking of product capabilities\nover time. As our initial implementations, we present two benchmarks:\nRecruitment and Marketing. For Recruitment, we collect 50 tasks from real-world\nheadhunting business scenarios to evaluate agents' abilities in company\nmapping, information retrieval, and talent sourcing. For Marketing, we assess\nagents' ability to match influencers with advertiser needs, evaluating their\nperformance across 50 advertiser requirements using a curated pool of 836\ncandidate influencers. We present initial evaluation results for leading\ncontemporary agents, establishing a baseline for these professional domains.\nOur continuously updated evalsets and evaluations are available at\nhttps://xbench.org.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.13651.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6505a02f9310ce8c400edc63",
      "avatarUrl": "/avatars/bbf781594fc8c812316711aa8e2797aa.svg",
      "fullname": "Fangfu Liu",
      "name": "Liuff23",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 8
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2506.14002",
      "authors": [
        {
          "_id": "685210eb0164cd131671043e",
          "name": "Siyu Chen",
          "hidden": false
        },
        {
          "_id": "685210eb0164cd131671043f",
          "name": "Heejune Sheen",
          "hidden": false
        },
        {
          "_id": "685210eb0164cd1316710440",
          "name": "Xuyuan Xiong",
          "hidden": false
        },
        {
          "_id": "685210eb0164cd1316710441",
          "name": "Tianhao Wang",
          "hidden": false
        },
        {
          "_id": "685210eb0164cd1316710442",
          "name": "Zhuoran Yang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-06-16T20:58:05.000Z",
      "submittedOnDailyAt": "2025-06-18T00:09:08.222Z",
      "title": "Utilisant l'Autoencodeur Espars pour Contrôler la Multimodalité d'un LLM : Un Méthode Probant pour la Réconstruction de Caractéristiques",
      "submittedOnDailyBy": {
        "_id": "683229900411a9d65cd410c0",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/VqwvpUYF8CQAKPHMNfLyw.png",
        "isPro": false,
        "fullname": "Siyu Chen",
        "user": "Siyuc",
        "type": "user"
      },
      "summary": "Nous étudions le problème de la récupération de caractéristiques fondées théoriquement en utilisant un autoencodeur sparso (SAE). L'algorithme actuel de formation de l'SAE manque de garanties mathématiques strictes et présente des limitations pratiques telles que la sensibilité et l'instabilité des hyperparamètres. Pour aborder ces problèmes, nous proposons pour la première fois un nouveau cadre statistique pour le problème de la récupération de caractéristiques. Ce cadre modélise les caractéristiques de dames comme une mélange espars de concepts potentiels, incorporant la spécificité des nouvelles caractéristiques. En se basant sur ce cadre, nous proposons un nouvel algorithme de formation de l'SAE basé sur la technique de \"ajustement de biais\". Cette technique vise à ajuster de manière adaptative les paramètres de biais de la réseau neuronal pour garantir la sparsité de l'activation. Théoriquement, nous avons démontré que cet algorithme peut récupérer correctement toutes les caractéristiques significatives dans le cas où les données d'entraînement sont échantillonnées selon notre modèle statistique proposé. De plus, nous avons développé une version expérimentale de cet algorithme appelée \"group bias adjustment\" (GBA) et nous avons démontré que celle-ci présente de hauts rendements comparés aux méthodes de référence dans un modèle de LLM avec environ 150 millions de paramètres. Ce travail représente une étape fondamentale pour comprendre la formation de l'SAE, fournit le premier algorithme de SAE avec des garanties théoriques de récupération, et contribue à l'interprétabilité structurale et à la création de systèmes AI transparents et fiables.",
      "upvotes": 4,
      "discussionId": "685210ec0164cd1316710443",
      "ai_summary": "A new statistical framework and training algorithm, Group Bias Adaptation, enhance Sparse Autoencoders for recovering monosemantic features in Large Language Models, offering theoretical guarantees and superior performance.",
      "ai_keywords": [
        "Sparse Autoencoders",
        "feature recovery",
        "statistical framework",
        "feature identifiability",
        "polysemantic features",
        "monosemantic concepts",
        "bias adaptation",
        "Group Bias Adaptation",
        "Large Language Models",
        "theoretical recovery guarantees",
        "mechnistic interpretability"
      ]
    },
    "publishedAt": "2025-06-16T16:58:05.000Z",
    "title": "Taming Polysemanticity in LLMs: Provable Feature Recovery via Sparse\n  Autoencoders",
    "summary": "We study the challenge of achieving theoretically grounded feature recovery\nusing Sparse Autoencoders (SAEs) for the interpretation of Large Language\nModels. Existing SAE training algorithms often lack rigorous mathematical\nguarantees and suffer from practical limitations such as hyperparameter\nsensitivity and instability. To address these issues, we first propose a novel\nstatistical framework for the feature recovery problem, which includes a new\nnotion of feature identifiability by modeling polysemantic features as sparse\nmixtures of underlying monosemantic concepts. Building on this framework, we\nintroduce a new SAE training algorithm based on ``bias adaptation'', a\ntechnique that adaptively adjusts neural network bias parameters to ensure\nappropriate activation sparsity. We theoretically prove that this\nalgorithm correctly recovers all monosemantic features when input data is\nsampled from our proposed statistical model. Furthermore, we develop an\nimproved empirical variant, Group Bias Adaptation (GBA), and\ndemonstrate its superior performance against benchmark methods when\napplied to LLMs with up to 1.5 billion parameters. This work represents a\nfoundational step in demystifying SAE training by providing the first SAE\nalgorithm with theoretical recovery guarantees, thereby advancing the\ndevelopment of more transparent and trustworthy AI systems through enhanced\nmechanistic interpretability.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.14002.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "683229900411a9d65cd410c0",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/VqwvpUYF8CQAKPHMNfLyw.png",
      "fullname": "Siyu Chen",
      "name": "Siyuc",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2506.10100",
      "authors": [
        {
          "_id": "68522b190164cd13167104d9",
          "name": "Yantai Yang",
          "hidden": false
        },
        {
          "_id": "68522b190164cd13167104da",
          "name": "Yuhao Wang",
          "hidden": false
        },
        {
          "_id": "68522b190164cd13167104db",
          "name": "Zichen Wen",
          "hidden": false
        },
        {
          "_id": "68522b190164cd13167104dc",
          "name": "Luo Zhongwei",
          "hidden": false
        },
        {
          "_id": "68522b190164cd13167104dd",
          "name": "Chang Zou",
          "hidden": false
        },
        {
          "_id": "68522b190164cd13167104de",
          "name": "Zhipeng Zhang",
          "hidden": false
        },
        {
          "_id": "68522b190164cd13167104df",
          "name": "Chuan Wen",
          "hidden": false
        },
        {
          "_id": "68522b190164cd13167104e0",
          "name": "Linfeng Zhang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-06-11T18:34:57.000Z",
      "submittedOnDailyAt": "2025-06-18T01:30:42.708Z",
      "title": "EfficientVLA : Modèle de Langage Visuolinguistique d'Action pour l'Accélération et la Compression Sans Entraînement",
      "submittedOnDailyBy": {
        "_id": "653b8c3e97a4d71d950e2f20",
        "avatarUrl": "/avatars/b68880022e14556d0be58c69615db3be.svg",
        "isPro": false,
        "fullname": "Zichen Wen",
        "user": "zichenwen",
        "type": "user"
      },
      "summary": "Vision-Language-Action (VLA) modèle, en particulier l'architecture basée sur les arbres de branchement, présente une variabilité de possibilités qui montre une intelligence structurée, bien que limitée par des consommations élevées en calcul et mémoire due à la redondance inhérente et pendant l'inférence. Les essais actuels pour améliorer son efficacité dans des applications séparées tentent de relever ces limites, mais chaque solution individuelle ne peut pas aborder de manière globale les différents blocages de calcul et mémoire tout au long du flux VLA, ce qui limite sa fonctionnalité pratique. Nous présentons EfficientVLA, un cadre d'accélération de l'inférence non entraîné et structuré, qui utilise une série de réductions de redondance multidimensionnelles pour éliminer ces blocages de manière systématique, renforçant ainsi sa fonctionnalité pratique. EfficientVLA intègre de manière simplifiée trois objectifs : éliminer des couches fonctionnellement inutiles dans le module de langage (guidé par l'analyse de redondance entre couches), optimiser le passage de traitement visuel avec des stratégies adaptées aux tâches (équilibrant la tâche-clé et l'information-cover avec un ensemble simple et varié de tokens visuels), et réduire les calculs temporels de redondance au sein de la tête d'action basée sur les arbres de branchement (stockant et réutilisant stratégiquement des caractéristiques intermédiaires des clés). En appliquant ces techniques à un modèle VLA standard comme CogACT, on a observé un accroissement de la vitesse d'inférence de 1,93 fois, une réduction des FLOPs de 28,9%, et une perte de précision de 0,6% sur le benchmark SIMPLER.",
      "upvotes": 4,
      "discussionId": "68522b190164cd13167104e1",
      "ai_summary": "EfficientVLA accelerates Vision-Language-Action models by pruning language layers, optimizing visual token selection, and caching intermediate features in the diffusion-based action head.",
      "ai_keywords": [
        "diffusion-based architectures",
        "inference acceleration framework",
        "pruning",
        "inter-layer redundancies",
        "visual tokens",
        "task-aware strategy",
        "iterative diffusion-based action head",
        "caching",
        "FLOPs",
        "SIMPLER benchmark"
      ]
    },
    "publishedAt": "2025-06-11T14:34:57.000Z",
    "title": "EfficientVLA: Training-Free Acceleration and Compression for\n  Vision-Language-Action Models",
    "summary": "Vision-Language-Action (VLA) models, particularly diffusion-based\narchitectures, demonstrate transformative potential for embodied intelligence\nbut are severely hampered by high computational and memory demands stemming\nfrom extensive inherent and inference-time redundancies. While existing\nacceleration efforts often target isolated inefficiencies, such piecemeal\nsolutions typically fail to holistically address the varied computational and\nmemory bottlenecks across the entire VLA pipeline, thereby limiting practical\ndeployability. We introduce EfficientVLA, a structured and training-free\ninference acceleration framework that systematically eliminates these barriers\nby cohesively exploiting multifaceted redundancies. EfficientVLA\nsynergistically integrates three targeted strategies: (1) pruning of\nfunctionally inconsequential layers from the language module, guided by an\nanalysis of inter-layer redundancies; (2) optimizing the visual processing\npathway through a task-aware strategy that selects a compact, diverse set of\nvisual tokens, balancing task-criticality with informational coverage; and (3)\nalleviating temporal computational redundancy within the iterative\ndiffusion-based action head by strategically caching and reusing key\nintermediate features. We apply our method to a standard VLA model CogACT,\nyielding a 1.93X inference speedup and reduces FLOPs to 28.9%, with only a 0.6%\nsuccess rate drop in the SIMPLER benchmark.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.10100.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "653b8c3e97a4d71d950e2f20",
      "avatarUrl": "/avatars/b68880022e14556d0be58c69615db3be.svg",
      "fullname": "Zichen Wen",
      "name": "zichenwen",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 3
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2506.10038",
      "authors": [
        {
          "_id": "68523b4a0164cd131671055d",
          "name": "Giannis Daras",
          "hidden": false
        },
        {
          "_id": "68523b4a0164cd131671055e",
          "user": {
            "_id": "67d204c05422de5644126f0b",
            "avatarUrl": "/avatars/8a9ac73d93785f48e63184d612b9fff1.svg",
            "isPro": false,
            "fullname": "Adrian Rodriguez Munoz",
            "user": "adrianrm",
            "type": "user"
          },
          "name": "Adrian Rodriguez-Munoz",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-06-18T04:06:37.569Z",
          "hidden": false
        },
        {
          "_id": "68523b4a0164cd131671055f",
          "name": "Adam Klivans",
          "hidden": false
        },
        {
          "_id": "68523b4a0164cd1316710560",
          "name": "Antonio Torralba",
          "hidden": false
        },
        {
          "_id": "68523b4a0164cd1316710561",
          "name": "Constantinos Daskalakis",
          "hidden": false
        }
      ],
      "publishedAt": "2025-06-10T22:37:39.000Z",
      "submittedOnDailyAt": "2025-06-18T02:40:58.837Z",
      "title": "Ambient Diffusion Omni : Méthode pour entraîner de bons modèles à travers des données médiocres",
      "submittedOnDailyBy": {
        "_id": "5f45f44b79c1ba4c353d1035",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/5f45f44b79c1ba4c353d1035/6piqagYr7RNCy6XwJGWCG.jpeg",
        "isPro": false,
        "fullname": "Giannis Daras",
        "user": "giannisdaras",
        "type": "user"
      },
      "summary": "Nous présentons des méthodes pour améliorer la qualité des modèles de distribution en utilisant des images de faible qualité, synthétiques et hors distribution. En général, les modèles de distribution sont entraînés sur un ensemble de données hautement filtrée de haute qualité obtenue de la web ou d'autres sources. Nous montrons qu'il est très bénéfique d'éliminer les images de faible qualité. Nous présentons un cadre simple et fondamental appelé Ambient Diffusion Omni, qui permet d'entraîner des modèles de distribution capables d'extraire des signaux de toutes les images pendant l'entraînement. Notre cadre exploite deux caractéristiques des images naturelles : l'atténuation spectrale de la puissance et la localisation. Tout d'abord, nous montrons que les modèles de distribution peuvent être entraînés avec succès en utilisant des images dégradées de manière synthétique par bruit gaussien, compression JPEG et bruit d'opération. Ensuite, nous utilisons le cadre pour atteindre les meilleurs résultats de FID sur ImageNet et améliorer significativement la qualité et la diversité des images générées à partir du texte. L'idée clé est que le bruit ajoute un biais initial entre la distribution désirée de haute qualité et la distribution de bruit observée. Nous analysons la transition entre le biais des données entraînées et les données limitées sans biais, et nous fournissons une démonstration théorique rigoureuse de notre approche.",
      "upvotes": 3,
      "discussionId": "68523b4a0164cd1316710562",
      "projectPage": "https://giannisdaras.github.io/publication/ambient_omni",
      "githubRepo": "https://github.com/giannisdaras/ambient-omni",
      "ai_summary": "Ambient Diffusion Omni framework leverages low-quality images to enhance diffusion models by utilizing properties of natural images and shows improvements in ImageNet FID and text-to-image quality.",
      "ai_keywords": [
        "diffusion models",
        "synthetic images",
        "out-of-distribution images",
        "Ambient Diffusion Omni",
        "spectral power law decay",
        "locality",
        "Gaussian blur",
        "JPEG compression",
        "motion blur",
        "ImageNet FID",
        "text-to-image generative modeling",
        "noise dampening",
        "biased data",
        "limited unbiased data"
      ]
    },
    "publishedAt": "2025-06-10T18:37:39.000Z",
    "title": "Ambient Diffusion Omni: Training Good Models with Bad Data",
    "summary": "We show how to use low-quality, synthetic, and out-of-distribution images to\nimprove the quality of a diffusion model. Typically, diffusion models are\ntrained on curated datasets that emerge from highly filtered data pools from\nthe Web and other sources. We show that there is immense value in the\nlower-quality images that are often discarded. We present Ambient Diffusion\nOmni, a simple, principled framework to train diffusion models that can extract\nsignal from all available images during training. Our framework exploits two\nproperties of natural images -- spectral power law decay and locality. We first\nvalidate our framework by successfully training diffusion models with images\nsynthetically corrupted by Gaussian blur, JPEG compression, and motion blur. We\nthen use our framework to achieve state-of-the-art ImageNet FID, and we show\nsignificant improvements in both image quality and diversity for text-to-image\ngenerative modeling. The core insight is that noise dampens the initial skew\nbetween the desired high-quality distribution and the mixed distribution we\nactually observe. We provide rigorous theoretical justification for our\napproach by analyzing the trade-off between learning from biased data versus\nlimited unbiased data across diffusion times.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.10038.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "5f45f44b79c1ba4c353d1035",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/5f45f44b79c1ba4c353d1035/6piqagYr7RNCy6XwJGWCG.jpeg",
      "fullname": "Giannis Daras",
      "name": "giannisdaras",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2506.05336",
      "authors": [
        {
          "_id": "68425a7ab63271ff41652734",
          "name": "Ghazi Shazan Ahmad",
          "hidden": false
        },
        {
          "_id": "68425a7ab63271ff41652735",
          "user": {
            "_id": "656864e12d73834278a8dea7",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/656864e12d73834278a8dea7/sfAWS2eyPtFHb_2GZIypp.jpeg",
            "isPro": true,
            "fullname": "Ahmed Heakl",
            "user": "ahmedheakl",
            "type": "user"
          },
          "name": "Ahmed Heakl",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-07T05:48:53.401Z",
          "hidden": false
        },
        {
          "_id": "68425a7ab63271ff41652736",
          "name": "Hanan Gani",
          "hidden": false
        },
        {
          "_id": "68425a7ab63271ff41652737",
          "name": "Abdelrahman Shaker",
          "hidden": false
        },
        {
          "_id": "68425a7ab63271ff41652738",
          "name": "Zhiqiang Shen",
          "hidden": false
        },
        {
          "_id": "68425a7ab63271ff41652739",
          "name": "Ranjay Krishna",
          "hidden": false
        },
        {
          "_id": "68425a7ab63271ff4165273a",
          "name": "Fahad Shahbaz Khan",
          "hidden": false
        },
        {
          "_id": "68425a7ab63271ff4165273b",
          "name": "Salman Khan",
          "hidden": false
        }
      ],
      "mediaUrls": [
        "https://cdn-uploads.huggingface.co/production/uploads/656864e12d73834278a8dea7/7r2x8C0UYFCrqk95QpBGr.mp4"
      ],
      "publishedAt": "2025-06-05T17:59:29.000Z",
      "submittedOnDailyAt": "2025-06-18T01:30:20.599Z",
      "title": "VideoMolmo: Spectre-Temps-Groundring et Main de Pilotage",
      "submittedOnDailyBy": {
        "_id": "656864e12d73834278a8dea7",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/656864e12d73834278a8dea7/sfAWS2eyPtFHb_2GZIypp.jpeg",
        "isPro": true,
        "fullname": "Ahmed Heakl",
        "user": "ahmedheakl",
        "type": "user"
      },
      "summary": "Le lieu et le temps sont essentiels pour des interactions précises dans divers domaines. Dans la recherche biologique, l'application est large en raison de l'automatisation. L'approche actuelle basée sur des images dépasse la traçabilité, mais sa capacité logique complexe ne permet pas d'entendre le contexte et de la généraliser. On présente VideoMolmo, un modèle qui aborde une large gamme de modèles. Ce modèle est conçu pour fournir des orientations précises dans le temps et l'espace en fonction du contexte. Basé sur l'architecture Molmo, VideoMolmo introduit des modules temporels et utilise des fonctions d'attention pour garantir la cohérence temporelle en faisant de chaque frame une condition sur les frames précédentes. De plus, on introduit un nouveau processus de fusion temporelle et on utilise SAM2 pour réaliser la propagation bidirectionnelle de points, améliorant considérablement la continuité des séquences vidéo. Ce processus de double résolution, en utilisant des modèles de LLM pour générer d'abord les coordonnées d'orientation précises et en demandant un module de fusion temporelle séquentiel pour simplifier l'compréhension du contexte et améliorer la compréhension, a permis de préparer un ensemble de données détaillé qui inclut 72k paires de vidéo-capture. Pour évaluer la généralisation de VideoMolmo, on introduit VPoS-Bench, un benchmark difficile à distribuer, et on présente 5 scénarios réels : sélection de cellules, calcul de vision, automatisation, interaction vidéo-GUI et robotique. De plus, on effectue des évaluations dans des tâches comme la Segmentation d'Objets en Vidéo par Référence (Refer-VOS) et la VOS par raison. Comparés aux modèles existants, VideoMolmo améliore considérablement la précision des orientations dans le temps et l'espace et sa capacité logique. Le code et le modèle sont disponibles sur https://github.com/mbzuai-oryx/VideoMolmo.",
      "upvotes": 3,
      "discussionId": "68425a80b63271ff416528f2",
      "projectPage": "https://mbzuai-oryx.github.io/VideoMolmo/",
      "githubRepo": "https://github.com/mbzuai-oryx/VideoMolmo",
      "ai_summary": "VideoMolmo, a multimodal model incorporating a temporal attention mechanism and SAM2 for mask fusion, enhances spatio-temporal pointing accuracy and reasoning capabilities in diverse real-world scenarios.",
      "ai_keywords": [
        "Molmo",
        "attention mechanism",
        "temporal mask fusion",
        "SAM2",
        "bidirectional point propagation",
        "VideoMolmo",
        "LLM",
        "sequential mask-fusion module",
        "VPoS-Bench",
        "Referring Video Object Segmentation",
        "Reasoning VOS"
      ]
    },
    "publishedAt": "2025-06-05T13:59:29.000Z",
    "title": "VideoMolmo: Spatio-Temporal Grounding Meets Pointing",
    "summary": "Spatio-temporal localization is vital for precise interactions across diverse\ndomains, from biological research to autonomous navigation and interactive\ninterfaces. Current video-based approaches, while proficient in tracking, lack\nthe sophisticated reasoning capabilities of large language models, limiting\ntheir contextual understanding and generalization. We introduce VideoMolmo, a\nlarge multimodal model tailored for fine-grained spatio-temporal pointing\nconditioned on textual descriptions. Building upon the Molmo architecture,\nVideoMolmo incorporates a temporal module utilizing an attention mechanism to\ncondition each frame on preceding frames, ensuring temporal consistency.\nAdditionally, our novel temporal mask fusion pipeline employs SAM2 for\nbidirectional point propagation, significantly enhancing coherence across video\nsequences. This two-step decomposition, i.e., first using the LLM to generate\nprecise pointing coordinates, then relying on a sequential mask-fusion module\nto produce coherent segmentation, not only simplifies the task for the language\nmodel but also enhances interpretability. Due to the lack of suitable datasets,\nwe curate a comprehensive dataset comprising 72k video-caption pairs annotated\nwith 100k object points. To evaluate the generalization of VideoMolmo, we\nintroduce VPoS-Bench, a challenging out-of-distribution benchmark spanning five\nreal-world scenarios: Cell Tracking, Egocentric Vision, Autonomous Driving,\nVideo-GUI Interaction, and Robotics. We also evaluate our model on Referring\nVideo Object Segmentation (Refer-VOS) and Reasoning VOS tasks. In comparison to\nexisting models, VideoMolmo substantially improves spatio-temporal pointing\naccuracy and reasoning capability. Our code and models are publicly available\nat https://github.com/mbzuai-oryx/VideoMolmo.",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/656864e12d73834278a8dea7/7r2x8C0UYFCrqk95QpBGr.mp4"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.05336.png",
    "numComments": 5,
    "submittedBy": {
      "_id": "656864e12d73834278a8dea7",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/656864e12d73834278a8dea7/sfAWS2eyPtFHb_2GZIypp.jpeg",
      "fullname": "Ahmed Heakl",
      "name": "ahmedheakl",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 41
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2506.14755",
      "authors": [
        {
          "_id": "685225250164cd13167104aa",
          "name": "Zhengxiang Cheng",
          "hidden": false
        },
        {
          "_id": "685225250164cd13167104ab",
          "name": "Dongping Chen",
          "hidden": false
        },
        {
          "_id": "685225250164cd13167104ac",
          "name": "Mingyang Fu",
          "hidden": false
        },
        {
          "_id": "685225250164cd13167104ad",
          "name": "Tianyi Zhou",
          "hidden": false
        }
      ],
      "publishedAt": "2025-06-17T17:50:16.000Z",
      "submittedOnDailyAt": "2025-06-18T01:05:46.554Z",
      "title": "Optimisation de la longueur de compression dans les modèles de calcul grands",
      "submittedOnDailyBy": {
        "_id": "647f5af5b0e96764589f3b2a",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/VJ4cDyjp5M3V5WmI5gPIU.jpeg",
        "isPro": false,
        "fullname": "Tianyi Zhou",
        "user": "zhoutianyi",
        "type": "user"
      },
      "summary": "Les modèles logiques (LRMs) ont connu un succès notable, mais ils font face à des problèmes comme la génération de logiques inutiles ou trop détaillées. Ce problème a été identifié sous le nom de \"pensée inutile\". Les modèles profitent de réconfirmer des travaux qui ont obtenu des réponses correctes. Pour aborder cette inadéquation spécifique, deux nouveaux principes plus détaillés sont proposés, qui transcenden l'efficacité générale et l'efficience, nommés Brevity (Concision) et Sufficiency (Suficience). Brevity argumente l'élimination de l'excès, tandis que Sufficiency assure la préservation des étapes logiques importantes. Selon ces principes, il est présenté LC-R1, un méthode d'apprentissage basée sur l'optimisation de politique de Groupe Relatif (GRPO). LC-R1 utilise une nouvelle combinaison de Reward de Longueur pour garantir la concision et un Reward de Compression spécialement conçu pour éliminer les parties inutiles du processus de pensée. Des expériences larges dans des cadres de tests logiques montrent que LC-R1 réduit significativement la longueur (environ 50%) bien que sa précision diminue légèrement (environ 2%), atteignant un point favorable au bord de la compression extrême (Poor Man's). De plus, LC-R1 évalue sa robustesse et fournit des indications précieuses pour le développement de modèles de calcul efficaces. Le code est disponible sur https://github.com/zxiangx/LC-R1.",
      "upvotes": 1,
      "discussionId": "685225250164cd13167104ae",
      "githubRepo": "https://github.com/zxiangx/LC-R1",
      "ai_summary": "LC-R1, a post-training method guided by Brevity and Sufficiency principles, reduces unnecessary reasoning in Large Reasoning Models with minimal accuracy loss.",
      "ai_keywords": [
        "Large Reasoning Models",
        "LRM",
        "post-training method",
        "Group Relative Policy Optimization",
        "GRPO",
        "Length Reward",
        "Compress Reward",
        "reasoning benchmarks",
        "Pareto frontier"
      ]
    },
    "publishedAt": "2025-06-17T13:50:16.000Z",
    "title": "Optimizing Length Compression in Large Reasoning Models",
    "summary": "Large Reasoning Models (LRMs) have achieved remarkable success, yet they\noften suffer from producing unnecessary and verbose reasoning chains. We\nidentify a core aspect of this issue as \"invalid thinking\" -- models tend to\nrepeatedly double-check their work after having derived the correct answer. To\naddress this specific inefficiency, we move beyond the general principles of\nEfficacy and Efficiency to propose two new, fine-grained principles: Brevity,\nwhich advocates for eliminating redundancy, and Sufficiency, which ensures\ncritical reasoning steps are preserved. Guided by these principles, we\nintroduce LC-R1, a post-training method based on Group Relative Policy\nOptimization (GRPO). LC-R1 employs a novel combination of a Length Reward for\noverall conciseness and a Compress Reward that is specifically designed to\nremove the invalid portion of the thinking process. Extensive experiments on\nmultiple reasoning benchmarks demonstrate that LC-R1 achieves a significant\nreduction in sequence length (~50%) with only a marginal (~2%) drop in\naccuracy, achieving a favorable trade-off point on the Pareto frontier that\nprioritizes high compression. Our analysis further validates the robustness of\nLC-R1 and provides valuable insights for developing more powerful yet\ncomputationally efficient LRMs. Our code is released at\nhttps://github.com/zxiangx/LC-R1.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.14755.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "647f5af5b0e96764589f3b2a",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/VJ4cDyjp5M3V5WmI5gPIU.jpeg",
      "fullname": "Tianyi Zhou",
      "name": "zhoutianyi",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 14
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2506.14731",
      "authors": [
        {
          "_id": "685236ac0164cd1316710512",
          "name": "Ring Team",
          "hidden": false
        },
        {
          "_id": "685236ac0164cd1316710513",
          "name": "Bin Hu",
          "hidden": false
        },
        {
          "_id": "685236ac0164cd1316710514",
          "name": "Cai Chen",
          "hidden": false
        },
        {
          "_id": "685236ac0164cd1316710515",
          "name": "Deng Zhao",
          "hidden": false
        },
        {
          "_id": "685236ac0164cd1316710516",
          "name": "Ding Liu",
          "hidden": false
        },
        {
          "_id": "685236ac0164cd1316710517",
          "name": "Dingnan Jin",
          "hidden": false
        },
        {
          "_id": "685236ac0164cd1316710518",
          "name": "Feng Zhu",
          "hidden": false
        },
        {
          "_id": "685236ac0164cd1316710519",
          "name": "Hao Dai",
          "hidden": false
        },
        {
          "_id": "685236ac0164cd131671051a",
          "name": "Hongzhi Luan",
          "hidden": false
        },
        {
          "_id": "685236ac0164cd131671051b",
          "name": "Jia Guo",
          "hidden": false
        },
        {
          "_id": "685236ac0164cd131671051c",
          "name": "Jiaming Liu",
          "hidden": false
        },
        {
          "_id": "685236ac0164cd131671051d",
          "name": "Jiewei Wu",
          "hidden": false
        },
        {
          "_id": "685236ac0164cd131671051e",
          "name": "Jun Mei",
          "hidden": false
        },
        {
          "_id": "685236ac0164cd131671051f",
          "name": "Jun Zhou",
          "hidden": false
        },
        {
          "_id": "685236ac0164cd1316710520",
          "name": "Junbo Zhao",
          "hidden": false
        },
        {
          "_id": "685236ac0164cd1316710521",
          "name": "Junwu Xiong",
          "hidden": false
        },
        {
          "_id": "685236ac0164cd1316710522",
          "name": "Kaihong Zhang",
          "hidden": false
        },
        {
          "_id": "685236ac0164cd1316710523",
          "name": "Kuan Xu",
          "hidden": false
        },
        {
          "_id": "685236ac0164cd1316710524",
          "name": "Lei Liang",
          "hidden": false
        },
        {
          "_id": "685236ac0164cd1316710525",
          "name": "Liang Jiang",
          "hidden": false
        },
        {
          "_id": "685236ac0164cd1316710526",
          "name": "Liangcheng Fu",
          "hidden": false
        },
        {
          "_id": "685236ac0164cd1316710527",
          "name": "Longfei Zheng",
          "hidden": false
        },
        {
          "_id": "685236ac0164cd1316710528",
          "name": "Qiang Gao",
          "hidden": false
        },
        {
          "_id": "685236ac0164cd1316710529",
          "name": "Qing Cui",
          "hidden": false
        },
        {
          "_id": "685236ac0164cd131671052a",
          "name": "Quan Wan",
          "hidden": false
        },
        {
          "_id": "685236ac0164cd131671052b",
          "name": "Shaomian Zheng",
          "hidden": false
        },
        {
          "_id": "685236ac0164cd131671052c",
          "name": "Shuaicheng Li",
          "hidden": false
        },
        {
          "_id": "685236ac0164cd131671052d",
          "name": "Tongkai Yang",
          "hidden": false
        },
        {
          "_id": "685236ac0164cd131671052e",
          "name": "Wang Ren",
          "hidden": false
        },
        {
          "_id": "685236ac0164cd131671052f",
          "name": "Xiaodong Yan",
          "hidden": false
        },
        {
          "_id": "685236ac0164cd1316710530",
          "name": "Xiaopei Wan",
          "hidden": false
        },
        {
          "_id": "685236ac0164cd1316710531",
          "name": "Xiaoyun Feng",
          "hidden": false
        },
        {
          "_id": "685236ac0164cd1316710532",
          "name": "Xin Zhao",
          "hidden": false
        },
        {
          "_id": "685236ac0164cd1316710533",
          "name": "Xinxing Yang",
          "hidden": false
        },
        {
          "_id": "685236ac0164cd1316710534",
          "name": "Xinyu Kong",
          "hidden": false
        },
        {
          "_id": "685236ac0164cd1316710535",
          "name": "Xuemin Yang",
          "hidden": false
        },
        {
          "_id": "685236ac0164cd1316710536",
          "name": "Yang Li",
          "hidden": false
        },
        {
          "_id": "685236ac0164cd1316710537",
          "name": "Yingting Wu",
          "hidden": false
        },
        {
          "_id": "685236ac0164cd1316710538",
          "name": "Yongkang Liu",
          "hidden": false
        },
        {
          "_id": "685236ac0164cd1316710539",
          "name": "Zhankai Xu",
          "hidden": false
        },
        {
          "_id": "685236ac0164cd131671053a",
          "name": "Zhenduo Zhang",
          "hidden": false
        },
        {
          "_id": "685236ac0164cd131671053b",
          "name": "Zhenglei Zhou",
          "hidden": false
        },
        {
          "_id": "685236ac0164cd131671053c",
          "name": "Zhenyu Huang",
          "hidden": false
        },
        {
          "_id": "685236ac0164cd131671053d",
          "name": "Zhiqiang Zhang",
          "hidden": false
        },
        {
          "_id": "685236ac0164cd131671053e",
          "name": "Zihao Wang",
          "hidden": false
        },
        {
          "_id": "685236ac0164cd131671053f",
          "name": "Zujie Wen",
          "hidden": false
        }
      ],
      "publishedAt": "2025-06-17T17:12:34.000Z",
      "submittedOnDailyAt": "2025-06-18T03:14:38.830Z",
      "title": "C3PO par le apprentissage par renforcement stabilisé pour appliquer le Réasonnement Échelonnable dans les modèles de langage d'intelligence artificielle (LLM)",
      "submittedOnDailyBy": {
        "_id": "60f1abe7544c2adfd699860c",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
        "isPro": true,
        "fullname": "AK",
        "user": "akhaliq",
        "type": "user"
      },
      "summary": "Introduisez Ring-lite. Ce modèle est une grande modélisation de langage basée sur une mélange d'experts (MoE) optimisée par apprentissage par renforcement (RL), atteignant des capacités logiques efficaces et robustes. Basé sur le modèle Ling-lite, un modèle public a été construit avec 168 milliards de paramètres et 275 millions de paramètres actifs. Cette approche maintient approximativement le tiers des paramètres du modèle actifs, permettant que le rendement des petits modèles de logique leader dans les benchmark difficiles (par exemple, AIME, LiveCodeBench, GPQA-Diamond) soit concurrentiel. Pour y parvenir, une éducation intégrée de pile de test a été introduite pour détecter les problèmes non enregistrés dans l'apprentissage RL de MoE. Tout d'abord, nous avons identifié l'instabilité de l'optimisation lors de l'apprentissage RL et proposé la Politique d'Optimisation de Contexte Contextuel Contrainte (C3PO). Ce méthode utilise un approche de conception publique-privée d'algorithmes et de systèmes pour améliorer la stabilité de l'apprentissage, augmentant l'efficacité des calculs. Ensuite, nous présentons des preuves basées sur des modèles et démontrons que cela améliore la transformation de l'efficacité-rendement dans le processus subséquent de l'apprentissage RL. Enfin, nous avons développé un modèle d'apprentissage en deux étapes pour intégrer différents données et résoudre les conflits de domaine dans les ensembles de données mixtes lors de l'apprentissage. Le modèle, l'ensemble de données et le code sont publiés.",
      "upvotes": 1,
      "discussionId": "685236ad0164cd1316710540",
      "ai_summary": "Ring-lite uses a MoE architecture and reinforcement learning to efficiently match SOTA reasoning models while activating fewer parameters and addressing challenges specific to MoE training.",
      "ai_keywords": [
        "Mixture-of-Experts (MoE)",
        "reinforcement learning (RL)",
        "Ling-lite",
        "AIME",
        "LiveCodeBench",
        "GPQA-Diamond",
        "Constrained Contextual Computation Policy Optimization(C3PO)",
        "entropy loss",
        "two-stage training paradigm"
      ]
    },
    "publishedAt": "2025-06-17T13:12:34.000Z",
    "title": "Ring-lite: Scalable Reasoning via C3PO-Stabilized Reinforcement Learning\n  for LLMs",
    "summary": "We present Ring-lite, a Mixture-of-Experts (MoE)-based large language model\noptimized via reinforcement learning (RL) to achieve efficient and robust\nreasoning capabilities. Built upon the publicly available Ling-lite model, a\n16.8 billion parameter model with 2.75 billion activated parameters, our\napproach matches the performance of state-of-the-art (SOTA) small-scale\nreasoning models on challenging benchmarks (e.g., AIME, LiveCodeBench,\nGPQA-Diamond) while activating only one-third of the parameters required by\ncomparable models. To accomplish this, we introduce a joint training pipeline\nintegrating distillation with RL, revealing undocumented challenges in MoE RL\ntraining. First, we identify optimization instability during RL training, and\nwe propose Constrained Contextual Computation Policy Optimization(C3PO), a\nnovel approach that enhances training stability and improves computational\nthroughput via algorithm-system co-design methodology. Second, we empirically\ndemonstrate that selecting distillation checkpoints based on entropy loss for\nRL training, rather than validation metrics, yields superior\nperformance-efficiency trade-offs in subsequent RL training. Finally, we\ndevelop a two-stage training paradigm to harmonize multi-domain data\nintegration, addressing domain conflicts that arise in training with mixed\ndataset. We will release the model, dataset, and code.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.14731.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": true,
      "isHf": true,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 7130
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2506.14702",
      "authors": [
        {
          "_id": "6852331e0164cd13167104fb",
          "name": "Daniel D'souza",
          "hidden": false
        },
        {
          "_id": "6852331e0164cd13167104fc",
          "name": "Julia Kreutzer",
          "hidden": false
        },
        {
          "_id": "6852331e0164cd13167104fd",
          "name": "Adrien Morisot",
          "hidden": false
        },
        {
          "_id": "6852331e0164cd13167104fe",
          "name": "Ahmet Üstün",
          "hidden": false
        },
        {
          "_id": "6852331e0164cd13167104ff",
          "name": "Sara Hooker",
          "hidden": false
        }
      ],
      "mediaUrls": [
        "https://cdn-uploads.huggingface.co/production/uploads/6658011eaba105a066e37e1b/RBQEHm8CJA9fKsg4bupgs.png"
      ],
      "publishedAt": "2025-06-17T16:40:42.000Z",
      "submittedOnDailyAt": "2025-06-18T02:55:26.808Z",
      "title": "「Boosting Sorri : Cibler des intervalles de temps en temps réel à l'aide de marqueurs pendant l'apprentissage」",
      "submittedOnDailyBy": {
        "_id": "6658011eaba105a066e37e1b",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6658011eaba105a066e37e1b/VPwyTv1bnVMQbVMoMQzcf.jpeg",
        "isPro": false,
        "fullname": "Daniel D'souza",
        "user": "dsouzadaniel",
        "type": "user"
      },
      "summary": "Une des plus graves problèmes du machine learning moderne est de maintenir un excellent rendement dans les parties longues avec des caractéristiques rares et insuffisantes. Les modèles à grande échelle sont entraînés pour plusieurs tâches, mais sont adaptés aux situations de haute fréquence. Il est difficile d'appliquer un modèle à des tâches spécifiques avec des caractéristiques peu représentées dans l'ensemble d'entraînement. Si dépendent de l'ingénierie front-end ou de l'ingénierie de caractéristiques pour maximiser la qualité de sortie des cas de test spécifiques, le modèle peut être très sensible à de petites variations, réagir de manière inattendue ou dépendre de l'ingénierie front-end statique pour maintenir le rendement, ce qui peut être frustrant. Dans cette étude, la question posée est si il est possible d'optimiser les protocoles d'entraînement et de contrôler et d'améliorer le rendement dans des situations de tâches peu représentées lors de l'inférence. On réévalue la différence entre les techniques d'entraînement et d'inférence, avec l'objectif de améliorer le rendement dans les parties longues, en fournissant à l'utilisateur une fonction de contrôle pour que le modèle réponde adéquatement. On décrit en détail les caractéristiques des données et les causes des tâches, en contrôlant clairement les propriétés générées lors de l'inférence et en essayant de générer de manière conditionnelle implicite. On ajuste des modèles de base pour qu'ils puissent inférer automatiquement ces marqueurs. Cet approche logique et flexible montre clairement des améliorations du rendement, avec un accroissement moyen de 5,7% en termes de supériorité et un accroissement de 9,1% en termes de surface déficiente. De plus, le rendement relatif dans des tâches déficientes comme CodeRepair dépasse de plus de 14,1%, et l'amélioration absolue selon la longueur est supérieure à 35,3%.",
      "upvotes": 1,
      "discussionId": "6852331e0164cd1316710500",
      "ai_summary": "A principled approach to fine-tuning models for better performance and controllability on underrepresented use cases is developed through automatic inference of generation attributes.",
      "ai_keywords": [
        "prompt engineering",
        "few-shot examples",
        "controllability",
        "performance",
        "long-tail",
        "training protocols",
        "inference techniques",
        "taxonomy",
        "data characteristics",
        "task provenance",
        "fine-tuning",
        "generation attributes",
        "markers",
        "underrepresented domains",
        "CodeRepair",
        "length instruction following"
      ]
    },
    "publishedAt": "2025-06-17T12:40:42.000Z",
    "title": "Treasure Hunt: Real-time Targeting of the Long Tail using Training-Time\n  Markers",
    "summary": "One of the most profound challenges of modern machine learning is performing\nwell on the long-tail of rare and underrepresented features. Large\ngeneral-purpose models are trained for many tasks, but work best on\nhigh-frequency use cases. After training, it is hard to adapt a model to\nperform well on specific use cases underrepresented in the training corpus.\nRelying on prompt engineering or few-shot examples to maximize the output\nquality on a particular test case can be frustrating, as models can be highly\nsensitive to small changes, react in unpredicted ways or rely on a fixed system\nprompt for maintaining performance. In this work, we ask: \"Can we optimize our\ntraining protocols to both improve controllability and performance on\nunderrepresented use cases at inference time?\" We revisit the divide between\ntraining and inference techniques to improve long-tail performance while\nproviding users with a set of control levers the model is trained to be\nresponsive to. We create a detailed taxonomy of data characteristics and task\nprovenance to explicitly control generation attributes and implicitly condition\ngenerations at inference time. We fine-tune a base model to infer these markers\nautomatically, which makes them optional at inference time. This principled and\nflexible approach yields pronounced improvements in performance, especially on\nexamples from the long tail of the training distribution. While we observe an\naverage lift of 5.7% win rates in open-ended generation quality with our\nmarkers, we see over 9.1% gains in underrepresented domains. We also observe\nrelative lifts of up to 14.1% on underrepresented tasks like CodeRepair and\nabsolute improvements of 35.3% on length instruction following evaluations.",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/6658011eaba105a066e37e1b/RBQEHm8CJA9fKsg4bupgs.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.14702.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6658011eaba105a066e37e1b",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6658011eaba105a066e37e1b/VPwyTv1bnVMQbVMoMQzcf.jpeg",
      "fullname": "Daniel D'souza",
      "name": "dsouzadaniel",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 4
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2506.13901",
      "authors": [
        {
          "_id": "685252860164cd13167105c7",
          "name": "Abhilekh Borah",
          "hidden": false
        },
        {
          "_id": "685252860164cd13167105c8",
          "name": "Chhavi Sharma",
          "hidden": false
        },
        {
          "_id": "685252860164cd13167105c9",
          "name": "Danush Khanna",
          "hidden": false
        },
        {
          "_id": "685252860164cd13167105ca",
          "name": "Utkarsh Bhatt",
          "hidden": false
        },
        {
          "_id": "685252860164cd13167105cb",
          "name": "Gurpreet Singh",
          "hidden": false
        },
        {
          "_id": "685252860164cd13167105cc",
          "name": "Hasnat Md Abdullah",
          "hidden": false
        },
        {
          "_id": "685252860164cd13167105cd",
          "name": "Raghav Kaushik Ravi",
          "hidden": false
        },
        {
          "_id": "685252860164cd13167105ce",
          "name": "Vinija Jain",
          "hidden": false
        },
        {
          "_id": "685252860164cd13167105cf",
          "name": "Jyoti Patel",
          "hidden": false
        },
        {
          "_id": "685252860164cd13167105d0",
          "name": "Shubham Singh",
          "hidden": false
        },
        {
          "_id": "685252860164cd13167105d1",
          "name": "Vasu Sharma",
          "hidden": false
        },
        {
          "_id": "685252860164cd13167105d2",
          "name": "Arpita Vats",
          "hidden": false
        },
        {
          "_id": "685252860164cd13167105d3",
          "name": "Rahul Raja",
          "hidden": false
        },
        {
          "_id": "685252860164cd13167105d4",
          "name": "Aman Chadha",
          "hidden": false
        },
        {
          "_id": "685252860164cd13167105d5",
          "name": "Amitava Das",
          "hidden": false
        }
      ],
      "publishedAt": "2025-06-16T18:22:28.000Z",
      "submittedOnDailyAt": "2025-06-18T04:17:43.427Z",
      "title": "L'Alignement Géométri des Clusters (GGC) : Au-delà de la Réjection : Géométrie Potentielle, Dispersion des Clusters, et le Diagramme d'Alignement de AQI à travers la Théorie des Layerways",
      "submittedOnDailyBy": {
        "_id": "63a4754927f1f64ed7238dac",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63a4754927f1f64ed7238dac/aH-eJF-31g4vof9jv2gmI.jpeg",
        "isPro": false,
        "fullname": "Aman Chadha",
        "user": "amanchadha",
        "type": "user"
      },
      "summary": "La alignement n'est pas simplement excellent ni nécessaire. Les grands modèles de langue (LLMs) se trouvent dans des domaines hautement réglementés comme l'éducation, la médecine, les professions et le droit, et leur comportement doit refléter clairement les valeurs de l'alignement humain et les restrictions sécuritaires. Cependant, actuellement, les évaluations ont de graves défauts, tels que le pourcentage de fautes, les scores de G-Eval et les classifieurs de genre. Les modèles d'alignement sont vulnérables à la \"palanche de frein\", à la randomisation de la génération et au \"fascinement\" de l'alignement.\n\nPour résoudre ce problème, nous présentons l'Indice de Qualité de l'Alignement (AQI). Ce nouveau métrique géométri et invariant à l'interface front-end évalue expérimentalement l'alignement des LLMs, en séparant et analysant les actions sécurisées et non sécurisées dans l'espace potentiel. En combinant des mesures comme le Score de Davies-Bouldin (DBS), l'Indice de Dunn (DI), l'Indice de Xie-Beni (XBI) et l'Indice de Calinski-Harabasz (CHI), l'AQI permet d'identifier la qualité du clustering et de détecter possibles alignements cachés et risques de palanche de frein. De plus, l'AQI fonctionne comme un avertissement anticipé du \"fascinement\" de l'alignement. Comme outil puissant et décodiable, l'AQI exécute un apprentissage sécurisé avec détermination.\n\nDe plus, nous proposons le jeu de données LITMUS. Ce jeu de données encourage des évaluations robustes dans des conditions difficiles. Les expériences sur LITMUS avec des modèles entraînés sous des conditions de DPO, GRPO et RLHF révèlent leurs faiblesses, détectées grâce à l'AQI et à la relation avec des juges externes et des métriques de rejet. Notre implémentation est disponible pour l'utilisation publique, favorisant la recherche future dans ce domaine.",
      "upvotes": 1,
      "discussionId": "685252870164cd13167105d6",
      "ai_summary": "A new evaluation metric called Alignment Quality Index (AQI) assesses the alignment of large language models by analyzing latent space activations, capturing clustering quality to detect misalignments and fake alignment, and complementing existing behavioral proxies.",
      "ai_keywords": [
        "Alignment Quality Index (AQI)",
        "latent space",
        "Davies-Bouldin Score (DBS)",
        "Dunn Index (DI)",
        "Xie-Beni Index (XBI)",
        "Calinski-Harabasz Index (CHI)",
        "LITMUS dataset",
        "DPO",
        "GRPO",
        "RLHF",
        "alignment faking",
        "external judges"
      ]
    },
    "publishedAt": "2025-06-16T14:22:28.000Z",
    "title": "Alignment Quality Index (AQI) : Beyond Refusals: AQI as an Intrinsic\n  Alignment Diagnostic via Latent Geometry, Cluster Divergence, and Layer wise\n  Pooled Representations",
    "summary": "Alignment is no longer a luxury, it is a necessity. As large language models\n(LLMs) enter high-stakes domains like education, healthcare, governance, and\nlaw, their behavior must reliably reflect human-aligned values and safety\nconstraints. Yet current evaluations rely heavily on behavioral proxies such as\nrefusal rates, G-Eval scores, and toxicity classifiers, all of which have\ncritical blind spots. Aligned models are often vulnerable to jailbreaking,\nstochasticity of generation, and alignment faking.\n  To address this issue, we introduce the Alignment Quality Index (AQI). This\nnovel geometric and prompt-invariant metric empirically assesses LLM alignment\nby analyzing the separation of safe and unsafe activations in latent space. By\ncombining measures such as the Davies-Bouldin Score (DBS), Dunn Index (DI),\nXie-Beni Index (XBI), and Calinski-Harabasz Index (CHI) across various\nformulations, AQI captures clustering quality to detect hidden misalignments\nand jailbreak risks, even when outputs appear compliant. AQI also serves as an\nearly warning signal for alignment faking, offering a robust, decoding\ninvariant tool for behavior agnostic safety auditing.\n  Additionally, we propose the LITMUS dataset to facilitate robust evaluation\nunder these challenging conditions. Empirical tests on LITMUS across different\nmodels trained under DPO, GRPO, and RLHF conditions demonstrate AQI's\ncorrelation with external judges and ability to reveal vulnerabilities missed\nby refusal metrics. We make our implementation publicly available to foster\nfuture research in this area.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.13901.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "63a4754927f1f64ed7238dac",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63a4754927f1f64ed7238dac/aH-eJF-31g4vof9jv2gmI.jpeg",
      "fullname": "Aman Chadha",
      "name": "amanchadha",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 6
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2506.13599",
      "authors": [
        {
          "_id": "685220810164cd131671048e",
          "name": "Yuwei Du",
          "hidden": false
        },
        {
          "_id": "685220810164cd131671048f",
          "name": "Jie Feng",
          "hidden": false
        },
        {
          "_id": "685220810164cd1316710490",
          "name": "Jian Yuan",
          "hidden": false
        },
        {
          "_id": "685220810164cd1316710491",
          "name": "Yong Li",
          "hidden": false
        }
      ],
      "mediaUrls": [
        "https://cdn-uploads.huggingface.co/production/uploads/6465d3bd63e7e09dd02e95c3/t_3QiPaJ54vNcgeYZKMgy.jpeg"
      ],
      "publishedAt": "2025-06-16T15:24:07.000Z",
      "submittedOnDailyAt": "2025-06-18T01:27:33.225Z",
      "title": "CAMS : Simulation de la Ville GPT en tant que Portefeuille de la Structure Agent Mobile de la Ville",
      "submittedOnDailyBy": {
        "_id": "6465d3bd63e7e09dd02e95c3",
        "avatarUrl": "/avatars/b2798bd5f8368f956bf7fab79d9432f0.svg",
        "isPro": false,
        "fullname": "Jie Feng",
        "user": "JJ-TMT",
        "type": "user"
      },
      "summary": "La simulation du mouvement humain joue un rôle important dans de nombreux domaines de la réalité. Récemment, les chercheurs ont exploré des méthodes d'apprentissage basées sur les données pour surmonter les limitations des grands modèles de langage (LLMs) et accélérer la simulation du mouvement humain. Cependant, ces méthodes présentent des défauts significatifs, comme une mauvaise modélisation des espaces urbains et une mauvaise intégration des motifs de mouvement individuels et collectifs. Pour relever ces défis, nous proposons un cadre d'agent pour simuler le mouvement humain dans l'espace urbain basé sur le langage, appelé 'CAMS'. CAMS comprend trois modules clés : MobExtractor, GeoGenerator et TrajEnhancer. En utilisant des profils de utilisateurs, CAMS extrait des motifs de mouvement de modèles pré-entraînés, synthétise de nouveaux motifs et génère des points de référence (Anchor) grâce au savoir collectif. De plus, il génère des candidats de quadrature dans l'espace urbain et crée des trajectoires mises à jour basées sur des motifs de mouvement réels. Les résultats des expérimentations avec des ensembles de données de la réalité montrent que CAMS ne dépend pas d'information géographique externe, mais offre des rendements élevés. En outre, en modélisant de manière intégral des motifs de mouvement individuels et des restrictions collectives, CAMS génère des trajectoires plus réalistes et appropriées. En général, CAMS établit un nouveau paradigme qui intègre un cadre d'agent avec les LLMs connus dans le domaine urbain, ouvrant de nouvelles possibilités dans la simulation du mouvement humain.",
      "upvotes": 1,
      "discussionId": "685220820164cd1316710492",
      "ai_summary": "CAMS integrates an agentic framework with urban-knowledgeable large language models to simulate human mobility more realistically by modeling individual and collective patterns.",
      "ai_keywords": [
        "large language models",
        "CityGPT",
        "agentic framework",
        "human mobility simulation",
        "urban spaces",
        "individual mobility patterns",
        "collective mobility distributions",
        "MobExtractor",
        "GeoGenerator",
        "TrajEnhancer",
        "DPO",
        "trajectory preference alignment",
        "real-world datasets"
      ]
    },
    "publishedAt": "2025-06-16T11:24:07.000Z",
    "title": "CAMS: A CityGPT-Powered Agentic Framework for Urban Human Mobility\n  Simulation",
    "summary": "Human mobility simulation plays a crucial role in various real-world\napplications. Recently, to address the limitations of traditional data-driven\napproaches, researchers have explored leveraging the commonsense knowledge and\nreasoning capabilities of large language models (LLMs) to accelerate human\nmobility simulation. However, these methods suffer from several critical\nshortcomings, including inadequate modeling of urban spaces and poor\nintegration with both individual mobility patterns and collective mobility\ndistributions. To address these challenges, we propose CityGPT-Powered\nAgentic framework for Mobility Simulation\n(CAMS), an agentic framework that leverages the language based urban\nfoundation model to simulate human mobility in urban space. CAMS\ncomprises three core modules, including MobExtractor to extract template\nmobility patterns and synthesize new ones based on user profiles, GeoGenerator\nto generate anchor points considering collective knowledge and generate\ncandidate urban geospatial knowledge using an enhanced version of CityGPT,\nTrajEnhancer to retrieve spatial knowledge based on mobility patterns and\ngenerate trajectories with real trajectory preference alignment via DPO.\nExperiments on real-world datasets show that CAMS achieves superior\nperformance without relying on externally provided geospatial information.\nMoreover, by holistically modeling both individual mobility patterns and\ncollective mobility constraints, CAMS generates more realistic and\nplausible trajectories. In general, CAMS establishes a new paradigm\nthat integrates the agentic framework with urban-knowledgeable LLMs for human\nmobility simulation.",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/6465d3bd63e7e09dd02e95c3/t_3QiPaJ54vNcgeYZKMgy.jpeg"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.13599.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6465d3bd63e7e09dd02e95c3",
      "avatarUrl": "/avatars/b2798bd5f8368f956bf7fab79d9432f0.svg",
      "fullname": "Jie Feng",
      "name": "JJ-TMT",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2506.13387",
      "authors": [
        {
          "_id": "6852239f0164cd13167104a4",
          "name": "Beilei Cui",
          "hidden": false
        },
        {
          "_id": "6852239f0164cd13167104a5",
          "name": "Yiming Huang",
          "hidden": false
        },
        {
          "_id": "6852239f0164cd13167104a6",
          "name": "Long Bai",
          "hidden": false
        },
        {
          "_id": "6852239f0164cd13167104a7",
          "name": "Hongliang Ren",
          "hidden": false
        }
      ],
      "publishedAt": "2025-06-16T11:50:00.000Z",
      "submittedOnDailyAt": "2025-06-18T00:57:15.579Z",
      "title": "TR2M : Conversion de la profondeur relative d'une seule caméra en profondeur métrique par comparaison avec l'échelle et la profondeur de la racine de la scène",
      "submittedOnDailyBy": {
        "_id": "68518fb45452a74491857c5b",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/SOYIB8T0LsNZM3ORcHXlr.png",
        "isPro": false,
        "fullname": "Beilei Cui",
        "user": "BeileiCui",
        "type": "user"
      },
      "summary": "Dans cette étude, nous proposons un cadre général pour convertir des profondeurs relatives en profondeurs standards. Les méthodes actuelles d'estimation de profondeur se divisent principalement en deux : l'estimation de profondeur standard (MMDE) et l'estimation de profondeur relative (MRDE). L'MMDE estime des profondeurs à l'échelle standard mais est limitée à certaines zones. L'MRDE peut être généralisée à d'autres zones, mais l'incertitude de son échelle peut empêcher son utilisation dans des applications plus basses. L'objectif est de résoudre ces problèmes et de construire un cadre qui convertit des profondeurs relatives en profondeurs standards. Les méthodes précédentes utilisent du langage comme entrée et estiment deux facteurs pour souligner. Notre approche, le TR2M, utilise comme entrée des descriptions textuelles et des images, et estime deux cartes de soulignement au niveau de pixel pour convertir des profondeurs relatives en profondeurs standards. Les deux modules sont caractérisés par une attention croisée modulaire qui fournit des informations d'échelle plus précises. Une stratégie a été conçue pour construire des profondeurs standards avec une grande confiance et filtrer pour fournir un superviseur plus détaillé. De plus, un entraînement de contraste a été développé pour guider la distribution de la profondeur et apprendre des connaissances uniques appropriées pour la distribution d'échelle. Le TR2M utilise plusieurs paramètres d'entraînement et est utilisé avec des ensembles de données entraînés dans différentes zones. Les expériences montrent de très bons résultats sur des ensembles de données existants et révèlent une capacité de 0 shot notable sur cinq ensembles de données non vus. Cela montre la possibilité de convertir des profondeurs relatives en profondeurs standards au niveau de pixel avec un grand potentiel. Le code est disponible sur la suivante URL : https://github.com/BeileiCui/TR2M",
      "upvotes": 0,
      "discussionId": "6852239f0164cd13167104a8",
      "ai_summary": "A framework, TR2M, uses multimodal inputs to rescale relative depth to metric depth, enhancing performance across various datasets through cross-modality attention and contrastive learning.",
      "ai_keywords": [
        "relative depth estimation",
        "metric depth estimation",
        "cross-modality attention",
        "contrastive learning",
        "rescale maps",
        "pseudo metric depth",
        "intrinsically aligned scale distribution"
      ]
    },
    "publishedAt": "2025-06-16T07:50:00.000Z",
    "title": "TR2M: Transferring Monocular Relative Depth to Metric Depth with\n  Language Descriptions and Scale-Oriented Contrast",
    "summary": "This work presents a generalizable framework to transfer relative depth to\nmetric depth. Current monocular depth estimation methods are mainly divided\ninto metric depth estimation (MMDE) and relative depth estimation (MRDE). MMDEs\nestimate depth in metric scale but are often limited to a specific domain.\nMRDEs generalize well across different domains, but with uncertain scales which\nhinders downstream applications. To this end, we aim to build up a framework to\nsolve scale uncertainty and transfer relative depth to metric depth. Previous\nmethods used language as input and estimated two factors for conducting\nrescaling. Our approach, TR2M, utilizes both text description and image as\ninputs and estimates two rescale maps to transfer relative depth to metric\ndepth at pixel level. Features from two modalities are fused with a\ncross-modality attention module to better capture scale information. A strategy\nis designed to construct and filter confident pseudo metric depth for more\ncomprehensive supervision. We also develop scale-oriented contrastive learning\nto utilize depth distribution as guidance to enforce the model learning about\nintrinsic knowledge aligning with the scale distribution. TR2M only exploits a\nsmall number of trainable parameters to train on datasets in various domains\nand experiments not only demonstrate TR2M's great performance in seen datasets\nbut also reveal superior zero-shot capabilities on five unseen datasets. We\nshow the huge potential in pixel-wise transferring relative depth to metric\ndepth with language assistance. (Code is available at:\nhttps://github.com/BeileiCui/TR2M)",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.13387.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "68518fb45452a74491857c5b",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/SOYIB8T0LsNZM3ORcHXlr.png",
      "fullname": "Beilei Cui",
      "name": "BeileiCui",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false
    },
    "isAuthorParticipating": false
  }
]