[
  {
    "paper": {
      "id": "2502.01362",
      "authors": [
        {
          "_id": "67a2ad6ac7caec9bf5a45e61",
          "name": "Nikita Gushchin",
          "hidden": false
        },
        {
          "_id": "67a2ad6ac7caec9bf5a45e62",
          "name": "David Li",
          "hidden": false
        },
        {
          "_id": "67a2ad6ac7caec9bf5a45e63",
          "name": "Daniil Selikhanovych",
          "hidden": false
        },
        {
          "_id": "67a2ad6ac7caec9bf5a45e64",
          "name": "Evgeny Burnaev",
          "hidden": false
        },
        {
          "_id": "67a2ad6ac7caec9bf5a45e65",
          "name": "Dmitry Baranchuk",
          "hidden": false
        },
        {
          "_id": "67a2ad6ac7caec9bf5a45e66",
          "name": "Alexander Korotin",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-03T13:56:03.000Z",
      "title": "Reverso Bridge Matching Style",
      "summary": "Le design de la réseau de mode de bridage de DeepDream est simple, mais le transformer en quelque chose pratique et rapide est artistique. La réseau de mode de bridage de DeepDream (DBMs) est une extension de la mode de DeepDream pour la transformation des images. Cependant, comme d'autres modes de DeepDream modernes ou flux, les DBMs n'avaient pas abordé le problème de la lenteur de l'inférence. Pour résoudre ce problème, nous proposons un nouveau méthode de distillation basée sur l'approche inverse de bridage et calculons des objets calculables pour résoudre les problèmes réels. Au contraire des méthodes de distillation des DBMs développées précédemment, le méthode proposée peut distiller tant les DBMs conditionnelles que les non conditionnelles, et peut distiller un générateur en un seul pas, en utilisant seulement des images détruites pour l'entraînement. Nous évaluons le méthode de distillation dans les deux modes de bridage conditionnels et non conditionnels dans une large gamme de configurations, et nous démontrons que notre méthode de distillation accélère la vitesse d'inférence des DBMs par un facteur de 4 à plus de 100 fois, et peut dépasser la qualité de génération des modes de terre.",
      "upvotes": 16,
      "discussionId": "67a2ad70c7caec9bf5a45fb0"
    },
    "publishedAt": "2025-02-05T03:01:40.464Z",
    "title": "Inverse Bridge Matching Distillation",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01362.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "672503c59f68afdd63cc81a2",
      "avatarUrl": "/avatars/91207207b56a1fc2b4a8197b1ab3a7f9.svg",
      "fullname": "Nikita Gushchin",
      "name": "ngushchin",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.01718",
      "authors": [
        {
          "_id": "67a2d995c97974764a8c294c",
          "name": "Huaye Zeng",
          "hidden": false
        },
        {
          "_id": "67a2d995c97974764a8c294d",
          "name": "Dongfu Jiang",
          "hidden": false
        },
        {
          "_id": "67a2d995c97974764a8c294e",
          "name": "Haozhe Wang",
          "hidden": false
        },
        {
          "_id": "67a2d995c97974764a8c294f",
          "name": "Ping Nie",
          "hidden": false
        },
        {
          "_id": "67a2d995c97974764a8c2950",
          "name": "Xiaotong Chen",
          "hidden": false
        },
        {
          "_id": "67a2d995c97974764a8c2951",
          "name": "Wenhu Chen",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-03T18:46:04.000Z",
      "title": "ACECODER : Le triomphe du code dans le bois aléatoire par la synthèse de cas de test aléatoires",
      "summary": "Le développement récent des modèles de code a été principalement motivé par l'ajuste micro observatoire (SFT), mais le potentiel de l'apprentissage par récompense (RL) a été très peu exploré dans le domaine du code en raison de la manque de données de récompense fiables et de la rareté des modèles. Dans cet article, nous résolvons ces défis en utilisant la synthèse automatique d'exemples de tests à grande échelle pour améliorer l'entraînement des modèles de code. En particulier, nous avons conçu une pipeline pour générer des paires détaillées (problème, exemple de test) à partir des données de code existantes. Ces exemples de tests sont utilisés pour entraîner un modèle de récompense basé sur le pourcentage de succès des programmes sampling, en utilisant la perte de Bradley-Lee. Cette approche a montré des améliorations moyennes de 10 points sur Llama-3.1-8B-Ins et de 5 points sur Qwen2.5-Coder-7B-Ins, atteignant un niveau comparable à DeepSeek-V2.5 (236B) en 32 échantillons de 32 exemples de tests. De plus, nous avons effectué un apprentissage par récompense en utilisant le modèle de récompense et la récompense par étape de l'exemple de test, obtenant des améliorations constantes sur HumanEval, MBPP, BigCodeBench et LiveCodeBench (V4). En particulier, en appliquant l'entraînement de R1 sur Qwen2.5-Coder-base, nous avons montré des améliorations de 25% sur HumanEval-plus et de 6% sur MBPP-plus. Nous sommes convaincus que ces résultats démontrent que l'apprentissage par récompense a un grand potentiel dans les modèles de code.",
      "upvotes": 12,
      "discussionId": "67a2d996c97974764a8c29a1"
    },
    "publishedAt": "2025-02-04T22:23:07.858Z",
    "title": "ACECODER: Acing Coder RL via Automated Test-Case Synthesis",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01718.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5946
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.02492",
      "authors": [
        {
          "_id": "67a2ec904ea0e3138ac966f2",
          "user": {
            "_id": "6181c72cdcc1df2c9de8a4d8",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1655248010394-6181c72cdcc1df2c9de8a4d8.jpeg",
            "isPro": false,
            "fullname": "Hila Chefer",
            "user": "Hila",
            "type": "user"
          },
          "name": "Hila Chefer",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-02-05T04:44:03.218Z",
          "hidden": false
        },
        {
          "_id": "67a2ec904ea0e3138ac966f3",
          "name": "Uriel Singer",
          "hidden": false
        },
        {
          "_id": "67a2ec904ea0e3138ac966f4",
          "name": "Amit Zohar",
          "hidden": false
        },
        {
          "_id": "67a2ec904ea0e3138ac966f5",
          "name": "Yuval Kirstain",
          "hidden": false
        },
        {
          "_id": "67a2ec904ea0e3138ac966f6",
          "name": "Adam Polyak",
          "hidden": false
        },
        {
          "_id": "67a2ec904ea0e3138ac966f7",
          "name": "Yaniv Taigman",
          "hidden": false
        },
        {
          "_id": "67a2ec904ea0e3138ac966f8",
          "name": "Lior Wolf",
          "hidden": false
        },
        {
          "_id": "67a2ec904ea0e3138ac966f9",
          "name": "Shelly Sheynin",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-04T17:07:10.000Z",
      "title": "VideoJAM : Expressions communes d'apparence-action qui améliorent la fonctionnalité dans les modèles de vidéo",
      "summary": "Bien que des avancés significatifs aient été réalisés récemment, les modèles de génération vidéo encore enfreignent des difficultés pour comprendre le mouvement, la mécanique et la physique du monde réel. Ces limites sont dues aux objectifs traditionnels de reconstruction des pixels, qui montrent que les modèles perdent la dynamique de cohésion. Pour résoudre ce problème, nous présentons le nouveau cadre de travail VideoJAM, conçu pour enseigner aux modèles à apprendre des représentations communes d'apparence-action, fournissant des mouvements efficaces aux générateurs vidéo. VideoJAM est composé de deux unités d'interpolation. Pendant l'entraînement, l'objectif est étendu et le mouvement correspondant aux pixels générés est prédit, ce qui permet de créer une représentation apprise. Lors de l'inférence, nous introduisons la structure Inner-Guidance, qui utilise la prédiction des mouvements qui évoluent automatiquement en tant que signaux guidants dynamiques pour contrôler la génération de mouvements cohérents. En particulier, notre cadre de travail est caractérisé par le fait qu'il ne nécessite pas de modifications dans les données d'entraînement ou dans la taille du modèle, permettant d'atteindre le meilleur rendement pour la dynamique de cohésion, de dépasser les modèles de profil compétitif et d'améliorer la qualité visuelle des contenus générés. Ces résultats soulignent que l'apparence et le mouvement sont interprétatifs et se intègrent efficacement, améliorant à la fois la qualité visuelle et la cohésion dans la génération vidéo. Site web du projet : https://hila-chefer.github.io/videojam-paper.github.io/",
      "upvotes": 11,
      "discussionId": "67a2ec934ea0e3138ac9678e"
    },
    "publishedAt": "2025-02-04T23:46:17.626Z",
    "title": "VideoJAM: Joint Appearance-Motion Representations for Enhanced Motion Generation in Video Models",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.02492.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6181c72cdcc1df2c9de8a4d8",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1655248010394-6181c72cdcc1df2c9de8a4d8.jpeg",
      "fullname": "Hila Chefer",
      "name": "Hila",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 8
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.02584",
      "authors": [
        {
          "_id": "67a2d59fd5ad3369a66ff394",
          "name": "Zongyu Lin",
          "hidden": false
        },
        {
          "_id": "67a2d59fd5ad3369a66ff395",
          "name": "Yao Tang",
          "hidden": false
        },
        {
          "_id": "67a2d59fd5ad3369a66ff396",
          "name": "Xingcheng Yao",
          "hidden": false
        },
        {
          "_id": "67a2d59fd5ad3369a66ff397",
          "name": "Da Yin",
          "hidden": false
        },
        {
          "_id": "67a2d59fd5ad3369a66ff398",
          "name": "Ziniu Hu",
          "hidden": false
        },
        {
          "_id": "67a2d59fd5ad3369a66ff399",
          "name": "Yizhou Sun",
          "hidden": false
        },
        {
          "_id": "67a2d59fd5ad3369a66ff39a",
          "name": "Kai-Wei Chang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-04T18:58:31.000Z",
      "title": "QLASS : Améliore l'inférence de la sortie d'assemblage de langage par une recherche guidée par Q à pas sur pas.",
      "summary": "Le langage de l'intelligence artificielle a été consolidé comme une solution prometteuse pour des tâches d'interaction complexes, et l'un des piliers clés de succès est le modèle de récompense dans le flux de la réseau d'agents. Ce modèle fournit une direction adéquate pendant l'entraînement ou l'inférence. Cependant, en raison de la manière dont il ne fournit pas une explication suffisante des interactions intermédiaires, de nombreux études antérieures ont utilisé des modèles de récompense, optimisant des politiques qui forment le ensemble de la trajectoire. Cela peut conduire à des politiques non optimales et à une perte de performance globale. Pour résoudre ce problème, on propose QLASS (Q-GUIDED Language Agent Step-Scale Search), qui estime des valeurs de Q dans un approche pas à pas pour générer des explications automatiques, offrant une guidance intermédiaire. En proposant des arbres de raisonnement, QLASS permet de modéliser la récompense à chaque pas, fournissant une guidance efficace intermédiaire à chaque étape. En se basant sur cette guidance, QLASS confère une plus grande adaptabilité à long terme et améliore le rendement dans l'inférence de modèles d'agents interactifs complexes. En particulier, QLASS maintient un rendement fort en utilisant seulement des données d'explication proches, démontrant une efficacité avec des superagents limités et en probant expérimentalement qu'il promeut des décisions plus efficaces grâce à un analyse qualitative. Les codes et les données sont disponibles.",
      "upvotes": 7,
      "discussionId": "67a2d5a0d5ad3369a66ff3d4"
    },
    "publishedAt": "2025-02-04T22:08:25.652Z",
    "title": "QLASS: Boosting Language Agent Inference via Q-Guided Stepwise Search",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.02584.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "634e4670a51d5df8c2d92fce",
      "avatarUrl": "/avatars/c52d7150b4de6a2eb2d83b345d35cbc2.svg",
      "fullname": "Da Yin",
      "name": "DaYin",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.01941",
      "authors": [
        {
          "_id": "67a2e2a02dd2adbc88755a47",
          "name": "Xiang Liu",
          "hidden": false
        },
        {
          "_id": "67a2e2a02dd2adbc88755a48",
          "name": "Zhenheng Tang",
          "hidden": false
        },
        {
          "_id": "67a2e2a02dd2adbc88755a49",
          "name": "Hong Chen",
          "hidden": false
        },
        {
          "_id": "67a2e2a02dd2adbc88755a4a",
          "name": "Peijie Dong",
          "hidden": false
        },
        {
          "_id": "67a2e2a02dd2adbc88755a4b",
          "name": "Zeyu Li",
          "hidden": false
        },
        {
          "_id": "67a2e2a02dd2adbc88755a4c",
          "name": "Xiuze Zhou",
          "hidden": false
        },
        {
          "_id": "67a2e2a02dd2adbc88755a4d",
          "name": "Bo Li",
          "hidden": false
        },
        {
          "_id": "67a2e2a02dd2adbc88755a4e",
          "name": "Xuming Hu",
          "hidden": false
        },
        {
          "_id": "67a2e2a02dd2adbc88755a4f",
          "name": "Xiaowen Chu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-04T02:23:06.000Z",
      "title": "Les modèles de langage à longue portée (LLM) peuvent-ils maintenir leurs capacités de base sous l'effet de la compression de la cache KV ?",
      "summary": "Cet article explore des problèmes non examinés dans les modèles de langage grands (LLMs) : le méthode de compression de la cache KV et son impact sur les capacités de base des LLMs. Les méthodes existantes atteignent des compressions spectaculaires dans les cadres de tests de contexte long, mais leur influence sur les capacités clés du modèle a été peu étudiée. Nous proposons un principal méthode de compression de la cache KV qui évalue une large gamme de tâches, y compris le savoir général, l'inférence générale, l'inférence arithmétique, la génération de code, la sécurité, la compréhension et la génération de contextes longs. L'analyse montre que la méthode de compression de la cache KV peut causer une perte de performance dans certaines tâches. Les tâches d'inférence arithmétique sont particulièrement sensibles à la compression, avec des pertes de performance de 17,4% à 43,3%. En particulier, le modèle DeepSeek R1 Distill montre une plus grande résistance à la compression par rapport aux modèles entraînés, avec des pertes de performance de 9,67% à 25,53%. Nous évaluons les motifs d'attention et le rendement de compression croisé entre tâches, et proposons un nouvel approche de compression appelé ShotKV. ShotKV traite séparément les étapes de pré-remplissage et de décodage, en maintenant des connexions significatives au niveau de la moteur, et atteint un amélioration du rendement de 9% à 18% dans les tâches de génération de contextes longs sous une compression sévère.",
      "upvotes": 6,
      "discussionId": "67a2e2a22dd2adbc88755ab4"
    },
    "publishedAt": "2025-02-04T23:04:25.888Z",
    "title": "Can LLMs Maintain Fundamental Abilities under KV Cache Compression?",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/63024676056ec3a2a8714b24/XcgjmhpXd3dH6LnFZGupJ.png",
      "https://cdn-uploads.huggingface.co/production/uploads/63024676056ec3a2a8714b24/hxWz1iVOUcE76E_K5z-B0.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01941.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "63024676056ec3a2a8714b24",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1661093436322-noauth.jpeg",
      "fullname": "Xiang Liu",
      "name": "Dominic789654",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 3
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.02508",
      "authors": [
        {
          "_id": "67a2d1f9bc9d072d9459e857",
          "user": {
            "_id": "6553c985a7aded0380b5f928",
            "avatarUrl": "/avatars/36109d6f536d2b34d98822b88eac9608.svg",
            "isPro": false,
            "fullname": "Maohao Shen",
            "user": "maohaos2",
            "type": "user"
          },
          "name": "Maohao Shen",
          "status": "extracted_confirmed",
          "statusLastChangedAt": "2025-02-05T03:00:33.470Z",
          "hidden": false
        },
        {
          "_id": "67a2d1f9bc9d072d9459e858",
          "name": "Guangtao Zeng",
          "hidden": false
        },
        {
          "_id": "67a2d1f9bc9d072d9459e859",
          "name": "Zhenting Qi",
          "hidden": false
        },
        {
          "_id": "67a2d1f9bc9d072d9459e85a",
          "name": "Zhang-Wei Hong",
          "hidden": false
        },
        {
          "_id": "67a2d1f9bc9d072d9459e85b",
          "name": "Zhenfang Chen",
          "hidden": false
        },
        {
          "_id": "67a2d1f9bc9d072d9459e85c",
          "name": "Wei Lu",
          "hidden": false
        },
        {
          "_id": "67a2d1f9bc9d072d9459e85d",
          "name": "Gregory Wornell",
          "hidden": false
        },
        {
          "_id": "67a2d1f9bc9d072d9459e85e",
          "name": "Subhro Das",
          "hidden": false
        },
        {
          "_id": "67a2d1f9bc9d072d9459e85f",
          "name": "David Cox",
          "hidden": false
        },
        {
          "_id": "67a2d1f9bc9d072d9459e860",
          "name": "Chuang Gan",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-04T17:26:58.000Z",
      "title": "Fabrication : L'apprentissage par renforcement basé sur la continuité de pensée renforce les modèles de langage",
      "summary": "Les modèles de langage grands (LLMs) montrent un talent révélateur pour la capacité de jugement logique dans diverses domaines. Selon des études récentes, l'augmentation de la quantité de calculs lors du processus de validation améliore la capacité de jugement logique des LLMs. Cela généralement inclut une grande échantillon de données externes de LLMs lors de l'inférence, ce qui permet de former un système à deux joueurs. Sans recours à des guides externes, ce système démontre son efficacité en montrant que seul un LLM peut résoudre des tâches complexes. Par conséquent, nous proposons un nouveau problème de recherche : déterminer si il est possible d'internaliser la capacité d'exploration dans un seul LLM pour améliorer ses habiletés de jugement logique de manière fondamentale. Cette recherche se concentre sur les LLMs entraînés plus tard, abordant un processus de jugement logique élargi (c'est-à-dire, l'auto-réflexion et l'exploration automatique de nouvelles stratégies incluses) et examinant des directions perpendiculaires. Pour y parvenir, nous proposons l'approche de la logique de l'action et du pensée (Chain-of-Action-Thought, COAT) et un modèle d'apprentissage à deux étapes : 1) un état d'entraînement réduit pour internaliser le format de la logique de COAT et 2) un état d'amélioration automatique à grande échelle en utilisant l'apprentissage par récompense. Notre approche a conduit à l'obtention d'un modèle de 7B LLM entraîné avec du code ouvert et de données, le «Satori». Les évaluations d'expériences larges montrent que Satori a atteint les meilleurs résultats dans les cadres de référence logique-mathématique et a démontré une forte capacité d'extension pour des tâches externes. Tout le code, les données et le modèle sont complètement ouverts.",
      "upvotes": 5,
      "discussionId": "67a2d1fcbc9d072d9459e91b"
    },
    "publishedAt": "2025-02-04T21:55:09.693Z",
    "title": "Satori: Reinforcement Learning with Chain-of-Action-Thought Enhances LLM Reasoning via Autoregressive Search",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.02508.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60ad0de755f970745d4ec28d",
      "avatarUrl": "/avatars/b0de0222b8ed5fdac8dc7cb0336d2ec7.svg",
      "fullname": "GtZeng",
      "name": "chaoscodes",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isMod": false,
      "followerCount": 11
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.01720",
      "authors": [
        {
          "_id": "67a2fddb4044bf1c86f765a3",
          "name": "Nupur Kumari",
          "hidden": false
        },
        {
          "_id": "67a2fddb4044bf1c86f765a4",
          "name": "Xi Yin",
          "hidden": false
        },
        {
          "_id": "67a2fddb4044bf1c86f765a5",
          "name": "Jun-Yan Zhu",
          "hidden": false
        },
        {
          "_id": "67a2fddb4044bf1c86f765a6",
          "name": "Ishan Misra",
          "hidden": false
        },
        {
          "_id": "67a2fddb4044bf1c86f765a7",
          "name": "Samaneh Azadi",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-03T18:59:41.000Z",
      "title": "Générer des données multi-image pour effectuer la personnalisation d'images à partir du texte.",
      "summary": "\"Adapter un modèle d'images pour la personnalisation des utilisateurs, de manière que les utilisateurs puissent introduire des concepts personnalisés et générer ces concepts dans des configurations qu'ils n'ont jamais vues avant. Les méthodes actuelles dépendent d'une optimisation coûteuse en tests ou s'appuient sur des ensembles de données d'entraînement avec seulement une image, ce qui peut réduire la qualité des images si elles ne comprennent pas une supervision à partir de plusieurs images. Nous proposons une approche simple pour résoudre deux restrictions. Premièrement, nous utilisons des modèles de texte et d'images et des ensembles de données 3D pour créer un dataset de personnalisation synthétique de haut rendement (SynCD) qui inclut des images avec différentes illuminations, fonds et positions d'objets. Ensuite, nous proposons une nouvelle architecture d'encodeur basée sur des structures d'attention partagée, avec l'objectif de améliorer l'intégration de détails visuels minutieux dans les images d'entrée. Enfin, nous proposons un nouveau méthode d'inférence pour atténuer le problème d'overexposition, en normalisant les vecteurs de guide de texte et d'images. A travers de nombreux expériments, nous montrons que notre modèle, entraîné avec des ensembles de données synthétiques, dépasse les méthodes actuelles dans les marques de référence standards de personnalisation, en utilisant l'encodeur et les algorithmes d'inférence proposés.\"",
      "upvotes": 2,
      "discussionId": "67a2fde34044bf1c86f767ba"
    },
    "publishedAt": "2025-02-05T00:59:11.275Z",
    "title": "Generating Multi-Image Synthetic Data for Text-to-Image Customization",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01720.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "62f6a894c3372328414c7021",
      "avatarUrl": "/avatars/e8b10912355712f38f10805c31bea962.svg",
      "fullname": "Nupur Kumari",
      "name": "nupurkmr9",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 4
    },
    "isAuthorParticipating": false
  }
]