[
  {
    "paper": {
      "id": "2501.12380",
      "authors": [
        {
          "_id": "67906f432565fc5140d72dc3",
          "name": "Yilun Zhao",
          "hidden": false
        },
        {
          "_id": "67906f432565fc5140d72dc4",
          "name": "Lujing Xie",
          "hidden": false
        },
        {
          "_id": "67906f432565fc5140d72dc5",
          "name": "Haowei Zhang",
          "hidden": false
        },
        {
          "_id": "67906f432565fc5140d72dc6",
          "name": "Guo Gan",
          "hidden": false
        },
        {
          "_id": "67906f432565fc5140d72dc7",
          "name": "Yitao Long",
          "hidden": false
        },
        {
          "_id": "67906f432565fc5140d72dc8",
          "name": "Zhiyuan Hu",
          "hidden": false
        },
        {
          "_id": "67906f432565fc5140d72dc9",
          "name": "Tongyan Hu",
          "hidden": false
        },
        {
          "_id": "67906f432565fc5140d72dca",
          "name": "Weiyuan Chen",
          "hidden": false
        },
        {
          "_id": "67906f432565fc5140d72dcb",
          "name": "Chuhan Li",
          "hidden": false
        },
        {
          "_id": "67906f432565fc5140d72dcc",
          "name": "Junyang Song",
          "hidden": false
        },
        {
          "_id": "67906f432565fc5140d72dcd",
          "name": "Zhijian Xu",
          "hidden": false
        },
        {
          "_id": "67906f432565fc5140d72dce",
          "name": "Chengye Wang",
          "hidden": false
        },
        {
          "_id": "67906f432565fc5140d72dcf",
          "name": "Weifeng Pan",
          "hidden": false
        },
        {
          "_id": "67906f432565fc5140d72dd0",
          "name": "Ziyao Shangguan",
          "hidden": false
        },
        {
          "_id": "67906f432565fc5140d72dd1",
          "name": "Xiangru Tang",
          "hidden": false
        },
        {
          "_id": "67906f432565fc5140d72dd2",
          "name": "Zhenwen Liang",
          "hidden": false
        },
        {
          "_id": "67906f432565fc5140d72dd3",
          "name": "Yixin Liu",
          "hidden": false
        },
        {
          "_id": "67906f432565fc5140d72dd4",
          "name": "Chen Zhao",
          "hidden": false
        },
        {
          "_id": "67906f432565fc5140d72dd5",
          "name": "Arman Cohan",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-21T18:56:18.000Z",
      "title": "MMVU : Évaluation de la compréhension des vidéos dans divers domaines académiques au niveau professionnel",
      "summary": "MMVU est un cadre de référence professionnel spécialisé pour évaluer la compréhension des vidéos. MMVU offre 3 000 questions avec des notations d'experts sur 27 thèmes répartis dans 4 domaines clés : sciences, médecine, humaines et sciences sociales, et ingénierie. Comparé à d'autres cadres de référence, MMVU se distingue par trois développements principaux. Premièrement, il se concentre sur le fait que les modèles appliquent des connaissances spécifiques d'un domaine pour analyser des vidéos professionnelles avec des raisons basées sur des connaissances professionnelles, dépassant le reconnaissance visuelle générale dans les cadres de référence vidéo. Deuxièmement, chaque exemple commence par une notation d'un expert, garantissant un haut niveau de qualité des données grâce à un traitement rigoureux de la qualité des données. Troisièmement, chaque exemple promeut un analysage détaillé en ajoutant des connaissances liées aux raisons et aux connaissances du domaine écrites par des experts. 32 modèles de pointe ont été évalués dans MMVU, où le modèle o1 de la capacité 2 du nouveau système et la Gemini 2.0 Flash Thinking ont montré les meilleurs résultats. Cependant, ils n'ont pas encore atteint la compétence des experts. L'analyse des erreurs spécifiques et les études de cas fournissent une richesse pratique pour le développement futur de la compréhension des vidéos dans des domaines spécialisés avec des connaissances denses.",
      "upvotes": 23,
      "discussionId": "67906f442565fc5140d72e4a"
    },
    "publishedAt": "2025-01-21T23:19:52.256Z",
    "title": "MMVU: Measuring Expert-Level Multi-Discipline Video Understanding",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.12380.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "62f662bcc58915315c4eccea",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62f662bcc58915315c4eccea/zOAQLONfMP88zr70sxHK-.jpeg",
      "fullname": "Yilun",
      "name": "yilunzhao",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isMod": false,
      "followerCount": 5
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.11425",
      "authors": [
        {
          "_id": "679080298ad1d8203a994f7f",
          "name": "Siyu Yuan",
          "hidden": false
        },
        {
          "_id": "679080298ad1d8203a994f80",
          "name": "Zehui Chen",
          "hidden": false
        },
        {
          "_id": "679080298ad1d8203a994f81",
          "name": "Zhiheng Xi",
          "hidden": false
        },
        {
          "_id": "679080298ad1d8203a994f82",
          "name": "Junjie Ye",
          "hidden": false
        },
        {
          "_id": "679080298ad1d8203a994f83",
          "name": "Zhengyin Du",
          "hidden": false
        },
        {
          "_id": "679080298ad1d8203a994f84",
          "name": "Jiecao Chen",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-20T11:46:04.000Z",
      "title": "Agent-R : Entraînement de modèles de langage d'agents à travers l'apprentissage auto-recurrent répétitif",
      "summary": "Les agents de modèles de langage grands (LLMs) jouent un rôle important dans la résolution de tâches complexes dans des environnements d'interaction. La recherche actuelle se concentre principalement sur l'amélioration du rendement par le cronocríminel des actions de forts experts, mais cette approche échoue dans la récupération des erreurs dans des applications réelles. Cependant, la collecte de données d'évaluation de pas est difficile et coûteuse. Par conséquent, il est crucial de construire automatiquement des ensembles de données d'évaluation dynamiques pour améliorer la capacité intelligente des agents. Dans cette étude, nous proposons un cadre d'entraînement itératif permettant à ces agents de langage de réfléchir immédiatement, appelé Agent-R. A différence des méthodes existantes, Agent-R construit des données d'entraînement à l'aide de MCTS, en utilisant des chemins qui mènent à des erreurs pour construire des chemins corrects. L'une des principales questions lors du processus de réflexion de l'agent est la nécessité de modifier les chemins en temps réel, sans attendre jusqu'au terme. Pour y parvenir, nous introduisons une structure d'évaluation guidée par modèles : le modèle compteur identifie le premier erreur sur un chemin erroné (dans le cadre des capacités actuelles) et, à partir de là, distribue des chemins précis voisins, de manière que les nœuds parents soient égaux. Cette stratégie permet au modèle d'apprendre à réfléchir sur sa politique actuelle et à effectuer un apprentissage plus efficace. De plus, nous explorons la scalabilité de ce paradigme d'amélioration automatique en investiguant l'optimisation itérative de la capacité de correction d'erreurs et de la construction d'ensembles de données d'évaluation. Nos résultats montrent que Agent-R améliore continuellement la capacité de récupération d'erreurs du modèle et permet la modification des erreurs en temps réel. Des expériences dans trois environnements d'interaction montrent que Agent-R fonctionne efficacement pour corriger des erreurs et atteint un rendement supérieur au méthode de référence (+5.59%).",
      "upvotes": 13,
      "discussionId": "6790802b8ad1d8203a994fc7"
    },
    "publishedAt": "2025-01-22T00:20:57.292Z",
    "title": "Agent-R: Training Language Model Agents to Reflect via Iterative Self-Training",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.11425.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5732
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.12273",
      "authors": [
        {
          "_id": "67906c674932687e24e0cc08",
          "name": "Maosong Cao",
          "hidden": false
        },
        {
          "_id": "67906c674932687e24e0cc09",
          "name": "Taolin Zhang",
          "hidden": false
        },
        {
          "_id": "67906c674932687e24e0cc0a",
          "name": "Mo Li",
          "hidden": false
        },
        {
          "_id": "67906c674932687e24e0cc0b",
          "name": "Chuyu Zhang",
          "hidden": false
        },
        {
          "_id": "67906c674932687e24e0cc0c",
          "name": "Yunxin Liu",
          "hidden": false
        },
        {
          "_id": "67906c674932687e24e0cc0d",
          "name": "Haodong Duan",
          "hidden": false
        },
        {
          "_id": "67906c674932687e24e0cc0e",
          "name": "Songyang Zhang",
          "hidden": false
        },
        {
          "_id": "67906c674932687e24e0cc0f",
          "name": "Kai Chen",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-21T16:44:12.000Z",
      "title": "Condor : Amélioration du rendement des modèles de langage d'intelligence artificielle par la synthèse et l'édition de données basée sur le savoir",
      "summary": "La qualité des données de Fine-Tuning Supervisé (SFT) joue un rôle crucial dans l'amélioration des compétences de conversation des Modèles de Langage Grands (LLMs). Cependant, lorsque les LLMs évoluent, la capacité à utiliser des données de SFT de haute qualité et annotées par des humains est devenue une limite importante, ce qui a augmenté la dépendance aux données synthétiques. Dans cet article, nous présentons un nouveau cadre de travail de génération de données synthétiques en deux étapes, appelé Condor, qui combine l'Arbre de Connaissances Mondiales et la Réflexion Auto-Refinament. Cette approche vise à générer des données de SFT de haute qualité et scalable. Les résultats des expérimentations montrent que l'application de 20K échantillons générés par Condor au modèle de base permet un comportement exceptionnel et confirme sa supériorité par rapport à d'autres modèles comparatifs. Les étapes supplémentaires d'amélioration de Condor permettent une amélioration automatique itérative à différentes échelles de LLMs (jusqu'à 72B), démontrant l'efficacité de notre approche. De plus, la recherche sur la scalabilité des données synthétiques montre une grande possibilité d'amélioration du rendement après l'entraînement, ouvrant des voies prometteuses pour des recherches futures.",
      "upvotes": 7,
      "discussionId": "67906c684932687e24e0cc61"
    },
    "publishedAt": "2025-01-21T22:56:36.701Z",
    "title": "Condor: Enhance LLM Alignment with Knowledge-Driven Data Synthesis and Refinement",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.12273.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "630716d11801ecc7d2595021",
      "avatarUrl": "/avatars/2d36a880ce4a3cf7efc5ff3987dbeaf3.svg",
      "fullname": "Songyang Zhang",
      "name": "zsytony",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 14
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.11733",
      "authors": [
        {
          "_id": "6790791b203b95acf96ebf45",
          "user": {
            "_id": "628d7265db4cd1d1717c884f",
            "avatarUrl": "/avatars/dff2a3dd10d84b4a73fa486402de7219.svg",
            "isPro": false,
            "fullname": "Zhenhailong Wang",
            "user": "mikewang",
            "type": "user"
          },
          "name": "Zhenhailong Wang",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-01-22T04:50:40.468Z",
          "hidden": false
        },
        {
          "_id": "6790791b203b95acf96ebf46",
          "name": "Haiyang Xu",
          "hidden": false
        },
        {
          "_id": "6790791b203b95acf96ebf47",
          "name": "Junyang Wang",
          "hidden": false
        },
        {
          "_id": "6790791b203b95acf96ebf48",
          "name": "Xi Zhang",
          "hidden": false
        },
        {
          "_id": "6790791b203b95acf96ebf49",
          "name": "Ming Yan",
          "hidden": false
        },
        {
          "_id": "6790791b203b95acf96ebf4a",
          "name": "Ji Zhang",
          "hidden": false
        },
        {
          "_id": "6790791b203b95acf96ebf4b",
          "name": "Fei Huang",
          "hidden": false
        },
        {
          "_id": "6790791b203b95acf96ebf4c",
          "name": "Heng Ji",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-20T20:35:46.000Z",
      "title": "Móvil-agente-E : Automatique pour des tâches complexes d'assistant mobile",
      "summary": "Le smartphone a acquis une position essentielle dans la vie moderne, mais parfois il ressent une insatisfaction lorsqu'il s'agit de réaliser des tâches complexes. Récemment, le développement d'agents mobiles basés sur des modèles de grandes multimodalités (LMM) a démontré la possibilité de reconnaissance et d'action dans des environnements mobiles. Cependant, l'approche actuelle présente des limites : elle ne satisfait pas les besoins réels des personnes, elle est difficile à utiliser pour traiter des tâches logiques et à long terme, et elle n'a pas une structure qui permet d'apprendre et d'améliorer à partir d'expériences antérieures. Pour résoudre ces problèmes, nous présentons le cadre d'agents mobiles évolutifs, Mobile-Agent-E, qui s'inspire des expériences passées et peut autoévoluer. Le terme « heuristique » fait référence à la claire distinction entre la planification d'un haut niveau et l'exécution d'actions de bas niveau. Ce cadre est composé de quatre agents subordonnés : Manager, Percepteur, Opérateur, Action Reflector et Notetaker. Le Percepteur est chargé du reconnaissance visuelle détaillée, l'Opérateur de l'exécution immédiate d'actions, l'Action Reflector de la vérification d'erreurs et le Notetaker de la récolte d'informations. Mobile-Agent-E introduit un nouveau module d'autoévolution qui se compose de conseils généraux et d'enseignements obtenus à partir de travaux antérieurs, ainsi qu'une liste d'opérations primaires réutilisables pour des sous-routines spécifiques. L'introduction de conseils et de court-circuits permet une amélioration continue du rendement et de l'efficacité. De plus, nous présentons Mobile-Eval-E, un nouveau cadre de référence qui inclut des tâches à long terme et l'interaction entre plusieurs applications. Les résultats des expériences montrent que Mobile-Agent-E, grâce à trois modèles basiques, atteint un accroissement absolu de 22% par rapport aux méthodes optimales précédentes. Le site web du projet est disponible sur https://x-plug.github.io/MobileAgent.",
      "upvotes": 5,
      "discussionId": "67907920203b95acf96ec126"
    },
    "publishedAt": "2025-01-22T00:17:48.799Z",
    "title": "Mobile-Agent-E: Self-Evolving Mobile Assistant for Complex Tasks",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.11733.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "645b10e80c73ea27d13f7aca",
      "avatarUrl": "/avatars/95e565306472a15067440b5b43e07a6f.svg",
      "fullname": "xuhaiyang",
      "name": "xhyandwyy",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.10687",
      "authors": [
        {
          "_id": "6790856e3b0a6384a4117d0e",
          "name": "Linrui Tian",
          "hidden": false
        },
        {
          "_id": "6790856e3b0a6384a4117d0f",
          "name": "Siqi Hu",
          "hidden": false
        },
        {
          "_id": "6790856e3b0a6384a4117d10",
          "name": "Qi Wang",
          "hidden": false
        },
        {
          "_id": "6790856e3b0a6384a4117d11",
          "name": "Bang Zhang",
          "hidden": false
        },
        {
          "_id": "6790856e3b0a6384a4117d12",
          "name": "Liefeng Bo",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-18T07:51:29.000Z",
      "title": "EMO2 : Génération Audio Live de la Chaîne Laser de l'Effet Terminal",
      "summary": "Dans cet article, nous proposons une nouvelle technique de tête de tableau de voix. Cette technique permet de générer des expressions faciales et des mouvements des mains de haute qualité en même temps. Les méthodes existantes se concentraient sur la génération d'une partie ou la moitié de la position, mais nous considérons que la faible relation entre les caractéristiques du parler et les mouvements des mains est un principal limite, ce qui nous a conduits à redéfinir le processus en deux étapes. Dans la première étape, une position des mains est générée directement à partir du parler, en utilisant la forte association entre le parler et les mouvements des mains. Dans la deuxième étape, un modèle de dispersion est utilisé pour synthétiser les cadres vidéo incluant la position des mains générée, créant des expressions réalistes et des mouvements corporels. Les résultats des expériences montrent que notre proposition est supérieure en termes de qualité visuelle et de précision de synchronisation par rapport aux méthodes les plus avancées (CyberHost, Vlogger). Cette recherche offre une nouvelle perspective sur la génération de la manipulation de la voix et fournit un solide cadre pour la création d'animations de tête de tableau expressives et naturelles.",
      "upvotes": 3,
      "discussionId": "679085813b0a6384a41183f1"
    },
    "publishedAt": "2025-01-22T00:49:10.316Z",
    "title": "EMO2: End-Effector Guided Audio-Driven Avatar Video Generation",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.10687.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "65df1f1ee98700500d4c289c",
      "avatarUrl": "/avatars/be11bf61465df29ac997cc0fedad1cb9.svg",
      "fullname": "qi wang",
      "name": "lucaskingjade",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.12326",
      "authors": [
        {
          "_id": "679078f902b4d94b0f2347c1",
          "name": "Yujia Qin",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347c2",
          "name": "Yining Ye",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347c3",
          "name": "Junjie Fang",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347c4",
          "name": "Haoming Wang",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347c5",
          "name": "Shihao Liang",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347c6",
          "name": "Shizuo Tian",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347c7",
          "name": "Junda Zhang",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347c8",
          "name": "Jiahao Li",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347c9",
          "name": "Yunxin Li",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347ca",
          "name": "Shijue Huang",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347cb",
          "name": "Wanjun Zhong",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347cc",
          "name": "Kuanye Li",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347cd",
          "name": "Jiale Yang",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347ce",
          "name": "Yu Miao",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347cf",
          "name": "Woyu Lin",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347d0",
          "name": "Longxiang Liu",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347d1",
          "name": "Xu Jiang",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347d2",
          "name": "Qianli Ma",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347d3",
          "name": "Jingyu Li",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347d4",
          "name": "Xiaojun Xiao",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347d5",
          "name": "Kai Cai",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347d6",
          "name": "Chuang Li",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347d7",
          "name": "Yaowei Zheng",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347d8",
          "name": "Chaolin Jin",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347d9",
          "name": "Chen Li",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347da",
          "name": "Xiao Zhou",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347db",
          "name": "Minchao Wang",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347dc",
          "name": "Haoli Chen",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347dd",
          "name": "Zhaojian Li",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347de",
          "name": "Haihua Yang",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347df",
          "name": "Haifeng Liu",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347e0",
          "name": "Feng Lin",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347e1",
          "name": "Tao Peng",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347e2",
          "name": "Xin Liu",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347e3",
          "name": "Guang Shi",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-21T17:48:10.000Z",
      "title": "UI-TARS : Guide de production leader en l'interaction de UI-TARS",
      "summary": "Dans cet article, nous présentons un modèle d'intelligence artificielle (IA) appelé \"UI-TARS\", utilisé pour traiter des captures de écran comme entrée directe, mais qui peut également interagir de manière humaine. Ce modèle, \"UI-TARS\", dépasse les modèles professionnels tels que GPT-4o qui dépendent de modèles de business répétitifs, démontrant une excellente performance dans les tâches de frontend. Les expériences réalisées sur plus de 10 cadres de référence d'agents de GUI pour évaluer l'exploration visuelle, les tâches de GUI et l'évaluation de la profondeur, ont montré que \"UI-TARS\" est le meilleur de sa catégorie. En particulier, dans le benchmark OSWorld, il a atteint un score de 24,6 sur 50 étapes et 22,7 sur 15 étapes, dépassant Claude (22,0 et 14,9). Dans AndroidWorld, il a atteint un score de 46,6, dépassant GPT-4o (34,5). \"UI-TARS\" introduit les nouveautés suivantes : (1) visualisation expérimentale : utilise de grands ensembles de données de captures d'écran pour comprendre et capturer précisément les éléments de l'interface utilisateur (UI) dans leur contexte. (2) modélisation intégrée des actions : uniformise les actions entre plateformes et réalise une exploration profonde et des interactions précises à travers une grande quantité de traces d'actions. (3) raisonnement de système 2 : inclut la perception de raisons incorrectes dans les décisions multi-étapes, et incorpore des modèles de raisonnement comme la décomposition des tâches, le pensée réflexive et le reconnaissance de milestones, atteignant une perception qui inclut plusieurs raisons. (4) apprentissage itératif par des traces réflexives en ligne : collecte, filtre et améliore automatiquement de nouvelles interactions en fonction de milliers de machines basiques, résolvant les problèmes de données et s'adaptant à des situations inattendues avec une intervention humaine minimale. A travers l'analyse du chemin de l'évolution des agents de GUI et son guide pour le développement de la technologie, \"UI-TARS\" contribue à l'évolution de ce domaine.",
      "upvotes": 3,
      "discussionId": "679078ff02b4d94b0f2348e0"
    },
    "publishedAt": "2025-01-21T23:51:53.248Z",
    "title": "UI-TARS: Pioneering Automated GUI Interaction with Native Agents",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.12326.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5732
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.11223",
      "authors": [
        {
          "_id": "6790772b8d7df822f1fb4405",
          "name": "Maciej Besta",
          "hidden": false
        },
        {
          "_id": "6790772b8d7df822f1fb4406",
          "name": "Julia Barth",
          "hidden": false
        },
        {
          "_id": "6790772b8d7df822f1fb4407",
          "name": "Eric Schreiber",
          "hidden": false
        },
        {
          "_id": "6790772b8d7df822f1fb4408",
          "name": "Ales Kubicek",
          "hidden": false
        },
        {
          "_id": "6790772b8d7df822f1fb4409",
          "name": "Afonso Catarino",
          "hidden": false
        },
        {
          "_id": "6790772b8d7df822f1fb440a",
          "name": "Robert Gerstenberger",
          "hidden": false
        },
        {
          "_id": "6790772b8d7df822f1fb440b",
          "name": "Piotr Nyczyk",
          "hidden": false
        },
        {
          "_id": "6790772b8d7df822f1fb440c",
          "name": "Patrick Iff",
          "hidden": false
        },
        {
          "_id": "6790772b8d7df822f1fb440d",
          "name": "Yueling Li",
          "hidden": false
        },
        {
          "_id": "6790772b8d7df822f1fb440e",
          "name": "Sam Houliston",
          "hidden": false
        },
        {
          "_id": "6790772b8d7df822f1fb440f",
          "name": "Tomasz Sternal",
          "hidden": false
        },
        {
          "_id": "6790772b8d7df822f1fb4410",
          "name": "Marcin Copik",
          "hidden": false
        },
        {
          "_id": "6790772b8d7df822f1fb4411",
          "name": "Grzegorz Kwaśniewski",
          "hidden": false
        },
        {
          "_id": "6790772b8d7df822f1fb4412",
          "name": "Jürgen Müller",
          "hidden": false
        },
        {
          "_id": "6790772b8d7df822f1fb4413",
          "name": "Łukasz Flis",
          "hidden": false
        },
        {
          "_id": "6790772b8d7df822f1fb4414",
          "name": "Hannes Eberhard",
          "hidden": false
        },
        {
          "_id": "6790772b8d7df822f1fb4415",
          "name": "Hubert Niewiadomski",
          "hidden": false
        },
        {
          "_id": "6790772b8d7df822f1fb4416",
          "name": "Torsten Hoefler",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-20T02:16:19.000Z",
      "title": "Modèle de langage de Riensing : Plan de travail",
      "summary": "Les modèles appelés de Réasonnement de Langue (RLMs) ou Grands Modèles de Réasonnement (LRMs) ont réactualisé la capacité de résolution de problèmes des Grands Modèles de Langue (LLMs) en ajoutant des structures logiques évolutives. Cependant, le haut coût, la propriété, la complexité de l'architecture, en particulier l'apprentissage par renforcement (RL), les heuristiques d'exploration et la combinaison avec les LLMs, génèrent des problèmes d'accessibilité et d'expansion. Pour résoudre ces problèmes, on propose un plan unifié pour intégrer les composants des RLMs dans un cadre modulaire. Ce plan est basé sur la recherche et l'analyse de tous les RLMs. Il inclut diverses structures logiques (séquentielle, arborescente, graphique, mot individuel) et stratégies de raisonnement (par exemple, exploration de l'arbre de Monte Carlo, recherche de rayons), ainsi que des concepts de RL (politiques, modèles de valeur) et des plans d'observation (basés sur l'output, basés sur le processus). De plus, il fournit des formules mathématiques détaillées et des spécifications d'algorithmes pour simplifier l'implémentation des RLMs. Il montre comment ils s'appliquent dans des cas simples comme LLaMA-Berry, QwQ, Journey Learning, et Graph of Thoughts. Il présente également des points clés tels que l'entraînement progressif des modèles de politique et de valeur, l'importance de la distribution de l'observation, etc., à travers x1 et une recherche bibliographique. Enfin, il explique comment les RLMs sont intégrés dans une large écosystème de LLMs. Notre étude vise à expliquer la construction des RLMs, à démocratiser les capacités évolutives de la raisonnement, à encourager l'innovation, et à réduire la différence entre \"AI pleine\" et \"AI vide\" en baissant les barrières de développement et d'expérimentation des RLMs.",
      "upvotes": 3,
      "discussionId": "6790772d8d7df822f1fb4493"
    },
    "publishedAt": "2025-01-21T23:42:44.747Z",
    "title": "Reasoning Language Models: A Blueprint",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.11223.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5732
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.12390",
      "authors": [
        {
          "_id": "67906d622ae55818ddfd0d93",
          "name": "Chao Feng",
          "hidden": false
        },
        {
          "_id": "67906d622ae55818ddfd0d94",
          "name": "Ziyang Chen",
          "hidden": false
        },
        {
          "_id": "67906d622ae55818ddfd0d95",
          "name": "Aleksander Holynski",
          "hidden": false
        },
        {
          "_id": "67906d622ae55818ddfd0d96",
          "name": "Alexei A. Efros",
          "hidden": false
        },
        {
          "_id": "67906d622ae55818ddfd0d97",
          "name": "Andrew Owens",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-21T18:59:46.000Z",
      "title": "Utiliser GPS comme signaux de contrôle pour la génération d'images",
      "summary": "Les images de données comportant des étiquettes GPS sont présentées comme des signaux de contrôle utiles pour la génération d'images. Les GPS sont utilisées pour entraîner des modèles d'images et pour réaliser des tâches complexes pour comprendre les petits changements dans les images urbaines. En particulier, un modèle de génération conditionnelle est entraîné en considérant à la fois les GPS et les phrases. Ce modèle entraîné génère des images qui détectent des caractéristiques particulières de quartiers, parcs et marques géographiques. De plus, un modèle 3D est extrait grâce au sampling de points de score en utilisant les GPS 2D. Les caractéristiques reconstruites à partir de chaque point de vue sont contrôlées en utilisant des conditions GPS. En évaluation, il est observé que les modèles conditionnels avec GPS peuvent générer des changements dans les images en fonction de la localisation, et que les conditions GPS améliorent la structure 3D inférée.",
      "upvotes": 3,
      "discussionId": "67906d682ae55818ddfd0f53"
    },
    "publishedAt": "2025-01-21T23:41:48.239Z",
    "title": "GPS as a Control Signal for Image Generation",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.12390.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "645ab0b7c266796265baefa4",
      "avatarUrl": "/avatars/bdac661996b63c4b2a56881707afa01f.svg",
      "fullname": "Chao Feng",
      "name": "chfeng",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.12202",
      "authors": [
        {
          "_id": "67908409416b83605450716a",
          "name": "Zibo Zhao",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450716b",
          "name": "Zeqiang Lai",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450716c",
          "name": "Qingxiang Lin",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450716d",
          "name": "Yunfei Zhao",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450716e",
          "name": "Haolin Liu",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450716f",
          "name": "Shuhui Yang",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507170",
          "name": "Yifei Feng",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507171",
          "name": "Mingxin Yang",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507172",
          "name": "Sheng Zhang",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507173",
          "name": "Xianghui Yang",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507174",
          "name": "Huiwen Shi",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507175",
          "name": "Sicong Liu",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507176",
          "name": "Junta Wu",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507177",
          "name": "Yihang Lian",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507178",
          "name": "Fan Yang",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507179",
          "name": "Ruining Tang",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450717a",
          "name": "Zebin He",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450717b",
          "name": "Xinzhou Wang",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450717c",
          "name": "Jian Liu",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450717d",
          "name": "Xuhui Zuo",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450717e",
          "name": "Zhuo Chen",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450717f",
          "name": "Biwen Lei",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507180",
          "name": "Haohan Weng",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507181",
          "name": "Jing Xu",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507182",
          "name": "Yiling Zhu",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507183",
          "name": "Xinhai Liu",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507184",
          "name": "Lixin Xu",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507185",
          "name": "Changrong Hu",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507186",
          "name": "Tianyu Huang",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507187",
          "name": "Lifu Wang",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507188",
          "name": "Jihong Zhang",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507189",
          "name": "Meng Chen",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450718a",
          "name": "Liang Dong",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450718b",
          "name": "Yiwen Jia",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450718c",
          "name": "Yulin Cai",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450718d",
          "name": "Jiaao Yu",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450718e",
          "name": "Yixuan Tang",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450718f",
          "name": "Hao Zhang",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507190",
          "name": "Zheng Ye",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507191",
          "name": "Peng He",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507192",
          "name": "Runzhou Wu",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507193",
          "name": "Chao Zhang",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507194",
          "name": "Yonghao Tan",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507195",
          "name": "Jie Xiao",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507196",
          "name": "Yangyu Tao",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507197",
          "name": "Jianchen Zhu",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507198",
          "name": "Jinbao Xue",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507199",
          "name": "Kai Liu",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450719a",
          "name": "Chongqing Zhao",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450719b",
          "name": "Xinming Wu",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450719c",
          "name": "Zhichao Hu",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450719d",
          "name": "Lei Qin",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450719e",
          "name": "Jianbing Peng",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450719f",
          "name": "Zhan Li",
          "hidden": false
        },
        {
          "_id": "67908409416b8360545071a0",
          "name": "Minghui Chen",
          "hidden": false
        },
        {
          "_id": "67908409416b8360545071a1",
          "name": "Xipeng Zhang",
          "hidden": false
        },
        {
          "_id": "67908409416b8360545071a2",
          "name": "Lin Niu",
          "hidden": false
        },
        {
          "_id": "67908409416b8360545071a3",
          "name": "Paige Wang",
          "hidden": false
        },
        {
          "_id": "67908409416b8360545071a4",
          "name": "Yingkai Wang",
          "hidden": false
        },
        {
          "_id": "67908409416b8360545071a5",
          "name": "Haozhao Kuang",
          "hidden": false
        },
        {
          "_id": "67908409416b8360545071a6",
          "name": "Zhongyi Fan",
          "hidden": false
        },
        {
          "_id": "67908409416b8360545071a7",
          "name": "Xu Zheng",
          "hidden": false
        },
        {
          "_id": "67908409416b8360545071a8",
          "name": "Weihao Zhuang",
          "hidden": false
        },
        {
          "_id": "67908409416b8360545071a9",
          "name": "YingPing He",
          "hidden": false
        },
        {
          "_id": "67908409416b8360545071aa",
          "name": "Tian Liu",
          "hidden": false
        },
        {
          "_id": "67908409416b8360545071ab",
          "name": "Yong Yang",
          "hidden": false
        },
        {
          "_id": "67908409416b8360545071ac",
          "name": "Di Wang",
          "hidden": false
        },
        {
          "_id": "67908409416b8360545071ad",
          "name": "Yuhong Liu",
          "hidden": false
        },
        {
          "_id": "67908409416b8360545071ae",
          "name": "Jie Jiang",
          "hidden": false
        },
        {
          "_id": "67908409416b8360545071af",
          "name": "Jingwei Huang",
          "hidden": false
        },
        {
          "_id": "67908409416b8360545071b0",
          "name": "Chunchao Guo",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-21T15:16:54.000Z",
      "title": "Formyn 3D 2.0 : Modèle de diffuseur étendu pour la génération de bibliothèques de pilotes de texture à haute résolution",
      "summary": "El Hunyuan 3D 2.0 introduit un système de synthèse 3D à grande échelle de haute qualité. Ce système est utilisé pour créer des ressources 3D à haute résolution. Ce système comprend deux composants clés : le modèle de génération de formes à grande échelle \"Hunyuan3D-DiT\" et le modèle de synthèse de textures à grande échelle \"Hunyuan3D-Paint\". Le modèle de formes est construit avec un transformateur basé sur une diffusion scalable, avec l'objectif de générer des géométries qui s'adaptent aux images de condition données. Cela fournit une base solide pour des applications ultérieures. Le modèle de textures est basé sur une forte géométrie et des priorités de diffusion, créant des cartes de texture à haute résolution et de richesse pour n'importe quelle maille générée ou créée manuellement. De plus, un développement de Hunyuan3D-Studio, un environnement de production amiable pour l'utilisateur, a simplifié le processus de réconfiguration de ressources 3D. Cela a permis aux professionnels et aux fanatiques de manipuler des mailles et de réaliser des animations. L'évaluation systématique du modèle montre que Hunyuan3D 2.0 dépasse les modèles précédents en termes de détails de géométrie, de cohérence de condition et de qualité de texture. Hunyuan3D 2.0 a été publié pour compléter les lacunes du comité ouvert de génération de modèles 3D à grande échelle. Le code du modèle et l'entraînement précédent sont disponibles sur la URL suivante :\nhttps://github.com/Tencent/Hunyuan3D-2",
      "upvotes": 1,
      "discussionId": "6790840d416b8360545072a7"
    },
    "publishedAt": "2025-01-22T00:37:32.486Z",
    "title": "Hunyuan3D 2.0: Scaling Diffusion Models for High Resolution Textured 3D Assets Generation",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.12202.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5732
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.10893",
      "authors": [
        {
          "_id": "67907dd5e1d8fc832b3e7b0f",
          "name": "Hongjin Su",
          "hidden": false
        },
        {
          "_id": "67907dd5e1d8fc832b3e7b10",
          "name": "Ruoxi Sun",
          "hidden": false
        },
        {
          "_id": "67907dd5e1d8fc832b3e7b11",
          "name": "Jinsung Yoon",
          "hidden": false
        },
        {
          "_id": "67907dd5e1d8fc832b3e7b12",
          "name": "Pengcheng Yin",
          "hidden": false
        },
        {
          "_id": "67907dd5e1d8fc832b3e7b13",
          "name": "Tao Yu",
          "hidden": false
        },
        {
          "_id": "67907dd5e1d8fc832b3e7b14",
          "name": "Sercan Ö. Arık",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-18T22:34:41.000Z",
      "title": "Apprentissage dans un environnement réel : cadre de données centré pour des programmes d'ajustement automatique de sortie dans des environnements réels",
      "summary": "Les modèles de langage automatiques (LLMs) basés sur des autonomies peuvent améliorer les capacités humaines et aider dans des tâches digitales, allant de la transmission de courriels à l'analyse de données. Les LLMs actuels sont limités dans ces tâches en raison des interactions entre les agents et les environnements qui nécessitent des données de qualité élevée. Nous proposons un cadre centré sur les données pour adapter les LLMs aux environnements sans nécessiter d'instructions, appelé \"apprendre pour s'adapter\". \"Apprendre pour s'adapter\" synthétise la trajectoire d'interaction entre l'agent basé sur les documents et l'environnement, résume ou abstrait l'historique d'interaction pour construire des commandes, ce qui est appelé \"construction rétroactionnelle\". Nous évaluons la qualité des données sans apprentissage via des scénarios basés sur l'apprentissage et l'apprentissage en contexte (ICL) sans apprentissage. Nous développons un accès externe à la recherche et optimisons l'agent. Dans des expériences réelles dans des environnements de codification, web et bureautique comme SWE-bench, WebArena, OSWorld et Spider2-V, \"apprendre pour s'adapter\" a montré des effets sur diverses tâches d'agents. Les résultats de l'ICL montrent un augmentation de 12,2% pour Claude-3,5 et de 19,5% pour Codestral-22B. De plus, il a démontré l'importance de la construction rétroactionnelle avec un augmentation de 14,0%. Notre étude de validation a démontré l'efficacité des données sans apprentissage dans l'ICL et la supériorité de notre pipeline de recherche. On espère l'introduction des LLMs dans des environnements réels et globaux.",
      "upvotes": 1,
      "discussionId": "67907dd9e1d8fc832b3e7c36"
    },
    "publishedAt": "2025-01-22T00:11:18.322Z",
    "title": "Learn-by-interact: A Data-Centric Framework for Self-Adaptive Agents in Realistic Environments",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.10893.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5732
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.11873",
      "authors": [
        {
          "_id": "679071da11a3f67d8f498649",
          "name": "Zihan Qiu",
          "hidden": false
        },
        {
          "_id": "679071da11a3f67d8f49864a",
          "name": "Zeyu Huang",
          "hidden": false
        },
        {
          "_id": "679071da11a3f67d8f49864b",
          "name": "Bo Zheng",
          "hidden": false
        },
        {
          "_id": "679071da11a3f67d8f49864c",
          "name": "Kaiyue Wen",
          "hidden": false
        },
        {
          "_id": "679071da11a3f67d8f49864d",
          "name": "Zekun Wang",
          "hidden": false
        },
        {
          "_id": "679071da11a3f67d8f49864e",
          "name": "Rui Men",
          "hidden": false
        },
        {
          "_id": "679071da11a3f67d8f49864f",
          "name": "Ivan Titov",
          "hidden": false
        },
        {
          "_id": "679071da11a3f67d8f498650",
          "name": "Dayiheng Liu",
          "hidden": false
        },
        {
          "_id": "679071da11a3f67d8f498651",
          "name": "Jingren Zhou",
          "hidden": false
        },
        {
          "_id": "679071da11a3f67d8f498652",
          "name": "Junyang Lin",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-21T04:04:39.000Z",
      "title": "Démocratisation de l'entretien : Mise en œuvre de perte de balance en bas pendant l'entraînement avec un modèle expert dans le domaine.",
      "summary": "Cet article examine l'implémentation du Loss de Balance de Charge (LBL) lors de l'entraînement de modèles Mixture-of-Experts (MoEs). Spécifiquement, le LBL des MoEs est défini comme N_E somme_{i=1}^{N_E} f_i p_i, où N_E est le nombre total d'experts, f_i est la fréquence de sélection de l'i-ème expert et p_i est le score moyen de gestion du i-ème expert. Le cadre actuel d'entraînement des MoEs utilise généralement des stratégies d'entraînement parallèles, où f_i et le LBL sont calculés dans des micro-batches et sont ensuite moyens dans des groupes parallèles correspondants. Fondamentalement, les micro-batches incluent très peu de séquences lors de l'entraînement de LLMs à grande échelle. Par conséquent, le LBL des micro-batches est presque à l'échelle de séquence, ce qui applique une pression pour répartir équitablement les tokens à l'intérieur de chaque séquence. Sous ces strictes contraintes, les tokens dans des séquences de spécialisation des experts (par exemple, du code) sont répartis équitablement entre tous les experts, ce qui inhibe la spécialisation des experts. Dans cette étude, il est proposé de libérer les contraintes des micro-batches et de calculer le LBL en utilisant un batch global. Ce batch global inclut des séquences très diverses par rapport aux micro-batches, ce qui favorise un équilibre de charge à l'échelle du corpus. Spécifiquement, un pas supplémentaire de communication est ajouté pour synchroniser f_i entre les micro-batches et pour utiliser cela pour calculer le LBL. Les expérimentations d'entraînement de LLMs basées sur des MoEs (avec un total de paramètres jusqu'à 42,8B et jusqu'à 400B de tokens) montrent une amélioration excellente du rendement, ainsi que de la prédiction avec la stratégie de LBL du batch global. Selon l'analyse, le LBL du batch global améliore significativement la spécialisation des experts dans les MoEs.",
      "upvotes": 1,
      "discussionId": "679071db11a3f67d8f498680"
    },
    "publishedAt": "2025-01-21T23:27:52.660Z",
    "title": "Demons in the Detail: On Implementing Load Balancing Loss for Training Specialized Mixture-of-Expert Models",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/647ccbd6e07cf9bb2d485244/ddUbQV_yVPwD6P0TSR5lu.png",
      "https://cdn-uploads.huggingface.co/production/uploads/647ccbd6e07cf9bb2d485244/f7Q4QULppOygZlsYBUvY9.png",
      "https://cdn-uploads.huggingface.co/production/uploads/647ccbd6e07cf9bb2d485244/9Jwx37bQkCjaWcccWbJ7b.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.11873.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "647ccbd6e07cf9bb2d485244",
      "avatarUrl": "/avatars/e8915abaff04f6762247e196b7cf84df.svg",
      "fullname": "Zihan Qiu",
      "name": "QwQZh",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 3
    },
    "isAuthorParticipating": false
  }
]