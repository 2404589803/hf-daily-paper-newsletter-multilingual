[
  {
    "paper": {
      "id": "2505.02550",
      "authors": [
        {
          "_id": "6819ef0b2ff435c58da4d860",
          "user": {
            "_id": "63ecbccac8827dd0f0f59579",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63ecbccac8827dd0f0f59579/kz-2F9Z0QKllifgZmr8tH.jpeg",
            "isPro": false,
            "fullname": "Chris Ociepa",
            "user": "chrisociepa",
            "type": "user"
          },
          "name": "Krzysztof Ociepa",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-12T09:03:56.213Z",
          "hidden": false
        },
        {
          "_id": "6819ef0b2ff435c58da4d861",
          "name": "Łukasz Flis",
          "hidden": false
        },
        {
          "_id": "6819ef0b2ff435c58da4d862",
          "user": {
            "_id": "61786d0b038518aa2827c6b7",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/61786d0b038518aa2827c6b7/d1UnfivoVreYebS5JM3P9.jpeg",
            "isPro": false,
            "fullname": "Remek Kinas",
            "user": "Remek",
            "type": "user"
          },
          "name": "Remigiusz Kinas",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-12T06:51:15.217Z",
          "hidden": false
        },
        {
          "_id": "6819ef0b2ff435c58da4d863",
          "user": {
            "_id": "5e47d3eb178ca95365287400",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1633554153914-5e47d3eb178ca95365287400.png",
            "isPro": true,
            "fullname": "Krzysztof Wróbel",
            "user": "djstrong",
            "type": "user"
          },
          "name": "Krzysztof Wróbel",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-12T09:03:54.135Z",
          "hidden": false
        },
        {
          "_id": "6819ef0b2ff435c58da4d864",
          "name": "Adrian Gwoździej",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-05T10:39:51.000Z",
      "submittedOnDailyAt": "2025-05-12T07:26:20.895Z",
      "title": "Bielik v3 Small : Rapport Technique",
      "submittedOnDailyBy": {
        "_id": "5e47d3eb178ca95365287400",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1633554153914-5e47d3eb178ca95365287400.png",
        "isPro": true,
        "fullname": "Krzysztof Wróbel",
        "user": "djstrong",
        "type": "user"
      },
      "summary": "Introduis la version 3 de BEVERICK. Ce modèle fait partie de la série de modèles génératifs de texte efficaces en paramètres, optimisé pour le traitement du polonais à des tailles de 1,5B et 4,5B. Ces modèles peuvent atteindre les performances de grands modèles avec un taille relativement petit, réduisant significativement la quantité de ressources informatiques utilisées. Notre approche comprend plusieurs innovations clés. Parmi elles, on trouve le Tokenizer Adapté pour le Polonais (APT4), conçu pour améliorer l'efficacité des tokens, l'équilibre entre l'apprentissage de types de commandes par la perte d'entropie croisée pondérée, et un apprentissage de ratio d'apprentissage adaptatif qui se ajuste dynamiquement pendant le processus d'apprentissage. Il a été entraîné sur un corpus de 292 milliards de tokens filtrés, composé de 303 millions d'articles. Ces modèles ont obtenu des résultats exceptionnels sur plusieurs benchmarks, y compris le Open PL LLM Leaderboard, le Benchmark de Compréhension du Texte Polonais, le Benchmark EQ-Bench Polonais et le Leaderboard de Médecine Polonais. Le modèle de 4,5B paramètres a obtenu des résultats compétitifs par rapport à des modèles deux à trois fois plus grands, tandis que le modèle de 1,5B offre un rendement robuste même dans des profils très petits. Ces avancées établissent de nouveaux standards d'efficacité dans la modélisation des langues et facilitent l'accès à une IA de haute qualité en polonais dans des applications avec des limitations de ressources.",
      "upvotes": 16,
      "discussionId": "6819ef0c2ff435c58da4d892",
      "projectPage": "https://bielik.ai/",
      "githubRepo": "https://github.com/speakleash",
      "ai_keywords": [
        "parameter-efficient",
        "generative text models",
        "token efficiency",
        "custom Polish tokenizer",
        "Weighted Instruction Cross-Entropy Loss",
        "Adaptive Learning Rate"
      ]
    },
    "publishedAt": "2025-05-05T06:39:51.000Z",
    "title": "Bielik v3 Small: Technical Report",
    "summary": "We introduce Bielik v3, a series of parameter-efficient generative text\nmodels (1.5B and 4.5B) optimized for Polish language processing. These models\ndemonstrate that smaller, well-optimized architectures can achieve performance\ncomparable to much larger counterparts while requiring substantially fewer\ncomputational resources. Our approach incorporates several key innovations: a\ncustom Polish tokenizer (APT4) that significantly improves token efficiency,\nWeighted Instruction Cross-Entropy Loss to balance learning across instruction\ntypes, and Adaptive Learning Rate that dynamically adjusts based on training\nprogress. Trained on a meticulously curated corpus of 292 billion tokens\nspanning 303 million documents, these models excel across multiple benchmarks,\nincluding the Open PL LLM Leaderboard, Complex Polish Text Understanding\nBenchmark, Polish EQ-Bench, and Polish Medical Leaderboard. The 4.5B parameter\nmodel achieves results competitive with models 2-3 times its size, while the\n1.5B model delivers strong performance despite its extremely compact profile.\nThese advances establish new benchmarks for parameter-efficient language\nmodeling in less-represented languages, making high-quality Polish language AI\nmore accessible for resource-constrained applications.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.02550.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "5e47d3eb178ca95365287400",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1633554153914-5e47d3eb178ca95365287400.png",
      "fullname": "Krzysztof Wróbel",
      "name": "djstrong",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 9
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.02410",
      "authors": [
        {
          "_id": "6819f19e5c7ea9f74284d3a3",
          "user": {
            "_id": "63ecbccac8827dd0f0f59579",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63ecbccac8827dd0f0f59579/kz-2F9Z0QKllifgZmr8tH.jpeg",
            "isPro": false,
            "fullname": "Chris Ociepa",
            "user": "chrisociepa",
            "type": "user"
          },
          "name": "Krzysztof Ociepa",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-12T09:03:52.265Z",
          "hidden": false
        },
        {
          "_id": "6819f19e5c7ea9f74284d3a4",
          "name": "Łukasz Flis",
          "hidden": false
        },
        {
          "_id": "6819f19e5c7ea9f74284d3a5",
          "user": {
            "_id": "5e47d3eb178ca95365287400",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1633554153914-5e47d3eb178ca95365287400.png",
            "isPro": true,
            "fullname": "Krzysztof Wróbel",
            "user": "djstrong",
            "type": "user"
          },
          "name": "Krzysztof Wróbel",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-12T09:03:50.340Z",
          "hidden": false
        },
        {
          "_id": "6819f19e5c7ea9f74284d3a6",
          "name": "Adrian Gwoździej",
          "hidden": false
        },
        {
          "_id": "6819f19e5c7ea9f74284d3a7",
          "user": {
            "_id": "61786d0b038518aa2827c6b7",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/61786d0b038518aa2827c6b7/d1UnfivoVreYebS5JM3P9.jpeg",
            "isPro": false,
            "fullname": "Remek Kinas",
            "user": "Remek",
            "type": "user"
          },
          "name": "Remigiusz Kinas",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-12T06:51:13.426Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-05T07:03:41.000Z",
      "submittedOnDailyAt": "2025-05-12T07:25:02.402Z",
      "title": "InternLM (书生·浦语) est traduit en français comme suit :\n\nRapport Technique de Technologie Biologique 11B v2",
      "submittedOnDailyBy": {
        "_id": "5e47d3eb178ca95365287400",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1633554153914-5e47d3eb178ca95365287400.png",
        "isPro": true,
        "fullname": "Krzysztof Wróbel",
        "user": "djstrong",
        "type": "user"
      },
      "summary": "BiELICK 11B v2, la plus avancée et optimisée pour le traitement du texte polonais, est présentée. Basée sur l'architecture Mistral 7B v0.2, une profonde augmentation de paramètres a été réalisée pour augmenter la quantité de paramètres jusqu'à 11B. Elle montre un excellent rendement sur les benchmarks polonais et possède une forte capacité de cross-linguisme. Deux innovations technologiques principales sont présentées : 1. Perte d'entropie d'instance avec poids : des poids basés sur la masse sont attribués aux échantillons d'entraînement pour optimiser l'apprentissage de différents types d'instances. 2. Apprentissage de la vitesse adaptative : l'ajustement est effectué dynamiquement selon la longueur du contexte. Une évaluation détaillée sur de nombreux benchmarks montre que Bielick 11B v2 dépasse les modèles ayant 2 à 6 fois plus de paramètres, et dépasse significativement les modèles spécialisés polonais dans des tâches allant de la compréhension du langage à l'explication de raisons complexes. L'efficacité des paramètres et les fonctions de dispersion du modèle permettent son introduction dans différentes configurations de matériel, établissant de nouveaux standards de benchmark pour le développement des capacités d'IA polonais et la modélisation du langage de manière efficace en ressources.",
      "upvotes": 16,
      "discussionId": "6819f19e5c7ea9f74284d3cc",
      "projectPage": "https://bielik.ai/",
      "githubRepo": "https://github.com/speakleash",
      "ai_keywords": [
        "Weighted Instruction Cross-Entropy Loss",
        "Adaptive Learning Rate",
        "depth up-scaling",
        "parameter efficiency",
        "quantization"
      ]
    },
    "publishedAt": "2025-05-05T03:03:41.000Z",
    "title": "Bielik 11B v2 Technical Report",
    "summary": "We present Bielik 11B v2, a state-of-the-art language model optimized for\nPolish text processing. Built on the Mistral 7B v0.2 architecture and scaled to\n11B parameters using depth up-scaling, this model demonstrates exceptional\nperformance across Polish language benchmarks while maintaining strong\ncross-lingual capabilities. We introduce two key technical innovations:\nWeighted Instruction Cross-Entropy Loss, which optimizes learning across\ndiverse instruction types by assigning quality-based weights to training\nexamples, and Adaptive Learning Rate, which dynamically adjusts based on\ncontext length. Comprehensive evaluation across multiple benchmarks\ndemonstrates that Bielik 11B v2 outperforms many larger models, including those\nwith 2-6 times more parameters, and significantly surpasses other specialized\nPolish language models on tasks ranging from linguistic understanding to\ncomplex reasoning. The model's parameter efficiency and extensive quantization\noptions enable deployment across various hardware configurations, advancing\nPolish language AI capabilities and establishing new benchmarks for\nresource-efficient language modeling in less-represented languages.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.02410.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "5e47d3eb178ca95365287400",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1633554153914-5e47d3eb178ca95365287400.png",
      "fullname": "Krzysztof Wróbel",
      "name": "djstrong",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 9
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.06046",
      "authors": [
        {
          "_id": "6821af48696b63e207ae8474",
          "user": {
            "_id": "64cb98c6f103036e23c69b1d",
            "avatarUrl": "/avatars/7ee33880ad39f5335b618dc53554124a.svg",
            "isPro": false,
            "fullname": "Harris",
            "user": "Joshua-Harris",
            "type": "user"
          },
          "name": "Joshua Harris",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-12T09:03:48.631Z",
          "hidden": false
        },
        {
          "_id": "6821af48696b63e207ae8475",
          "name": "Fan Grayson",
          "hidden": false
        },
        {
          "_id": "6821af48696b63e207ae8476",
          "name": "Felix Feldman",
          "hidden": false
        },
        {
          "_id": "6821af48696b63e207ae8477",
          "name": "Timothy Laurence",
          "hidden": false
        },
        {
          "_id": "6821af48696b63e207ae8478",
          "name": "Toby Nonnenmacher",
          "hidden": false
        },
        {
          "_id": "6821af48696b63e207ae8479",
          "name": "Oliver Higgins",
          "hidden": false
        },
        {
          "_id": "6821af48696b63e207ae847a",
          "name": "Leo Loman",
          "hidden": false
        },
        {
          "_id": "6821af48696b63e207ae847b",
          "name": "Selina Patel",
          "hidden": false
        },
        {
          "_id": "6821af48696b63e207ae847c",
          "name": "Thomas Finnie",
          "hidden": false
        },
        {
          "_id": "6821af48696b63e207ae847d",
          "name": "Samuel Collins",
          "hidden": false
        },
        {
          "_id": "6821af48696b63e207ae847e",
          "name": "Michael Borowitz",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-09T13:42:59.000Z",
      "submittedOnDailyAt": "2025-05-12T07:35:55.202Z",
      "title": "Santé des LLMs ? Cadre de référence de connaissances des LLMs pour les informations de santé publique du gouvernement du Royaume-Uni",
      "submittedOnDailyBy": {
        "_id": "64cb98c6f103036e23c69b1d",
        "avatarUrl": "/avatars/7ee33880ad39f5335b618dc53554124a.svg",
        "isPro": false,
        "fullname": "Harris",
        "user": "Joshua-Harris",
        "type": "user"
      },
      "summary": "L'expansion des LLM a démontré que l'une compréhension détaillée de l'information est essentielle pour le succès de leur application dans certains domaines. En particulier, en matière de santé publique, la difficulté d'obtenir des informations précises et actualisées peut avoir des conséquences graves pour les citoyens du Royaume-Uni. Cependant, actuellement, on connaît peu ce que les LLM savent sur les informations sanitaires officielles du gouvernement britannique. Pour aborder ce problème, cet article présente un nouveau cadre de référence, appelé PubHealthBench, qui évalue la réponse à des questions à plusieurs réponses correctes (MCQA) et des réponses libres sur la santé publique, offrant plus de 8 000 questions générées automatiquement. De plus, un nouveau ensemble de données a été lancé pour être utilisé comme source de texte de PubHealthBench, qui comprend les directives sanitaires officielles du gouvernement britannique. Les résultats de l'évaluation de 24 LLM dans PubHealthBench montrent que les derniers modèles publics (GPT-4.5, GPT-4.1, o1) ont des niveaux élevés de connaissance, atteignant plus de 90% en MCQA et dépassant les humains utilisant un moteur de recherche pour répondre aux questions et consulter le texte de source. Cependant, aucun modèle ne dépasse 75% en réponses libres. Par conséquent, les meilleurs (SOTA) LLM ont la possibilité d'être un ressource précise d'informations sanitaires ; cependant, pour fournir des réponses libres sur des thèmes de santé publique, des mesures supplémentaires de sécurité et des outils sont nécessaires.",
      "upvotes": 6,
      "discussionId": "6821af49696b63e207ae84c6",
      "ai_keywords": [
        "Large Language Models (LLMs)",
        "Multiple Choice Question Answering (MCQA)",
        "PubHealthBench",
        "UK Government public health information",
        "automated pipeline",
        "extracted UK Government public health guidance documents",
        "SOTA (state of the art) LLMs",
        "GPT-4.5",
        "GPT-4.1",
        "o1"
      ]
    },
    "publishedAt": "2025-05-09T09:42:59.000Z",
    "title": "Healthy LLMs? Benchmarking LLM Knowledge of UK Government Public Health\n  Information",
    "summary": "As Large Language Models (LLMs) become widely accessible, a detailed\nunderstanding of their knowledge within specific domains becomes necessary for\nsuccessful real world use. This is particularly critical in public health,\nwhere failure to retrieve relevant, accurate, and current information could\nsignificantly impact UK residents. However, currently little is known about LLM\nknowledge of UK Government public health information. To address this issue,\nthis paper introduces a new benchmark, PubHealthBench, with over 8000 questions\nfor evaluating LLMs' Multiple Choice Question Answering (MCQA) and free form\nresponses to public health queries, created via an automated pipeline. We also\nrelease a new dataset of the extracted UK Government public health guidance\ndocuments used as source text for PubHealthBench. Assessing 24 LLMs on\nPubHealthBench we find the latest private LLMs (GPT-4.5, GPT-4.1 and o1) have a\nhigh degree of knowledge, achieving >90% in the MCQA setup, and outperform\nhumans with cursory search engine use. However, in the free form setup we see\nlower performance with no model scoring >75%. Therefore, whilst there are\npromising signs that state of the art (SOTA) LLMs are an increasingly accurate\nsource of public health information, additional safeguards or tools may still\nbe needed when providing free form responses on public health topics.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.06046.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "64cb98c6f103036e23c69b1d",
      "avatarUrl": "/avatars/7ee33880ad39f5335b618dc53554124a.svg",
      "fullname": "Harris",
      "name": "Joshua-Harris",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.06111",
      "authors": [
        {
          "_id": "68218b847202d193249511b6",
          "name": "Qingwen Bu",
          "hidden": false
        },
        {
          "_id": "68218b847202d193249511b7",
          "name": "Yanting Yang",
          "hidden": false
        },
        {
          "_id": "68218b847202d193249511b8",
          "name": "Jisong Cai",
          "hidden": false
        },
        {
          "_id": "68218b847202d193249511b9",
          "name": "Shenyuan Gao",
          "hidden": false
        },
        {
          "_id": "68218b847202d193249511ba",
          "user": {
            "_id": "646ec9b135f55eb49e405faa",
            "avatarUrl": "/avatars/a17194be585d20e2a021e77a5a20e213.svg",
            "isPro": false,
            "fullname": "Guanghui Ren",
            "user": "sundrops",
            "type": "user"
          },
          "name": "Guanghui Ren",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-12T06:50:15.305Z",
          "hidden": false
        },
        {
          "_id": "68218b847202d193249511bb",
          "name": "Maoqing Yao",
          "hidden": false
        },
        {
          "_id": "68218b847202d193249511bc",
          "name": "Ping Luo",
          "hidden": false
        },
        {
          "_id": "68218b847202d193249511bd",
          "name": "Hongyang Li",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-09T15:11:13.000Z",
      "submittedOnDailyAt": "2025-05-12T04:30:20.087Z",
      "title": "UniVLA : Utilisant des actions potentielles axées sur des tâches pour apprendre à agir dans n'importe quel endroit.",
      "submittedOnDailyBy": {
        "_id": "64ac1f169dcc5787461468a4",
        "avatarUrl": "/avatars/c031a75989147009b7850df4eddfcb27.svg",
        "isPro": false,
        "fullname": "Qingwen Bu",
        "user": "qwbu",
        "type": "user"
      },
      "summary": "Les robots généralistes doivent fonctionner efficacement dans divers environnements. Cependant, de nombreuses approches actuelles se concentrent sur l'expansion des données basées sur des manuels d'exploitation, qui dépendent fortement de ces données pour améliorer leurs capacités. Par conséquent, ils habituellement limitent une caractéristique physique et trouvent difficile d'apprendre des connaissances qui sont apprenables à travers différents corps de robots et différents environnements. Pour contrer ces limitations, nous proposons un nouveau cadre appelé UniVLA. C'est un nouveau cadre pour l'apprentissage de politiques de langage visuel-action (VLA) apprenables à travers différents corps de robots. Notre innovation principale est la capacité d'obtenir des représentations d'actions axées sur des tâches à partir de vidéos en utilisant des modèles d'actions potentielles. Cela permet l'utilisation d'une large gamme de données provenant de différents corps de robots et de différents angles de vue. Pour atténuer l'impact des dynamiques non liées à la tâche, nous adoptons l'inclusion d'instructions linguistiques et la construction de modèles d'actions potentielles dans l'espace de caractéristiques DINO. Les politiques générales entraînées sur des vidéos à l'échelle internet peuvent être efficacement déployées sur divers robots grâce à la décodage des actions potentielles. Des résultats de pointe ont été obtenus dans de nombreux benchmarks d'actions et de navigation, et une déploiement sur robots réels a également été réalisé. UniVLA atteint des performances plus élevées que OpenVLA, avec un calcul d'entraînement de 1/20 ou moins et un données de données de suite de 1/10 ou moins. L'inclusion de vidéos humaines ou d'autres types de données sur la ligne exposée est attendue pour conduire à des améliorations continuelles de la performance. Ces résultats montrent que UniVLA peut contribuer à l'apprentissage efficace de politiques de robots échangeables.",
      "upvotes": 5,
      "discussionId": "68218b857202d19324951214",
      "githubRepo": "https://github.com/OpenDriveLab/UniVLA",
      "ai_keywords": [
        "UniVLA",
        "vision-language-action (VLA) policies",
        "latent action model",
        "DINO feature space",
        "latent action decoding",
        "manipulation benchmarks",
        "navigation benchmarks",
        "real-robot deployments",
        "OpenVLA"
      ]
    },
    "publishedAt": "2025-05-09T11:11:13.000Z",
    "title": "UniVLA: Learning to Act Anywhere with Task-centric Latent Actions",
    "summary": "A generalist robot should perform effectively across various environments.\nHowever, most existing approaches heavily rely on scaling action-annotated data\nto enhance their capabilities. Consequently, they are often limited to single\nphysical specification and struggle to learn transferable knowledge across\ndifferent embodiments and environments. To confront these limitations, we\npropose UniVLA, a new framework for learning cross-embodiment\nvision-language-action (VLA) policies. Our key innovation is to derive\ntask-centric action representations from videos with a latent action model.\nThis enables us to exploit extensive data across a wide spectrum of embodiments\nand perspectives. To mitigate the effect of task-irrelevant dynamics, we\nincorporate language instructions and establish a latent action model within\nthe DINO feature space. Learned from internet-scale videos, the generalist\npolicy can be deployed to various robots through efficient latent action\ndecoding. We obtain state-of-the-art results across multiple manipulation and\nnavigation benchmarks, as well as real-robot deployments. UniVLA achieves\nsuperior performance over OpenVLA with less than 1/20 of pretraining compute\nand 1/10 of downstream data. Continuous performance improvements are observed\nas heterogeneous data, even including human videos, are incorporated into the\ntraining pipeline. The results underscore UniVLA's potential to facilitate\nscalable and efficient robot policy learning.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.06111.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64ac1f169dcc5787461468a4",
      "avatarUrl": "/avatars/c031a75989147009b7850df4eddfcb27.svg",
      "fullname": "Qingwen Bu",
      "name": "qwbu",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2505.05026",
      "authors": [
        {
          "_id": "6821771ddf190eabf5f666d8",
          "user": {
            "_id": "655c44752205aab35222aca3",
            "avatarUrl": "/avatars/57900539952382de0ce6892faf50b401.svg",
            "isPro": false,
            "fullname": "Jaehyun Jeon",
            "user": "jeochris",
            "type": "user"
          },
          "name": "Jaehyun Jeon",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-12T06:50:17.832Z",
          "hidden": false
        },
        {
          "_id": "6821771ddf190eabf5f666d9",
          "name": "Jang Han Yoon",
          "hidden": false
        },
        {
          "_id": "6821771ddf190eabf5f666da",
          "name": "Min Soo Kim",
          "hidden": false
        },
        {
          "_id": "6821771ddf190eabf5f666db",
          "name": "Sumin Shim",
          "hidden": false
        },
        {
          "_id": "6821771ddf190eabf5f666dc",
          "name": "Yejin Choi",
          "hidden": false
        },
        {
          "_id": "6821771ddf190eabf5f666dd",
          "name": "Hanbin Kim",
          "hidden": false
        },
        {
          "_id": "6821771ddf190eabf5f666de",
          "name": "Youngjae Yu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-08T08:00:32.000Z",
      "submittedOnDailyAt": "2025-05-12T05:33:20.932Z",
      "title": "G-FOCUS : Efforts pour évaluer la persuasiveness dans le design des interfaces utilisateur (UI)",
      "submittedOnDailyBy": {
        "_id": "655c44752205aab35222aca3",
        "avatarUrl": "/avatars/57900539952382de0ce6892faf50b401.svg",
        "isPro": false,
        "fullname": "Jaehyun Jeon",
        "user": "jeochris",
        "type": "user"
      },
      "summary": "L'évaluation efficace des designs utilisateur (UI) se concentre sur des aspects pouvant influencer le comportement de l'utilisateur, passant par les propriétés artistiques. Cette évaluation est basée sur les principes fondamentaux de la persuasion du design. Les tests A/B sont l'un des principaux méthodes pour sélectionner un design utilisateur qui augmente la participation de l'utilisateur, bien qu'ils nécessitent des coûts et du temps. Les modèles Vision-Langue (VLM) récents ont réussi à analyser automatiquement des designs utilisateur, mais leur approche actuelle se concentre sur des caractéristiques de design indépendantes, au lieu d'évaluer leur persuasion. Pour répondre à cette question, nous présentons WiserUI-Bench, un cadre de référence pour évaluer la persuasion de designs utilisateur paires. Ce cadre comprend 300 pairs d'images de designs utilisateur réels, étiquetés avec des motifs professionnels basés sur des résultats de tests A/B. De plus, nous proposons G-FOCUS, une stratégie de raisonnement qui renforce l'évaluation de la persuasion basée sur VLM, réduit le biais de position et améliore la précision de l'évaluation. Les résultats des tests montrent que G-FOCUS dépasse les stratégies d'inférence actuelles en termes de concordance et de précision dans l'évaluation de designs utilisateur paires. Notre étude promeut l'évaluation de la persuasion des designs utilisateur via VLM, offrant une approche qui complète les tests A/B et encourage le modélisation de préférences de designs utilisateur échangeables et l'optimisation du design. Les codes et les données sont disponibles publiquement.",
      "upvotes": 5,
      "discussionId": "68217722df190eabf5f66814",
      "ai_keywords": [
        "Vision-Language Models",
        "WiserUI-Bench",
        "Pairwise UI Design Persuasiveness Assessment",
        "G-FOCUS",
        "inference-time reasoning strategy",
        "position bias",
        "VLM-driven evaluation"
      ]
    },
    "publishedAt": "2025-05-08T04:00:32.000Z",
    "title": "G-FOCUS: Towards a Robust Method for Assessing UI Design Persuasiveness",
    "summary": "Evaluating user interface (UI) design effectiveness extends beyond aesthetics\nto influencing user behavior, a principle central to Design Persuasiveness. A/B\ntesting is the predominant method for determining which UI variations drive\nhigher user engagement, but it is costly and time-consuming. While recent\nVision-Language Models (VLMs) can process automated UI analysis, current\napproaches focus on isolated design attributes rather than comparative\npersuasiveness-the key factor in optimizing user interactions. To address this,\nwe introduce WiserUI-Bench, a benchmark designed for Pairwise UI Design\nPersuasiveness Assessment task, featuring 300 real-world UI image pairs labeled\nwith A/B test results and expert rationales. Additionally, we propose G-FOCUS,\na novel inference-time reasoning strategy that enhances VLM-based\npersuasiveness assessment by reducing position bias and improving evaluation\naccuracy. Experimental results show that G-FOCUS surpasses existing inference\nstrategies in consistency and accuracy for pairwise UI evaluation. Through\npromoting VLM-driven evaluation of UI persuasiveness, our work offers an\napproach to complement A/B testing, propelling progress in scalable UI\npreference modeling and design optimization. Code and data will be released\npublicly.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.05026.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "655c44752205aab35222aca3",
      "avatarUrl": "/avatars/57900539952382de0ce6892faf50b401.svg",
      "fullname": "Jaehyun Jeon",
      "name": "jeochris",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.02686",
      "authors": [
        {
          "_id": "6821acfb2808328b91c0e365",
          "name": "Xiaobao Wu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-05T14:33:49.000Z",
      "submittedOnDailyAt": "2025-05-12T06:41:36.276Z",
      "title": "L'ascension dans le ciel d'un IA : Recherche sur l'apprentissage compensatoire après l'entraînement et l'échelle dans l'entraînement et la validation de modèles de langage grands",
      "submittedOnDailyBy": {
        "_id": "64cb02869e30a46f7b80b355",
        "avatarUrl": "/avatars/81ce4ba78826b54f0e1b53eeaff87ee6.svg",
        "isPro": false,
        "fullname": "Xiaobao Wu",
        "user": "bobxwu",
        "type": "user"
      },
      "summary": "Le développement récent des modèles de langage grands (LLMs) a été réalisé à travers des échelles d'apprentissage préalable, d'apprentissage et de temps de test postérieur. Dans cette évolution, un paradigme central et unifié a émergé : l'apprentissage par compensation oriente les actions des LLMs de manière cruciale. Ce paradigme forme la base d'une large gamme de technologies introduites, comme l'apprentissage par renforcement guidé (RLHF, DPO, GRPO), la décodification guidée par compensation, et la correction postérieure. Un point clé est que ce paradigme permet que l'apprentissage passif à partir de données statiques se transforme en un apprentissage actif à partir de rétroalimentation dynamique. Cela confère aux LLMs des préférences consistantes et des capacités théoriques profondes. Dans cette recherche, un résumé détaillé du paradigme d'apprentissage par compensation est fourni. Les stratégies d'apprentissage, d'inférence et de post-inférence sont classifiées et analysées sous ce paradigme. De plus, les cadres de référence des modèles de compensation et leurs applications principales sont discutées. Enfin, les problèmes et les directions futures sont soulignés. La documentation des articles sur l'apprentissage des LLMs par compensation est disponible sur https://github.com/bobxwu/learning-from-rewards-llm-papers.",
      "upvotes": 3,
      "discussionId": "6821acfd2808328b91c0e3e3",
      "githubRepo": "https://github.com/bobxwu/learning-from-rewards-llm-papers",
      "ai_keywords": [
        "reinforcement learning",
        "RLHF",
        "DPO",
        "GRPO",
        "reward-guided decoding",
        "post-hoc correction",
        "active learning",
        "reward models"
      ]
    },
    "publishedAt": "2025-05-05T10:33:49.000Z",
    "title": "Sailing AI by the Stars: A Survey of Learning from Rewards in\n  Post-Training and Test-Time Scaling of Large Language Models",
    "summary": "Recent developments in Large Language Models (LLMs) have shifted from\npre-training scaling to post-training and test-time scaling. Across these\ndevelopments, a key unified paradigm has arisen: Learning from Rewards, where\nreward signals act as the guiding stars to steer LLM behavior. It has\nunderpinned a wide range of prevalent techniques, such as reinforcement\nlearning (in RLHF, DPO, and GRPO), reward-guided decoding, and post-hoc\ncorrection. Crucially, this paradigm enables the transition from passive\nlearning from static data to active learning from dynamic feedback. This endows\nLLMs with aligned preferences and deep reasoning capabilities. In this survey,\nwe present a comprehensive overview of the paradigm of learning from rewards.\nWe categorize and analyze the strategies under this paradigm across training,\ninference, and post-inference stages. We further discuss the benchmarks for\nreward models and the primary applications. Finally we highlight the challenges\nand future directions. We maintain a paper collection at\nhttps://github.com/bobxwu/learning-from-rewards-llm-papers.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.02686.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64cb02869e30a46f7b80b355",
      "avatarUrl": "/avatars/81ce4ba78826b54f0e1b53eeaff87ee6.svg",
      "fullname": "Xiaobao Wu",
      "name": "bobxwu",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false
    },
    "isAuthorParticipating": false
  }
]