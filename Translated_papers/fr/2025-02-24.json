[
  {
    "paper": {
      "id": "2502.14776",
      "authors": [
        {
          "_id": "67bbdb46d94d32bcfba70db7",
          "name": "Xun Liang",
          "hidden": false
        },
        {
          "_id": "67bbdb46d94d32bcfba70db8",
          "name": "Jiawei Yang",
          "hidden": false
        },
        {
          "_id": "67bbdb46d94d32bcfba70db9",
          "user": {
            "_id": "662dd19f9e6d371ab71b91ce",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/662dd19f9e6d371ab71b91ce/mZBPw_Zs8ZlEFGlbekAoH.jpeg",
            "isPro": false,
            "fullname": "Yezhaohui Wang",
            "user": "HaruTeru",
            "type": "user"
          },
          "name": "Yezhaohui Wang",
          "status": "extracted_confirmed",
          "statusLastChangedAt": "2025-02-24T04:12:46.485Z",
          "hidden": false
        },
        {
          "_id": "67bbdb46d94d32bcfba70dba",
          "name": "Chen Tang",
          "hidden": false
        },
        {
          "_id": "67bbdb46d94d32bcfba70dbb",
          "user": {
            "_id": "656f47ba2f058b368c0b1611",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/656f47ba2f058b368c0b1611/mrmcmA8bxaDNUhuJQQ7T1.png",
            "isPro": false,
            "fullname": "Zifan Zheng",
            "user": "fan2goa1",
            "type": "user"
          },
          "name": "Zifan Zheng",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-24T09:07:22.303Z",
          "hidden": false
        },
        {
          "_id": "67bbdb46d94d32bcfba70dbc",
          "name": "Simin Niu",
          "hidden": false
        },
        {
          "_id": "67bbdb46d94d32bcfba70dbd",
          "name": "Shichao Song",
          "hidden": false
        },
        {
          "_id": "67bbdb46d94d32bcfba70dbe",
          "user": {
            "_id": "669e0b93c7cb0568dac6e92e",
            "avatarUrl": "/avatars/a39ea77d7391f164af8a80f94f85f2ca.svg",
            "isPro": false,
            "fullname": "hanyu Wang",
            "user": "UglyToilet",
            "type": "user"
          },
          "name": "Hanyu Wang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-24T09:07:20.146Z",
          "hidden": false
        },
        {
          "_id": "67bbdb46d94d32bcfba70dbf",
          "name": "Bo Tang",
          "hidden": false
        },
        {
          "_id": "67bbdb46d94d32bcfba70dc0",
          "name": "Feiyu Xiong",
          "hidden": false
        },
        {
          "_id": "67bbdb46d94d32bcfba70dc1",
          "name": "Keming Mao",
          "hidden": false
        },
        {
          "_id": "67bbdb46d94d32bcfba70dc2",
          "name": "Zhiyu li",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-20T17:59:45.000Z",
      "title": "SurveyX : Modèle de Rationalisation d'Opinions par Automatisation de la Recherche Académique",
      "summary": "Les modèles de langage grand (LLMs) montrent des capacités d'compréhension exceptionnelles et une large base de connaissances, ce qui les permet d'être utilisés comme outils efficaces pour la génération automatique d'enquêtes. Cependant, les études récentes sur la génération automatique d'enquêtes sont limitées par des restrictions importantes, telles que le taille du fenêtre de contexte limitée et la manque de discussion sur des sujets profonds. Inspirés par le processus d'écriture humain, nous divisons la création d'enquêtes en deux étapes : 'Préparation' et 'Génération', proposant ainsi un système efficace et organisé appelé 'SurveyX'. Grâce à l'introduction créative de la recherche de ressources en ligne, le méthode de pré-traitement 'AttributeTree' et le processus de remise à l'ordre, SurveyX améliore significativement l'efficacité dans la création d'enquêtes. Les résultats de l'évaluation expérimentale montrent que SurveyX dépasse les systèmes actuels de génération automatique d'enquêtes en termes de qualité de contenu (amélioration de 0,259) et de qualité des citations (amélioration de 1,76), et se rapproche de la performance des experts sur plusieurs critères d'évaluation. Des exemples d'enquêtes générées dans SurveyX sont disponibles sur www.surveyx.cn.",
      "upvotes": 61,
      "discussionId": "67bbdb47d94d32bcfba70df3"
    },
    "publishedAt": "2025-02-23T21:39:54.375Z",
    "title": "SurveyX: Academic Survey Automation via Large Language Models",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.14776.png",
    "numComments": 4,
    "submittedBy": {
      "_id": "669e60ee8580d17cb60f8347",
      "avatarUrl": "/avatars/37963b833228afe39cc24854c9326670.svg",
      "fullname": "yang jiawei",
      "name": "Dany-0",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 5
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.11663",
      "authors": [
        {
          "_id": "67b705d2ebee4662205c47f7",
          "name": "Jingcheng Ni",
          "hidden": false
        },
        {
          "_id": "67b705d2ebee4662205c47f8",
          "name": "Yuxin Guo",
          "hidden": false
        },
        {
          "_id": "67b705d2ebee4662205c47f9",
          "user": {
            "_id": "6572dcc6bbd6664053b1fa6b",
            "avatarUrl": "/avatars/aba29efd00bc41f14ce422f7807cd2c3.svg",
            "isPro": false,
            "fullname": "Liu Yichen",
            "user": "lyclyc52",
            "type": "user"
          },
          "name": "Yichen Liu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-24T09:23:40.466Z",
          "hidden": false
        },
        {
          "_id": "67b705d2ebee4662205c47fa",
          "name": "Rui Chen",
          "hidden": false
        },
        {
          "_id": "67b705d2ebee4662205c47fb",
          "name": "Lewei Lu",
          "hidden": false
        },
        {
          "_id": "67b705d2ebee4662205c47fc",
          "user": {
            "_id": "65717368be66cd9b65a8201c",
            "avatarUrl": "/avatars/fe945828eec9ded4cfa3b89d48a64d90.svg",
            "isPro": false,
            "fullname": "Wu Zehuan",
            "user": "wzhgba",
            "type": "user"
          },
          "name": "Zehuan Wu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-21T09:59:38.956Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-17T10:53:56.000Z",
      "title": "MaskGWM: Modèle Mondial de Motorisation Généralisable avec Masques Vidéo",
      "summary": "Le modèle mondial est capable de prédire les changements environnementaux à partir d'actions, ce qui est crucial pour les modèles autonomes de conduite qui ont une forte capacité de généralisation. Les principaux modèles de conduite sont construits sur des modèles de prédiction vidéo. En utilisant des générateurs basés sur la division, on peut créer des séquences vidéo de haute qualité, mais cela est limité par le temps de prédiction et la capacité de généralisation globale. Dans cet article, nous examinons un méthode pour résoudre ces problèmes en combinant l'entraînement de perte de génération et l'apprentissage de contexte basé sur les caractéristiques de style MAE. Spécifiquement, nous introduisons trois conceptions clés pour atteindre cet objectif : 1) nous étendons la structure de Transformer de division (DiT) pour qu'elle puisse être entraînée avec des tâches supplémentaires de configuration de masques. 2) nous concevons des tokens de masque liés pour traiter les tâches de reconstruction de masque et de génération. 3) nous étendons la tâche de configuration de masques aux régions spatiales-temporelles, en utilisant des masques individuels pour remplacer l'auto-attention cachée de MAE. Ensuite, nous introduisons un module de vision croisée individuel selon cette conception de masques. En se basant sur ces améliorations, nous proposons un modèle de conduite vidéo de haute généralisation, appelé MaskGWM, qui aborde la reconstruction de masques vidéo. Le modèle comprend deux variantes : MaskGWM-long, qui se concentre sur la prédiction à long terme, et MaskGWM-mview, qui se spécialise dans la génération de multiples perspectives. Les expériences détaillées dans les cadres de référence standard incluent la validation de généralisation sur le jeu de données Nuscene, la prédiction à long terme sur le jeu de données OpenDV-2K, et la validation de zero-shot sur le jeu de données Waymo, démontrant les effets des méthodes proposées. Les mesures numériques dans ces jeux de données montrent que notre méthode améliore significativement les modèles de conduite les plus avancés.",
      "upvotes": 33,
      "discussionId": "67b705d4ebee4662205c489c"
    },
    "publishedAt": "2025-02-24T01:16:03.517Z",
    "title": "MaskGWM: A Generalizable Driving World Model with Video Mask Reconstruction",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.11663.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "65717368be66cd9b65a8201c",
      "avatarUrl": "/avatars/fe945828eec9ded4cfa3b89d48a64d90.svg",
      "fullname": "Wu Zehuan",
      "name": "wzhgba",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.13449",
      "authors": [
        {
          "_id": "67b7ceae3e8a45f770b2606e",
          "user": {
            "_id": "65633c5e84a9fbe322f87d81",
            "avatarUrl": "/avatars/7233a555b43c669847a950ce5697c92c.svg",
            "isPro": false,
            "fullname": "DongkiKim",
            "user": "DongkiKim",
            "type": "user"
          },
          "name": "Dongki Kim",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-21T09:59:11.214Z",
          "hidden": false
        },
        {
          "_id": "67b7ceae3e8a45f770b2606f",
          "name": "Wonbin Lee",
          "hidden": false
        },
        {
          "_id": "67b7ceae3e8a45f770b26070",
          "name": "Sung Ju Hwang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-19T05:49:10.000Z",
      "title": "Mol-LLaMA : Modèle de Langue de Modularité Moléculaire pour la Compréhension Générale des Molécules",
      "summary": "La compréhension des molécules joue un rôle essentiel dans la compréhension des organismes et dans le développement de la découverte de médicaments, ce qui nécessite un connaissance spécialisée en chimie et biologie. Les modèles de langage moléculaire grands ont eu un grand succès dans l'interprétation de la structure des molécules, mais leur ensemble de données d'entraînement est limité aux ensembles de données axés sur des tâches spécifiques de connaissances particulières, ce qui a empêché de couvrir complètement les caractéristiques basiques des molécules, limitant ainsi leur capacité en tant qu'outils de soutien généraux. Pour résoudre ces problèmes, nous proposons Mol-LLaMA, un modèle de langage moléculaire grand qui applique différentes indications pour comprendre le savoir général des molécules. Dans ce modèle, les principales types de données sont conçus pour inclure les caractéristiques basiques des molécules et sont intégrés avec des connaissances importantes de la structure moléculaire. De plus, un module qui intègre des informations complémentaires d'autres encodeurs de molécules est introduit pour améliorer leurs caractéristiques, et des représentations différentes des molécules sont utilisées pour améliorer leurs propriétés. A travers les résultats expérimentaux, Mol-LLaMA montre sa capacité à comprendre les caractéristiques générales des molécules, à générer des réponses liées aux questions des utilisateurs et à montrer la possibilité d'être un outil de soutien général dans l'analyse des molécules.",
      "upvotes": 28,
      "discussionId": "67b7ceae3e8a45f770b2609f"
    },
    "publishedAt": "2025-02-23T21:52:51.059Z",
    "title": "Mol-LLaMA: Towards General Understanding of Molecules in Large Molecular Language Model",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13449.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "65633c5e84a9fbe322f87d81",
      "avatarUrl": "/avatars/7233a555b43c669847a950ce5697c92c.svg",
      "fullname": "DongkiKim",
      "name": "DongkiKim",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 5
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.15007",
      "authors": [
        {
          "_id": "67bc1a4a72499ce2ba28cc70",
          "name": "Anton Razzhigaev",
          "hidden": false
        },
        {
          "_id": "67bc1a4a72499ce2ba28cc71",
          "name": "Matvey Mikhalchuk",
          "hidden": false
        },
        {
          "_id": "67bc1a4a72499ce2ba28cc72",
          "name": "Temurbek Rahmatullaev",
          "hidden": false
        },
        {
          "_id": "67bc1a4a72499ce2ba28cc73",
          "name": "Elizaveta Goncharova",
          "hidden": false
        },
        {
          "_id": "67bc1a4a72499ce2ba28cc74",
          "name": "Polina Druzhinina",
          "hidden": false
        },
        {
          "_id": "67bc1a4a72499ce2ba28cc75",
          "name": "Ivan Oseledets",
          "hidden": false
        },
        {
          "_id": "67bc1a4a72499ce2ba28cc76",
          "name": "Andrey Kuznetsov",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-20T19:59:35.000Z",
      "title": "LLM-Microscope : Outil pour découvrir le rôle des erreurs cachées dans le contexte mémoire de Transformer",
      "summary": "La méthodologie de codification de l'information contextuelle dans les modèles de lagragian jungle (LLM) est quantifiée, confirmant que les petits éléments (par exemple, dimensions, symboles) ont une grande importance contextuelle. En particulier, l'élimination de ces groupes d'étiquettes diminue considérablement le rendement dans les évaluations comme MMLU et BABILong-4k, surtout lorsque l'on supprime les stopwords, les mots et les virgules. Cependant, l'élimination seulement d'étiquettes non pertinentes produit les mêmes résultats. Notre analyse montre une forte corrélation entre la contextualisation et la linéarité. La linéarité mesure la précision des transformations qui peuvent être approximées par une seule transformation linéaire. Ces résultats soulignent l'importance des étiquettes de filtre pour maintenir le contexte. Pour cela, nous proposons un paquet de logiciels open-source appelé LLM-Microscope. Ce paquet de logiciels évalue la non-linéarité au niveau des groupes d'étiquettes, évalue la mémoire contextuelle, visualise la contribution des couches indirectes (en utilisant une amélioration de Logit Lens), et mesure la dimension des caractéristiques uniques des représentations. Ce paquet de logiciels démontre que les groupes d'étiquettes sont essentiels pour une compréhension à long terme.",
      "upvotes": 25,
      "discussionId": "67bc1a4c72499ce2ba28cd49"
    },
    "publishedAt": "2025-02-24T02:07:41.624Z",
    "title": "LLM-Microscope: Uncovering the Hidden Role of Punctuation in Context Memory of Transformers",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/6172aaeec8e66e2aa84c06b9/ZPSmOQ-7Yd7B7YIYiwcTw.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.15007.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "6172aaeec8e66e2aa84c06b9",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6172aaeec8e66e2aa84c06b9/ZdRZSp3P1SU6CIDbvQwkv.jpeg",
      "fullname": "Anton Razzhigaev",
      "name": "razzant",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 8
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.14397",
      "authors": [
        {
          "_id": "67bbed806f2833ecccf914dd",
          "name": "Shijie Huang",
          "hidden": false
        },
        {
          "_id": "67bbed806f2833ecccf914de",
          "name": "Yiren Song",
          "hidden": false
        },
        {
          "_id": "67bbed806f2833ecccf914df",
          "name": "Yuxuan Zhang",
          "hidden": false
        },
        {
          "_id": "67bbed806f2833ecccf914e0",
          "name": "Hailong Guo",
          "hidden": false
        },
        {
          "_id": "67bbed806f2833ecccf914e1",
          "name": "Xueyin Wang",
          "hidden": false
        },
        {
          "_id": "67bbed806f2833ecccf914e2",
          "name": "Mike Zheng Shou",
          "hidden": false
        },
        {
          "_id": "67bbed806f2833ecccf914e3",
          "name": "Jiaming Liu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-20T09:35:38.000Z",
      "title": "PhotoDoodle : Données de couples de quelques cadres pour apprendre l'édition d'images artistiques",
      "summary": "PhotoDoodle est un nouveau cadre de travail pour éditer des images, utilisé pour superposer des éléments de décoration sur des photos. Le dessin sur des photos nécessite que les éléments insérés s'intègrent naturellement avec le fond, ce qui implique des besoins en branding réaliste, des ajustements de crayon et une cohérence du contexte. De plus, le fond ne se déforme pas et est préservé, et le style propre de l'artiste doit être compris adéquatement à partir de données d'entraînement limitées. Ces exigences n'ont pas été satisfaites par les méthodes précédentes, qui se concentraient principalement sur la transfert d'un style global ou sur l'influence locale. Dans la proposition, PhotoDoodle utilise une stratégie d'entraînement en deux étapes. Tout d'abord, un modèle général d'édition d'images, OmniEditor, est entraîné avec une grande quantité de données. Ensuite, le modèle est fine-tuné en utilisant EditLoRA avec un petit ensemble d'images éditées par un artiste, pour que le modèle puisse comprendre différents styles et techniques d'édition. Pour améliorer la cohérence des résultats générés, une structure de réutilisation de données de position est introduite. De plus, un ensemble de données de PhotoDoodle avec six styles de haute qualité est publié. Les expériences étendues montrent un haut rendement et une robustesse dans l'édition d'images personnalisées, ouvrant de nouvelles possibilités pour la création artistique.",
      "upvotes": 22,
      "discussionId": "67bbed856f2833ecccf915c5"
    },
    "publishedAt": "2025-02-23T22:55:04.409Z",
    "title": "PhotoDoodle: Learning Artistic Image Editing from Few-Shot Pairwise Data",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.14397.png",
    "numComments": 4,
    "submittedBy": {
      "_id": "64311a95034ecbefddd141ef",
      "avatarUrl": "/avatars/b6dc5ca373bedbaa368208517954c375.svg",
      "fullname": "Yiren Song",
      "name": "yiren98",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isMod": false,
      "followerCount": 4
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.14922",
      "authors": [
        {
          "_id": "67bbe4ba79e0a705cf573985",
          "name": "Zihao Zeng",
          "hidden": false
        },
        {
          "_id": "67bbe4ba79e0a705cf573986",
          "name": "Xuyao Huang",
          "hidden": false
        },
        {
          "_id": "67bbe4ba79e0a705cf573987",
          "name": "Boxiu Li",
          "hidden": false
        },
        {
          "_id": "67bbe4ba79e0a705cf573988",
          "name": "Zhijie Deng",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-19T17:38:46.000Z",
      "title": "SIFT : Base de l'inférence de LLM basée sur le contexte (utilisant des cartes de \"sticky\")",
      "summary": "Dans cet article, il est reconnu comme un problème important la manque de compréhension du texte dans les processus de logique des modèles de langage grands. Ce problème a étendu-se depuis les modèles petits jusqu'aux modèles avancés tels que Llama3.2-3B-Instruct et DeepSeek-R1. Par exemple, les modèles de langage grands (LLMs) souvent ne reconnaissent pas que « per » dans « 10 dólares/kilogramme » signifie « par kilogramme » et produisent des erreurs dans les calculs. Pour résoudre ces problèmes, un nouvel approche d'apprentissage en arrière appelé **Stick to the Facts (SIFT)** est présentée. SIFT renforce la logique des modèles basés sur le texte en augmentant la quantité de calculs lors de l'inférence. Le cœur de SIFT est le **stack text**, qui est la façon dont le modèle enregistre et met clairement en évidence les informations importantes du texte. Lorsque le stack text est fourni, SIFT génère des prédictions tant de la demande originale que de la demande avec le stack text ajouté. Si ces prédictions sont différentes, le stack text améliore progressivement le résultat grâce à l'optimisation *forward* (ajustant l'extraction de faits à la demande) et *inverse* (adaptant aux tendances propres au modèle). De cette manière, des résultats logiques avec une grande confiance sont obtenus. Les résultats de la recherche montrent un amélioration constante dans différents modèles (de 3B à plus de 100B) et dans des benchmarks comme GSM8K et MATH-500. En particulier, SIFT a augmenté la précision de DeepSeek-R1 dans l'AIME2024 de 78.33% à **85.67%**, ce qui a conféré à la communauté ouverte une nouvelle avant-garde. Le code est disponible sur https://github.com/zhijie-group/SIFT.",
      "upvotes": 13,
      "discussionId": "67bbe4bb79e0a705cf5739c3"
    },
    "publishedAt": "2025-02-23T22:17:18.309Z",
    "title": "SIFT: Grounding LLM Reasoning in Contexts via Stickers",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.14922.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 6193
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.12084",
      "authors": [
        {
          "_id": "67b8922ef6632327952ec1e1",
          "user": {
            "_id": "65d8b0f0661492b25c6623de",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65d8b0f0661492b25c6623de/c6LPDse8NIV_3BHIu8dYe.png",
            "isPro": false,
            "fullname": "Jianshu Zhang",
            "user": "Sterzhang",
            "type": "user"
          },
          "name": "Jianshu Zhang",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-02-21T14:48:16.643Z",
          "hidden": false
        },
        {
          "_id": "67b8922ef6632327952ec1e2",
          "user": {
            "_id": "64b0377121a001042bc0d274",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64b0377121a001042bc0d274/Hk8yI5_s7ey5o9SVZzXrB.png",
            "isPro": false,
            "fullname": "Dongyu Yao",
            "user": "RainJamesY",
            "type": "user"
          },
          "name": "Dongyu Yao",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-24T09:20:43.528Z",
          "hidden": false
        },
        {
          "_id": "67b8922ef6632327952ec1e3",
          "name": "Renjie Pi",
          "hidden": false
        },
        {
          "_id": "67b8922ef6632327952ec1e4",
          "name": "Paul Pu Liang",
          "hidden": false
        },
        {
          "_id": "67b8922ef6632327952ec1e5",
          "name": "Yi R.",
          "hidden": false
        },
        {
          "_id": "67b8922ef6632327952ec1e6",
          "name": "Fung",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-17T17:57:50.000Z",
      "title": "VLM^2-Bench : Exploration plus détaillée de la relation entre la vision cachée des modèles visuels et la correspondance explicite.",
      "summary": "La capacité de relier des catégories visuellement est fondamentale dans la vie quotidienne. Par exemple, on peut identifier la même personne dans plusieurs photographies en utilisant des catégories comme base. Bien que les compétences des modèles de langage visuel (VLMs) pour réaliser ces tâches de base soient connues, leur efficacité dans ce domaine était peu claire. Pour aborder ce sujet, nous présentons VLM^2-Bench, un cadre d'évaluation conçu pour analyser la capacité des VLMs à relier des catégories visuellement. Ce cadre contient 9 sous-tâches et plus de 3 000 cas de test.\n\nDes évaluations détaillées ont été effectuées sur 8 modèles, y compris 8 VLMs ouverts et GPT-4o, et les méthodes de front-end ont été analysées tant du point de vue linguistique que visuel, aboutissant à 8 constats importants. Des limitations importantes ont été détectées dans la capacité des modèles à relier des catégories visuellement, et il a été révélé que GPT-4o était 34,80% moins efficace que la personne humaine. Sur la base de ces constats, nous proposons les recommandations suivantes : améliorer la capacité visuelle essentielle des modèles, réduire la dépendance aux connaissances préalables, unifier la justification basée sur le langage dans les tâches visuelles, éviter les biais nécessaires, construire des relations de catégories visuelles de manière indépendante, et améliorer le rendement des modèles d'inférence en modifiant le modèle d'entraînement avec des contextes visuels.",
      "upvotes": 12,
      "discussionId": "67b89230f6632327952ec27a"
    },
    "publishedAt": "2025-02-24T00:36:34.341Z",
    "title": "VLM$^2$-Bench: A Closer Look at How Well VLMs Implicitly Link Explicit Matching Visual Cues",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.12084.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "65d8b0f0661492b25c6623de",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65d8b0f0661492b25c6623de/c6LPDse8NIV_3BHIu8dYe.png",
      "fullname": "Jianshu Zhang",
      "name": "Sterzhang",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 8
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.15589",
      "authors": [
        {
          "_id": "67bbfe2d670ece8d9184f339",
          "name": "Jintian Zhang",
          "hidden": false
        },
        {
          "_id": "67bbfe2d670ece8d9184f33a",
          "name": "Yuqi Zhu",
          "hidden": false
        },
        {
          "_id": "67bbfe2d670ece8d9184f33b",
          "name": "Mengshu Sun",
          "hidden": false
        },
        {
          "_id": "67bbfe2d670ece8d9184f33c",
          "name": "Yujie Luo",
          "hidden": false
        },
        {
          "_id": "67bbfe2d670ece8d9184f33d",
          "user": {
            "_id": "6447800f30fa4ecb85ddad80",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6447800f30fa4ecb85ddad80/NsmXIaMsWctmTNA7tFVkX.jpeg",
            "isPro": false,
            "fullname": "Shuofei Qiao",
            "user": "GoooDte",
            "type": "user"
          },
          "name": "Shuofei Qiao",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-24T09:07:02.722Z",
          "hidden": false
        },
        {
          "_id": "67bbfe2d670ece8d9184f33e",
          "name": "Lun Du",
          "hidden": false
        },
        {
          "_id": "67bbfe2d670ece8d9184f33f",
          "name": "Da Zheng",
          "hidden": false
        },
        {
          "_id": "67bbfe2d670ece8d9184f340",
          "name": "Huajun Chen",
          "hidden": false
        },
        {
          "_id": "67bbfe2d670ece8d9184f341",
          "user": {
            "_id": "620b3bbb0668e435407c8d0a",
            "avatarUrl": "/avatars/e0fccbb2577d76088e09f054c35cffbc.svg",
            "isPro": false,
            "fullname": "Ningyu Zhang",
            "user": "Ningyu",
            "type": "user"
          },
          "name": "Ningyu Zhang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-24T09:07:04.794Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-21T16:57:22.000Z",
      "title": "LightThinker: Compression basée sur des pensées en étapes",
      "summary": "Les modèles de langage grand (LLMs) montrent un comportement exceptionnel dans des tâches théoriques complexes, mais leur efficacité diminue en raison des coûts élevés de mémoire et de calcul liés à la génération de longs tokens. Dans cet article, nous proposons une nouvelle méthodologie permettant aux LLMs de compresser les pensées intermédiaires lors de la résolution de problèmes théoriques de manière dynamique. Inspiré par le processus cognitif humain, LightThinker transforme des étapes de pensée prolongées en expressions plus courtes, en laissant de côté la chaîne originale de raisonnement et en réduisant significativement le nombre de tokens dans la fenêtre de contexte. Cela est réalisé grâce à la construction de données, au mapping des tokens compressés et à l'application d'une masque d'action spécialisée pour entraîner le modèle. De plus, nous introduisons la métrique Dependency (Dep) pour mesurer les relations de dépendance entre les tokens générés dans le processus. Les expériences étendues, basées sur 4 ensembles de données et 2 modèles, montrent que LightThinker peut maintenir la précision tout en réduisant la quantité de mémoire utilisée et le temps d'inférence. Notre étude ouvre de nouvelles perspectives pour améliorer l'efficacité des LLMs dans des tâches théoriques complexes. Le code est disponible sur : https://github.com/zjunlp/LightThinker.",
      "upvotes": 12,
      "discussionId": "67bbfe2f670ece8d9184f3a4"
    },
    "publishedAt": "2025-02-24T00:07:05.804Z",
    "title": "LightThinker: Thinking Step-by-Step Compression",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/620b3bbb0668e435407c8d0a/dhGMWf_tcPkvQlRm5DbD6.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.15589.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "620b3bbb0668e435407c8d0a",
      "avatarUrl": "/avatars/e0fccbb2577d76088e09f054c35cffbc.svg",
      "fullname": "Ningyu Zhang",
      "name": "Ningyu",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 19
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.14494",
      "authors": [
        {
          "_id": "67b9dda03593f69f41cdb5d3",
          "name": "Jinnan Li",
          "hidden": false
        },
        {
          "_id": "67b9dda03593f69f41cdb5d4",
          "name": "Jinzhe Li",
          "hidden": false
        },
        {
          "_id": "67b9dda03593f69f41cdb5d5",
          "name": "Yue Wang",
          "hidden": false
        },
        {
          "_id": "67b9dda03593f69f41cdb5d6",
          "name": "Yi Chang",
          "hidden": false
        },
        {
          "_id": "67b9dda03593f69f41cdb5d7",
          "name": "Yuan Wu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-20T12:22:18.000Z",
      "title": "StructFlowBench : Benchmark des Flux Structures à Plusieurs Tours",
      "summary": "La capacité de suivi de commandes de transformation multi-à-multi est un aspect essentiel dans les applications réelles des modèles de langage grands (LLMs). Les évaluations actuelles se concentrent sur la satisfaction de restrictions délicates et sur l'évaluation de compétences spécifiques du domaine, ignorant la relation structurelle importante entre les transformations multi-à-multi et uni-à-uni. Cette relation structurelle reflète les intentions des utilisateurs et fournit un niveau de vérification supplémentaire au-delà de la satisfaction des restrictions. Pour aborder ce problème, nous proposons StructureFlowBench. StructureFlowBench est un cadre de référence d'évaluation pour le suivi de commandes de transformation multi-à-multi qui inclut un modélisation de flux structurel. Ce cadre innovant définit la relation entre six transformations basiques et introduit de nouvelles restrictions structurelles dans l'évaluation des modèles, générant des paramètres de flux de dialogue personnalisés qui s'adaptent à différents scans. Nous avons appliqué des méthodes d'évaluation basées sur les LLMs pour effectuer une évaluation systématique de 13 modèles de LLM, tant de code ouvert que de code fermé. Les résultats des expériences montrent clairement que les modèles actuels ont des déficiences dans la compréhension de la structure des dialogues de transformation multi-à-multi. Le code est disponible à : https://github.com/MLGroupJLU/StructFlowBench.",
      "upvotes": 10,
      "discussionId": "67b9dda13593f69f41cdb635"
    },
    "publishedAt": "2025-02-23T23:43:43.529Z",
    "title": "StructFlowBench: A Structured Flow Benchmark for Multi-turn Instruction Following",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.14494.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "670e57b3391f1a7021182bff",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/N0tuHZVz8KFPCv8G1qUX2.png",
      "fullname": "Yuan Wu",
      "name": "WhiteCatY",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.15027",
      "authors": [
        {
          "_id": "67bbdcec79fcd85f09ddd869",
          "name": "Henry Hengyuan Zhao",
          "hidden": false
        },
        {
          "_id": "67bbdcec79fcd85f09ddd86a",
          "name": "Wenqi Pei",
          "hidden": false
        },
        {
          "_id": "67bbdcec79fcd85f09ddd86b",
          "name": "Yifei Tao",
          "hidden": false
        },
        {
          "_id": "67bbdcec79fcd85f09ddd86c",
          "name": "Haiyang Mei",
          "hidden": false
        },
        {
          "_id": "67bbdcec79fcd85f09ddd86d",
          "name": "Mike Zheng Shou",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-20T20:27:06.000Z",
      "title": "InterFeedback : Méthode pour clarifier l'interaction intelligente des grands modèles multimodaux avec les humains à partir de rétroaction",
      "summary": "Les actuels benchmarks ne mesurent pas l'intelligence d'interaction de grands modèles multimodal (MMM) avec des utilisateurs humains. Cela est un élément nécessaire pour le développement de programmes d'assistance générale d'IA. Nous avons conçu un cadre interactif \"InterFeedback\" applicable à la fois aux MMM et aux ensembles de données. De cette manière, il est possible d'évaluer automatiquement cette intelligence. De plus, nous avons introduit \"InterFeedback-Bench\" pour évaluer l'intelligence interactive en utilisant des ensembles de données représentatifs comme MMU-Pro et MathVerse. Ce benchmark mesure 10 modèles multimodal ouverts de code. De plus, nous avons fourni un nouveau ensemble de données de 120 cas \"InterFeedback-Human\" pour mesurer de manière manuelle l'exécution interactive de modèles avancés comme OpenAI-o1 et Claude-3.5-Sonnet. Nos résultats d'évaluation montrent que le MMM le plus avancé actuellement (par exemple, OpenAI-o1) ne peut modifier ses résultats avec moins de 50% des feedbacks humains. Nos résultats démontrent la nécessité d'entendre l'intelligence des MMM et d'exploiter les bénéfices des feedbacks.",
      "upvotes": 4,
      "discussionId": "67bbdced79fcd85f09ddd8da"
    },
    "publishedAt": "2025-02-23T21:44:33.443Z",
    "title": "InterFeedback: Unveiling Interactive Intelligence of Large Multimodal Models via Human Feedback",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.15027.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 6193
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.15657",
      "authors": [
        {
          "_id": "67bbfd6c3593f69f41512d54",
          "name": "Yoshua Bengio",
          "hidden": false
        },
        {
          "_id": "67bbfd6c3593f69f41512d55",
          "name": "Michael Cohen",
          "hidden": false
        },
        {
          "_id": "67bbfd6c3593f69f41512d56",
          "name": "Damiano Fornasiere",
          "hidden": false
        },
        {
          "_id": "67bbfd6c3593f69f41512d57",
          "name": "Joumana Ghosn",
          "hidden": false
        },
        {
          "_id": "67bbfd6c3593f69f41512d58",
          "name": "Pietro Greiner",
          "hidden": false
        },
        {
          "_id": "67bbfd6c3593f69f41512d59",
          "name": "Matt MacDermott",
          "hidden": false
        },
        {
          "_id": "67bbfd6c3593f69f41512d5a",
          "name": "Sören Mindermann",
          "hidden": false
        },
        {
          "_id": "67bbfd6c3593f69f41512d5b",
          "name": "Adam Oberman",
          "hidden": false
        },
        {
          "_id": "67bbfd6c3593f69f41512d5c",
          "name": "Jesse Richardson",
          "hidden": false
        },
        {
          "_id": "67bbfd6c3593f69f41512d5d",
          "name": "Oliver Richardson",
          "hidden": false
        },
        {
          "_id": "67bbfd6c3593f69f41512d5e",
          "name": "Marc-Antoine Rondeau",
          "hidden": false
        },
        {
          "_id": "67bbfd6c3593f69f41512d5f",
          "name": "Pierre-Luc St-Charles",
          "hidden": false
        },
        {
          "_id": "67bbfd6c3593f69f41512d60",
          "name": "David Williams-King",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-21T18:28:36.000Z",
      "title": "L'hyperintelligence a un risque extrêmement dangereux : peut-la la science de l'IA offrir un chemin sûr ?",
      "summary": "Les entreprises avancées en IA se concentrent sur la construction d'agents IA communs. Ces systèmes sont capables de planifier, agir et poursuivre automatiquement des objectifs dans presque toutes les tâches que les humains effectuent. Ces systèmes détectent diverses menaces, mais ces menaces représentent un grand risque pour la sécurité publique et privée, car elles peuvent être causées par une mauvaise utilisation d'agents IA malicieux ou par une perte de contrôle instable des humains. Actuellement, on discute des méthodes d'entraînement de l'IA qui pourraient être les sources de ces risques. En fait, diverses scénarios et expériences présentent des preuves que les agents IA peuvent déviant de l'objectif établi par les opérateurs humains et peuvent chercher des objectifs qui contredisent les intérêts humains. Selon le principe de précaution, il est nécessaire de remplacer le chemin actuel des agents IA et de choisir ceux qui soient sécurisés et utiles. Pour cela, nous proposons de développer des systèmes d'IA plus sécuris et fiables comme blocs fondamentaux. Ces systèmes seront appelés \"Scientist AI\" et ont pour objectif que les humains comprennent mieux leur monde, agissant uniquement pour observer et interpréter le monde. Ce système est composé d'un modèle du monde pour générer des théories d'expliquer les données et d'une inférence pour répondre aux questions. Les deux composants ont la notion de l'incertitude spécifique pour réduire le risque de prédictions excessives. Selon ces considérations, le Scientist AI peut aider à accélérer la recherche scientifique et, en particulier, inclure la sécurité de l'IA. En particulier, notre système peut être utilisé comme guide pour réduire les risques des agents IA. Enfin, concentrer notre approche sur le développement d'IA sans agents peut démontrer que les bénéfices de l'innovation en IA peuvent être obtenus tout en évitant les risques associés au chemin actuel. Nous espérons que cette discussion motive les chercheurs, développeurs et décideurs à choisir des chemins sécuris.",
      "upvotes": 3,
      "discussionId": "67bbfd6c3593f69f41512d96"
    },
    "publishedAt": "2025-02-24T00:02:52.495Z",
    "title": "Superintelligent Agents Pose Catastrophic Risks: Can Scientist AI Offer a Safer Path?",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.15657.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6039478ab3ecf716b1a5fd4d",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg",
      "fullname": "taesiri",
      "name": "taesiri",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isMod": false,
      "followerCount": 63
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.15631",
      "authors": [
        {
          "_id": "67bbdbe8ea3003f47f15d036",
          "name": "Marthe Ballon",
          "hidden": false
        },
        {
          "_id": "67bbdbe8ea3003f47f15d037",
          "name": "Andres Algaba",
          "hidden": false
        },
        {
          "_id": "67bbdbe8ea3003f47f15d038",
          "name": "Vincent Ginis",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-21T17:59:13.000Z",
      "title": "La relation entre raisons et rendement dans les grands modèles de langage -- ou (mini) -- peut être pensée de manière forte sans besoin de beaucoup de temps.",
      "summary": "Les modèles de langage de haut niveau montrent des progrès significatifs mathématiques en utilisant des contextes associatifs et une échelle de calcul pendant les tests. Cependant, il existe de nombreux problèmes dans l'interaction entre l'utilisation de tokens logiques et l'augmentation de précision. En particulier, lorsqu'on compare la génération de modèles entre générations, on ne peut pas déterminer si les meilleurs résultats proviennent d'une meilleure association logique ou d'une efficacité logique. Par conséquent, une analyse systématique de la longueur de l'association logique d'o1-mini et d'o3-mini dans le benchmark Omni-MATH a confirmé que d'o3-mini (m) peut atteindre une précision supérieure à d'o1-mini sans nécessiter des associations logiques longues. De plus, il est montré que la précision généralement diminue lorsque l'association logique est plus longue, et ce effet est indépendant de la difficulté du problème, même lorsque la difficulté est ajustée. Cette réduction de précision est moins prononcée dans les modèles plus spécialisés, et un utilisation plus efficace de la capacité de calcul est une caractéristique des nouvelles générations de modèles logiques. Enfin, d'o3-mini (h) atteint un accroissement de précision plus minimal sur d'o3-mini (m), ce qui est réalisé en attribuant de nombreux tokens logiques à tous les problèmes, y compris ceux qui peuvent déjà être résolus par d'o3-mini (m). Ces résultats offrent une nouvelle perspective sur la relation entre la capacité du modèle et la longueur de l'association logique, affectant l'efficacité, l'échelle et les méthodes d'évaluation.",
      "upvotes": 3,
      "discussionId": "67bbdbefea3003f47f15d226"
    },
    "publishedAt": "2025-02-23T21:40:17.216Z",
    "title": "The Relationship Between Reasoning and Performance in Large Language Models -- o3 (mini) Thinks Harder, Not Longer",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.15631.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 6193
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.14905",
      "authors": [
        {
          "_id": "67bbe0520aabd5d571a723e7",
          "name": "Bhavik Agarwal",
          "hidden": false
        },
        {
          "_id": "67bbe0520aabd5d571a723e8",
          "name": "Ishan Joshi",
          "hidden": false
        },
        {
          "_id": "67bbe0520aabd5d571a723e9",
          "name": "Viktoria Rojkova",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-18T16:44:55.000Z",
      "title": "JSON pensant en : Pendant que je pense à JSON avec rigueur dans la stratégie de renforcement simple d'obéissance d'un LLM",
      "summary": "Dans cet article, on aborde le défi de générer un modèle de langage grand (LLM) qui respecte la syntaxe stricte d'inflexion, en utilisant la capacité de raisonnement du modèle pour sa mise en œuvre. En nous appuyant sur le cadre d'apprentissage par renforcement de DeepSeek R1, notre approche combine la construction d'un ensemble de données de raisonnement synthétique avec l'optimisation de politiques relatives (GRPO) et une fonction de récompense personnalisée, pour développer un nouveau flux de travail pour entraîner des habiletés structurées de raisonnement dans un modèle à 15 milliards de paramètres. En particulier, pour la première fois, l'apprentissage par renforcement est effectué sur un ensemble de données structurées à partir de 20 000 échantillons non structurés, et les méthodes de DeepSeek R1 sont réfléchies pour établir des capacités de raisonnement essentielles. Ensuite, l'entraînement est effectué sur un ensemble de 10 000 échantillons de données de raisonnement pour améliorer le respect de la syntaxe dans des tâches de descente. Dans un cadre d'entraînement relativement léger, l'entraînement de GRPO nécessite environ 20 heures sur un cluster de GPU 8xH100, tandis que l'entraînement de SFT nécessite 3 heures sur un GPU A100. Notre modèle a démontré une excellente capacité à respecter la syntaxe d'inflexion, et notre approche ThinkJSON a démontré son efficacité dans des applications réelles par rapport à DeepSeek R1 (671B), la version de DeepSeek R1 (Qwen-1.5B et Qwen-7B) et Gemini 2.0 Flash (70B). Nos résultats soulignent l'utilité pratique d'un cadre de travail efficace en ressources.",
      "upvotes": 2,
      "discussionId": "67bbe0530aabd5d571a72437"
    },
    "publishedAt": "2025-02-23T22:11:17.789Z",
    "title": "Think Inside the JSON: Reinforcement Strategy for Strict LLM Schema Adherence",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.14905.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 6193
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.15681",
      "authors": [
        {
          "_id": "67bbe67c7727595ca5979d2a",
          "name": "Yilun Xu",
          "hidden": false
        },
        {
          "_id": "67bbe67c7727595ca5979d2b",
          "name": "Weili Nie",
          "hidden": false
        },
        {
          "_id": "67bbe67c7727595ca5979d2c",
          "name": "Arash Vahdat",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-21T18:59:20.000Z",
      "title": "1. Modèle de diffusion en un pas : Coincidence de distributions de divergence f",
      "summary": "Dans les modèles de diffusion, la sampling est une fonction utile qui se réalise à travers un processus long et répétitif, surtout dans des applications interactives où son implémentation est difficile. Pour accélérer la vitesse de génération, les méthodes récentes extraient les modèles de diffusion multi-étapes comme générateurs de pas uniques sous un score non-neuronal, et ajustent la distribution des échantillons générés par les étudiants pour qu'elle corresponde à la distribution guide, ce qui accélère la vitesse de génération. Cependant, ces méthodes sont connues pour leur utilisation de la divergence KL inverse pour ajuster les distributions, mais cela est connu sous le nom de \"mode シーキング\". Dans cet article, nous proposons un nouveau cadre de travail de minimisation de la divergence f pour généraliser l'ajustement des distributions et aborder différents types de divergences, y compris la version \"mode カバー バージョン\" et la variabilité d'apprentissage. Nous calculons la pente de la divergence f entre la distribution guide et l'étudiant, ce qui est exprimé comme la multiplication d'une fonction de poids déterminée par la différence de scores et la raison de densité, montrant comment les échantillons de haute densité dans la distribution guide sont naturellement prioritisés. L'approche généralisée de la divergence non-neuronale en utilisant le score non-neuronal est considérée comme un cas spécial dans notre cadre de travail. Expérimentalement, les divergences f alternatives comme la divergence KL vers l'avenir et la divergence GENESIS-シャーニング dépassent actuellement le meilleur méthode de score non-neuronal, et en particulier, l'utilisation de la divergence GENESIS-シャーニング permet à f-distill d'atteindre le meilleur rendement de génération en un pas sur ImageNet64 et de montrer des résultats excellents dans la génération d'images à partir de texte non supervisé sur MS-COCO. Page du projet : https://research.nvidia.com/labs/genair/f-distill",
      "upvotes": 1,
      "discussionId": "67bbe6837727595ca5979e8c"
    },
    "publishedAt": "2025-02-23T22:24:55.500Z",
    "title": "One-step Diffusion Models with $f$-Divergence Distribution Matching",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.15681.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 6193
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.13189",
      "authors": [
        {
          "_id": "67b7152f299e4d30f9eb41c2",
          "name": "Enzhe Lu",
          "hidden": false
        },
        {
          "_id": "67b7152f299e4d30f9eb41c3",
          "name": "Zhejun Jiang",
          "hidden": false
        },
        {
          "_id": "67b7152f299e4d30f9eb41c4",
          "name": "Jingyuan Liu",
          "hidden": false
        },
        {
          "_id": "67b7152f299e4d30f9eb41c5",
          "name": "Yulun Du",
          "hidden": false
        },
        {
          "_id": "67b7152f299e4d30f9eb41c6",
          "name": "Tao Jiang",
          "hidden": false
        },
        {
          "_id": "67b7152f299e4d30f9eb41c7",
          "name": "Chao Hong",
          "hidden": false
        },
        {
          "_id": "67b7152f299e4d30f9eb41c8",
          "name": "Shaowei Liu",
          "hidden": false
        },
        {
          "_id": "67b7152f299e4d30f9eb41c9",
          "name": "Weiran He",
          "hidden": false
        },
        {
          "_id": "67b7152f299e4d30f9eb41ca",
          "name": "Enming Yuan",
          "hidden": false
        },
        {
          "_id": "67b7152f299e4d30f9eb41cb",
          "name": "Yuzhi Wang",
          "hidden": false
        },
        {
          "_id": "67b7152f299e4d30f9eb41cc",
          "name": "Zhiqi Huang",
          "hidden": false
        },
        {
          "_id": "67b7152f299e4d30f9eb41cd",
          "name": "Huan Yuan",
          "hidden": false
        },
        {
          "_id": "67b7152f299e4d30f9eb41ce",
          "name": "Suting Xu",
          "hidden": false
        },
        {
          "_id": "67b7152f299e4d30f9eb41cf",
          "name": "Xinran Xu",
          "hidden": false
        },
        {
          "_id": "67b7152f299e4d30f9eb41d0",
          "name": "Guokun Lai",
          "hidden": false
        },
        {
          "_id": "67b7152f299e4d30f9eb41d1",
          "name": "Yanru Chen",
          "hidden": false
        },
        {
          "_id": "67b7152f299e4d30f9eb41d2",
          "name": "Huabin Zheng",
          "hidden": false
        },
        {
          "_id": "67b7152f299e4d30f9eb41d3",
          "name": "Junjie Yan",
          "hidden": false
        },
        {
          "_id": "67b7152f299e4d30f9eb41d4",
          "name": "Jianlin Su",
          "hidden": false
        },
        {
          "_id": "67b7152f299e4d30f9eb41d5",
          "name": "Yuxin Wu",
          "hidden": false
        },
        {
          "_id": "67b7152f299e4d30f9eb41d6",
          "name": "Neo Y. Zhang",
          "hidden": false
        },
        {
          "_id": "67b7152f299e4d30f9eb41d7",
          "name": "Zhilin Yang",
          "hidden": false
        },
        {
          "_id": "67b7152f299e4d30f9eb41d8",
          "name": "Xinyu Zhou",
          "hidden": false
        },
        {
          "_id": "67b7152f299e4d30f9eb41d9",
          "name": "Mingxing Zhang",
          "hidden": false
        },
        {
          "_id": "67b7152f299e4d30f9eb41da",
          "name": "Jiezhong Qiu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-18T14:06:05.000Z",
      "title": "MoBA : Mixture d'Attraction de Bloc dans les Modèles de Langue de Contexte Long",
      "summary": "L'effetif taille du contexte dans les échelles de modèles de langage grands (LLMs) est essentiel pour favoriser leur développement vers une intelligence artificielle générale (AGI). Cependant, l'augmentation quadratique de la complexité computationnelle dans des structures d'actions simples impose une charge significative. Les méthodes actuelles appliquent des structures spécifiques à des tâches particulières (par exemple, attention de fenêtre ou sink) ou déforment la structure d'actions pour une approximation linéaire, mais les effets de ces approches sur des tâches d'inférence complexes n'ont pas été suffisamment étudiés.\n\nDans cet article, une solution basée sur le principe de \"minimiser la structure\" est proposée, se concentrant sur le fait que le modèle détermine automatiquement la position des actions et évite l'introduction de biais prédéfinis. On introduit le Block Attention Mixture (MoBA), proposant une nouvelle approche qui applique les principes d'Experts Mixture (MoE) à la structure d'actions. Cette nouvelle architecture montre un haut rendement dans des tâches de contexte long, permet une transition adéquate entre l'attention totale et l'attention épars, et améliore l'efficacité sans augmenter le risque de dégrader le rendement. MoBA déjà supporte des demandes de contexte long dans Kimi et a démontré des avancées significatives dans l'efficacité du calcul d'actions dans les LLMs. Le code est disponible sur https://github.com/MoonshotAI/MoBA.",
      "upvotes": 0,
      "discussionId": "67b71530299e4d30f9eb4213"
    },
    "publishedAt": "2025-02-24T04:52:30.963Z",
    "title": "MoBA: Mixture of Block Attention for Long-Context LLMs",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13189.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "63a369d98c0c89dcae3b8329",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63a369d98c0c89dcae3b8329/6OUJ7Hc9T1jXynYH3FGaf.png",
      "fullname": "Adina Yakefu",
      "name": "AdinaY",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 420
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.13407",
      "authors": [
        {
          "_id": "67bb33f3829dedfc99ae1288",
          "user": {
            "_id": "67bb32b6a0cb6e48cfd27d80",
            "avatarUrl": "/avatars/3cafe3a3fb60405252962d00105667c5.svg",
            "isPro": false,
            "fullname": "Ziyuan Liu",
            "user": "circleLZY",
            "type": "user"
          },
          "name": "Ziyuan Liu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-24T09:07:29.223Z",
          "hidden": false
        },
        {
          "_id": "67bb33f3829dedfc99ae1289",
          "name": "Ruifei Zhu",
          "hidden": false
        },
        {
          "_id": "67bb33f3829dedfc99ae128a",
          "name": "Long Gao",
          "hidden": false
        },
        {
          "_id": "67bb33f3829dedfc99ae128b",
          "name": "Yuanxiu Zhou",
          "hidden": false
        },
        {
          "_id": "67bb33f3829dedfc99ae128c",
          "name": "Jingyu Ma",
          "hidden": false
        },
        {
          "_id": "67bb33f3829dedfc99ae128d",
          "name": "Yuantao Gu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-19T03:33:54.000Z",
      "title": "JL1-CD : Nouveau Benchmark pour la Détection de Changements dans les Observations à Distance et un Fortifié Cadre de Filtrage du Connaissance de Données de Différences",
      "summary": "Deep learning a été efficacement appliqué dans le domaine de la détection de changements (DC) dans les images d'observation à distance, mais il reste encore deux grands problèmes majeurs : l'absence de jeux de données complètes et ouverts de DC à petite échelle, et la difficulté de réaliser des résultats de détection satisfaisants sur des images avec des zones de changement différentes. Pour aborder ces problèmes, nous présentons le jeu de données JL1-DC. Ce jeu de données comprend 5 000 paires d'images de 512×512 pixels à une résolution de 0,5 à 0,75 mètres. De plus, nous proposons un cadre de travail de connaissance d'apprentissage multi-turner (MTKD) pour la DC. Grâce aux résultats des expériences avec le jeu de données JL1-DC et SYSU-CD, nous avons démontré que le cadre MTKD a considérablement amélioré le rendement des modèles de DC avec différentes structures de réseau et tailles de paramètres, obtenant des résultats de pointe. Le code est disponible sur https://github.com/circleLZY/MTKD-CD.",
      "upvotes": 0,
      "discussionId": "67bb33f6829dedfc99ae135e"
    },
    "publishedAt": "2025-02-24T04:29:42.452Z",
    "title": "JL1-CD: A New Benchmark for Remote Sensing Change Detection and a Robust Multi-Teacher Knowledge Distillation Framework",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13407.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "67bb32b6a0cb6e48cfd27d80",
      "avatarUrl": "/avatars/3cafe3a3fb60405252962d00105667c5.svg",
      "fullname": "Ziyuan Liu",
      "name": "circleLZY",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.15011",
      "authors": [
        {
          "_id": "67bc0d12ffc2c387329c8cfd",
          "user": {
            "_id": "650ec19e6620b0c57e2a551b",
            "avatarUrl": "/avatars/c26c03fa920d857120f03c9ccb9f1d7a.svg",
            "isPro": false,
            "fullname": "Sayan Deb Sarkar",
            "user": "sayandsarkar",
            "type": "user"
          },
          "name": "Sayan Deb Sarkar",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-24T09:06:56.555Z",
          "hidden": false
        },
        {
          "_id": "67bc0d12ffc2c387329c8cfe",
          "name": "Ondrej Miksik",
          "hidden": false
        },
        {
          "_id": "67bc0d12ffc2c387329c8cff",
          "name": "Marc Pollefeys",
          "hidden": false
        },
        {
          "_id": "67bc0d12ffc2c387329c8d00",
          "name": "Daniel Barath",
          "hidden": false
        },
        {
          "_id": "67bc0d12ffc2c387329c8d01",
          "name": "Iro Armeni",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-20T20:05:30.000Z",
      "title": "CrossOver: Simulation 3D de Alignement Croisé",
      "summary": "Damodal 3D objeto comprensión reçoit une attention importante, mais les méthodes actuelles supposent l'utilisation complète des données et l'ajustement rigide de toutes les modalités. Je présente un nouveau cadre de travail appelé CrossOver. Ce cadre de travail réalise la compréhension de scènes 3D croisées par des ajustements de modalités flexibles à l'échelle de la scène. A différence des méthodes existantes, CrossOver apprend des espaces de dispersion modalement indépendants dans des scènes continues de modalités par un apprentissage continu de modalités, sans nécessité d'ajuster des données modales ajustées pour toutes les instances d'objets. Il est entraîné en apprenant avec des images RGB, ensembles de points, modèles CAD, plans de sol et descriptions textuelles, tout en connaissant des restrictions strictes et en évitant l'inclusion explicite du sens des objets. En utilisant des codificateurs spécifiques par dimensions, un flux de travail d'entraînement multiétapes et des actions croisées de modalités, CrossOver fournit des recherches de scènes robustes et la spécification de la localisation d'objets, même lorsque l'information modale est insuffisante. Dans des évaluations avec les ensembles de données ScanNet et 3RScan, il montre un comportement supérieur sur différentes métriques, soulignant l'adaptabilité de la compréhension de scènes 3D dans des applications réelles.",
      "upvotes": 0,
      "discussionId": "67bc0d18ffc2c387329c8e56"
    },
    "publishedAt": "2025-02-24T01:13:24.911Z",
    "title": "CrossOver: 3D Scene Cross-Modal Alignment",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/650ec19e6620b0c57e2a551b/S_xFBPoV3YbtHmtLtRrSV.gif"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.15011.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "650ec19e6620b0c57e2a551b",
      "avatarUrl": "/avatars/c26c03fa920d857120f03c9ccb9f1d7a.svg",
      "fullname": "Sayan Deb Sarkar",
      "name": "sayandsarkar",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.15082",
      "authors": [
        {
          "_id": "67bbe93f267aa2b537b318be",
          "user": {
            "_id": "64f64da90efa33bfe0a3d9ba",
            "avatarUrl": "/avatars/c45fb015433e46a2eeb9518910f75d35.svg",
            "isPro": false,
            "fullname": "Vaidehi Patil",
            "user": "vaidehi99",
            "type": "user"
          },
          "name": "Vaidehi Patil",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-24T09:07:15.794Z",
          "hidden": false
        },
        {
          "_id": "67bbe93f267aa2b537b318bf",
          "name": "Elias Stengel-Eskin",
          "hidden": false
        },
        {
          "_id": "67bbe93f267aa2b537b318c0",
          "name": "Mohit Bansal",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-20T22:51:10.000Z",
      "title": "UPCORE : Équilibré sans apprentissage grâce à la sélection d'un ensemble de noyaux de conservation d'utilité",
      "summary": "Vous pouvez supprimer des informations d'un modèle de restauration de données selon les exigences spécifiques des utilisateurs ou les structures légales. Dans ce cas, il est nécessaire de supprimer des points de données spécifiques d'un modèle entraîné ou de les \"oublier\". Cette opération peut affecter le rendement du modèle sur d'autres points de données, ce qui rend l'équilibre entre la suppression d'information et la préservation des autres capacités du modèle crucial. Si cet équilibre n'est pas atteint, cela peut entraîner la perte du modèle ou sa pertinence. À cette lumière, nous proposons UPCORE (Sélection de Ensembles de Nœuds pour Préserver l'Utilité), un cadre de sélection de données qui minimise les pertes qui surviennent lors de l'oubli de données. Le dommage au modèle est lié à la variance de la représentation du modèle dans l'ensemble de données à \"oublier\", et l'objectif est de proposer des ensembles de données de manière sélective pour minimiser le dommage au modèle après \"oubli\" de données. UPCORE dépasse l'objectif d'équilibre entre l'efficacité de la suppression et la préservation du modèle en utilisant trois méthodes standard de \"oublir\" des données. Pour améliorer l'évaluation de ces opérations, nous introduisons de nouvelles métriques et mesurons l'aire sous la courbe (AUC) des métriques standards. UPCORE améliore à la fois les métriques standards et l'AUC, obtient une transition positive entre les points de l'ensemble de données et les points proposés, et réduit la transition négative vers les points non proposés dans l'ensemble de données à \"oublier\".",
      "upvotes": 0,
      "discussionId": "67bbe940267aa2b537b318f4"
    },
    "publishedAt": "2025-02-23T23:17:33.152Z",
    "title": "UPCORE: Utility-Preserving Coreset Selection for Balanced Unlearning",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.15082.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64f64da90efa33bfe0a3d9ba",
      "avatarUrl": "/avatars/c45fb015433e46a2eeb9518910f75d35.svg",
      "fullname": "Vaidehi Patil",
      "name": "vaidehi99",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  }
]