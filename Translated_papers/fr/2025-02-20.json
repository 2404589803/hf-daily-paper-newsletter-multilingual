[
  {
    "paper": {
      "id": "2502.13923",
      "authors": [
        {
          "_id": "67b6b0688b56622e70b9e83e",
          "name": "Shuai Bai",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e83f",
          "name": "Keqin Chen",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e840",
          "name": "Xuejing Liu",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e841",
          "name": "Jialin Wang",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e842",
          "name": "Wenbin Ge",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e843",
          "name": "Sibo Song",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e844",
          "name": "Kai Dang",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e845",
          "name": "Peng Wang",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e846",
          "name": "Shijie Wang",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e847",
          "name": "Jun Tang",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e848",
          "name": "Humen Zhong",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e849",
          "name": "Yuanzhi Zhu",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e84a",
          "user": {
            "_id": "6417fa211f1f3b0fa811edc0",
            "avatarUrl": "/avatars/fa9e1ef1472a736c2ceebe12b77d6c89.svg",
            "isPro": false,
            "fullname": "Mingkun Yang",
            "user": "ayumiymk",
            "type": "user"
          },
          "name": "Mingkun Yang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-20T09:35:44.878Z",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e84b",
          "name": "Zhaohai Li",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e84c",
          "name": "Jianqiang Wan",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e84d",
          "name": "Pengfei Wang",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e84e",
          "name": "Wei Ding",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e84f",
          "name": "Zheren Fu",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e850",
          "name": "Yiheng Xu",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e851",
          "name": "Jiabo Ye",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e852",
          "name": "Xi Zhang",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e853",
          "name": "Tianbao Xie",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e854",
          "name": "Zesen Cheng",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e855",
          "name": "Hang Zhang",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e856",
          "name": "Zhibo Yang",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e857",
          "user": {
            "_id": "645b10e80c73ea27d13f7aca",
            "avatarUrl": "/avatars/95e565306472a15067440b5b43e07a6f.svg",
            "isPro": false,
            "fullname": "xuhaiyang",
            "user": "xhyandwyy",
            "type": "user"
          },
          "name": "Haiyang Xu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-20T09:35:42.372Z",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e858",
          "name": "Junyang Lin",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-19T18:00:14.000Z",
      "title": "Rapport Technique Qwen2.5-VL\n\nLe rapport technique Qwen2.5-VL détaille exhaustivement les aspects techniques du modèle Qwen2.5-VL, présentant son rendement, ses caractéristiques et le contexte de son développement. Ce document est d'une grande utilité pour les experts et les chercheurs dans le domaine de l'IA et est essentiel pour comprendre les dernières tendances technologiques et orientations de développement.",
      "summary": "Qwen2.5-VL est l'un des leaders du domaine du langage visuel et a connu des progrès considérables dans ses capacités de base et ses fonctionnalités innovantes. Qwen2.5-VL a démontré des progrès significatifs dans le reconnaissance visuelle, la précision dans la localisation d'objets, l'analyse de documents et la compréhension de vidéos longues. Une des caractéristiques notables de Qwen2.5-VL est sa capacité à spécifier précisément la position d'objets en utilisant des boîtes délimitatrices ou des points. De plus, elle peut extraire des données structurées de documents comptables, formulaires et tableaux, ainsi que détailler l'analyse de graphiques, diagrammes et réseaux de routers. Pour gérer des entrées complexes, Qwen2.5-VL a introduit un traitement dynamique de résolution et une codification absolue du temps, ce qui lui permet de traiter des images de différentes tailles et des vidéos de longue durée (jusqu'à des vidéos en direct) en secondes d'événements. Cela permet au modèle de comprendre de manière nature l'échelle spatiale et la dynamique temporelle, sans dépendre des méthodes de normalisation traditionnelles. Initialement, il a appris une Vision Transformer (ViT) de résolution dynamique, réduisant ainsi le fardeau de calculs en incluant des attributions de fenêtre tout en maintenant la résolution dynamique. Par conséquent, Qwen2.5-VL se distingue comme un agent visuel interactif pour le traitement de commandes, l'utilisation d'outils et l'exécution de tâches dans des scénarios réels, tant pour des images statiques et des documents que pour des interactions comme le gestion de dispositifs. Qwen2.5-VL est disponible en trois tailles pour aborder diverses applications. Comme modèle de pointe, Qwen2.5-VL-72B concourt avec des modèles récents tels que GPT-4o et Claude 3.5 Sonnet, surtout en ce qui concerne la compréhension de documents et de diagrammes. De plus, Qwen2.5-VL maintient les capacités linguistiques essentielles de Qwen2.5 LLM et maintient un rendement linguistique robuste.",
      "upvotes": 48,
      "discussionId": "67b6b0688b56622e70b9e875"
    },
    "publishedAt": "2025-02-19T23:35:06.194Z",
    "title": "Qwen2.5-VL Technical Report",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13923.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "63451cf0a05b51f7ded25505",
      "avatarUrl": "/avatars/dec4bbee4a82b773fc58dfc2dce9dbeb.svg",
      "fullname": "shuai bai",
      "name": "bluelike",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 11
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.13144",
      "authors": [
        {
          "_id": "67b55c7fba22c1ddbb8d5746",
          "user": {
            "_id": "6536187bd34e9f02b9df1c3b",
            "avatarUrl": "/avatars/0b34d62868b93053b0a05062a018b5bd.svg",
            "isPro": false,
            "fullname": "Hao Gao",
            "user": "Hao605",
            "type": "user"
          },
          "name": "Hao Gao",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-19T09:00:48.944Z",
          "hidden": false
        },
        {
          "_id": "67b55c7fba22c1ddbb8d5747",
          "name": "Shaoyu Chen",
          "hidden": false
        },
        {
          "_id": "67b55c7fba22c1ddbb8d5748",
          "name": "Bo Jiang",
          "hidden": false
        },
        {
          "_id": "67b55c7fba22c1ddbb8d5749",
          "name": "Bencheng Liao",
          "hidden": false
        },
        {
          "_id": "67b55c7fba22c1ddbb8d574a",
          "name": "Yiang Shi",
          "hidden": false
        },
        {
          "_id": "67b55c7fba22c1ddbb8d574b",
          "name": "Xiaoyang Guo",
          "hidden": false
        },
        {
          "_id": "67b55c7fba22c1ddbb8d574c",
          "name": "Yuechuan Pu",
          "hidden": false
        },
        {
          "_id": "67b55c7fba22c1ddbb8d574d",
          "name": "Haoran Yin",
          "hidden": false
        },
        {
          "_id": "67b55c7fba22c1ddbb8d574e",
          "name": "Xiangyu Li",
          "hidden": false
        },
        {
          "_id": "67b55c7fba22c1ddbb8d574f",
          "name": "Xinbang Zhang",
          "hidden": false
        },
        {
          "_id": "67b55c7fba22c1ddbb8d5750",
          "name": "Ying Zhang",
          "hidden": false
        },
        {
          "_id": "67b55c7fba22c1ddbb8d5751",
          "name": "Wenyu Liu",
          "hidden": false
        },
        {
          "_id": "67b55c7fba22c1ddbb8d5752",
          "name": "Qian Zhang",
          "hidden": false
        },
        {
          "_id": "67b55c7fba22c1ddbb8d5753",
          "name": "Xinggang Wang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-18T18:59:21.000Z",
      "title": "RAD : Entraînement de politiques de conduite depuis le point de départ jusqu'à l'arrivée en utilisant l'apprentissage par renforcement basé sur 3DGS",
      "summary": "Actuellement, l'algorithme de conduite automatique (AD) de bout en bout à bout en bout se développe généralement suivant le paradigme d'apprentissage en environnement immersif (IL). Ce méthode provoque des problèmes tels que la confusion causale et les erreurs de circuits fermés, entre autres. Dans cette étude, un paradigme d'apprentissage de résistance aux circuits fermés basé sur 3DGS est construit. En utilisant la technologie 3DGS, une image numérique de la réalité physique est construite et de vastes zones de l'espace des états sont explorées, permettant d'aborder des scénarios perturbateurs avec des erreurs significatives. Pour améliorer la sécurité, une récompense spéciale est conçue pour que la politique s'adapte efficacement aux événements sûrs et pour comprendre les relations causales dans la réalité. Pour améliorer la concordance avec les actions de conduite humaine, l'IL est intégré comme terme normalisant de la résistance aux circuits fermés. En comparant avec des méthodes basées sur l'IL, le RAD montre une grande amélioration sur plusieurs métriques de circuits fermés, en particulier en atteignant un taux de collisions trois fois moins élevé. Pour plus de détails sur les résultats des circuits fermés, consultez [https://hgao-cv.github.io/RAD](https://hgao-cv.github.io/RAD).",
      "upvotes": 22,
      "discussionId": "67b55c80ba22c1ddbb8d579c"
    },
    "publishedAt": "2025-02-19T22:13:49.764Z",
    "title": "RAD: Training an End-to-End Driving Policy via Large-Scale 3DGS-based Reinforcement Learning",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13144.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6536187bd34e9f02b9df1c3b",
      "avatarUrl": "/avatars/0b34d62868b93053b0a05062a018b5bd.svg",
      "fullname": "Hao Gao",
      "name": "Hao605",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.13128",
      "authors": [
        {
          "_id": "67b6c696e9b901edeaf320d5",
          "name": "Zihan Liu",
          "hidden": false
        },
        {
          "_id": "67b6c696e9b901edeaf320d6",
          "name": "Shuangrui Ding",
          "hidden": false
        },
        {
          "_id": "67b6c696e9b901edeaf320d7",
          "name": "Zhixiong Zhang",
          "hidden": false
        },
        {
          "_id": "67b6c696e9b901edeaf320d8",
          "name": "Xiaoyi Dong",
          "hidden": false
        },
        {
          "_id": "67b6c696e9b901edeaf320d9",
          "name": "Pan Zhang",
          "hidden": false
        },
        {
          "_id": "67b6c696e9b901edeaf320da",
          "name": "Yuhang Zang",
          "hidden": false
        },
        {
          "_id": "67b6c696e9b901edeaf320db",
          "name": "Yuhang Cao",
          "hidden": false
        },
        {
          "_id": "67b6c696e9b901edeaf320dc",
          "name": "Dahua Lin",
          "hidden": false
        },
        {
          "_id": "67b6c696e9b901edeaf320dd",
          "name": "Jiaqi Wang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-18T18:52:21.000Z",
      "title": "SongGen : Inférence des canaux pour la génération de musique à partir de texte en un seul pas automatique",
      "summary": "La génération de chansons est le processus de créer un bordel et un accompagnement à partir d'un texte d'entrée. Ce domaine rencontre de grands défis en raison de sa complexité et de la rareté des données. Les méthodes actuelles utilisent principalement des processus de génération multi-étapes, ce qui implique des processus d'entraînement et d'inférence complexes. Dans cet article, on propose un modèle d'apprentissage automatique mono-étape complètement ouvert-code, appelé Machine d'Apprentissage Channel-Driving. Ce modèle permet de contrôler de manière précise diverses caractéristiques musicales, comme les textes de chansons, la configuration des instruments, le genre, l'ambiance et la tonalité. De plus, il a été conçu pour sélectionner un clip de référence de 3 secondes pour cloner un bordel. Dans un seul cadre de travail intégré de récupération automatique, SongGen supporte des modes de mélange de bordel et d'accompagnement, ainsi qu'un mode de double bas. Dans le mode double bas, SongGen permet de créer des chansons avec un double bas, offrant une expérience de création musicale plus contrôlée et efficace.",
      "upvotes": 20,
      "discussionId": "67b6c698e9b901edeaf321a7"
    },
    "publishedAt": "2025-02-20T01:07:44.785Z",
    "title": "SongGen: A Single Stage Auto-regressive Transformer for Text-to-Song Generation",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13128.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64b4eec4faa3181a5eab9c46",
      "avatarUrl": "/avatars/bcc9bf5cbf67546ad2b4c9ec8b96ac96.svg",
      "fullname": "Jiaqi Wang",
      "name": "myownskyW7",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isMod": false,
      "followerCount": 16
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.13685",
      "authors": [
        {
          "_id": "67b6dc1ba7567156c6547880",
          "name": "Jusen Du",
          "hidden": false
        },
        {
          "_id": "67b6dc1ba7567156c6547881",
          "user": {
            "_id": "6246bb33da617c00b48e4d92",
            "avatarUrl": "/avatars/0304a9f6eb7f5dee4d933d03222f94e9.svg",
            "isPro": false,
            "fullname": "Weigao Sun",
            "user": "weigao266",
            "type": "user"
          },
          "name": "Weigao Sun",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-02-20T07:39:08.547Z",
          "hidden": false
        },
        {
          "_id": "67b6dc1ba7567156c6547882",
          "name": "Disen Lan",
          "hidden": false
        },
        {
          "_id": "67b6dc1ba7567156c6547883",
          "name": "Jiaxi Hu",
          "hidden": false
        },
        {
          "_id": "67b6dc1ba7567156c6547884",
          "name": "Yu Cheng",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-19T12:53:55.000Z",
      "title": "MoM : Modélisation de Séquences Linéaires avec Mémoire de Mémoire Confuse",
      "summary": "Les méthodes de modélisation séquentielle linéaires, comme par exemple l'action linéaire, le modélisation dans l'espace d'états et les réseaux neuronaux récurrents linéaires, réduisent la complexité de l'entraînement et de l'inférence, offrant ainsi une amélioration notable de l'efficacité. Cependant, ces méthodes apprennent à maintenir la capacité de mémoire à long terme du cerveau, réduisant l'interférence de la mémoire, en compressant l'entrée complète de la séquence dans un état de mémoire de taille fixe et en réduisant l'interférence de la mémoire, grâce à la capacité de maintenir la mémoire à long terme du cerveau.",
      "upvotes": 16,
      "discussionId": "67b6dc1ca7567156c65478b8"
    },
    "publishedAt": "2025-02-20T02:40:09.567Z",
    "title": "MoM: Linear Sequence Modeling with Mixture-of-Memories",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13685.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6246bb33da617c00b48e4d92",
      "avatarUrl": "/avatars/0304a9f6eb7f5dee4d933d03222f94e9.svg",
      "fullname": "Weigao Sun",
      "name": "weigao266",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.13347",
      "authors": [
        {
          "_id": "67b6a7e83ef3656c48f149b9",
          "user": {
            "_id": "6135eeeb5bc6ecdf86b60f0d",
            "avatarUrl": "/avatars/43cedcf20ab6b0801a662787400e1384.svg",
            "isPro": false,
            "fullname": "Shi Yu",
            "user": "yushi",
            "type": "user"
          },
          "name": "Shi Yu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-20T09:35:47.487Z",
          "hidden": false
        },
        {
          "_id": "67b6a7e83ef3656c48f149ba",
          "name": "Zhiyuan Liu",
          "hidden": false
        },
        {
          "_id": "67b6a7e83ef3656c48f149bb",
          "name": "Chenyan Xiong",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-19T00:31:43.000Z",
      "title": "Craw4LLM : Crawler Web pour l'Apprentissage Professionnel de LLM",
      "summary": "Le web scraping est l'une des principales sources de données pour l'entraînement préalable de modèles de langage grands (LLMs). Cependant, de nombreuses pages web recueillies de faible qualité sont éliminées lors de l'entraînement préalable. Cet article présente une méthodologie efficace de web scraping, appelée Crawl4LLM, qui s'adapte aux préférences de l'entraînement préalable de LLMs. En particulier, Crawl4LLM utilise l'influence des pages web sur l'entraînement préalable pour déterminer l'ordre de priorité de la liste de recherche, remplaçant la priorité basée sur la connectivité standard de graphes. À travers des expériences sur un graphe web de 900 millions de pages, basé sur l'index d'un moteur de recherche commercial, il est démontré que Crawl4LLM peut obtenir des données d'entraînement préalable de haute qualité de manière efficace. Avec seulement 21% des URLs recueillies, un LLM entraîné avec des données de Crawl4LLM atteint un rendement inférieur à celui observé avec une recherche préalable, réduisant significativement l'utilisation d'énergie et la charge des sites web. Le code est disponible sur GitHub : https://github.com/cxcscmu/Crawl4LLM.",
      "upvotes": 16,
      "discussionId": "67b6a7e93ef3656c48f149f1"
    },
    "publishedAt": "2025-02-19T22:57:23.298Z",
    "title": "Craw4LLM: Efficient Web Crawling for LLM Pretraining",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13347.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6135eeeb5bc6ecdf86b60f0d",
      "avatarUrl": "/avatars/43cedcf20ab6b0801a662787400e1384.svg",
      "fullname": "Shi Yu",
      "name": "yushi",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 7
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.13922",
      "authors": [
        {
          "_id": "67b6948dbef24bad725b5d4b",
          "name": "Guanzheng Chen",
          "hidden": false
        },
        {
          "_id": "67b6948dbef24bad725b5d4c",
          "name": "Xin Li",
          "hidden": false
        },
        {
          "_id": "67b6948dbef24bad725b5d4d",
          "name": "Michael Qizhe Shieh",
          "hidden": false
        },
        {
          "_id": "67b6948dbef24bad725b5d4e",
          "name": "Lidong Bing",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-19T17:59:03.000Z",
      "title": "LongPO : Evolution automatique sur long terme dans les modèles de langage pour optimiser le style des textes de court à long",
      "summary": "Les grands modèles de langue (LLMs) montrent des capacités impressionnantes grâce à l'entraînement préalable et l'ajustement. Cependant, dans des contextes longs, l'ajustement de contexte long n'est pas suffisant, ce qui peut entraîner une diminution du rendement des LLMs de contexte court à haut niveau. L'ajustement de contexte long reste un problème due à l'inefficacité humaine dans des contextes longs et au défi de équilibrer le rendement entre des contextes courts et longs. Pour résoudre ces problèmes, on présente LongPO. LongPO permet aux LLMs de contexte court de transmettre les capacités internes de gestion de contextes courts, ce qui leur permet d'afficher un excellent rendement dans des tâches de contexte long. LongPO entraîne les LLMs en utilisant des données préférentielles générées à partir de contextes courts, y compris des paires d'entrées de contexte long et sa compression correspondante en contexte court. Cette préférence montre la capacité et le potentiel des LLMs entraînés dans des contextes courts et la diminution qui survient dans des contextes longs. De plus, LongPO applique une restriction de KL depuis le contexte court jusqu'au contexte long pour atténuer la perte de rendement dans le contexte court lors de l'ajustement de contexte long. En appliquant LongPO à Mistral-7B-Instruct-v0.2, de un contexte de 128K à 512K, le rendement dans les contextes courts est maintenu complètement, et il est significativement supérieur aux méthodes de SFT et DPO. En particulier, les modèles entraînés avec LongPO peuvent concourir ou dépasser les hauts niveaux de LLMs avec des grandes échelles de paramètres et des ajustements de contexte long, comme GPT-4-128K.",
      "upvotes": 16,
      "discussionId": "67b6948ebef24bad725b5d84"
    },
    "publishedAt": "2025-02-19T21:35:20.931Z",
    "title": "LongPO: Long Context Self-Evolution of Large Language Models through Short-to-Long Preference Optimization",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13922.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "645475e2548f22be59847604",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/645475e2548f22be59847604/EhSurrZ25u31qQ2TVXQXt.jpeg",
      "fullname": "Chen",
      "name": "Guanzheng",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.12143",
      "authors": [
        {
          "_id": "67b4d05a9f8a8ab661450397",
          "name": "Yuetai Li",
          "hidden": false
        },
        {
          "_id": "67b4d05a9f8a8ab661450398",
          "name": "Xiang Yue",
          "hidden": false
        },
        {
          "_id": "67b4d05a9f8a8ab661450399",
          "user": {
            "_id": "653df1323479e9ebbe3eb6cc",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/653df1323479e9ebbe3eb6cc/K_g-r1iMRNKj99LXPuYF3.jpeg",
            "isPro": true,
            "fullname": "Zhangchen Xu",
            "user": "flydust",
            "type": "user"
          },
          "name": "Zhangchen Xu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-20T09:37:32.715Z",
          "hidden": false
        },
        {
          "_id": "67b4d05a9f8a8ab66145039a",
          "name": "Fengqing Jiang",
          "hidden": false
        },
        {
          "_id": "67b4d05a9f8a8ab66145039b",
          "name": "Luyao Niu",
          "hidden": false
        },
        {
          "_id": "67b4d05a9f8a8ab66145039c",
          "name": "Bill Yuchen Lin",
          "hidden": false
        },
        {
          "_id": "67b4d05a9f8a8ab66145039d",
          "name": "Bhaskar Ramasubramanian",
          "hidden": false
        },
        {
          "_id": "67b4d05a9f8a8ab66145039e",
          "name": "Radha Poovendran",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-17T18:56:15.000Z",
      "title": "Petits modèles ont des difficultés à apprendre de forts débattreurs.",
      "summary": "Les modèles de langage grands (LLMs) montrent un excellent rendement dans des tâches théoriques complexes. L'échec expérimental de l'absorption de la capacité théorique dans des petits modèles est intéressant. Cependant, nous avons découvert un phénomène intrigant que nous appelons \"erreur d'apprentissage des petits modèles\". Les petits modèles (avec moins de 3B paramètres) montrent des résultats meilleurs dans des chaînes de raisonnement courtes et simples, par rapport à des chaînes de raisonnement longues (Chain-of-Thought, CoT) ou aux grands modèles. En revanche, nous proposons une stratégie simple et efficace appelée \"Mix Distillation\" pour affronter ce phénomène. Cette stratégie combine des raisonnements de long et court CoT, ou de grands et petits modèles, pour équilibrer la complexité de la raisonnement. Nos expériences montrent que la Mix Distillation améliore significativement le rendement théorique des petits modèles qui dépendent exclusivement de données entraînées. Ces résultats soulignent directement les limites des conceptions de modèles grands et soulignent l'importance d'équilibrer la complexité de la raisonnement pour un mouvement vers une capacité théorique efficace.",
      "upvotes": 12,
      "discussionId": "67b4d05b9f8a8ab6614503cb"
    },
    "publishedAt": "2025-02-19T21:38:13.468Z",
    "title": "Small Models Struggle to Learn from Strong Reasoners",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.12143.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "653df1323479e9ebbe3eb6cc",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/653df1323479e9ebbe3eb6cc/K_g-r1iMRNKj99LXPuYF3.jpeg",
      "fullname": "Zhangchen Xu",
      "name": "flydust",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isMod": false,
      "followerCount": 8
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.13965",
      "authors": [
        {
          "_id": "67b6a3fa09841367596a1db5",
          "name": "Michael Luo",
          "hidden": false
        },
        {
          "_id": "67b6a3fa09841367596a1db6",
          "name": "Xiaoxiang Shi",
          "hidden": false
        },
        {
          "_id": "67b6a3fa09841367596a1db7",
          "name": "Colin Cai",
          "hidden": false
        },
        {
          "_id": "67b6a3fa09841367596a1db8",
          "name": "Tianjun Zhang",
          "hidden": false
        },
        {
          "_id": "67b6a3fa09841367596a1db9",
          "name": "Justin Wong",
          "hidden": false
        },
        {
          "_id": "67b6a3fa09841367596a1dba",
          "user": {
            "_id": "626e3449e7914f0d5ea78ad1",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/626e3449e7914f0d5ea78ad1/pVzdmdPMpNcxuj94qiIvB.jpeg",
            "isPro": false,
            "fullname": "Yichuan",
            "user": "Chrisyichuan",
            "type": "user"
          },
          "name": "Yichuan Wang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-20T09:35:50.487Z",
          "hidden": false
        },
        {
          "_id": "67b6a3fa09841367596a1dbb",
          "name": "Chi Wang",
          "hidden": false
        },
        {
          "_id": "67b6a3fa09841367596a1dbc",
          "name": "Yanping Huang",
          "hidden": false
        },
        {
          "_id": "67b6a3fa09841367596a1dbd",
          "name": "Zhifeng Chen",
          "hidden": false
        },
        {
          "_id": "67b6a3fa09841367596a1dbe",
          "name": "Joseph E. Gonzalez",
          "hidden": false
        },
        {
          "_id": "67b6a3fa09841367596a1dbf",
          "name": "Ion Stoica",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-19T18:59:30.000Z",
      "title": "Oterrix : Moteur de service efficace d'un agent de langage grand (un programme général)",
      "summary": "Les applications des modèles de langage grands (LLM) ont évolué au-delà de simples chatbots, développant la programmation d'agents pour des tâches générales dynamiques. Ces programmes aident les agents intelligents à explorer et à résoudre des tâches complexes de manière rationnelle, en échelonnant des appels à LLM et en utilisant des tokens de sortie. Cependant, les systèmes de service actuels de LLM ignorent la dépendance entre la programmation et l'appel, perdant des opportunités d'optimisation importantes. Selon notre analyse, les programmes présentés au moteur de service de LLM souvent subissent des délais accumulés de attendance dues aux demandes individuelles de LLM et au routage des têtes de programme. En réponse à cela, nous présentons \"Autellix\", un système qui traite les programmes comme des citoyens de première classe dans le service de LLM. Autellix insère des appels à LLM à partir des programmes et attribue un contexte au niveau du programme au scheduler. Nous proposons deux algorithmes de planification pour les programmes en single-thread et distribué : prioriser et préparer préalablement les appels à LLM en fonction de la complétion précédente du programme. Notre évaluation montre que, dans des temps d'exécution égaux, Autellix améliore les transactions de programme de 4 à 15 fois par rapport aux meilleurs systèmes (par exemple, vLLM) pour différents LLM et charges de travail d'agent.",
      "upvotes": 11,
      "discussionId": "67b6a3fb09841367596a1e06"
    },
    "publishedAt": "2025-02-19T22:42:06.502Z",
    "title": "Autellix: An Efficient Serving Engine for LLM Agents as General Programs",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13965.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "654037be97949fd2304aab7f",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/654037be97949fd2304aab7f/2cSME81gcwYa2OTeVlq5Q.jpeg",
      "fullname": "Michael Luo",
      "name": "michaelzhiluo",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.13946",
      "authors": [
        {
          "_id": "67b6b416b4ad845374143c31",
          "name": "Chak Tou Leong",
          "hidden": false
        },
        {
          "_id": "67b6b416b4ad845374143c32",
          "name": "Qingyu Yin",
          "hidden": false
        },
        {
          "_id": "67b6b416b4ad845374143c33",
          "name": "Jian Wang",
          "hidden": false
        },
        {
          "_id": "67b6b416b4ad845374143c34",
          "name": "Wenjie Li",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-19T18:42:45.000Z",
      "title": "Pourquoi ne pas plonger les navires protégés ? La structure de sécurité des grands modèles de langage corrigés est presque fixée dans les régions de modèles.",
      "summary": "La sécurité des modèles de langage grand (LLMs) est en un état faible et peuvent facilement être détruits par des attaques complexes. Dans les modèles existants de LLMs, il est courant de présenter un tampon fixe entre les instructions d'entrée et la première sortie du modèle, ce qui est supposé pouvoir agir comme une clé vulnérable : le design de la sécurité dans les LLMs dépend excessivement de l'information intégrée dans la zone du tampon, ce qui affecte significativement le comportement sécurisé de ces modèles. Cette problématique est appelée \"sécurité du tampon\". Dans cet article, des expériences étendues sont réalisées pour montrer qu'il existe une sécurité du tampon dans de nombreux modèles de LLMs. L'analyse structurelle montre que ce problème affecte la sécurité des modèles de manière que les attaques déstructrices puissent exploiter leurs vulnérabilités. De plus, il est indiqué que c'est souhaitable de séparer les fonctions de sécurité de la zone du tampon pour inhiber les vulnérabilités face aux attaques déstructrices. Dans les futures recherches, des méthodes seront recherchées pour réduire la dépendance du tampon, ce qui pourrait pousser le développement de technologies de sécurité plus puissantes.",
      "upvotes": 7,
      "discussionId": "67b6b416b4ad845374143c5b"
    },
    "publishedAt": "2025-02-19T23:54:57.669Z",
    "title": "Why Safeguarded Ships Run Aground? Aligned Large Language Models' Safety Mechanisms Tend to Be Anchored in The Template Region",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13946.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "631326d6289cf15634c52369",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/631326d6289cf15634c52369/lmPWGHLsQ36H556cqcXjT.jpeg",
      "fullname": "Cooper Leong",
      "name": "cooperleong00",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 5
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.13173",
      "authors": [
        {
          "_id": "67b6b014f7e569081326494f",
          "name": "Wang Yang",
          "hidden": false
        },
        {
          "_id": "67b6b014f7e5690813264950",
          "name": "Hongye Jin",
          "hidden": false
        },
        {
          "_id": "67b6b014f7e5690813264951",
          "name": "Jingfeng Yang",
          "hidden": false
        },
        {
          "_id": "67b6b014f7e5690813264952",
          "name": "Vipin Chaudhary",
          "hidden": false
        },
        {
          "_id": "67b6b014f7e5690813264953",
          "name": "Xiaotian Han",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-17T19:56:21.000Z",
      "title": "Preférence de Pensée Optimisation",
      "summary": "Supervised Fine-Tuning (SFT) est un méthode efficace pour améliorer la capacité de longue CoT (Chain-of-Thought) dans un petit LLM en utilisant des réponses longues de CoT obtenues d'un grand LLM. Ce méthode est complétée par la SFT. Pour continuer d'améliorer la capacité de longue CoT, on considère la collecte de nouveaux données de SFT de haute qualité ou le retraining des ensembles de données de SFT existants. Cependant, l'obtention de nouveaux données de SFT de longue CoT implique des coûts et des limites, et le retraining répétitif peut provoquer des patrons de performance ou une déclination. On propose l'Optimisation des Préférences de Pensée (ThinkPO) comme une façon de améliorer la qualité des données de SFT. ThinkPO sélectionne des réponses de longue CoT pour la même question, même lorsque des réponses de courte CoT sont éliminées. De plus, une optimisation directe des préférences est appliquée pour inciter le modèle à préférer des résultats logiques longs. Les expériences montrent que ThinkPO améliore la capacité logique des modèles SFT, augmentant par exemple la taux de réponses correctes en mathématiques de 8,6% et la longueur de la réponse de 25,9%. En particulier, ThinkPO peut continuellement améliorer le comportement des modèles SFT publics, comme augmenter la performance sur MATH500 du modèle DeepSeek-R1-Distill-Qwen-7B de 87,4% à 91,2%.",
      "upvotes": 7,
      "discussionId": "67b6b015f7e56908132649a0"
    },
    "publishedAt": "2025-02-19T23:31:36.410Z",
    "title": "Thinking Preference Optimization",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13173.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 6149
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.13962",
      "authors": [
        {
          "_id": "67b691751f861500916ecd5d",
          "user": {
            "_id": "6372bc95c4267fd7cd77f4d0",
            "avatarUrl": "/avatars/17a24af68f45487e601687d777b352b6.svg",
            "isPro": false,
            "fullname": "William Jurayj",
            "user": "wjurayj",
            "type": "user"
          },
          "name": "William Jurayj",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-20T09:36:09.674Z",
          "hidden": false
        },
        {
          "_id": "67b691751f861500916ecd5e",
          "name": "Jeffrey Cheng",
          "hidden": false
        },
        {
          "_id": "67b691751f861500916ecd5f",
          "name": "Benjamin Van Durme",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-19T18:58:31.000Z",
      "title": "C'est la réponse finale. La programmation du temps améliore la réponse aux problèmes de choix.",
      "summary": "Les modèles de langage à grande échelle qui ont augmenté la quantité de calculs au cours du temps de test ont démontré un comportement surprenant dans les marqueurs de logique. Cependant, l'évaluation de l'échelle en temps de test actuel suppose que les systèmes de logique doivent répondre aux questions fournies. Cela évite les préoccupations concernant si le modèle a confiance dans sa réponse et si fournir une réponse est toujours appropriée. Pour aborder ces préoccupations, un Score de Confiance lors de la logique est extrait pour évaluer les réponses du modèle. De cette manière, augmenter la charge de calcul dans le temps d'inférence peut augmenter la probabilité que le modèle réponde correctement et augmenter la confiance dans les réponses correctes. De plus, le modèle de réponse est étendu sans risque actuel et un méthode est proposée pour évaluer et rapporter l'évaluation en considérant des configurations où le risque de la réponse n'est pas nul.",
      "upvotes": 6,
      "discussionId": "67b691761f861500916ecd8e"
    },
    "publishedAt": "2025-02-19T23:34:43.424Z",
    "title": "Is That Your Final Answer? Test-Time Scaling Improves Selective Question Answering",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13962.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 6149
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.13233",
      "authors": [
        {
          "_id": "67b689aeba514d2c2c969289",
          "user": {
            "_id": "64beb6b6140491ca9f803ebf",
            "avatarUrl": "/avatars/0daa2e813a13668b8b708cd8c12763d9.svg",
            "isPro": false,
            "fullname": "Yucheng SHi",
            "user": "YuchengShi",
            "type": "user"
          },
          "name": "Yucheng Shi",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-20T09:36:18.925Z",
          "hidden": false
        },
        {
          "_id": "67b689aeba514d2c2c96928a",
          "name": "Tianze Yang",
          "hidden": false
        },
        {
          "_id": "67b689aeba514d2c2c96928b",
          "name": "Canyu Chen",
          "hidden": false
        },
        {
          "_id": "67b689aeba514d2c2c96928c",
          "name": "Quanzheng Li",
          "hidden": false
        },
        {
          "_id": "67b689aeba514d2c2c96928d",
          "name": "Tianming Liu",
          "hidden": false
        },
        {
          "_id": "67b689aeba514d2c2c96928e",
          "name": "Xiang Li",
          "hidden": false
        },
        {
          "_id": "67b689aeba514d2c2c96928f",
          "name": "Ninghao Liu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-18T19:12:15.000Z",
      "title": "SearchRAG : Pouvez-vous un moteur de recherche basé sur le langage naturel (LLM) aider à fournir des réponses médicales basées sur la recherche ?",
      "summary": "Les modèles de langue généralisées (LLMs) montrent des capacités exceptionnelles dans divers domaines, mais souvent rencontrent des défis lorsqu'il s'agit de tâches nécessitant des connaissances spécifiques. Les méthodes courantes de génération de littérature et de recherche (RAG) recueillent des informations externes à partir de bases de connaissances statiques, mais sont inefficaces et peuvent manquer de détails spécifiques nécessaires pour une consultation médicale précise. Dans cet article, nous proposons un nouveau cadre de travail appelé \"SearchRAG\" qui utilise un moteur de recherche en temps réel pour surmonter les limites des méthodes RAG. Notre approche crée un cache de synthèse pour transformer des requêtes complexes en attente médicale en questions qui peuvent être traitées par un moteur de recherche, et utilise un processus de sélection de connaissances basé sur les probabilités pour filtrer l'information la plus pertinente pour être incluse dans l'entrée de l'LLM. Les résultats des expérimentations montrent que notre approche améliore significativement la précision des réponses aux consultations médicales et est particulièrement efficace pour aborder des problèmes complexes qui nécessitent de l'information détaillée et actualisée.",
      "upvotes": 6,
      "discussionId": "67b689aeba514d2c2c9692b9"
    },
    "publishedAt": "2025-02-19T22:27:22.403Z",
    "title": "SearchRAG: Can Search Engines Be Helpful for LLM-based Medical Question Answering?",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13233.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64beb6b6140491ca9f803ebf",
      "avatarUrl": "/avatars/0daa2e813a13668b8b708cd8c12763d9.svg",
      "fullname": "Yucheng SHi",
      "name": "YuchengShi",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.13943",
      "authors": [
        {
          "_id": "67b6a9a7c721bee91cac2888",
          "name": "Yuliang Liu",
          "hidden": false
        },
        {
          "_id": "67b6a9a7c721bee91cac2889",
          "name": "Junjie Lu",
          "hidden": false
        },
        {
          "_id": "67b6a9a7c721bee91cac288a",
          "name": "Zhaoling Chen",
          "hidden": false
        },
        {
          "_id": "67b6a9a7c721bee91cac288b",
          "name": "Chaofeng Qu",
          "hidden": false
        },
        {
          "_id": "67b6a9a7c721bee91cac288c",
          "name": "Jason Klein Liu",
          "hidden": false
        },
        {
          "_id": "67b6a9a7c721bee91cac288d",
          "name": "Chonghan Liu",
          "hidden": false
        },
        {
          "_id": "67b6a9a7c721bee91cac288e",
          "name": "Zefan Cai",
          "hidden": false
        },
        {
          "_id": "67b6a9a7c721bee91cac288f",
          "name": "Yunhui Xia",
          "hidden": false
        },
        {
          "_id": "67b6a9a7c721bee91cac2890",
          "name": "Li Zhao",
          "hidden": false
        },
        {
          "_id": "67b6a9a7c721bee91cac2891",
          "name": "Jiang Bian",
          "hidden": false
        },
        {
          "_id": "67b6a9a7c721bee91cac2892",
          "name": "Chuheng Zhang",
          "hidden": false
        },
        {
          "_id": "67b6a9a7c721bee91cac2893",
          "name": "Wei Shen",
          "hidden": false
        },
        {
          "_id": "67b6a9a7c721bee91cac2894",
          "name": "Zhouhan Lin",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-19T18:35:55.000Z",
      "title": "AdaptiveStep : Division automatique du processus logique d'un modèle en fonction de la confiance du modèle.",
      "summary": "Les modèles actuels de récompense de processus (PRMs) utilisent un approche d'entraînement basée sur les règles et décomposent les raisons en plusieurs étapes de théorie. Par exemple, des étiquettes de symboles de divination sont utilisées pour déterminer la longueur des étapes de théorie d'un taille fixe. Cette approche est faible car elle ne reconnaît pas que certaines mots marquent vraiment des points de décision dans la phrase. Dans ce contexte, nous proposons AdaptiveStep. AdaptiveStep divise les étapes de théorie en fonction de la prédiction du prochain mot par le modèle. Ce méthode fournit plus d'informations de décision à chaque étape, améliorant ainsi le rendement dans des tâches ultérieures. De plus, notre méthode ne nécessite pas d'annotations manuelles. Nous avons démontré l'effet d'entraîner les PRMs avec AdaptiveStep sur des tâches de raisonnement mathématique et de génération de code, présentant les résultats expérimentaux. Les résultats montrent que les PRMs atteignent le meilleur rendement de \"meilleur de N\" et dépassent la stratégie de recherche greedie en utilisant la décodification des valeurs de token, en plus de réduire de moins de 30% les coûts d'implémentation par rapport aux PRMs ouverts. De plus, nous fournissons un analyse détaillée et des études de cas sur le rendement, la transitivité et la capacité de généralisation des PRMs.",
      "upvotes": 5,
      "discussionId": "67b6a9a8c721bee91cac28e7"
    },
    "publishedAt": "2025-02-19T23:07:01.367Z",
    "title": "AdaptiveStep: Automatically Dividing Reasoning Step through Model Confidence",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13943.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6529f79e802e3d1a4f8ec662",
      "avatarUrl": "/avatars/d05320c370a6497d8792ef5acb563dd5.svg",
      "fullname": "Yuliang Liu",
      "name": "yuliang03181",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.12638",
      "authors": [
        {
          "_id": "67b6acdb3a3df2f965e7af0b",
          "name": "Zhiyuan Liu",
          "hidden": false
        },
        {
          "_id": "67b6acdb3a3df2f965e7af0c",
          "name": "Yanchen Luo",
          "hidden": false
        },
        {
          "_id": "67b6acdb3a3df2f965e7af0d",
          "name": "Han Huang",
          "hidden": false
        },
        {
          "_id": "67b6acdb3a3df2f965e7af0e",
          "name": "Enzhi Zhang",
          "hidden": false
        },
        {
          "_id": "67b6acdb3a3df2f965e7af0f",
          "name": "Sihang Li",
          "hidden": false
        },
        {
          "_id": "67b6acdb3a3df2f965e7af10",
          "name": "Junfeng Fang",
          "hidden": false
        },
        {
          "_id": "67b6acdb3a3df2f965e7af11",
          "name": "Yaorui Shi",
          "hidden": false
        },
        {
          "_id": "67b6acdb3a3df2f965e7af12",
          "user": {
            "_id": "65fca775fa59bdf4737b1a84",
            "avatarUrl": "/avatars/a161b510bde8f57e7686cbb0b4aa6a52.svg",
            "isPro": false,
            "fullname": "Xiang Wang",
            "user": "xiangwang1223",
            "type": "user"
          },
          "name": "Xiang Wang",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-02-20T04:17:33.860Z",
          "hidden": false
        },
        {
          "_id": "67b6acdb3a3df2f965e7af13",
          "name": "Kenji Kawaguchi",
          "hidden": false
        },
        {
          "_id": "67b6acdb3a3df2f965e7af14",
          "name": "Tat-Seng Chua",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-18T08:40:13.000Z",
      "title": "NExT-Mol : Distribution 3D et Modélisation 1D de Langue pour la Génération de Molécules 3D",
      "summary": "La génération de molécules 3D est cruciale dans le développement de médicaments et le conception de matériaux. Les efforts antérieurs ont mis l'accent sur les avantages des modèles de dispersion 3D, mais ont ignoré les avantages des modèles de langage basés sur l'ATTENTION SELF-ATTENTION (SELF-ATTENTION) 1D. Les modèles de langage peuvent générer des molécules valides et utilisent des ensembles de données de molécules 1D contenant un milliard de molécules. En combinant ces avantages, nous proposons NExT-Mol : une intégration de modèles de dispersion 3D et de modélisation de langage 1D pour la génération de molécules 3D. NExT-Mol utilise un modèle de langage de molécules 1D large pour générer des molécules 1D et prédit la structure 3D de ces molécules. Nous améliorons le rendement de NExT-Mol en augmentant la taille du modèle de langage, en améliorant la structure du modèle de dispersion et en appliquant l'entraînement de transition entre 1D et 3D. En particulier, le modèle de langage 1D garantit la validité des molécules et dépasse les limites de la similitude de dispersion. De plus, le modèle de dispersion 3D atteint un rendement de pointe dans la prédiction de structures. Avec l'amélioration des modèles 1D et 3D, NExT-Mol réalise un accroissement relatif de 26% dans la génération de molécules 3D dans GEOM-DRUGS et un effet relatif moyen de 13% dans la génération conditionnelle de molécules 3D dans QM9-2014. Notre code et les checkpoints sont publiés sur https://github.com/acharkq/NExT-Mol.",
      "upvotes": 3,
      "discussionId": "67b6acdd3a3df2f965e7af85"
    },
    "publishedAt": "2025-02-19T23:18:32.647Z",
    "title": "NExT-Mol: 3D Diffusion Meets 1D Language Modeling for 3D Molecule Generation",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.12638.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6310a3cd531cc21f9e06de6a",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6310a3cd531cc21f9e06de6a/aTGMx3O41lUARK9s3dAik.jpeg",
      "fullname": "Zhiyuan Liu",
      "name": "acharkq",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.13581",
      "authors": [
        {
          "_id": "67b6ee04412c9eccae5151f5",
          "user": {
            "_id": "64a62c2f500beb50968e5c9c",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/wfL3ojJmXqyzGUmCblPf4.jpeg",
            "isPro": false,
            "fullname": "Yupeng Hou",
            "user": "hyp1231",
            "type": "user"
          },
          "name": "Yupeng Hou",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-20T09:35:14.498Z",
          "hidden": false
        },
        {
          "_id": "67b6ee04412c9eccae5151f6",
          "name": "Jianmo Ni",
          "hidden": false
        },
        {
          "_id": "67b6ee04412c9eccae5151f7",
          "name": "Zhankui He",
          "hidden": false
        },
        {
          "_id": "67b6ee04412c9eccae5151f8",
          "name": "Noveen Sachdeva",
          "hidden": false
        },
        {
          "_id": "67b6ee04412c9eccae5151f9",
          "name": "Wang-Cheng Kang",
          "hidden": false
        },
        {
          "_id": "67b6ee04412c9eccae5151fa",
          "name": "Ed H. Chi",
          "hidden": false
        },
        {
          "_id": "67b6ee04412c9eccae5151fb",
          "name": "Julian McAuley",
          "hidden": false
        },
        {
          "_id": "67b6ee04412c9eccae5151fc",
          "name": "Derek Zhiyuan Cheng",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-19T09:45:29.000Z",
      "title": "ActionPiece : Tokenisation séquentielle d'actions basée sur le contexte pour la recommandation générative",
      "summary": "La génération de recommandations (GR) est un nouveau paradigme qui transforme les actions de l'utilisateur en motifs de tokens dispersés pour les prédire automatiquement. Cependant, les modèles actuels de GR tokenisent indépendamment chaque action et attribuent le même token fixe à la même action dans toutes les séquences, sans considérer les relations contextuelles. Cette absence de connaissance contextuelle rend impossible pour le modèle de considérer que la même action peut avoir différents sens selon le contexte environnant, ce qui peut réduire son rendement. Pour résoudre ces problèmes, nous proposons ActionPiece. Dans ActionPiece, le contexte est considéré explicitement lors du tokenisage de séquences d'actions. Chaque action est représentée par un ensemble de vecteurs de caractéristiques des éléments, utilisés comme tokens initiaux. Des modèles de vecteurs de caractéristiques sont combinés à partir des données de corpus de séquences d'actions, et un dictionnaire est construit en tenant compte de la fréquence de coexistence. Étant donné que l'ordre des vecteurs de caractéristiques n'importe pas, nous avons introduit la normalisation d'échange pour générer plusieurs partitions de séquences d'actions avec le même sens. Les résultats des expériences sur des ensembles de données publiques montrent que ActionPiece améliore significativement le rendement par rapport aux méthodes de tokenisation d'actions existantes, augmentant la NDCG@10 dans un intervalle de 6,00% à 12,82%.",
      "upvotes": 2,
      "discussionId": "67b6ee04412c9eccae515223"
    },
    "publishedAt": "2025-02-20T03:56:54.121Z",
    "title": "ActionPiece: Contextually Tokenizing Action Sequences for Generative Recommendation",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13581.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64a62c2f500beb50968e5c9c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/wfL3ojJmXqyzGUmCblPf4.jpeg",
      "fullname": "Yupeng Hou",
      "name": "hyp1231",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 5
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.11995",
      "authors": [
        {
          "_id": "67b65bbe0d878eff1a6b111d",
          "name": "Siddhesh Pawar",
          "hidden": false
        },
        {
          "_id": "67b65bbe0d878eff1a6b111e",
          "name": "Arnav Arora",
          "hidden": false
        },
        {
          "_id": "67b65bbe0d878eff1a6b111f",
          "name": "Lucie-Aimée Kaffee",
          "hidden": false
        },
        {
          "_id": "67b65bbe0d878eff1a6b1120",
          "user": {
            "_id": "608918b7df398c3b285ce960",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1621507769190-608918b7df398c3b285ce960.jpeg",
            "isPro": false,
            "fullname": "Isabelle Augenstein",
            "user": "IAugenstein",
            "type": "user"
          },
          "name": "Isabelle Augenstein",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-20T09:36:32.278Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-17T16:35:15.000Z",
      "title": "La reconnue culture : Comment affecte-t-on les réponses d'un modèle de langage le nom ?",
      "summary": "Le nom est profondément lié à l'identité humaine. Les noms jouent le rôle de marqueurs des caractéristiques personnelles, du patrimoine culturel et de l'histoire personnelle des individus. Cependant, lorsqu'ils sont utilisés comme indicateurs centraux d'identification, ils sont associés à la simplification de l'identification complexe. Dans l'interaction avec un Modèle de Langue de Grande Taille (MLG), le nom de l'utilisateur est une information fondamentale pour la personnalisation. Le nom est entré dans le dialogue du chatbot via les données directes de l'utilisateur (demandées par le chatbot) et est stocké dans la mémoire interne pour personnaliser le contexte de travail (examen de CV, etc.). Nous étudions les biais liés aux noms et mesurons la prédiction culturelle dans les réponses générées à des requêtes qui cherchent des suggestions générales. Cette analyse montre une forte prédiction de l'identité culturelle associée aux noms dans la génération des MLG dans diverses cultures. Notre étude influence le design de systèmes de traitement plus complexes pour éviter les biais tout en maintenant une personnalisation significative.",
      "upvotes": 1,
      "discussionId": "67b65bbf0d878eff1a6b1174"
    },
    "publishedAt": "2025-02-20T01:20:46.431Z",
    "title": "Presumed Cultural Identity: How Names Shape LLM Responses",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.11995.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60c50f18754747f54fa37114",
      "avatarUrl": "/avatars/648ae58b81806dbd93a68546666047e3.svg",
      "fullname": "Siddhesh",
      "name": "sidicity",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.11573",
      "authors": [
        {
          "_id": "67b6f629d9da6999328e38f5",
          "name": "Congkai Xie",
          "hidden": false
        },
        {
          "_id": "67b6f629d9da6999328e38f6",
          "name": "Shuo Cai",
          "hidden": false
        },
        {
          "_id": "67b6f629d9da6999328e38f7",
          "name": "Wenjun Wang",
          "hidden": false
        },
        {
          "_id": "67b6f629d9da6999328e38f8",
          "name": "Pengxiang Li",
          "hidden": false
        },
        {
          "_id": "67b6f629d9da6999328e38f9",
          "name": "Zhijie Sang",
          "hidden": false
        },
        {
          "_id": "67b6f629d9da6999328e38fa",
          "name": "Kejing Yang",
          "hidden": false
        },
        {
          "_id": "67b6f629d9da6999328e38fb",
          "name": "Yiming Zhang",
          "hidden": false
        },
        {
          "_id": "67b6f629d9da6999328e38fc",
          "name": "Zhen Li",
          "hidden": false
        },
        {
          "_id": "67b6f629d9da6999328e38fd",
          "name": "Guanghao Zhu",
          "hidden": false
        },
        {
          "_id": "67b6f629d9da6999328e38fe",
          "name": "Zeyu Liu",
          "hidden": false
        },
        {
          "_id": "67b6f629d9da6999328e38ff",
          "name": "Yang Yu",
          "hidden": false
        },
        {
          "_id": "67b6f629d9da6999328e3900",
          "name": "Yuhang Liu",
          "hidden": false
        },
        {
          "_id": "67b6f629d9da6999328e3901",
          "name": "Su Lu",
          "hidden": false
        },
        {
          "_id": "67b6f629d9da6999328e3902",
          "name": "Baoyi He",
          "hidden": false
        },
        {
          "_id": "67b6f629d9da6999328e3903",
          "name": "Qi Zhou",
          "hidden": false
        },
        {
          "_id": "67b6f629d9da6999328e3904",
          "name": "Xiaotian Han",
          "hidden": false
        },
        {
          "_id": "67b6f629d9da6999328e3905",
          "name": "Jianbo Yuan",
          "hidden": false
        },
        {
          "_id": "67b6f629d9da6999328e3906",
          "name": "Shengyu Zhang",
          "hidden": false
        },
        {
          "_id": "67b6f629d9da6999328e3907",
          "name": "Fei Wu",
          "hidden": false
        },
        {
          "_id": "67b6f629d9da6999328e3908",
          "name": "Hongxia Yang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-17T09:07:32.000Z",
      "title": "InfiR : Méthode de Création de Modèles de Langue Efficaces et de Modèles de Langue Multi-modèle Basé sur les Causes",
      "summary": "Les Grands Modèles de Langue (GMLs) et les Grands Modèles de Langue Multimodal (GMLMs) ont marqué un grand avance dans le développement de l'intelligence artificielle. Cependant, ces modèles présentent des problèmes comme des fortes demandes en ressources et des problèmes de confidentialité, entre autres. Dans cet article, nous nous concentrons sur le développement de Modèles de Langue Petits (MLPs) et de Modèles de Langue Multimodal Petits (MLMPs) pour maintenir une intelligence artificielle forte. Nous présentons un nouveau processus d'entraînement pour améliorer l'intelligence artificielle, avec l'objectif d'atteindre les meilleurs résultats possibles tout en minimisant les coûts de développement. InfR vise à encourager le développement de systèmes d'intelligence artificielle, améliorer l'intelligence artificielle, réduire l'incidence de handicap professionnel et résoudre les problèmes de confidentialité en utilisant des modèles de petite taille. Les ressources sont disponibles sur https://github.com/Reallm-Labs/InfiR.",
      "upvotes": 0,
      "discussionId": "67b6f62ad9da6999328e3955"
    },
    "publishedAt": "2025-02-20T04:32:22.011Z",
    "title": "InfiR : Crafting Effective Small Language Models and Multimodal Small Language Models in Reasoning",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.11573.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "618c1ad1c74578e0a4a4d074",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/618c1ad1c74578e0a4a4d074/8u_AkeHt4d6xtQ8hzaffU.jpeg",
      "fullname": "Drishti Sharma",
      "name": "DrishtiSharma",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 60
    },
    "isAuthorParticipating": false
  }
]