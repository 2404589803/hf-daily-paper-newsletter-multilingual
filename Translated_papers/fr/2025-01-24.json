[
  {
    "paper": {
      "id": "2501.13200",
      "authors": [
        {
          "_id": "67933d69b843fda452c689dd",
          "user": {
            "_id": "65c0db0fbda79a18292dfbb7",
            "avatarUrl": "/avatars/1201b8282664c2d8c18beaba2396c03b.svg",
            "isPro": false,
            "fullname": "Alsu Sagirova",
            "user": "alsu-sagirova",
            "type": "user"
          },
          "name": "Alsu Sagirova",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-01-24T09:07:49.036Z",
          "hidden": false
        },
        {
          "_id": "67933d69b843fda452c689de",
          "name": "Yuri Kuratov",
          "hidden": false
        },
        {
          "_id": "67933d69b843fda452c689df",
          "user": {
            "_id": "639c6e978a34ed9a404c6a7b",
            "avatarUrl": "/avatars/c98ca8c9f9ed8509c2f1bb6aa994fd57.svg",
            "isPro": false,
            "fullname": "MIKHAIL BURTSEV",
            "user": "mbur",
            "type": "user"
          },
          "name": "Mikhail Burtsev",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:07:03.954Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-22T20:08:53.000Z",
      "title": "SRMT : Projet de mémoire partagée pour le classement de vies multiples agents et la recherche de mots de passe",
      "summary": "La vision des effets multiples dans l'apprentissage par renforcement multi-agent (MARL) montre une grande avancée dans la résolution efficace de problèmes d'entreprise et compétitifs multi-agent dans différents environnements. L'un des principaux défis du MARL est la nécessité de prédire explicitement les actions de chaque agent pour atteindre les objectifs d'entreprise. Pour aborder ce problème, nous proposons l'extension de la transformer de mémoire vers un environnement multi-agent appelé \"Transformer de Mémoire de Réproduction Partagée (SRMT)\". SRMT permet aux agents d'échanger des informations cachées et de réguler leurs actions mutuellement. SRMT a été évalué dans des problèmes d'apprentissage par renforcement multi-agent observables par portefeuille, tels que le TASK de Navigation dans le Collar de Potter et le TASK de POGEMA. Dans le TASK de Navigation dans le Collar de Potter, SRMT a démontré une excellence dans les lignes d'apprentissage basées sur des renforcements divers, en particulier en généralisant efficacement lors d'entraînements plus longs avec des récompenses rares. Dans le TASK de POGEMA MAP, SRMT a compété avec des algorithmes de MARL, hybrides et basés sur la planification, y compris des cartes comme MAZES, RANDOM et MovingAI. Ces résultats montrent que l'intégration d'une mémoire de reproduction partagée dans des architectures basées sur des transformers peut améliorer la coordination dans des systèmes multi-agent distribués. Les codes source pour l'apprentissage et l'évaluation sont disponibles sur GitHub : https://github.com/Aloriosa/srmt.",
      "upvotes": 36,
      "discussionId": "67933d6ab843fda452c68a38"
    },
    "publishedAt": "2025-01-24T02:35:35.802Z",
    "title": "SRMT: Shared Memory for Multi-agent Lifelong Pathfinding",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.13200.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "65c0db0fbda79a18292dfbb7",
      "avatarUrl": "/avatars/1201b8282664c2d8c18beaba2396c03b.svg",
      "fullname": "Alsu Sagirova",
      "name": "alsu-sagirova",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2501.13918",
      "authors": [
        {
          "_id": "679319848d46289f90266168",
          "user": {
            "_id": "639be86b59473c6ae02ef9c4",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/639be86b59473c6ae02ef9c4/gw34RBCVZCOkcAA79xUr3.png",
            "isPro": false,
            "fullname": "Jie Liu",
            "user": "jieliu",
            "type": "user"
          },
          "name": "Jie Liu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-01-24T09:07:53.235Z",
          "hidden": false
        },
        {
          "_id": "679319848d46289f90266169",
          "name": "Gongye Liu",
          "hidden": false
        },
        {
          "_id": "679319848d46289f9026616a",
          "name": "Jiajun Liang",
          "hidden": false
        },
        {
          "_id": "679319848d46289f9026616b",
          "name": "Ziyang Yuan",
          "hidden": false
        },
        {
          "_id": "679319848d46289f9026616c",
          "name": "Xiaokun Liu",
          "hidden": false
        },
        {
          "_id": "679319848d46289f9026616d",
          "name": "Mingwu Zheng",
          "hidden": false
        },
        {
          "_id": "679319848d46289f9026616e",
          "name": "Xiele Wu",
          "hidden": false
        },
        {
          "_id": "679319848d46289f9026616f",
          "name": "Qiulin Wang",
          "hidden": false
        },
        {
          "_id": "679319848d46289f90266170",
          "name": "Wenyu Qin",
          "hidden": false
        },
        {
          "_id": "679319848d46289f90266171",
          "name": "Menghan Xia",
          "hidden": false
        },
        {
          "_id": "679319848d46289f90266172",
          "user": {
            "_id": "60e272ca6c78a8c122b12127",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/60e272ca6c78a8c122b12127/xldEGBzGrU-bX6IwAw0Ie.jpeg",
            "isPro": false,
            "fullname": "Xintao Wang",
            "user": "Xintao",
            "type": "user"
          },
          "name": "Xintao Wang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-01-24T09:07:51.248Z",
          "hidden": false
        },
        {
          "_id": "679319848d46289f90266173",
          "name": "Xiaohong Liu",
          "hidden": false
        },
        {
          "_id": "679319848d46289f90266174",
          "name": "Fei Yang",
          "hidden": false
        },
        {
          "_id": "679319848d46289f90266175",
          "name": "Pengfei Wan",
          "hidden": false
        },
        {
          "_id": "679319848d46289f90266176",
          "name": "Di Zhang",
          "hidden": false
        },
        {
          "_id": "679319848d46289f90266177",
          "name": "Kun Gai",
          "hidden": false
        },
        {
          "_id": "679319848d46289f90266178",
          "name": "Yujiu Yang",
          "hidden": false
        },
        {
          "_id": "679319848d46289f90266179",
          "name": "Wanli Ouyang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-23T18:55:41.000Z",
      "title": "Améliorer la génération de vidéos en utilisant la rétroaction humaine",
      "summary": "La génération de vidéos a évolué grâce à la technologie des flux de normalisation, bien que des problèmes persistent comme des mouvements inadéquats ou l'asymétrie entre vidéos et prompts. Dans cette étude, un système de pipeline icônique est développé en utilisant une rétroaction humaine pour atténuer ces problèmes et créer un modèle de génération de vidéos plus précis. En particulier, l'étude se concentre sur des modèles modernes de génération de vidéos et construit un grand ensemble de données de préférences humaines pour inclure des explications de paires de dimensions. Ensuite, le modèle de récompense de vidéos (VideoReward) est introduit pour évaluer l'impact des choix de design et des explications sur l'effet de la récompense. La récompense est maximisée à partir d'une perspective unique d'apprentissage par renforcement, incluant la normalisation de Kullback-Leibler et trois algorithmes d'initialisation pour des modèles basés sur des flux. Ces algorithmes offrent deux stratégies lors de l'entraînement : l'optimisation directe du plaisir du flux (Flow-DPO) et la régression avec poids de récompense (Flow-RWR), et lors de l'inférence, la guidance de récompense avec bruit (Flow-NRG). Flow-NRG applique directement une guidance de récompense à des vidéos avec bruit lors de l'inférence. Les résultats des expériences montrent que VideoReward dépasse significativement les modèles de récompense existants, et Flow-DPO présente un comportement exceptionnel comparé à Flow-RWR et au méthode optimale d'entraînement de normalisation standard. De plus, Flow-NRG permet d'attribuer des poids personnalisés à plusieurs objets lors de l'inférence, ce qui satisfait la qualité individuelle des vidéos. Page du projet : https://gongyeliu.github.io/videoalign.",
      "upvotes": 28,
      "discussionId": "679319858d46289f90266203"
    },
    "publishedAt": "2025-01-24T05:39:01.676Z",
    "title": "Improving Video Generation with Human Feedback",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.13918.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "639be86b59473c6ae02ef9c4",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/639be86b59473c6ae02ef9c4/gw34RBCVZCOkcAA79xUr3.png",
      "fullname": "Jie Liu",
      "name": "jieliu",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 10
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2501.13629",
      "authors": [
        {
          "_id": "6792f8ed5e3ec6035dafb06a",
          "user": {
            "_id": "63776f1806241efce1e7aae6",
            "avatarUrl": "/avatars/d67d9dcd932934c630f407ac152f2ce6.svg",
            "isPro": false,
            "fullname": "Zhenghao Lin",
            "user": "Lin0",
            "type": "user"
          },
          "name": "Zhenghao Lin",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T09:14:52.584Z",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb06b",
          "user": {
            "_id": "656c6bd8e0ff1cebe966aa35",
            "avatarUrl": "/avatars/1083cb58bdb0bee72036953276d42e13.svg",
            "isPro": false,
            "fullname": "tangzihao",
            "user": "tzh94588",
            "type": "user"
          },
          "name": "Zihao Tang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T09:15:04.802Z",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb06c",
          "user": {
            "_id": "63fb6e281b4b1bd4e7ffc5be",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1677422062937-noauth.jpeg",
            "isPro": false,
            "fullname": "Xiao Liu",
            "user": "lx865712528",
            "type": "user"
          },
          "name": "Xiao Liu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-01-24T09:08:05.797Z",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb06d",
          "user": {
            "_id": "643f615aa16cd6d1f4c581de",
            "avatarUrl": "/avatars/47753a3e82b44f81881600c52e1e8495.svg",
            "isPro": false,
            "fullname": "Yeyun Gong",
            "user": "yegong",
            "type": "user"
          },
          "name": "Yeyun Gong",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T09:58:33.228Z",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb06e",
          "name": "Yi Cheng",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb06f",
          "name": "Qi Chen",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb070",
          "user": {
            "_id": "61342a4b488458a484dee6c4",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1630808595161-noauth.png",
            "isPro": false,
            "fullname": "Hang Li",
            "user": "hanglics",
            "type": "user"
          },
          "name": "Hang Li",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:03:59.680Z",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb071",
          "name": "Ying Xin",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb072",
          "user": {
            "_id": "62f6a9add3bdacb7eec0d4f5",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1660332390183-noauth.jpeg",
            "isPro": false,
            "fullname": "Ziyue Yang",
            "user": "ziyueyang37",
            "type": "user"
          },
          "name": "Ziyue Yang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:04:09.709Z",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb073",
          "user": {
            "_id": "646fc402e9c03ba436d5e93e",
            "avatarUrl": "/avatars/870c86dc99fb1cb6a348a7a0385b1a04.svg",
            "isPro": false,
            "fullname": "Kailai Yang",
            "user": "klyang",
            "type": "user"
          },
          "name": "Kailai Yang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:04:16.033Z",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb074",
          "name": "Yu Yan",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb075",
          "name": "Xiao Liang",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb076",
          "name": "Shuai Lu",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb077",
          "name": "Yiming Huang",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb078",
          "user": {
            "_id": "6443bb593c323e0918f61a96",
            "avatarUrl": "/avatars/b9e1ba17f7798b5142bc0124fba95237.svg",
            "isPro": false,
            "fullname": "zheheng luo",
            "user": "KenLuo",
            "type": "user"
          },
          "name": "Zheheng Luo",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:04:49.140Z",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb079",
          "name": "Lei Qu",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb07a",
          "name": "Xuan Feng",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb07b",
          "name": "Yaoxiang Wang",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb07c",
          "user": {
            "_id": "6369e01864aad59d4d4501ac",
            "avatarUrl": "/avatars/bcbd3f9d0d194eeccd061c4fa6a6e283.svg",
            "isPro": false,
            "fullname": "Yuqing Xia",
            "user": "yuqxia",
            "type": "user"
          },
          "name": "Yuqing Xia",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:05:26.287Z",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb07d",
          "user": {
            "_id": "673fd856a45b6f21829a3bf5",
            "avatarUrl": "/avatars/deb8c5362fad22019cccaed6d03dea09.svg",
            "isPro": false,
            "fullname": "Feiyang Chen",
            "user": "PhilipChen",
            "type": "user"
          },
          "name": "Feiyang Chen",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:05:34.991Z",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb07e",
          "user": {
            "_id": "64e85f4e5ddcace745bc0a55",
            "avatarUrl": "/avatars/e316355b913c73104db530010ceedeb4.svg",
            "isPro": false,
            "fullname": "Yuting Jiang",
            "user": "Stautinger",
            "type": "user"
          },
          "name": "Yuting Jiang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:05:41.151Z",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb07f",
          "name": "Yasen Hu",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb080",
          "name": "Hao Ni",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb081",
          "user": {
            "_id": "6485714cfc41a0b97fe377cc",
            "avatarUrl": "/avatars/0af8a3df9ad711a5eac739bce26c4c2a.svg",
            "isPro": false,
            "fullname": "Li",
            "user": "Binyang",
            "type": "user"
          },
          "name": "Binyang Li",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:06:03.263Z",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb082",
          "user": {
            "_id": "663de80ca920d195191807da",
            "avatarUrl": "/avatars/2437ce3fa073a07b971d370c26c7ab65.svg",
            "isPro": false,
            "fullname": "Guoshuai Zhao",
            "user": "crayonshine",
            "type": "user"
          },
          "name": "Guoshuai Zhao",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:05:17.780Z",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb083",
          "name": "Jui-Hao Chiang",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb084",
          "name": "Zhongxin Guo",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb085",
          "name": "Chen Lin",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb086",
          "name": "Kun Kuang",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb087",
          "user": {
            "_id": "66a3710a4ee2a4c936315a5a",
            "avatarUrl": "/avatars/ef8da8fb1031695d77d34a5d365aa177.svg",
            "isPro": false,
            "fullname": "Li",
            "user": "WenjieLi",
            "type": "user"
          },
          "name": "Wenjie Li",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:06:22.951Z",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb088",
          "user": {
            "_id": "6454c337a13edf669cd5d8ea",
            "avatarUrl": "/avatars/a383a0dda7c2ef6a0d6c3c64651f42ff.svg",
            "isPro": false,
            "fullname": "Yelong Shen",
            "user": "uuu6",
            "type": "user"
          },
          "name": "Yelong Shen",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:06:30.109Z",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb089",
          "name": "Jian Jiao",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb08a",
          "name": "Peng Cheng",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb08b",
          "name": "Mao Yang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-23T12:58:14.000Z",
      "title": "Sigma : Modèle de langage efficace par ajustement des différences de questions, clés et valeurs",
      "summary": "Sigma est un grand modèle de langage qui s'adapte aux domaines spécifiques de systèmes, en se basant sur une nouvelle architecture. Il introduit la technique d'attention DiffQKV, ce qui signifie une augmentation considérable de l'efficacité de l'inférence du modèle. L'attention DiffQKV optimise les paramètres de performance et d'efficacité du modèle en considérant que les composantes Query (Q), Key (K) et Value (V) ont des effets différents. En particulier, elle démontre sa capacité à gérer des tâches complexes en K et V, en développant un V plus compact et en étendant la dimension des têtes Q pour améliorer la représentation du modèle. Selon l'analyse théorique et expérimentale, l'attention DiffQKV atteint un accroissement de 33,36% de la vitesse d'inférence par rapport à GQA dans des contextes longs. Sigma a été entraîné sur 6T tokens de données, dont 19,5B sont de données de domaines de systèmes et 1T sont des données synthétiques collectées avec soin. Dans les domaines généraux, Sigma montre le même rendement que d'autres modèles de haut rendement, tandis que dans les domaines de systèmes, il est le premier modèle à avoir enregistré des résultats confirmés sur le benchmark AIMicius. Dans ce benchmark, Sigma montre des résultats exceptionnels pour toutes les tâches, dépassant de manière significative GPT-4 avec un accroissement absolu de 52,5%.",
      "upvotes": 27,
      "discussionId": "6792f8f05e3ec6035dafb140"
    },
    "publishedAt": "2025-01-23T22:48:16.405Z",
    "title": "Sigma: Differential Rescaling of Query, Key and Value for Efficient Language Models",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.13629.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "63fb6e281b4b1bd4e7ffc5be",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1677422062937-noauth.jpeg",
      "fullname": "Xiao Liu",
      "name": "lx865712528",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 7
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2501.13926",
      "authors": [
        {
          "_id": "6793040ec67af4a116a25d05",
          "user": {
            "_id": "647d9ab61a1fcad2fdbf2d3d",
            "avatarUrl": "/avatars/48c8aeae8979d2c87df8bde922437d62.svg",
            "isPro": true,
            "fullname": "Ziyu Guo",
            "user": "ZiyuG",
            "type": "user"
          },
          "name": "Ziyu Guo",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:07:58.258Z",
          "hidden": false
        },
        {
          "_id": "6793040ec67af4a116a25d06",
          "name": "Renrui Zhang",
          "hidden": false
        },
        {
          "_id": "6793040ec67af4a116a25d07",
          "name": "Chengzhuo Tong",
          "hidden": false
        },
        {
          "_id": "6793040ec67af4a116a25d08",
          "user": {
            "_id": "6713a71e7dfe714b425cccfb",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/95YYcbv_f6J8yWTunwn4z.png",
            "isPro": false,
            "fullname": "zhizhengzhao",
            "user": "zhizhengzhao",
            "type": "user"
          },
          "name": "Zhizheng Zhao",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:08:20.272Z",
          "hidden": false
        },
        {
          "_id": "6793040ec67af4a116a25d09",
          "user": {
            "_id": "6759af3eccbc8817f9169179",
            "avatarUrl": "/avatars/49e64c7ccf71b8f25c52783b6ae93620.svg",
            "isPro": false,
            "fullname": "Peng Gao",
            "user": "gaopenghigh",
            "type": "user"
          },
          "name": "Peng Gao",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:08:26.816Z",
          "hidden": false
        },
        {
          "_id": "6793040ec67af4a116a25d0a",
          "user": {
            "_id": "65c04e9c27a5fdca81abcbd9",
            "avatarUrl": "/avatars/12a155683c824fa23da4a9e2bed4f64e.svg",
            "isPro": false,
            "fullname": "Hongsheng LI",
            "user": "hsli-cuhk",
            "type": "user"
          },
          "name": "Hongsheng Li",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:08:33.312Z",
          "hidden": false
        },
        {
          "_id": "6793040ec67af4a116a25d0b",
          "name": "Pheng-Ann Heng",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-23T18:59:43.000Z",
      "title": "Pouvez-vous générer des images dans le CoT ? Vérifier et améliorer la génération d'images à mesure.",
      "summary": "La raisonnement par chaîne d'esprit (CoT) est largement révisé pour résoudre des tâches complexes dans des modèles grands. Cependant, l'applicabilité de ces stratégies dans la validation et le renforcement de scénarios de génération d'images reste un sujet de débat. Dans cet article, nous examinons en détail la possibilité que le raisonnement par chaîne d'esprit renforce la génération automatique d'images. L'approche comprend trois technologies : l'accélération du calcul de temps de test pour la validation, la concordance entre le style du modèle et l'Optimisation de Préférences Directes (DPO), et l'intégration des effets complémentaires de ces technologies. Cette approche montre qu'il est possible de significativement améliorer le rendement de la génération d'images. De plus, en considérant le rôle crucial des modèles de récompense dans nos résultats, nous proposons le Modèle de Récompense d'Évaluation Potentielle (PARM) et PARM++ (PARM++). Le PARM intègre les forces des modèles de récompense existants et évalue chaque étape de génération de manière adaptative en utilisant un approche d'évaluation potentielle. Le PARM++ ajoute une fonction de correction automatique pour corriger les images générées avec insatisfaction. En utilisant la technique d'accès à la cause, nous renforceons le modèle de base Show-o pour atteindre un amélioration significative de +24% sur le benchmark GenEval, et dépasser la Stable Diffusion 3 de plus de +15%. Notre étude offre une vision spécifique sur l'intégration du raisonnement par chaîne d'esprit et la génération automatique d'images, ouvrant de nouvelles voies. Les codes et modèles sont disponibles sur https://github.com/ZiyuGuo99/Image-Generation-CoT.",
      "upvotes": 9,
      "discussionId": "67930410c67af4a116a25da4"
    },
    "publishedAt": "2025-01-23T22:08:17.598Z",
    "title": "Can We Generate Images with CoT? Let's Verify and Reinforce Image Generation Step by Step",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.13926.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "63468720dd6d90d82ccf3450",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63468720dd6d90d82ccf3450/tVBFlmZNz8FRMkOrDaDID.jpeg",
      "fullname": "YSH",
      "name": "BestWishYsh",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 28
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.13920",
      "authors": [
        {
          "_id": "679316ff3698fd97252a8e6f",
          "user": {
            "_id": "64c3c72e8f31d1e6c664b052",
            "avatarUrl": "/avatars/af1ad5048eaa9dc417837ad02f927911.svg",
            "isPro": false,
            "fullname": "jiayi lei",
            "user": "jyjyjyjy",
            "type": "user"
          },
          "name": "Jiayi Lei",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:12:22.641Z",
          "hidden": false
        },
        {
          "_id": "679316ff3698fd97252a8e70",
          "name": "Renrui Zhang",
          "hidden": false
        },
        {
          "_id": "679316ff3698fd97252a8e71",
          "name": "Xiangfei Hu",
          "hidden": false
        },
        {
          "_id": "679316ff3698fd97252a8e72",
          "user": {
            "_id": "66026c9068d519ed32519e9c",
            "avatarUrl": "/avatars/8fa051312c713772e5b8ba65989ff7f5.svg",
            "isPro": false,
            "fullname": "Weifeng Lin",
            "user": "Afeng-x",
            "type": "user"
          },
          "name": "Weifeng Lin",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:13:07.303Z",
          "hidden": false
        },
        {
          "_id": "679316ff3698fd97252a8e73",
          "name": "Zhen Li",
          "hidden": false
        },
        {
          "_id": "679316ff3698fd97252a8e74",
          "name": "Wenjian Sun",
          "hidden": false
        },
        {
          "_id": "679316ff3698fd97252a8e75",
          "user": {
            "_id": "64a54586c0f13de8e7093314",
            "avatarUrl": "/avatars/389e43e9a32cf2fc95f8f3a23b8f0508.svg",
            "isPro": false,
            "fullname": "Ruoyi Du",
            "user": "RuoyiDu",
            "type": "user"
          },
          "name": "Ruoyi Du",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:13:21.861Z",
          "hidden": false
        },
        {
          "_id": "679316ff3698fd97252a8e76",
          "user": {
            "_id": "6358a167f56b03ec9147074d",
            "avatarUrl": "/avatars/e54ea7bf0c240cf76d538296efb3976c.svg",
            "isPro": false,
            "fullname": "Le Zhuo",
            "user": "JackyZhuo",
            "type": "user"
          },
          "name": "Le Zhuo",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:13:27.523Z",
          "hidden": false
        },
        {
          "_id": "679316ff3698fd97252a8e77",
          "user": {
            "_id": "6740a5730bb4a675446a80ad",
            "avatarUrl": "/avatars/27c08e33df88e4f73c136da65f2b5adb.svg",
            "isPro": false,
            "fullname": "Zhong-Yu Li",
            "user": "lzyhha",
            "type": "user"
          },
          "name": "Zhongyu Li",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:13:33.108Z",
          "hidden": false
        },
        {
          "_id": "679316ff3698fd97252a8e78",
          "name": "Xinyue Li",
          "hidden": false
        },
        {
          "_id": "679316ff3698fd97252a8e79",
          "user": {
            "_id": "62c66504031996c36c86976a",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62c66504031996c36c86976a/wIq0YJhkWnEhlzsh-TGYO.png",
            "isPro": true,
            "fullname": "steve z",
            "user": "stzhao",
            "type": "user"
          },
          "name": "Shitian Zhao",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-01-24T13:30:14.688Z",
          "hidden": false
        },
        {
          "_id": "679316ff3698fd97252a8e7a",
          "user": {
            "_id": "647d9ab61a1fcad2fdbf2d3d",
            "avatarUrl": "/avatars/48c8aeae8979d2c87df8bde922437d62.svg",
            "isPro": true,
            "fullname": "Ziyu Guo",
            "user": "ZiyuG",
            "type": "user"
          },
          "name": "Ziyu Guo",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:14:21.821Z",
          "hidden": false
        },
        {
          "_id": "679316ff3698fd97252a8e7b",
          "user": {
            "_id": "6614fb3d5aed02b298a4b469",
            "avatarUrl": "/avatars/d0ddb4f989ad1a3f24128cc843347bde.svg",
            "isPro": false,
            "fullname": "yiting lu",
            "user": "yeeeeeyy",
            "type": "user"
          },
          "name": "Yiting Lu",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:14:50.714Z",
          "hidden": false
        },
        {
          "_id": "679316ff3698fd97252a8e7c",
          "user": {
            "_id": "6759af3eccbc8817f9169179",
            "avatarUrl": "/avatars/49e64c7ccf71b8f25c52783b6ae93620.svg",
            "isPro": false,
            "fullname": "Peng Gao",
            "user": "gaopenghigh",
            "type": "user"
          },
          "name": "Peng Gao",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:15:04.489Z",
          "hidden": false
        },
        {
          "_id": "679316ff3698fd97252a8e7d",
          "user": {
            "_id": "65c04e9c27a5fdca81abcbd9",
            "avatarUrl": "/avatars/12a155683c824fa23da4a9e2bed4f64e.svg",
            "isPro": false,
            "fullname": "Hongsheng LI",
            "user": "hsli-cuhk",
            "type": "user"
          },
          "name": "Hongsheng Li",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:15:11.437Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-23T18:58:33.000Z",
      "title": "IMAGINE-E : Évaluation avancée de la génération d'images en situation intra-situation",
      "summary": "L'essor rapide des modèles de diffusion a conduit à une amélioration notable des modèles texte à image (T2I) et à leur montrer des compétences exceptionnelles dans la capture de prompts et la génération d'images. Des modèles récents comme FLUX.1 et Ideogram2.0, ainsi que d'autres tels que Dall-E3 et Stable Diffusion 3, ont montré une excellente capacité dans des tâches complexes, soulevant la question de savoir si les modèles T2I évoluent dans leurs utilisations générales. Ces modèles offrent des fonctions dans diverses zones, comme la génération de contenu contrôlable, l'édition d'images, vidéos, sons, 3D et mouvements, et soutiennent également des tâches de visualisation en informatique comme la segmentation sémantique et l'estimation de profondeur. Cependant, actuellement, les cadres d'évaluation ne peuvent pas évaluer de manière parfaite le comportement de ces modèles dans leurs nouvelles zones d'application. Pour aborder ce problème, IMAGINE-E a été développé pour valider les modèles FLUX.1, Ideogram2.0, Midjourney, Dall-E3, Stable Diffusion 3 et Jimeng. L'évaluation a été divisée en cinq domaines principaux : génération de sorties structurées, Réalisme, cohérence physique, génération dans des zones spécifiques, génération de scénarios difficiles et tâches de multiples styles. Cette évaluation détaillée permet de clairement identifier les forces et les faiblesses de chaque modèle, particulièrement soulignant la capacité excellente de FLUX.1 et Ideogram2.0 dans des tâches structurées et dans des zones spécifiques, et soulignant la possibilité d'application et le potentiel des modèles T2I. Cette étude offre des perspectives précieuses sur l'état actuel et les perspectives futures des modèles T2I. Les scripts d'évaluation sont disponibles sur https://github.com/jylei16/Imagine-e.",
      "upvotes": 8,
      "discussionId": "679317043698fd97252a8f6f"
    },
    "publishedAt": "2025-01-23T23:31:27.973Z",
    "title": "IMAGINE-E: Image Generation Intelligence Evaluation of State-of-the-art Text-to-Image Models",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.13920.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "645dbaa6f5760d1530d7580d",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/645dbaa6f5760d1530d7580d/Bqob8arLZoHIgMwNZpL9I.jpeg",
      "fullname": "Simeon Emanuilov",
      "name": "s-emanuilov",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isMod": false,
      "followerCount": 16
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.10018",
      "authors": [
        {
          "_id": "678e125d09dc6d3a311cc04e",
          "user": {
            "_id": "6497b4464a3c31df8e4148d8",
            "avatarUrl": "/avatars/4397a380468e84bc7945fddd9a6d1066.svg",
            "isPro": false,
            "fullname": "Xiaowen Li",
            "user": "asLKHFksasak",
            "type": "user"
          },
          "name": "Xiaowen Li",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:31:02.655Z",
          "hidden": false
        },
        {
          "_id": "678e125d09dc6d3a311cc04f",
          "name": "Haolan Xue",
          "hidden": false
        },
        {
          "_id": "678e125d09dc6d3a311cc050",
          "user": {
            "_id": "64b74a45f902508f0d786505",
            "avatarUrl": "/avatars/8bc5aaa011642827e12524c4f0a56927.svg",
            "isPro": false,
            "fullname": "Peiran REN",
            "user": "lyraestar",
            "type": "user"
          },
          "name": "Peiran Ren",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:30:47.443Z",
          "hidden": false
        },
        {
          "_id": "678e125d09dc6d3a311cc051",
          "user": {
            "_id": "63d0cc736b985b0f25d0412c",
            "avatarUrl": "/avatars/3eb8c79f9a7c4c819038ea7b04e323dd.svg",
            "isPro": false,
            "fullname": "Bo",
            "user": "Liefeng",
            "type": "user"
          },
          "name": "Liefeng Bo",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:30:55.550Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-17T08:03:02.000Z",
      "title": "DiffuEraser : Modèle de diffusion qui complète les parties incomplètes d'une image",
      "summary": "Récemment, les algorithmes de vidéo inpainting ont intégré la propagation de pixels basée sur le flux et la génération basée sur les transformers, en utilisant l'information des frames adjacentes pour récupérer des textes et des listes d'objets, et en appliquant des flux optiques. De plus, les régions masquées sont traitées parfaitement par un transformer visuel. Cependant, ces approximations présentent des incertitudes spatio-temporelles et temporelles lorsqu'il s'agit de grandes masques, ce qui nécessite un améliorament de la capacité de génération. Récemment, les modèles de diffusion ont démontré des résultats exceptionnels dans la génération d'images et de vidéos et ont été considérés comme une technologie importante. Dans cet article, nous présentons un modèle de vidéo inpainting stable basé sur des modèles de diffusion appelé \"DiffuEraser\", avec l'objectif de remplir les régions masquées avec des détails plus détaillés et des structures cohérentes. Les informations antérieures sont combinées pour fournir une initialisation et des conditions faibles, ce qui permet d'inhiber l'aberration et l'hologramme du bruit. De plus, pour améliorer la consistance temporelle lors de l'inférence de séquences longues, les fenêtres de réception temporelles des modèles précédents et de \"DiffuEraser\" sont étendues, et les caractéristiques de la lissage temporel sont utilisées pour améliorer la consistance. Les résultats des expérimentations montrent que notre méthode propose des technologies plus avancées en termes de complétude des contenus et de consistance temporelle, tout en maintenant une efficacité reconnaissable.",
      "upvotes": 7,
      "discussionId": "678e125f09dc6d3a311cc0af"
    },
    "publishedAt": "2025-01-24T03:08:08.583Z",
    "title": "DiffuEraser: A Diffusion Model for Video Inpainting",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.10018.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "5f1158120c833276f61f1a84",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1608042047613-5f1158120c833276f61f1a84.jpeg",
      "fullname": "Niels Rogge",
      "name": "nielsr",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 735
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.13919",
      "authors": [
        {
          "_id": "679317f9d3ef2f790a539a28",
          "user": {
            "_id": "6785fc7d17a2dfa3720ec082",
            "avatarUrl": "/avatars/73e9d715bb16f14240c733c4843dfc22.svg",
            "isPro": false,
            "fullname": "Rui Li",
            "user": "ruili0",
            "type": "user"
          },
          "name": "Rui Li",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-01-24T10:17:34.282Z",
          "hidden": false
        },
        {
          "_id": "679317f9d3ef2f790a539a29",
          "user": {
            "_id": "65703fab7f50602340d23704",
            "avatarUrl": "/avatars/324c45f5fba9cd8c38a89b30427c06b4.svg",
            "isPro": false,
            "fullname": "Xiaohan Wang",
            "user": "nicholswang",
            "type": "user"
          },
          "name": "Xiaohan Wang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:11:30.999Z",
          "hidden": false
        },
        {
          "_id": "679317f9d3ef2f790a539a2a",
          "user": {
            "_id": "62da55164398e21bf7f0e292",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62da55164398e21bf7f0e292/xjKkG8IA2IZZqCdjApSh3.jpeg",
            "isPro": false,
            "fullname": "Yuhui Zhang",
            "user": "yuhuizhang",
            "type": "user"
          },
          "name": "Yuhui Zhang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:11:46.689Z",
          "hidden": false
        },
        {
          "_id": "679317f9d3ef2f790a539a2b",
          "name": "Zeyu Wang",
          "hidden": false
        },
        {
          "_id": "679317f9d3ef2f790a539a2c",
          "user": {
            "_id": "677c8b2e92550a07fcad0f50",
            "avatarUrl": "/avatars/2be26e8f25e98cfe5b1d227ee0409cd0.svg",
            "isPro": false,
            "fullname": "Serena Yeung-Levy",
            "user": "yeunglevy",
            "type": "user"
          },
          "name": "Serena Yeung-Levy",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:09:52.788Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-23T18:58:03.000Z",
      "title": "\"Optimisation de la préférence de séquences temporelles pour la compréhension de vidéos longues\"",
      "summary": "L'implémentation efficace de la base temporelle dans les vidéos longues est un défi complexe pour les modèles actuels. Pour surmonter cela, nous proposons un nouveau cadre d'apprentissage postérieur appelé \"Temporal Preference Optimization (TPO)\". TPO améliore la capacité de la base temporelle dans les vidéos longues en apprenant des préférences. En utilisant deux ensembles de données de préférences, TPO permet au modèle de distinguer clairement entre les réactions à une base temporelle établie et les réactions à une base temporelle moins précise. Ce processus d'optimisation améliore significativement la compréhension du temps et réduit la dépendance des données annotées automatiquement. Les résultats de TPO ont été validés dans différents expériments dans le cadre de LongVideoBench, MLVU et Video-MME. En particulier, LLaVA-Video-TPO a été reconnu comme le meilleur modèle de 7B dans Video-MME, démontrant la possibilité de TPO pour améliorer la compréhension des vidéos longues et fournir des solutions efficaces au problème de la base temporelle. Page du projet : https://ruili33.github.io/tpo_website.",
      "upvotes": 7,
      "discussionId": "679317fcd3ef2f790a539ad6"
    },
    "publishedAt": "2025-01-23T23:33:03.175Z",
    "title": "Temporal Preference Optimization for Long-Form Video Understanding",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.13919.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "645dbaa6f5760d1530d7580d",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/645dbaa6f5760d1530d7580d/Bqob8arLZoHIgMwNZpL9I.jpeg",
      "fullname": "Simeon Emanuilov",
      "name": "s-emanuilov",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isMod": false,
      "followerCount": 16
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.13826",
      "authors": [
        {
          "_id": "67934585e4e44e2866b644f2",
          "user": {
            "_id": "6400ba2b261cfa61f3a00555",
            "avatarUrl": "/avatars/1311e0b5e21b1c94d73fcaf455d3c7f7.svg",
            "isPro": false,
            "fullname": "Kairui",
            "user": "KairuiHu",
            "type": "user"
          },
          "name": "Kairui Hu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-01-24T09:07:46.937Z",
          "hidden": false
        },
        {
          "_id": "67934585e4e44e2866b644f3",
          "user": {
            "_id": "64101f81b27543634e377fc1",
            "avatarUrl": "/avatars/557dd9d4707e3b38e0805dfb87c08004.svg",
            "isPro": false,
            "fullname": "Penghao Wu",
            "user": "craigwu",
            "type": "user"
          },
          "name": "Penghao Wu",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:21:29.750Z",
          "hidden": false
        },
        {
          "_id": "67934585e4e44e2866b644f4",
          "user": {
            "_id": "646e1ef5075bbcc48ddf21e8",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/_vJC0zeVOIvaNV2R6toqg.jpeg",
            "isPro": false,
            "fullname": "Pu Fanyi",
            "user": "pufanyi",
            "type": "user"
          },
          "name": "Fanyi Pu",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:21:39.917Z",
          "hidden": false
        },
        {
          "_id": "67934585e4e44e2866b644f5",
          "user": {
            "_id": "647efcc945baf21ad707e10c",
            "avatarUrl": "/avatars/e2fab1c9031eb0eec9f015a8fc237f64.svg",
            "isPro": false,
            "fullname": "Wang Xiao",
            "user": "wangxiao1208",
            "type": "user"
          },
          "name": "Wang Xiao",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:21:46.540Z",
          "hidden": false
        },
        {
          "_id": "67934585e4e44e2866b644f6",
          "user": {
            "_id": "62a993d80472c0b7f94027df",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62a993d80472c0b7f94027df/j5vp-IwLA2YBexylUHiQU.png",
            "isPro": false,
            "fullname": "Zhang Yuanhan",
            "user": "ZhangYuanhan",
            "type": "user"
          },
          "name": "Yuanhan Zhang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:26:42.528Z",
          "hidden": false
        },
        {
          "_id": "67934585e4e44e2866b644f7",
          "user": {
            "_id": "6230d750d93e84e233882dbc",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6230d750d93e84e233882dbc/4MGEekLW3oWzqeFWDWvIK.jpeg",
            "isPro": false,
            "fullname": "Xiang Yue",
            "user": "yuexiang96",
            "type": "user"
          },
          "name": "Xiang Yue",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:27:14.894Z",
          "hidden": false
        },
        {
          "_id": "67934585e4e44e2866b644f8",
          "name": "Bo Li",
          "hidden": false
        },
        {
          "_id": "67934585e4e44e2866b644f9",
          "user": {
            "_id": "62ab1ac1d48b4d8b048a3473",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1656826685333-62ab1ac1d48b4d8b048a3473.png",
            "isPro": false,
            "fullname": "Ziwei Liu",
            "user": "liuziwei7",
            "type": "user"
          },
          "name": "Ziwei Liu",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:27:30.310Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-23T16:51:47.000Z",
      "title": "Video-MMMU : Évaluation du savoir sur plusieurs problèmes de mathématiques",
      "summary": "L'être humain passe par trois étapes cognitives pour obtenir des connaissances : la reconnaissance de l'information, la compréhension du savoir et l'application du savoir dans la résolution de problèmes. Les vidéos sont une média efficace pour ce processus d'apprentissage et peuvent encourager ces étapes cognitives. Cependant, actuellement, les marqueurs de vidéo ne peuvent pas évaluer de manière systématique la capacité des modèles de grands multimodales (LMMs) pour obtenir des connaissances. Cette limitation n'est pas résolue. Pour résoudre ce problème, on présente le video-MMMU (marqueur multidisciplinaire multimodal de vidéo). Le video-MMMU sélectionne 300 vidéos de niveau professionnel dans 6 disciplines et 900 questions répondues par des humains pour évaluer l'obtention de connaissances dans les étapes de reconnaissance, compréhension et application. La mesure de bénéfice du savoir proposée, Δ savoir, quantifie l'amélioration du rendement après avoir vu la vidéo. Dans l'évaluation des modèles, lorsque la demande cognitive augmente, le rendement diminue rapidement, et les différences entre le savoir humain et les modèles sont clairement mises en évidence, soulignant la nécessité d'améliorer la capacité d'apprentissage et d'application des modèles.",
      "upvotes": 6,
      "discussionId": "67934587e4e44e2866b64597"
    },
    "publishedAt": "2025-01-24T04:24:01.412Z",
    "title": "Video-MMMU: Evaluating Knowledge Acquisition from Multi-Discipline Professional Videos",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.13826.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6400ba2b261cfa61f3a00555",
      "avatarUrl": "/avatars/1311e0b5e21b1c94d73fcaf455d3c7f7.svg",
      "fullname": "Kairui",
      "name": "KairuiHu",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 5
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2501.13554",
      "authors": [
        {
          "_id": "6793900eddc6cc37fdc74928",
          "user": {
            "_id": "65a909fe8581aad8c97a67d3",
            "avatarUrl": "/avatars/96570e47117e957543d9f0fe5e1d9d57.svg",
            "isPro": false,
            "fullname": "liutao",
            "user": "byliutao",
            "type": "user"
          },
          "name": "Tao Liu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-01-24T13:30:20.097Z",
          "hidden": false
        },
        {
          "_id": "6793900eddc6cc37fdc74929",
          "name": "Kai Wang",
          "hidden": false
        },
        {
          "_id": "6793900eddc6cc37fdc7492a",
          "name": "Senmao Li",
          "hidden": false
        },
        {
          "_id": "6793900eddc6cc37fdc7492b",
          "name": "Joost van de Weijer",
          "hidden": false
        },
        {
          "_id": "6793900eddc6cc37fdc7492c",
          "name": "Fahad Shahbaz Khan",
          "hidden": false
        },
        {
          "_id": "6793900eddc6cc37fdc7492d",
          "name": "Shiqi Yang",
          "hidden": false
        },
        {
          "_id": "6793900eddc6cc37fdc7492e",
          "name": "Yaxing Wang",
          "hidden": false
        },
        {
          "_id": "6793900eddc6cc37fdc7492f",
          "name": "Jian Yang",
          "hidden": false
        },
        {
          "_id": "6793900eddc6cc37fdc74930",
          "name": "Ming-Ming Cheng",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-23T10:57:22.000Z",
      "title": "Une phrase avec une histoire : le Free-Lunch de la génération des images à partir de texte cohérent",
      "summary": "Le modèle de génération d'images à partir de texte peut créer des images de haute qualité à partir d'un prompt d'entrée. Cependant, ces modèles ont le défi de maintenir une identité propre tout en générant des images cohérentes, ce qui fait que les méthodes actuelles généralement nécessitent d'agrandir l'entraînement avec de grands ensembles de données ou de modifications supplémentaires dans la structure du modèle original. Cela limite son applicabilité à d'autres ensembles de données ou à des structures différentes de modèles d'entraînement. Dans cet article, les habiletés uniques et la cohérence contextuelle des modèles de langage sont reconnues, et il est observé que un seul prompt peut comprendre une identité propre. En se basant sur cette cohérence, un nouvel approche appelé \"One-Prompt-One-Story\" (1Prompt1Story) est proposée, qui ne nécessite pas d'entraînement supplémentaire. 1Prompt1Story combine tous les prompts dans un seul input pour maintenir l'identité propre depuis le début. Ensuite, deux nouvelles techniques sont utilisées : Singular-Value Reweighting et Identity-Preserving Cross-Attention pour raffiner le processus de génération et améliorer la correspondance entre chaque frame et l'explication d'entrée. L'efficacité de cet approche a été démontrée en comparant avec les méthodes actuelles de génération cohérente de T2I, en utilisant des mesures qualitatives et quantitatives. Le code est disponible sur https://github.com/byliutao/1Prompt1Story.",
      "upvotes": 4,
      "discussionId": "67939013ddc6cc37fdc74a9d"
    },
    "publishedAt": "2025-01-24T08:34:50.383Z",
    "title": "One-Prompt-One-Story: Free-Lunch Consistent Text-to-Image Generation Using a Single Prompt",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.13554.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "65a909fe8581aad8c97a67d3",
      "avatarUrl": "/avatars/96570e47117e957543d9f0fe5e1d9d57.svg",
      "fullname": "liutao",
      "name": "byliutao",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2501.13452",
      "authors": [
        {
          "_id": "6793480ec6fd669f7341cf41",
          "name": "Jiangchuan Wei",
          "hidden": false
        },
        {
          "_id": "6793480ec6fd669f7341cf42",
          "name": "Shiyue Yan",
          "hidden": false
        },
        {
          "_id": "6793480ec6fd669f7341cf43",
          "user": {
            "_id": "6676c4f86f2ac48ee6c2f4d4",
            "avatarUrl": "/avatars/fea4e5be4da7a7047df567a4aa86de0c.svg",
            "isPro": false,
            "fullname": "linwenfeng",
            "user": "linwf",
            "type": "user"
          },
          "name": "Wenfeng Lin",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:18:06.509Z",
          "hidden": false
        },
        {
          "_id": "6793480ec6fd669f7341cf44",
          "name": "Boyuan Liu",
          "hidden": false
        },
        {
          "_id": "6793480ec6fd669f7341cf45",
          "name": "Renjie Chen",
          "hidden": false
        },
        {
          "_id": "6793480ec6fd669f7341cf46",
          "name": "Mingyu Guo",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-23T08:06:11.000Z",
      "title": "EchoVideo : Génération de vidéos humaines de maintenance d'identité par intégration de caractéristiques multimodales",
      "summary": "Le récent progrès dans la génération de vidéos a eu un impact spécial sur les sous-sous comme la génération de vidéos d'identité (IPT2V). Cependant, les méthodes actuelles font face à des problèmes tels que des artefacts de \"restauration rapide\" et une faible similitude en raison de leur dépendance à un bas niveau d'information faciale. Cette dépendance conduit à des artefacts qui reflètent une rigidité faciale excessive et des détails irrélevants. Pour résoudre ces problèmes, nous proposons EchoVideo, qui utilise deux stratégies clés : (1) le module de fusion de texte et de caractéristiques d'identité (IITF), qui intègre des niveaux élevés de caractéristiques significatives à partir du texte, capture clairement l'identité faciale, élimine les changements de masque, posture et lumière pour éviter l'apparition d'artefactes ; (2) un processus d'apprentissage en deux étapes, où dans la deuxième étape, un méthode utilise de l'information faciale peu profonde de manière aléatoire. L'objectif est de améliorer la fidélité par des caractéristiques peu profondes et de mitiguer la dépendance excessive. Cette étape recommande l'utilisation de niveaux élevés de caractéristiques pendant l'entraînement et renforce la représentation de l'identité faciale. EchoVideo maintient l'identité faciale et l'harmonie dans sa totalité. Les expériences étendues montrent des résultats exceptionnels en termes de génération de vidéos de haute qualité et contrôlables.",
      "upvotes": 4,
      "discussionId": "67934811c6fd669f7341cfbf"
    },
    "publishedAt": "2025-01-24T02:59:28.457Z",
    "title": "EchoVideo: Identity-Preserving Human Video Generation by Multimodal Feature Fusion",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.13452.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "63468720dd6d90d82ccf3450",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63468720dd6d90d82ccf3450/tVBFlmZNz8FRMkOrDaDID.jpeg",
      "fullname": "YSH",
      "name": "BestWishYsh",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 28
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.10799",
      "authors": [
        {
          "_id": "679208664e521de952ca0cdc",
          "user": {
            "_id": "5df9c78eda6d0311fd3d541f",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/5df9c78eda6d0311fd3d541f/8oDFuP77l5zhvamXNVmnc.jpeg",
            "isPro": false,
            "fullname": "Yen-Ting Lin",
            "user": "yentinglin",
            "type": "user"
          },
          "name": "Yen-Ting Lin",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-01-23T09:17:30.742Z",
          "hidden": false
        },
        {
          "_id": "679208664e521de952ca0cdd",
          "user": {
            "_id": "62f690dfc58915315c504af5",
            "avatarUrl": "/avatars/a6732dda8cd7e37d9c0e0b1dfb68c66b.svg",
            "isPro": false,
            "fullname": "Di Jin",
            "user": "jindi",
            "type": "user"
          },
          "name": "Di Jin",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:15:36.716Z",
          "hidden": false
        },
        {
          "_id": "679208664e521de952ca0cde",
          "name": "Tengyu Xu",
          "hidden": false
        },
        {
          "_id": "679208664e521de952ca0cdf",
          "name": "Tianhao Wu",
          "hidden": false
        },
        {
          "_id": "679208664e521de952ca0ce0",
          "user": {
            "_id": "66a8611eb51510d82ed54231",
            "avatarUrl": "/avatars/ad559e774fee4914091b82c9831ae2a2.svg",
            "isPro": false,
            "fullname": "Sainbayar Sukhbaatar",
            "user": "sainbar",
            "type": "user"
          },
          "name": "Sainbayar Sukhbaatar",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:16:23.763Z",
          "hidden": false
        },
        {
          "_id": "679208664e521de952ca0ce1",
          "name": "Chen Zhu",
          "hidden": false
        },
        {
          "_id": "679208664e521de952ca0ce2",
          "user": {
            "_id": "6437de5d51c7ebfc813ce68a",
            "avatarUrl": "/avatars/144cb1c5d5a4a645080611953494f437.svg",
            "isPro": false,
            "fullname": "he",
            "user": "yunhe",
            "type": "user"
          },
          "name": "Yun He",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:16:34.273Z",
          "hidden": false
        },
        {
          "_id": "679208664e521de952ca0ce3",
          "name": "Yun-Nung Chen",
          "hidden": false
        },
        {
          "_id": "679208664e521de952ca0ce4",
          "user": {
            "_id": "62f023a36a027498eaa2f9cc",
            "avatarUrl": "/avatars/8ac1c5c74d0957e3c6cc94b3a7795c37.svg",
            "isPro": false,
            "fullname": "Jason Weston",
            "user": "spermwhale",
            "type": "user"
          },
          "name": "Jason Weston",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:15:25.564Z",
          "hidden": false
        },
        {
          "_id": "679208664e521de952ca0ce5",
          "user": {
            "_id": "6344cf73ee1504dbcd5bdfe7",
            "avatarUrl": "/avatars/6dd2bf1f9c5679e5c8c85d62c9836aac.svg",
            "isPro": false,
            "fullname": "Yuandong Tian",
            "user": "tydsh",
            "type": "user"
          },
          "name": "Yuandong Tian",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:16:47.602Z",
          "hidden": false
        },
        {
          "_id": "679208664e521de952ca0ce6",
          "name": "Arash Rahnama",
          "hidden": false
        },
        {
          "_id": "679208664e521de952ca0ce7",
          "user": {
            "_id": "65b483c5ed110eb9f1ee62df",
            "avatarUrl": "/avatars/29100098f5aed1735675d06c516a85b7.svg",
            "isPro": false,
            "fullname": "Sinong Wang",
            "user": "TheronWong",
            "type": "user"
          },
          "name": "Sinong Wang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:17:03.211Z",
          "hidden": false
        },
        {
          "_id": "679208664e521de952ca0ce8",
          "name": "Hao Ma",
          "hidden": false
        },
        {
          "_id": "679208664e521de952ca0ce9",
          "name": "Han Fang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-18T15:38:03.000Z",
      "title": "Step・Casion・Optimizer: Optimisation de la logique mathématique basée sur la rétroaction de valeurs par étapes",
      "summary": "Les grands modèles de langue (LLMs) ont connu un succès impressionnant dans la théorie de calcul mathématique récemment. L'élaboration de méthodes telles que l'association continentale ou le sampling d'auto-cohérence a démontré que, pour garantir la précision finale, l'harmonie et la confiance en base de la théorie ne sont pas nécessairement nécessaires. Dans cet article, nous présentons un cadre d'entraînement appelé \"Step-KTO\", qui combine la rétroaction binaire à des niveaux de phase et de résultat pour guider le chemin de la théorie évolutive. En fournissant des évaluations binaires tant au niveau de phase que au niveau de résultat, le modèle est incité à prioriser le processus logique et à ne pas croire aux courts chemins superficiels. Les expériences dans des cadres de tests mathématiques difficiles ont confirmé que l'amélioration de la qualité de la théorie au niveau de phase améliore significativement la précision finale du résultat. Par exemple, dans le jeu de données MATH-500, nous avons confirmé que l'amélioration de la qualité de la théorie au niveau de phase améliore significativement la précision finale du résultat. Ces résultats montrent la possibilité d'inclure une rétroaction de progression dans l'entraînement des LLMs de manière statistique et ouvrent le chemin vers la fonctionnalité de théories interprétables et fiables.",
      "upvotes": 4,
      "discussionId": "679208674e521de952ca0d2f"
    },
    "publishedAt": "2025-01-23T22:32:09.207Z",
    "title": "Step-KTO: Optimizing Mathematical Reasoning through Stepwise Binary Feedback",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/5df9c78eda6d0311fd3d541f/VXjkUKeidLg_JO5d3RWUG.jpeg"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.10799.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "5df9c78eda6d0311fd3d541f",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/5df9c78eda6d0311fd3d541f/8oDFuP77l5zhvamXNVmnc.jpeg",
      "fullname": "Yen-Ting Lin",
      "name": "yentinglin",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 281
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2501.13124",
      "authors": [
        {
          "_id": "6793188b56f015277a9ed95c",
          "user": {
            "_id": "65a6131fee7aa779f5bf8329",
            "avatarUrl": "/avatars/aa25cc3153fd7e511b51b801e8107564.svg",
            "isPro": false,
            "fullname": "langhao",
            "user": "langnick",
            "type": "user"
          },
          "name": "Hao Lang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:09:24.142Z",
          "hidden": false
        },
        {
          "_id": "6793188b56f015277a9ed95d",
          "user": {
            "_id": "635b8b6a37c6a2c12e2cce00",
            "avatarUrl": "/avatars/229fb72180529141515d1df797b33709.svg",
            "isPro": false,
            "fullname": "Fei Huang",
            "user": "hzhwcmhf",
            "type": "user"
          },
          "name": "Fei Huang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:09:39.353Z",
          "hidden": false
        },
        {
          "_id": "6793188b56f015277a9ed95e",
          "user": {
            "_id": "66641b2fd8e1e34bc621e688",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/66641b2fd8e1e34bc621e688/csPETwnx2zCIHSWi9uAi-.png",
            "isPro": false,
            "fullname": "Yongbin Li",
            "user": "Yongbin-Li",
            "type": "user"
          },
          "name": "Yongbin Li",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:08:59.394Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-21T05:36:13.000Z",
      "title": "Il doit agir comme un catalyseur de la généralisation des caractéristiques faibles vers les caractéristiques fortes.",
      "summary": "Usuellement, les méthodes pour aligner la capacité du modèle avec le comportement attendu reposent sur la capacité de supervision fournie par les humains. Cependant, les modèles futurs de robots humain supérieurs dépasseront les capacités humaines. Par conséquent, les humains pourront seulement superviser ces modèles de robots humain supérieurs de manière faible. Cette insuffisance prévue de supervision humaine diminuera la sécurité des systèmes d'IA futurs. Deux méthodes complémentaires pour aborder ce problème sont la supervision expandible et la généralisation de la supervision de faible à fort. Dans cet article, nous essayons d'améliorer la concordance en combinant ces deux méthodes. Plus spécifiquement, nous explorons comment améliorer la supervision humaine en utilisant des modèles pré-entraînés forts, et ensuite comment utiliser la supervision faible renforcée pour superviser des modèles forts. Pour la progression empirique itérative, nous considérons l'analogie suivante : déterminer si on peut améliorer la supervision d'un modèle faible en utilisant un modèle fort, et ensuite si on peut utiliser ce modèle faible pour améliorer un modèle fort. Nous avons effectué des expériences en utilisant un petit modèle faible ajusté à des étiquettes réelles, et un modèle fort grand pour ajuster le modèle fort avec les étiquettes générées par le modèle faible. Nous avons constaté que le débat d'un modèle faible peut extraire de l'information fiable d'un modèle fort, ce qui fournit un contexte pendant l'entraînement. De plus, nous avons montré que l'intégration d'un modèle faible permet d'obtenir des estimations de supervision plus robustes en utilisant le long débat généré par le modèle fort. A travers une large gamme d'expériences sur les tests de NLP de faible à fort de OpenAI, nous avons démontré que le méthode combinée montre une meilleure concordance, ce qui indique le potentiel que le débat peut aider à la généralisation de faible à fort.",
      "upvotes": 3,
      "discussionId": "6793188d56f015277a9ed9aa"
    },
    "publishedAt": "2025-01-23T23:35:50.957Z",
    "title": "Debate Helps Weak-to-Strong Generalization",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.13124.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "62e0ef42edb0462c8d51818d",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62e0ef42edb0462c8d51818d/3YM7DUynIWiiRFM6_enpg.jpeg",
      "fullname": "Ting-En Lin",
      "name": "tnlin",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 9
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.13075",
      "authors": [
        {
          "_id": "6791ae54330198cc26b72479",
          "user": {
            "_id": "6444241e9c1bd83bd19ea70f",
            "avatarUrl": "/avatars/24b4e65f26f5f8dcc1465cef67fd334b.svg",
            "isPro": false,
            "fullname": "Joel Lehman",
            "user": "jal278",
            "type": "user"
          },
          "name": "Joel Lehman",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-01-23T02:49:57.110Z",
          "hidden": false
        },
        {
          "_id": "6791ae54330198cc26b7247a",
          "user": {
            "_id": "6514b7fde1273c28705142cc",
            "avatarUrl": "/avatars/072bf14abd8ef17d9393338a20157cc2.svg",
            "isPro": false,
            "fullname": "Elliot Meyerson",
            "user": "ekmeyerson",
            "type": "user"
          },
          "name": "Elliot Meyerson",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:20:51.128Z",
          "hidden": false
        },
        {
          "_id": "6791ae54330198cc26b7247b",
          "name": "Tarek El-Gaaly",
          "hidden": false
        },
        {
          "_id": "6791ae54330198cc26b7247c",
          "name": "Kenneth O. Stanley",
          "hidden": false
        },
        {
          "_id": "6791ae54330198cc26b7247d",
          "name": "Tarin Ziyaee",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-22T18:38:41.000Z",
      "title": "Le développement de l'intelligence artificielle et l'énigme de la vision artificielle",
      "summary": "Cet article soutient que l'intelligence artificielle (IA) a ouvert une breche importante dans un aspect crucial de l'intelligence générale : la robustesse face à un futur inconnu de manière qualitative dans un monde ouvert. Cette robustesse est liée à l'incertitude de Knightian (IK), c'est-à-dire l'incertitude qui ne peut pas être quantifiée, et qui n'est pas considérée dans les principes théoriques principaux de l'IA. L'article identifie ces lacunes et soutient leur importance, en cherchant à inciter les recherches pour les résoudre. Nous considérons qu'elles sont essentielles pour rendre l'IA dans un monde ouvert vraiment robuste et nous comparons l'apprentissage par renforcement (RL) -un sous-domaine de l'IA- au processus biologique de l'évolution. Bien que l'évolution avance à une vitesse impressionnante, le RL encore en face de défis dans un monde ouvert et souvent échoue dans des situations inattendues. Par exemple, il est très ambitieux d'introduire des politiques de conduite autonomes entraînées uniquement aux États-Unis en Royaume-Uni. En contraste, l'évolution biologique généralement produit des agents capables de survivre dans un monde ouvert, même dans des situations extrêmes et inconnues (par exemple, l'invasion d'espèces ou l'exercice d'un 0-shot de conduite internationale). Intéressant, l'évolution réalise cette robustesse sans nécessité de théories explicites, formalismes ou mathématiques. Nous explorons les bases des principes généraux du RL et montrons comment ils reflètent les caractéristiques spécifiques d'un monde complexe et changeant avec \"unknown unknowns\". De plus, nous identifions les structures que l'évolution utilise pour favoriser la robustesse face aux nouveaux défis et discutons des étapes possibles vers une implémentation algorithmique. En conclusion, les vulnérabilités intéressantes qui restent à l'IA peuvent émerger dans des points de faiblesses de la théorie et peuvent être améliorées significativement en faisant face directement au défi de l'IK.",
      "upvotes": 2,
      "discussionId": "6791ae55330198cc26b724bc"
    },
    "publishedAt": "2025-01-24T01:17:22.150Z",
    "title": "Evolution and The Knightian Blindspot of Machine Learning",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.13075.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6444241e9c1bd83bd19ea70f",
      "avatarUrl": "/avatars/24b4e65f26f5f8dcc1465cef67fd334b.svg",
      "fullname": "Joel Lehman",
      "name": "jal278",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2501.13824",
      "authors": [
        {
          "_id": "6793a52265c4dd63499ca548",
          "user": {
            "_id": "662ce44c8b8705f30371fba8",
            "avatarUrl": "/avatars/b96a25a8c124e7caa9de06b7188bdc15.svg",
            "isPro": false,
            "fullname": "Shuzhou Yuan",
            "user": "shuzyuan",
            "type": "user"
          },
          "name": "Shuzhou Yuan",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-01-24T14:52:27.570Z",
          "hidden": false
        },
        {
          "_id": "6793a52265c4dd63499ca549",
          "name": "Michael Färber",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-23T16:45:51.000Z",
      "title": "Horowitzson peut améliorer les grands modèles de langue pour la détection de substances.",
      "summary": "La préoccupation par le \"hallucination\" dans les modèles de langue de la Terre (LLMs) est un problème qui attire l'attention des chercheurs, mais le \"hallucination\" a un potentiel dans les domaines créatifs, et en particulier, elle est valorisée dans le domaine de la découverte de médicaments pour son utilité en exploration. Dans cet article, nous proposons que le \"hallucination\" peut améliorer les LLMs dans le domaine de la découverte de médicaments. Pour vérifier cette hypothèse, nous avons évalué 7 modèles de LLMs et 5 tâches de classification en utilisant l'explication en langue nature des séquences de SMILES de molécules, générées par les modèles de LLMs, comme partie des prompts pour des tâches spécifiques de découverte de médicaments. Nos résultats ont confirmé que les modèles de LLMs peuvent atteindre de meilleurs résultats avec des textes qui incluent \"hallucination\". En particulier, Llama-3.1-8B a atteint une amélioration de 18,35% en termes de ROC-AUC par rapport à un modèle de référence sans \"hallucination\". De plus, la meilleure amélioration, consistant à générer un modèle complet, a été apportée par la génération de GPT-4o. De plus, des analyses expérimentales et des études de cas ont été réalisées pour explorer les facteurs qui affectent le rendement et ses fondements. Cette étude révèle le potentiel de la \"hallucination\" dans les LLMs et offre de nouvelles perspectives pour les recherches futures qui cherchent à élargir l'application des LLMs dans le domaine de la découverte de médicaments.",
      "upvotes": 1,
      "discussionId": "6793a52465c4dd63499ca5ad"
    },
    "publishedAt": "2025-01-24T09:39:01.834Z",
    "title": "Hallucinations Can Improve Large Language Models in Drug Discovery",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.13824.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "662ce44c8b8705f30371fba8",
      "avatarUrl": "/avatars/b96a25a8c124e7caa9de06b7188bdc15.svg",
      "fullname": "Shuzhou Yuan",
      "name": "shuzyuan",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2501.10283",
      "authors": [
        {
          "_id": "67934e1511eb9c774dd1bfc3",
          "user": {
            "_id": "67936c63ddd1e487c0c6c691",
            "avatarUrl": "/avatars/6d57469b4afdc8bedffeea9ed5f59dd4.svg",
            "isPro": false,
            "fullname": "Chengwei Zheng",
            "user": "zhengcw18",
            "type": "user"
          },
          "name": "Chengwei Zheng",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-01-24T13:30:16.388Z",
          "hidden": false
        },
        {
          "_id": "67934e1511eb9c774dd1bfc4",
          "user": {
            "_id": "645b95f8438d6cfbe1ae8256",
            "avatarUrl": "/avatars/ac0ebb0a73569ab063c5b2f28c509d23.svg",
            "isPro": false,
            "fullname": "Lixin Xue",
            "user": "lxxue",
            "type": "user"
          },
          "name": "Lixin Xue",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:27:50.665Z",
          "hidden": false
        },
        {
          "_id": "67934e1511eb9c774dd1bfc5",
          "name": "Juan Zarate",
          "hidden": false
        },
        {
          "_id": "67934e1511eb9c774dd1bfc6",
          "name": "Jie Song",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-17T16:26:24.000Z",
      "title": "GSTAR : Suivi et Réconstruction de Surfaces Gaussiennes",
      "summary": "La technologie Gauss 3D a réussi à rendre efficacement des images statiques. Des études récentes ont élargi cette méthodologie pour la configuration et le suivi de surfaces. Cependant, le suivi de surfaces dynamiques à l'aide de Gauss 3D peut rencontrer des défis en raison de changements topologiques complexes, comme lorsque les surfaces apparaissent, disparaissent ou se séparent. Pour répondre à ces défis, nous proposons la méthodologie GSTAR. GSTAR effectue la rendition d'images cinématiques dynamiques générales, la configuration précise de surfaces et le suivi 3D fiable de surfaces dynamiques avec des changements topologiques. GSTAR prend en entrée plusieurs photographies et combine Gauss sur les surfaces d'une maille pour représenter des objets dynamiques. Pour des surfaces avec des topologies constantes, GSTAR maintient la topologie de la maille et le suivi en utilisant Gauss. Dans les endroits où la topologie change, GSTAR adapte la combinaison et la séparation de Gauss dans la maille, permettant la création de nouvelles surfaces basées sur ces adaptations optimales. De plus, nous présentons un méthode de flux cinématographique basée sur les surfaces et une initialisation forte pour le suivi entre cadres. Les expériences montrent que notre approche permet de suivre et de configurer des surfaces dynamiques avec précision, facilitant diverses applications. Le code de l'implémentation et la page du projet sont disponibles sur https://eth-ait.github.io/GSTAR/.",
      "upvotes": 1,
      "discussionId": "67934e1611eb9c774dd1bffe"
    },
    "publishedAt": "2025-01-24T03:24:06.601Z",
    "title": "GSTAR: Gaussian Surface Tracking and Reconstruction",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.10283.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "5f1158120c833276f61f1a84",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1608042047613-5f1158120c833276f61f1a84.jpeg",
      "fullname": "Niels Rogge",
      "name": "nielsr",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 735
    },
    "isAuthorParticipating": false
  }
]