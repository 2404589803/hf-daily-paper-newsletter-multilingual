[
  {
    "paper": {
      "id": "2502.18934",
      "authors": [
        {
          "_id": "67bfe1bf4426925c82fe5953",
          "name": "Kanana LLM Team",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe5954",
          "name": "Yunju Bak",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe5955",
          "name": "Hojin Lee",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe5956",
          "user": {
            "_id": "60436d159e905013ae8715d7",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1623809612769-60436d159e905013ae8715d7.jpeg",
            "isPro": false,
            "fullname": "Minho Ryu",
            "user": "bzantium",
            "type": "user"
          },
          "name": "Minho Ryu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-27T09:14:17.979Z",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe5957",
          "user": {
            "_id": "66ebb4fdc5b2c25450fd17de",
            "avatarUrl": "/avatars/e6b40dcbe2eba838ba21be9221758a3c.svg",
            "isPro": false,
            "fullname": "Jiyeon Ham",
            "user": "jiyeonham",
            "type": "user"
          },
          "name": "Jiyeon Ham",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-27T09:14:11.786Z",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe5958",
          "name": "Seungjae Jung",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe5959",
          "user": {
            "_id": "66c82a50c1b3c03c61aea140",
            "avatarUrl": "/avatars/3c508f96bdca2f2ce9746d3decd4718e.svg",
            "isPro": false,
            "fullname": "daniel nam",
            "user": "daniel-rl2",
            "type": "user"
          },
          "name": "Daniel Wontae Nam",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-27T09:14:09.613Z",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe595a",
          "name": "Taegyeong Eo",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe595b",
          "name": "Donghun Lee",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe595c",
          "user": {
            "_id": "6142e17fe9e656d4459121e4",
            "avatarUrl": "/avatars/6baebd4598a845ec7fdb735eb0d53139.svg",
            "isPro": false,
            "fullname": "Doohae Jung",
            "user": "Doohae",
            "type": "user"
          },
          "name": "Doohae Jung",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-27T09:14:06.858Z",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe595d",
          "user": {
            "_id": "60f559be68ee3ef098e407cf",
            "avatarUrl": "/avatars/e1f00ff1c1c9fa7f591535d39c7d5e44.svg",
            "isPro": false,
            "fullname": "Boseop Kim",
            "user": "seopbo",
            "type": "user"
          },
          "name": "Boseop Kim",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-27T09:14:01.989Z",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe595e",
          "user": {
            "_id": "6605028007a154c768e1c4c7",
            "avatarUrl": "/avatars/88678edb83fdb466067e38acd22d07de.svg",
            "isPro": false,
            "fullname": "Nayeon Kim",
            "user": "lana-ny",
            "type": "user"
          },
          "name": "Nayeon Kim",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-27T09:14:13.867Z",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe595f",
          "user": {
            "_id": "6136f65440e43b8f748a0833",
            "avatarUrl": "/avatars/f72a5ae3d3e94485de8aed8df94abdad.svg",
            "isPro": false,
            "fullname": "Jaesun Park",
            "user": "jaesun",
            "type": "user"
          },
          "name": "Jaesun Park",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-27T09:14:15.898Z",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe5960",
          "name": "Hyunho Kim",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe5961",
          "name": "Hyunwoong Ko",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe5962",
          "user": {
            "_id": "63d268bb57ab367124ea7b75",
            "avatarUrl": "/avatars/11312cde1e9f077aa9e5103b48be5de6.svg",
            "isPro": false,
            "fullname": "Changmin Lee",
            "user": "changminlee",
            "type": "user"
          },
          "name": "Changmin Lee",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-27T09:14:04.506Z",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe5963",
          "name": "Kyoung-Woon On",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe5964",
          "name": "Seulye Baeg",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe5965",
          "name": "Junrae Cho",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe5966",
          "name": "Sunghee Jung",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe5967",
          "name": "Jieun Kang",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe5968",
          "name": "EungGyun Kim",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe5969",
          "name": "Eunhwa Kim",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe596a",
          "name": "Byeongil Ko",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe596b",
          "name": "Daniel Lee",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe596c",
          "name": "Minchul Lee",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe596d",
          "name": "Miok Lee",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe596e",
          "name": "Shinbok Lee",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe596f",
          "name": "Gaeun Seo",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-26T08:36:20.000Z",
      "title": "Kanana : Modèle de langage de programmation bilingue efficace pour les calculs",
      "summary": "Kanana, une série de modèles de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de langage de",
      "upvotes": 39,
      "discussionId": "67bfe1c04426925c82fe59a1"
    },
    "publishedAt": "2025-02-26T23:05:13.440Z",
    "title": "Kanana: Compute-efficient Bilingual Language Models",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.18934.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60436d159e905013ae8715d7",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1623809612769-60436d159e905013ae8715d7.jpeg",
      "fullname": "Minho Ryu",
      "name": "bzantium",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 5
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.19400",
      "authors": [
        {
          "_id": "67bfd6f15db054ee3c5a766b",
          "user": {
            "_id": "631d760344503b7227837242",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/631d760344503b7227837242/3b6JRusFX6GKJpsN9ZdeJ.png",
            "isPro": false,
            "fullname": "Max Ku",
            "user": "vinesmsuic",
            "type": "user"
          },
          "name": "Max Ku",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-27T09:14:55.238Z",
          "hidden": false
        },
        {
          "_id": "67bfd6f15db054ee3c5a766c",
          "user": {
            "_id": "6365d5baa7a1324ccd5ecdb9",
            "avatarUrl": "/avatars/636d3f410b878e451a878a6cf171dd53.svg",
            "isPro": false,
            "fullname": "Thomas Chong",
            "user": "chongcht",
            "type": "user"
          },
          "name": "Thomas Chong",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-27T09:14:49.567Z",
          "hidden": false
        },
        {
          "_id": "67bfd6f15db054ee3c5a766d",
          "name": "Jonathan Leung",
          "hidden": false
        },
        {
          "_id": "67bfd6f15db054ee3c5a766e",
          "user": {
            "_id": "67bfdfdbf856fd8ddbb7e0f0",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/rIR0QnVM3wxMCulG2R9SJ.png",
            "isPro": false,
            "fullname": "Krish Shah",
            "user": "KrishKrosh",
            "type": "user"
          },
          "name": "Krish Shah",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-27T09:14:47.269Z",
          "hidden": false
        },
        {
          "_id": "67bfd6f15db054ee3c5a766f",
          "user": {
            "_id": "6696061aa8dbb9a9997dfff6",
            "avatarUrl": "/avatars/d8f0bbff362fd630e6e60aab141076d3.svg",
            "isPro": false,
            "fullname": "Alvin Yu",
            "user": "AlvinYuVotee",
            "type": "user"
          },
          "name": "Alvin Yu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-27T09:14:52.146Z",
          "hidden": false
        },
        {
          "_id": "67bfd6f15db054ee3c5a7670",
          "name": "Wenhu Chen",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-26T18:50:09.000Z",
      "title": "AgentExpliquerThéorème : Recherche sur les explications multimodales pour la compréhension des théorèmes de LLM",
      "summary": "La compréhension de l'organisation dans des domaines spécifiques ne suffit pas seulement à base de raisons contextuelles, mais une vision structurée et visualisée est essentielle pour une communication efficace qui nécessite une profondeur d'compréhension. Les modèles de langage à grande échelle (LLMs) montrent un excellent rendement dans la justification de l'organisation basée sur le contexte, mais leur capacité à générer des explications collaboratives et éducatives visuelles est un défi ouvert. Dans cette étude, nous présentons le TheoremExplainAgent, un agent utilisant Manim pour créer des vidéos d'explication de théorèmes de longue durée (plus de 5 minutes). Pour évaluer la multifonctionnalité, nous proposons le TheoremExplainBench, un ensemble de 240 théorèmes de diverses disciplines STEM, et nous appliquons 5 critères d'évaluation automatique. Les résultats confirment clairement l'importance de la planification des agents pour la création de vidéos efficaces, et l'agent o3-mini a atteint un rendement de 93,8% et une note globale de 0,77. Cependant, des études qualitatives et quantitatives révèlent que de nombreux vidéos générées présentent des inconsistances légères dans la séquence des éléments visualisés. De plus, les explications multifonctionnelles révèlent clairement les failles cachées dans les explications basées sur le contexte, soulignant l'importance des explications multifonctionnelles.",
      "upvotes": 17,
      "discussionId": "67bfd6f25db054ee3c5a7699"
    },
    "publishedAt": "2025-02-26T22:07:49.438Z",
    "title": "TheoremExplainAgent: Towards Multimodal Explanations for LLM Theorem Understanding",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.19400.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 6232
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.19361",
      "authors": [
        {
          "_id": "67bfe435ca6e3c22b6e29442",
          "name": "Yancheng He",
          "hidden": false
        },
        {
          "_id": "67bfe435ca6e3c22b6e29443",
          "name": "Shilong Li",
          "hidden": false
        },
        {
          "_id": "67bfe435ca6e3c22b6e29444",
          "name": "Jiaheng Liu",
          "hidden": false
        },
        {
          "_id": "67bfe435ca6e3c22b6e29445",
          "name": "Weixun Wang",
          "hidden": false
        },
        {
          "_id": "67bfe435ca6e3c22b6e29446",
          "name": "Xingyuan Bu",
          "hidden": false
        },
        {
          "_id": "67bfe435ca6e3c22b6e29447",
          "user": {
            "_id": "638efcf4c67af472d316d424",
            "avatarUrl": "/avatars/97a57859d7d87a3a8f1bb41d32a72bc2.svg",
            "isPro": false,
            "fullname": "Ge Zhang",
            "user": "zhangysk",
            "type": "user"
          },
          "name": "Ge Zhang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-27T09:13:58.959Z",
          "hidden": false
        },
        {
          "_id": "67bfe435ca6e3c22b6e29448",
          "name": "Zhongyuan Peng",
          "hidden": false
        },
        {
          "_id": "67bfe435ca6e3c22b6e29449",
          "name": "Zhaoxiang Zhang",
          "hidden": false
        },
        {
          "_id": "67bfe435ca6e3c22b6e2944a",
          "name": "Wenbo Su",
          "hidden": false
        },
        {
          "_id": "67bfe435ca6e3c22b6e2944b",
          "name": "Bo Zheng",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-26T17:59:27.000Z",
      "title": "Les grands modèles de langue détectent-ils des erreurs dans la chaîne de pensée de longue durée ?",
      "summary": "Récemment, des modèles similaires à o1 reçoivent de l'attention. Ces modèles génèrent de longs Chain-of-Thought (CoT) pour améliorer la capacité d'inférence des modèles actuels de Langue Large (LLMs). Dans cette étude, DeltaBench est utilisé pour comprendre la qualité de ces longs CoT et pour évaluer la capacité des modèles actuels de mesurer ces longs CoT. DeltaBench inclut des CoT générés par différents modèles similaires à o1, comme QwQ et DeepSeek-R1, et est utilisé dans des tâches d'inférence variées, comme les mathématiques, le code et les généraux. Cela permet de mesurer la capacité de détection d'erreurs dans l'inférence longue CoT. En se basant sur DeltaBench, d'abord, un analyse détaillée des longs CoT générés est effectuée pour découvrir l'efficacité et l'efficience de chaque modèle similaire à o1. Ensuite, une évaluation étendue des Process Reward Models (PRMs) et des modèles d'évaluation est réalisée pour explorer les limites et les limitations de chaque PRM et modèle d'évaluation dans la détection d'erreurs dans chaque inférence. Enfin, DeltaBench aide les développeurs à mieux comprendre la capacité d'inférence longue des modèles, tant pour les comprendre mieux que pour les améliorer.",
      "upvotes": 12,
      "discussionId": "67bfe438ca6e3c22b6e2948e"
    },
    "publishedAt": "2025-02-26T23:04:47.406Z",
    "title": "Can Large Language Models Detect Errors in Long Chain-of-Thought Reasoning?",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.19361.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "65377c30e48353201e6fdda0",
      "avatarUrl": "/avatars/a8f803b6f2e598eaee9c52c0d2ddfc16.svg",
      "fullname": "Jiaheng Liu",
      "name": "CheeryLJH",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 7
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.19328",
      "authors": [
        {
          "_id": "67bfcb774d22a9379b29334c",
          "name": "Hao Peng",
          "hidden": false
        },
        {
          "_id": "67bfcb774d22a9379b29334d",
          "name": "Yunjia Qi",
          "hidden": false
        },
        {
          "_id": "67bfcb774d22a9379b29334e",
          "name": "Xiaozhi Wang",
          "hidden": false
        },
        {
          "_id": "67bfcb774d22a9379b29334f",
          "name": "Zijun Yao",
          "hidden": false
        },
        {
          "_id": "67bfcb774d22a9379b293350",
          "name": "Bin Xu",
          "hidden": false
        },
        {
          "_id": "67bfcb774d22a9379b293351",
          "name": "Lei Hou",
          "hidden": false
        },
        {
          "_id": "67bfcb774d22a9379b293352",
          "name": "Juanzi Li",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-26T17:19:12.000Z",
      "title": "Modèle de Récompenses Agentiques : Modèle de Récompenses Sûres qui Intègre les Préférences Humaines et des Signaux de Vérification Précisés",
      "summary": "Les modules de récompense (MR) jouent un rôle crucial dans l'échelle de l'entraînement et de l'inférence des modules de langage de grande taille (LLMs). Cependant, les modules de récompense actuels se concentrent principalement sur les préférences humaines, ignorant les signaux de précision vérifiable et considérant que le potentiel des LLMs dans leur entraînement est trop ancien. Dans cet article, nous proposons un modèle de récompense basé sur des signaux de précision vérifiable. Ce système de récompense combine des signaux de précision vérifiable et des modules de récompense pour fournir une récompense fiable. Expérimentalement, nous avons mis en œuvre un agent de récompense (\"RewardAgent\") qui combine deux signaux de récompense vérifiable : une basée sur les préférences humaines et l'autre sur la réalité et les instructions. \"RewardAgent\" se concentre sur fournir une récompense fiable. Des expériences ont été réalisées avec le benchmark actuel des modules de récompense et dans la meilleure de n en tâches d'inférence réelles. \"RewardAgent\" a démontré être significativement supérieur aux modules de récompense actuels. De plus, en utilisant \"RewardAgent\" pour construire des paires de préférences d'entraînement et en entraînant un LLM avec l'objectif de DPO, nous avons obtenu une amélioration significative dans différents cadres de référence de NLP par rapport aux modules de récompense traditionnels. Notre code est disponible et offre une flexibilité pour des recherches avancées (https://github.com/THU-KEG/Agentic-Reward-Modeling).",
      "upvotes": 11,
      "discussionId": "67bfcb784d22a9379b29338f"
    },
    "publishedAt": "2025-02-26T22:05:16.150Z",
    "title": "Agentic Reward Modeling: Integrating Human Preferences with Verifiable Correctness Signals for Reliable Reward Systems",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.19328.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "625a5446f1063e7085d5178a",
      "avatarUrl": "/avatars/5e78186f13f74b14e01583e06ff6c4dc.svg",
      "fullname": "Hao Peng",
      "name": "Wesleythu",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.17955",
      "authors": [
        {
          "_id": "67bff526ca6e3c22b6e89d71",
          "user": {
            "_id": "65d2f1e0fe21569868393411",
            "avatarUrl": "/avatars/1401020e76d958bef3f33e7449773694.svg",
            "isPro": false,
            "fullname": "Tushar Aggarwal",
            "user": "AggarwalTushar",
            "type": "user"
          },
          "name": "Tushar Aggarwal",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-02-27T05:16:24.257Z",
          "hidden": false
        },
        {
          "_id": "67bff526ca6e3c22b6e89d72",
          "name": "Kumar Tanmay",
          "hidden": false
        },
        {
          "_id": "67bff526ca6e3c22b6e89d73",
          "user": {
            "_id": "61a7cbb0fcbbebe775bf17fd",
            "avatarUrl": "/avatars/8b54907c6a1ea90a1242f26e03e117af.svg",
            "isPro": false,
            "fullname": "Ayush Agrawal",
            "user": "ayush1801",
            "type": "user"
          },
          "name": "Ayush Agrawal",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-27T09:13:56.625Z",
          "hidden": false
        },
        {
          "_id": "67bff526ca6e3c22b6e89d74",
          "name": "Kumar Ayush",
          "hidden": false
        },
        {
          "_id": "67bff526ca6e3c22b6e89d75",
          "name": "Hamid Palangi",
          "hidden": false
        },
        {
          "_id": "67bff526ca6e3c22b6e89d76",
          "name": "Paul Pu Liang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-25T08:27:18.000Z",
      "title": "La vérité d'un modèle de langue dépend du langage de la question.",
      "summary": "Les modèles de langue multilingues (MLMs) attendent que se souviennent avec cohérence des connaissances factuelles dans plusieurs langues, mais peuvent échouer dans la transfert de ces connaissances si cette information est précise dans chaque langue. Par exemple, un MLM peut reconnaître avec précision que Rashed Al Shashai est le lieu de naissance du Troisième de Mai en une question en arabe, mais il est plus difficile que le même sache cette information avec précision lorsque la question est posée en anglais ou en swahili. Pour étudier systématiquement ces limites, nous proposons un cadre de référence basé sur 10 000 faits de relations internationales dans 13 langues, ainsi que des scores de mémoire factuelle, de mobilité de connaissance et de mobilité de connaissance contextualisée. Ces scores sont utilisés pour quantifier la mémoire factuelle et la mobilité de connaissance entre différentes langues dans les MLMs. Nos résultats révèlent les principales limitations fondamentales des MLMs les plus avancés actuellement, en particulier, la faible mobilité de connaissance entre différentes langues, ce qui indique une incertitude dans le rendement dépendant du langage. Nos résultats soulignent la nécessité pour les MLMs de reconnaître la confiance dans les faits idiomatiques et d'utiliser les informations plus fiables dans différentes langues. Nous publions notre cadre de référence et notre cadre d'évaluation, avec l'objectif de promouvoir futures recherches sur la mobilité de connaissance multilingue.",
      "upvotes": 9,
      "discussionId": "67bff528ca6e3c22b6e89ddd"
    },
    "publishedAt": "2025-02-27T00:17:58.262Z",
    "title": "Language Models' Factuality Depends on the Language of Inquiry",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.17955.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "65d2f1e0fe21569868393411",
      "avatarUrl": "/avatars/1401020e76d958bef3f33e7449773694.svg",
      "fullname": "Tushar Aggarwal",
      "name": "AggarwalTushar",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.18864",
      "authors": [
        {
          "_id": "67bfd957c2a9b64ab3f97aa7",
          "name": "Juraj Gottweis",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97aa8",
          "name": "Wei-Hung Weng",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97aa9",
          "name": "Alexander Daryin",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97aaa",
          "name": "Tao Tu",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97aab",
          "name": "Anil Palepu",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97aac",
          "name": "Petar Sirkovic",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97aad",
          "name": "Artiom Myaskovsky",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97aae",
          "name": "Felix Weissenberger",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97aaf",
          "name": "Keran Rong",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ab0",
          "name": "Ryutaro Tanno",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ab1",
          "name": "Khaled Saab",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ab2",
          "name": "Dan Popovici",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ab3",
          "name": "Jacob Blum",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ab4",
          "name": "Fan Zhang",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ab5",
          "name": "Katherine Chou",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ab6",
          "name": "Avinatan Hassidim",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ab7",
          "name": "Burak Gokturk",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ab8",
          "name": "Amin Vahdat",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ab9",
          "name": "Pushmeet Kohli",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97aba",
          "name": "Yossi Matias",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97abb",
          "name": "Andrew Carroll",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97abc",
          "name": "Kavita Kulkarni",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97abd",
          "name": "Nenad Tomasev",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97abe",
          "name": "Yuan Guan",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97abf",
          "name": "Vikram Dhillon",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ac0",
          "name": "Eeshit Dhaval Vaishnav",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ac1",
          "name": "Byron Lee",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ac2",
          "name": "Tiago R D Costa",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ac3",
          "name": "José R Penadés",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ac4",
          "name": "Gary Peltz",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ac5",
          "name": "Yunhan Xu",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ac6",
          "name": "Annalisa Pawlosky",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ac7",
          "name": "Alan Karthikesalingam",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ac8",
          "name": "Vivek Natarajan",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-26T06:17:13.000Z",
      "title": "Nous nous concentrons sur la collaboration avec l'IA comme objectif.",
      "summary": "La découverte scientifique se réalise à travers la génération de nouvelles hypothèses par les scientifiques et leur validation expérimentale rigoureuse. Pour soutenir ce processus, nous présentons l'AI Cosine Intelligence, un système d'intelligence artificielle basé sur un système multi-agent construit sur l'Orca Mini 2.0. L'AI Cosine Intelligence vise à découvrir de nouveaux et existants savoirs et à proposer de nouvelles hypothèses de recherche basées sur des preuves existantes et guidées par les objectifs et directives fournies par les scientifiques. Le design du système est inspiré par les méthodes scientifiques, adoptant une approche qui accélère l'échelle des calculs et une méthodologie pour la génération, la logique et l'évolution des hypothèses. Les principaux contributeurs sont :\n\n1. Une architecture multi-agent qui permet l'exécution de tâches non synchrones, facilitant l'efficacité de l'échelle des calculs nécessaires pour la génération d'hypothèses.\n2. Un processus d'évolution de tournois pour la génération d'hypothèses qui auto-améliore.\n\nL'évaluation automatique montre un avantage continu en termes de calculs, améliorant la qualité des hypothèses. Elle est utilisée dans divers domaines, mais se concentre sur trois zones biomédicales : le recyclage des médicaments, la détection de nouveaux cibles, et l'évolution et la résistance antimicrobienne des bactéries. Dans le recyclage des médicaments, il propose des candidats qui montrent une mutation à des concentrations cliniquement efficaces, en particulier dans le cancer du myélome, démontrant une inhibition de la prolifération cellulaire. Dans la détection de nouveaux cibles, la nouvelle génétique d'un nouveau cible de cancer du foie proposé par l'AI Cosine Intelligence est validée, confirmant sa activité antitumorale et la régénération des cellules humaines. Enfin, l'AI Cosine Intelligence reconstruit des résultats expérimentaux non publiés en parallèle avec l'évolution génétique des bactéries par une technique de cinémadiscabari. Ces résultats sont enregistrés dans des billets détaillés simultanément, mais démontrent leur soutien à la biomédecine et au découverte scientifique, montrant le commencement d'une nouvelle ère de scientifiques basée sur l'intelligence artificielle.",
      "upvotes": 9,
      "discussionId": "67bfd958c2a9b64ab3f97afa"
    },
    "publishedAt": "2025-02-26T22:18:06.494Z",
    "title": "Towards an AI co-scientist",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.18864.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 6232
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.19414",
      "authors": [
        {
          "_id": "67c01587925b73feaf61ac41",
          "name": "Shiven Sinha",
          "hidden": false
        },
        {
          "_id": "67c01587925b73feaf61ac42",
          "name": "Shashwat Goel",
          "hidden": false
        },
        {
          "_id": "67c01587925b73feaf61ac43",
          "name": "Ponnurangam Kumaraguru",
          "hidden": false
        },
        {
          "_id": "67c01587925b73feaf61ac44",
          "name": "Jonas Geiping",
          "hidden": false
        },
        {
          "_id": "67c01587925b73feaf61ac45",
          "name": "Matthias Bethge",
          "hidden": false
        },
        {
          "_id": "67c01587925b73feaf61ac46",
          "name": "Ameya Prabhu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-26T18:58:13.000Z",
      "title": "Le modèle de langage peut-il créer des fausses informations ? Évaluation de l'inférence algorithmique, par exemple la génération",
      "summary": "L'intérêt pour le développement scientifique des modèles de langue (ML) est en augmentation. La négation d'hypothèse est une clé pour le développement scientifique, permettant que les affirmations soient améliorées répétivement au fil du temps. Ce processus requiert un effort considérable des chercheurs et nécessite une logique et une créativité. Cependant, les critères actuels d'évaluation des ML se concentrent principalement sur la capacité à générer des solutions, et l'évaluation de la capacité contraire est insuffisante. Nous argumentons la nécessité de développer des critères d'évaluation pour la capacité contraire. Plus spécifiquement, nous cherchons à créer un algorithme qui résoud des problèmes, avec un environnement d'exécution automatique pour évaluer le rendement, connu sous le nom de \"counter engineering\". En particulier, nous utilisons REFUTE, un standard d'évaluation actuellement dynamique, qui a été développé à partir de l'expérience des experts qui ont réussi à identifier efficacement le counter engineering dans des compétitions de programmation qui incluent des problèmes récents. Selon nos analyses, l'agent REFUTE, tels que OpenAI ou 3-mini (haut), est capable de réaliser le counter engineering dans plus de <9% des solutions négatives, bien que il ne reçoive pas de rétroaction d'exécution de code. Cependant, son évaluation montre sa capacité à résoudre rapidement ces problèmes. Nous demandons que l'évaluation et l'amélioration de la capacité des ML pour nier des solutions négatives soient développées, ce qui est crucial pour l'accélération de la recherche et l'amélioration autocorrective des modèles basés sur des raisonnements réflexifs et fiables.",
      "upvotes": 8,
      "discussionId": "67c01588925b73feaf61ad2c"
    },
    "publishedAt": "2025-02-27T02:36:29.037Z",
    "title": "Can Language Models Falsify? Evaluating Algorithmic Reasoning with Counterexample Creation",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.19414.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6506832221ac448013f94995",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6506832221ac448013f94995/sVUI1JV4Dxan5l-MqNze4.jpeg",
      "fullname": "Shashwat Goel",
      "name": "shash42",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.18906",
      "authors": [
        {
          "_id": "67bfd5d2381f8fcb67e5ad36",
          "name": "Jiani Zheng",
          "hidden": false
        },
        {
          "_id": "67bfd5d2381f8fcb67e5ad37",
          "name": "Lu Wang",
          "hidden": false
        },
        {
          "_id": "67bfd5d2381f8fcb67e5ad38",
          "user": {
            "_id": "669dcf6200970c3b27aafa5d",
            "avatarUrl": "/avatars/bb9ed5ff86326fdaeb184c6b0e40f74f.svg",
            "isPro": false,
            "fullname": "kaikai yang",
            "user": "keanudicap",
            "type": "user"
          },
          "name": "Fangkai Yang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-27T09:14:57.452Z",
          "hidden": false
        },
        {
          "_id": "67bfd5d2381f8fcb67e5ad39",
          "user": {
            "_id": "654dbac9938fbf1e696be8aa",
            "avatarUrl": "/avatars/b3c4035c48169c1bfb04a439fce3499f.svg",
            "isPro": false,
            "fullname": "Chaoyun Zhang",
            "user": "vyokky",
            "type": "user"
          },
          "name": "Chaoyun Zhang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-27T09:14:59.653Z",
          "hidden": false
        },
        {
          "_id": "67bfd5d2381f8fcb67e5ad3a",
          "name": "Lingrui Mei",
          "hidden": false
        },
        {
          "_id": "67bfd5d2381f8fcb67e5ad3b",
          "name": "Wenjie Yin",
          "hidden": false
        },
        {
          "_id": "67bfd5d2381f8fcb67e5ad3c",
          "name": "Qingwei Lin",
          "hidden": false
        },
        {
          "_id": "67bfd5d2381f8fcb67e5ad3d",
          "name": "Dongmei Zhang",
          "hidden": false
        },
        {
          "_id": "67bfd5d2381f8fcb67e5ad3e",
          "name": "Saravan Rajmohan",
          "hidden": false
        },
        {
          "_id": "67bfd5d2381f8fcb67e5ad3f",
          "name": "Qi Zhang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-26T07:52:02.000Z",
      "title": "VEM : Exploration et modélisation d'environnements de valeur pour les agents d'interface graphique par l'entretien sans environnement",
      "summary": "Les problèmes importants dans le processus d'entraînement de modèles de langue visuelle (VLMs) pour des interfaces graphiques (GUI) avec apprentissage par renforcement (RL) sont clairement apparentés. L'apprentissage par renforcement basé sur l'environnement nécessite des interactions très coûteuses, tandis que les méthodes sans environnement font face à des défis dans la transformation de la distribution et la généralisation de la récompense. Nous proposons un cadre d'apprentissage par renforcement sans environnement utilisant des modèles de prédiction de l'environnement (VEM). Le VEM prédit directement le valeur de l'état-action à partir de données off-line, structurant une prévisualisation humain grâce aux interactions avec la GUI. Cela évite l'accumulation d'erreurs et la nécessité de prédictions d'état futur et de rétroaction de l'environnement, améliorant ainsi la robustesse face aux changements dans l'interface. Le cadre d'apprentissage fonctionne en deux étapes : (1) prédiction du VEM et évaluation du valeur de l'action à long terme, et (2) utilisation des messages du VEM pour guider la recherche de politiques, facilitant l'automatisation de la GUI sans lien avec le design. Par des évaluations dans le cadre de référence Android-in-the-Wild, le VEM a atteint le meilleur rendement dans les environnements off-line et on-line, surpassant considérablement le limite de l'apprentissage par renforcement basé sur l'environnement et atteignant un rendement comparable aux méthodes basées sur l'environnement. Un point clé est que le VEM peut atteindre un rendement relativement excellent dans l'évaluation de valeur basée sur la compréhension du sens, comparé aux méthodes entraînées en ligne.",
      "upvotes": 5,
      "discussionId": "67bfd5d7381f8fcb67e5ae3d"
    },
    "publishedAt": "2025-02-26T22:02:50.690Z",
    "title": "VEM: Environment-Free Exploration for Training GUI Agent with Value Environment Model",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.18906.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "654dbac9938fbf1e696be8aa",
      "avatarUrl": "/avatars/b3c4035c48169c1bfb04a439fce3499f.svg",
      "fullname": "Chaoyun Zhang",
      "name": "vyokky",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.18772",
      "authors": [
        {
          "_id": "67bfc297ca6e3c22b6d99c78",
          "name": "Xueqing Peng",
          "hidden": false
        },
        {
          "_id": "67bfc297ca6e3c22b6d99c79",
          "name": "Triantafillos Papadopoulos",
          "hidden": false
        },
        {
          "_id": "67bfc297ca6e3c22b6d99c7a",
          "name": "Efstathia Soufleri",
          "hidden": false
        },
        {
          "_id": "67bfc297ca6e3c22b6d99c7b",
          "name": "Polydoros Giannouris",
          "hidden": false
        },
        {
          "_id": "67bfc297ca6e3c22b6d99c7c",
          "name": "Ruoyu Xiang",
          "hidden": false
        },
        {
          "_id": "67bfc297ca6e3c22b6d99c7d",
          "name": "Yan Wang",
          "hidden": false
        },
        {
          "_id": "67bfc297ca6e3c22b6d99c7e",
          "name": "Lingfei Qian",
          "hidden": false
        },
        {
          "_id": "67bfc297ca6e3c22b6d99c7f",
          "user": {
            "_id": "63b58ed5889aa6707f0bb0f4",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63b58ed5889aa6707f0bb0f4/znl74_aMswlV8VtHrfj3G.jpeg",
            "isPro": true,
            "fullname": "Jimin Huang",
            "user": "jiminHuang",
            "type": "user"
          },
          "name": "Jimin Huang",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-02-27T01:40:40.189Z",
          "hidden": false
        },
        {
          "_id": "67bfc297ca6e3c22b6d99c80",
          "name": "Qianqian Xie",
          "hidden": false
        },
        {
          "_id": "67bfc297ca6e3c22b6d99c81",
          "name": "Sophia Ananiadou",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-26T03:04:01.000Z",
      "title": "Pulls: Benchmark de Modèles de Langage en Finances Grieques de l'Auteur Original",
      "summary": "Grèce joue un rôle important dans l'économie mondiale, mais dans le contexte financier, les modèles de langage grands à grande échelle (LLMs) n'ont pas été étudiés en raison de la complexité du grec et de l'insuffisance de données spécifiques de son domaine. Des différences significatives ont été identifiées dans le rendement des efforts de traitement du langage naturel financier (NLP) multilingue, mais jusqu'à présent, aucun benchmark professionnel de finances grecques et aucun LLM spécifique pour cette langue n'ont été développés. Pour corriger cela, nous présentons le premier benchmark d'évaluation de finances grecques, Plutus-ben, et le premier LLM de finances grecques, Plutus-8B. Plutus-8B a été fine-tuné avec des données uniques du grec. Plutus-ben traite 5 tâches financières fondamentales et promeut une évaluation systématique et reproductible des LLMs. En se basant sur ces tâches, nous fournissons trois nouveaux ensembles de données de haute qualité de finances grecques, annotés avec rigueur par des experts nationaux, ajoutant à deux ressources existantes. Selon une évaluation complète de 22 LLMs, la NLP de finances grecques fait face à des défis en raison de la complexité linguistique, l'utilisation de terminologie spécifique et des erreurs de calculs financiers. Ces résultats soulignent les limites des transformers entre langues, la nécessité de connaissances financières pour l'apprentissage du grec et les défis d'application d'un LLM de finances au grec. Nous publions Plutus-ben, Plutus-8B et tous les ensembles de données liés pour promouvoir une recherche reproductible et le développement de la NLP de finances grecques, ainsi que pour encourager l'inclusion multilingue dans le secteur financier.",
      "upvotes": 4,
      "discussionId": "67bfc298ca6e3c22b6d99caa"
    },
    "publishedAt": "2025-02-27T00:08:09.082Z",
    "title": "Plutus: Benchmarking Large Language Models in Low-Resource Greek Finance",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.18772.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "63b58ed5889aa6707f0bb0f4",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63b58ed5889aa6707f0bb0f4/znl74_aMswlV8VtHrfj3G.jpeg",
      "fullname": "Jimin Huang",
      "name": "jiminHuang",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isMod": false,
      "followerCount": 14
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.16776",
      "authors": [
        {
          "_id": "67bfd8d546083445aacb4605",
          "name": "Zhexin Zhang",
          "hidden": false
        },
        {
          "_id": "67bfd8d546083445aacb4606",
          "name": "Leqi Lei",
          "hidden": false
        },
        {
          "_id": "67bfd8d546083445aacb4607",
          "name": "Junxiao Yang",
          "hidden": false
        },
        {
          "_id": "67bfd8d546083445aacb4608",
          "name": "Xijie Huang",
          "hidden": false
        },
        {
          "_id": "67bfd8d546083445aacb4609",
          "name": "Yida Lu",
          "hidden": false
        },
        {
          "_id": "67bfd8d546083445aacb460a",
          "name": "Shiyao Cui",
          "hidden": false
        },
        {
          "_id": "67bfd8d546083445aacb460b",
          "name": "Renmiao Chen",
          "hidden": false
        },
        {
          "_id": "67bfd8d546083445aacb460c",
          "name": "Qinglin Zhang",
          "hidden": false
        },
        {
          "_id": "67bfd8d546083445aacb460d",
          "name": "Xinyuan Wang",
          "hidden": false
        },
        {
          "_id": "67bfd8d546083445aacb460e",
          "name": "Hao Wang",
          "hidden": false
        },
        {
          "_id": "67bfd8d546083445aacb460f",
          "user": {
            "_id": "653f1ef4aabbf15fc76a259c",
            "avatarUrl": "/avatars/94e569999d913e961266394ea2875965.svg",
            "isPro": false,
            "fullname": "LLLeo Li",
            "user": "LLLeo612",
            "type": "user"
          },
          "name": "Hao Li",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-27T09:14:45.366Z",
          "hidden": false
        },
        {
          "_id": "67bfd8d546083445aacb4610",
          "name": "Xianqi Lei",
          "hidden": false
        },
        {
          "_id": "67bfd8d546083445aacb4611",
          "name": "Chengwei Pan",
          "hidden": false
        },
        {
          "_id": "67bfd8d546083445aacb4612",
          "name": "Lei Sha",
          "hidden": false
        },
        {
          "_id": "67bfd8d546083445aacb4613",
          "name": "Hongning Wang",
          "hidden": false
        },
        {
          "_id": "67bfd8d546083445aacb4614",
          "name": "Minlie Huang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-24T02:11:52.000Z",
      "title": "AI Sécurité : Modèle Intégrateur d'Évaluation et d'Amélioration de la Sécurité de l'IA",
      "summary": "Le modèle d'IA est en expansion quotidienne via différents écraseurs de réalité virtuelle, mais la garantie de sa sécurité reste un problème important qui n'est pas résolu et n'a pas été suffisamment étudié. Des efforts importants sont faits pour améliorer l'évaluation et la sécurité de l'IA, mais la manque de référentiels standardisés et d'un ensemble complet d'outils empêche considérablement le progrès dans la recherche et l'introduction pratique des systèmes. Pour résoudre ce problème, on présente le cadre intégré et ensemble d'outils appelé AISafetyLab. AISafetyLab intègre les méthodes d'attaque, de défense et d'évaluation et est conçu pour que les développeurs puissent appliquer différentes techniques de manière intuitive à travers une interface simple. De plus, un étude expérimentale sur Vicuna est en cours, analysant des stratégies d'attaque et de défense pour offrir un rendement relativement efficace. AISafetyLab est accessible au public et se consacre à son maintien et à son amélioration continue (https://github.com/thu-coai/AISafetyLab), ce qui contribue à encourager le développement et la recherche de la sécurité de l'IA.",
      "upvotes": 4,
      "discussionId": "67bfd8d646083445aacb464f"
    },
    "publishedAt": "2025-02-26T22:16:03.582Z",
    "title": "AISafetyLab: A Comprehensive Framework for AI Safety Evaluation and Improvement",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.16776.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "61b58aa0d65058ce70beb98c",
      "avatarUrl": "/avatars/aefd9271b891abc6dd2ded1a30eebca4.svg",
      "fullname": "Zhexin Zhang",
      "name": "nonstopfor",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.19204",
      "authors": [
        {
          "_id": "67bfd735ca6e3c22b6de43c7",
          "name": "Xiankang He",
          "hidden": false
        },
        {
          "_id": "67bfd735ca6e3c22b6de43c8",
          "name": "Dongyan Guo",
          "hidden": false
        },
        {
          "_id": "67bfd735ca6e3c22b6de43c9",
          "name": "Hongji Li",
          "hidden": false
        },
        {
          "_id": "67bfd735ca6e3c22b6de43ca",
          "name": "Ruibo Li",
          "hidden": false
        },
        {
          "_id": "67bfd735ca6e3c22b6de43cb",
          "name": "Ying Cui",
          "hidden": false
        },
        {
          "_id": "67bfd735ca6e3c22b6de43cc",
          "name": "Chi Zhang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-26T15:10:05.000Z",
      "title": "Quelle profondeur de résultats peut-on obtenir : les concepteurs peuvent également créer des estimateurs de profondeur monophoniques puissants.",
      "summary": "MDE a pour but de prédire la profondeur de l'essence dans des images RGB et joue un rôle important dans la compréhension tridimensionnelle de l'essence. Le développement récent de MDE 0-shot a amélioré la capacité de généralisation pour différents essences en utilisant des représentations de profondeur normalisées et des résultats basés sur l'apprentissage. Cependant, le méthode actuelle de normalisation de profondeur utilise une normalisation globale, ce qui amplifie le bruit et limite l'efficacité de la collecte de résultats. Dans cet article, on analyse de manière systématique l'impact de différentes stratégies de normalisation de profondeur. En se basant sur ces résultats, on propose la Cross-Context Distillation, qui intègre des codes de profondeur globaux et locaux pour améliorer la qualité des étiquetteurs de rendu. De plus, on introduit un cadre pour collecter des résultats de détection multiple d'objets en utilisant les avantages d'interpolation. De cette manière, la prédiction de profondeur devient plus robuste et précise. Grâce à des expériences larges sur des ensembles de données standards, on montre que notre approche est significativement supérieure en termes statistiques et de qualité par rapport aux méthodes actuelles.",
      "upvotes": 4,
      "discussionId": "67bfd736ca6e3c22b6de441e"
    },
    "publishedAt": "2025-02-26T22:10:20.646Z",
    "title": "Distill Any Depth: Distillation Creates a Stronger Monocular Depth Estimator",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/64196320ed725fef64419c2a/k13rSuJPlDkMtzwdHXCXm.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.19204.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64196320ed725fef64419c2a",
      "avatarUrl": "/avatars/96feb22fb5e8931d6c9e0ea06148266f.svg",
      "fullname": "Chi Zhang",
      "name": "DrChiZhang",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 3
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.19279",
      "authors": [
        {
          "_id": "67bffaca3f838c1e33e074e7",
          "user": {
            "_id": "638ef0b0c67af472d31674a6",
            "avatarUrl": "/avatars/02df97d15a0f46b47f9162221733b121.svg",
            "isPro": false,
            "fullname": "Honglin Guo",
            "user": "KYLN24",
            "type": "user"
          },
          "name": "Honglin Guo",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-27T09:13:52.094Z",
          "hidden": false
        },
        {
          "_id": "67bffaca3f838c1e33e074e8",
          "name": "Kai Lv",
          "hidden": false
        },
        {
          "_id": "67bffaca3f838c1e33e074e9",
          "name": "Qipeng Guo",
          "hidden": false
        },
        {
          "_id": "67bffaca3f838c1e33e074ea",
          "name": "Tianyi Liang",
          "hidden": false
        },
        {
          "_id": "67bffaca3f838c1e33e074eb",
          "name": "Zhiheng Xi",
          "hidden": false
        },
        {
          "_id": "67bffaca3f838c1e33e074ec",
          "name": "Demin Song",
          "hidden": false
        },
        {
          "_id": "67bffaca3f838c1e33e074ed",
          "name": "Qiuyinzhe Zhang",
          "hidden": false
        },
        {
          "_id": "67bffaca3f838c1e33e074ee",
          "name": "Yu Sun",
          "hidden": false
        },
        {
          "_id": "67bffaca3f838c1e33e074ef",
          "name": "Kai Chen",
          "hidden": false
        },
        {
          "_id": "67bffaca3f838c1e33e074f0",
          "name": "Xipeng Qiu",
          "hidden": false
        },
        {
          "_id": "67bffaca3f838c1e33e074f1",
          "name": "Tao Gui",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-26T16:33:41.000Z",
      "title": "Carískus : Nous développons des normes de qualité de données à partir des préférences humaines.",
      "summary": "Le modèle de langue est essentiel pour atteindre son meilleur rendement, ce qui nécessite des données de qualité élevée. Actuellement, l'approche est basée sur des heuristiques manuellement conçues, des variantes de modèles existants, l'entraînement de classifieurs ou des ajustements de règles. Cette approche requiert un grand savoir professionnel et un effort humain, et peut introduire des biais dans les données. Nous présentons CritiQ, un nouveau méthode de sélection de données. CritiQ utilise des paires de signes humains de sim30 pour extraire automatiquement les préférences humaines sur la qualité des données et sélectionne des données de manière efficace. L'un de ses principaux composants, CritiQ Flow, permet à un agent administratif d'évoluer les règles de qualité et à un agent de travail d'évaluer deux généralisations. Dans nos études précédentes, nous avons extrait des règles de qualité et construit un savoir basé pour renforcer CritiQ Flow. Comparé aux méthodes basées sur la variabilité et les classifieurs, les règles linguistiques sont interprétables et ont une valeur de réutilisation. Après avoir obtenu les règles, nous entraînons un score CritiQ et assignons un score de qualité pour sélectionner des données de manière efficace. Nous avons démontré des effets dans des domaines comme le code, les mathématiques et la logique, et nous avons atteint des hautes précisions sur des ensembles de tests de signes humains. Pour vérifier la qualité des données sélectionnées, nous continuons d'entraîner le modèle Llama 3.1 et nous observons des améliorations dans des tâches de flux postérieures. Les études d'ablation montrent les avantages du savoir basé et du processus de réflexion. Nous analysons l'évolution des règles et l'effet de la majorité.",
      "upvotes": 3,
      "discussionId": "67bffacc3f838c1e33e075a2"
    },
    "publishedAt": "2025-02-27T00:47:02.948Z",
    "title": "CritiQ: Mining Data Quality Criteria from Human Preferences",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.19279.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "638ef0b0c67af472d31674a6",
      "avatarUrl": "/avatars/02df97d15a0f46b47f9162221733b121.svg",
      "fullname": "Honglin Guo",
      "name": "KYLN24",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.19413",
      "authors": [
        {
          "_id": "67c02d6aa15ac71dcf1c754e",
          "name": "Christoph Schuhmann",
          "hidden": false
        },
        {
          "_id": "67c02d6aa15ac71dcf1c754f",
          "name": "Gollam Rabby",
          "hidden": false
        },
        {
          "_id": "67c02d6aa15ac71dcf1c7550",
          "name": "Ameya Prabhu",
          "hidden": false
        },
        {
          "_id": "67c02d6aa15ac71dcf1c7551",
          "name": "Tawsif Ahmed",
          "hidden": false
        },
        {
          "_id": "67c02d6aa15ac71dcf1c7552",
          "name": "Andreas Hochlehnert",
          "hidden": false
        },
        {
          "_id": "67c02d6aa15ac71dcf1c7553",
          "name": "Huu Nguyen",
          "hidden": false
        },
        {
          "_id": "67c02d6aa15ac71dcf1c7554",
          "name": "Nick Akinci Heidrich",
          "hidden": false
        },
        {
          "_id": "67c02d6aa15ac71dcf1c7555",
          "name": "Ludwig Schmidt",
          "hidden": false
        },
        {
          "_id": "67c02d6aa15ac71dcf1c7556",
          "name": "Robert Kaczmarczyk",
          "hidden": false
        },
        {
          "_id": "67c02d6aa15ac71dcf1c7557",
          "name": "Sören Auer",
          "hidden": false
        },
        {
          "_id": "67c02d6aa15ac71dcf1c7558",
          "name": "Jenia Jitsev",
          "hidden": false
        },
        {
          "_id": "67c02d6aa15ac71dcf1c7559",
          "name": "Matthias Bethge",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-26T18:56:52.000Z",
      "title": "Aleksei Notre projet : Projet qui utilise les LMs pour atténuer l'impact de la propriété intellectuelle dans la science",
      "summary": "Paywall, résent et règles de droit d'auteur limitent la large diffusion et le réutilisation étendue de la connaissance scientifique. Nous basons notre approche sur les principes et la faisabilité technique d'extraire la connaissance scientifique des papiers académiques. Les méthodes actuelles, telles que l'embedding de texte, ne peuvent pas préserver de manière fiable le contenu factuel. Une simple redéfinition légalement justifiée. Nous encourageons la communauté à accepter de nouvelles idées : transformer les papiers académiques en Unités de Connaissances à l'aide de LLMs. Ces unités sont de données structurées sans style, utilisant des données structurées pour capturer des informations sur les entités, les attributs et les relations. Nous démontrons avec des Unités de Connaissances que : (1) un cadre basé sur l'analyse du droit d'auteur allemand et de la théorie « Fair Use » des États-Unis peut soutenir la partage légal de la connaissance provenant des papiers de recherche. (2) presque toute la connaissance factuelle (environ 95%) de l'article original peut être préservée, et les résultats de mesure des faits à partir du document copyrighté en utilisant des MCQs sont présentés. Nous prédissons que la connaissance scientifique peut tirer des bénéfices significatifs pour la recherche scientifique et l'éducation en réutilisant des faits importants provenant des documents copyrightés. Pour soutenir cela, nous partageons des outils open-source pour convertir les papiers académiques en Unités de Connaissances. En résumé, notre travail affirme la possibilité d'un accès démocratique à la connaissance scientifique tout en respectant le droit d'auteur.",
      "upvotes": 2,
      "discussionId": "67c02d6ba15ac71dcf1c7596"
    },
    "publishedAt": "2025-02-27T04:18:26.724Z",
    "title": "Project Alexandria: Towards Freeing Scientific Knowledge from Copyright Burdens via LLMs",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.19413.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6464a0d41683d3c81f51924a",
      "avatarUrl": "/avatars/bfa89f568302fa34a641e0d8744bf8b5.svg",
      "fullname": "Ameya Prabhu",
      "name": "AmeyaPrabhu",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 4
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.18417",
      "authors": [
        {
          "_id": "67c02b2eb14cf3cbc800c292",
          "name": "Alexander Groshev",
          "hidden": false
        },
        {
          "_id": "67c02b2eb14cf3cbc800c293",
          "user": {
            "_id": "67aafccd7517c92ba71142f2",
            "avatarUrl": "/avatars/ef4b5c6867250b8b7af2c995dd7ad740.svg",
            "isPro": false,
            "fullname": "Anastasiia Iashchenko",
            "user": "nastasia-y",
            "type": "user"
          },
          "name": "Anastasiia Iashchenko",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-27T09:13:49.896Z",
          "hidden": false
        },
        {
          "_id": "67c02b2eb14cf3cbc800c294",
          "name": "Pavel Paramonov",
          "hidden": false
        },
        {
          "_id": "67c02b2eb14cf3cbc800c295",
          "name": "Denis Dimitrov",
          "hidden": false
        },
        {
          "_id": "67c02b2eb14cf3cbc800c296",
          "name": "Andrey Kuznetsov",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-25T18:13:55.000Z",
      "title": "GHOST 2.0 : Transmission de haute qualité en rotation d'une seule tour",
      "summary": "Récemment, tandis que le problème d'échange de visages a reçu une attention dans la communauté de recherche, le problème d'échange de têtes n'a pas été largement étudié. L'échange de têtes, en dehors du mouvement de couleur de visage, présente un problème spécial en synthèse, car il faut conserver toute l'information structurale de la tête et remplir les espaces vides entre la tête échangée et le fond. Dans cet article, deux modules spécialisés sont utilisés pour aborder ces problèmes : GHOST 2.0. Tout d'abord, on renforce le modèle d'alignement approprié pour la représentation de la tête, en conservant l'identité à différentes échelles et en la rendant résistante aux changements de posture extrêmes. Ensuite, on utilise le module de Blender pour déplacer le couleur de visage et remplir les zones incorrectes, permettant ainsi que la tête se adapte complètement au fond cible. Les deux modules montrent un rendement supérieur aux normes dans leurs tâches respectives et permettent d'atteindre des résultats de pointe dans l'échange de têtes. De plus, ils résolvent des cas complexes tels que des grandes différences entre les formes de tête de source et de cible. Le code est disponible sur : https://github.com/ai-forever/ghost-2.0.",
      "upvotes": 2,
      "discussionId": "67c02b31b14cf3cbc800c34b"
    },
    "publishedAt": "2025-02-27T04:15:43.126Z",
    "title": "GHOST 2.0: generative high-fidelity one shot transfer of heads",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.18417.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "67aafccd7517c92ba71142f2",
      "avatarUrl": "/avatars/ef4b5c6867250b8b7af2c995dd7ad740.svg",
      "fullname": "Anastasiia Iashchenko",
      "name": "nastasia-y",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.19187",
      "authors": [
        {
          "_id": "67c01747e8c7d56a8e0cbdc3",
          "name": "Mehran Kazemi",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdc4",
          "user": {
            "_id": "654e97ef5da3196a78409341",
            "avatarUrl": "/avatars/1a5ea7351ca21960891cf9721b9f4667.svg",
            "isPro": false,
            "fullname": "Bahare Fatemi",
            "user": "baharefatemi",
            "type": "user"
          },
          "name": "Bahare Fatemi",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-02-27T07:42:00.525Z",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdc5",
          "name": "Hritik Bansal",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdc6",
          "name": "John Palowitch",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdc7",
          "name": "Chrysovalantis Anastasiou",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdc8",
          "name": "Sanket Vaibhav Mehta",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdc9",
          "name": "Lalit K. Jain",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdca",
          "name": "Virginia Aglietti",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdcb",
          "name": "Disha Jindal",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdcc",
          "name": "Peter Chen",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdcd",
          "name": "Nishanth Dikkala",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdce",
          "name": "Gladys Tyen",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdcf",
          "name": "Xin Liu",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdd0",
          "name": "Uri Shalit",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdd1",
          "name": "Silvia Chiappa",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdd2",
          "name": "Kate Olszewska",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdd3",
          "name": "Yi Tay",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdd4",
          "name": "Vinh Q. Tran",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdd5",
          "name": "Quoc V. Le",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdd6",
          "name": "Orhan Firat",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-26T14:50:50.000Z",
      "title": "BIG-Bench EXTRA HARD",
      "summary": "Les modèles de langue générale (LLMs) sont en croissance quotidienne dans les applications quotidiennes et exigent des capacités de logique générale et une large gamme de compétences logiques. Cependant, les marques d'évaluation actuelles de logique pour les LLMs se concentrent principalement sur les capacités mathématiques et de programmation, ce qui limite l'évaluation d'une large gamme de compétences logiques. En particulier, le jeu de données BIG-Bench est un cas exceptionnel, car comprend une série de tâches difficiles et offre une évaluation de la capacité logique générale des LLMs à travers un seul cadre unifié. Cependant, l'avancée récente des LLMs, appelée SATAR, qui est une version plus difficile de BIG-Bench (BBH), a montré une réduction de son utilité. Les modèles les plus avancés atteignent des scores presque à la limite dans de nombreuses tâches du BBH, mais son utilité est affectée. Pour surmonter ces limites, un nouveau cadre d'évaluation a été introduit, le BIG-Bench Extra Hard (BBEH), dont l'objectif est de dépasser les limites de l'évaluation de la logique dans les LLMs. BBEH remplace chaque tâche du BBH par une nouvelle tâche qui explore la même capacité logique mais avec un grand accroissement de difficulté. Dans BBEH, différents modèles sont évalués, et le moyenne de précision du meilleur modèle général est de 9,8%, tandis que le meilleur modèle de logique est de 44,8%, montrant un grand potentiel pour des améliorations et clairement identifiant le défi de réaliser une forte capacité logique générale dans les LLMs. BBEH est accessible publiquement : https://github.com/google-deepmind/bbeh.",
      "upvotes": 2,
      "discussionId": "67c01748e8c7d56a8e0cbe0b"
    },
    "publishedAt": "2025-02-27T02:43:05.341Z",
    "title": "BIG-Bench Extra Hard",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.19187.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "5f1158120c833276f61f1a84",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1608042047613-5f1158120c833276f61f1a84.jpeg",
      "fullname": "Niels Rogge",
      "name": "nielsr",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 773
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.16284",
      "authors": [
        {
          "_id": "67bfdbd0302c06f220658e9d",
          "user": {
            "_id": "64e84ec6d41a68b065bf78a7",
            "avatarUrl": "/avatars/bae3c5e3210b40af6e4f113e85f3e206.svg",
            "isPro": false,
            "fullname": "Liang Wang",
            "user": "AzureLeon1",
            "type": "user"
          },
          "name": "Liang Wang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-27T09:14:42.802Z",
          "hidden": false
        },
        {
          "_id": "67bfdbd0302c06f220658e9e",
          "name": "Shaozhen Liu",
          "hidden": false
        },
        {
          "_id": "67bfdbd0302c06f220658e9f",
          "name": "Yu Rong",
          "hidden": false
        },
        {
          "_id": "67bfdbd0302c06f220658ea0",
          "name": "Deli Zhao",
          "hidden": false
        },
        {
          "_id": "67bfdbd0302c06f220658ea1",
          "name": "Qiang Liu",
          "hidden": false
        },
        {
          "_id": "67bfdbd0302c06f220658ea2",
          "name": "Shu Wu",
          "hidden": false
        },
        {
          "_id": "67bfdbd0302c06f220658ea3",
          "name": "Liang Wang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-22T16:34:32.000Z",
      "title": "MolSpectra : L'apprentissage préalable de représentations tridimensionnelles de molécules se fait par l'intermédiaire de la diversité des spectres d'énergie.",
      "summary": "Establir la relation entre la structure 3D et l'état d'énergie des molécules a démontré être un méthode prometteuse pour apprendre la représentation des molécules 3D. Cependant, les méthodes actuelles sont limitées par la modélisation des états d'énergie des molécules basée sur la mécanique classique. Cette limitation exclut des évaluations détaillées de l'énergie des molécules et la mesure expérimentale de leur spectre d'énergie, sauf par effets quantiques-mécaniques et la structure des niveaux d'énergie due à la quantification. Dans cet article, on propose un méthode pour entraîner la représentation des molécules 3D en utilisant des spectres d'énergie (MolSpectra), avec l'objectif d'incorporer des connaissances de la mécanique quantique dans la représentation des molécules. Spécifiquement, on propose d'encoder les spectres de molécules à l'aide d'un encodeur de spectres (SpecFormer) par reconstruction de patchs masqués. Pour mieux comprendre la représentation des molécules 3D, on ajuste les résultats des encodeurs 3D et spectrals en les comparant à un objet d'ajustement. Dans des évaluations sur des référentiels publics, on a confirmé que les représentations entraînées dépassent les méthodes actuelles en la prédiction de caractéristiques moléculaires et la modélisation de dynamiques.",
      "upvotes": 2,
      "discussionId": "67bfdbd1302c06f220658ece"
    },
    "publishedAt": "2025-02-26T22:29:40.056Z",
    "title": "MolSpectra: Pre-training 3D Molecular Representation with Multi-modal Energy Spectra",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.16284.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64e84ec6d41a68b065bf78a7",
      "avatarUrl": "/avatars/bae3c5e3210b40af6e4f113e85f3e206.svg",
      "fullname": "Liang Wang",
      "name": "AzureLeon1",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.17540",
      "authors": [
        {
          "_id": "67bff9608d761fc6a75e24ad",
          "user": {
            "_id": "657ccbf2869d5bb0e53b482f",
            "avatarUrl": "/avatars/2eae5a10bdc14814a04d9f255f16de6b.svg",
            "isPro": false,
            "fullname": "Rohit Saxena",
            "user": "rohitsaxena",
            "type": "user"
          },
          "name": "Rohit Saxena",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-27T09:13:54.284Z",
          "hidden": false
        },
        {
          "_id": "67bff9608d761fc6a75e24ae",
          "name": "Pasquale Minervini",
          "hidden": false
        },
        {
          "_id": "67bff9608d761fc6a75e24af",
          "name": "Frank Keller",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-24T18:35:39.000Z",
      "title": "\"Événement de Benchmark de Résumé : Un Benchmark Multimodal pour les Affiches Scientifiques\"",
      "summary": "Dans le document March Modern, la génération de résumés de texte précis et simple est une tâche difficile. En particulier, il est particulièrement complexe de traiter des contenus visuels complexes comme les posters scientifiques. Pour aborder ce défi, un nouveau benchmark est présenté en utilisant des résumés de posters pour que les modèles de vision-langue (VLMs) puissent comprendre et résumer les posters scientifiques comme des résumés d'articles scientifiques. Le dataset inclut 16 305 posters de congrès, fournis sous format d'image, présentant divers problèmes visuels complexes, comme des routes denses, des zones de texte compactes, des tableaux et des dessins. L'application du benchmark aux résumés de posters permet d'évaluer les meilleurs modèles de vision-langue (MLLMs) actuels, démontrant les défis en termes de précision et de résumé des posters scientifiques. Une méthode hiérarchique appelée Segment & Summarize est proposée, qui dépasse les modèles MLLMs actuels, atteignant un gain de 3,14% sur la métrique ROUGE-L. Ce résultat peut servir de point de départ pour futures recherches sur les résumés de posters.",
      "upvotes": 1,
      "discussionId": "67bff96d8d761fc6a75e27a0"
    },
    "publishedAt": "2025-02-27T00:37:24.965Z",
    "title": "PosterSum: A Multimodal Benchmark for Scientific Poster Summarization",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.17540.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "657ccbf2869d5bb0e53b482f",
      "avatarUrl": "/avatars/2eae5a10bdc14814a04d9f255f16de6b.svg",
      "fullname": "Rohit Saxena",
      "name": "rohitsaxena",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 4
    },
    "isAuthorParticipating": true
  }
]