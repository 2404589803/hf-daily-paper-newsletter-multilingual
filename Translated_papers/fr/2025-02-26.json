[
  {
    "paper": {
      "id": "2502.18411",
      "authors": [
        {
          "_id": "67be834ae7b05f9e43b172b2",
          "user": {
            "_id": "6530e62f536dbca918e71c3e",
            "avatarUrl": "/avatars/efc93bc767e561c6c6d429f65c23382d.svg",
            "isPro": false,
            "fullname": "Xiangyu Z",
            "user": "PhoenixZ",
            "type": "user"
          },
          "name": "Xiangyu Zhao",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-26T08:26:02.247Z",
          "hidden": false
        },
        {
          "_id": "67be834ae7b05f9e43b172b3",
          "user": {
            "_id": "646cd947da8e99940b6e55cf",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/646cd947da8e99940b6e55cf/9c0P0WppFqNW9pdo8LgOS.jpeg",
            "isPro": false,
            "fullname": "Shengyuan Ding",
            "user": "ChrisDing1105",
            "type": "user"
          },
          "name": "Shengyuan Ding",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-26T08:25:59.887Z",
          "hidden": false
        },
        {
          "_id": "67be834ae7b05f9e43b172b4",
          "user": {
            "_id": "675aa937ab6aa7ecd09341ce",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/d_CNUsNOw92pg7MVhf9Vm.png",
            "isPro": false,
            "fullname": "Zicheng Zhang",
            "user": "UniverseCA",
            "type": "user"
          },
          "name": "Zicheng Zhang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:49:10.028Z",
          "hidden": false
        },
        {
          "_id": "67be834ae7b05f9e43b172b5",
          "name": "Haian Huang",
          "hidden": false
        },
        {
          "_id": "67be834ae7b05f9e43b172b6",
          "name": "Maosong Cao",
          "hidden": false
        },
        {
          "_id": "67be834ae7b05f9e43b172b7",
          "user": {
            "_id": "619507e7b74b6c591f794340",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/619507e7b74b6c591f794340/JbPDoy6Ko1V1-6oJJwFV8.jpeg",
            "isPro": false,
            "fullname": "Weiyun Wang",
            "user": "Weiyun1025",
            "type": "user"
          },
          "name": "Weiyun Wang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:48:45.520Z",
          "hidden": false
        },
        {
          "_id": "67be834ae7b05f9e43b172b8",
          "user": {
            "_id": "64638c4d51fa6e63060521b5",
            "avatarUrl": "/avatars/c863ace5b1dc788a341bcf4ddbdfaec1.svg",
            "isPro": false,
            "fullname": "JIaqi",
            "user": "Jiaqiwang",
            "type": "user"
          },
          "name": "Jiaqi Wang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:48:38.876Z",
          "hidden": false
        },
        {
          "_id": "67be834ae7b05f9e43b172b9",
          "user": {
            "_id": "64f5f8dd9b17cd59c453c57f",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64f5f8dd9b17cd59c453c57f/MulhwLcePFUWUQel8LQZ8.jpeg",
            "isPro": false,
            "fullname": "Xinyu Fang",
            "user": "nebulae09",
            "type": "user"
          },
          "name": "Xinyu Fang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-26T08:26:04.433Z",
          "hidden": false
        },
        {
          "_id": "67be834ae7b05f9e43b172ba",
          "user": {
            "_id": "64d1c560c0c627dfa71bdbe0",
            "avatarUrl": "/avatars/f42794fe25bffcd870a1bcee69b95298.svg",
            "isPro": false,
            "fullname": "wenhai.wang",
            "user": "wangwhcore",
            "type": "user"
          },
          "name": "Wenhai Wang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:48:28.151Z",
          "hidden": false
        },
        {
          "_id": "67be834ae7b05f9e43b172bb",
          "name": "Guangtao Zhai",
          "hidden": false
        },
        {
          "_id": "67be834ae7b05f9e43b172bc",
          "user": {
            "_id": "63ee1379190ddd6214efd73a",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1676546883247-noauth.png",
            "isPro": false,
            "fullname": "HAODONG DUAN",
            "user": "KennyUTC",
            "type": "user"
          },
          "name": "Haodong Duan",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:48:20.155Z",
          "hidden": false
        },
        {
          "_id": "67be834ae7b05f9e43b172bd",
          "name": "Hua Yang",
          "hidden": false
        },
        {
          "_id": "67be834ae7b05f9e43b172be",
          "name": "Kai Chen",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-25T18:05:14.000Z",
      "title": "OmniAlign-V : Amélioration de la correspondance entre les préférences humaines et les MLLM.",
      "summary": "Le développement récent des modèles de langage multimodal (MLLM) open-source a principalement visé à améliorer leurs capacités de base, mais présente des déficiences notables en ce qui concerne les préférences humaines. Dans cet article, nous présentons OmniAlign-V, un ensemble de données unifié caractérisé par 200K échantillons de qualité élevée, qui comprend différentes images, des questions complexes et des formats de réponse variés, avec l'objectif de améliorer l'alignement des MLLM avec les préférences humaines. De plus, nous introduisons MM-AlignBench, un benchmark spécifiquement conçu pour évaluer les MLLM en termes de valuation humaine. Les résultats des expérimentations montrent que le fine-tuning supervisé (SFT) ou l'optimisation directe des préférences (DPO) en utilisant OmniAlign-V peuvent maintenir ou améliorer le rendement sur les normes de benchmark VQA, tout en améliorant significativement l'alignement avec les préférences humaines et en maintenant les capacités de base. Notre ensemble de données, benchmark, code et checkpoints sont disponibles sur https://github.com/PhoenixZ810/OmniAlign-V.",
      "upvotes": 46,
      "discussionId": "67be834ce7b05f9e43b1730a"
    },
    "publishedAt": "2025-02-25T22:01:56.532Z",
    "title": "OmniAlign-V: Towards Enhanced Alignment of MLLMs with Human Preference",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.18411.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6530e62f536dbca918e71c3e",
      "avatarUrl": "/avatars/efc93bc767e561c6c6d429f65c23382d.svg",
      "fullname": "Xiangyu Z",
      "name": "PhoenixZ",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.18137",
      "authors": [
        {
          "_id": "67be8443ed8e258c0f70063a",
          "user": {
            "_id": "66c0a08bac74db25de8427ec",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/66c0a08bac74db25de8427ec/9D-piDBZqSt6KNkHImmkv.jpeg",
            "isPro": false,
            "fullname": "Jintao Zhang",
            "user": "jt-zhang",
            "type": "user"
          },
          "name": "Jintao Zhang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-26T08:25:57.704Z",
          "hidden": false
        },
        {
          "_id": "67be8443ed8e258c0f70063b",
          "user": {
            "_id": "6329bdbbde087eac2921e6a9",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1663679904323-noauth.jpeg",
            "isPro": false,
            "fullname": "Xiangchendong",
            "user": "Xiang-cd",
            "type": "user"
          },
          "name": "Chendong Xiang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:49:29.341Z",
          "hidden": false
        },
        {
          "_id": "67be8443ed8e258c0f70063c",
          "name": "Haofeng Huang",
          "hidden": false
        },
        {
          "_id": "67be8443ed8e258c0f70063d",
          "name": "Jia Wei",
          "hidden": false
        },
        {
          "_id": "67be8443ed8e258c0f70063e",
          "user": {
            "_id": "65d5a000ec7e31555e4db57e",
            "avatarUrl": "/avatars/aab8319fbaffdd53faff59a40ca5a5ea.svg",
            "isPro": false,
            "fullname": "Haocheng Xi",
            "user": "hxi0408",
            "type": "user"
          },
          "name": "Haocheng Xi",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:49:45.446Z",
          "hidden": false
        },
        {
          "_id": "67be8443ed8e258c0f70063f",
          "name": "Jun Zhu",
          "hidden": false
        },
        {
          "_id": "67be8443ed8e258c0f700640",
          "user": {
            "_id": "65fcad0ba0d7adc40b54fac2",
            "avatarUrl": "/avatars/7564b5642378fddb46ec3b5ae57c0402.svg",
            "isPro": false,
            "fullname": "Jianfei Chen",
            "user": "surfingtomchen",
            "type": "user"
          },
          "name": "Jianfei Chen",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:49:52.550Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-25T12:02:17.000Z",
      "title": "SpargeAttn : Attention Exacte Esparsée. Ceci est un méthode d'accès utilisée pour accélérer l'inférence du modèle.",
      "summary": "La importance de l'implémentation efficace des actions dans des modèles à grande échelle est due à leur complexité temporelle. À son heureux, les actions montrent généralement une grande espesitude, c'est-à-dire que la majorité des valeurs dans la matrice d'actions sont approximativement égales, ce qui permet de réduire significativement les calculs relatifs. De nombreux études essaient d'accélérer les actions en utilisant des motifs espesités, mais la plupart de ces études se concentrent sur l'optimisation des actions dans un modèle spécifique, en utilisant des motifs espesités spécifiques dans la matrice d'actions. Jusqu'à présent, aucune action espesite générale n'a été trouvée pour améliorer la vitesse de divers modèles et garantir un rendement constant. Dans cet article, nous proposons SpargeAttn, une action espesite et quantifiée générale qui peut être utilisée dans tous les modèles. Notre méthode utilise deux filtres en ligne : dans le premier pas, la matrice d'actions est prédite rapidement et précisément, permettant de sauter une partie de la multiplication de matrices. Dans le second pas, un filtre pour la softmax en ligne est conçu pour permettre de sauter plus de multiplications de matrices sans ajouter de charge supplémentaire. Les expériences montrent que notre méthode peut accélérer les modèles de génération de langage, d'images et de vidéos, en maintenant les critères de rendement sans perte. Le code est disponible sur https://github.com/thu-ml/SpargeAttn.",
      "upvotes": 33,
      "discussionId": "67be8447ed8e258c0f70075f"
    },
    "publishedAt": "2025-02-25T22:04:57.351Z",
    "title": "SpargeAttn: Accurate Sparse Attention Accelerating Any Model Inference",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.18137.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "66c0a08bac74db25de8427ec",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/66c0a08bac74db25de8427ec/9D-piDBZqSt6KNkHImmkv.jpeg",
      "fullname": "Jintao Zhang",
      "name": "jt-zhang",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.17363",
      "authors": [
        {
          "_id": "67bd6d2bbf6d46017e619f31",
          "user": {
            "_id": "66078994c50f8393c56ed837",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/aYYde45zaFACRllyEhJyU.jpeg",
            "isPro": true,
            "fullname": "Tianrui Zhu",
            "user": "xilluill",
            "type": "user"
          },
          "name": "Tianrui Zhu",
          "status": "extracted_confirmed",
          "statusLastChangedAt": "2025-02-25T07:24:35.845Z",
          "hidden": false
        },
        {
          "_id": "67bd6d2bbf6d46017e619f32",
          "user": {
            "_id": "6315d306a9456afe2b9bf34a",
            "avatarUrl": "/avatars/7285b4e7d84b528d1a50f8ee4eb10727.svg",
            "isPro": false,
            "fullname": "ElevenZ",
            "user": "shiyi0408",
            "type": "user"
          },
          "name": "Shiyi Zhang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-26T08:30:48.262Z",
          "hidden": false
        },
        {
          "_id": "67bd6d2bbf6d46017e619f33",
          "user": {
            "_id": "646c6985d072747f7ebf352a",
            "avatarUrl": "/avatars/8aaf92045687b21b56c257db62bf4fa5.svg",
            "isPro": false,
            "fullname": "Jiawei Shao",
            "user": "jewelshaw",
            "type": "user"
          },
          "name": "Jiawei Shao",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:50:09.030Z",
          "hidden": false
        },
        {
          "_id": "67bd6d2bbf6d46017e619f34",
          "name": "Yansong Tang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-24T17:40:09.000Z",
      "title": "KV-Edit : Technologie d'édition d'images sans entraînement permettant la conservation précise du fond.",
      "summary": "La consistance du fondo est un problème important dans le travail d'édition d'images, et la technologie actuelle a développé ce problème pendant de nombreuses années. Dans la recherche actuelle, l'harmonie entre maintenir la similitude avec l'image originale et créer du contenu qui répond à l'objectif reste un défi. Dans ce contexte, on propose un approche non entraînante appelée KV-Edit. KV-Edit utilise le cache de KV de DiTs pour stocker et éviter la récupération des tokens du fondo, maintenant la consistance du fondo tout en évitant la nécessité d'une structure complexe ou d'un entraînement coûteux, et se concentre sur la création de nouveau contenu continu avec le fondo dans la zone fournie par l'utilisateur. De plus, on étudie l'utilisation de la mémoire du cache de KV lors du processus d'édition, optimisant la complexité spatiale à O(1) sans nécessité de rétractions en utilisant des méthodes sans rétractions. Notre approche permet d'étendre les modèles de génération basés sur DiTs sans entraînement supplémentaire. Selon les expériences, KV-Edit dépasse significativement les métriques de qualité tant du fondo que de l'image, démontrant qu'il dépasse les méthodes basées sur l'entraînement. Le site web du projet est disponible sur https://xilluill.github.io/projectpages/KV-Edit.",
      "upvotes": 22,
      "discussionId": "67bd6d2dbf6d46017e619f99"
    },
    "publishedAt": "2025-02-25T21:36:19.851Z",
    "title": "KV-Edit: Training-Free Image Editing for Precise Background Preservation",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.17363.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "66078994c50f8393c56ed837",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/aYYde45zaFACRllyEhJyU.jpeg",
      "fullname": "Tianrui Zhu",
      "name": "xilluill",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.18449",
      "authors": [
        {
          "_id": "67be845a8a5a80542314579f",
          "user": {
            "_id": "632a176259950c1d279d5ea7",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/632a176259950c1d279d5ea7/xsSGhBXalt9RaKzSKY8uk.jpeg",
            "isPro": false,
            "fullname": "Yuxiang Wei",
            "user": "yuxiang630",
            "type": "user"
          },
          "name": "Yuxiang Wei",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:50:44.837Z",
          "hidden": false
        },
        {
          "_id": "67be845a8a5a8054231457a0",
          "name": "Olivier Duchenne",
          "hidden": false
        },
        {
          "_id": "67be845a8a5a8054231457a1",
          "user": {
            "_id": "6481e0ac50b759c75d5fdad0",
            "avatarUrl": "/avatars/49f08d989ca505ae01bce5578a94f6fe.svg",
            "isPro": false,
            "fullname": "Jade Copet",
            "user": "JadeCopet",
            "type": "user"
          },
          "name": "Jade Copet",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:50:58.290Z",
          "hidden": false
        },
        {
          "_id": "67be845a8a5a8054231457a2",
          "name": "Quentin Carbonneaux",
          "hidden": false
        },
        {
          "_id": "67be845a8a5a8054231457a3",
          "user": {
            "_id": "656f473c14fa8cfccd14559e",
            "avatarUrl": "/avatars/8f4fef3d835a7a11c2ab66dbf04f3424.svg",
            "isPro": false,
            "fullname": "Lingming Zhang",
            "user": "lingming",
            "type": "user"
          },
          "name": "Lingming Zhang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:51:10.640Z",
          "hidden": false
        },
        {
          "_id": "67be845a8a5a8054231457a4",
          "name": "Daniel Fried",
          "hidden": false
        },
        {
          "_id": "67be845a8a5a8054231457a5",
          "user": {
            "_id": "630eac7931970d1cd4fbacf2",
            "avatarUrl": "/avatars/b7ccbddfa745db854dc342be1327cd53.svg",
            "isPro": false,
            "fullname": "Gabriel Synnaeve",
            "user": "gsynnaeve",
            "type": "user"
          },
          "name": "Gabriel Synnaeve",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:51:21.641Z",
          "hidden": false
        },
        {
          "_id": "67be845a8a5a8054231457a6",
          "user": {
            "_id": "6597e5a6420dcc68501a69e9",
            "avatarUrl": "/avatars/da48b13e07c367ecd5c891abfd6c3ded.svg",
            "isPro": false,
            "fullname": "Rishabh Singh",
            "user": "RishabhSingh021",
            "type": "user"
          },
          "name": "Rishabh Singh",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:51:28.321Z",
          "hidden": false
        },
        {
          "_id": "67be845a8a5a8054231457a7",
          "name": "Sida I. Wang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-25T18:45:04.000Z",
      "title": "SWE-RL : Développement de l'inférence de LLM par apprentissage répété - Une étude sur le développement de logiciels open source",
      "summary": "La récente publication de DeepSeek-R1 a démontré le grand potentiel de l'apprentissage par renforcement (RL) pour renforcer les capacités générales de l'intelligence artificielle (IA) dans des modèles grands de langage (LLMs). Alors que d'autres travaux continués ont appliqué principalement l'RL à des marathons de programmation et des problèmes de mathématiques, cet article présente le premier approche pour étendre l'intelligence artificielle basée sur l'RL dans le domaine de l'ingénierie logicielle mondiale. En utilisant une petite règle de récompense basée (par exemple, la pondération de la similitude entre la solution réelle et celle générée par le modèle de langage), SWE-RL permet au modèle de langage (LLM) de récupérer automatiquement les processus d'intelligence artificielle des développeurs à partir des données d'évolution de logiciels ouverts, incluant des événements comme les cycles de synthèse de logiciel, les captures de code, les modifications de code, les erreurs et les demandes de réponse. Après avoir été entraîné sur Llama 3, notre modèle d'intelligence artificielle, Llama3-SWE-RL-70B, a atteint un rendement de 41.0% sur SWE-bench Verified - un ensemble de problèmes réels et humainment certifiés sur GitHub. Selon notre expérience, cela est le meilleur rendement rapporté jusqu'à présent pour des modèles de LLMs de taille intermédiaire (<100B), et est considérablement supérieur aux avancées de modèles d'IA personnels comme GPT-4o. Surprenant, Llama3-SWE-RL, qui a été entraîné sur des données d'évolution de logiciels limitées, a découvert une intelligence artificielle élargie. Par exemple, il a montré des améliorations dans la codification de fonctions, l'utilisation de bibliothèques, l'intelligence artificielle du code, les mathématiques et la compréhension générale du langage sur cinq tâches externes. De plus, l'entraînement observatoire basé sur la régression linéaire a entraîné un déclin du rendement. En général, SWE-RL ouvre une nouvelle voie pour améliorer l'intelligence artificielle des modèles de langage par l'apprentissage par renforcement avec des données de grande ingénierie logicielle.",
      "upvotes": 14,
      "discussionId": "67be845b8a5a8054231457d6"
    },
    "publishedAt": "2025-02-25T22:03:08.515Z",
    "title": "SWE-RL: Advancing LLM Reasoning via Reinforcement Learning on Open Software Evolution",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.18449.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 6218
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.17262",
      "authors": [
        {
          "_id": "67bd3870a917fc506d9f3d15",
          "user": {
            "_id": "66ab06956b8847339d449128",
            "avatarUrl": "/avatars/d71490acb91981459121005b84e556d8.svg",
            "isPro": false,
            "fullname": "Xu Chengyin",
            "user": "JerryXu98",
            "type": "user"
          },
          "name": "Chengyin Xu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-25T09:39:44.252Z",
          "hidden": false
        },
        {
          "_id": "67bd3870a917fc506d9f3d16",
          "user": {
            "_id": "636b4d796e6981ebad73f398",
            "avatarUrl": "/avatars/bcd405b98c12afaf1e32d85ad8ce7f23.svg",
            "isPro": false,
            "fullname": "Kaiyuan Chen",
            "user": "Lucky2022",
            "type": "user"
          },
          "name": "Kaiyuan Chen",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-25T09:40:01.532Z",
          "hidden": false
        },
        {
          "_id": "67bd3870a917fc506d9f3d17",
          "name": "Xiao Li",
          "hidden": false
        },
        {
          "_id": "67bd3870a917fc506d9f3d18",
          "user": {
            "_id": "645604eebabbbbd3486dc615",
            "avatarUrl": "/avatars/17a5ca8274e2bfc8f183a4af9878a930.svg",
            "isPro": false,
            "fullname": "shenke",
            "user": "shenke18",
            "type": "user"
          },
          "name": "Ke Shen",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-25T09:39:49.578Z",
          "hidden": false
        },
        {
          "_id": "67bd3870a917fc506d9f3d19",
          "name": "Chenggang Li",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-24T15:44:57.000Z",
      "title": "Méthodes pour clarifier l'échelle des résultats de LLM : Méthodes de visualisation basées sur le clustering",
      "summary": "Le développement rapide des calculatrices avancées a un grand impact sur la taille et le coût du training de modèles de grands langages (LLM). Prédire avec précision le rendement des tâches ultérieures est important pour une distribution efficace des ressources, mais il y a deux principales limitations : (1) \"Le phénomène\" rend les métriques de rendement des tâches ultérieures significatives en détail après le training, mais leur capacité à les prédire avec de petits modèles est limitée ; (2) la distribution non uniforme de la difficulté des tâches et l'absence de lois de scalabilité cohérentes génèrent de grandes variations dans les métriques. Les méthodes actuelles de prédiction de rendement ont des limitations en termes de précision et de confiance, ce qui empêche d'évaluer les potentiels des LLM. Pour aborder ces problèmes, on propose un cadre de prédiction de rendement des tâches ultérieures basé sur la difficulté (COD). COD regroupe les tâches selon leurs caractéristiques de difficulté pour construire sous-ensembles supportables et exclut stratégiquement des clusters non observables et non scalables. Les scores des sous-ensembles sélectionnés agissent comme bons prédicteurs intermédiaires du rendement de l'évaluation complète. Avec un soutien théorique, on peut obtenir une fonction qui transforme les métriques des sous-ensembles possibles en l'ensemble d'évaluation complète. Le méthode est appliquée à la prédiction de la scalabilité du rendement d'un LLM de 70B, fournit des actions qui peuvent aider à la distribution des ressources de training et à observer le processus de training. En particulier, COD atteint une précision notable dans la prédiction d'un LLM de 70B en utilisant un ensemble de petits modèles, avec un écart absolu moyen de 1,36% sur 8 tests de benchmark importants de LLM.",
      "upvotes": 13,
      "discussionId": "67bd3872a917fc506d9f3d8f"
    },
    "publishedAt": "2025-02-25T22:18:24.064Z",
    "title": "Unveiling Downstream Performance Scaling of LLMs: A Clustering-Based Perspective",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.17262.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "636b4d796e6981ebad73f398",
      "avatarUrl": "/avatars/bcd405b98c12afaf1e32d85ad8ce7f23.svg",
      "fullname": "Kaiyuan Chen",
      "name": "Lucky2022",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.15499",
      "authors": [
        {
          "_id": "67be86743ea16c7e9491ff16",
          "name": "Ya Wang",
          "hidden": false
        },
        {
          "_id": "67be86743ea16c7e9491ff17",
          "user": {
            "_id": "66335b9c95c5b79ebf306f30",
            "avatarUrl": "/avatars/d57784ee65cbef014360c9bac1ad4119.svg",
            "isPro": false,
            "fullname": "Zhijian Zhuo",
            "user": "BryceZhuo",
            "type": "user"
          },
          "name": "Zhijian Zhuo",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:58:10.556Z",
          "hidden": false
        },
        {
          "_id": "67be86743ea16c7e9491ff18",
          "user": {
            "_id": "6371128eafbe42caa5a5222b",
            "avatarUrl": "/avatars/c3b2ab35949c38aa3dfb2657a1300aac.svg",
            "isPro": false,
            "fullname": "Yutao Zeng",
            "user": "Taoer",
            "type": "user"
          },
          "name": "Yutao Zeng",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-26T08:25:55.016Z",
          "hidden": false
        },
        {
          "_id": "67be86743ea16c7e9491ff19",
          "user": {
            "_id": "62533db4a06ec75172eeabe7",
            "avatarUrl": "/avatars/b1a4dad90afae5c00df97233a97777db.svg",
            "isPro": false,
            "fullname": "xunzhou",
            "user": "xunzhou",
            "type": "user"
          },
          "name": "Xun Zhou",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:52:26.974Z",
          "hidden": false
        },
        {
          "_id": "67be86743ea16c7e9491ff1a",
          "name": "Jian Yang",
          "hidden": false
        },
        {
          "_id": "67be86743ea16c7e9491ff1b",
          "user": {
            "_id": "64648638351adef1a847a7ad",
            "avatarUrl": "/avatars/7518e058fcf81ee81a06c96e996531e9.svg",
            "isPro": false,
            "fullname": "Xiaoqing Li",
            "user": "LLIXQ",
            "type": "user"
          },
          "name": "Xiaoqing Li",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:51:57.314Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-21T14:49:34.000Z",
      "title": "Échappage de la distribution d'échelle : cela permet l'entraînement stable et efficace de modèles de langage à grande échelle.",
      "summary": "La stabilité de l'entraînement est un problème long duré reconnu dans l'apprentissage préalable de modèles de langage grands (LLM), en particulier dans les structures comme le Transformer Post-Norm, qui sont vulnérables aux explosions de gradients et à la perte. Dans cette étude, une nouvelle approche appelée \"Séparation de la Distribution des Échelles (SDD)\" est proposée pour prévenir les explosions et la perte de gradients et stabiliser l'entraînement. La SDD sépare explicitement les échelles et les distributions des matrices de poids dans toutes les couches de la fusion, en utilisant des structures de normalisation et des vecteurs d'échellabilité apprenables pour réguler l'activation. De cette manière, elle préventit les explosions et la perte de gradients et optimise l'efficacité de l'optimisation. Cette séparation garantit une propagation stable des gradients et fonctionne efficacement même dans des réseaux très profonds. Les résultats des expérimentations montrent que la SDD garantit la stabilité de l'entraînement de différentes structures de LLM et obtient des résultats supérieurs aux méthodes existantes dans différentes configurations de normalisation. De plus, la proposition est légère, compatible avec les frameworks existants et fournit une solution pratique efficace pour la stabilité de l'entraînement de LLM. Le code est disponible sur https://github.com/kaihemo/SDD.",
      "upvotes": 10,
      "discussionId": "67be86753ea16c7e9491ff49"
    },
    "publishedAt": "2025-02-25T22:26:11.421Z",
    "title": "Scale-Distribution Decoupling: Enabling Stable and Effective Training of Large Language Models",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/6371128eafbe42caa5a5222b/eu6jpeTjTn34I1SJ4_K1a.png",
      "https://cdn-uploads.huggingface.co/production/uploads/6371128eafbe42caa5a5222b/P6mXXagZPsH6fwQ6myMlr.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.15499.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6371128eafbe42caa5a5222b",
      "avatarUrl": "/avatars/c3b2ab35949c38aa3dfb2657a1300aac.svg",
      "fullname": "Yutao Zeng",
      "name": "Taoer",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.18364",
      "authors": [
        {
          "_id": "67be81414084d82ee69ad4a2",
          "user": {
            "_id": "647e83257f9ad5e44babe82a",
            "avatarUrl": "/avatars/2d9593775c49856fe5dfa5bd23dfcda7.svg",
            "isPro": false,
            "fullname": "yifan pu",
            "user": "yifanpu001",
            "type": "user"
          },
          "name": "Yifan Pu",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:58:24.942Z",
          "hidden": false
        },
        {
          "_id": "67be81414084d82ee69ad4a3",
          "user": {
            "_id": "65e78ebf24a38e0fc5e149e6",
            "avatarUrl": "/avatars/d05e267f29de7de226c4fc0ae37c95ff.svg",
            "isPro": false,
            "fullname": "Yiming Zhao",
            "user": "2JZ",
            "type": "user"
          },
          "name": "Yiming Zhao",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:58:30.860Z",
          "hidden": false
        },
        {
          "_id": "67be81414084d82ee69ad4a4",
          "name": "Zhicong Tang",
          "hidden": false
        },
        {
          "_id": "67be81414084d82ee69ad4a5",
          "name": "Ruihong Yin",
          "hidden": false
        },
        {
          "_id": "67be81414084d82ee69ad4a6",
          "user": {
            "_id": "65229f2f6b01183a67e86370",
            "avatarUrl": "/avatars/b218207fce28497b30e22c807d44b2d2.svg",
            "isPro": false,
            "fullname": "Haoxing Ye",
            "user": "131131yhx",
            "type": "user"
          },
          "name": "Haoxing Ye",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:58:52.821Z",
          "hidden": false
        },
        {
          "_id": "67be81414084d82ee69ad4a7",
          "name": "Yuhui Yuan",
          "hidden": false
        },
        {
          "_id": "67be81414084d82ee69ad4a8",
          "user": {
            "_id": "666470a28f5513b0cf11e850",
            "avatarUrl": "/avatars/7beea758882677ad32a12ce56d4d084a.svg",
            "isPro": false,
            "fullname": "Dong Chen",
            "user": "DongChen06",
            "type": "user"
          },
          "name": "Dong Chen",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:59:16.526Z",
          "hidden": false
        },
        {
          "_id": "67be81414084d82ee69ad4a9",
          "user": {
            "_id": "646b2f4bb1202bc77c0fb396",
            "avatarUrl": "/avatars/6b09dec5d5affe817ad6acda60f61740.svg",
            "isPro": false,
            "fullname": "Jianmin_bao",
            "user": "JianminBao",
            "type": "user"
          },
          "name": "Jianmin Bao",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:59:22.654Z",
          "hidden": false
        },
        {
          "_id": "67be81414084d82ee69ad4aa",
          "user": {
            "_id": "64f7f119a92703ef65d9a717",
            "avatarUrl": "/avatars/118524faab66cecba6d4da622034b44b.svg",
            "isPro": false,
            "fullname": "Sirui Zhang",
            "user": "zsr200901",
            "type": "user"
          },
          "name": "Sirui Zhang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:59:30.766Z",
          "hidden": false
        },
        {
          "_id": "67be81414084d82ee69ad4ab",
          "user": {
            "_id": "67965a5a9f57883759a6efc3",
            "avatarUrl": "/avatars/9138a879fbe1f60c2f4720810bfdfda6.svg",
            "isPro": false,
            "fullname": "Yanbin Wang",
            "user": "yanbinwang",
            "type": "user"
          },
          "name": "Yanbin Wang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:59:38.138Z",
          "hidden": false
        },
        {
          "_id": "67be81414084d82ee69ad4ac",
          "name": "Lin Liang",
          "hidden": false
        },
        {
          "_id": "67be81414084d82ee69ad4ad",
          "user": {
            "_id": "6672e20d1dbdf7da8310dd92",
            "avatarUrl": "/avatars/5d2fb23f92a7f9ff025a5be17a26de4d.svg",
            "isPro": false,
            "fullname": "lijuanwang",
            "user": "lijuanwang228",
            "type": "user"
          },
          "name": "Lijuan Wang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T09:00:05.520Z",
          "hidden": false
        },
        {
          "_id": "67be81414084d82ee69ad4ae",
          "name": "Ji Li",
          "hidden": false
        },
        {
          "_id": "67be81414084d82ee69ad4af",
          "name": "Xiu Li",
          "hidden": false
        },
        {
          "_id": "67be81414084d82ee69ad4b0",
          "user": {
            "_id": "64c882f7527d7636555bbb2c",
            "avatarUrl": "/avatars/578a118a945dd6fa62fd3be9d6e4e986.svg",
            "isPro": false,
            "fullname": "Zhouhui Lian",
            "user": "lianzhouhui",
            "type": "user"
          },
          "name": "Zhouhui Lian",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:59:57.943Z",
          "hidden": false
        },
        {
          "_id": "67be81414084d82ee69ad4b1",
          "name": "Gao Huang",
          "hidden": false
        },
        {
          "_id": "67be81414084d82ee69ad4b2",
          "name": "Baining Guo",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-25T16:57:04.000Z",
      "title": "ART : Génération d'Images Multi-Couche Transparentes avec Transformateur de Régions Non-Nommées",
      "summary": "La génération d'images multi-couche est une tâche fondamentale qui permet aux utilisateurs de séparer, de sélectionner et d'éditer des couches spécifiques d'une image, ce qui est essentiel pour innover l'interaction entre modèles de génération. Dans cet article, nous introduisons le Transformer Région Anonyme (ART), qui génère des images multi-couche directement en se basant sur un texte global et la position de régions anonymes. ART est un modèle structurant du savoir basé sur une théorie simple, différenciant-se des principaux modèles de position de régions significatives existants, en ce sens qu'il permet que le modèle de génération détermine automatiquement la correspondance entre les tokens de texte et les tokens visuels. De plus, la structure de coupe de régions, qui sélectionne uniquement les tokens visuels appartenant à chaque région anonyme, réduit considérablement le coût de calcul et permet une génération efficace d'images multi-couche (par exemple, plus de 50 couches). Comparé à un approche globale, ART est plus rapide au moins 12 fois et réduit les collisions entre couches. De plus, ART permet une génération efficace de couches et un contrôle précis de la visibilité, établissant un nouveau modèle interactif de génération de contenu.",
      "upvotes": 7,
      "discussionId": "67be81464084d82ee69ad576"
    },
    "publishedAt": "2025-02-25T21:50:19.941Z",
    "title": "ART: Anonymous Region Transformer for Variable Multi-Layer Transparent Image Generation",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.18364.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "646f69a6041e48e1c4728de3",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/646f69a6041e48e1c4728de3/U5OaW6PgsXTXnfG03xs9Q.png",
      "fullname": "GlyphByT5",
      "name": "GlyphByT5",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 34
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.18461",
      "authors": [
        {
          "_id": "67bea0cc2d6011a72335f704",
          "user": {
            "_id": "67be9daa65ae638b17e461e9",
            "avatarUrl": "/avatars/30ab04b8a6a4d3e1d211943c0344b95e.svg",
            "isPro": false,
            "fullname": "Ziheng Ouyang",
            "user": "oyzh2005",
            "type": "user"
          },
          "name": "Ziheng Ouyang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-26T08:25:46.941Z",
          "hidden": false
        },
        {
          "_id": "67bea0cc2d6011a72335f705",
          "name": "Zhen Li",
          "hidden": false
        },
        {
          "_id": "67bea0cc2d6011a72335f706",
          "name": "Qibin Hou",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-25T18:59:12.000Z",
      "title": "K-LoRA : Méthode d'intégration de LoRA de n'importe quel style et de n'importe quelle section gratuite",
      "summary": "Recentes études ont révisé le méthode de combinaison de différents LoRA pour générer des styles et des contenus en même temps. Cependant, les méthodes actuelles ne peuvent pas conserver efficacement les deux thèmes et styles simultanément, ou nécessitent un entraînement supplémentaire. Dans cet article, il est affirmé que les caractéristiques internes de LoRA peuvent fusionner efficacement des thèmes et des styles appris dans des modèles de dispersion. En se basant sur cette perspective, on propose K-LoRA, une approche simple et efficace sans entraînement supplémentaire pour combiner les LoRA. À chaque couche d'attention, K-LoRA compare les K éléments les plus importants des LoRA à fusionner et sélectionne le LoRA qui se adapte le mieux à la fusion optimale. Cette structure de sélection garantit que les principales caractéristiques du thème et du style soient maintenues lors du processus de fusion et que leur contribution soit équilibrée efficacement. À travers les résultats expérimentaux, il est montré que le méthode proposée intègre efficacement l'information de thème et de style apprise par les LoRA originaux et dépasse les normes d'entraînement en termes qualitatifs et quantitatifs.",
      "upvotes": 6,
      "discussionId": "67bea0cf2d6011a72335f7aa"
    },
    "publishedAt": "2025-02-26T00:56:27.275Z",
    "title": "K-LoRA: Unlocking Training-Free Fusion of Any Subject and Style LoRAs",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.18461.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6285a9133ab6642179158944",
      "avatarUrl": "/avatars/6e10fa07c94141fcdbe0cab02bb731ca.svg",
      "fullname": "Zhen Li",
      "name": "Paper99",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 14
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.18356",
      "authors": [
        {
          "_id": "67be8866823e790d21a2bb90",
          "user": {
            "_id": "6529aa1460e706730575baa9",
            "avatarUrl": "/avatars/550fac58a6ebf937a65d19a48e71eb45.svg",
            "isPro": false,
            "fullname": "George Thomas",
            "user": "georgethomas",
            "type": "user"
          },
          "name": "George Thomas",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T09:06:53.500Z",
          "hidden": false
        },
        {
          "_id": "67be8866823e790d21a2bb91",
          "user": {
            "_id": "636c1e4415cd58e915bc45df",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/636c1e4415cd58e915bc45df/KnPgdPe0G5ngvXaCBua6R.jpeg",
            "isPro": false,
            "fullname": "Alex J. Chan",
            "user": "XanderJC",
            "type": "user"
          },
          "name": "Alex J. Chan",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-02-26T03:20:08.029Z",
          "hidden": false
        },
        {
          "_id": "67be8866823e790d21a2bb92",
          "name": "Jikun Kang",
          "hidden": false
        },
        {
          "_id": "67be8866823e790d21a2bb93",
          "user": {
            "_id": "63a2f1dfc8a2aa5d9e85f8f6",
            "avatarUrl": "/avatars/f2191e3a0ce92563f9bfe83283d8d966.svg",
            "isPro": false,
            "fullname": "Wenqi Wu",
            "user": "BiggieW",
            "type": "user"
          },
          "name": "Wenqi Wu",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T09:08:43.843Z",
          "hidden": false
        },
        {
          "_id": "67be8866823e790d21a2bb94",
          "user": {
            "_id": "64f46b681d337935d0495d4d",
            "avatarUrl": "/avatars/cce5a4910617931fb13062b832e14ef8.svg",
            "isPro": false,
            "fullname": "Filippos Christianos",
            "user": "semitable",
            "type": "user"
          },
          "name": "Filippos Christianos",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T09:08:23.534Z",
          "hidden": false
        },
        {
          "_id": "67be8866823e790d21a2bb95",
          "user": {
            "_id": "5f195784925b9863e28ad610",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1595496291585-noauth.png",
            "isPro": false,
            "fullname": "Fraser Greenlee",
            "user": "Fraser",
            "type": "user"
          },
          "name": "Fraser Greenlee",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T09:08:16.380Z",
          "hidden": false
        },
        {
          "_id": "67be8866823e790d21a2bb96",
          "name": "Andy Toulis",
          "hidden": false
        },
        {
          "_id": "67be8866823e790d21a2bb97",
          "user": {
            "_id": "6787c4a970c0f5272f456968",
            "avatarUrl": "/avatars/bdfa53add57b0f0a9e4e94e24115b354.svg",
            "isPro": false,
            "fullname": "Marvin Purtorab",
            "user": "comvergent-marvin",
            "type": "user"
          },
          "name": "Marvin Purtorab",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T09:07:42.610Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-25T16:45:08.000Z",
      "title": "Webjuego : Agente de recherche AI pour les sites web communs difficiles",
      "summary": "WebGames est une feuille de calcul de référence rigoureuse conçue pour évaluer les agents de navigation web, rassemblant des problèmes interactifs avec un valeur de 50 points ou plus. Ce ensemble de problèmes a été spécialement conçu pour être faciles pour un être humain et vise la vérification systématique des limites des systèmes AI actuels en termes d'interaction avec le navigateur, de traitement d'entrées très complexes, de tâches cognitives, d'automatisation des flux de travail et de divertissement interactif. Le cadre de travail assure des évaluations reproductibles dans un environnement de test harmonieux, en excluant les dépendances externes. Les rendements des modèles visuels avancés tels que GPT-4o, Claude Computer-Use, Gemini-1.5-Pro et Qwen2-VL sont comparés à ceux du rendement humain. Les résultats montrent des différences significatives de capacité, avec le meilleur système AI atteignant un rendement de 95,7% dans 43,1% des cas. Ce benchmark révèle des limites fondamentales dans la capacité de traiter des patrons d'interaction web qui sont intuitifs pour l'être humain. WebGames est disponible sur webgames.convergence.ai et fournit une implémentation légère sur le côté client pour accélérer les cycles d'évaluation. Grâce à la spécification de problèmes standardisés et à une architecture modulaire, WebGames offre une base solide pour mesurer le progrès dans le développement d'AI avancés pour la navigation web.",
      "upvotes": 4,
      "discussionId": "67be8868823e790d21a2bbea"
    },
    "publishedAt": "2025-02-25T22:20:16.916Z",
    "title": "WebGames: Challenging General-Purpose Web-Browsing AI Agents",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.18356.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 6218
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.16794",
      "authors": [
        {
          "_id": "67be86a78a5a80542314f0e6",
          "user": {
            "_id": "6531a65daed617662c7f1007",
            "avatarUrl": "/avatars/ea2e504780dc40719f7501ab2c7d9c91.svg",
            "isPro": false,
            "fullname": "Xilin Jiang",
            "user": "xi-j",
            "type": "user"
          },
          "name": "Xilin Jiang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-26T08:25:52.841Z",
          "hidden": false
        },
        {
          "_id": "67be86a78a5a80542314f0e7",
          "user": {
            "_id": "661361993bb67cb4f356c3de",
            "avatarUrl": "/avatars/b707c07f9c70d2ed1e8cd8cff2551c69.svg",
            "isPro": false,
            "fullname": "Sukru Samet Dindar",
            "user": "susameddin",
            "type": "user"
          },
          "name": "Sukru Samet Dindar",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T09:11:37.706Z",
          "hidden": false
        },
        {
          "_id": "67be86a78a5a80542314f0e8",
          "user": {
            "_id": "670e8671ba29b3fca221b8c9",
            "avatarUrl": "/avatars/20f6479bd5218d6d3e304539df5003f9.svg",
            "isPro": false,
            "fullname": "Vishal Choudhari",
            "user": "vchoudhari",
            "type": "user"
          },
          "name": "Vishal Choudhari",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T09:11:45.258Z",
          "hidden": false
        },
        {
          "_id": "67be86a78a5a80542314f0e9",
          "name": "Stephan Bickel",
          "hidden": false
        },
        {
          "_id": "67be86a78a5a80542314f0ea",
          "name": "Ashesh Mehta",
          "hidden": false
        },
        {
          "_id": "67be86a78a5a80542314f0eb",
          "name": "Guy M McKhann",
          "hidden": false
        },
        {
          "_id": "67be86a78a5a80542314f0ec",
          "name": "Adeen Flinker",
          "hidden": false
        },
        {
          "_id": "67be86a78a5a80542314f0ed",
          "name": "Daniel Friedman",
          "hidden": false
        },
        {
          "_id": "67be86a78a5a80542314f0ee",
          "name": "Nima Mesgarani",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-24T03:06:45.000Z",
      "title": "AAD-LLM : Attention de Réseau pour Compréhension des Échelles Acoustiques",
      "summary": "Les modèles basés sur l'audio, notamment les modèles de langage de son (LLMs), traitent uniformément toutes les entrées sonores et ne dépendent pas de la perception des ouïs. Cependant, la perception acoustique humaine a une sélection intrinsèque : les ouïs peuvent se concentrer sur un seul locuteur dans un environnement complexe de sons, ignorant le reste. Actuellement, ces modèles n'ont pas cette capacité de sélection, ce qui limite leur capacité à générer des réponses appropriées. Pour aborder ce problème, nous introduisons l'Intelligence Informée de Compréhension de l'Écosystème Acoustique (II-ASU) et présentons un prototype de système, le Modèle de Langage de Son (AAD-LLM), qui estime l'attention de l'ouï intégrant des signaux cérébraux. L'AAD-LLM interprète le locuteur sur lequel l'ouï est concentré et génère des réponses améliorées en intégrant des enregistrements de programmation des valeurs électriques cérébrales (iEEG). Le modèle prédit le locuteur sur lequel l'ouï est concentré et conditionne la génération de réponses en fonction de l'état d'attention prédit. L'AAD-LLM a démontré améliorer les évaluations subjectives et objectives des locuteurs, ainsi que la précision de l'identification des locuteurs, la traduction des discours, l'extraction d'information et les réponses aux questions, dans des scénarios avec plusieurs locuteurs. Cette recherche est la première étape dans l'intelligence artificielle de son orientée par l'intention et explore un nouveau paradigme où la perception humaine fournit des informations à l'audition de la machine. Les démonstrations et les codes sont disponibles sur la URL suivante : https://aad-llm.github.io.",
      "upvotes": 4,
      "discussionId": "67be86a98a5a80542314f16e"
    },
    "publishedAt": "2025-02-25T22:20:08.416Z",
    "title": "AAD-LLM: Neural Attention-Driven Auditory Scene Understanding",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.16794.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "6531a65daed617662c7f1007",
      "avatarUrl": "/avatars/ea2e504780dc40719f7501ab2c7d9c91.svg",
      "fullname": "Xilin Jiang",
      "name": "xi-j",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.17425",
      "authors": [
        {
          "_id": "67bddd63c7d8b835b82ced9a",
          "user": {
            "_id": "635364b3c41f548fe39db945",
            "avatarUrl": "/avatars/ad1916bbfabca0b6651c8eabacc5eba8.svg",
            "isPro": false,
            "fullname": "Runpeng Yu",
            "user": "rp-yu",
            "type": "user"
          },
          "name": "Runpeng Yu",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T09:14:07.580Z",
          "hidden": false
        },
        {
          "_id": "67bddd63c7d8b835b82ced9b",
          "user": {
            "_id": "64396ebc21221ac7411852b3",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64396ebc21221ac7411852b3/SR0dC8N0bdj9tZFxYPpSf.jpeg",
            "isPro": false,
            "fullname": "Xinyin Ma",
            "user": "horseee",
            "type": "user"
          },
          "name": "Xinyin Ma",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T09:14:13.670Z",
          "hidden": false
        },
        {
          "_id": "67bddd63c7d8b835b82ced9c",
          "user": {
            "_id": "63fc03a50aab060792ffef39",
            "avatarUrl": "/avatars/9d5b1bb2a41928e08176b703935133ab.svg",
            "isPro": false,
            "fullname": "Wangxinchao",
            "user": "wxcTest",
            "type": "user"
          },
          "name": "Xinchao Wang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T09:14:53.838Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-24T18:56:12.000Z",
      "title": "Je présente la façon de intégrer le Token de Perception Visuelle dans un Modèle de Langue de Grande Taille Multimodal.",
      "summary": "La utilisation de l'information visuelle dépend du modèle de langage multimodal de différentes modalités (MLLM), qui dépend du traitement du reconnaissance visuelle par l'encodeur visuel. La complétude et la précision du reconnaissance visuelle ont un grand impact sur la logique spatiale, l'entendement détaillé et la précision d'autres tâches. Cependant, le MLLM n'a pas la capacité de réviser de manière sélective des zones spécifiques d'une image ou de se concentrer sur des informations liées à des catégories d'objets spécifiques. Dans cette étude, on propose le concept de token de reconnaissance visuelle et on cherche à assigner une structure permettant que le MLLM contrôle le traitement de la reconnaissance visuelle. Deux types de tokens de reconnaissance visuelle sont conçus : Token de sélection de régions et Token de réencodage visuel. Le MLLM génère ces tokens pour initier des actions supplémentaires de reconnaissance visuelle. Le Token de sélection de régions définit clairement une région de l'image et continue avec cette région. Le Token de réencodage visuel utilise son état caché comme signal de contrôle pour guider un traitement visuel supplémentaire. Les expériences prolongées montrent les avantages de ces tokens en termes de logique spatiale, d'entendement détaillé et d'autres tâches. En moyenne, l'introduction de ces tokens de reconnaissance visuelle améliore le rendement du modèle de 2B de 23,6%, augmentant les scores de 0,572 à 0,708, et dépasse de plus de 13,4% le rendement du modèle de 7B (de 0,624 à). Une vérification locale est requise. https://github.com/yu-rp/VisualPerceptionToken",
      "upvotes": 3,
      "discussionId": "67bddd64c7d8b835b82cee5a"
    },
    "publishedAt": "2025-02-26T02:37:36.287Z",
    "title": "Introducing Visual Perception Token into Multimodal Large Language Model",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.17425.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "635364b3c41f548fe39db945",
      "avatarUrl": "/avatars/ad1916bbfabca0b6651c8eabacc5eba8.svg",
      "fullname": "Runpeng Yu",
      "name": "rp-yu",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.17535",
      "authors": [
        {
          "_id": "67beaec94a1d9d7e368a7840",
          "user": {
            "_id": "66a4a319a1711696948b045c",
            "avatarUrl": "/avatars/1d92d57a949332cb8227697b9a0c2f39.svg",
            "isPro": false,
            "fullname": "Zhenheng Tang",
            "user": "coolzhtang",
            "type": "user"
          },
          "name": "Zhenheng Tang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T09:15:34.971Z",
          "hidden": false
        },
        {
          "_id": "67beaec94a1d9d7e368a7841",
          "name": "Xiang Liu",
          "hidden": false
        },
        {
          "_id": "67beaec94a1d9d7e368a7842",
          "name": "Qian Wang",
          "hidden": false
        },
        {
          "_id": "67beaec94a1d9d7e368a7843",
          "name": "Peijie Dong",
          "hidden": false
        },
        {
          "_id": "67beaec94a1d9d7e368a7844",
          "name": "Bingsheng He",
          "hidden": false
        },
        {
          "_id": "67beaec94a1d9d7e368a7845",
          "user": {
            "_id": "6676935fcd0b89a0115174b0",
            "avatarUrl": "/avatars/4caca1b672d29e787814f9a30bf20bcc.svg",
            "isPro": false,
            "fullname": "Xiaowen Chu",
            "user": "wenxinsiju",
            "type": "user"
          },
          "name": "Xiaowen Chu",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T09:15:41.884Z",
          "hidden": false
        },
        {
          "_id": "67beaec94a1d9d7e368a7846",
          "name": "Bo Li",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-24T15:39:35.000Z",
      "title": "La hypothèse de LLM Rotellieri, quelles compétences doivent être maintenues lors de la compression d'un LLM ?",
      "summary": "Le déclin des coûts de calcul et de stockage a conduit à ce que les modèles de LLMs (Modèles de Langue de Grande Taille) et la compression de la cache KV (Cache de Mots et Vecteurs) deviennent des objets d'attention pour les chercheurs. Cependant, les méthodes actuelles se heurtent principalement au défi de mesurer le rendement des modèles compressés de LLMs, en favorisant souvent la préservation de la précision simple. Ce blog propose une brève revue des derniers avancées dans la génération d'ensembles de recherche liés aux LLMs, la logique multiniveau, les outils externes et la représentation de calcul, qui peuvent considérablement améliorer leur rendement. Par la suite, une hypothèse sur l'existence de petits modèles de LLMs pour le langue latine est proposée, soutenue par la logique multiniveau et les outils externes. En se basant sur une revue du développement actuel des LLMs, les capacités basiques nécessaires pour les modèles de LLMs et la compression de la cache KV sont discutées, et il est expliqué ce qui a été laissé de côté par le droit actuel.",
      "upvotes": 3,
      "discussionId": "67beaeca4a1d9d7e368a7875"
    },
    "publishedAt": "2025-02-26T01:04:23.776Z",
    "title": "The Lottery LLM Hypothesis, Rethinking What Abilities Should LLM Compression Preserve?",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.17535.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "63024676056ec3a2a8714b24",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1661093436322-noauth.jpeg",
      "fullname": "Xiang Liu",
      "name": "Dominic789654",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 4
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.17092",
      "authors": [
        {
          "_id": "67bea8cc7e54112af6c372aa",
          "user": {
            "_id": "63d9e09f1cae35c27bf80cb2",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1675223055197-noauth.jpeg",
            "isPro": true,
            "fullname": "Syed Abdul Gaffar Shakhadri",
            "user": "SyedAbdul",
            "type": "user"
          },
          "name": "Syed Abdul Gaffar Shakhadri",
          "status": "extracted_confirmed",
          "statusLastChangedAt": "2025-02-26T05:52:19.355Z",
          "hidden": false
        },
        {
          "_id": "67bea8cc7e54112af6c372ab",
          "user": {
            "_id": "5fb7ae48e6ae537272bdeb3c",
            "avatarUrl": "/avatars/e5d01cb428f4b22161e0d17895a5c678.svg",
            "isPro": false,
            "fullname": "Kruthika",
            "user": "kruthika",
            "type": "user"
          },
          "name": "Kruthika KR",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-02-26T05:38:21.529Z",
          "hidden": false
        },
        {
          "_id": "67bea8cc7e54112af6c372ac",
          "user": {
            "_id": "677cc34fe4cf361eedccd085",
            "avatarUrl": "/avatars/e97a3f9a84ed258ab4b75c12865562d6.svg",
            "isPro": false,
            "fullname": "Kartik Basavaraj Angadi",
            "user": "KartikAngadi",
            "type": "user"
          },
          "name": "Kartik Basavaraj Angadi",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-02-26T05:38:21.529Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-24T12:15:07.000Z",
      "title": "Shakti-VLMs : Modèle de Vision-Langue Scalable pour l'IA de l'Entreprise",
      "summary": "Shakti VLM est une famille de modèles de logique de langage avec 1B et 4B paramètres. Ces modèles ont été conçus pour résoudre les problèmes d'efficacité des données lors de l'entraînement en plusieurs modes. Les VLMs récents atteignent de hauts rendements avec de grands ensembles de données d'entraînement, mais les modèles Shakti utilisent des innovations architecturales pour obtenir des résultats compétitifs avec peu de tokens. Les principaux points d'amélioration comprennent la QK-Normalization (stabilisation de l'attention), le méthode de normalisation hybride et l'amélioration du codage de position. Une stratégie d'entraînement en trois étapes améliore l'efficacité de l'apprentissage. Selon les résultats d'évaluation, Shakti-VLM-1B et Shakti-VLM-4B sont exceptionnels en compréhension de documents, logique visuelle, extraction OCR et logique générale multi-modal. Nos résultats montrent que des rendements élevés peuvent être atteints par le design et la stratégie d'entraînement du modèle, ce qui agit comme une solution efficace pour des tâches multi-modales d'échelle entreprise, non seulement par la taille des données.",
      "upvotes": 2,
      "discussionId": "67bea8cd7e54112af6c37305"
    },
    "publishedAt": "2025-02-26T00:38:42.527Z",
    "title": "Shakti-VLMs: Scalable Vision-Language Models for Enterprise AI",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.17092.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "63d9e09f1cae35c27bf80cb2",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1675223055197-noauth.jpeg",
      "fullname": "Syed Abdul Gaffar Shakhadri",
      "name": "SyedAbdul",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isMod": false,
      "followerCount": 6
    },
    "isAuthorParticipating": true
  }
]