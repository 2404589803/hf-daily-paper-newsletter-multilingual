[
  {
    "paper": {
      "id": "2506.01939",
      "authors": [
        {
          "_id": "683e7a6d97fd742a8edee1ba",
          "user": {
            "_id": "6486dde1f74857df3f1a5828",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6486dde1f74857df3f1a5828/FgE80CpalBO5qqArdfwxA.jpeg",
            "isPro": false,
            "fullname": "Shenzhi Wang",
            "user": "shenzhi-wang",
            "type": "user"
          },
          "name": "Shenzhi Wang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-03T08:41:16.481Z",
          "hidden": false
        },
        {
          "_id": "683e7a6d97fd742a8edee1bb",
          "name": "Le Yu",
          "hidden": false
        },
        {
          "_id": "683e7a6d97fd742a8edee1bc",
          "name": "Chang Gao",
          "hidden": false
        },
        {
          "_id": "683e7a6d97fd742a8edee1bd",
          "user": {
            "_id": "610b70452719facd4ea85e28",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/610b70452719facd4ea85e28/S7nMy7D0Rxq0VIVblhYDG.jpeg",
            "isPro": false,
            "fullname": "Chujie Zheng",
            "user": "chujiezheng",
            "type": "user"
          },
          "name": "Chujie Zheng",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-03T08:41:13.605Z",
          "hidden": false
        },
        {
          "_id": "683e7a6d97fd742a8edee1be",
          "name": "Shixuan Liu",
          "hidden": false
        },
        {
          "_id": "683e7a6d97fd742a8edee1bf",
          "name": "Rui Lu",
          "hidden": false
        },
        {
          "_id": "683e7a6d97fd742a8edee1c0",
          "name": "Kai Dang",
          "hidden": false
        },
        {
          "_id": "683e7a6d97fd742a8edee1c1",
          "user": {
            "_id": "63f30b870a16587ea970edfe",
            "avatarUrl": "/avatars/059491b33fecec69032e6d481229ee31.svg",
            "isPro": false,
            "fullname": "Xiong-Hui Chen",
            "user": "xionghuichen",
            "type": "user"
          },
          "name": "Xionghui Chen",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-03T08:41:10.358Z",
          "hidden": false
        },
        {
          "_id": "683e7a6d97fd742a8edee1c2",
          "name": "Jianxin Yang",
          "hidden": false
        },
        {
          "_id": "683e7a6d97fd742a8edee1c3",
          "user": {
            "_id": "64704e973601bb7b06643e98",
            "avatarUrl": "/avatars/52e51f4d1be6769e4397b8be2799cf32.svg",
            "isPro": false,
            "fullname": "Zhenru Zhang",
            "user": "Zhenru",
            "type": "user"
          },
          "name": "Zhenru Zhang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-06-03T09:40:21.027Z",
          "hidden": false
        },
        {
          "_id": "683e7a6d97fd742a8edee1c4",
          "user": {
            "_id": "666aacfb918ba11c7c598194",
            "avatarUrl": "/avatars/45bee8f1fdbdd256ee47d25e4bf01a7a.svg",
            "isPro": false,
            "fullname": "Yuqiong Liu",
            "user": "lyq333",
            "type": "user"
          },
          "name": "Yuqiong Liu",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-06-03T09:40:30.240Z",
          "hidden": false
        },
        {
          "_id": "683e7a6d97fd742a8edee1c5",
          "name": "An Yang",
          "hidden": false
        },
        {
          "_id": "683e7a6d97fd742a8edee1c6",
          "name": "Andrew Zhao",
          "hidden": false
        },
        {
          "_id": "683e7a6d97fd742a8edee1c7",
          "name": "Yang Yue",
          "hidden": false
        },
        {
          "_id": "683e7a6d97fd742a8edee1c8",
          "name": "Shiji Song",
          "hidden": false
        },
        {
          "_id": "683e7a6d97fd742a8edee1c9",
          "user": {
            "_id": "63d9d68c1cae35c27bf7a6a7",
            "avatarUrl": "/avatars/b5ad98cf269ae5f1fe90861fb4170fae.svg",
            "isPro": false,
            "fullname": "Bowen Yu",
            "user": "Tigerph",
            "type": "user"
          },
          "name": "Bowen Yu",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-06-03T04:30:38.648Z",
          "hidden": false
        },
        {
          "_id": "683e7a6d97fd742a8edee1ca",
          "name": "Gao Huang",
          "hidden": false
        },
        {
          "_id": "683e7a6d97fd742a8edee1cb",
          "user": {
            "_id": "620760a26e3b7210c2ff1943",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/620760a26e3b7210c2ff1943/VC-rKqimF6yxGESNVlPoR.jpeg",
            "isPro": false,
            "fullname": "Junyang Lin",
            "user": "JustinLin610",
            "type": "user"
          },
          "name": "Junyang Lin",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-06-03T09:39:54.278Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-06-02T17:54:39.000Z",
      "submittedOnDailyAt": "2025-06-03T03:09:30.655Z",
      "title": "Au-delà de la loi de 80/20 : les rares tokens d'entropie élevée poussent l'apprentissage de la logique efficace dans les LLMs.",
      "submittedOnDailyBy": {
        "_id": "6486dde1f74857df3f1a5828",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6486dde1f74857df3f1a5828/FgE80CpalBO5qqArdfwxA.jpeg",
        "isPro": false,
        "fullname": "Shenzhi Wang",
        "user": "shenzhi-wang",
        "type": "user"
      },
      "summary": "RLVR (Rewards with Verification) est un puissant méthode d'apprentissage par renforcement conçue pour améliorer la capacité logique de grands modèles de langage (LLMs), bien que sa structure soit encore mal compris. Dans cette étude, RLVR est examinée à partir d'une nouvelle perspective axée sur les mots d'entropie et leur impact sur la capacité logique. On analyse en détail le modèle d'entropie des mots dans la logique de la chaîne de pensée (Chain-of-Thought, CoT), et on constate que les mots d'entropie élevée sont très rares, et qu'ils sont des points de rupture cruciales qui conduisent à différentes voies logiques. De plus, grâce à l'étude de l'évolution des modèles d'entropie lors de l'entraînement de RLVR, on découvre que RLVR principalement suit les modèles d'entropie du modèle de base et que l'entropie des mots d'entropie élevée peut être ajustée. Ces résultats mettent en évidence l'importance des mots d'entropie élevée (c.-à-d., des mots de rupture) dans RLVR. Enfin, en limitant l'actualisation de la politique de gradient aux mots de rupture et en utilisant seulement 20% des mots pour atteindre un rendement significativement ou excessivement supérieur pour Qwen3-8B (AIME'25: +11.04, AIME'24: +7.71) et Qwen3-14B (AIME'25: +4.79, AIME'24: +5.21), on confirme que il est possible de dépasser considérablement le rendement du modèle de base. Ces résultats montrent que l'effet de RLVR repose sur l'optimisation des mots d'entropie élevée qui déterminent la direction logique, et qu'on peut comprendre RLVR à travers la perspective de l'entropie des mots, et que les capacités logiques des LLMs peuvent être développées en utilisant les rares mots d'entropie élevée.",
      "upvotes": 66,
      "discussionId": "683e7a6e97fd742a8edee227",
      "projectPage": "https://shenzhi-wang.github.io/high-entropy-minority-tokens-rlvr/",
      "ai_summary": "Token entropy patterns are crucial in RLVR, with high-entropy tokens significantly impacting reasoning performance and model optimization.",
      "ai_keywords": [
        "Reinforcement Learning with Verifiable Rewards",
        "RLVR",
        "Large Language Models",
        "LLMs",
        "token entropy patterns",
        "Chain-of-Thought",
        "CoT reasoning",
        "high-entropy tokens",
        "policy gradient updates",
        "Qwen3-8B",
        "Qwen3-32B",
        "Qwen3-14B",
        "AIME"
      ]
    },
    "publishedAt": "2025-06-02T13:54:39.000Z",
    "title": "Beyond the 80/20 Rule: High-Entropy Minority Tokens Drive Effective\n  Reinforcement Learning for LLM Reasoning",
    "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a\npowerful approach to enhancing the reasoning capabilities of Large Language\nModels (LLMs), while its mechanisms are not yet well understood. In this work,\nwe undertake a pioneering exploration of RLVR through the novel perspective of\ntoken entropy patterns, comprehensively analyzing how different tokens\ninfluence reasoning performance. By examining token entropy patterns in\nChain-of-Thought (CoT) reasoning, we observe that only a small fraction of\ntokens exhibit high entropy, and these tokens act as critical forks that steer\nthe model toward diverse reasoning pathways. Furthermore, studying how entropy\npatterns evolve during RLVR training reveals that RLVR largely adheres to the\nbase model's entropy patterns, primarily adjusting the entropy of high-entropy\ntokens. These findings highlight the significance of high-entropy tokens (i.e.,\nforking tokens) to RLVR. We ultimately improve RLVR by restricting policy\ngradient updates to forking tokens and uncover a finding even beyond the 80/20\nrule: utilizing only 20% of the tokens while maintaining performance comparable\nto full-gradient updates on the Qwen3-8B base model and significantly\nsurpassing full-gradient updates on the Qwen3-32B (+11.04 on AIME'25 and +7.71\non AIME'24) and Qwen3-14B (+4.79 on AIME'25 and +5.21 on AIME'24) base models,\nhighlighting a strong scaling trend. In contrast, training exclusively on the\n80% lowest-entropy tokens leads to a marked decline in performance. These\nfindings indicate that the efficacy of RLVR primarily arises from optimizing\nthe high-entropy tokens that decide reasoning directions. Collectively, our\nresults highlight the potential to understand RLVR through a token-entropy\nperspective and optimize RLVR by leveraging high-entropy minority tokens to\nfurther improve LLM reasoning.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.01939.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6486dde1f74857df3f1a5828",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6486dde1f74857df3f1a5828/FgE80CpalBO5qqArdfwxA.jpeg",
      "fullname": "Shenzhi Wang",
      "name": "shenzhi-wang",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 326
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2506.01049",
      "authors": [
        {
          "_id": "683e5b9a1167d9630159b27f",
          "user": {
            "_id": "640f7083208821a59b74c757",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1678735253848-640f7083208821a59b74c757.jpeg",
            "isPro": false,
            "fullname": "Siyuan Li",
            "user": "Lupin1998",
            "type": "user"
          },
          "name": "Siyuan Li",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-03T08:46:39.296Z",
          "hidden": false
        },
        {
          "_id": "683e5b9a1167d9630159b280",
          "user": {
            "_id": "670880950e79a8b46f7ff9dd",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/670880950e79a8b46f7ff9dd/hA1TLhwlQblkFsq8wLrkB.jpeg",
            "isPro": false,
            "fullname": "Juanxi Tian",
            "user": "Juanxi",
            "type": "user"
          },
          "name": "Juanxi Tian",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-06-03T09:40:52.165Z",
          "hidden": false
        },
        {
          "_id": "683e5b9a1167d9630159b281",
          "user": {
            "_id": "6594d390674349122ce6f368",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6594d390674349122ce6f368/KdWz6lZyGYQpjAgBDeiC1.jpeg",
            "isPro": false,
            "fullname": "Zedong Wang (Jacky)",
            "user": "ZedongWangAI",
            "type": "user"
          },
          "name": "Zedong Wang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-03T08:46:41.911Z",
          "hidden": false
        },
        {
          "_id": "683e5b9a1167d9630159b282",
          "name": "Xin Jin",
          "hidden": false
        },
        {
          "_id": "683e5b9a1167d9630159b283",
          "user": {
            "_id": "67ee7eef2a8e2fd1445407ab",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/TelMtjU8Ki8ulQU4-b0He.jpeg",
            "isPro": false,
            "fullname": "Zicheng Liu",
            "user": "MarcusB3n",
            "type": "user"
          },
          "name": "Zicheng Liu",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-06-03T09:41:29.426Z",
          "hidden": false
        },
        {
          "_id": "683e5b9a1167d9630159b284",
          "name": "Wentao Zhang",
          "hidden": false
        },
        {
          "_id": "683e5b9a1167d9630159b285",
          "user": {
            "_id": "67cd1d6c96e0a33b99c78b26",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/wsUk7e5BPHa6L7GroWtat.png",
            "isPro": false,
            "fullname": "Dan Xu",
            "user": "danxu",
            "type": "user"
          },
          "name": "Dan Xu",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-06-03T09:41:02.065Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-06-01T15:30:37.000Z",
      "submittedOnDailyAt": "2025-06-03T00:52:33.852Z",
      "title": "Accélération du taux d'apprentissage pour l'agrégation de gradients dans le contrôle de LLM d'érotique",
      "submittedOnDailyBy": {
        "_id": "6594d390674349122ce6f368",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6594d390674349122ce6f368/KdWz6lZyGYQpjAgBDeiC1.jpeg",
        "isPro": false,
        "fullname": "Zedong Wang (Jacky)",
        "user": "ZedongWangAI",
        "type": "user"
      },
      "summary": "L'entraînement de modèles de langage grands (LLMs) fait face à plusieurs problèmes liés à leur taille et à leur architecture. Des algorithmes d'optimisation adaptatifs comme AdamW peuvent résoudre des problèmes de gradient, mais évaluer de manière appropriée l'apprentissage pour chaque paramètre est difficile, ce qui génère une instabilité dans l'entraînement, une lenteur de convergence et une incompatibilité avec des méthodes de régularisation efficace (PEFT). Dans cet article, nous présentons une amélioration des apprentissages adaptatifs avec la Structure de Gradient de Groupes (SGG). La SGG utilise un groupe dynamique et échelonné par groupe pour regrouper les statistiques de gradient de chaque couche et ajuste l'apprentissage pour chaque paramètre. La SGG ne considère pas les restrictions du groupe entier, mais se concentre sur maintenir la réaction appropriée de chaque paramètre. Les expériences dans différents (M) marques de validation de LLMs montrent que la SGG s'intègre aux algorithmes d'optimisation actuels, démontrant un effet constant et rapide de convergence par rapport aux baselines, et peut être implémentée dans différents tailles de modèle. La SGG surpasse l'instabilité causée par les changements de taille de l'échantillon et de l'apprentissage, et se transforme en une option puissante pour l'optimisation de LLMs.",
      "upvotes": 22,
      "discussionId": "683e5b9b1167d9630159b2ef",
      "ai_summary": "SGG, an optimizer wrapper, enhances adaptive learning rates for large language models by grouping gradients and applying cluster-specific scaling, improving convergence and stability.",
      "ai_keywords": [
        "large language models",
        "adaptive optimizers",
        "AdamW",
        "parameter-wise learning rate estimation",
        "training instability",
        "parameter-efficient fine-tuning",
        "Scaling with Gradient Grouping",
        "gradient grouping",
        "cluster-specific scaling",
        "LLM benchmarks",
        "robust choice for LLM optimization"
      ]
    },
    "publishedAt": "2025-06-01T11:30:37.000Z",
    "title": "Taming LLMs by Scaling Learning Rates with Gradient Grouping",
    "summary": "Training large language models (LLMs) poses challenges due to their massive\nscale and heterogeneous architectures. While adaptive optimizers like AdamW\nhelp address gradient variations, they still struggle with efficient and\neffective parameter-wise learning rate estimation, resulting in training\ninstability, slow convergence, and poor compatibility with parameter-efficient\nfine-tuning (PEFT) techniques. This work introduces Scaling with Gradient\nGrouping (SGG), an optimizer wrapper that improves adaptive learning rate\nestimation by dynamic grouping and group-specific scaling. SGG first groups\ngradient statistics in each layer into clusters and then applies\ncluster-specific scaling to calibrate learning rates for each parameter, thus\nimposing collective group-wise constraints while maintaining precise\nper-parameter adaptation. Experiments on diverse (M)LLM benchmarks show that\nSGG integrates seamlessly with existing optimizers, and offers consistent gains\nand faster convergence over baselines, with various model sizes. Its stability\nacross varying batch sizes and learning rates establishes SGG as a robust\nchoice for LLM optimization.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.01049.png",
    "numComments": 3,
    "submittedBy": {
      "_id": "6594d390674349122ce6f368",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6594d390674349122ce6f368/KdWz6lZyGYQpjAgBDeiC1.jpeg",
      "fullname": "Zedong Wang (Jacky)",
      "name": "ZedongWangAI",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.23590",
      "authors": [
        {
          "_id": "683e6b2d97fd742a8edb8a8e",
          "user": {
            "_id": "64f5c7cb65a4b1acb20ffc15",
            "avatarUrl": "/avatars/67c42a6e26bbeddc4bf706eb8f1a75b1.svg",
            "isPro": false,
            "fullname": "Zifu Wang",
            "user": "wangzifu",
            "type": "user"
          },
          "name": "Zifu Wang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-06-03T09:41:52.137Z",
          "hidden": false
        },
        {
          "_id": "683e6b2d97fd742a8edb8a8f",
          "user": {
            "_id": "6477b2038ab7e732b6d8a9b5",
            "avatarUrl": "/avatars/c859a35b8965a904f103bbc34f36ab2a.svg",
            "isPro": false,
            "fullname": "Junyi Zhu",
            "user": "RyanZhu",
            "type": "user"
          },
          "name": "Junyi Zhu",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-06-03T09:42:00.703Z",
          "hidden": false
        },
        {
          "_id": "683e6b2d97fd742a8edb8a90",
          "name": "Bo Tang",
          "hidden": false
        },
        {
          "_id": "683e6b2d97fd742a8edb8a91",
          "name": "Zhiyu Li",
          "hidden": false
        },
        {
          "_id": "683e6b2d97fd742a8edb8a92",
          "name": "Feiyu Xiong",
          "hidden": false
        },
        {
          "_id": "683e6b2d97fd742a8edb8a93",
          "name": "Jiaqian Yu",
          "hidden": false
        },
        {
          "_id": "683e6b2d97fd742a8edb8a94",
          "name": "Matthew B. Blaschko",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-29T16:01:22.000Z",
      "submittedOnDailyAt": "2025-06-03T01:56:17.990Z",
      "title": "Jigsaw-R1 : Recherche sur l'apprentissage de la visualisation basée sur des règles à l'aide de puzzles de Jigsaw",
      "submittedOnDailyBy": {
        "_id": "64f5c7cb65a4b1acb20ffc15",
        "avatarUrl": "/avatars/67c42a6e26bbeddc4bf706eb8f1a75b1.svg",
        "isPro": false,
        "fullname": "Zifu Wang",
        "user": "wangzifu",
        "type": "user"
      },
      "summary": "L'application de l'apprentissage par référence basé sur les règles (RL) à des modèles de langage multilingues (MLLMs) a exploré la possibilité de spécifier des méthodes de recherche et des caractéristiques dans des domaines où seuls existent des documents. En particulier, des défis visuels ont été rencontrés. Cet article utilise une étude structurée avec un puzzle de chameau pour mener une recherche concrète sur le RL. Le puzzle de chameau a été sélectionné parce qu'il nécessite des réponses internes, l'ajustement de la difficulté et des jugements complexes, ce qui le rend idéal pour cette étude. Dans ce travail, les auteurs ont découvert les points suivants :\n\n1. Les MLLMs montrent un rendement similaire à la prédiction aléatoire dans les puzzles les plus simples, mais atteignent une précision presque complète à la fin de l'entraînement et peuvent généraliser à de nouvelles configurations complexes.\n2. L'apprentissage dans les puzzles de chameau peut être généralisé à d'autres tâches visuelles, et cet effet peut varier selon la configuration de la tâche.\n3. Les MLLMs apprennent avec des raisons explicites et peuvent généraliser, mais de nombreux modèles ouverts préfèrent des réponses directes. Par conséquent, lorsqu'ils apprennent des raisons en étapes, ils peuvent ignorer les raisons à la fin de la réponse.\n4. Des patrons de raisons complexes sont communs et leur fréquence augmente avec le niveau d'entraînement et la difficulté de la tâche.\n5. Enfin, le RL montre une généralisation plus efficace que la rétro-alimentation de sous-vidéo (SFT) dans les tâches visuelles, et le début de l'SFT peut affecter l'optimisation subséquente du RL.\n\nCes résultats, basés sur des puzzles de chameau, peuvent donner des résultats différents dans d'autres tâches visuelles, mais contribuent à la compréhension du RL et à la possibilité d'entraînement de multiples modèles. Le code est disponible sur https://github.com/zifuwanggg/Jigsaw-R1.",
      "upvotes": 20,
      "discussionId": "683e6b2e97fd742a8edb8ac1",
      "githubRepo": "https://github.com/zifuwanggg/Jigsaw-R1",
      "ai_summary": "Rule-based reinforcement learning applied to multimodal large language models demonstrates effective generalization in visual tasks, particularly using jigsaw puzzles, outperforming supervised fine-tuning.",
      "ai_keywords": [
        "rule-based reinforcement learning",
        "multimodal large language models",
        "visual RL",
        "jigsaw puzzles",
        "fine-tuning",
        "supervised fine-tuning",
        "complex decision-making",
        "visual tasks",
        "step-by-step reasoning",
        "generalization"
      ]
    },
    "publishedAt": "2025-05-29T12:01:22.000Z",
    "title": "Jigsaw-R1: A Study of Rule-based Visual Reinforcement Learning with\n  Jigsaw Puzzles",
    "summary": "The application of rule-based reinforcement learning (RL) to multimodal large\nlanguage models (MLLMs) introduces unique challenges and potential deviations\nfrom findings in text-only domains, particularly for perception-heavy tasks.\nThis paper provides a comprehensive study of rule-based visual RL, using jigsaw\npuzzles as a structured experimental framework. Jigsaw puzzles offer inherent\nground truth, adjustable difficulty, and demand complex decision-making, making\nthem ideal for this study. Our research reveals several key findings:\nFirstly, we find that MLLMs, initially performing near to random\nguessing on the simplest jigsaw puzzles, achieve near-perfect accuracy and\ngeneralize to complex, unseen configurations through fine-tuning.\nSecondly, training on jigsaw puzzles can induce generalization to\nother visual tasks, with effectiveness tied to specific task configurations.\nThirdly, MLLMs can learn and generalize with or without explicit\nreasoning, though open-source models often favor direct answering.\nConsequently, even when trained for step-by-step reasoning, they can ignore the\nthinking process in deriving the final answer. Fourthly, we observe\nthat complex reasoning patterns appear to be pre-existing rather than emergent,\nwith their frequency increasing alongside training and task difficulty.\nFinally, our results demonstrate that RL exhibits more effective\ngeneralization than Supervised Fine-Tuning (SFT), and an initial SFT cold start\nphase can hinder subsequent RL optimization. Although these observations are\nbased on jigsaw puzzles and may vary across other visual tasks, this research\ncontributes a valuable piece of jigsaw to the larger puzzle of collective\nunderstanding rule-based visual RL and its potential in multimodal learning.\nThe code is available at: https://github.com/zifuwanggg/Jigsaw-R1.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.23590.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64f5c7cb65a4b1acb20ffc15",
      "avatarUrl": "/avatars/67c42a6e26bbeddc4bf706eb8f1a75b1.svg",
      "fullname": "Zifu Wang",
      "name": "wangzifu",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2506.00539",
      "authors": [
        {
          "_id": "683e76c17a0996f979e72700",
          "user": {
            "_id": "671a4abbef737c0abe21b3f8",
            "avatarUrl": "/avatars/da826af5472a3b9f1969f0c766672731.svg",
            "isPro": false,
            "fullname": "Ruihan Yang",
            "user": "rhyang2021",
            "type": "user"
          },
          "name": "Ruihan Yang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-03T08:41:32.053Z",
          "hidden": false
        },
        {
          "_id": "683e76c17a0996f979e72701",
          "name": "Yikai Zhang",
          "hidden": false
        },
        {
          "_id": "683e76c17a0996f979e72702",
          "user": {
            "_id": "63f86b099f87cc3e645b51d9",
            "avatarUrl": "/avatars/27ca5ba425640bf67474cee871e8e53a.svg",
            "isPro": false,
            "fullname": "Ellie Chen",
            "user": "sheep33333",
            "type": "user"
          },
          "name": "Aili Chen",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-03T08:41:28.422Z",
          "hidden": false
        },
        {
          "_id": "683e76c17a0996f979e72703",
          "name": "Xintao Wang",
          "hidden": false
        },
        {
          "_id": "683e76c17a0996f979e72704",
          "name": "Siyu Yuan",
          "hidden": false
        },
        {
          "_id": "683e76c17a0996f979e72705",
          "name": "Jiangjie Chen",
          "hidden": false
        },
        {
          "_id": "683e76c17a0996f979e72706",
          "name": "Deqing Yang",
          "hidden": false
        },
        {
          "_id": "683e76c17a0996f979e72707",
          "name": "Yanghua Xiao",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-31T12:54:49.000Z",
      "submittedOnDailyAt": "2025-06-03T02:50:22.439Z",
      "title": "ARIA : Formation du vocabulaire du langage ARIA pour centrer la récompense selon l'objectif",
      "submittedOnDailyBy": {
        "_id": "671a4abbef737c0abe21b3f8",
        "avatarUrl": "/avatars/da826af5472a3b9f1969f0c766672731.svg",
        "isPro": false,
        "fullname": "Ruihan Yang",
        "user": "rhyang2021",
        "type": "user"
      },
      "summary": "Les modèles de langage ouverts (LLMs) peuvent formuler des théories complexes et prendre des décisions dans des environnements d'actions de langage ouverts qui représentent la distribution des combinaisons de mots, où l'espace d'actions est exponentiellement grand. Cependant, dans des environnements d'actions ouverts comme le dialogue ou les jeux de questions, l'espace d'actions devient exponentiellement grand lorsqu'il représente la distribution des combinaisons de mots. Dans ces espaces, l'échantillonnage d'actions conduit à une extrême rarité des récompenses, ce qui augmente la variance de la récompense et rend l'apprentissage par renforcement (RL) efficace plus difficile. Dans ce sens, nous proposons un méthode pour concentrer la récompense. Cette méthode permet d'entraîner des sorties de langage efficaces et efficaces. ARIA projette des actions naturelles de mots de haute dimensionnalité dans un espace d'intentions de faible dimensionnalité, regroupe des actions semantiquement similaires et attribue des récompenses partagées. La concentration de la récompense dans les intentions réduit la variance de la récompense et améliore l'optimisation des politiques, favorisant un meilleur apprentissage. Les tests rigoureux montrent que ARIA améliore en moyenne de 9,95% sur quatre tâches, et coïncide avec les lignes de RL en ligne et hors ligne, démontrant son excellence.",
      "upvotes": 19,
      "discussionId": "683e76ca7a0996f979e728e0",
      "projectPage": "https://aria-agent.github.io/",
      "githubRepo": "https://github.com/rhyang2021/ARIA",
      "ai_summary": "ARIA aggregates rewards in an intention space to mitigate reward sparsity and improve policy optimization in language-based reinforcement learning tasks.",
      "ai_keywords": [
        "large language models",
        "reinforcement learning",
        "action space",
        "token distribution",
        "extreme reward sparsity",
        "reward variance",
        "policy optimization",
        "intention space",
        "semantically similar actions",
        "shared rewards",
        "policy gradient variance",
        "performance gains",
        "offline RL",
        "online RL"
      ]
    },
    "publishedAt": "2025-05-31T08:54:49.000Z",
    "title": "ARIA: Training Language Agents with Intention-Driven Reward Aggregation",
    "summary": "Large language models (LLMs) have enabled agents to perform complex reasoning\nand decision-making through free-form language interactions. However, in\nopen-ended language action environments (e.g., negotiation or question-asking\ngames), the action space can be formulated as a joint distribution over tokens,\nresulting in an exponentially large action space. Sampling actions in such a\nspace can lead to extreme reward sparsity, which brings large reward variance,\nhindering effective reinforcement learning (RL). To address this, we propose\nARIA, a method that Aggregates Rewards in Intention space to enable efficient\nand effective language Agents training. ARIA aims to project natural language\nactions from the high-dimensional joint token distribution space into a\nlow-dimensional intention space, where semantically similar actions are\nclustered and assigned shared rewards. This intention-aware reward aggregation\nreduces reward variance by densifying reward signals, fostering better policy\noptimization. Extensive experiments demonstrate that ARIA not only\nsignificantly reduces policy gradient variance, but also delivers substantial\nperformance gains of an average of 9.95% across four downstream tasks,\nconsistently outperforming offline and online RL baselines.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.00539.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "671a4abbef737c0abe21b3f8",
      "avatarUrl": "/avatars/da826af5472a3b9f1969f0c766672731.svg",
      "fullname": "Ruihan Yang",
      "name": "rhyang2021",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 4
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2506.00411",
      "authors": [
        {
          "_id": "683e86e31bca54bb6d169fc4",
          "user": {
            "_id": "6707eaaf5f50b17754ff9cbc",
            "avatarUrl": "/avatars/f08ca6228b124a8955787d0662a52bbd.svg",
            "isPro": false,
            "fullname": "Yang",
            "user": "Yysrc",
            "type": "user"
          },
          "name": "Yi Yang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-03T08:40:09.713Z",
          "hidden": false
        },
        {
          "_id": "683e86e31bca54bb6d169fc5",
          "name": "Jiaxuan Sun",
          "hidden": false
        },
        {
          "_id": "683e86e31bca54bb6d169fc6",
          "name": "Siqi Kou",
          "hidden": false
        },
        {
          "_id": "683e86e31bca54bb6d169fc7",
          "name": "Yihan Wang",
          "hidden": false
        },
        {
          "_id": "683e86e31bca54bb6d169fc8",
          "name": "Zhijie Deng",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-31T06:01:03.000Z",
      "submittedOnDailyAt": "2025-06-03T03:54:29.259Z",
      "title": "LoHoVLA : Modèle de Langue Vision et Actions à Long Terme",
      "submittedOnDailyBy": {
        "_id": "654e330f350abceb30a1390b",
        "avatarUrl": "/avatars/e54a8be788fa1bdc7acefecc208215bb.svg",
        "isPro": false,
        "fullname": "KouSiqi",
        "user": "karrykkk",
        "type": "user"
      },
      "summary": "Le modèle de visualisation de la réalité dans l'IA est confronté à des tâches à long terme qui exigent des solutions multiniveaux avec des niveaux de buts élevés. Pour réaliser ces tâches avec succès, il est nécessaire d'avoir à la fois un haut niveau de planification de tâches (c'est-à-dire, diviser les objectifs en étapes) et un haut niveau de contrôle d'actions (c'est-à-dire, générer des mouvements du robot avec précision). Les deux niveaux sont nécessaires et doivent fonctionner de manière coordonnée. Actuellement, les modèles de langage de vision et d'action (VLA) et leurs structures hiérarchiques offrent des potentiels pour des tâches visuelles, mais le premier modèle a des difficultés dans la planification et le second dans les problèmes de collaboration, ce qui empêche d'améliorer le rendement.\n\nNous présentons un nouveau cadre intégré pour des tâches à long terme, appelé LoHoVLA (Long-Horizon Vision Language Action). LoHoVLA utilise un modèle de langage de vision et d'action préalablement entraîné à grande échelle comme base et génère des tokens de langage et d'action pour la génération de tâches et de prédictions d'actions du robot dans des étapes. Cette représentation partagée favorise une meilleure généralisation entre tâches. De plus, LoHoVLA introduit une structure de contrôle de rétroaction pour réduire les erreurs dans la planification haute et le contrôle basse. Pour l'entraînement de LoHoVLA, nous introduisons le jeu de données LoHoSet basé sur le simulateur Ravens, qui comprend 20 tâches à long terme et 1 000 démonstrations d'experts, avec des observations visuelles, des objectifs linguistiques, des tâches en étapes et des actions du robot. Les résultats des expériences montrent que LoHoVLA dépasse significativement les approximations hiérarchiques et standards de VLA dans des tâches visuelles à long terme, ce qui met en avant la possibilité d'un cadre intégré pour le développement d'une intelligence visuelle large.",
      "upvotes": 19,
      "discussionId": "683e86e31bca54bb6d169ff5",
      "ai_summary": "A unified vision language action framework, LoHoVLA, combines a large pretrained vision language model with hierarchical closed-loop control to improve performance on long-horizon embodied tasks.",
      "ai_keywords": [
        "vision language action models",
        "hierarchical architectures",
        "high-level task planning",
        "low-level motion control",
        "LoHoVLA",
        "large pretrained vision language model",
        "shared representation",
        "hierarchical closed-loop control",
        "LoHoSet",
        "Ravens simulator",
        "long-horizon tasks",
        "sub-task generation",
        "robot action prediction",
        "embodied intelligence"
      ]
    },
    "publishedAt": "2025-05-31T02:01:03.000Z",
    "title": "LoHoVLA: A Unified Vision-Language-Action Model for Long-Horizon\n  Embodied Tasks",
    "summary": "Real-world embodied agents face long-horizon tasks, characterized by\nhigh-level goals demanding multi-step solutions beyond single actions.\nSuccessfully navigating these requires both high-level task planning (i.e.,\ndecomposing goals into sub-tasks) and low-level motion control (i.e.,\ngenerating precise robot actions). While existing vision language action (VLA)\nmodels and hierarchical architectures offer potential in embodied tasks, the\nformer often falter in planning, and the latter can suffer from coordination\nissues, both hampering performance. We introduce a new unified VLA framework\nfor long-horizon tasks, dubbed LoHoVLA, to overcome these limitations. LoHoVLA\nleverages a large pretrained vision language model (VLM) as the backbone to\njointly generate language and action tokens for sub-task generation and robot\naction prediction, respectively. This shared representation promotes better\ngeneralization across tasks. Additionally, LoHoVLA embraces a hierarchical\nclosed-loop control mechanism to mitigate errors originating from both\nhigh-level planning and low-level control. To train LoHoVLA, we introduce\nLoHoSet, a dataset built on the Ravens simulator, containing 20 long-horizon\ntasks, each with 1,000 expert demonstrations composed of visual observations,\nlinguistic goals, sub-tasks, and robot actions. Experimental results show that\nLoHoVLA significantly surpasses both hierarchical and standard VLA approaches\non long-horizon embodied tasks in the Ravens simulator. These findings\nunderscore the promise of unified architectures for advancing generalizable\nembodied intelligence.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.00411.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "654e330f350abceb30a1390b",
      "avatarUrl": "/avatars/e54a8be788fa1bdc7acefecc208215bb.svg",
      "fullname": "KouSiqi",
      "name": "karrykkk",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 4
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2506.01844",
      "authors": [
        {
          "_id": "683eb85825fcc99d2a7fc26d",
          "user": {
            "_id": "62bdeedd01dc22b4d22a371e",
            "avatarUrl": "/avatars/6adc904fb1e08661d293a966270afabb.svg",
            "isPro": false,
            "fullname": "Mustafa Shukor",
            "user": "mshukor",
            "type": "user"
          },
          "name": "Mustafa Shukor",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-06-03T09:11:09.058Z",
          "hidden": false
        },
        {
          "_id": "683eb85825fcc99d2a7fc26e",
          "user": {
            "_id": "640e21ef3c82bd463ee5a76d",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/640e21ef3c82bd463ee5a76d/nVR1DFPAsiLw6Boys28Rb.jpeg",
            "isPro": false,
            "fullname": "Dana Aubakirova",
            "user": "danaaubakirova",
            "type": "user"
          },
          "name": "Dana Aubakirova",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-06-03T09:11:18.586Z",
          "hidden": false
        },
        {
          "_id": "683eb85825fcc99d2a7fc26f",
          "user": {
            "_id": "63d67eac6f49aa8230601996",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63d67eac6f49aa8230601996/djvtWdy718whUgh7tu1Ko.jpeg",
            "isPro": false,
            "fullname": "Francesco Capuano",
            "user": "fracapuano",
            "type": "user"
          },
          "name": "Francesco Capuano",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-06-03T09:11:29.639Z",
          "hidden": false
        },
        {
          "_id": "683eb85825fcc99d2a7fc270",
          "user": {
            "_id": "65f9d37113336392bad1e49c",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65f9d37113336392bad1e49c/B0Fxwconnu7lvtjBz4Ruq.jpeg",
            "isPro": false,
            "fullname": "Pepijn Kooijmans",
            "user": "pepijn223",
            "type": "user"
          },
          "name": "Pepijn Kooijmans",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-06-03T09:11:38.693Z",
          "hidden": false
        },
        {
          "_id": "683eb85825fcc99d2a7fc271",
          "user": {
            "_id": "67b124b081d4eae18b957606",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/CXvSv2l15uPkMQL_HBRDF.png",
            "isPro": false,
            "fullname": "Steven Palma",
            "user": "imstevenpmwork",
            "type": "user"
          },
          "name": "Steven Palma",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-06-03T09:11:47.379Z",
          "hidden": false
        },
        {
          "_id": "683eb85825fcc99d2a7fc272",
          "user": {
            "_id": "64c255b2254239173af0570a",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64c255b2254239173af0570a/JvYNX4gpk0hVQJeJif8Mo.jpeg",
            "isPro": false,
            "fullname": "Adil Zouitine",
            "user": "AdilZtn",
            "type": "user"
          },
          "name": "Adil Zouitine",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-06-03T09:11:56.957Z",
          "hidden": false
        },
        {
          "_id": "683eb85825fcc99d2a7fc273",
          "user": {
            "_id": "668bd06dd58b51a628566d80",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/668bd06dd58b51a628566d80/II7Yr5dT5ItMrpoMkQEy3.jpeg",
            "isPro": false,
            "fullname": "Michel Aractingi",
            "user": "aractingi",
            "type": "user"
          },
          "name": "Michel Aractingi",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-06-03T09:12:05.798Z",
          "hidden": false
        },
        {
          "_id": "683eb85825fcc99d2a7fc274",
          "user": {
            "_id": "67d7dea1786ddcb3af5a44b3",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/67d7dea1786ddcb3af5a44b3/gEgXTH4oO91GIzjHR-yrb.png",
            "isPro": false,
            "fullname": "Caroline Pascal",
            "user": "CarolinePascal",
            "type": "user"
          },
          "name": "Caroline Pascal",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-06-03T09:12:15.340Z",
          "hidden": false
        },
        {
          "_id": "683eb85825fcc99d2a7fc275",
          "user": {
            "_id": "631365ad289cf15634c6f600",
            "avatarUrl": "/avatars/a464d228328719274a20121e2a82f703.svg",
            "isPro": false,
            "fullname": "Martino Russi",
            "user": "nepyope",
            "type": "user"
          },
          "name": "Martino Russi",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-06-03T09:12:23.474Z",
          "hidden": false
        },
        {
          "_id": "683eb85825fcc99d2a7fc276",
          "user": {
            "_id": "65d66b494bbd0d92b641cdbb",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65d66b494bbd0d92b641cdbb/6-7dm7B-JxcoS1QlCPdMN.jpeg",
            "isPro": false,
            "fullname": "Andres Marafioti",
            "user": "andito",
            "type": "user"
          },
          "name": "Andres Marafioti",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-06-03T09:12:31.740Z",
          "hidden": false
        },
        {
          "_id": "683eb85825fcc99d2a7fc277",
          "user": {
            "_id": "65fcb7f133a3d6f126772121",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65fcb7f133a3d6f126772121/BvVbNqnlQgDr2f_9dm5Es.jpeg",
            "isPro": false,
            "fullname": "Simon  Alibert",
            "user": "aliberts",
            "type": "user"
          },
          "name": "Simon Alibert",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-06-03T09:12:39.999Z",
          "hidden": false
        },
        {
          "_id": "683eb85825fcc99d2a7fc278",
          "name": "Matthieu Cord",
          "hidden": false
        },
        {
          "_id": "683eb85825fcc99d2a7fc279",
          "user": {
            "_id": "5df7e9e5da6d0311fd3d53f9",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1583857746553-5df7e9e5da6d0311fd3d53f9.jpeg",
            "isPro": false,
            "fullname": "Thomas Wolf",
            "user": "thomwolf",
            "type": "user"
          },
          "name": "Thomas Wolf",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-06-03T09:13:02.139Z",
          "hidden": false
        },
        {
          "_id": "683eb85825fcc99d2a7fc27a",
          "user": {
            "_id": "62f857fbb9fda55613ce80d9",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62f857fbb9fda55613ce80d9/d7bRniKLmOt-iFN07k1Su.png",
            "isPro": false,
            "fullname": "Remi Cadene",
            "user": "cadene",
            "type": "user"
          },
          "name": "Remi Cadene",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-06-03T09:13:11.882Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-06-02T16:30:19.000Z",
      "submittedOnDailyAt": "2025-06-03T07:31:41.152Z",
      "title": "SmolVLA : Modèle de Vision, Langue et Action pour l'Ingénierie de Robotique Économique et Efficace",
      "submittedOnDailyBy": {
        "_id": "65d66b494bbd0d92b641cdbb",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65d66b494bbd0d92b641cdbb/6-7dm7B-JxcoS1QlCPdMN.jpeg",
        "isPro": false,
        "fullname": "Andres Marafioti",
        "user": "andito",
        "type": "user"
      },
      "summary": "Les modèles de langue visuelle (VLMs) sont entraînés avec de grands ensembles de données de multiples types pour enregistrer un riche savoir visuel et linguistique, formant une base solide pour les systèmes de robotique. Une approche récente pour programmer les politiques de robots est de convertir ces modèles en modèles d'action visuel-linguistique (VLA) de manière plus naturelle. Cependant, actuellement, les VLA généralement ont des centaines de milliards de paramètres, associés à des coûts élevés d'entraînement et une fonctionnalité dans le monde réel. De plus, les ensembles de données se concentrent sur l'académie et l'industrie, ignorant le développement des données communautaires de plateformes de robots à faible coût. Dans cette étude, nous présentons SmolVLA, un modèle d'action visuel-linguistique petit et efficace basé sur la communauté, qui réduit significativement les coûts d'entraînement et d'inférence, maintenant une performance compétitive. SmolVLA est entraîné sur une seule GPU et est conçu pour fonctionner avec des GPUs de consommation ou des CPUs. De plus, nous introduisons une pile d'inférence asynchrone pour améliorer la réponse et sépare la prédiction d'action visuelle de l'exécution d'actions pour générer des actions courtes, atteignant une haute vitesse de contrôle. Malgré son petit taille, SmolVLA atteint la même performance qu'un VLA beaucoup plus grand. SmolVLA a été évalué sur plusieurs benchmarks de simulation et de robots dans le monde réel, et tous les codes, modèles pré-entraînés et données d'entraînement sont disponibles.",
      "upvotes": 17,
      "discussionId": "683eb85925fcc99d2a7fc2dc",
      "ai_summary": "SmolVLA is a compact, efficient vision-language-action model that achieves competitive performance at reduced computational costs and can be deployed on consumer-grade hardware.",
      "ai_keywords": [
        "vision-language models",
        "multimodal datasets",
        "robotic policies",
        "vision-language-action models",
        "natural language-driven perception",
        "asynchronous inference",
        "action prediction",
        "action execution",
        "chunked action generation",
        "performance benchmarks"
      ]
    },
    "publishedAt": "2025-06-02T12:30:19.000Z",
    "title": "SmolVLA: A Vision-Language-Action Model for Affordable and Efficient\n  Robotics",
    "summary": "Vision-language models (VLMs) pretrained on large-scale multimodal datasets\nencode rich visual and linguistic knowledge, making them a strong foundation\nfor robotics. Rather than training robotic policies from scratch, recent\napproaches adapt VLMs into vision-language-action (VLA) models that enable\nnatural language-driven perception and control. However, existing VLAs are\ntypically massive--often with billions of parameters--leading to high training\ncosts and limited real-world deployability. Moreover, they rely on academic and\nindustrial datasets, overlooking the growing availability of\ncommunity-collected data from affordable robotic platforms. In this work, we\npresent SmolVLA, a small, efficient, and community-driven VLA that drastically\nreduces both training and inference costs, while retaining competitive\nperformance. SmolVLA is designed to be trained on a single GPU and deployed on\nconsumer-grade GPUs or even CPUs. To further improve responsiveness, we\nintroduce an asynchronous inference stack decoupling perception and action\nprediction from action execution, allowing higher control rates with chunked\naction generation. Despite its compact size, SmolVLA achieves performance\ncomparable to VLAs that are 10x larger. We evaluate SmolVLA on a range of both\nsimulated as well as real-world robotic benchmarks and release all code,\npretrained models, and training data.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.01844.png",
    "numComments": 3,
    "submittedBy": {
      "_id": "65d66b494bbd0d92b641cdbb",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65d66b494bbd0d92b641cdbb/6-7dm7B-JxcoS1QlCPdMN.jpeg",
      "fullname": "Andres Marafioti",
      "name": "andito",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 185
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2506.01943",
      "authors": [
        {
          "_id": "683e6b6424742a21489ec9f8",
          "name": "Xiao Fu",
          "hidden": false
        },
        {
          "_id": "683e6b6424742a21489ec9f9",
          "name": "Xintao Wang",
          "hidden": false
        },
        {
          "_id": "683e6b6424742a21489ec9fa",
          "name": "Xian Liu",
          "hidden": false
        },
        {
          "_id": "683e6b6424742a21489ec9fb",
          "name": "Jianhong Bai",
          "hidden": false
        },
        {
          "_id": "683e6b6424742a21489ec9fc",
          "name": "Runsen Xu",
          "hidden": false
        },
        {
          "_id": "683e6b6424742a21489ec9fd",
          "name": "Pengfei Wan",
          "hidden": false
        },
        {
          "_id": "683e6b6424742a21489ec9fe",
          "name": "Di Zhang",
          "hidden": false
        },
        {
          "_id": "683e6b6424742a21489ec9ff",
          "name": "Dahua Lin",
          "hidden": false
        }
      ],
      "mediaUrls": [
        "https://cdn-uploads.huggingface.co/production/uploads/63aef2cafcca84593e6682db/9mFDJaCOc6KLHlhboYA59.mp4"
      ],
      "publishedAt": "2025-06-02T17:57:06.000Z",
      "submittedOnDailyAt": "2025-06-03T01:57:30.514Z",
      "title": "Contrôle de la trajectoire coopérative de manipulation de robots par apprentissage par vision",
      "submittedOnDailyBy": {
        "_id": "63aef2cafcca84593e6682db",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1672409763337-noauth.jpeg",
        "isPro": false,
        "fullname": "Xiao Fu",
        "user": "lemonaddie",
        "type": "user"
      },
      "summary": "Le développement récent des modèles de diffusion d'images a montré un potentiel puissant pour la génération de données de décision de robots. Les conditions de projet permettent un contrôle plus précis. Cependant, les méthodes actuelles basées sur le projet se concentrent principalement sur le mouvement individuel d'objets et ne comprennent pas l'interaction multi-objet nécessaire pour gérer des tâches complexes de robots. Cette limitation est due à la combinaison de caractéristiques dans des zones répétées. Pour résoudre ce problème, nous présentons RoboMaster. RoboMaster modélise la dynamique entre les objets par des projets coopératifs. En contraste avec les méthodes existantes, RoboMaster ne sépare pas les objets mais divise le processus d'interaction en trois étapes : avant, pendant et après l'interaction. Chaque étape est modélisée en utilisant les caractéristiques de l'objet principal. Dans les étapes avant et après l'interaction, les mains du robot sont utilisées, tandis que lors de l'interaction, les objets de manipulation sont utilisés comme caractéristiques. De cette manière, les défis de fusion de caractéristiques multi-objets observés dans des recherches précédentes sont réduits. De plus, il inclut une représentation potentielle de l'apparence et de la forme des objets pour garantir la cohérence significative du thème tout au long de la vidéo. A travers des expériences détaillées sur le jeu de données Bridge V2 et l'évaluation des états naturels, notre méthode dépasse les méthodes existantes et explore un nouveau rendement supérieur dans la génération de vidéos de contrôle de projet pour la manipulation de robots.",
      "upvotes": 15,
      "discussionId": "683e6b6724742a21489eca8d",
      "ai_summary": "A novel framework, RoboMaster, enhances trajectory-controlled video generation for robotic manipulation by modeling inter-object dynamics through a collaborative trajectory formulation, achieving state-of-the-art performance on the Bridge V2 dataset.",
      "ai_keywords": [
        "video diffusion models",
        "trajectory conditions",
        "multi-object interaction",
        "multi-feature entanglement",
        "visual fidelity",
        "collaborative trajectory formulation",
        "pre-interaction",
        "interaction",
        "post-interaction",
        "appearance-aware latent representations",
        "shape-aware latent representations",
        "trajectory-controlled video generation",
        "robotic manipulation",
        "Bridge V2 dataset"
      ]
    },
    "publishedAt": "2025-06-02T13:57:06.000Z",
    "title": "Learning Video Generation for Robotic Manipulation with Collaborative\n  Trajectory Control",
    "summary": "Recent advances in video diffusion models have demonstrated strong potential\nfor generating robotic decision-making data, with trajectory conditions further\nenabling fine-grained control. However, existing trajectory-based methods\nprimarily focus on individual object motion and struggle to capture\nmulti-object interaction crucial in complex robotic manipulation. This\nlimitation arises from multi-feature entanglement in overlapping regions, which\nleads to degraded visual fidelity. To address this, we present RoboMaster, a\nnovel framework that models inter-object dynamics through a collaborative\ntrajectory formulation. Unlike prior methods that decompose objects, our core\nis to decompose the interaction process into three sub-stages: pre-interaction,\ninteraction, and post-interaction. Each stage is modeled using the feature of\nthe dominant object, specifically the robotic arm in the pre- and\npost-interaction phases and the manipulated object during interaction, thereby\nmitigating the drawback of multi-object feature fusion present during\ninteraction in prior work. To further ensure subject semantic consistency\nthroughout the video, we incorporate appearance- and shape-aware latent\nrepresentations for objects. Extensive experiments on the challenging Bridge V2\ndataset, as well as in-the-wild evaluation, demonstrate that our method\noutperforms existing approaches, establishing new state-of-the-art performance\nin trajectory-controlled video generation for robotic manipulation.",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/63aef2cafcca84593e6682db/9mFDJaCOc6KLHlhboYA59.mp4"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.01943.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "63aef2cafcca84593e6682db",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1672409763337-noauth.jpeg",
      "fullname": "Xiao Fu",
      "name": "lemonaddie",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 15
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2506.01853",
      "authors": [
        {
          "_id": "683e671483a130f817c4937a",
          "name": "Junliang Ye",
          "hidden": false
        },
        {
          "_id": "683e671483a130f817c4937b",
          "name": "Zhengyi Wang",
          "hidden": false
        },
        {
          "_id": "683e671483a130f817c4937c",
          "user": {
            "_id": "6522e4fbd89bc7773ddc4b58",
            "avatarUrl": "/avatars/3e9b158af52c5f738a3eae72dcbb3824.svg",
            "isPro": false,
            "fullname": "Ruowen Zhao",
            "user": "zzzrw",
            "type": "user"
          },
          "name": "Ruowen Zhao",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-03T08:46:03.565Z",
          "hidden": false
        },
        {
          "_id": "683e671483a130f817c4937d",
          "name": "Shenghao Xie",
          "hidden": false
        },
        {
          "_id": "683e671483a130f817c4937e",
          "name": "Jun Zhu",
          "hidden": false
        }
      ],
      "mediaUrls": [
        "https://cdn-uploads.huggingface.co/production/uploads/65a420cd90e65dc39a6abe9e/84A40qBWJeZaBv2qYO6Pj.mp4",
        "https://cdn-uploads.huggingface.co/production/uploads/65a420cd90e65dc39a6abe9e/Xl6IajTG3VravdQABgC6l.mp4"
      ],
      "publishedAt": "2025-06-02T16:40:50.000Z",
      "submittedOnDailyAt": "2025-06-03T03:57:42.122Z",
      "title": "ShapeLLM-Omni : LLM Monomodal pour la Génération et la Compréhension 3D",
      "submittedOnDailyBy": {
        "_id": "65a420cd90e65dc39a6abe9e",
        "avatarUrl": "/avatars/81ac5b749043e899f5017782409f9e28.svg",
        "isPro": false,
        "fullname": "yejunliang",
        "user": "yejunliang23",
        "type": "user"
      },
      "summary": "Récemment, la capacité de ChatGPT-4o à transformer de texte fort en images a augmenté l'enthousiasme des modèles multimodales natifs de langue, bien que sa capacité multimodale soit encore limitée aux textes et aux images. Cependant, la compréhension et la génération de contenu 3D sont tout aussi importantes que les images. Pour combler cette lacune, nous proposons ShapeLLM-Omni, un modèle natif de langue 3D. Ce modèle peut comprendre et générer des ressources 3D et du texte dans n'importe quel ordre. Tout d'abord, un visualisateur de vecteurs 3D pour la visualisation de la variation (VQVAE) est entraîné pour cartographier les objets 3D dans un espace potentiel dispersé, réussissant une représentation efficace et précise des formes et de leur reconstruction. Ensuite, un grand jeu de données d'entraînement continu appelé 3D-Alpaca est construit, qui inclut la génération, la compréhension et l'édition, offrant des ressources riches pour futurs travaux de recherche et d'entraînement. Finalement, le modèle Qwen-2.5-vl-7B-Instruct basé sur des instructions est entraîné sur le jeu de données 3D-Alpaca. Notre recherche offre un essai efficace pour étendre les modèles multimodales avec des capacités 3D de base, contribuant à la recherche future des IA natifs 3D. Page du projet : https://github.com/JAMESYJL/ShapeLLM-Omni",
      "upvotes": 15,
      "discussionId": "683e671683a130f817c493cd",
      "ai_summary": "A native 3D large language model, ShapeLLM-Omni, is proposed to understand and generate 3D assets and text, trained using a 3D vector-quantized variational autoencoder and a new 3D-Alpaca dataset.",
      "ai_keywords": [
        "3D vector-quantized variational autoencoder (VQVAE)",
        "discrete latent space",
        "instruction-based training",
        "3D-Alpaca dataset",
        "3D-native AI"
      ]
    },
    "publishedAt": "2025-06-02T12:40:50.000Z",
    "title": "ShapeLLM-Omni: A Native Multimodal LLM for 3D Generation and\n  Understanding",
    "summary": "Recently, the powerful text-to-image capabilities of ChatGPT-4o have led to\ngrowing appreciation for native multimodal large language models. However, its\nmultimodal capabilities remain confined to images and text. Yet beyond images,\nthe ability to understand and generate 3D content is equally crucial. To\naddress this gap, we propose ShapeLLM-Omni-a native 3D large language model\ncapable of understanding and generating 3D assets and text in any sequence.\nFirst, we train a 3D vector-quantized variational autoencoder (VQVAE), which\nmaps 3D objects into a discrete latent space to achieve efficient and accurate\nshape representation and reconstruction. Building upon the 3D-aware discrete\ntokens, we innovatively construct a large-scale continuous training dataset\nnamed 3D-Alpaca, encompassing generation, comprehension, and editing, thus\nproviding rich resources for future research and training. Finally, by\nperforming instruction-based training of the Qwen-2.5-vl-7B-Instruct model on\nthe 3D-Alpaca dataset. Our work provides an effective attempt at extending\nmultimodal models with basic 3D capabilities, which contributes to future\nresearch in 3D-native AI. Project page:\nhttps://github.com/JAMESYJL/ShapeLLM-Omni",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/65a420cd90e65dc39a6abe9e/84A40qBWJeZaBv2qYO6Pj.mp4",
      "https://cdn-uploads.huggingface.co/production/uploads/65a420cd90e65dc39a6abe9e/Xl6IajTG3VravdQABgC6l.mp4"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.01853.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "65a420cd90e65dc39a6abe9e",
      "avatarUrl": "/avatars/81ac5b749043e899f5017782409f9e28.svg",
      "fullname": "yejunliang",
      "name": "yejunliang23",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 3
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2505.24760",
      "authors": [
        {
          "_id": "683e6af92139ea008faa74ba",
          "user": {
            "_id": "65144e46004a986ccc9d21d6",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65144e46004a986ccc9d21d6/oImRY64V-UeYGdrbd_ozU.jpeg",
            "isPro": false,
            "fullname": "Zafir Stojanovski",
            "user": "zafstojano",
            "type": "user"
          },
          "name": "Zafir Stojanovski",
          "status": "extracted_confirmed",
          "statusLastChangedAt": "2025-06-03T06:28:46.378Z",
          "hidden": false
        },
        {
          "_id": "683e6af92139ea008faa74bb",
          "user": {
            "_id": "6303f5f37b50dd9d0a371b28",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6303f5f37b50dd9d0a371b28/H25eCzAYVwBtpSpD8tnUV.jpeg",
            "isPro": false,
            "fullname": "Oliver Stanley",
            "user": "OllieStanley",
            "type": "user"
          },
          "name": "Oliver Stanley",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-03T08:45:56.277Z",
          "hidden": false
        },
        {
          "_id": "683e6af92139ea008faa74bc",
          "name": "Joe Sharratt",
          "hidden": false
        },
        {
          "_id": "683e6af92139ea008faa74bd",
          "name": "Richard Jones",
          "hidden": false
        },
        {
          "_id": "683e6af92139ea008faa74be",
          "name": "Abdulhakeem Adefioye",
          "hidden": false
        },
        {
          "_id": "683e6af92139ea008faa74bf",
          "user": {
            "_id": "6304061c0547362a22a76a17",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1661339692442-6304061c0547362a22a76a17.jpeg",
            "isPro": false,
            "fullname": "Jean Kaddour",
            "user": "JeanKaddour",
            "type": "user"
          },
          "name": "Jean Kaddour",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-03T09:13:54.739Z",
          "hidden": false
        },
        {
          "_id": "683e6af92139ea008faa74c0",
          "name": "Andreas Köpf",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-30T16:20:18.000Z",
      "submittedOnDailyAt": "2025-06-03T02:02:10.153Z",
      "title": "La logique de l'apprentissage par renforcement avec récompenses visibles dans un environnement de raisonnement",
      "submittedOnDailyBy": {
        "_id": "65144e46004a986ccc9d21d6",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65144e46004a986ccc9d21d6/oImRY64V-UeYGdrbd_ozU.jpeg",
        "isPro": false,
        "fullname": "Zafir Stojanovski",
        "user": "zafstojano",
        "type": "user"
      },
      "summary": "Reasoning Gym (RG) est une bibliothèque d'environnements pour la logique apprenante par renforcement qui permet d'essayer des expériences de compensation. Elle comporte plus de 100 générateurs de données et fournisseurs de tests, et s'étend sur des domaines tels que la logique, l'arithmétique, le calcul, la perception, la géométrie, la théorie des graphes, la logique de Horn et de nombreux autres domaines généraux de jeux. L'innovation principale est qu'en contraste avec les ensembles de données de logique précédentes, elle peut générer des données de complexité variable de manière infinie. Ce processus de génération permet des évaluations continuelles à différents niveaux de difficulté. À travers les résultats d'expériences, RG démontre son efficacité dans l'évaluation de modèles de logique et dans l'apprentissage par renforcement.",
      "upvotes": 15,
      "discussionId": "683e6afa2139ea008faa7531",
      "githubRepo": "https://github.com/open-thought/reasoning-gym",
      "ai_summary": "Reasoning Gym provides a library of reasoning environments with verifiable rewards and procedural data generation for reinforcement learning, enabling the evaluation and training of reasoning models at varying difficulty levels.",
      "ai_keywords": [
        "reinforcement learning",
        "verifiable rewards",
        "data generators",
        "verifiers",
        "procedural generation",
        "reasoning models"
      ]
    },
    "publishedAt": "2025-05-30T12:20:18.000Z",
    "title": "REASONING GYM: Reasoning Environments for Reinforcement Learning with\n  Verifiable Rewards",
    "summary": "We introduce Reasoning Gym (RG), a library of reasoning environments for\nreinforcement learning with verifiable rewards. It provides over 100 data\ngenerators and verifiers spanning multiple domains including algebra,\narithmetic, computation, cognition, geometry, graph theory, logic, and various\ncommon games. Its key innovation is the ability to generate virtually infinite\ntraining data with adjustable complexity, unlike most previous reasoning\ndatasets, which are typically fixed. This procedural generation approach allows\nfor continuous evaluation across varying difficulty levels. Our experimental\nresults demonstrate the efficacy of RG in both evaluating and reinforcement\nlearning of reasoning models.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.24760.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "65144e46004a986ccc9d21d6",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65144e46004a986ccc9d21d6/oImRY64V-UeYGdrbd_ozU.jpeg",
      "fullname": "Zafir Stojanovski",
      "name": "zafstojano",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2506.00996",
      "authors": [
        {
          "_id": "683e7cbf402acb186580d5ec",
          "name": "Kinam Kim",
          "hidden": false
        },
        {
          "_id": "683e7cbf402acb186580d5ed",
          "name": "Junha Hyung",
          "hidden": false
        },
        {
          "_id": "683e7cbf402acb186580d5ee",
          "name": "Jaegul Choo",
          "hidden": false
        }
      ],
      "mediaUrls": [
        "https://cdn-uploads.huggingface.co/production/uploads/64797735a68454566356b708/a-8jl8yq3KdDLnuZEaB3K.mp4"
      ],
      "publishedAt": "2025-06-01T12:57:43.000Z",
      "submittedOnDailyAt": "2025-06-03T03:25:10.796Z",
      "title": "La correction de la diversité temporelle pour modèles de diversité vidéo avec différents contrôles",
      "submittedOnDailyBy": {
        "_id": "64797735a68454566356b708",
        "avatarUrl": "/avatars/3424d022dd8ad29b56eb41814c5c3dee.svg",
        "isPro": false,
        "fullname": "Kinam Kim",
        "user": "kinam0252",
        "type": "user"
      },
      "summary": "Dans le contexte récent, le développement de modèles de diffusion pour les vidéos a permis la synthèse de vidéos de haute qualité, bien que la génération contrôlée ait été particulièrement difficile en raison des limites des données et de la quantité de calcul. Les méthodes d'ajustement pour la génération conditionnelle actuelles dépendent d'encodeurs externes ou de modifications structurelles, ce qui nécessite de grands ensembles de données et limite la flexibilité et l'échelle spatiale de la génération conditionnelle. Dans cet article, nous introduisons la technique d'ajustement conditionnel dans le contexte temporel (Temporal In-Context Fine-Tuning, TIC-FT) pour offrir une approche efficace et large à l'accès aux tâches de génération conditionnelle variées, à partir de modèles de diffusion de vidéos préalablement fournis. Notre idée principale est de combiner les conditions et les phrases cibles sur l'axe temporel et d'insérer des cadres d'un buffer avec un niveau de bruit croissant. Ces cadres de buffer permettent des mouvements suaves et assurent que le processus d'ajustement coïncide avec la dynamique temporelle du modèle fourni. La TIC-FT ne nécessite pas de modifications structurelles et atteint un bon rendement avec seulement 10-30 échantillons d'entraînement. Notre méthode a été validée sur des tâches telles que la génération de vidéos à partir d'images et la génération de vidéos à partir de vidéos, en utilisant des modèles de base comme CogVideoX-5B et Wan-14B. Les expériences étendues ont montré d'excéder les limites des baselines en termes de fidélité à la condition et de qualité visuelle, et ont présenté des efficacités élevées tant en entraînement que dans l'inférence. Pour obtenir plus de résultats, consultez https://kinam0252.github.io/TIC-FT/.",
      "upvotes": 14,
      "discussionId": "683e7cc1402acb186580d663",
      "ai_summary": "Temporal In-Context Fine-Tuning (TIC-FT) enhances pretrained video diffusion models for diverse conditional generation tasks with minimal data and without architectural changes.",
      "ai_keywords": [
        "text-to-video diffusion models",
        "fine-tuning",
        "external encoders",
        "architectural modifications",
        "Temporal In-Context Fine-Tuning",
        "condition and target frames",
        "buffer frames",
        "noise levels",
        "smooth transitions",
        "pretrained video diffusion models",
        "image-to-video generation",
        "video-to-video generation",
        "CogVideoX-5B",
        "Wan-14B"
      ]
    },
    "publishedAt": "2025-06-01T08:57:43.000Z",
    "title": "Temporal In-Context Fine-Tuning for Versatile Control of Video Diffusion\n  Models",
    "summary": "Recent advances in text-to-video diffusion models have enabled high-quality\nvideo synthesis, but controllable generation remains challenging, particularly\nunder limited data and compute. Existing fine-tuning methods for conditional\ngeneration often rely on external encoders or architectural modifications,\nwhich demand large datasets and are typically restricted to spatially aligned\nconditioning, limiting flexibility and scalability. In this work, we introduce\nTemporal In-Context Fine-Tuning (TIC-FT), an efficient and versatile approach\nfor adapting pretrained video diffusion models to diverse conditional\ngeneration tasks. Our key idea is to concatenate condition and target frames\nalong the temporal axis and insert intermediate buffer frames with\nprogressively increasing noise levels. These buffer frames enable smooth\ntransitions, aligning the fine-tuning process with the pretrained model's\ntemporal dynamics. TIC-FT requires no architectural changes and achieves strong\nperformance with as few as 10-30 training samples. We validate our method\nacross a range of tasks, including image-to-video and video-to-video\ngeneration, using large-scale base models such as CogVideoX-5B and Wan-14B.\nExtensive experiments show that TIC-FT outperforms existing baselines in both\ncondition fidelity and visual quality, while remaining highly efficient in both\ntraining and inference. For additional results, visit\nhttps://kinam0252.github.io/TIC-FT/",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/64797735a68454566356b708/a-8jl8yq3KdDLnuZEaB3K.mp4"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.00996.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64797735a68454566356b708",
      "avatarUrl": "/avatars/3424d022dd8ad29b56eb41814c5c3dee.svg",
      "fullname": "Kinam Kim",
      "name": "kinam0252",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2505.24846",
      "authors": [
        {
          "_id": "683e82f2fa7ede4842f95214",
          "name": "Jingyan Shen",
          "hidden": false
        },
        {
          "_id": "683e82f2fa7ede4842f95215",
          "user": {
            "_id": "66f8689725464a7989b75845",
            "avatarUrl": "/avatars/43a61a528c5779103eaf5687ba44ee14.svg",
            "isPro": false,
            "fullname": "Jiarui Yao",
            "user": "FlippyDora",
            "type": "user"
          },
          "name": "Jiarui Yao",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-03T08:40:58.100Z",
          "hidden": false
        },
        {
          "_id": "683e82f2fa7ede4842f95216",
          "user": {
            "_id": "64d45451c34a346181b130dd",
            "avatarUrl": "/avatars/9bb8205b889337df5d321539c9b5d69d.svg",
            "isPro": false,
            "fullname": "Rui Yang",
            "user": "Ray2333",
            "type": "user"
          },
          "name": "Rui Yang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-03T08:40:16.572Z",
          "hidden": true
        },
        {
          "_id": "683e82f2fa7ede4842f95217",
          "name": "Yifan Sun",
          "hidden": false
        },
        {
          "_id": "683e82f2fa7ede4842f95218",
          "name": "Feng Luo",
          "hidden": false
        },
        {
          "_id": "683e82f2fa7ede4842f95219",
          "name": "Rui Pan",
          "hidden": false
        },
        {
          "_id": "683e82f2fa7ede4842f9521a",
          "name": "Tong Zhang",
          "hidden": false
        },
        {
          "_id": "683e82f2fa7ede4842f9521b",
          "name": "Han Zhao",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-30T17:44:28.000Z",
      "submittedOnDailyAt": "2025-06-03T03:51:59.115Z",
      "title": "Micro : Apprentissage de préférences personnalisées avec modélisation mixte et apprentissage par contexte",
      "submittedOnDailyBy": {
        "_id": "64d45451c34a346181b130dd",
        "avatarUrl": "/avatars/9bb8205b889337df5d321539c9b5d69d.svg",
        "isPro": false,
        "fullname": "Rui Yang",
        "user": "Ray2333",
        "type": "user"
      },
      "summary": "Le modèle à niveaux est un pas important dans la construction sécurisée de grands modèles de langage (LLMs) basés sur la rétroalimentation humaine. Cependant, le modèle de Bradley-Terry (BT) à niveaux suppose une unique fonction de récompense et ne détecte pas la diversité et la différenciation propres. Cette simplification empêche les LLMs d'apporter une personnalisation et un soutien à diverses oppositions.\n\nThéoriquement, lorsque les préférences humaines suivent une distribution mixte de groupes, un seul modèle BT présente des erreurs insuffisantes. Actuellement, des apprentissages multi-fonctionnels et des fine-tuning sont utilisés pour aborder ces problèmes, mais ces méthodes sont coûteuses et limitées aux caractéristiques prédéfinies, ce qui empêche de capturer complètement la riche valeur humaine.\n\nDans cet article, nous présentons un cadre à deux étapes appelé MiCRo, qui utilise un ensemble de données binaires de préférences pour renforcer l'apprentissage de préférences personnalisées sans besoin de fine-tuning. Dans la première étape, MiCRo introduit un approche de modélisation mixte liée au contexte pour détecter différentes préférences humaines. Dans la deuxième étape, MiCRo intègre une stratégie de routage en ligne qui ajuste les poids de mélange dynamiquement en fonction du contexte, résolvant ainsi les incertitudes et permettant un apprentissage adaptatif efficace et scalable sans besoin d'ajout de fine-tuning. Les expériences avec différents ensembles de données de préférences ont démontré que MiCRo est efficace pour détecter différentes préférences humaines et améliore significativement la personnalisation dans la phase suivante.",
      "upvotes": 11,
      "discussionId": "683e82f3fa7ede4842f95246",
      "ai_summary": "MiCRo, a two-stage framework, improves personalized preference learning for large language models by leveraging binary preference datasets and dynamically adapting mixture weights based on context, effectively capturing diverse human preferences.",
      "ai_keywords": [
        "Reward modeling",
        "reinforcement learning from human feedback (RLHF)",
        "Large Language Models (LLMs)",
        "Bradley-Terry (BT) model",
        "mixture distribution",
        "personalization",
        "pluralistic alignment",
        "multi-objective learning",
        "context-aware mixture modeling",
        "online routing strategy"
      ]
    },
    "publishedAt": "2025-05-30T13:44:28.000Z",
    "title": "MiCRo: Mixture Modeling and Context-aware Routing for Personalized\n  Preference Learning",
    "summary": "Reward modeling is a key step in building safe foundation models when\napplying reinforcement learning from human feedback (RLHF) to align Large\nLanguage Models (LLMs). However, reward modeling based on the Bradley-Terry\n(BT) model assumes a global reward function, failing to capture the inherently\ndiverse and heterogeneous human preferences. Hence, such oversimplification\nlimits LLMs from supporting personalization and pluralistic alignment.\nTheoretically, we show that when human preferences follow a mixture\ndistribution of diverse subgroups, a single BT model has an irreducible error.\nWhile existing solutions, such as multi-objective learning with fine-grained\nannotations, help address this issue, they are costly and constrained by\npredefined attributes, failing to fully capture the richness of human values.\nIn this work, we introduce MiCRo, a two-stage framework that enhances\npersonalized preference learning by leveraging large-scale binary preference\ndatasets without requiring explicit fine-grained annotations. In the first\nstage, MiCRo introduces context-aware mixture modeling approach to capture\ndiverse human preferences. In the second stage, MiCRo integrates an online\nrouting strategy that dynamically adapts mixture weights based on specific\ncontext to resolve ambiguity, allowing for efficient and scalable preference\nadaptation with minimal additional supervision. Experiments on multiple\npreference datasets demonstrate that MiCRo effectively captures diverse human\npreferences and significantly improves downstream personalization.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.24846.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64d45451c34a346181b130dd",
      "avatarUrl": "/avatars/9bb8205b889337df5d321539c9b5d69d.svg",
      "fullname": "Rui Yang",
      "name": "Ray2333",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 12
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.24298",
      "authors": [
        {
          "_id": "683d12963aa5ac98190e1eda",
          "name": "Wei Fu",
          "hidden": false
        },
        {
          "_id": "683d12963aa5ac98190e1edb",
          "name": "Jiaxuan Gao",
          "hidden": false
        },
        {
          "_id": "683d12963aa5ac98190e1edc",
          "name": "Xujie Shen",
          "hidden": false
        },
        {
          "_id": "683d12963aa5ac98190e1edd",
          "name": "Chen Zhu",
          "hidden": false
        },
        {
          "_id": "683d12963aa5ac98190e1ede",
          "name": "Zhiyu Mei",
          "hidden": false
        },
        {
          "_id": "683d12963aa5ac98190e1edf",
          "name": "Chuyi He",
          "hidden": false
        },
        {
          "_id": "683d12963aa5ac98190e1ee0",
          "name": "Shusheng Xu",
          "hidden": false
        },
        {
          "_id": "683d12963aa5ac98190e1ee1",
          "name": "Guo Wei",
          "hidden": false
        },
        {
          "_id": "683d12963aa5ac98190e1ee2",
          "name": "Jun Mei",
          "hidden": false
        },
        {
          "_id": "683d12963aa5ac98190e1ee3",
          "name": "Jiashu Wang",
          "hidden": false
        },
        {
          "_id": "683d12963aa5ac98190e1ee4",
          "name": "Tongkai Yang",
          "hidden": false
        },
        {
          "_id": "683d12963aa5ac98190e1ee5",
          "name": "Binhang Yuan",
          "hidden": false
        },
        {
          "_id": "683d12963aa5ac98190e1ee6",
          "name": "Yi Wu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-30T07:18:25.000Z",
      "submittedOnDailyAt": "2025-06-03T05:39:21.066Z",
      "title": "AReaL : La logique du langage est l'objet de systèmes d'apprentissage par renforcement non-synchrone à grande échelle.",
      "submittedOnDailyBy": {
        "_id": "63159678915d0b80682fe9f9",
        "avatarUrl": "/avatars/a19e44ffe681099a155b8f8ecb53f0ce.svg",
        "isPro": false,
        "fullname": "Shusheng Xu",
        "user": "xssstory",
        "type": "user"
      },
      "summary": "L'apprentissage par réflexion (RL) se trouve en particulier dans le domaine des tâches considérées comme logiques et a acquis un rôle de croissance rapide dans le développement de l'entraînement de modèles de langage grands (LLMs). L'apprentissage efficace par réflexion dans les LLMs nécessite une grande parallélisation et souligne la nécessité urgente d'un système d'entraînement efficace. Actuellement, de nombreux systèmes de RL pour les grands LLMs sont réalisés avec un approche d'entraînement et de génération en parallèle, où, à chaque cycle d'entraînement, des sorties sont générées avec le même contenu (ou la dernière version du modèle). Cela stabilise l'entraînement mais pose des problèmes d'inefficacité systématique. La génération doit attendre jusqu'à ce que le plus long output soit complet, ce qui diminue l'efficacité de l'utilisation des GPUs. Nous présentons AReaL, un système d'apprentissage par réflexion asynchrone. AReaL sépare complètement la génération et l'entraînement, et continue de générer des sorties tout en les travailleurs d'entraînement mettent à jour le modèle lorsqu'ils reçoivent de nouvelles entrées. AReaL introduit des optimisations au niveau du système pour élever significativement l'efficacité des GPUs. Pour stabiliser l'entraînement par réflexion, AReaL équilibre la quantité de travail des sorties et des travailleurs d'entraînement, contrôle la génération de données et introduit une technique de contrôle de fin basée sur une variante du PPO pour traiter mieux les exemples d'entraînement terminés. Grâce à des expérimentations distribuées dans des cadres de référence logiques mathématiques et de code, AReaL, en utilisant le même GPU, atteint un accroissement de la vitesse d'entraînement de 2,57 fois, montrant un système de motivation optimal ou des résultats finaux meilleurs. Le code de AReaL est disponible sur https://github.com/inclusionAI/AReaL/.",
      "upvotes": 10,
      "discussionId": "683d12973aa5ac98190e1f19",
      "ai_summary": "AReaL, a fully asynchronous reinforcement learning system, decouples generation and training to achieve higher GPU utilization and up to 2.57x training speedup for large language models on reasoning tasks.",
      "ai_keywords": [
        "reinforcement learning",
        "large language models",
        "asynchronous system",
        "rollouts",
        "model update",
        "GPU utilization",
        "PPO",
        "data staleness",
        "training speedup"
      ]
    },
    "publishedAt": "2025-05-30T03:18:25.000Z",
    "title": "AReaL: A Large-Scale Asynchronous Reinforcement Learning System for\n  Language Reasoning",
    "summary": "Reinforcement learning (RL) has become a trending paradigm for training large\nlanguage models (LLMs), particularly for reasoning tasks. Effective RL for LLMs\nrequires massive parallelization and poses an urgent need for efficient\ntraining systems. Most existing large-scale RL systems for LLMs are synchronous\nby alternating generation and training in a batch setting, where the rollouts\nin each training batch are generated by the same (or latest) model. This\nstabilizes RL training but suffers from severe system-level inefficiency.\nGeneration must wait until the longest output in the batch is completed before\nmodel update, resulting in GPU underutilization. We present AReaL, a\nfully asynchronous RL system that completely decouples generation from\ntraining. Rollout workers in AReaL continuously generate new outputs without\nwaiting, while training workers update the model whenever a batch of data is\ncollected. AReaL also incorporates a collection of system-level optimizations,\nleading to substantially higher GPU utilization. To stabilize RL training,\nAReaL balances the workload of rollout and training workers to control data\nstaleness, and adopts a staleness-enhanced PPO variant to better handle\noutdated training samples. Extensive experiments on math and code reasoning\nbenchmarks show that AReaL achieves up to 2.57times training\nspeedup compared to the best synchronous systems with the same number of GPUs\nand matched or even improved final performance. The code of AReaL is available\nat https://github.com/inclusionAI/AReaL/.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.24298.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "63159678915d0b80682fe9f9",
      "avatarUrl": "/avatars/a19e44ffe681099a155b8f8ecb53f0ce.svg",
      "fullname": "Shusheng Xu",
      "name": "xssstory",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2505.23907",
      "authors": [
        {
          "_id": "683e6838a6815c77acb18ea3",
          "user": {
            "_id": "650e3abcae507a2c7c847baa",
            "avatarUrl": "/avatars/a138bc6c9ba80a486fb36f4e1aa16b33.svg",
            "isPro": false,
            "fullname": "Amirhossein Alimohammadi",
            "user": "Amirhossein-Alimohammadi",
            "type": "user"
          },
          "name": "Amirhossein Almohammadi",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-03T08:45:59.757Z",
          "hidden": false
        },
        {
          "_id": "683e6838a6815c77acb18ea4",
          "name": "Aryan Mikaeili",
          "hidden": false
        },
        {
          "_id": "683e6838a6815c77acb18ea5",
          "name": "Sauradip Nag",
          "hidden": false
        },
        {
          "_id": "683e6838a6815c77acb18ea6",
          "name": "Negar Hassanpour",
          "hidden": false
        },
        {
          "_id": "683e6838a6815c77acb18ea7",
          "name": "Andrea Tagliasacchi",
          "hidden": false
        },
        {
          "_id": "683e6838a6815c77acb18ea8",
          "name": "Ali Mahdavi-Amiri",
          "hidden": false
        }
      ],
      "mediaUrls": [
        "https://cdn-uploads.huggingface.co/production/uploads/650e3abcae507a2c7c847baa/dRNPZqV4HrW79gs506jk7.mp4"
      ],
      "publishedAt": "2025-05-29T18:00:56.000Z",
      "submittedOnDailyAt": "2025-06-03T01:51:49.601Z",
      "title": "Kora : Édition d'images pour la communication en moins de pas par divergence",
      "submittedOnDailyBy": {
        "_id": "650e3abcae507a2c7c847baa",
        "avatarUrl": "/avatars/a138bc6c9ba80a486fb36f4e1aa16b33.svg",
        "isPro": false,
        "fullname": "Amirhossein Alimohammadi",
        "user": "Amirhossein-Alimohammadi",
        "type": "user"
      },
      "summary": "L'édition d'images est l'un des travaux les plus importants dans les graphismes informatiques, la vision artificielle et les VFX, et les méthodes basées sur la diffusion ont réussi à obtenir des résultats de haute qualité de manière rapide. Cependant, les éditions nécessitant des changements structurels, comme des déformations non linéaires, des modifications d'objets ou la génération de contenu, peuvent être complexes. Les approches d'édition en peu de pas actuelles font face à des difficultés pour préserver des attributs de texture et des caractéristiques clés non pertinentes (par exemple, la posture). Nous présentons un nouveau cadre d'édition appelé Cora, qui introduit des corrections de bruit et des cartes d'attention interpolées basées sur des relations correspondantes pour résoudre ces limites. Notre méthode répare la texture et la structure des images sources et cibles à travers des relations correspondantes, et génère de nouveau contenu lorsque cela est nécessaire, facilitant ainsi une transmission précise de texture. Cora contrôle l'équilibre entre la génération et l'enregistrement du contenu. Les expériences larges montrent que Cora maintient l'identité structurale, texturale et de différents types d'édition tant quantitativement que qualitativement, démontrant des résultats excellents dans les changements de posture, l'ajout d'objets et l'amélioration de la texture. Les utilisateurs ont confirmé que Cora offre les meilleurs résultats et dépasse les alternatives existantes.",
      "upvotes": 8,
      "discussionId": "683e683aa6815c77acb18f03",
      "projectPage": "https://cora-edit.github.io/",
      "githubRepo": "https://github.com/alimohammadiamirhossein/cora",
      "ai_summary": "Cora framework enhances image editing through correspondence-aware noise correction and interpolated attention maps, excelling in structure and texture preservation and generation.",
      "ai_keywords": [
        "diffusion-based methods",
        "non-rigid deformations",
        "object modifications",
        "content generation",
        "correspondence-aware noise correction",
        "interpolated attention maps",
        "semantic correspondence",
        "texture transfer",
        "content generation",
        "preservation",
        "pose changes",
        "object addition",
        "texture refinements"
      ]
    },
    "publishedAt": "2025-05-29T14:00:56.000Z",
    "title": "Cora: Correspondence-aware image editing using few step diffusion",
    "summary": "Image editing is an important task in computer graphics, vision, and VFX,\nwith recent diffusion-based methods achieving fast and high-quality results.\nHowever, edits requiring significant structural changes, such as non-rigid\ndeformations, object modifications, or content generation, remain challenging.\nExisting few step editing approaches produce artifacts such as irrelevant\ntexture or struggle to preserve key attributes of the source image (e.g.,\npose). We introduce Cora, a novel editing framework that addresses these\nlimitations by introducing correspondence-aware noise correction and\ninterpolated attention maps. Our method aligns textures and structures between\nthe source and target images through semantic correspondence, enabling accurate\ntexture transfer while generating new content when necessary. Cora offers\ncontrol over the balance between content generation and preservation. Extensive\nexperiments demonstrate that, quantitatively and qualitatively, Cora excels in\nmaintaining structure, textures, and identity across diverse edits, including\npose changes, object addition, and texture refinements. User studies confirm\nthat Cora delivers superior results, outperforming alternatives.",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/650e3abcae507a2c7c847baa/dRNPZqV4HrW79gs506jk7.mp4"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.23907.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "650e3abcae507a2c7c847baa",
      "avatarUrl": "/avatars/a138bc6c9ba80a486fb36f4e1aa16b33.svg",
      "fullname": "Amirhossein Alimohammadi",
      "name": "Amirhossein-Alimohammadi",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.23001",
      "authors": [
        {
          "_id": "6839f87c49d173e7b23f220b",
          "user": {
            "_id": "66fa2c61c25c3fcb32f9f131",
            "avatarUrl": "/avatars/05387c30f2d1803fa0a5b176c3706772.svg",
            "isPro": false,
            "fullname": "Yize Cheng",
            "user": "yizecheng",
            "type": "user"
          },
          "name": "Yize Cheng",
          "status": "extracted_confirmed",
          "statusLastChangedAt": "2025-05-30T18:27:47.059Z",
          "hidden": false
        },
        {
          "_id": "6839f87c49d173e7b23f220c",
          "user": {
            "_id": "659dc02d72238596c24d49f5",
            "avatarUrl": "/avatars/d4600d23ccc72f296fab7f626d5895e7.svg",
            "isPro": false,
            "fullname": "Wenxiao Wang",
            "user": "wangwenxiao",
            "type": "user"
          },
          "name": "Wenxiao Wang",
          "status": "extracted_confirmed",
          "statusLastChangedAt": "2025-05-30T18:28:18.975Z",
          "hidden": false
        },
        {
          "_id": "6839f87c49d173e7b23f220d",
          "user": {
            "_id": "63449874ee1504dbcd59af3d",
            "avatarUrl": "/avatars/57a805d82d16de9544c98585bd7a3e55.svg",
            "isPro": false,
            "fullname": "MazdaM",
            "user": "mmoayeri",
            "type": "user"
          },
          "name": "Mazda Moayeri",
          "status": "extracted_confirmed",
          "statusLastChangedAt": "2025-05-30T20:01:34.913Z",
          "hidden": false
        },
        {
          "_id": "6839f87c49d173e7b23f220e",
          "name": "Soheil Feizi",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-29T02:22:14.000Z",
      "submittedOnDailyAt": "2025-06-03T00:16:12.678Z",
      "title": "Dípack : Méthode pour marquer clairement la contamination du jeu de tests dans les LLMs par l'utilisation de backdoors",
      "submittedOnDailyBy": {
        "_id": "66fa2c61c25c3fcb32f9f131",
        "avatarUrl": "/avatars/05387c30f2d1803fa0a5b176c3706772.svg",
        "isPro": false,
        "fullname": "Yize Cheng",
        "user": "yizecheng",
        "type": "user"
      },
      "summary": "Le benchmark ouvert est essentiel pour l'évaluation et le développement de modèles de langage grands, offrant une réplicabilité et une transparence, mais sa accessibilité peut diminuer si les ensembles de test sont contaminés. Dans cet article, nous utilisons le cadre de travail 'DyePack' pour déterminer si un modèle a utilisé un ensemble de test du benchmark. Notre objectif est de marquer avec un flag tout modèle qui a appris des données de test mélangées avec des échantillons de Wikipedia, comme si un banquier identifiquait un voleur mélangeant de l'argent avec des sacs de billets. De plus, nous proposons un design de base qui inclut plusieurs Wikipedias et permet de calculer un taux de faux positifs (FPR) probabiliste pour tout modèle marqué. De cette manière, nous évitons les faux positifs tout en fournissant des tests forts lorsque des phénomènes de contamination sont détectés. DyePack évalue 5 modèles avec 3 ensembles de données, couvrant autant des problèmes de sélection multiple que des tâches de génération ouvertes. Dans les problèmes de sélection multiple, nous utilisons 8 Wikipedias dans MMLU-Pro et Big-Bench-Hard, avec un taux de faux positifs probabiliste inférieur à 0.000073%, détectant avec succès tous les modèles contaminés. Dans les tâches de génération ouvertes, tous les modèles sont détectés comme contaminés, avec un taux de faux positifs probabiliste de 0.127% et 6 Wikipedias, détectant tous les modèles contaminés.",
      "upvotes": 8,
      "discussionId": "6839f87c49d173e7b23f222c",
      "githubRepo": "https://github.com/chengez/DyePack",
      "ai_summary": "DyePack, a framework using backdoor attacks, identifies models that leveraged benchmark test sets during training by introducing benign backdoor samples, ensuring precise false positive rates while preventing false accusations.",
      "ai_keywords": [
        "backdoor attacks",
        "test set contamination",
        "false positive rate",
        "FPR",
        "DyePack",
        "multiple backdoors",
        "stochastic targets",
        "MMLU-Pro",
        "Big-Bench-Hard",
        "Alpaca",
        "multiple-choice questions",
        "open-ended generation tasks"
      ]
    },
    "publishedAt": "2025-05-28T22:22:14.000Z",
    "title": "DyePack: Provably Flagging Test Set Contamination in LLMs Using\n  Backdoors",
    "summary": "Open benchmarks are essential for evaluating and advancing large language\nmodels, offering reproducibility and transparency. However, their accessibility\nmakes them likely targets of test set contamination. In this work, we introduce\nDyePack, a framework that leverages backdoor attacks to identify models that\nused benchmark test sets during training, without requiring access to the loss,\nlogits, or any internal details of the model. Like how banks mix dye packs with\ntheir money to mark robbers, DyePack mixes backdoor samples with the test data\nto flag models that trained on it. We propose a principled design incorporating\nmultiple backdoors with stochastic targets, enabling exact false positive rate\n(FPR) computation when flagging every model. This provably prevents false\naccusations while providing strong evidence for every detected case of\ncontamination. We evaluate DyePack on five models across three datasets,\ncovering both multiple-choice and open-ended generation tasks. For\nmultiple-choice questions, it successfully detects all contaminated models with\nguaranteed FPRs as low as 0.000073% on MMLU-Pro and 0.000017% on Big-Bench-Hard\nusing eight backdoors. For open-ended generation tasks, it generalizes well and\nidentifies all contaminated models on Alpaca with a guaranteed false positive\nrate of just 0.127% using six backdoors.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.23001.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "66fa2c61c25c3fcb32f9f131",
      "avatarUrl": "/avatars/05387c30f2d1803fa0a5b176c3706772.svg",
      "fullname": "Yize Cheng",
      "name": "yizecheng",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2506.00577",
      "authors": [
        {
          "_id": "683e646de9f216ff5a3e5dea",
          "user": {
            "_id": "658ab894c4b2004663dff3ae",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/658ab894c4b2004663dff3ae/oPRnFuW2Imaa2KkYWNbSf.jpeg",
            "isPro": false,
            "fullname": "YUFA ZHOU",
            "user": "MasterZhou",
            "type": "user"
          },
          "name": "Yufa Zhou",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-03T08:46:13.058Z",
          "hidden": false
        },
        {
          "_id": "683e646de9f216ff5a3e5deb",
          "user": {
            "_id": "66968099c952e09a4cb29f78",
            "avatarUrl": "/avatars/bd3a361fe5315e26e9ae328071704eed.svg",
            "isPro": false,
            "fullname": "Wang",
            "user": "Steven-Shaobo",
            "type": "user"
          },
          "name": "Shaobo Wang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-03T08:46:16.609Z",
          "hidden": false
        },
        {
          "_id": "683e646de9f216ff5a3e5dec",
          "name": "Xingyu Dong",
          "hidden": false
        },
        {
          "_id": "683e646de9f216ff5a3e5ded",
          "name": "Xiangqi Jin",
          "hidden": false
        },
        {
          "_id": "683e646de9f216ff5a3e5dee",
          "name": "Yifang Chen",
          "hidden": false
        },
        {
          "_id": "683e646de9f216ff5a3e5def",
          "name": "Yue Min",
          "hidden": false
        },
        {
          "_id": "683e646de9f216ff5a3e5df0",
          "name": "Kexin Yang",
          "hidden": false
        },
        {
          "_id": "683e646de9f216ff5a3e5df1",
          "name": "Xingzhang Ren",
          "hidden": false
        },
        {
          "_id": "683e646de9f216ff5a3e5df2",
          "name": "Dayiheng Liu",
          "hidden": false
        },
        {
          "_id": "683e646de9f216ff5a3e5df3",
          "name": "Linfeng Zhang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-31T14:22:40.000Z",
      "submittedOnDailyAt": "2025-06-03T01:32:07.834Z",
      "title": "Nous cherchons des raisons comme un économiste : l'impact de la généralisation stratégique post-entraînement sur les problèmes économiques généraux.",
      "submittedOnDailyBy": {
        "_id": "658ab894c4b2004663dff3ae",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/658ab894c4b2004663dff3ae/oPRnFuW2Imaa2KkYWNbSf.jpeg",
        "isPro": false,
        "fullname": "YUFA ZHOU",
        "user": "MasterZhou",
        "type": "user"
      },
      "summary": "Un entraînement direct dans le langage des modèles de langage d'intelligence artificielle (LLMs) dans des systèmes d'agents multiples (MAS) peuvent rencontrer des défis liés à la modélisation des récompenses complexes, l'interaction dynamique entre les agents et la nécessité d'une forte généralisation. Dans cet article, nous explorons si des technologies d'entraînement postérieur, en particulier l'entraînement de vérification de l'apprentissage (SFT) et l'apprentissage par renforcement (RLVR), peuvent être appliquées dans des scénarios d'agents multiples. Nous utilisons un testeur comme un économiste pour tester nos algorithmes, incorporant une forte base en mathématiques et théorie des jeux, ainsi que la nécessité d'un analyse logique structurée, de conception de marché, de distribution des ressources et d'analyse des politiques, entre autres aspects applicables au monde réel. Nous présentons Recon, un modèle de langage d'intelligence artificielle (LLM) de 7B paramètres qui est entraîné postérieurement avec un ensemble de données de sélections manuelles de 2,100 problèmes de logique économique de haute qualité. Selon les évaluations détaillées dans des référentiels de logique économique et de jeux d'agents multiples, Recon a considérablement amélioré la logique structurée et la raisonnabilité économique. Ces résultats soulignent la possibilité que l'entraînement postérieur améliore la logique et la réponse des agents, et mettent en avant le rôle joué par le SFT et le RL dans la formation des actions du modèle. Le code est disponible sur https://github.com/MasterZhou1/Recon.",
      "upvotes": 7,
      "discussionId": "683e646ee9f216ff5a3e5e2c",
      "githubRepo": "https://github.com/MasterZhou1/Recon",
      "ai_summary": "Post-training techniques such as Supervised Fine-Tuning and Reinforcement Learning with Verifiable Rewards improve the reasoning and economic rationality of Large Language Models in multi-agent scenarios through domain-aligned training.",
      "ai_keywords": [
        "Large Language Models",
        "Multi-Agent Systems",
        "Supervised Fine-Tuning",
        "Reinforcement Learning with Verifiable Rewards",
        "economic reasoning",
        "domain-aligned post-training"
      ]
    },
    "publishedAt": "2025-05-31T10:22:40.000Z",
    "title": "Reasoning Like an Economist: Post-Training on Economic Problems Induces\n  Strategic Generalization in LLMs",
    "summary": "Directly training Large Language Models (LLMs) for Multi-Agent Systems (MAS)\nremains challenging due to intricate reward modeling, dynamic agent\ninteractions, and demanding generalization requirements. This paper explores\nwhether post-training techniques, specifically Supervised Fine-Tuning (SFT) and\nReinforcement Learning with Verifiable Rewards (RLVR), can effectively\ngeneralize to multi-agent scenarios. We use economic reasoning as a\ntestbed, leveraging its strong foundations in mathematics and game theory, its\ndemand for structured analytical reasoning, and its relevance to real-world\napplications such as market design, resource allocation, and policy analysis.\nWe introduce Recon (Reasoning like an\nECONomist), a 7B-parameter open-source LLM post-trained on a\nhand-curated dataset of 2,100 high-quality economic reasoning problems.\nComprehensive evaluation on economic reasoning benchmarks and multi-agent games\nreveals clear improvements in structured reasoning and economic rationality.\nThese results underscore the promise of domain-aligned post-training for\nenhancing reasoning and agent alignment, shedding light on the roles of SFT and\nRL in shaping model behavior. Code is available at\nhttps://github.com/MasterZhou1/Recon .",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.00577.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "658ab894c4b2004663dff3ae",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/658ab894c4b2004663dff3ae/oPRnFuW2Imaa2KkYWNbSf.jpeg",
      "fullname": "YUFA ZHOU",
      "name": "MasterZhou",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.23977",
      "authors": [
        {
          "_id": "683e380cb028cae60270adcf",
          "user": {
            "_id": "6702d9e2db3b7a57f9420e8d",
            "avatarUrl": "/avatars/2e65e83e8d13ca129f6382deb6e8bdfc.svg",
            "isPro": false,
            "fullname": "Yichen Feng",
            "user": "EthanSta",
            "type": "user"
          },
          "name": "Yichen Feng",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-03T08:47:01.523Z",
          "hidden": false
        },
        {
          "_id": "683e380cb028cae60270add0",
          "user": {
            "_id": "653df1323479e9ebbe3eb6cc",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/653df1323479e9ebbe3eb6cc/K_g-r1iMRNKj99LXPuYF3.jpeg",
            "isPro": true,
            "fullname": "Zhangchen Xu",
            "user": "zhangchenxu",
            "type": "user"
          },
          "name": "Zhangchen Xu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-03T08:46:58.968Z",
          "hidden": false
        },
        {
          "_id": "683e380cb028cae60270add1",
          "name": "Fengqing Jiang",
          "hidden": false
        },
        {
          "_id": "683e380cb028cae60270add2",
          "name": "Yuetai Li",
          "hidden": false
        },
        {
          "_id": "683e380cb028cae60270add3",
          "name": "Bhaskar Ramasubramanian",
          "hidden": false
        },
        {
          "_id": "683e380cb028cae60270add4",
          "name": "Luyao Niu",
          "hidden": false
        },
        {
          "_id": "683e380cb028cae60270add5",
          "name": "Bill Yuchen Lin",
          "hidden": false
        },
        {
          "_id": "683e380cb028cae60270add6",
          "name": "Radha Poovendran",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-29T20:08:36.000Z",
      "submittedOnDailyAt": "2025-06-03T01:08:43.749Z",
      "title": "VisualSphinx : RL pour le jeu de puzzle visuel de logique synthétique à grande échelle",
      "submittedOnDailyBy": {
        "_id": "653df1323479e9ebbe3eb6cc",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/653df1323479e9ebbe3eb6cc/K_g-r1iMRNKj99LXPuYF3.jpeg",
        "isPro": true,
        "fullname": "Zhangchen Xu",
        "user": "zhangchenxu",
        "type": "user"
      },
      "summary": "Les modèles de langue visuo-linguistique (VLMs) attendent de réaliser des logiques multimodales efficaces et de prendre des décisions logiquement cohérentes. Cela est crucial pour des tâches telles que l'interprétation d'images ou la résolution de problèmes spatiaux. Cependant, actuellement, les VLMs sont confrontés à une manque de logique et de structure dans les grands ensembles de données d'entraînement. Pour corriger cette déficience, nous proposons VisualSphinx, le premier grand ensemble de données d'entraînement synthétique de logique visuo-logique. Pour aborder le défi de la fondamentalisation des réponses dans la synthèse d'images, nous proposons un flux de travail de synthèse d'images basé sur des règles. Ce flux permet d'extraire et d'étendre des règles cachées à partir de diverses questions, générant des codes pour la synthèse d'images fondamentales qui décrivent la composition de échantillons cachés. Les expériences montrent que les VLMs entraînés avec GRPO sur VisualSphinx reçoivent des bêta par la logique et l'interprétation de notre ensemble de données. Ces modèles présentent des améliorations dans des tâches de logique. Les capacités de logique étendues développées dans VisualSphinx offrent également des avantages dans des tâches logiques telles que l'arithmétique, la logique algébrique et la géométrie.",
      "upvotes": 7,
      "discussionId": "683e380eb028cae60270ae82",
      "ai_summary": "VisualSphinx provides a large-scale synthetic dataset to improve multimodal reasoning in vision language models, enhancing performance on various logical reasoning tasks.",
      "ai_keywords": [
        "vision language models",
        "multimodal reasoning",
        "logical reasoning",
        "large-scale synthetic visual logical reasoning",
        "image synthesis",
        "rule-to-image synthesis",
        "GRPO"
      ]
    },
    "publishedAt": "2025-05-29T16:08:36.000Z",
    "title": "VisualSphinx: Large-Scale Synthetic Vision Logic Puzzles for RL",
    "summary": "Vision language models (VLMs) are expected to perform effective multimodal\nreasoning and make logically coherent decisions, which is critical to tasks\nsuch as diagram understanding and spatial problem solving. However, current VLM\nreasoning lacks large-scale and well-structured training datasets. To bridge\nthis gap, we propose VisualSphinx, a first-of-its-kind large-scale synthetic\nvisual logical reasoning training data. To tackle the challenge of image\nsynthesis with grounding answers, we propose a rule-to-image synthesis\npipeline, which extracts and expands puzzle rules from seed questions and\ngenerates the code of grounding synthesis image synthesis for puzzle sample\nassembly. Experiments demonstrate that VLM trained using GRPO on VisualSphinx\nbenefit from logical coherence and readability of our dataset and exhibit\nimproved performance on logical reasoning tasks. The enhanced reasoning\ncapabilities developed from VisualSphinx also benefit other reasoning tasks\nsuch as algebraic reasoning, arithmetic reasoning and geometry reasoning.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.23977.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "653df1323479e9ebbe3eb6cc",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/653df1323479e9ebbe3eb6cc/K_g-r1iMRNKj99LXPuYF3.jpeg",
      "fullname": "Zhangchen Xu",
      "name": "zhangchenxu",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 16
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.23059",
      "authors": [
        {
          "_id": "683b4b86c4b9677f3f7125e5",
          "user": {
            "_id": "6683c3b04905815dcffe7a21",
            "avatarUrl": "/avatars/73c50843d99b6fb8b1ee8fe11106c4ce.svg",
            "isPro": false,
            "fullname": "Dohyeon Lee",
            "user": "waylight3",
            "type": "user"
          },
          "name": "Dohyeon Lee",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-03T08:50:07.024Z",
          "hidden": false
        },
        {
          "_id": "683b4b86c4b9677f3f7125e6",
          "user": {
            "_id": "645aedd221ab438e732bff43",
            "avatarUrl": "/avatars/31e14fee670fd5ddd296ea0249dbf710.svg",
            "isPro": false,
            "fullname": "Yeonseok Jeong",
            "user": "yeonseokjeong",
            "type": "user"
          },
          "name": "Yeonseok Jeong",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-02T07:42:20.758Z",
          "hidden": false
        },
        {
          "_id": "683b4b86c4b9677f3f7125e7",
          "name": "Seung-won Hwang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-29T04:04:25.000Z",
      "submittedOnDailyAt": "2025-06-03T01:42:51.938Z",
      "title": "Des de tokens à actions : Théorie de la représentation d'états pour réduire l'excès de considération dans la recherche d'information.",
      "submittedOnDailyBy": {
        "_id": "645aedd221ab438e732bff43",
        "avatarUrl": "/avatars/31e14fee670fd5ddd296ea0249dbf710.svg",
        "isPro": false,
        "fullname": "Yeonseok Jeong",
        "user": "yeonseokjeong",
        "type": "user"
      },
      "summary": "Chain-of-Thought (CoT) prompting permet la génération de logiques complexes dans les modèles de langage grands (LLMs). Cette technologie peut également être appliquée à la recherche d'information (IR). Cependant, le modèle peut générer des phrases excessivement longues et significatives, ce qui peut affecter son rendement. Nous avons identifié deux problèmes importants dans l'IR : premièrement, le parcours excessivement long pour revisiter des états similaires, et secondement, la logique qui s'éloigne des désirs du utilisateur. Pour résoudre ces problèmes, nous avons proposé la raisonnement avec machine de états (SMR). SMR se réalise avec des actions discrètes (Refine, Rerank, Stop) qui fournissent une conclusion rapide et un contrôle précis. Les expériences sur BEIR et BRIGHT ont montré que SMR réduit l'utilisation de tokens d'un 74,4 % et améliore le rendement de recherche en nDCG@10 d'un 3,4 %. SMR est généralisable tant pour les LLMs que pour les modèles de recherche, et ne nécessite pas d'ajustements spécifiques pour des tâches particulières, offrant une version pratique de CoT. Les codes et détails sont disponibles sur https://github.com/ldilab/SMR.",
      "upvotes": 7,
      "discussionId": "683b4b87c4b9677f3f712609",
      "githubRepo": "https://github.com/ldilab/SMR",
      "ai_summary": "State Machine Reasoning (SMR) improves information retrieval performance and reduces token usage in large language models by addressing overthinking through a discrete action framework.",
      "ai_keywords": [
        "Chain-of-Thought",
        "State Machine Reasoning",
        "IR",
        "redundant trajectories",
        "misguided reasoning",
        "early stopping",
        "nDCG@10"
      ]
    },
    "publishedAt": "2025-05-29T00:04:25.000Z",
    "title": "From Token to Action: State Machine Reasoning to Mitigate Overthinking\n  in Information Retrieval",
    "summary": "Chain-of-Thought (CoT) prompting enables complex reasoning in large language\nmodels (LLMs), including applications in information retrieval (IR). However,\nit often leads to overthinking, where models produce excessively long and\nsemantically redundant traces with little or no benefit. We identify two key\nchallenges in IR: redundant trajectories that revisit similar states and\nmisguided reasoning that diverges from user intent. To address these, we\npropose State Machine Reasoning (SMR), a transition-based reasoning framework\ncomposed of discrete actions (Refine, Rerank, Stop) that support early stopping\nand fine-grained control. Experiments on the BEIR and BRIGHT benchmarks show\nthat SMR improves retrieval performance (nDCG@10) by 3.4% while reducing token\nusage by 74.4%. It generalizes across LLMs and retrievers without requiring\ntask-specific tuning, offering a practical alternative to conventional CoT\nreasoning. The code and details are available at https://github.com/ldilab/SMR.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.23059.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "645aedd221ab438e732bff43",
      "avatarUrl": "/avatars/31e14fee670fd5ddd296ea0249dbf710.svg",
      "fullname": "Yeonseok Jeong",
      "name": "yeonseokjeong",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 3
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2506.01881",
      "authors": [
        {
          "_id": "683e6708ef9c250c6642783c",
          "user": {
            "_id": "65c431a609672feb8cac22e7",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65c431a609672feb8cac22e7/obXCXUOgEoCuJbGuzYOGA.jpeg",
            "isPro": false,
            "fullname": "Yaoyao Qian",
            "user": "FreaxRuby",
            "type": "user"
          },
          "name": "Yaoyao Qian",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-06-03T03:07:55.037Z",
          "hidden": false
        },
        {
          "_id": "683e6708ef9c250c6642783d",
          "name": "Jindan Huang",
          "hidden": false
        },
        {
          "_id": "683e6708ef9c250c6642783e",
          "name": "Yuanli Wang",
          "hidden": false
        },
        {
          "_id": "683e6708ef9c250c6642783f",
          "user": {
            "_id": "636681feaa6a4af6073ba73e",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/636681feaa6a4af6073ba73e/u_0moYNu6as9Sszp-ej95.png",
            "isPro": true,
            "fullname": "Simon Yu",
            "user": "simonycl",
            "type": "user"
          },
          "name": "Simon Yu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-03T08:46:06.559Z",
          "hidden": false
        },
        {
          "_id": "683e6708ef9c250c66427840",
          "name": "Kyrie Zhixuan Zhou",
          "hidden": false
        },
        {
          "_id": "683e6708ef9c250c66427841",
          "name": "Jiayuan Mao",
          "hidden": false
        },
        {
          "_id": "683e6708ef9c250c66427842",
          "name": "Mingfu Liang",
          "hidden": false
        },
        {
          "_id": "683e6708ef9c250c66427843",
          "name": "Hanhan Zhou",
          "hidden": false
        }
      ],
      "publishedAt": "2025-06-02T17:11:10.000Z",
      "submittedOnDailyAt": "2025-06-03T01:38:44.220Z",
      "title": "Modèle de sélection temporelle de trajets structuraux pour la possibilité de déclenchement d'intentions dans le design de journaux pour tâches : moment d'action, moment d'attente",
      "submittedOnDailyBy": {
        "_id": "65c431a609672feb8cac22e7",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65c431a609672feb8cac22e7/obXCXUOgEoCuJbGuzYOGA.jpeg",
        "isPro": false,
        "fullname": "Yaoyao Qian",
        "user": "FreaxRuby",
        "type": "user"
      },
      "summary": "Les systèmes de dialogue orientés par des tâches rencontrent des difficultés lorsque les demandes du utilisateur sont grammaticalement complètes mais manquent de l'information structurelle nécessaire pour le comportement approprié du système. Cela est dû au fait que l'utilisateur ne comprend pas complètement ses propres besoins tandis que le système exige une définition de l'objectif spécifique. Les agents basés sur des modèles de grands langages (LLM) ne peuvent pas distinguer efficacement entre un langage complet ou un texte qui peut être récupéré selon le contexte, ce qui fait que manque un cadre pour la formation collaborative de l'intention. Nous présentons le cadre STORM. Ce cadre modélise l'information symétrique et structurelle dans les conversations entre UserLLM (accès complet interne) et AgentLLM (actions observables uniquement). STORM génère un corpus qui détecte le trace des représentations et des transitions cognitives potentielles, et se développe via un analyse systématique de la compréhension collaborative. Notre contribution comprend : (1) la formalisation du traitement de l'information symétrique dans les systèmes de dialogue, (2) le suivi de la formation de l'intention et du développement de la compréhension collaborative, et (3) un indice d'évaluation qui mesure tant le rendement de la tâche que l'augmentation du connaissance cognitif interne. Les tests expérimentaux avec quatre modèles de langage ont révélé que un niveau modéré d'incertitude (40-60%) peut dépasser la transparence totale dans certains échantillonnages, et les motifs propres aux modèles contribuent à la réévaluation de la pertinence de l'information plus appropriée dans les collaborations entre humains et IA. Ces résultats contribuent à la dynamique de la justification symétrique et fournissent des informations sur le design des systèmes de dialogue adaptés à l'incertitude.",
      "upvotes": 6,
      "discussionId": "683e670bef9c250c664278be",
      "projectPage": "https://nanostorm.netlify.app/",
      "githubRepo": "https://github.com/H-Freax/Storm",
      "ai_summary": "STORM frameworks facilitates collaborative intent formation in task-oriented dialogue systems by modeling asymmetric information dynamics between UserLLM and AgentLLM.",
      "ai_keywords": [
        "UserLLM",
        "AgentLLM",
        "asymmetric information dynamics",
        "collaborative understanding",
        "intent formation",
        "expression trajectories",
        "latent cognitive transitions",
        "uncertainty-calibrated dialogue systems"
      ]
    },
    "publishedAt": "2025-06-02T13:11:10.000Z",
    "title": "WHEN TO ACT, WHEN TO WAIT: Modeling Structural Trajectories for Intent\n  Triggerability in Task-Oriented Dialogue",
    "summary": "Task-oriented dialogue systems often face difficulties when user utterances\nseem semantically complete but lack necessary structural information for\nappropriate system action. This arises because users frequently do not fully\nunderstand their own needs, while systems require precise intent definitions.\nCurrent LLM-based agents cannot effectively distinguish between linguistically\ncomplete and contextually triggerable expressions, lacking frameworks for\ncollaborative intent formation. We present STORM, a framework modeling\nasymmetric information dynamics through conversations between UserLLM (full\ninternal access) and AgentLLM (observable behavior only). STORM produces\nannotated corpora capturing expression trajectories and latent cognitive\ntransitions, enabling systematic analysis of collaborative understanding\ndevelopment. Our contributions include: (1) formalizing asymmetric information\nprocessing in dialogue systems; (2) modeling intent formation tracking\ncollaborative understanding evolution; and (3) evaluation metrics measuring\ninternal cognitive improvements alongside task performance. Experiments across\nfour language models reveal that moderate uncertainty (40-60%) can outperform\ncomplete transparency in certain scenarios, with model-specific patterns\nsuggesting reconsideration of optimal information completeness in human-AI\ncollaboration. These findings contribute to understanding asymmetric reasoning\ndynamics and inform uncertainty-calibrated dialogue system design.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.01881.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "65c431a609672feb8cac22e7",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65c431a609672feb8cac22e7/obXCXUOgEoCuJbGuzYOGA.jpeg",
      "fullname": "Yaoyao Qian",
      "name": "FreaxRuby",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2506.01667",
      "authors": [
        {
          "_id": "683eaa8ed8d42fc832445ebd",
          "name": "Yan Shu",
          "hidden": false
        },
        {
          "_id": "683eaa8ed8d42fc832445ebe",
          "name": "Bin Ren",
          "hidden": false
        },
        {
          "_id": "683eaa8ed8d42fc832445ebf",
          "name": "Zhitong Xiong",
          "hidden": false
        },
        {
          "_id": "683eaa8ed8d42fc832445ec0",
          "name": "Danda Pani Paudel",
          "hidden": false
        },
        {
          "_id": "683eaa8ed8d42fc832445ec1",
          "name": "Luc Van Gool",
          "hidden": false
        },
        {
          "_id": "683eaa8ed8d42fc832445ec2",
          "name": "Begum Demir",
          "hidden": false
        },
        {
          "_id": "683eaa8ed8d42fc832445ec3",
          "name": "Nicu Sebe",
          "hidden": false
        },
        {
          "_id": "683eaa8ed8d42fc832445ec4",
          "name": "Paolo Rota",
          "hidden": false
        }
      ],
      "publishedAt": "2025-06-02T13:36:05.000Z",
      "submittedOnDailyAt": "2025-06-03T06:26:41.885Z",
      "title": "EarthMind : EarthMind pour l'observation de la Terre à grandes grains de granularité et de sensibilité avec des modèles multimodales grands\n\nÉtude de l'observation de la Terre à grandes grains de granularité et de sensibilité pour EarthMind avec des modèles multimodales grands",
      "submittedOnDailyBy": {
        "_id": "65c4f99b27736b5b86c2cbda",
        "avatarUrl": "/avatars/8789b231ec16073ea0229c28f1f1dd06.svg",
        "isPro": false,
        "fullname": "Yan Shu",
        "user": "sy1998",
        "type": "user"
      },
      "summary": "Les grands modèles multimodales (MMMs) ont démontré un excellent rendement sur de nombreuses tâches de langage visuel. Cependant, la compréhension générale des données d'observation de la Terre (EO) présente des difficultés, ce qui est crucial pour comprendre l'impact des activités humaines et l'observation de l'environnement. Dans cet article, nous présentons un nouveau cadre de travail de langage visuel \"EarthMind\". EarthMind se concentre sur l'interprétation des données EO de grandes et petites échelles. Ce cadre contient deux éléments clés : (1) L'attention spatiale de notation (SAP), qui réorganise l'attention des modèles de langage de grande taille pour renforcer la compréhension au niveau de pixel ; (2) La fusion multimodale, qui ajuste les modèles de différentes modalités dans un espace commun, adaptant les tokens en fonction de la densité d'information pour atteindre une fusion efficace. Pour promouvoir l'évaluation de la fusion multiéchelle, nous proposons EarthMind-Bench, un cadre de test détaillé. EarthMind-Bench inclut plus de 2 000 paires d'images multiéchelle avec des étiquettes humaines, enregistrant une large gamme de tâches d'observation et de logique. Les expériences étendues démontrent l'efficacité de EarthMind. Dans EarthMind-Bench, EarthMind atteint les meilleurs résultats et peut dépasser GPT-4o. De plus, EarthMind dépasse les méthodes actuelles dans la plupart des benchmarks publics d'observation de la Terre. Ces résultats montrent que EarthMind peut facilement aborder des défis d'échelle grande et petite à travers un seul cadre de travail intégré.",
      "upvotes": 6,
      "discussionId": "683eaa94d8d42fc832446013",
      "githubRepo": "https://github.com/shuyansy/EarthMind",
      "ai_summary": "EarthMind is a vision-language framework that uses spatial attention prompting and cross-modal fusion for efficient multi-granular and multi-sensor Earth Observation data understanding, outperforming larger models on specialized benchmarks.",
      "ai_keywords": [
        "Spatial Attention Prompting",
        "Cross-modal Fusion",
        "Earth Observation",
        "multi-granular",
        "multi-sensor",
        "EarthMind-Bench"
      ]
    },
    "publishedAt": "2025-06-02T09:36:05.000Z",
    "title": "EarthMind: Towards Multi-Granular and Multi-Sensor Earth Observation\n  with Large Multimodal Models",
    "summary": "Large Multimodal Models (LMMs) have demonstrated strong performance in\nvarious vision-language tasks. However, they often struggle to comprehensively\nunderstand Earth Observation (EO) data, which is critical for monitoring the\nenvironment and the effects of human activity on it. In this work, we present\nEarthMind, a novel vision-language framework for multi-granular and\nmulti-sensor EO data understanding. EarthMind features two core components: (1)\nSpatial Attention Prompting (SAP), which reallocates attention within the LLM\nto enhance pixel-level understanding; and (2) Cross-modal Fusion, which aligns\nheterogeneous modalities into a shared space and adaptively reweighs tokens\nbased on their information density for effective fusion. To facilitate\nmulti-sensor fusion evaluation, we propose EarthMind-Bench, a comprehensive\nbenchmark with over 2,000 human-annotated multi-sensor image-question pairs,\ncovering a wide range of perception and reasoning tasks. Extensive experiments\ndemonstrate the effectiveness of EarthMind. It achieves state-of-the-art\nperformance on EarthMind-Bench, surpassing GPT-4o despite being only 4B in\nscale. Moreover, EarthMind outperforms existing methods on multiple public EO\nbenchmarks, showcasing its potential to handle both multi-granular and\nmulti-sensor challenges in a unified framework.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.01667.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "65c4f99b27736b5b86c2cbda",
      "avatarUrl": "/avatars/8789b231ec16073ea0229c28f1f1dd06.svg",
      "fullname": "Yan Shu",
      "name": "sy1998",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 5
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2505.24625",
      "authors": [
        {
          "_id": "683e5569fce31842c60675d7",
          "user": {
            "_id": "646e2fcaf813cfe153f1af6c",
            "avatarUrl": "/avatars/2f87d0e5c071000990da29cd744bc03d.svg",
            "isPro": false,
            "fullname": "Duo Zheng",
            "user": "zd11024",
            "type": "user"
          },
          "name": "Duo Zheng",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-03T08:46:45.196Z",
          "hidden": false
        },
        {
          "_id": "683e5569fce31842c60675d8",
          "name": "Shijia Huang",
          "hidden": false
        },
        {
          "_id": "683e5569fce31842c60675d9",
          "name": "Yanyang Li",
          "hidden": false
        },
        {
          "_id": "683e5569fce31842c60675da",
          "name": "Liwei Wang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-30T14:16:41.000Z",
      "submittedOnDailyAt": "2025-06-03T00:24:09.506Z",
      "title": "Le monde 3D appris à partir de vidéos : Améliorer MLLM avec la vision 3D\nGéométrie de la propriété",
      "submittedOnDailyBy": {
        "_id": "646e2fcaf813cfe153f1af6c",
        "avatarUrl": "/avatars/2f87d0e5c071000990da29cd744bc03d.svg",
        "isPro": false,
        "fullname": "Duo Zheng",
        "user": "zd11024",
        "type": "user"
      },
      "summary": "Antécédents de recherches ont exploré l'application de Modèles de Langage Large Multimodales (MLLMs) pour comprendre des scènes 3D en lisant des vidéos. Cette méthodologie requiert généralement des données 3D, tels que des clusters de points ou des cartes de vue aérienne de la perspective de l'oiseau (BEV) reconstruites. Dans notre étude, nous avons amélioré ces recherches et élargi la capacité des MLLMs pour comprendre et expliquer l'intégration de espaces 3D directement à partir des données vidéo, améliorant ce domaine. Notre équipe de recherche a proposé un nouveau méthode efficace appelé Modèle de Langage Large de Géométrie 3D à partir de Vidéos (VG LLM). Notre approche utilise un codageur de géométrie visuelle 3D et extrait des informations 3D à partir de séquences de vidéo. Cette information est intégrée avec des tokens visuels et fournie comme entrée aux MLLMs. Les expériences étendues ont démontré des améliorations significatives dans notre méthodologie pour différentes tâches de compréhension de scènes 3D et de raisonnement spatial. Ce qui est le plus impressionnant, notre modèle de 4B ne nécessite pas une entrée explicite de données 3D, obtenant des résultats compétitifs par rapport aux meilleurs méthodes actuelles et dépassant Gemini-1.5-Pro dans l'évaluation VSI-Bench.",
      "upvotes": 6,
      "discussionId": "683e556efce31842c6067737",
      "projectPage": "https://lavi-lab.github.io/VG-LLM/",
      "githubRepo": "https://github.com/LaVi-Lab/VG-LLM",
      "ai_summary": "A novel Video-3D Geometry Large Language Model (VG LLM) extracts 3D information directly from video sequences to enhance 3D scene understanding without additional 3D data, achieving competitive results in various tasks.",
      "ai_keywords": [
        "MLLMs",
        "Video-3D Geometry Large Language Model",
        "VG LLM",
        "3D visual geometry encoder",
        "VSI-Bench"
      ]
    },
    "publishedAt": "2025-05-30T10:16:41.000Z",
    "title": "Learning from Videos for 3D World: Enhancing MLLMs with 3D Vision\n  Geometry Priors",
    "summary": "Previous research has investigated the application of Multimodal Large\nLanguage Models (MLLMs) in understanding 3D scenes by interpreting them as\nvideos. These approaches generally depend on comprehensive 3D data inputs, such\nas point clouds or reconstructed Bird's-Eye View (BEV) maps. In our research,\nwe advance this field by enhancing the capability of MLLMs to understand and\nreason in 3D spaces directly from video data, without the need for additional\n3D input. We propose a novel and efficient method, the Video-3D Geometry Large\nLanguage Model (VG LLM). Our approach employs a 3D visual geometry encoder that\nextracts 3D prior information from video sequences. This information is\nintegrated with visual tokens and fed into the MLLM. Extensive experiments have\nshown that our method has achieved substantial improvements in various tasks\nrelated to 3D scene understanding and spatial reasoning, all directly learned\nfrom video sources. Impressively, our 4B model, which does not rely on explicit\n3D data inputs, achieves competitive results compared to existing\nstate-of-the-art methods, and even surpasses the Gemini-1.5-Pro in the\nVSI-Bench evaluations.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.24625.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "646e2fcaf813cfe153f1af6c",
      "avatarUrl": "/avatars/2f87d0e5c071000990da29cd744bc03d.svg",
      "fullname": "Duo Zheng",
      "name": "zd11024",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2506.01413",
      "authors": [
        {
          "_id": "683e6aa057738c5cc3616d70",
          "user": {
            "_id": "6390525c00fb8ec4a424e0ff",
            "avatarUrl": "/avatars/4302571e2ef4a9875491221aa630a329.svg",
            "isPro": false,
            "fullname": "Yulei Qin",
            "user": "yolay",
            "type": "user"
          },
          "name": "Yulei Qin",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-06-03T03:23:18.288Z",
          "hidden": false
        },
        {
          "_id": "683e6aa057738c5cc3616d71",
          "name": "Gang Li",
          "hidden": false
        },
        {
          "_id": "683e6aa057738c5cc3616d72",
          "name": "Zongyi Li",
          "hidden": false
        },
        {
          "_id": "683e6aa057738c5cc3616d73",
          "name": "Zihan Xu",
          "hidden": false
        },
        {
          "_id": "683e6aa057738c5cc3616d74",
          "name": "Yuchen Shi",
          "hidden": false
        },
        {
          "_id": "683e6aa057738c5cc3616d75",
          "name": "Zhekai Lin",
          "hidden": false
        },
        {
          "_id": "683e6aa057738c5cc3616d76",
          "name": "Xiao Cui",
          "hidden": false
        },
        {
          "_id": "683e6aa057738c5cc3616d77",
          "name": "Ke Li",
          "hidden": false
        },
        {
          "_id": "683e6aa057738c5cc3616d78",
          "name": "Xing Sun",
          "hidden": false
        }
      ],
      "publishedAt": "2025-06-02T08:11:44.000Z",
      "submittedOnDailyAt": "2025-06-03T02:06:35.145Z",
      "title": "Programme de Risque d'Inclination de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Risque de Ris",
      "submittedOnDailyBy": {
        "_id": "6390525c00fb8ec4a424e0ff",
        "avatarUrl": "/avatars/4302571e2ef4a9875491221aa630a329.svg",
        "isPro": false,
        "fullname": "Yulei Qin",
        "user": "yolay",
        "type": "user"
      },
      "summary": "Les grands modèles de langue actuels (LLMs) rencontrent des problèmes lorsqu'ils reçoivent un commande complexe, surtout lorsque ces contraintes sont posées de manière séquentielle et structurée avec des points de coupure. On espère que la technique de \"chain-of-thought\" (CoT) puisse considérablement améliorer les capacités des LLMs. Cependant, une CoT basée sur des réécritures superficielles de patrons simples des instructions a un impact négatif sur le rendement. Cela se produit en raison de la faible capacité à identifier et à gérer les relations entre contraintes de type et dimension.\n\nDans ce contexte, nous proposons un méthode pour améliorer la capacité des LLMs à traiter des commandes complexes en utilisant l'escalade du calcul pour induire un raisonnement dans le traitement des instructions. Tout d'abord, en se basant sur la technologie actuelle, nous proposons une méthodologie pour obtenir des données représentatives de commandes complexes. Ensuite, nous utilisons un algorithme d'apprentissage par renforcement axé sur les règles provables (RL) pour encourager la formation de raisons dans les instructions. Pour aborder les caractéristiques superficielles et non pertinentes des raisons de commandes complexes, nous utilisons des contrastes au niveau d'échantillons pour imposer la nécessité d'une CoT supérieure. De plus, nous promouvons une transition stable vers une distribution de raisons familières à partir d'une réponse rapide des LLMs en utilisant le criblage des actions d'experts.\n\nUne évaluation large dans 7 cadres de référence confirme l'efficacité de notre méthode, montrant que l'un des LLMs de 1.5B peut atteindre le rendement d'un LLM de 8B avec un amélioration de 11.74%. Les codes et les données sont disponibles sur https://github.com/yuleiqin/RAIF.",
      "upvotes": 5,
      "discussionId": "683e6aa657738c5cc3616ecc",
      "projectPage": "https://huggingface.co/collections/yolay/raif-arxivorg-pdf-250601413-682b16e5c0c2fa9b73811369",
      "githubRepo": "https://github.com/yuleiqin/RAIF",
      "ai_summary": "A method is proposed to enhance large language models in handling complex instructions through incentivized reasoning and reinforcement learning, improving performance and reducing computational load.",
      "ai_keywords": [
        "chain-of-thought (CoT)",
        "reinforcement learning (RL)",
        "rule-centric reward signals",
        "sample-wise contrast",
        "behavior cloning",
        "instruction following",
        "decomposition of complex instructions"
      ]
    },
    "publishedAt": "2025-06-02T04:11:44.000Z",
    "title": "Incentivizing Reasoning for Advanced Instruction-Following of Large\n  Language Models",
    "summary": "Existing large language models (LLMs) face challenges of following complex\ninstructions, especially when multiple constraints are present and organized in\nparalleling, chaining, and branching structures. One intuitive solution, namely\nchain-of-thought (CoT), is expected to universally improve capabilities of\nLLMs. However, we find that the vanilla CoT exerts a negative impact on\nperformance due to its superficial reasoning pattern of simply paraphrasing the\ninstructions. It fails to peel back the compositions of constraints for\nidentifying their relationship across hierarchies of types and dimensions. To\nthis end, we propose a systematic method to boost LLMs in dealing with complex\ninstructions via incentivizing reasoning for test-time compute scaling. First,\nwe stem from the decomposition of complex instructions under existing\ntaxonomies and propose a reproducible data acquisition method. Second, we\nexploit reinforcement learning (RL) with verifiable rule-centric reward signals\nto cultivate reasoning specifically for instruction following. We address the\nshallow, non-essential nature of reasoning under complex instructions via\nsample-wise contrast for superior CoT enforcement. We also exploit behavior\ncloning of experts to facilitate steady distribution shift from fast-thinking\nLLMs to skillful reasoners. Extensive evaluations on seven comprehensive\nbenchmarks confirm the validity of the proposed method, where a 1.5B LLM\nachieves 11.74% gains with performance comparable to a 8B LLM. Codes and data\nare available at https://github.com/yuleiqin/RAIF.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.01413.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6390525c00fb8ec4a424e0ff",
      "avatarUrl": "/avatars/4302571e2ef4a9875491221aa630a329.svg",
      "fullname": "Yulei Qin",
      "name": "yolay",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 5
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.24452",
      "authors": [
        {
          "_id": "683e8abd8e6e97efe0bf20d9",
          "name": "Anda Tang",
          "hidden": false
        },
        {
          "_id": "683e8abd8e6e97efe0bf20da",
          "name": "Yiming Dong",
          "hidden": false
        },
        {
          "_id": "683e8abd8e6e97efe0bf20db",
          "user": {
            "_id": "6371128eafbe42caa5a5222b",
            "avatarUrl": "/avatars/c3b2ab35949c38aa3dfb2657a1300aac.svg",
            "isPro": false,
            "fullname": "Yutao Zeng",
            "user": "Taoer",
            "type": "user"
          },
          "name": "Yutao Zeng",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-03T08:39:15.864Z",
          "hidden": false
        },
        {
          "_id": "683e8abd8e6e97efe0bf20dc",
          "name": "zhou Xun",
          "hidden": false
        },
        {
          "_id": "683e8abd8e6e97efe0bf20dd",
          "name": "Zhouchen Lin",
          "hidden": false
        }
      ],
      "mediaUrls": [
        "https://cdn-uploads.huggingface.co/production/uploads/6371128eafbe42caa5a5222b/GfsrISs7G7K3rMBB1uws5.png",
        "https://cdn-uploads.huggingface.co/production/uploads/6371128eafbe42caa5a5222b/eQqbJxhzxMNKVlyoqQPRA.png",
        "https://cdn-uploads.huggingface.co/production/uploads/6371128eafbe42caa5a5222b/q1H4zp_jhjZw57UYMnECl.png",
        "https://cdn-uploads.huggingface.co/production/uploads/6371128eafbe42caa5a5222b/TpjaRwRNbGOzWfL7y5C4P.png"
      ],
      "publishedAt": "2025-05-30T10:38:03.000Z",
      "submittedOnDailyAt": "2025-06-03T04:32:00.766Z",
      "title": "Un des tailles d'étapes : l'apprentissage de la vitesse de traitement du flux de travail intégré",
      "submittedOnDailyBy": {
        "_id": "6371128eafbe42caa5a5222b",
        "avatarUrl": "/avatars/c3b2ab35949c38aa3dfb2657a1300aac.svg",
        "isPro": false,
        "fullname": "Yutao Zeng",
        "user": "Taoer",
        "type": "user"
      },
      "summary": "L'augmentation des coûts informatiques et la restriction des ressources ont mis en avant l'importance de l'apprentissage avec budget assigné. Ce cadre est conçu pour atteindre l'apprentissage optimal dans un ensemble d'entraînement réservé. L'ajustement du learning rate est la variable qui domine le rendement de différentes réseaux et tâches, surtout lors d'entraînements avec budget limité, où la découpe est principalement heuristique et manque une base théorique solide. De plus, la décision du learning rate optimal est basée sur une grande quantité de tests, ce qui réduit l'efficacité du processus d'entraînement. Dans cet article, nous proposons un ajustement du learning rate théoriquement fondé qui montre un rendement excellent dans différentes architectures et tâches, même sous un budget d'entraînement limité. Tout d'abord, nous construisons un nouveau cadre d'optimisation lié au budget et nous considérons la robustesse face à la variation des courbes. Dans ce cadre, nous pouvons obtenir un ajustement du learning rate Unifié avec Budget (UBA) théoriquement fondé. L'UBA est contrôlé par un seul paramètre unique φ, offrant un équilibre entre flexibilité et simplicité, et réduisant la nécessité d'optimisation numérique pour chaque réseau. De plus, nous établissons la relation théorique entre φ et le conditionnel, justifiant notre approche. Nous testons la convergence pour différents valeurs de φ. En se basant sur un analyse théorique et des résultats expérimentaux, nous fournissons des guides pratiques pour la sélection de φ. À travers de nombreux expériences, nous montrons que l'UBA dépasse les autres méthodes d'entraînement dans une large gamme de tâches visuelles et linguistiques, différentes architectures de réseau (comme ResNet et OLMo) et différents budgets d'itérations d'entraînement.",
      "upvotes": 5,
      "discussionId": "683e8abf8e6e97efe0bf2155",
      "ai_summary": "A unified budget-aware learning rate schedule is proposed to optimize training within limited iteration budgets, outperforming traditional schedules across various tasks and network architectures.",
      "ai_keywords": [
        "budgeted-iteration training",
        "learning rate schedules",
        "Unified Budget-Aware (UBA) schedule",
        "training budget-aware optimization framework",
        "robustness to landscape curvature variations",
        "condition number",
        "convergence",
        "ResNet",
        "OLMo"
      ]
    },
    "publishedAt": "2025-05-30T06:38:03.000Z",
    "title": "Stepsize anything: A unified learning rate schedule for\n  budgeted-iteration training",
    "summary": "The expanding computational costs and limited resources underscore the\ncritical need for budgeted-iteration training, which aims to achieve optimal\nlearning within predetermined iteration budgets.While learning rate schedules\nfundamentally govern the performance of different networks and tasks,\nparticularly in budgeted-iteration scenarios, their design remains largely\nheuristic, lacking theoretical foundations.In addition, the optimal learning\nrate schedule requires extensive trial-and-error selection, making the training\nprocess inefficient.In this work, we propose the Unified Budget-Aware (UBA)\nschedule, a theoretically grounded learning rate schedule that consistently\noutperforms commonly-used schedules among diverse architectures and tasks under\ndifferent constrained training budgets.First, we bridge the gap by constructing\na novel training budget-aware optimization framework, which explicitly accounts\nfor the robustness to landscape curvature variations.From this framework, we\nderive the UBA schedule, controlled by a single hyper-parameter varphi that\nprovides a trade-off between flexibility and simplicity, eliminating the need\nfor per-network numerical optimization. Moreover, we establish a theoretical\nconnection between varphi and the condition number, adding interpretation\nand justification to our approach. Besides, we prove the convergence for\ndifferent values of varphi.We offer practical guidelines for its selection\nvia theoretical analysis and empirical results.xtensive experimental results\nshow that UBA consistently surpasses the commonly-used schedules\nacross diverse vision and language tasks, spanning network architectures (e.g.,\nResNet, OLMo) and scales, under different training-iteration budgets.",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/6371128eafbe42caa5a5222b/GfsrISs7G7K3rMBB1uws5.png",
      "https://cdn-uploads.huggingface.co/production/uploads/6371128eafbe42caa5a5222b/eQqbJxhzxMNKVlyoqQPRA.png",
      "https://cdn-uploads.huggingface.co/production/uploads/6371128eafbe42caa5a5222b/q1H4zp_jhjZw57UYMnECl.png",
      "https://cdn-uploads.huggingface.co/production/uploads/6371128eafbe42caa5a5222b/TpjaRwRNbGOzWfL7y5C4P.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.24452.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6371128eafbe42caa5a5222b",
      "avatarUrl": "/avatars/c3b2ab35949c38aa3dfb2657a1300aac.svg",
      "fullname": "Yutao Zeng",
      "name": "Taoer",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2506.00338",
      "authors": [
        {
          "_id": "683e64eb3e5a54d05365ddc6",
          "user": {
            "_id": "61809f31a367a8f5351ef353",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/61809f31a367a8f5351ef353/s5eQ00YeoirakzE_rJ0cy.jpeg",
            "isPro": false,
            "fullname": "Yifan Peng",
            "user": "pyf98",
            "type": "user"
          },
          "name": "Yifan Peng",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-03T08:46:09.029Z",
          "hidden": false
        },
        {
          "_id": "683e64eb3e5a54d05365ddc7",
          "name": "Shakeel Muhammad",
          "hidden": false
        },
        {
          "_id": "683e64eb3e5a54d05365ddc8",
          "name": "Yui Sudo",
          "hidden": false
        },
        {
          "_id": "683e64eb3e5a54d05365ddc9",
          "name": "William Chen",
          "hidden": false
        },
        {
          "_id": "683e64eb3e5a54d05365ddca",
          "name": "Jinchuan Tian",
          "hidden": false
        },
        {
          "_id": "683e64eb3e5a54d05365ddcb",
          "name": "Chyi-Jiunn Lin",
          "hidden": false
        },
        {
          "_id": "683e64eb3e5a54d05365ddcc",
          "name": "Shinji Watanabe",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-31T01:44:44.000Z",
      "submittedOnDailyAt": "2025-06-03T01:39:05.927Z",
      "title": "OWSM v4 : Échelonnage des données et ajustements pour des modèles de voix de type Open Whisper",
      "submittedOnDailyBy": {
        "_id": "61809f31a367a8f5351ef353",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/61809f31a367a8f5351ef353/s5eQ00YeoirakzE_rJ0cy.jpeg",
        "isPro": false,
        "fullname": "Yifan Peng",
        "user": "pyf98",
        "type": "user"
      },
      "summary": "Les modèles de parole de style Open Whisper (OWSM) du projet utilisent des ressources académiques pour développer des modèles complets ouverts de parole basés sur la voix, mais les données d'entraînement ne sont pas suffisantes. Cet article renforce les OWSM en intégrant un grand ensemble de données de crawling web sous licence Creative Commons, appelé YODAS. Cependant, l'intégration de YODAS présente des problèmes tels que les étiquettes de langage négative et le décalage entre la voix et le texte. Pour aborder ces défis, un pipeline de nettoyage de données scalable a été développé en utilisant un ensemble de logiciels open, et un ensemble de données de 166 000 heures de voix dans 75 langues a été collecté. Avec cet ensemble de données de Cambodge et les données existantes de OWSM, un nouveau modèle OWSM v4 a été entraîné, améliorant significativement par rapport aux versions précédentes et surpassant notablement dans les benchmarks multilingues. De plus, le modèle atteint le sommet de la classe dans de nombreux scénarios comparé aux modèles industriels avancés tels que Whisper et MMS. En raison de sa publication, les données nettoyées, les modèles pré-entraînés et tous les cryptographiques liés sont publiés en ligne à travers le paquet de logiciels ESPnet.",
      "upvotes": 4,
      "discussionId": "683e64ec3e5a54d05365ddee",
      "projectPage": "https://www.wavlab.org/activities/2024/owsm/",
      "githubRepo": "https://github.com/espnet/espnet",
      "ai_summary": "The OWSM project is enhanced with a large-scale, cleaned web dataset, leading to improved multilingual speech models comparable to leading industrial models.",
      "ai_keywords": [
        "speach foundation models",
        "YODAS",
        "data-cleaning pipeline",
        "multilingual benchmarks",
        "Whisper",
        "MMS",
        "ESPnet toolkit"
      ]
    },
    "publishedAt": "2025-05-30T21:44:44.000Z",
    "title": "OWSM v4: Improving Open Whisper-Style Speech Models via Data Scaling and\n  Cleaning",
    "summary": "The Open Whisper-style Speech Models (OWSM) project has developed a series of\nfully open speech foundation models using academic-scale resources, but their\ntraining data remains insufficient. This work enhances OWSM by integrating\nYODAS, a large-scale web-crawled dataset with a Creative Commons license.\nHowever, incorporating YODAS is nontrivial due to its wild nature, which\nintroduces challenges such as incorrect language labels and audio-text\nmisalignments. To address this, we develop a scalable data-cleaning pipeline\nusing public toolkits, yielding a dataset with 166,000 hours of speech across\n75 languages. Our new series of OWSM v4 models, trained on this curated dataset\nalongside existing OWSM data, significantly outperform previous versions on\nmultilingual benchmarks. Our models even match or surpass frontier industrial\nmodels like Whisper and MMS in multiple scenarios. We will publicly release the\ncleaned YODAS data, pre-trained models, and all associated scripts via the\nESPnet toolkit.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.00338.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "61809f31a367a8f5351ef353",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/61809f31a367a8f5351ef353/s5eQ00YeoirakzE_rJ0cy.jpeg",
      "fullname": "Yifan Peng",
      "name": "pyf98",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 24
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.24183",
      "authors": [
        {
          "_id": "683e9a174de2ca71b8bc915b",
          "user": {
            "_id": "67de68f4f38795c545310088",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/8604Li6_OlATOsTdY9oHL.png",
            "isPro": false,
            "fullname": "Yaoyu Zhu",
            "user": "zhuyaoyu",
            "type": "user"
          },
          "name": "Yaoyu Zhu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-03T08:39:09.237Z",
          "hidden": false
        },
        {
          "_id": "683e9a174de2ca71b8bc915c",
          "user": {
            "_id": "62c581177b48ba0bb8cdb737",
            "avatarUrl": "/avatars/d1a85c28f13bb86481b6be80824eb1fa.svg",
            "isPro": false,
            "fullname": "di huang",
            "user": "dihuang",
            "type": "user"
          },
          "name": "Di Huang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-03T08:37:07.655Z",
          "hidden": false
        },
        {
          "_id": "683e9a174de2ca71b8bc915d",
          "name": "Hanqi Lyu",
          "hidden": false
        },
        {
          "_id": "683e9a174de2ca71b8bc915e",
          "name": "Xiaoyun Zhang",
          "hidden": false
        },
        {
          "_id": "683e9a174de2ca71b8bc915f",
          "name": "Chongxiao Li",
          "hidden": false
        },
        {
          "_id": "683e9a174de2ca71b8bc9160",
          "name": "Wenxuan Shi",
          "hidden": false
        },
        {
          "_id": "683e9a174de2ca71b8bc9161",
          "name": "Yutong Wu",
          "hidden": false
        },
        {
          "_id": "683e9a174de2ca71b8bc9162",
          "name": "Jianan Mu",
          "hidden": false
        },
        {
          "_id": "683e9a174de2ca71b8bc9163",
          "name": "Jinghua Wang",
          "hidden": false
        },
        {
          "_id": "683e9a174de2ca71b8bc9164",
          "name": "Yang Zhao",
          "hidden": false
        },
        {
          "_id": "683e9a174de2ca71b8bc9165",
          "name": "Pengwei Jin",
          "hidden": false
        },
        {
          "_id": "683e9a174de2ca71b8bc9166",
          "name": "Shuyao Cheng",
          "hidden": false
        },
        {
          "_id": "683e9a174de2ca71b8bc9167",
          "name": "Shengwen Liang",
          "hidden": false
        },
        {
          "_id": "683e9a174de2ca71b8bc9168",
          "name": "Xishan Zhang",
          "hidden": false
        },
        {
          "_id": "683e9a174de2ca71b8bc9169",
          "name": "Rui Zhang",
          "hidden": false
        },
        {
          "_id": "683e9a174de2ca71b8bc916a",
          "name": "Zidong Du",
          "hidden": false
        },
        {
          "_id": "683e9a174de2ca71b8bc916b",
          "name": "Qi Guo",
          "hidden": false
        },
        {
          "_id": "683e9a174de2ca71b8bc916c",
          "name": "Xing Hu",
          "hidden": false
        },
        {
          "_id": "683e9a174de2ca71b8bc916d",
          "name": "Yunji Chen",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-30T03:51:06.000Z",
      "submittedOnDailyAt": "2025-06-03T05:58:04.258Z",
      "title": "CodeV-R1 : Création de Verilog avec Notes de Motivo",
      "submittedOnDailyBy": {
        "_id": "62c581177b48ba0bb8cdb737",
        "avatarUrl": "/avatars/d1a85c28f13bb86481b6be80824eb1fa.svg",
        "isPro": false,
        "fullname": "di huang",
        "user": "dihuang",
        "type": "user"
      },
      "summary": "Les grands modèles de langue (LLMs) ont démontré leur efficacité dans l'apprentissage par renforcement basé sur des récompenses vérifiables (RLVR), réalisant des progrès dans des tâches claires et automatiquement vérifiables telles que la programmation de logiciel ou la résolution de problèmes mathématiques. Ces résultats ont été étendus au domaine de l'automatisation du design électronique (EDA), avec un accent particulier sur la génération automatique de langages de représentation de matériel (HDL) comme Verilog à partir de règles de langage naturel (NL). Cependant, trois problèmes principaux ont été identifiés : la rareté d'environnements de vérification précise et automatique, la manque de paires de code NL de haute qualité, et le coût élevé du RLVR. Pour aborder ces défis, nous présentons le cadre RLVR appelé CodeV-R1. Tout d'abord, nous développons un générateur de banques de tests de logique de base de données qui exécute des références monétaires et des vérifications de parité fortes. Ensuite, nous combinons des snapshots de Verilog de source ouverte avec des explications de NL générées par un modèle de langue, pour vérifier la cohérence entre le code, le NL et le code, et pour éliminer les exemples non cohérents pour générer des ensembles de données de haute qualité. Enfin, nous utilisons une pipeline d'entraînement en deux étapes de «RL après distillation» : nous effectuons une distillation initiale des compétences, et nous utilisons un nouvel algorithme de RLVR (DAPO) pour ajuster automatiquement les taux d'échantillonnage, réduisant ainsi les coûts d'entraînement. Sur cette base, CodeV-R1-7B atteint un taux de 68.6% sur VerilogEval v2 et un taux de 72.9% sur RTLLM v1.1, dépassant les meilleurs résultats précédents d'un intervalle de 12 à 20% et potentiellement dépassant le rendement de CodeV-R1-671B. Nous publions le modèle, la pipeline d'entraînement et les ensembles de données pour soutenir la recherche de la communauté EDA et de modèles de langue naturelle.",
      "upvotes": 4,
      "discussionId": "683e9a184de2ca71b8bc91b3",
      "projectPage": "https://iprc-dip.github.io/CodeV-R1",
      "ai_summary": "CodeV-R1, an RLVR framework for Verilog generation, achieves state-of-the-art performance in EDA using a rule-based testbench, round-trip data synthesis, and adaptive RLVR training.",
      "ai_keywords": [
        "reinforcement learning with verifiable reward",
        "RLVR",
        "electronic design automation",
        "EDA",
        "hardware description languages",
        "HDLs",
        "Verilog",
        "natural-language",
        "NL",
        "testbench generator",
        "equivalence checking",
        "round-trip data synthesis",
        "dataset",
        "two-stage training pipeline",
        "distillation",
        "adaptive DAPO",
        "VerilogEval",
        "RTLLM"
      ]
    },
    "publishedAt": "2025-05-29T23:51:06.000Z",
    "title": "CodeV-R1: Reasoning-Enhanced Verilog Generation",
    "summary": "Large language models (LLMs) trained via reinforcement learning with\nverifiable reward (RLVR) have achieved breakthroughs on tasks with explicit,\nautomatable verification, such as software programming and mathematical\nproblems. Extending RLVR to electronic design automation (EDA), especially\nautomatically generating hardware description languages (HDLs) like Verilog\nfrom natural-language (NL) specifications, however, poses three key challenges:\nthe lack of automated and accurate verification environments, the scarcity of\nhigh-quality NL-code pairs, and the prohibitive computation cost of RLVR. To\nthis end, we introduce CodeV-R1, an RLVR framework for training Verilog\ngeneration LLMs. First, we develop a rule-based testbench generator that\nperforms robust equivalence checking against golden references. Second, we\npropose a round-trip data synthesis method that pairs open-source Verilog\nsnippets with LLM-generated NL descriptions, verifies code-NL-code consistency\nvia the generated testbench, and filters out inequivalent examples to yield a\nhigh-quality dataset. Third, we employ a two-stage \"distill-then-RL\" training\npipeline: distillation for the cold start of reasoning abilities, followed by\nadaptive DAPO, our novel RLVR algorithm that can reduce training cost by\nadaptively adjusting sampling rate. The resulting model, CodeV-R1-7B, achieves\n68.6% and 72.9% pass@1 on VerilogEval v2 and RTLLM v1.1, respectively,\nsurpassing prior state-of-the-art by 12~20%, while matching or even exceeding\nthe performance of 671B DeepSeek-R1. We will release our model, training\npipeline, and dataset to facilitate research in EDA and LLM communities.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.24183.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "62c581177b48ba0bb8cdb737",
      "avatarUrl": "/avatars/d1a85c28f13bb86481b6be80824eb1fa.svg",
      "fullname": "di huang",
      "name": "dihuang",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.23504",
      "authors": [
        {
          "_id": "683e501c89dc42ba0515a4d8",
          "name": "Liyun Zhu",
          "hidden": false
        },
        {
          "_id": "683e501c89dc42ba0515a4d9",
          "name": "Qixiang Chen",
          "hidden": false
        },
        {
          "_id": "683e501c89dc42ba0515a4da",
          "name": "Xi Shen",
          "hidden": false
        },
        {
          "_id": "683e501c89dc42ba0515a4db",
          "name": "Xiaodong Cun",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-29T14:48:10.000Z",
      "submittedOnDailyAt": "2025-06-03T00:01:06.695Z",
      "title": "VAU-R1 : Améliorer la compréhension de la détection d'anomalies en utilisant l'apprentissage par répétition",
      "submittedOnDailyBy": {
        "_id": "63184c517ca1b876d99b7e0e",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63184c517ca1b876d99b7e0e/b-qDExoeJuDXK0cJBZKnz.jpeg",
        "isPro": false,
        "fullname": "Xiaodong Cun",
        "user": "vinthony",
        "type": "user"
      },
      "summary": "L'Understanding des Anomalies en Vidéo (UAV) est crucial dans divers domaines comme les villes intelligentes, la surveillance sécuritaire et les systèmes d'alerte des catastrophes, mais il en est confronté à des défis en raison de la nécessité de reconnaître les détails spatiaux et temporels et de soutenir des logiques robustes dans des situations complexes. Les méthodes actuelles présentent des limitations en termes d'interprétabilité et de compréhension facile des causes et contextes des événements anormaux. Ces limitations sont accentuées en raison de la manque de cadres de référence détaillés pour évaluer la capacité théorique de la détection d'anomalies. Pour faire face à ces défis, nous présentons UAV-R1. UAV-R1 est un cadre efficace basé sur des modèles de langage multimodal grands (MLLMs), qui renforce la théorie logique des anomalies par fine-tuning par renforcement. De plus, nous proposons UAV-Bench. UAV-Bench est un cadre de référence de type Chain-of-Thought adapté pour la théorie logique des anomalies, caractérisé par des questions multiples, des raisons détaillées, des notations temporelles et des captures explicatives. Les résultats des expériences montrent que UAV-R1 améliore significativement la précision des réponses aux questions, le développement temporel et la cohérence des raisons dans différents contextes. Ces méthodes et cadres de référence établissent une base solide pour la compréhension logique expliquable des images avec des anomalies. Le code est disponible sur https://github.com/GVCLab/VAU-R1.",
      "upvotes": 4,
      "discussionId": "683e502189dc42ba0515a5e1",
      "ai_summary": "VAU-R1 uses Multimodal Large Language Models with Reinforcement Fine-Tuning to enhance video anomaly reasoning, complemented by VAU-Bench, a Chain-of-Thought benchmark for evaluating anomaly understanding.",
      "ai_keywords": [
        "Multimodal Large Language Models (MLLMs)",
        "Reinforcement Fine-Tuning (RFT)",
        "Chain-of-Thought",
        "benchmark",
        "question answering",
        "temporal grounding",
        "reasoning coherence"
      ]
    },
    "publishedAt": "2025-05-29T10:48:10.000Z",
    "title": "VAU-R1: Advancing Video Anomaly Understanding via Reinforcement\n  Fine-Tuning",
    "summary": "Video Anomaly Understanding (VAU) is essential for applications such as smart\ncities, security surveillance, and disaster alert systems, yet remains\nchallenging due to its demand for fine-grained spatio-temporal perception and\nrobust reasoning under ambiguity. Despite advances in anomaly detection,\nexisting methods often lack interpretability and struggle to capture the causal\nand contextual aspects of abnormal events. This limitation is further\ncompounded by the absence of comprehensive benchmarks for evaluating reasoning\nability in anomaly scenarios. To address both challenges, we introduce VAU-R1,\na data-efficient framework built upon Multimodal Large Language Models (MLLMs),\nwhich enhances anomaly reasoning through Reinforcement Fine-Tuning (RFT).\nBesides, we propose VAU-Bench, the first Chain-of-Thought benchmark tailored\nfor video anomaly reasoning, featuring multiple-choice QA, detailed rationales,\ntemporal annotations, and descriptive captions. Empirical results show that\nVAU-R1 significantly improves question answering accuracy, temporal grounding,\nand reasoning coherence across diverse contexts. Together, our method and\nbenchmark establish a strong foundation for interpretable and reasoning-aware\nvideo anomaly understanding. Our code is available at\nhttps://github.com/GVCLab/VAU-R1.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.23504.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "63184c517ca1b876d99b7e0e",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63184c517ca1b876d99b7e0e/b-qDExoeJuDXK0cJBZKnz.jpeg",
      "fullname": "Xiaodong Cun",
      "name": "vinthony",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 323
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2505.21179",
      "authors": [
        {
          "_id": "6838c66dc60fb2fc462cec9f",
          "user": {
            "_id": "64d0eb731ed6649d70afb136",
            "avatarUrl": "/avatars/4c591c86c575c82760126c39af5a02b4.svg",
            "isPro": true,
            "fullname": "Chen Dar-Yen",
            "user": "ChenDY",
            "type": "user"
          },
          "name": "Dar-Yen Chen",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-02T07:47:40.163Z",
          "hidden": false
        },
        {
          "_id": "6838c66dc60fb2fc462ceca0",
          "user": {
            "_id": "638c81fa61eb51017518fa31",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/f0eCrzBrxz7Y9n25WkZ2v.png",
            "isPro": false,
            "fullname": "Hmrishav Bandyopadhyay",
            "user": "Hmrishav",
            "type": "user"
          },
          "name": "Hmrishav Bandyopadhyay",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-02T13:40:02.354Z",
          "hidden": false
        },
        {
          "_id": "6838c66dc60fb2fc462ceca1",
          "name": "Kai Zou",
          "hidden": false
        },
        {
          "_id": "6838c66dc60fb2fc462ceca2",
          "name": "Yi-Zhe Song",
          "hidden": false
        }
      ],
      "mediaUrls": [
        "https://cdn-uploads.huggingface.co/production/uploads/64d0eb731ed6649d70afb136/BtItSeWg7RJJDSWqnZWIB.mp4"
      ],
      "publishedAt": "2025-05-27T13:30:46.000Z",
      "submittedOnDailyAt": "2025-06-03T07:58:27.904Z",
      "title": "Normativación de atención : directives générales négatives pour les modèles de diffusion",
      "submittedOnDailyBy": {
        "_id": "64d0eb731ed6649d70afb136",
        "avatarUrl": "/avatars/4c591c86c575c82760126c39af5a02b4.svg",
        "isPro": true,
        "fullname": "Chen Dar-Yen",
        "user": "ChenDY",
        "type": "user"
      },
      "summary": "Guide des routines - la suppression explicite de caractéristiques de désaccord - est un problème de base dans les modèles d'expansion, surtout sous une richesse de données très faible. La guide de classe libre de passage (CFG) est généralement efficace, mais échoue sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression de passages strictes lorsque la prédiction par richesse s'améliore. La prédiction par richesse s'améliore sous la compression",
      "upvotes": 4,
      "discussionId": "6838c673c60fb2fc462cee10",
      "projectPage": "https://chendaryen.github.io/NAG.github.io/",
      "githubRepo": "https://github.com/ChenDarYen/Normalized-Attention-Guidance",
      "ai_summary": "Normalized Attention Guidance (NAG) enhances diffusion models by providing effective negative guidance across regimes and modalities without retraining.",
      "ai_keywords": [
        "negative guidance",
        "diffusion models",
        "few-step sampling",
        "Classifier-Free Guidance (CFG)",
        "Normalized Attention Guidance (NAG)",
        "attention space",
        "L1-based normalization",
        "extrapolation",
        "fidelity",
        "CLIP Score",
        "FID",
        "PFID",
        "ImageReward",
        "UNet",
        "DiT",
        "image",
        "video",
        "model-agnostic inference-time approach"
      ]
    },
    "publishedAt": "2025-05-27T09:30:46.000Z",
    "title": "Normalized Attention Guidance: Universal Negative Guidance for Diffusion\n  Model",
    "summary": "Negative guidance -- explicitly suppressing unwanted attributes -- remains a\nfundamental challenge in diffusion models, particularly in few-step sampling\nregimes. While Classifier-Free Guidance (CFG) works well in standard settings,\nit fails under aggressive sampling step compression due to divergent\npredictions between positive and negative branches. We present Normalized\nAttention Guidance (NAG), an efficient, training-free mechanism that applies\nextrapolation in attention space with L1-based normalization and refinement.\nNAG restores effective negative guidance where CFG collapses while maintaining\nfidelity. Unlike existing approaches, NAG generalizes across architectures\n(UNet, DiT), sampling regimes (few-step, multi-step), and modalities (image,\nvideo), functioning as a universal plug-in with minimal computational\noverhead. Through extensive experimentation, we demonstrate consistent\nimprovements in text alignment (CLIP Score), fidelity (FID, PFID), and\nhuman-perceived quality (ImageReward). Our ablation studies validate each\ndesign component, while user studies confirm significant preference for\nNAG-guided outputs. As a model-agnostic inference-time approach requiring no\nretraining, NAG provides effortless negative guidance for all modern diffusion\nframeworks -- pseudocode in the Appendix!",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/64d0eb731ed6649d70afb136/BtItSeWg7RJJDSWqnZWIB.mp4"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.21179.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "64d0eb731ed6649d70afb136",
      "avatarUrl": "/avatars/4c591c86c575c82760126c39af5a02b4.svg",
      "fullname": "Chen Dar-Yen",
      "name": "ChenDY",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 21
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2506.01084",
      "authors": [
        {
          "_id": "683ea4388be2e40086ea9056",
          "name": "Saibo Geng",
          "hidden": false
        },
        {
          "_id": "683ea4388be2e40086ea9057",
          "user": {
            "_id": "6420afc71ccd411979dc12dc",
            "avatarUrl": "/avatars/ee4a89ebc7a0716e21deaebc86e062e6.svg",
            "isPro": false,
            "fullname": "nathan ranchin",
            "user": "nathanrchn",
            "type": "user"
          },
          "name": "Nathan Ranchin",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-03T09:39:27.313Z",
          "hidden": false
        },
        {
          "_id": "683ea4388be2e40086ea9058",
          "name": "Yunzhen yao",
          "hidden": false
        },
        {
          "_id": "683ea4388be2e40086ea9059",
          "name": "Maxime Peyrard",
          "hidden": false
        },
        {
          "_id": "683ea4388be2e40086ea905a",
          "name": "Chris Wendler",
          "hidden": false
        },
        {
          "_id": "683ea4388be2e40086ea905b",
          "name": "Michael Gastpar",
          "hidden": false
        },
        {
          "_id": "683ea4388be2e40086ea905c",
          "name": "Robert West",
          "hidden": false
        }
      ],
      "mediaUrls": [
        "https://cdn-uploads.huggingface.co/production/uploads/5fce0cfeb3dbf216ad31836a/VnqCCx4RG5-62le1tQcaW.png",
        "https://cdn-uploads.huggingface.co/production/uploads/5fce0cfeb3dbf216ad31836a/EGD7DC-lDXkTXOLD6r0IP.png",
        "https://cdn-uploads.huggingface.co/production/uploads/5fce0cfeb3dbf216ad31836a/YDPF1VlfQ0Yfynq9peK5s.png",
        "https://cdn-uploads.huggingface.co/production/uploads/5fce0cfeb3dbf216ad31836a/QY0t5DXqhIVBWrLpJvZm8.png",
        "https://cdn-uploads.huggingface.co/production/uploads/5fce0cfeb3dbf216ad31836a/af0uwzA8bV-7byretzGwW.png"
      ],
      "publishedAt": "2025-06-01T17:03:02.000Z",
      "submittedOnDailyAt": "2025-06-03T06:05:31.112Z",
      "title": "zip2zip : La collection de mots applicable dans l'inférence des modèles de langage est fournie par la compression de tokens.",
      "submittedOnDailyBy": {
        "_id": "5fce0cfeb3dbf216ad31836a",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1625748458774-5fce0cfeb3dbf216ad31836a.png",
        "isPro": false,
        "fullname": "Saibo-creator",
        "user": "Saibo-creator",
        "type": "user"
      },
      "summary": "La efficacité de la tokenisation dans l'analyse de conversations joue un rôle crucial dans le rendement et les coûts des modèles de langage grands (LLMs). Cependant, la plupart des modèles utilisent un tokeniseur fixe avec un vocabulaire prédéfini optimisé pour un corpus général. Ce vocabulaire fixe ne s'adapte pas adéquatement aux entrées spécifiques de domaines ou de langues, ce qui contribue à augmenter la longueur des séquences de tokens, ce qui augmente les coûts de calcul. Nous présentons le cadre zip2zip. Ce cadre permet aux LLMs d'ajuster dynamiquement le vocabulaire de tokens pendant l'inférence, réduisant les tokens générés et accélérant la vitesse d'inférence. Le zip2zip est composé de trois composants importants : 1) un tokeniseur basé sur la compression Lempel-Ziv-Welch (LZW), qui compresse dynamiquement les tokens et les transforme en 'hyper tokens' réutilisables. 2) une couche d'embedding pour calculer des embeddings pour les nouveaux hyper tokens. 3) une variante du modèle de langage causal qui opère avec des séquences compressées d'hyper tokens. Nous avons démontré que grâce à zip2zip, le traitement de modèles LLMs antérieurs nécessite 10 heures de GPU. Par conséquent, les modèles LLMs avec zip2zip peuvent réduire la longueur des séquences d'entrée et de sortie de 20 à 60% en utilisant des hyper tokens, améliorant significativement la latence d'inférence.",
      "upvotes": 3,
      "discussionId": "683ea4398be2e40086ea90b7",
      "githubRepo": "https://github.com/epfl-dlab/zip2zip",
      "ai_summary": "A framework called zip2zip dynamically adjusts token vocabulary in LLMs at inference time using LZW compression, reducing token sequence length and improving inference speed.",
      "ai_keywords": [
        "LZW compression",
        "hypertokens",
        "embedding layer",
        "causal language modeling",
        "parameter-efficient finetuning"
      ]
    },
    "publishedAt": "2025-06-01T13:03:02.000Z",
    "title": "zip2zip: Inference-Time Adaptive Vocabularies for Language Models via\n  Token Compression",
    "summary": "Tokenization efficiency plays a critical role in the performance and cost of\nlarge language models (LLMs), yet most models rely on static tokenizers\noptimized for general-purpose corpora. These tokenizers' fixed vocabularies\noften fail to adapt to domain- or language-specific inputs, leading to longer\ntoken sequences and higher computational costs. We introduce zip2zip, a\nframework that enables LLMs to dynamically adjust token vocabulary at inference\ntime, allowing for fewer generated tokens and thus faster inference. zip2zip\nconsists of three key components: (1) a tokenizer based on Lempel-Ziv-Welch\n(LZW) compression that incrementally compresses tokens into reusable\n\"hypertokens\" on the fly; (2) an embedding layer that computes embeddings for\nnewly formed hypertokens at runtime; and (3) a causal language modeling variant\nthat trains the model to operate on hypertokenized, compressed sequences. We\nshow that an existing LLM can be zip2zip-fied in 10 GPU-hours via\nparameter-efficient finetuning. The resulting zip2zip LLMs effectively learn to\nuse hypertokens at inference time, reducing input and output sequence length by\n20-60\\%, with significant improvements in inference latency.",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/5fce0cfeb3dbf216ad31836a/VnqCCx4RG5-62le1tQcaW.png",
      "https://cdn-uploads.huggingface.co/production/uploads/5fce0cfeb3dbf216ad31836a/EGD7DC-lDXkTXOLD6r0IP.png",
      "https://cdn-uploads.huggingface.co/production/uploads/5fce0cfeb3dbf216ad31836a/YDPF1VlfQ0Yfynq9peK5s.png",
      "https://cdn-uploads.huggingface.co/production/uploads/5fce0cfeb3dbf216ad31836a/QY0t5DXqhIVBWrLpJvZm8.png",
      "https://cdn-uploads.huggingface.co/production/uploads/5fce0cfeb3dbf216ad31836a/af0uwzA8bV-7byretzGwW.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.01084.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "5fce0cfeb3dbf216ad31836a",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1625748458774-5fce0cfeb3dbf216ad31836a.png",
      "fullname": "Saibo-creator",
      "name": "Saibo-creator",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 8
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2506.00643",
      "authors": [
        {
          "_id": "683e61338ebad8b7519bc7f3",
          "user": {
            "_id": "63e3f57754f51ea342ce26be",
            "avatarUrl": "/avatars/df9d52c376bed6868d341bb006bec212.svg",
            "isPro": false,
            "fullname": "Weijie Xu",
            "user": "xwjzds",
            "type": "user"
          },
          "name": "Weijie Xu",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-06-03T02:43:01.430Z",
          "hidden": false
        },
        {
          "_id": "683e61338ebad8b7519bc7f4",
          "name": "Shixian Cui",
          "hidden": false
        },
        {
          "_id": "683e61338ebad8b7519bc7f5",
          "name": "Xi Fang",
          "hidden": false
        },
        {
          "_id": "683e61338ebad8b7519bc7f6",
          "name": "Chi Xue",
          "hidden": false
        },
        {
          "_id": "683e61338ebad8b7519bc7f7",
          "name": "Stephanie Eckman",
          "hidden": false
        },
        {
          "_id": "683e61338ebad8b7519bc7f8",
          "name": "Chandan Reddy",
          "hidden": false
        }
      ],
      "mediaUrls": [
        "https://cdn-uploads.huggingface.co/production/uploads/63e3f57754f51ea342ce26be/lDZvyKeHC66Fk1-x6VgbB.png",
        "https://cdn-uploads.huggingface.co/production/uploads/63e3f57754f51ea342ce26be/l-YQ7eiVk7rb7n3Hi51p5.png"
      ],
      "publishedAt": "2025-05-31T17:14:21.000Z",
      "submittedOnDailyAt": "2025-06-03T01:22:58.893Z",
      "title": "SATA-BENCH : Benchmark de Multi-sélection\nQuestion",
      "submittedOnDailyBy": {
        "_id": "63e3f57754f51ea342ce26be",
        "avatarUrl": "/avatars/df9d52c376bed6868d341bb006bec212.svg",
        "isPro": false,
        "fullname": "Weijie Xu",
        "user": "xwjzds",
        "type": "user"
      },
      "summary": "Les modèles de langage grands (LLMs) augmentent leur évaluation dans des tâches de réponses multiples à une réponse unique, mais il est nécessaire de spécifier toutes les réponses correctes pour résoudre de nombreux problèmes de la réalité. Cette capacité est encore peu étudiée. Nous présentons SATA-BENCH, le premier cadre de référence professionnel pour évaluer les questions de sélection multiple (SATA), pour évaluer les LLMs dans différentes domaines comme la lecture, le droit et la bioinformatique. Selon l'évaluation de 27 modèles open-source et sous contrat de droits d'auteur, des erreurs significatives ont été détectées : même les modèles les plus puissants n'ont pas un haut pourcentage de concordance correcte, c'est-à-dire, les LLMs ne peuvent pas se confiancer à identifier toutes les réponses correctes. Cette limitation génère deux problèmes essentiels : le biais de sélection - les modèles préfèrent une option sans regarder le contenu, et le biais du compteur - les modèles ne peuvent pas prédire la quantité de réponses correctes. Pour résoudre ces problèmes, nous proposons Choice Funnel, un modèle d'interprétation qui combine le biais de token et la discrimination adaptative. Choice Funnel peut augmenter la concordance correcte de 29% comparativement et réduire les coûts d'inférence de plus de 64%. Cette découverte clairement montre les limitations fondamentales des LLMs et introduit un nouveau cadre de travail pour diagnostiquer et améliorer la logique de réponses multiples. La publication de SATA-BENCH et Choice Funnel encourage le développement des LLMs pour prendre des décisions robustes dans diverses applications de réponses multiples.",
      "upvotes": 3,
      "discussionId": "683e61358ebad8b7519bc8cf",
      "githubRepo": "https://github.com/sata-bench/sata-bench",
      "ai_summary": "SATA-BENCH evaluates LLMs on multi-answer questions, revealing selections biases and proposing Choice Funnel to improve accuracy and reduce costs in multi-answer reasoning tasks.",
      "ai_keywords": [
        "Select All That Apply (SATA) questions",
        "SATA-BENCH",
        "token debiasing",
        "adaptive thresholding",
        "Choice Funnel"
      ]
    },
    "publishedAt": "2025-05-31T13:14:21.000Z",
    "title": "SATA-BENCH: Select All That Apply Benchmark for Multiple Choice\n  Questions",
    "summary": "Large language models (LLMs) are increasingly evaluated on single-answer\nmultiple-choice tasks, yet many real-world problems require identifying all\ncorrect answers from a set of options. This capability remains underexplored.\nWe introduce SATA-BENCH, the first dedicated benchmark for evaluating LLMs on\nSelect All That Apply (SATA) questions across diverse domains, including\nreading comprehension, law, and biomedicine. Our evaluation of 27 open-source\nand proprietary models reveals a significant gap: even the strongest model\nachieves only 41.8% exact match, exposing LLMs' inability to reliably identify\nall correct answers. We find that this weakness stems from two core challenges:\nselection bias - models favor certain choices regardless of content, and count\nbias - models fail to predict the correct number of answers. To address these\nissues, we propose Choice Funnel, a decoding strategy that combines token\ndebiasing with adaptive thresholding to guide models toward complete and\naccurate selections. Choice Funnel achieves up to 29% higher exact match than\ncompetitive baselines while reducing inference cost by over 64%. Our findings\nexpose fundamental limitations in current LLMs and introduce a new framework\nfor diagnosing and improving multi-answer reasoning. We release SATA-BENCH and\nChoice Funnel to promote LLM development for robust decision-making in\nrealistic, multi-answer applications.",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/63e3f57754f51ea342ce26be/lDZvyKeHC66Fk1-x6VgbB.png",
      "https://cdn-uploads.huggingface.co/production/uploads/63e3f57754f51ea342ce26be/l-YQ7eiVk7rb7n3Hi51p5.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.00643.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "63e3f57754f51ea342ce26be",
      "avatarUrl": "/avatars/df9d52c376bed6868d341bb006bec212.svg",
      "fullname": "Weijie Xu",
      "name": "xwjzds",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 10
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.24842",
      "authors": [
        {
          "_id": "683e9da357738c5cc36d5175",
          "name": "Harsh Chaudhari",
          "hidden": false
        },
        {
          "_id": "683e9da357738c5cc36d5176",
          "name": "Jamie Hayes",
          "hidden": false
        },
        {
          "_id": "683e9da357738c5cc36d5177",
          "name": "Matthew Jagielski",
          "hidden": false
        },
        {
          "_id": "683e9da357738c5cc36d5178",
          "name": "Ilia Shumailov",
          "hidden": false
        },
        {
          "_id": "683e9da357738c5cc36d5179",
          "name": "Milad Nasr",
          "hidden": false
        },
        {
          "_id": "683e9da357738c5cc36d517a",
          "name": "Alina Oprea",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-30T17:41:58.000Z",
      "submittedOnDailyAt": "2025-06-03T05:35:48.034Z",
      "title": "Injection jusqu'au chauffage continu de biais adverses dans les modèles de langage",
      "submittedOnDailyBy": {
        "_id": "6475c2794766357252e69e9f",
        "avatarUrl": "/avatars/757ed789423113369868e972f21ce559.svg",
        "isPro": false,
        "fullname": "i",
        "user": "iliashum",
        "type": "user"
      },
      "summary": "Les résultats du modèle sont renvoyés.",
      "upvotes": 3,
      "discussionId": "683e9da457738c5cc36d51b2",
      "ai_summary": "Adversarial injection of biased content can significantly propagate from teacher to student models during distillation, leading to frequent biased responses in both targeted and untargeted scenarios across various bias types and modalities.",
      "ai_keywords": [
        "model distillation",
        "language models",
        "adversarial manipulation",
        "data poisoning",
        "bias injection",
        "Untargeted Propagation",
        "Targeted Propagation",
        "perplexity filtering",
        "bias detection systems",
        "LLM-based autorater frameworks"
      ]
    },
    "publishedAt": "2025-05-30T13:41:58.000Z",
    "title": "Cascading Adversarial Bias from Injection to Distillation in Language\n  Models",
    "summary": "Model distillation has become essential for creating smaller, deployable\nlanguage models that retain larger system capabilities. However, widespread\ndeployment raises concerns about resilience to adversarial manipulation. This\npaper investigates vulnerability of distilled models to adversarial injection\nof biased content during training. We demonstrate that adversaries can inject\nsubtle biases into teacher models through minimal data poisoning, which\npropagates to student models and becomes significantly amplified. We propose\ntwo propagation modes: Untargeted Propagation, where bias affects multiple\ntasks, and Targeted Propagation, focusing on specific tasks while maintaining\nnormal behavior elsewhere. With only 25 poisoned samples (0.25% poisoning\nrate), student models generate biased responses 76.9% of the time in targeted\nscenarios - higher than 69.4% in teacher models. For untargeted propagation,\nadversarial bias appears 6x-29x more frequently in student models on unseen\ntasks. We validate findings across six bias types (targeted advertisements,\nphishing links, narrative manipulations, insecure coding practices), various\ndistillation methods, and different modalities spanning text and code\ngeneration. Our evaluation reveals shortcomings in current defenses -\nperplexity filtering, bias detection systems, and LLM-based autorater\nframeworks - against these attacks. Results expose significant security\nvulnerabilities in distilled models, highlighting need for specialized\nsafeguards. We propose practical design principles for building effective\nadversarial bias mitigation strategies.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.24842.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6475c2794766357252e69e9f",
      "avatarUrl": "/avatars/757ed789423113369868e972f21ce559.svg",
      "fullname": "i",
      "name": "iliashum",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 4
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2505.24086",
      "authors": [
        {
          "_id": "683ebe67140f76a0a5485d51",
          "user": {
            "_id": "668e6b47f59574a8ec2ae078",
            "avatarUrl": "/avatars/1cbc80ee4fb4a832783bd3dbee032d6e.svg",
            "isPro": false,
            "fullname": "Zeeshan Khan",
            "user": "zk95",
            "type": "user"
          },
          "name": "Zeeshan Khan",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-03T09:39:29.585Z",
          "hidden": false
        },
        {
          "_id": "683ebe67140f76a0a5485d52",
          "name": "Shizhe Chen",
          "hidden": false
        },
        {
          "_id": "683ebe67140f76a0a5485d53",
          "name": "Cordelia Schmid",
          "hidden": false
        }
      ],
      "mediaUrls": [
        "https://cdn-uploads.huggingface.co/production/uploads/638878e0c9a44f05de452e91/V8gVhCAESrievXk5RWL_7.png"
      ],
      "publishedAt": "2025-05-30T00:13:36.000Z",
      "submittedOnDailyAt": "2025-06-03T07:53:33.269Z",
      "title": "Compétiteur Anison : Pionnier pour la génération d'images à partir de texte d'objets synthétiques",
      "submittedOnDailyBy": {
        "_id": "638878e0c9a44f05de452e91",
        "avatarUrl": "/avatars/5748195a0ac761e2776548aabc3a53e3.svg",
        "isPro": false,
        "fullname": "Matthieu Futeral",
        "user": "matthieufp",
        "type": "user"
      },
      "summary": "Composition et Association : Traiter de gérer la disposition de nouveaux objets complexes dans la génération d'images à partir de texte est un problème important dans les modèles de conversion de texte en images (T2I). Les méthodes basées sur l'autorégulation actuelles peuvent améliorer la disposition d'objets en utilisant des contraintes spatiales avec l'autorégulation bidimensionnelle, mais perdent facilement de l'information de position tridimensionnelle, de qualité et de cohérence. Dans cet article, nous présentons un nouveau cadre de travail appelé \"ComposeAnything\" pour améliorer la génération d'images basée sur la logique de connexion des modèles T2I sans nécessiter de réentraîner les modèles. Notre approche utilise le pouvoir de la capacité logique de connexion des modèles de langage grand (LLM) pour générer une autorégulation 2.5D significative à partir du texte. Cela ajoute des informations de profondeur aux boîtes bidimensionnelles d'objets et améliore la capture de détails. En se basant sur cette autorégulation, nous générons une approximation générale de la composition d'objets intéressants dans l'espace et la profondeur, et utilisons un modèle T2I basé sur des configurations conçus pour remplacer l'initialisation aléatoire probabiliste du modèle T2I. Ce modèle permet la génération suave d'objets avec une composition et un fond cohérent en fortifiant les objets et en traitant la dé-bruitage contrôlé spatialement, permettant également la refinement de modèles incorrects. ComposeAnything montre un rendement supérieur aux méthodes les plus avancées en termes de disposition spatiale 2D/3D, de grand nombre d'objets et d'effets de surface sur les benchmarks T2I-CompBench et NSR-1K. Il montre également dans les évaluations humaines que notre modèle reflète fidèlement la qualité des images à partir du texte.",
      "upvotes": 3,
      "discussionId": "683ebe6a140f76a0a5485e06",
      "ai_summary": "ComposeAnything improves text-to-image generation by using LLMs for 2.5D semantic layouts, enhancing object placement and coherence in diffusion-based models.",
      "ai_keywords": [
        "LLMs",
        "chain-of-thought reasoning",
        "2.5D semantic layouts",
        "object bounding boxes",
        "depth information",
        "spatial and depth aware",
        "coarse composite",
        "denoising process",
        "object prior reinforcement",
        "spatial-controlled denoising",
        "diffusion-based T2I models",
        "T2I-CompBench",
        "NSR-1K benchmarks"
      ]
    },
    "publishedAt": "2025-05-29T20:13:36.000Z",
    "title": "ComposeAnything: Composite Object Priors for Text-to-Image Generation",
    "summary": "Generating images from text involving complex and novel object arrangements\nremains a significant challenge for current text-to-image (T2I) models.\nAlthough prior layout-based methods improve object arrangements using spatial\nconstraints with 2D layouts, they often struggle to capture 3D positioning and\nsacrifice quality and coherence. In this work, we introduce ComposeAnything, a\nnovel framework for improving compositional image generation without retraining\nexisting T2I models. Our approach first leverages the chain-of-thought\nreasoning abilities of LLMs to produce 2.5D semantic layouts from text,\nconsisting of 2D object bounding boxes enriched with depth information and\ndetailed captions. Based on this layout, we generate a spatial and depth aware\ncoarse composite of objects that captures the intended composition, serving as\na strong and interpretable prior that replaces stochastic noise initialization\nin diffusion-based T2I models. This prior guides the denoising process through\nobject prior reinforcement and spatial-controlled denoising, enabling seamless\ngeneration of compositional objects and coherent backgrounds, while allowing\nrefinement of inaccurate priors. ComposeAnything outperforms state-of-the-art\nmethods on the T2I-CompBench and NSR-1K benchmarks for prompts with 2D/3D\nspatial arrangements, high object counts, and surreal compositions. Human\nevaluations further demonstrate that our model generates high-quality images\nwith compositions that faithfully reflect the text.",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/638878e0c9a44f05de452e91/V8gVhCAESrievXk5RWL_7.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.24086.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "638878e0c9a44f05de452e91",
      "avatarUrl": "/avatars/5748195a0ac761e2776548aabc3a53e3.svg",
      "fullname": "Matthieu Futeral",
      "name": "matthieufp",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 3
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2506.01952",
      "authors": [
        {
          "_id": "683ebebfb5052f5f8741c7f5",
          "user": {
            "_id": "6527b37c0ae663e384eb1b85",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6527b37c0ae663e384eb1b85/zKWa8h6YU4BWfcitpM5Pl.png",
            "isPro": true,
            "fullname": "Atsuyuki Miyai",
            "user": "AtsuMiyai",
            "type": "user"
          },
          "name": "Atsuyuki Miyai",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-03T09:39:31.731Z",
          "hidden": false
        },
        {
          "_id": "683ebebfb5052f5f8741c7f6",
          "name": "Zaiying Zhao",
          "hidden": false
        },
        {
          "_id": "683ebebfb5052f5f8741c7f7",
          "name": "Kazuki Egashira",
          "hidden": false
        },
        {
          "_id": "683ebebfb5052f5f8741c7f8",
          "name": "Atsuki Sato",
          "hidden": false
        },
        {
          "_id": "683ebebfb5052f5f8741c7f9",
          "name": "Tatsumi Sunada",
          "hidden": false
        },
        {
          "_id": "683ebebfb5052f5f8741c7fa",
          "name": "Shota Onohara",
          "hidden": false
        },
        {
          "_id": "683ebebfb5052f5f8741c7fb",
          "name": "Hiromasa Yamanishi",
          "hidden": false
        },
        {
          "_id": "683ebebfb5052f5f8741c7fc",
          "name": "Mashiro Toyooka",
          "hidden": false
        },
        {
          "_id": "683ebebfb5052f5f8741c7fd",
          "name": "Kunato Nishina",
          "hidden": false
        },
        {
          "_id": "683ebebfb5052f5f8741c7fe",
          "name": "Ryoma Maeda",
          "hidden": false
        },
        {
          "_id": "683ebebfb5052f5f8741c7ff",
          "name": "Kiyoharu Aizawa",
          "hidden": false
        },
        {
          "_id": "683ebebfb5052f5f8741c800",
          "name": "Toshihiko Yamasaki",
          "hidden": false
        }
      ],
      "publishedAt": "2025-06-02T17:59:45.000Z",
      "submittedOnDailyAt": "2025-06-03T07:52:49.121Z",
      "title": "WebCorearnya: Évaluation d'agents de navigateurs dans des tâches web pratiques et complexes",
      "submittedOnDailyBy": {
        "_id": "6527b37c0ae663e384eb1b85",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6527b37c0ae663e384eb1b85/zKWa8h6YU4BWfcitpM5Pl.png",
        "isPro": true,
        "fullname": "Atsuyuki Miyai",
        "user": "AtsuMiyai",
        "type": "user"
      },
      "summary": "Une intelligence artificielle basée sur des modèles de langue profonde (LLM) dans un navigateur web peut manipuler le navigateur comme un être humain et automatiser diverses tâches quotidiennes de manière très transparente. Avec l'augmentation des intelligences artificielles dans le navigateur web, des questions importantes sont soulevées sur si ces systèmes peuvent gérer avec précision des tâches longues et complexes ou des tâches que la personne évite elle-même, comme des tâches domestiques. Dans cet article, on présente WebChoreArena, un nouveau cadre de référence completement reproductible. Ce cadre de référence comprend 532 tâches bien sélectionnées et s'étend au-delà des tâches communes du navigateur pour aborder des tâches plus avancées et complexes. WebChoreArena intègre de manière systématique trois défis clés : (i) tâches de mémoire grande, nécessité de recherche précise de beaucoup d'information ; (ii) tâches de calcul, nécessité de calculs mathématiques précis ; (iii) tâches de modélisation à long terme, nécessité de modéliser entre plusieurs pages web. WebChoreArena a été largement appliqué dans quatre environnements de simulation d'agents web completament reproductibles, garantissant une grande précision et permettant une comparaison directe avec le cadre de référence WebArena existant. Cela fournit une importante vision des développements des agents. Les résultats des expériences montrent que GPT-4o, Claude 3.7 Sonnet et Gemini 2.5 Pro ont montré une amélioration significative de leur rendement dans WebChoreArena, ce qui démontre le développement des modèles de langue profonde. Ces résultats indiquent que WebChoreArena est le cadre de référence idéal pour mesurer le développement des modèles de langue profonde les plus avancés. Cependant, dans le cas de Gemini 2.5 Pro, il est observé qu'il reste un plus grand potentiel d'amélioration par rapport à WebArena, ce qui est clairement démontré par le défi accru fourni par WebChoreArena.",
      "upvotes": 2,
      "discussionId": "683ebec0b5052f5f8741c847",
      "ai_summary": "WebChoreArena, a new benchmark comprising 532 tasks, extends the scope of WebArena to more complex and tedious web browsing tasks, measuring advancements in LLM capabilities.",
      "ai_keywords": [
        "LLM",
        "Web browsing agent",
        "WebChoreArena",
        "benchmark",
        "general browsing",
        "Massive Memory tasks",
        "Calculation tasks",
        "Long-Term Memory tasks",
        "WebArena simulation environments",
        "GPT-4o",
        "Claude 3.7 Sonnet",
        "Gemini 2.5 Pro"
      ]
    },
    "publishedAt": "2025-06-02T13:59:45.000Z",
    "title": "WebChoreArena: Evaluating Web Browsing Agents on Realistic Tedious Web\n  Tasks",
    "summary": "Powered by a large language model (LLM), a web browsing agent operates web\nbrowsers in a human-like manner and offers a highly transparent path toward\nautomating a wide range of everyday tasks. As web agents become increasingly\ncapable and demonstrate proficiency in general browsing tasks, a critical\nquestion emerges: Can they go beyond general browsing to robustly handle tasks\nthat are tedious and complex, or chores that humans often avoid doing\nthemselves? In this paper, we introduce WebChoreArena, a new fully reproducible\nbenchmark comprising 532 carefully curated tasks designed to extend the scope\nof WebArena beyond general browsing to more labor-intensive and tedious tasks.\nWebChoreArena systematically integrates three key challenges: (i) Massive\nMemory tasks requiring accurate retrieval of large amounts of information in\nthe observations, (ii) Calculation tasks demanding precise mathematical\nreasoning, and (iii) Long-Term Memory tasks necessitating long-term memory\nacross multiple webpages. Built on top of the fully reproducible and widely\nadopted four WebArena simulation environments, WebChoreArena ensures strict\nreproducibility and enables fair, direct comparisons with the established\nWebArena benchmark, offering key insights into agent progress. Our experimental\nresults demonstrate that as LLMs evolve, represented by GPT-4o, Claude 3.7\nSonnet, and Gemini 2.5 Pro, significant improvements in performance are\nobserved on WebChoreArena. These findings suggest that WebChoreArena is\nwell-suited to measure the advancement of state-of-the-art LLMs with greater\nclarity. Nevertheless, the results also indicate that even with Gemini 2.5 Pro,\nthere remains substantial room for improvement compared to WebArena,\nhighlighting the increased challenges posed by WebChoreArena.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.01952.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6527b37c0ae663e384eb1b85",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6527b37c0ae663e384eb1b85/zKWa8h6YU4BWfcitpM5Pl.png",
      "fullname": "Atsuyuki Miyai",
      "name": "AtsuMiyai",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 4
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2506.01484",
      "authors": [
        {
          "_id": "683eb167b3f3b41729e1d2e8",
          "name": "Shuzhou Yuan",
          "hidden": false
        },
        {
          "_id": "683eb167b3f3b41729e1d2e9",
          "name": "Ercong Nie",
          "hidden": false
        },
        {
          "_id": "683eb167b3f3b41729e1d2ea",
          "name": "Lukas Kouba",
          "hidden": false
        },
        {
          "_id": "683eb167b3f3b41729e1d2eb",
          "name": "Ashish Yashwanth Kangen",
          "hidden": false
        },
        {
          "_id": "683eb167b3f3b41729e1d2ec",
          "name": "Helmut Schmid",
          "hidden": false
        },
        {
          "_id": "683eb167b3f3b41729e1d2ed",
          "name": "Hinrich Schutze",
          "hidden": false
        },
        {
          "_id": "683eb167b3f3b41729e1d2ee",
          "name": "Michael Farber",
          "hidden": false
        }
      ],
      "mediaUrls": [
        "https://cdn-uploads.huggingface.co/production/uploads/662ce44c8b8705f30371fba8/7b4Mhx2INBhnjYZc55g7h.png"
      ],
      "publishedAt": "2025-06-02T09:45:05.000Z",
      "submittedOnDailyAt": "2025-06-03T08:19:44.458Z",
      "title": "\"LLM dans la Boucle : Création du Dataset Paladehait et Correspondance avec le Speech du Coeur\nDétoxification : Création de Modèles d'Élimination de Toxins et Correspondance avec le Speech du Coeur\"",
      "submittedOnDailyBy": {
        "_id": "662ce44c8b8705f30371fba8",
        "avatarUrl": "/avatars/b96a25a8c124e7caa9de06b7188bdc15.svg",
        "isPro": false,
        "fullname": "Shuzhou Yuan",
        "user": "shuzyuan",
        "type": "user"
      },
      "summary": "La détoxification, la tâche de vérifier des mots nocifs dans des textes innocents, a acquis une importance croissante en ligne grâce à l'augmentation du contenu toxique. Cependant, les ensembles de données parallèles de haute qualité appropriés pour la détoxification, surtout pour le langage odieux, sont rares en raison du coût élevé des annotations humaines et de la sensibilité. Dans cet article, nous proposons un nouveau flux de travail dans le boucle d'un modèle de langage de machine (LLM-in-the-loop) pour utiliser GPT-4o-mini pour la détoxification. Initialement, nous avons remplacé les annotations humaines par un LLM et reproduit le flux de travail ParaDetox, démontrant que l'utilisation d'un LLM peut atteindre un rendement comparable aux annotations humaines. En nous basant sur ce résultat, nous avons construit un grand ensemble de données parallèles appelé PARADEHATE, conçu spécifiquement pour la détoxification du langage odieux. PARADEHATE comprend plus de 8K pairs de textes odieux/non odieux et est rendu public comme un benchmark pour évaluer divers méthodes. Les résultats expérimentaux montrent que les modèles fine-tunés sur PARADEHATE (par exemple, BART) présentent un meilleur rendement en termes de précision de style, de préservation du contenu et de fluidité, et démontrent également la versatilité et l'efficacité des textes détoxifiés générés par un LLM.",
      "upvotes": 2,
      "discussionId": "683eb169b3f3b41729e1d370",
      "ai_summary": "A novel pipeline using GPT-4o-mini generates a large-scale dataset for hate speech detoxification, improving baseline model performance in style accuracy, content preservation, and fluency.",
      "ai_keywords": [
        "LLM-in-the-loop",
        "GPT-4o-mini",
        "ParaDetox",
        "PARADEHATE",
        "BART",
        "style accuracy",
        "content preservation",
        "fluency"
      ]
    },
    "publishedAt": "2025-06-02T05:45:05.000Z",
    "title": "LLM in the Loop: Creating the PARADEHATE Dataset for Hate Speech\n  Detoxification",
    "summary": "Detoxification, the task of rewriting harmful language into non-toxic text,\nhas become increasingly important amid the growing prevalence of toxic content\nonline. However, high-quality parallel datasets for detoxification, especially\nfor hate speech, remain scarce due to the cost and sensitivity of human\nannotation. In this paper, we propose a novel LLM-in-the-loop pipeline\nleveraging GPT-4o-mini for automated detoxification. We first replicate the\nParaDetox pipeline by replacing human annotators with an LLM and show that the\nLLM performs comparably to human annotation. Building on this, we construct\nPARADEHATE, a large-scale parallel dataset specifically for hatespeech\ndetoxification. We release PARADEHATE as a benchmark of over 8K hate/non-hate\ntext pairs and evaluate a wide range of baseline methods. Experimental results\nshow that models such as BART, fine-tuned on PARADEHATE, achieve better\nperformance in style accuracy, content preservation, and fluency, demonstrating\nthe effectiveness of LLM-generated detoxification text as a scalable\nalternative to human annotation.",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/662ce44c8b8705f30371fba8/7b4Mhx2INBhnjYZc55g7h.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.01484.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "662ce44c8b8705f30371fba8",
      "avatarUrl": "/avatars/b96a25a8c124e7caa9de06b7188bdc15.svg",
      "fullname": "Shuzhou Yuan",
      "name": "shuzyuan",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2506.00512",
      "authors": [
        {
          "_id": "683eb1f54c5b9f381d5b42ad",
          "name": "Yang Zheng",
          "hidden": false
        },
        {
          "_id": "683eb1f54c5b9f381d5b42ae",
          "name": "Mengqi Huang",
          "hidden": false
        },
        {
          "_id": "683eb1f54c5b9f381d5b42af",
          "user": {
            "_id": "6629d7c9fa14eaccf07d8633",
            "avatarUrl": "/avatars/dceb2f6c804c583adf15a3536c8c995b.svg",
            "isPro": false,
            "fullname": "Nan Chen",
            "user": "CNcreator0331",
            "type": "user"
          },
          "name": "Nan Chen",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-03T08:36:45.797Z",
          "hidden": false
        },
        {
          "_id": "683eb1f54c5b9f381d5b42b0",
          "name": "Zhendong Mao",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-31T11:11:55.000Z",
      "submittedOnDailyAt": "2025-06-03T07:11:36.988Z",
      "title": "Pro3D-Editor : Perspectives avancées qui correspondent à un vaste panorama et édition précise de 3D",
      "submittedOnDailyBy": {
        "_id": "6629d7c9fa14eaccf07d8633",
        "avatarUrl": "/avatars/dceb2f6c804c583adf15a3536c8c995b.svg",
        "isPro": false,
        "fullname": "Nan Chen",
        "user": "CNcreator0331",
        "type": "user"
      },
      "summary": "Le guide d'édition 3D a pour objectif d'éditer avec une grande précision l'aire 3D, en maintenant l'association contextuelle. Cette technologie a un grand potentiel dans des applications pratiques, non seulement dans les jeux 3D mais également dans la production de films. Les méthodes actuelles éditent généralement indépendamment de la vision 2D et les retournent ensuite dans un espace 3D. Cependant, ces méthodes ignorent les différentes dépendances visuelles et entraînent des incohérences dans l'édition de polyèdres. Dans cette étude, on soutient que il est possible d'atteindre une édition 3D unifiée à travers un paradigme visuel avancé. Dans ce paradigme, le contexte édité est propagé depuis une vision éditée vers d'autres visions éditées. En particulier, on propose un nouveau cadre de travail appelé 3D Editor. Ce cadre de travail inclut le Sampling de la Vision Principale, la Renderisation des Visions Clés et la Refactorisation des Visions. Le Sampling de la Vision Principale édite et montre dynamiquement la vision éditée la plus importante. La Renderisation des Visions Clés utilise l'Adaptation de Bas Rang avec Experts Mixte de Vues (MoVE-LoRA) pour propager précisément le contexte édité de la vision principale vers d'autres visions clés. La Refactorisation des Visions édite et réfactorise les objets 3D en se basant sur les visions éditées. Les expériences étendues démontrent que notre méthode dépasse les méthodes actuelles en termes de précision d'édition et de cohérence spatiale.",
      "upvotes": 2,
      "discussionId": "683eb1f64c5b9f381d5b42ed",
      "projectPage": "https://shuoyueli4519.github.io/Pro3D-Editor",
      "ai_summary": "A progressive-views paradigm with Pro3D-Editor achieves consistent 3D editing by propagating semantics from key views to less edited ones.",
      "ai_keywords": [
        "progressive-views paradigm",
        "Primary-view Sampler",
        "Key-view Render",
        "Full-view Refiner",
        "Mixture-of-View-Experts Low-Rank Adaptation",
        "MoVE-LoRA"
      ]
    },
    "publishedAt": "2025-05-31T07:11:55.000Z",
    "title": "Pro3D-Editor : A Progressive-Views Perspective for Consistent and\n  Precise 3D Editing",
    "summary": "Text-guided 3D editing aims to precisely edit semantically relevant local 3D\nregions, which has significant potential for various practical applications\nranging from 3D games to film production. Existing methods typically follow a\nview-indiscriminate paradigm: editing 2D views indiscriminately and projecting\nthem back into 3D space. However, they overlook the different cross-view\ninterdependencies, resulting in inconsistent multi-view editing. In this study,\nwe argue that ideal consistent 3D editing can be achieved through a\nprogressive-views paradigm, which propagates editing semantics from\nthe editing-salient view to other editing-sparse views. Specifically, we\npropose Pro3D-Editor, a novel framework, which mainly includes\nPrimary-view Sampler, Key-view Render, and Full-view Refiner. Primary-view\nSampler dynamically samples and edits the most editing-salient view as the\nprimary view. Key-view Render accurately propagates editing semantics from the\nprimary view to other key views through its Mixture-of-View-Experts Low-Rank\nAdaption (MoVE-LoRA). Full-view Refiner edits and refines the 3D object based\non the edited multi-views. Extensive experiments demonstrate that our method\noutperforms existing methods in editing accuracy and spatial consistency.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.00512.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6629d7c9fa14eaccf07d8633",
      "avatarUrl": "/avatars/dceb2f6c804c583adf15a3536c8c995b.svg",
      "fullname": "Nan Chen",
      "name": "CNcreator0331",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2506.00385",
      "authors": [
        {
          "_id": "683e707763e27c6256f58a51",
          "name": "Yakun Song",
          "hidden": false
        },
        {
          "_id": "683e707763e27c6256f58a52",
          "name": "Jiawei Chen",
          "hidden": false
        },
        {
          "_id": "683e707763e27c6256f58a53",
          "user": {
            "_id": "63774ca43a63a2983ffc12f9",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63774ca43a63a2983ffc12f9/j_VcANnAXvvrIuu6QYxn6.png",
            "isPro": false,
            "fullname": "xiaobin zhuang",
            "user": "xiaobinzhuang",
            "type": "user"
          },
          "name": "Xiaobin Zhuang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-03T08:45:12.616Z",
          "hidden": false
        },
        {
          "_id": "683e707763e27c6256f58a54",
          "name": "Chenpeng Du",
          "hidden": false
        },
        {
          "_id": "683e707763e27c6256f58a55",
          "name": "Ziyang Ma",
          "hidden": false
        },
        {
          "_id": "683e707763e27c6256f58a56",
          "name": "Jian Wu",
          "hidden": false
        },
        {
          "_id": "683e707763e27c6256f58a57",
          "name": "Jian Cong",
          "hidden": false
        },
        {
          "_id": "683e707763e27c6256f58a58",
          "name": "Dongya Jia",
          "hidden": false
        },
        {
          "_id": "683e707763e27c6256f58a59",
          "name": "Zhuo Chen",
          "hidden": false
        },
        {
          "_id": "683e707763e27c6256f58a5a",
          "name": "Yuping Wang",
          "hidden": false
        },
        {
          "_id": "683e707763e27c6256f58a5b",
          "name": "Yuxuan Wang",
          "hidden": false
        },
        {
          "_id": "683e707763e27c6256f58a5c",
          "name": "Xie Chen",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-31T04:31:02.000Z",
      "submittedOnDailyAt": "2025-06-03T04:28:21.280Z",
      "title": "MagiCodec : Implémente une haute qualité de reconstruction et de génération avec un simple code de Gauss-Jensen Injection.",
      "submittedOnDailyBy": {
        "_id": "63774ca43a63a2983ffc12f9",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63774ca43a63a2983ffc12f9/j_VcANnAXvvrIuu6QYxn6.png",
        "isPro": false,
        "fullname": "xiaobin zhuang",
        "user": "xiaobinzhuang",
        "type": "user"
      },
      "summary": "El Nueral Voice Codec aide à convertir efficacement la voix de notes en représentations de tokens discrètes, offrant une base pour les modèles modernes de génération de voix. Cependant, actuellement, le Codec se concentre principalement sur l'optimisation de la qualité de reconstruction, et ne considère pas sa possibilité de modèles futurs. Pour surmonter ces limitations, nous présentons MagiCodec, un nouveau code de voix basé sur un Transformer de couche simple et en ligne. MagiCodec a été conçu grâce à un entraînement multi-échelle avec l'injection de bruit Gaussien et de normalisation potentielle, avec l'objectif clair de améliorer la représentation sémantique du code généré tout en maintenant une haute qualité de reconstruction. L'effet de l'injection de bruit a été analysé analytiquement dans la région des fréquences, montrant un effet d'atténuation dans les composantes de haute fréquence et un amélioration dans la fixation des tokens. Dans des évaluations expérimentales larges, MagiCodec dépasse les meilleurs codes de voix en termes de qualité de reconstruction et de tâches ultérieures. En particulier, les tokens générés par MagiCodec montrent une distribution similaire à celle des mots dans un langage naturel, améliorant la compatibilité avec des architectures de génération basées sur des modèles de langue. Les codes et modèles pré-entraînés sont disponibles sur https://github.com/Ereboas/MagiCodec.",
      "upvotes": 2,
      "discussionId": "683e707963e27c6256f58a98",
      "ai_summary": "MagiCodec, a Transformer-based audio codec, enhances semantic tokenization while maintaining high reconstruction quality, improving compatibility with generative models.",
      "ai_keywords": [
        "Transformer",
        "Gaussian noise injection",
        "latent regularization",
        "frequency domain",
        "Zipf-like distributions",
        "generative models"
      ]
    },
    "publishedAt": "2025-05-31T00:31:02.000Z",
    "title": "MagiCodec: Simple Masked Gaussian-Injected Codec for High-Fidelity\n  Reconstruction and Generation",
    "summary": "Neural audio codecs have made significant strides in efficiently mapping raw\naudio waveforms into discrete token representations, which are foundational for\ncontemporary audio generative models. However, most existing codecs are\noptimized primarily for reconstruction quality, often at the expense of the\ndownstream modelability of the encoded tokens. Motivated by the need to\novercome this bottleneck, we introduce MagiCodec, a novel\nsingle-layer, streaming Transformer-based audio codec. MagiCodec is designed\nwith a multistage training pipeline that incorporates Gaussian noise injection\nand latent regularization, explicitly targeting the enhancement of semantic\nexpressiveness in the generated codes while preserving high reconstruction\nfidelity. We analytically derive the effect of noise injection in the frequency\ndomain, demonstrating its efficacy in attenuating high-frequency components and\nfostering robust tokenization. Extensive experimental evaluations show that\nMagiCodec surpasses state-of-the-art codecs in both reconstruction quality and\ndownstream tasks. Notably, the tokens produced by MagiCodec exhibit Zipf-like\ndistributions, as observed in natural languages, thereby improving\ncompatibility with language-model-based generative architectures. The code and\npre-trained models are available at https://github.com/Ereboas/MagiCodec.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.00385.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "63774ca43a63a2983ffc12f9",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63774ca43a63a2983ffc12f9/j_VcANnAXvvrIuu6QYxn6.png",
      "fullname": "xiaobin zhuang",
      "name": "xiaobinzhuang",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.21724",
      "authors": [
        {
          "_id": "683b44583f2842f6afcc5e6f",
          "name": "Cheng Luo",
          "hidden": false
        },
        {
          "_id": "683b44583f2842f6afcc5e70",
          "name": "Jianghui Wang",
          "hidden": false
        },
        {
          "_id": "683b44583f2842f6afcc5e71",
          "name": "Bing Li",
          "hidden": false
        },
        {
          "_id": "683b44583f2842f6afcc5e72",
          "name": "Siyang Song",
          "hidden": false
        },
        {
          "_id": "683b44583f2842f6afcc5e73",
          "name": "Bernard Ghanem",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-27T20:12:46.000Z",
      "submittedOnDailyAt": "2025-06-03T08:26:23.533Z",
      "title": "OmniResponse : Génération de réponses dans l'interaction de dialogue dans les systèmes de conversation monomodal en ligne",
      "submittedOnDailyBy": {
        "_id": "666ddb45c0f3d5afc27e85ba",
        "avatarUrl": "/avatars/dce98fc77bd8cf9e348f2d91bc3c0225.svg",
        "isPro": false,
        "fullname": "Bing Li",
        "user": "bing-li-ai",
        "type": "user"
      },
      "summary": "Dans cet article, on présente une nouvelle tâche appelée Génération de Réponses Conversationnelles Multimodales en Ligne (Generation of Online Multimodal Conversational Responses, GOMCR). Cette tâche vise à générer des réactions multimodales synchronisées d'un écouteur en ligne à partir d'entrées multimodales du locuteur. GOMCR reflète les interactions naturelles et présente de nouveaux défis pour atteindre la synchronisation entre l'audio généré et les réactions faciales de l'écouteur. Pour aborder ces défis, on introduit le texte comme une modalité intermédiaire et on crée de nouvelles outils pour relier l'audio aux réactions faciales. Ainsi, on propose le modèle de langage de grandes capacités multimodal (MLLM) appelé OmniResponse. OmniResponse utilise un modèle d'apprentissage profond avec deux nouvelles fonctions : Chrono-Text et TempoVoice, pour générer automatiquement des réactions d'écouteurs de haute qualité. Chrono-Text fixe temporellement les tokens de texte générés, tandis que TempoVoice génère une voix synchronisée avec les réactions faciales. On présente ResponseNet, un nouveau jeu de données, pour encourager le développement de GOMCR. Ce jeu de données comprend 696 interactions de haute qualité, avec des vidéos d'interactions synchronisées, des sons multi-canaux, du texte et un analyse des actions faciales. Dans l'évaluation détaillée de ResponseNet, on montre que OmniResponse dépasse significativement les modèles de référence en termes de contenu vocal, de synchronisation de la voix et de la vision et de qualité de génération.",
      "upvotes": 2,
      "discussionId": "683b445c3f2842f6afcc5f49",
      "ai_summary": "OmniResponse, a Multimodal Large Language Model, generates high-quality synchronized verbal and non-verbal listener responses using text as an intermediate modality.",
      "ai_keywords": [
        "Online Multimodal Conversational Response Generation",
        "OmniResponse",
        "Multimodal Large Language Model",
        "Chrono-Text",
        "TempoVoice",
        "ResponseNet",
        "audio-visual synchronization"
      ]
    },
    "publishedAt": "2025-05-27T16:12:46.000Z",
    "title": "OmniResponse: Online Multimodal Conversational Response Generation in\n  Dyadic Interactions",
    "summary": "In this paper, we introduce Online Multimodal Conversational Response\nGeneration (OMCRG), a novel task that aims to online generate synchronized\nverbal and non-verbal listener feedback, conditioned on the speaker's\nmultimodal input. OMCRG reflects natural dyadic interactions and poses new\nchallenges in achieving synchronization between the generated audio and facial\nresponses of the listener. To address these challenges, we innovatively\nintroduce text as an intermediate modality to bridge the audio and facial\nresponses. We hence propose OmniResponse, a Multimodal Large Language Model\n(MLLM) that autoregressively generates high-quality multi-modal listener\nresponses. OmniResponse leverages a pretrained LLM enhanced with two novel\ncomponents: Chrono-Text, which temporally anchors generated text tokens, and\nTempoVoice, a controllable online TTS module that produces speech synchronized\nwith facial reactions. To support further OMCRG research, we present\nResponseNet, a new dataset comprising 696 high-quality dyadic interactions\nfeaturing synchronized split-screen videos, multichannel audio, transcripts,\nand facial behavior annotations. Comprehensive evaluations conducted on\nResponseNet demonstrate that OmniResponse significantly outperforms baseline\nmodels in terms of semantic speech content, audio-visual synchronization, and\ngeneration quality.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.21724.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "666ddb45c0f3d5afc27e85ba",
      "avatarUrl": "/avatars/dce98fc77bd8cf9e348f2d91bc3c0225.svg",
      "fullname": "Bing Li",
      "name": "bing-li-ai",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2505.19621",
      "authors": [
        {
          "_id": "683ea7297e58553a7f73c210",
          "name": "George Kour",
          "hidden": false
        },
        {
          "_id": "683ea7297e58553a7f73c211",
          "name": "Itay Nakash",
          "hidden": false
        },
        {
          "_id": "683ea7297e58553a7f73c212",
          "name": "Ateret Anaby-Tavor",
          "hidden": false
        },
        {
          "_id": "683ea7297e58553a7f73c213",
          "name": "Michal Shmueli-Scheuer",
          "hidden": false
        }
      ],
      "mediaUrls": [
        "https://cdn-uploads.huggingface.co/production/uploads/671f8106d677d3a764a6f9a5/dQxbCsfx-MqMegYL0zCWu.png"
      ],
      "publishedAt": "2025-05-26T07:41:21.000Z",
      "submittedOnDailyAt": "2025-06-03T06:13:25.326Z",
      "title": "Pongamos de nuevo en cuenta ! Discutons l'influence du temps informatique sur les tests de préférences, opinions et croyances des grands modèles de langue.",
      "submittedOnDailyBy": {
        "_id": "671f8106d677d3a764a6f9a5",
        "avatarUrl": "/avatars/90b4b00058aac30c060c5eac8debb1c7.svg",
        "isPro": false,
        "fullname": "itay nakash",
        "user": "itaynakash",
        "type": "user"
      },
      "summary": "Les modèles de langage de grande taille (LLMs) organisent profondément la vie humaine et influent sur les décisions. Il est crucial d'évaluer dans quelle mesure ces modèles expriment des préférences, des opinions et des croyances subjectives. Ces tendances peuvent être générées par des préjugés inclus dans le modèle, affectant son comportement et les recommandations qu'ils offrent aux utilisateurs. Elles peuvent également renforcer des visions spécifiques. Dans cet article, on propose l'Évaluation des Préférences, Opinions et Croyances (POBs) pour évaluer les tendances subjectives dans des domaines sociaux, culturels, éthiques et personnels. En utilisant ces critères, on a évalué et mesuré la fiabilité, la neutralité et la cohérence de modèles LLMs ouverts et fermés développés. De plus, on a étudié l'impact sur la quantité de calculs lors des tests et on a évalué les avantages des fonctions logiques et auto-réflexives. Bien que ces fonctions soient efficaces dans d'autres tâches, cet article montre que dans le domaine de ce travail, elles ont un effet limité. De plus, on montre comment de nouvelles versions de modèles peuvent affecter la cohérence et augmenter les préjugés, montrant également des domaines qui peuvent être ignorés et des tendances de préoccupation. POBS : https://ibm.github.io/POBS",
      "upvotes": 2,
      "discussionId": "683ea72b7e58553a7f73c277",
      "ai_summary": "The Preference, Opinion, and Belief survey assesses the subjective tendencies and biases of Large Language Models across various domains and highlights a trend of increased bias in newer model versions.",
      "ai_keywords": [
        "Large Language Models",
        "Preference",
        "Opinion",
        "and Belief survey",
        "reliability",
        "neutrality",
        "consistency",
        "reasoning mechanisms",
        "self-reflection mechanisms"
      ]
    },
    "publishedAt": "2025-05-26T03:41:21.000Z",
    "title": "Think Again! The Effect of Test-Time Compute on Preferences, Opinions,\n  and Beliefs of Large Language Models",
    "summary": "As Large Language Models (LLMs) become deeply integrated into human life and\nincreasingly influence decision-making, it's crucial to evaluate whether and to\nwhat extent they exhibit subjective preferences, opinions, and beliefs. These\ntendencies may stem from biases within the models, which may shape their\nbehavior, influence the advice and recommendations they offer to users, and\npotentially reinforce certain viewpoints. This paper presents the Preference,\nOpinion, and Belief survey (POBs), a benchmark developed to assess LLMs'\nsubjective inclinations across societal, cultural, ethical, and personal\ndomains. We applied our benchmark to evaluate leading open- and closed-source\nLLMs, measuring desired properties such as reliability, neutrality, and\nconsistency. In addition, we investigated the effect of increasing the\ntest-time compute, through reasoning and self-reflection mechanisms, on those\nmetrics. While effective in other tasks, our results show that these mechanisms\noffer only limited gains in our domain. Furthermore, we reveal that newer model\nversions are becoming less consistent and more biased toward specific\nviewpoints, highlighting a blind spot and a concerning trend. POBS:\nhttps://ibm.github.io/POBS",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/671f8106d677d3a764a6f9a5/dQxbCsfx-MqMegYL0zCWu.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.19621.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "671f8106d677d3a764a6f9a5",
      "avatarUrl": "/avatars/90b4b00058aac30c060c5eac8debb1c7.svg",
      "fullname": "itay nakash",
      "name": "itaynakash",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2506.00772",
      "authors": [
        {
          "_id": "683ec2d53c81cc903bbb418c",
          "name": "Zihang Liu",
          "hidden": false
        },
        {
          "_id": "683ec2d53c81cc903bbb418d",
          "name": "Tianyu Pang",
          "hidden": false
        },
        {
          "_id": "683ec2d53c81cc903bbb418e",
          "name": "Oleg Balabanov",
          "hidden": false
        },
        {
          "_id": "683ec2d53c81cc903bbb418f",
          "name": "Chaoqun Yang",
          "hidden": false
        },
        {
          "_id": "683ec2d53c81cc903bbb4190",
          "name": "Tianjin Huang",
          "hidden": false
        },
        {
          "_id": "683ec2d53c81cc903bbb4191",
          "name": "Lu Yin",
          "hidden": false
        },
        {
          "_id": "683ec2d53c81cc903bbb4192",
          "name": "Yaoqing Yang",
          "hidden": false
        },
        {
          "_id": "683ec2d53c81cc903bbb4193",
          "name": "Shiwei Liu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-06-01T01:31:50.000Z",
      "submittedOnDailyAt": "2025-06-03T08:10:49.247Z",
      "title": "Levez le voile pour la vérité : nous nous concentrons sur les raisons pour lesquelles la qualité des experts diminue, puis nous améliorons notre classement.",
      "submittedOnDailyBy": {
        "_id": "65b04d2291e63920a7898c9e",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65b04d2291e63920a7898c9e/iUHs235G4bqK-KnH_94ti.jpeg",
        "isPro": false,
        "fullname": "Liu",
        "user": "Shiweiliuiiiiiii",
        "type": "user"
      },
      "summary": "Selon les derniers études, il a été clairement démontré que l'utilisation de jeux de données de haute qualité avec des décimales dans les modèles de LLM et la réalisation d'ajustements microréguliers peut obtenir des habiletés logiques fortes. Cependant, l'ajuste complet (Full FT) est puissant mais a des coûts de calcul élevés, est vulnérable au surapprentissage et au catastrophe de la perte, surtout lorsque les données sont limitées. L'ajuste micro-onde a réussi à obtenir des résultats notables précédemment, mais a rencontré des difficultés pour s'adapter à l'ère des LLM, en raison de la difficulté d'identifier les paramètres importants pour la logique. Dans cette étude, on propose que les poids importants dans l'ajuste micro-onde ont une grande magnitude absolue après des approximations de basse fréquence, et qu'ils sont appelés \"poids principaux\". Surprenant, l'ajuste micro-onde basé sur la magnitude absolue peut être efficace dans la réduction de la dimensionnalité et peut être une référence pour l'ajustement des LLM. En se basant sur cette observation, on propose le méthode d'Ajuste Micro-onde Informé de Basse Ranura (LIFT). Le LIFT met à jour seulement 5% des poids principaux pendant tout le période d'entraînement, maintient un rendement meilleur pour des tâches logiques par rapport à Full FT, et maintient l'efficacité mémoire similaire à d'autres méthodes d'ajustement. De plus, dans les cas où LIFT montre un excellent rendement dans des zones spécifiques comme la logique arithmétique, il maintient au moins 20% du savoir du modèle original plus que Full FT et LoRA. Le code de cette étude est disponible sur la URL suivante : https://github.com/zihanghliu/LIFT.",
      "upvotes": 1,
      "discussionId": "683ec2d53c81cc903bbb41c4",
      "ai_summary": "Leveraging low-rank approximation to identify critical weights for sparse fine-tuning of large language models enhances performance and efficiency compared to full fine-tuning.",
      "ai_keywords": [
        "LLMs",
        "supervised fine-tuning",
        "full fine-tuning",
        "sparse fine-tuning",
        "low-rank approximation",
        "Principal Weights",
        "Low-rank Informed Sparse Fine-Tuning",
        "LIFT",
        "memory efficiency",
        "parameter-efficient fine-tuning",
        "reasoning tasks",
        "arithmetic reasoning",
        "source-domain knowledge",
        "LoRA"
      ]
    },
    "publishedAt": "2025-05-31T21:31:50.000Z",
    "title": "LIFT the Veil for the Truth: Principal Weights Emerge after Rank\n  Reduction for Reasoning-Focused Supervised Fine-Tuning",
    "summary": "Recent studies have shown that supervised fine-tuning of LLMs on a small\nnumber of high-quality datasets can yield strong reasoning capabilities.\nHowever, full fine-tuning (Full FT), while powerful, is computationally\nexpensive and susceptible to overfitting and catastrophic forgetting,\nparticularly when data is limited. Sparse fine-tuning, which previously\nachieved notable success by updating only a small subset of model parameters,\noffers a promising trade-off between efficiency and effectiveness. Yet, it has\nlagged behind in the LLM era due to the difficulty of identifying parameters\ntruly critical for reasoning. In this work, we state that weights with the\nlargest magnitude after low-rank approximation are critical weights for\nfine-tuning, which we call Principal Weights. Surprisingly, while\nmagnitude-based sparse fine-tuning performs poorly as a baseline on LLM\nfine-tuning, it becomes highly effective after rank reduction. These insights\nmotivate our method: Low-rank Informed Sparse Fine-Tuning (LIFT). LIFT only\nupdates the top 5% Principal Weights throughout training and consistently\nachieves better performance on reasoning tasks than Full FT, while maintaining\nmemory efficiency on par with popular parameter-efficient fine-tuning methods.\nIn addition to strong performance on target domains such as arithmetic\nreasoning, LIFT also retains up to 20% more source-domain knowledge, compared\nto Full FT and LoRA. Our code is available at:\nhttps://github.com/zihanghliu/LIFT.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.00772.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "65b04d2291e63920a7898c9e",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65b04d2291e63920a7898c9e/iUHs235G4bqK-KnH_94ti.jpeg",
      "fullname": "Liu",
      "name": "Shiweiliuiiiiiii",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2506.00469",
      "authors": [
        {
          "_id": "683e9e0a1c5320ac91b85a19",
          "user": {
            "_id": "617a92e16f37340367d5d791",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/617a92e16f37340367d5d791/omgyzmaF90KBLa3YgFxhS.png",
            "isPro": false,
            "fullname": "Shaoxiong",
            "user": "jisx",
            "type": "user"
          },
          "name": "Shaoxiong Ji",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-03T08:37:04.382Z",
          "hidden": true
        },
        {
          "_id": "683e9e0a1c5320ac91b85a1a",
          "name": "Zihao Li",
          "hidden": false
        },
        {
          "_id": "683e9e0a1c5320ac91b85a1b",
          "name": "Jaakko Paavola",
          "hidden": false
        },
        {
          "_id": "683e9e0a1c5320ac91b85a1c",
          "name": "Indraneil Paul",
          "hidden": false
        },
        {
          "_id": "683e9e0a1c5320ac91b85a1d",
          "name": "Hengyu Luo",
          "hidden": false
        },
        {
          "_id": "683e9e0a1c5320ac91b85a1e",
          "name": "Jörg Tiedemann",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-31T08:37:17.000Z",
      "submittedOnDailyAt": "2025-06-03T05:43:58.004Z",
      "title": "Dans des environnements multilingues à grande échelle, l'utilisation de données de traduction bilingues dans des modèles de langage à grande échelle.",
      "submittedOnDailyBy": {
        "_id": "617a92e16f37340367d5d791",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/617a92e16f37340367d5d791/omgyzmaF90KBLa3YgFxhS.png",
        "isPro": false,
        "fullname": "Shaoxiong",
        "user": "jisx",
        "type": "user"
      },
      "summary": "Cet article explore les décisions de conception cruciales pour l'apprentissage continu préalable de Magic Steel. En particulier, il examine la configuration des données parallèles. Plus spécifiquement, il étudie l'impact des données de traduction de mots sur l'ajustement multilingue à l'échelle de 500 langues du modèle Llama3. Par conséquent, un corpus MaLA de traduction de mots est construit, comprenant plus de 2 500 paires de langues. Ensuite, quatre modèles multilingues significatifs sont développés avec le système EMMA-500 Llama 3. Ces modèles sont entraînés préalablement continuément sur des patterns de données variés basés sur Llama3. De plus, l'impact de l'absence de données de traduction de mots sur l'apprentissage continu préalable est étudié. Des évaluations détaillées sur 7 tâches et 12 référentiels montrent que les données de traduction de mots améliorent la transfert de langue et le rendement. En particulier, il est montré qu'ils ont un effet significatif même dans les langues à faibles ressources. Le corpus MaLA, le design, le code et la génération des modèles du système EMMA-500 Llama 3 sont publiés.",
      "upvotes": 1,
      "discussionId": "683e9e0a1c5320ac91b85a50",
      "projectPage": "https://mala-lm.github.io/emma-500-gen2.html",
      "githubRepo": "https://github.com/MaLA-LM/emma-500/",
      "ai_summary": "Bilingual translation data enhances language transfer and performance in massively multilingual language adaptation of the Llama3 family of models.",
      "ai_keywords": [
        "massively multilingual continual pre-training",
        "bilingual translation data",
        "Llama3",
        "MaLA bilingual translation corpus",
        "EMMA-500 Llama 3 suite",
        "continual pre-training",
        "language transfer",
        "low-resource languages"
      ]
    },
    "publishedAt": "2025-05-31T04:37:17.000Z",
    "title": "Massively Multilingual Adaptation of Large Language Models Using\n  Bilingual Translation Data",
    "summary": "This paper investigates a critical design decision in the practice of\nmassively multilingual continual pre-training -- the inclusion of parallel\ndata. Specifically, we study the impact of bilingual translation data for\nmassively multilingual language adaptation of the Llama3 family of models to\n500 languages. To this end, we construct the MaLA bilingual translation corpus,\ncontaining data from more than 2,500 language pairs. Subsequently, we develop\nthe EMMA-500 Llama 3 suite of four massively multilingual models -- continually\npre-trained from the Llama 3 family of base models extensively on diverse data\nmixes up to 671B tokens -- and explore the effect of continual pre-training\nwith or without bilingual translation data. Comprehensive evaluation across 7\ntasks and 12 benchmarks demonstrates that bilingual data tends to enhance\nlanguage transfer and performance, particularly for low-resource languages. We\nopen-source the MaLA corpus, EMMA-500 Llama 3 suite artefacts, code, and model\ngenerations.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.00469.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "617a92e16f37340367d5d791",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/617a92e16f37340367d5d791/omgyzmaF90KBLa3YgFxhS.png",
      "fullname": "Shaoxiong",
      "name": "jisx",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 11
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2506.01920",
      "authors": [
        {
          "_id": "683ec5047ec12b4ee9a21215",
          "name": "Serry Sibaee",
          "hidden": false
        },
        {
          "_id": "683ec5047ec12b4ee9a21216",
          "name": "Omer Nacar",
          "hidden": false
        },
        {
          "_id": "683ec5047ec12b4ee9a21217",
          "name": "Adel Ammar",
          "hidden": false
        },
        {
          "_id": "683ec5047ec12b4ee9a21218",
          "name": "Yasser Al-Habashi",
          "hidden": false
        },
        {
          "_id": "683ec5047ec12b4ee9a21219",
          "name": "Abdulrahman Al-Batati",
          "hidden": false
        },
        {
          "_id": "683ec5047ec12b4ee9a2121a",
          "name": "Wadii Boulila",
          "hidden": false
        }
      ],
      "publishedAt": "2025-06-02T17:39:50.000Z",
      "submittedOnDailyAt": "2025-06-03T08:20:38.744Z",
      "title": "Éxecuter les directives en action : Nouveau paradigme pour l'évaluation du modèle de langue arabe",
      "submittedOnDailyBy": {
        "_id": "628f7a71dd993507cfcbe587",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/628f7a71dd993507cfcbe587/3frAcMgfBCx-OJsrdAhnb.png",
        "isPro": true,
        "fullname": "Omartificial Intelligence Space",
        "user": "Omartificial-Intelligence-Space",
        "type": "user"
      },
      "summary": "Cet article présente une guide théorique concrète pour résoudre les défauts importants dans l'évaluation de modèles de langue arabe et introduit un nouveau cadre d'évaluation. Tout d'abord, il analyse les ensembles de données d'évaluation actuels pour identifier des problèmes significatifs en termes de précision linguistique, cohérence culturelle et rigueur méthodologique. Pour surmonter les limitations des modèles de langue, on présente l'ensemble de données de samples profonds arabes (ADMD). L'ADMD comprend 490 questions difficiles répétées dans 10 domaines principaux (42 sous-ensembles de données, voir le graphique 1). En utilisant l'ADMD, on évalue 5 modèles de langue avancés : GPT-4, Claude 3.5 Sonnet, Gemini Flash 1.5, CommandR 100B et Qwen-Max. Les résultats montrent clairement des différences notables dans le rendement du modèle dans différentes domaines, surtout lorsqu'il est nécessaire une compréhension profonde culturelle et des connaissances spécialisées. Claude 3.5 Sonnet présente une forte force relative en mathématiques, arabe et islamique, avec une précision générale de 30%, la plus élevée. Cette étude fournit une base théorique et une perspective pratique pour améliorer l'évaluation de modèles de langue arabe, soulignant l'importance de l'harmonie culturelle et du pouvoir technologique.",
      "upvotes": 0,
      "discussionId": "683ec5137ec12b4ee9a21496",
      "ai_summary": "A new evaluation framework and dataset, ADMD, are introduced to assess Arabic language models, highlighting variations in performance and emphasizing the importance of cultural competence.",
      "ai_keywords": [
        "evaluation framework",
        "Arabic Depth Mini Dataset (ADMD)",
        "GPT-4",
        "Claude 3.5 Sonnet",
        "Gemini Flash 1.5",
        "CommandR 100B",
        "Qwen-Max",
        "cultural understanding",
        "specialized knowledge",
        "cultural competence"
      ]
    },
    "publishedAt": "2025-06-02T13:39:50.000Z",
    "title": "From Guidelines to Practice: A New Paradigm for Arabic Language Model\n  Evaluation",
    "summary": "This paper addresses critical gaps in Arabic language model evaluation by\nestablishing comprehensive theoretical guidelines and introducing a novel\nevaluation framework. We first analyze existing Arabic evaluation datasets,\nidentifying significant issues in linguistic accuracy, cultural alignment, and\nmethodological rigor. To address these limitations in LLMs, we present the\nArabic Depth Mini Dataset (ADMD), a carefully curated collection of 490\nchallenging questions spanning ten major domains (42 sub-domains, see Figure 1.\nUsing ADMD, we evaluate five leading language models: GPT-4, Claude 3.5 Sonnet,\nGemini Flash 1.5, CommandR 100B, and Qwen-Max. Our results reveal significant\nvariations in model performance across different domains, with particular\nchallenges in areas requiring deep cultural understanding and specialized\nknowledge. Claude 3.5 Sonnet demonstrated the highest overall accuracy at 30\\%,\nshowing relative strength in mathematical theory in Arabic, Arabic language,\nand islamic domains. This work provides both theoretical foundations and\npractical insights for improving Arabic language model evaluation, emphasizing\nthe importance of cultural competence alongside technical capabilities.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.01920.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "628f7a71dd993507cfcbe587",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/628f7a71dd993507cfcbe587/3frAcMgfBCx-OJsrdAhnb.png",
      "fullname": "Omartificial Intelligence Space",
      "name": "Omartificial-Intelligence-Space",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 100
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2506.01920",
      "authors": [
        {
          "_id": "683ec5047ec12b4ee9a21215",
          "name": "Serry Sibaee",
          "hidden": false
        },
        {
          "_id": "683ec5047ec12b4ee9a21216",
          "name": "Omer Nacar",
          "hidden": false
        },
        {
          "_id": "683ec5047ec12b4ee9a21217",
          "name": "Adel Ammar",
          "hidden": false
        },
        {
          "_id": "683ec5047ec12b4ee9a21218",
          "name": "Yasser Al-Habashi",
          "hidden": false
        },
        {
          "_id": "683ec5047ec12b4ee9a21219",
          "name": "Abdulrahman Al-Batati",
          "hidden": false
        },
        {
          "_id": "683ec5047ec12b4ee9a2121a",
          "name": "Wadii Boulila",
          "hidden": false
        }
      ],
      "publishedAt": "2025-06-02T17:39:50.000Z",
      "submittedOnDailyAt": "2025-06-03T08:20:38.744Z",
      "title": "La ligne de respiration vers la pratique : Nouveau paradigme pour l'évaluation de modèles de langue arabe",
      "submittedOnDailyBy": {
        "_id": "628f7a71dd993507cfcbe587",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/628f7a71dd993507cfcbe587/3frAcMgfBCx-OJsrdAhnb.png",
        "isPro": true,
        "fullname": "Omartificial Intelligence Space",
        "user": "Omartificial-Intelligence-Space",
        "type": "user"
      },
      "summary": "Cet article aborde les déficiences critiques dans l'évaluation des modèles de langue arabe, en établissant une ligne directrice théorique spécifique et en introduisant un nouveau cadre d'évaluation. Tout d'abord, il analyse les ensembles de données d'évaluation arabe existants pour identifier des problèmes importants en termes de précision linguistique, d'adaptation culturelle et de méthodologie. Pour résoudre ces limitations, il propose l'ensemble de données profond arabe (ADMD). L'ADMD comprend 490 questions défiquantes et aborde 10 domaines principaux (42 sous-domaines, se référer au graphique 1). En utilisant l'ADMD, les performances de 5 modèles récents sont évaluées : GPT-4, Claude 3.5 Sonnet, Gemini Flash 1.5, CommandR 100B et Qwen-Max. Les résultats montrent des différences significatives dans le rendement des modèles dans différents domaines, soulignant particulièrement les problèmes dans les domaines nécessitant un compréhension culturelle profonde et des connaissances spécialisées. Claude 3.5 Sonnet se distingue par son excellence en mathématiques arabes et dans le domaine arabe-Israélien, avec une précision générale de 30%, la plus élevée de tous. Cette étude fournit une base théorique et une rétroaction pratique pour l'amélioration de l'évaluation des modèles de langue arabe, soulignant l'importance de la compréhension culturelle et de la capacité technique.",
      "upvotes": 0,
      "discussionId": "683ec5137ec12b4ee9a21496",
      "ai_summary": "A new evaluation framework and dataset, ADMD, are introduced to assess Arabic language models, highlighting variations in performance and emphasizing the importance of cultural competence.",
      "ai_keywords": [
        "evaluation framework",
        "Arabic Depth Mini Dataset (ADMD)",
        "GPT-4",
        "Claude 3.5 Sonnet",
        "Gemini Flash 1.5",
        "CommandR 100B",
        "Qwen-Max",
        "cultural understanding",
        "specialized knowledge",
        "cultural competence"
      ]
    },
    "publishedAt": "2025-06-02T13:39:50.000Z",
    "title": "From Guidelines to Practice: A New Paradigm for Arabic Language Model\n  Evaluation",
    "summary": "This paper addresses critical gaps in Arabic language model evaluation by\nestablishing comprehensive theoretical guidelines and introducing a novel\nevaluation framework. We first analyze existing Arabic evaluation datasets,\nidentifying significant issues in linguistic accuracy, cultural alignment, and\nmethodological rigor. To address these limitations in LLMs, we present the\nArabic Depth Mini Dataset (ADMD), a carefully curated collection of 490\nchallenging questions spanning ten major domains (42 sub-domains, see Figure 1.\nUsing ADMD, we evaluate five leading language models: GPT-4, Claude 3.5 Sonnet,\nGemini Flash 1.5, CommandR 100B, and Qwen-Max. Our results reveal significant\nvariations in model performance across different domains, with particular\nchallenges in areas requiring deep cultural understanding and specialized\nknowledge. Claude 3.5 Sonnet demonstrated the highest overall accuracy at 30\\%,\nshowing relative strength in mathematical theory in Arabic, Arabic language,\nand islamic domains. This work provides both theoretical foundations and\npractical insights for improving Arabic language model evaluation, emphasizing\nthe importance of cultural competence alongside technical capabilities.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.01920.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "628f7a71dd993507cfcbe587",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/628f7a71dd993507cfcbe587/3frAcMgfBCx-OJsrdAhnb.png",
      "fullname": "Omartificial Intelligence Space",
      "name": "Omartificial-Intelligence-Space",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 100
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2506.01713",
      "authors": [
        {
          "_id": "683ec81753981b08324ce57b",
          "name": "Zhongwei Wan",
          "hidden": false
        },
        {
          "_id": "683ec81753981b08324ce57c",
          "name": "Zhihao Dou",
          "hidden": false
        },
        {
          "_id": "683ec81753981b08324ce57d",
          "name": "Che Liu",
          "hidden": false
        },
        {
          "_id": "683ec81753981b08324ce57e",
          "name": "Yu Zhang",
          "hidden": false
        },
        {
          "_id": "683ec81753981b08324ce57f",
          "name": "Dongfei Cui",
          "hidden": false
        },
        {
          "_id": "683ec81753981b08324ce580",
          "name": "Qinjian Zhao",
          "hidden": false
        },
        {
          "_id": "683ec81753981b08324ce581",
          "name": "Hui Shen",
          "hidden": false
        },
        {
          "_id": "683ec81753981b08324ce582",
          "name": "Jing Xiong",
          "hidden": false
        },
        {
          "_id": "683ec81753981b08324ce583",
          "name": "Yi Xin",
          "hidden": false
        },
        {
          "_id": "683ec81753981b08324ce584",
          "name": "Yifan Jiang",
          "hidden": false
        },
        {
          "_id": "683ec81753981b08324ce585",
          "name": "Yangfan He",
          "hidden": false
        },
        {
          "_id": "683ec81753981b08324ce586",
          "name": "Mi Zhang",
          "hidden": false
        },
        {
          "_id": "683ec81753981b08324ce587",
          "name": "Shen Yan",
          "hidden": false
        }
      ],
      "publishedAt": "2025-06-02T14:21:44.000Z",
      "submittedOnDailyAt": "2025-06-03T08:34:07.706Z",
      "title": "SRPO : Amélioration de la Théorie de la Logique de la Cognition Réflexive Basée sur l'Apprentissage par Référence de Modèles de LLM",
      "submittedOnDailyBy": {
        "_id": "631b9ff5824f2502e3557c7e",
        "avatarUrl": "/avatars/076043c9dba07644a570692563ef8114.svg",
        "isPro": true,
        "fullname": "liu",
        "user": "che111",
        "type": "user"
      },
      "summary": "Les modèles de langue multimodal de DeepMind (MLLMs) montrent les capacités attendues dans des tâches de raisonnement, mais rencontrent des difficultés lorsqu'ils sont confrontés à des problèmes complexes qui nécessitent une claire auto-réflexion et auto-adaptation, surtout en comparaison avec la logique basée sur le texte dans des modalités uniques. Les méthodes de rétroaction actuelles sont simples, ne génèrent pas de préoccupations significatives et les limites de la capacité de raisonnement et du savoir sont bien établies lors de l'entraînement initial. Pour surmonter ces défis, nous proposons la Politique d'Optimisation de Groupe de Rétroaction (SRPO) pour renforcer le raisonnement dans les modèles multimodal de DeepMind. SRPO est un cadre d'apprentissage par renforcement avec connaissance de rétroaction en deux étapes, spécialement conçu pour renforcer le raisonnement. Dans la première étape, sous la direction d'un MLLM avancé, un ensemble de données de rétroaction de haute qualité est construit et une rétroaction basée sur les réponses initiales est générée pour pousser l'apprentissage simultané de raisonnement et d'auto-réflexion dans le modèle de politique. Dans la deuxième étape, une nouvelle structure de récompense est introduite dans le cadre de SRPO pour pousser la rétroaction claire et cognitivement significative sans répéter des cycles, évitant ainsi le dégât cognitif. A travers des expériences élargies sur des benchmarks multimodal de raisonnement comme MathVista, MathVision, MathVerse et MMMU-Pro, en utilisant des modèles comme Qwen-2.5-VL-7B et Qwen-2.5-VL-32B, SRPO a dépassé de manière significative les modèles leaders, atteignant un grand progrès en termes de précision du raisonnement et de qualité de l'auto-réflexion.",
      "upvotes": 0,
      "discussionId": "683ec81853981b08324ce5f1",
      "projectPage": "https://srpo.pages.dev/"
    },
    "publishedAt": "2025-06-02T10:21:44.000Z",
    "title": "SRPO: Enhancing Multimodal LLM Reasoning via Reflection-Aware\n  Reinforcement Learning",
    "summary": "Multimodal large language models (MLLMs) have shown promising capabilities in\nreasoning tasks, yet still struggle with complex problems requiring explicit\nself-reflection and self-correction, especially compared to their unimodal\ntext-based counterparts. Existing reflection methods are simplistic and\nstruggle to generate meaningful and instructive feedback, as the reasoning\nability and knowledge limits of pre-trained models are largely fixed during\ninitial training. To overcome these challenges, we propose Multimodal\nSelf-Reflection enhanced reasoning with Group Relative Policy Optimization\n(SRPO), a two-stage reflection-aware reinforcement learning (RL) framework\nexplicitly designed to enhance multimodal LLM reasoning. In the first stage, we\nconstruct a high-quality, reflection-focused dataset under the guidance of an\nadvanced MLLM, which generates reflections based on initial responses to help\nthe policy model learn both reasoning and self-reflection. In the second stage,\nwe introduce a novel reward mechanism within the GRPO framework that encourages\nconcise and cognitively meaningful reflection while avoiding redundancy.\nExtensive experiments across multiple multimodal reasoning benchmarks,\nincluding MathVista, MathVision, MathVerse, and MMMU-Pro, using Qwen-2.5-VL-7B\nand Qwen-2.5-VL-32B demonstrate that SRPO significantly outperforms\nstate-of-the-art models, achieving notable improvements in both reasoning\naccuracy and reflection quality.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.01713.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "631b9ff5824f2502e3557c7e",
      "avatarUrl": "/avatars/076043c9dba07644a570692563ef8114.svg",
      "fullname": "liu",
      "name": "che111",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 8
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2505.15772",
      "authors": [
        {
          "_id": "683ec87a4246cd3c413046e1",
          "name": "Yifan Cheng",
          "hidden": false
        },
        {
          "_id": "683ec87a4246cd3c413046e2",
          "name": "Ruoyi Zhang",
          "hidden": false
        },
        {
          "_id": "683ec87a4246cd3c413046e3",
          "name": "Jiatong Shi",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-21T17:23:12.000Z",
      "submittedOnDailyAt": "2025-06-03T08:35:09.353Z",
      "title": "MIKU-PAL : Méthode pour l'automatisation et la normalisation de diverses informations, en excluant le sens linguistique sémantique, et sa détection.",
      "submittedOnDailyBy": {
        "_id": "6607d9c2d81d6112498810b9",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6607d9c2d81d6112498810b9/mmwx-SFEP-6gjnAdjbcxb.png",
        "isPro": false,
        "fullname": "PoTaTo",
        "user": "PoTaTo721",
        "type": "user"
      },
      "summary": "La collecte de grandes quantités de données de phrases émotionnelles ayant une forte concordance est un grand défi dans la synthèse de phrases. Dans cet article, nous présentons le pipeline multi-modèle entièrement automatisé \"MIKU-PAL\" pour extraire des phrases émotionnelles à haute qualité de concordance à partir de vidéos non étiquetées. En utilisant des algorithmes de détection et de suivi de visages, nous avons développé un système d'analyse automatique des émotions basé sur plusieurs modèles et modèles de langage (MLLM). MIKU-PAL a atteint une précision humaine (68,5% sur MELD) et une forte concordance (kappa de Fleiss de 0,93), fonctionnant à un coût plus bas et avec une plus grande rapidité que l'étiquetage humain. Avec la haute qualité d'étiquetage flexible et de forte concordance obtenue avec MIKU-PAL, nous avons enregistré 26 catégories détaillées d'émotions dans des phrases et évalué 83% des étiquetages humains. Sur la base de ce système, nous avons lancé un nouveau benchmark de phrases et de visualisations d'émotions, \"MIKU-EmoBench\", qui consiste en un ensemble de données détaillées de 131,2 heures de phrases émotionnelles.",
      "upvotes": 0,
      "discussionId": "683ec87a4246cd3c41304708"
    },
    "publishedAt": "2025-05-21T13:23:12.000Z",
    "title": "MIKU-PAL: An Automated and Standardized Multi-Modal Method for Speech\n  Paralinguistic and Affect Labeling",
    "summary": "Acquiring large-scale emotional speech data with strong consistency remains a\nchallenge for speech synthesis. This paper presents MIKU-PAL, a fully automated\nmultimodal pipeline for extracting high-consistency emotional speech from\nunlabeled video data. Leveraging face detection and tracking algorithms, we\ndeveloped an automatic emotion analysis system using a multimodal large\nlanguage model (MLLM). Our results demonstrate that MIKU-PAL can achieve\nhuman-level accuracy (68.5% on MELD) and superior consistency (0.93 Fleiss\nkappa score) while being much cheaper and faster than human annotation. With\nthe high-quality, flexible, and consistent annotation from MIKU-PAL, we can\nannotate fine-grained speech emotion categories of up to 26 types, validated by\nhuman annotators with 83% rationality ratings. Based on our proposed system, we\nfurther released a fine-grained emotional speech dataset MIKU-EmoBench(131.2\nhours) as a new benchmark for emotional text-to-speech and visual voice\ncloning.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.15772.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6607d9c2d81d6112498810b9",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6607d9c2d81d6112498810b9/mmwx-SFEP-6gjnAdjbcxb.png",
      "fullname": "PoTaTo",
      "name": "PoTaTo721",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 11
    },
    "isAuthorParticipating": false
  }
]