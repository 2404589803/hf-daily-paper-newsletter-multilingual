[
  {
    "paper": {
      "id": "2501.15368",
      "authors": [
        {
          "_id": "67986c6822990ae89bb71fb9",
          "name": "Yadong Li",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fba",
          "name": "Jun Liu",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fbb",
          "name": "Tao Zhang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fbc",
          "name": "Tao Zhang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fbd",
          "name": "Song Chen",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fbe",
          "name": "Tianpeng Li",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fbf",
          "name": "Zehuan Li",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fc0",
          "name": "Lijun Liu",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fc1",
          "name": "Lingfeng Ming",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fc2",
          "name": "Guosheng Dong",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fc3",
          "name": "Da Pan",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fc4",
          "name": "Chong Li",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fc5",
          "name": "Yuanbo Fang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fc6",
          "name": "Dongdong Kuang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fc7",
          "name": "Mingrui Wang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fc8",
          "name": "Chenglin Zhu",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fc9",
          "name": "Youwei Zhang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fca",
          "name": "Hongyu Guo",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fcb",
          "name": "Fengyu Zhang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fcc",
          "name": "Yuran Wang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fcd",
          "name": "Bowen Ding",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fce",
          "name": "Wei Song",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fcf",
          "name": "Xu Li",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fd0",
          "name": "Yuqi Huo",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fd1",
          "name": "Zheng Liang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fd2",
          "name": "Shusen Zhang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fd3",
          "name": "Xin Wu",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fd4",
          "name": "Shuai Zhao",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fd5",
          "name": "Linchu Xiong",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fd6",
          "name": "Yozhen Wu",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fd7",
          "name": "Jiahui Ye",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fd8",
          "name": "Wenhao Lu",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fd9",
          "name": "Bowen Li",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fda",
          "name": "Yan Zhang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fdb",
          "name": "Yaqi Zhou",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fdc",
          "name": "Xin Chen",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fdd",
          "name": "Lei Su",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fde",
          "name": "Hongda Zhang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fdf",
          "name": "Fuzhong Chen",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fe0",
          "name": "Xuezhen Dong",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fe1",
          "name": "Na Nie",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fe2",
          "name": "Zhiying Wu",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fe3",
          "name": "Bin Xiao",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fe4",
          "name": "Ting Li",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fe5",
          "name": "Shunya Dang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fe6",
          "name": "Ping Zhang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fe7",
          "name": "Yijia Sun",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fe8",
          "name": "Jincheng Wu",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fe9",
          "name": "Jinjie Yang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fea",
          "name": "Xionghai Lin",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71feb",
          "name": "Zhi Ma",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fec",
          "name": "Kegeng Wu",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fed",
          "name": "Jia li",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fee",
          "name": "Aiyuan Yang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fef",
          "name": "Hui Liu",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71ff0",
          "name": "Jianqiang Zhang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71ff1",
          "name": "Xiaoxi Chen",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71ff2",
          "name": "Guangwei Ai",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71ff3",
          "name": "Wentao Zhang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71ff4",
          "name": "Yicong Chen",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71ff5",
          "name": "Xiaoqin Huang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71ff6",
          "name": "Kun Li",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71ff7",
          "name": "Wenjing Luo",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71ff8",
          "name": "Yifei Duan",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71ff9",
          "name": "Lingling Zhu",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71ffa",
          "name": "Ran Xiao",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71ffb",
          "name": "Zhe Su",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71ffc",
          "name": "Jiani Pu",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71ffd",
          "name": "Dian Wang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71ffe",
          "name": "Xu Jia",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fff",
          "name": "Tianyu Zhang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb72000",
          "name": "Mengyu Ai",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb72001",
          "name": "Mang Wang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb72002",
          "name": "Yujing Qiao",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb72003",
          "name": "Lei Zhang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb72004",
          "name": "Yanjun Shen",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb72005",
          "name": "Fan Yang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb72006",
          "name": "Miao Zhen",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb72007",
          "name": "Yijie Zhou",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb72008",
          "name": "Mingyang Chen",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb72009",
          "name": "Fei Li",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb7200a",
          "name": "Chenzheng Zhu",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb7200b",
          "name": "Keer Lu",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb7200c",
          "name": "Yaqi Zhao",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb7200d",
          "name": "Hao Liang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb7200e",
          "name": "Youquan Li",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb7200f",
          "name": "Yanzhao Qin",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb72010",
          "name": "Linzhuang Sun",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb72011",
          "name": "Jianhua Xu",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb72012",
          "name": "Haoze Sun",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb72013",
          "name": "Mingan Lin",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb72014",
          "name": "Zenan Zhou",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb72015",
          "name": "Weipeng Chen",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-26T02:19:03.000Z",
      "title": "Baichuan-Omni-1.5 技術報告",
      "summary": "Baichuan-Omni-1.5は、様々なモダルの理解能力を持つものであり、さらにオーディオ生成能力を提供します。モデルの機能を失わずに、様々なモダル間で流れ通りの良いやりとりを実現するために、3つの重要な面について優先的に最適化しました。まず、多モダルデータのコンテンツクリーニングおよび合成パイプラインを構築し、約500Bの高品質データ（テキスト、オーディオ、ビジョン）を得ました。次に、オーディオトークナイザー（Baichuan-Audio-Tokenizer）を設計し、オーディオからの意味的的および音響的情報を捉え、MLLMとの無間違いのない、機能の向上を実現しました。最後に、多ステップトレーニング戦略を設計し、進段的に多モダルのアライメントと多タスクのファイナルチューニングを統合し、すべてのモダル間での効果的なシンプロジーを確保しました。Baichuan-Omni-1.5は、現代のモデル（GPT4o-miniやMiniCPM-o 2.6を含む）に比べて、様々なモダルの詳細な機能を持っています。特に、様々な多モダル医療ベンチマークでは、Qwen2-VL-72Bとの比較的な結果を収めています。",
      "upvotes": 18,
      "discussionId": "67986c6b22990ae89bb720aa"
    },
    "publishedAt": "2025-01-28T00:34:49.721Z",
    "title": "Baichuan-Omni-1.5 Technical Report",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.15368.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5828
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.15383",
      "authors": [
        {
          "_id": "67986c83b5e71350993d28eb",
          "name": "An Yang",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28ec",
          "name": "Bowen Yu",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28ed",
          "name": "Chengyuan Li",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28ee",
          "name": "Dayiheng Liu",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28ef",
          "name": "Fei Huang",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28f0",
          "name": "Haoyan Huang",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28f1",
          "name": "Jiandong Jiang",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28f2",
          "name": "Jianhong Tu",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28f3",
          "name": "Jianwei Zhang",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28f4",
          "name": "Jingren Zhou",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28f5",
          "name": "Junyang Lin",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28f6",
          "name": "Kai Dang",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28f7",
          "name": "Kexin Yang",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28f8",
          "name": "Le Yu",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28f9",
          "name": "Mei Li",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28fa",
          "name": "Minmin Sun",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28fb",
          "name": "Qin Zhu",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28fc",
          "name": "Rui Men",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28fd",
          "name": "Tao He",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28fe",
          "name": "Weijia Xu",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28ff",
          "name": "Wenbiao Yin",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d2900",
          "name": "Wenyuan Yu",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d2901",
          "name": "Xiafei Qiu",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d2902",
          "name": "Xingzhang Ren",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d2903",
          "name": "Xinlong Yang",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d2904",
          "name": "Yong Li",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d2905",
          "name": "Zhiying Xu",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d2906",
          "name": "Zipeng Zhang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-26T03:47:25.000Z",
      "title": "Qwen2.5-1M 技術報告",
      "summary": "Qwen2.5-1M モデルシリーズを紹介します。これらのモデルはコンテキスト長を1百万トークンに拡張します。前の128Kバージョンに比して、長コンテキストプレトレーニングと後プレトレーニングにより長コンテキスト能力が大幅に向上しました。長データ合成、進歩的なプレトレーニング、多段階のサブジェクト制御の最適化などのキーテクニックを使用して、長コンテキスト性能を効果的に向上させながらトレーニングコストを減らします。\n\nより広いユーザーベースに長コンテキストモデルの利用を促進するために、推論フレームワークを提供してオープンソース化します。このフレームワークは、追加のトレーニングを除きものでもモデルのコンテキスト長を少なくとも4倍以上拡大できる長コンテキスト拡大メソッドを含みます。推論コストを減らすために、スパースアタションメソッドとチャンク付きのプリフィルオプティマイズを実装し、スパースさの精確化メソッドも実装します。また、推論エンジンの最適化について詳細に説明し、カーネル最適化、パイプラインパラレリズム、スケジューリング最適化などを実施し、全体の推論性能を大幅に向上させます。\n\nこの推論フレームワークを利用することで、1百万トークンのコンテキストの場合には3倍から7倍のプリフィルスピードアップを実現できます。このフレームワークは、開放ソースモデルを使用した長コンテキスト処理のアプリケーション開発において効率的かつパワーフルな解決策を提供します。\n\n現在、Qwen2.5-1M シリーズは、オープンソースモデル Qwen2.5-7B-Instruct-1M、Qwen2.5-14B-Instruct-1M および APIアクセス可能なモデル Qwen2.5-Turbo を含みます。評価によると、Qwen2.5-1M モデルは長コンテキストタスクで大幅に向上し、短コンテキストシナリオでの性能を犠牲にしません。特に、Qwen2.5-14B-Instruct-1M モデルは長コンテキストタスクでGPT-4o-miniを大幅に超え、8倍の長コンテキストをサポートします。",
      "upvotes": 7,
      "discussionId": "67986c84b5e71350993d2974"
    },
    "publishedAt": "2025-01-28T00:35:46.871Z",
    "title": "Qwen2.5-1M Technical Report",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.15383.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5828
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.15570",
      "authors": [
        {
          "_id": "679843ae7d7b7f8196c61ab7",
          "name": "Lin Yueyu",
          "hidden": false
        },
        {
          "_id": "679843ae7d7b7f8196c61ab8",
          "name": "Li Zhiyuan",
          "hidden": false
        },
        {
          "_id": "679843ae7d7b7f8196c61ab9",
          "name": "Peter Yue",
          "hidden": false
        },
        {
          "_id": "679843ae7d7b7f8196c61aba",
          "user": {
            "_id": "6176b32847ee6431f632981e",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6176b32847ee6431f632981e/02rZ_oLAI0Ll6Y6be7Q9F.jpeg",
            "isPro": false,
            "fullname": "IvanD",
            "user": "xiaol",
            "type": "user"
          },
          "name": "Liu Xiao",
          "status": "extracted_confirmed",
          "statusLastChangedAt": "2025-01-28T02:44:02.658Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-26T15:56:56.000Z",
      "title": "ARWKV: 予ち学習は必要ない、Transformerから生まれたRNN-Attentionベースの言語モデル",
      "summary": "これまで知られているように、多ヘッドアーキテクチャでのハイブリッド二次元と次二次元アテンションモデルは、TransformerやLinear RNNモデルを超えています。これらの研究は主にKV複雑性の削減と効率向上に焦点を当てています。さらなる表現力に関する研究のために、Qwen 2.5から練習された、プライムナテブルなRWKV-7アテンションに基づくモデルシリーズを紹介します。これらのモデルはRNNの表現力を高め、Transformerよりも状態追跡能力を示します。また、QRWK 32BはRWKV-6アーキテクチャに基づき、16ドライブのAMD MI300XGPUを使用して知識処理時間を8時間に制限し、Qwen 2.5の性能を維持するように設計されています。実際、練習過程はどのようなLLMを利用できることができ、大きなLLMから小さなLLMへの知識伝達を可能にします。これらの詳細な過程を説明し、強力な基盤モデルの構築に関するフィードバックを共有します。これは継続的に更新されている進行中の研究です。モデルチェックポイントとソースコードは以下のURLで利用できます。\n\nhttps://github.com/yynil/RWKVInside\nhttps://huggingface.co/RWKV-Red-Team/ARWKV-7B-Preview-0.1",
      "upvotes": 3,
      "discussionId": "679843af7d7b7f8196c61b21"
    },
    "publishedAt": "2025-01-28T03:02:56.062Z",
    "title": "ARWKV: Pretrain is not what we need, an RNN-Attention-Based Language Model Born from Transformer",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.15570.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6176b32847ee6431f632981e",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6176b32847ee6431f632981e/02rZ_oLAI0Ll6Y6be7Q9F.jpeg",
      "fullname": "IvanD",
      "name": "xiaol",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 81
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2501.16142",
      "authors": [
        {
          "_id": "67986cbc7dbf69e4e38539b7",
          "name": "Scott Fujimoto",
          "hidden": false
        },
        {
          "_id": "67986cbc7dbf69e4e38539b8",
          "name": "Pierluca D'Oro",
          "hidden": false
        },
        {
          "_id": "67986cbc7dbf69e4e38539b9",
          "name": "Amy Zhang",
          "hidden": false
        },
        {
          "_id": "67986cbc7dbf69e4e38539ba",
          "name": "Yuandong Tian",
          "hidden": false
        },
        {
          "_id": "67986cbc7dbf69e4e38539bb",
          "name": "Michael Rabbat",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-27T15:36:37.000Z",
      "title": "一般用語でのモデル無し再強化学習のための研究",
      "summary": "強化学習（RL）は近似にも限らず問題解決のフレームワークを提供することを承諾しています。実践的には、RLアルゴリズムは特定のベンチマークに適合され、調整された超パラメータとアルゴリズムの選択に依存しています。最近、強力なモデルベースのRLメソッドは、複雑さと運行時間の拡大に伴い、複数のベンチマークで驚異的な一般的な結果を示していますが、これは広範囲的な適用性を制限しています。本論文では、広範囲のドメインと問題設定を扱うモデル無しの深層RLアルゴリズムを一つ見つけることを試みます。これを達成するために、モデルベースの表現を活用し、モデルベースのRLで使用されるより密なタスクオブジェクトを利用しながら、計画や計算ベースのトラジェクトに関連するコストを避けることで、価値関数を近似線形化します。我々のアルゴリズム、MR.Qは、一つの超パラメーターセットで多くの一般的なRLベンチマークで評価され、ドメイン専門的なベースラインと一般的なベースラインとの比較で競争的な性能を示し、一般用のモデル無しの深層RLアルゴリズムの構築に向けて具象的なステップを提供します。",
      "upvotes": 2,
      "discussionId": "67986cbf7dbf69e4e3853a89"
    },
    "publishedAt": "2025-01-28T00:36:09.186Z",
    "title": "Towards General-Purpose Model-Free Reinforcement Learning",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.16142.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5828
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.15369",
      "authors": [
        {
          "_id": "6798706dabdc35456a92212d",
          "name": "Chuanyang Zheng",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-26T02:34:58.000Z",
      "title": "iFormer: モバイルアプリケーション向けのConvNetとTransformerの統合",
      "summary": "ここでは、モバイルアプリケーションでの遅延と精度を最適化するための新しいモバイルハイブリッドビジョンネットワークの家族「iFormer」を紹介します。iFormerは、畳み込みの高速の局所的表現能力と自動注意の効率的なグローバルモデリング能力を有効に統合しています。局所的な相互作用は、標準の畳み込みネットワーク（ConvNeXt）を変換して、より軽量なモバイルネットワークを設計することにより得られます。新たに導入されたモバイルモデレーションアテンションは、MHAのメモリ負担のある操作を削減し、効率的なモデレーション機構を用いて動的なグローバル表現能力を向上させます。詳細な実験を行い、iFormerは現在の軽量ネットワークを超えるような様々なタスクで優れていることを示しています。特に、ImageNet-1kでTop-1精度が80.4%を達成し、iPhone 13での遅延が1.10msであり、類似の遅延制約下で新近に提案されたMobileNetV4を超えています。また、この方法は、COCO物体検出、インスタンス分割、ADE20k記号分割などの下流タスクにおいて顕著な向上を示し、これらのシナリオでの高解像度入力の場合にもモバイルデバイス上で低遅延を維持しています。",
      "upvotes": 1,
      "discussionId": "6798706eabdc35456a92215a"
    },
    "publishedAt": "2025-01-28T00:51:51.263Z",
    "title": "iFormer: Integrating ConvNet and Transformer for Mobile Application",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.15369.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5828
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.16295",
      "authors": [
        {
          "_id": "67986cd6bdc99911a989b0a5",
          "name": "Weixin Liang",
          "hidden": false
        },
        {
          "_id": "67986cd6bdc99911a989b0a6",
          "name": "Junhong Shen",
          "hidden": false
        },
        {
          "_id": "67986cd6bdc99911a989b0a7",
          "name": "Genghan Zhang",
          "hidden": false
        },
        {
          "_id": "67986cd6bdc99911a989b0a8",
          "name": "Ning Dong",
          "hidden": false
        },
        {
          "_id": "67986cd6bdc99911a989b0a9",
          "name": "Luke Zettlemoyer",
          "hidden": false
        },
        {
          "_id": "67986cd6bdc99911a989b0aa",
          "name": "Lili Yu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-27T18:35:05.000Z",
      "title": "Mixture-of-Mamba: モダリティに関する隠れサインを用いた多モダル状態スペースモデルの拡張",
      "summary": "ステートスペースモデル（SSMs）は、シーケンスモデリングに対するTransformersの効率的な代替として登場しましたが、モデル毎の特徴を活用できないことが、多モデル予習学習の性能に限界をもたらしています。ここで、モデル毎の隠れサインを導入する新しいSSMアーキテクチャ、Mixture-of-Mambaを提案します。これは、Mambaブロックのモデル毎のパラメータ化によって模様適応的なスパース性を導入します。Mixture-of-Transformers（W. Liang et al. arXiv:2411.04996; 2024）に基づいて、SSMにモデル毎の隠れサインの利益を延長し、計算的な効率性を維持します。Mixture-of-Mambaは、Transfusion（間接的文字と続きの画像トークンとディフュージョン損失）、Chameleon（間接的文字と離散の画像トークン）、および言語を含む拡張された三モデルフレームワークの3つの多モデル予習学習設定で評価されます。Mixture-of-Mambaは、同じ損失値を早期の訓練ステップで達成し、大幅に計算コストを削減します。Transfusion設定では、1.4Bスケールで34.76%のトレーニングFLOPを使用して等価な画像損失を達成します。Chameleon設定では、1.4Bスケールで42.50%のFLOPで類似の画像損失、65.40%のFLOPで類似の文字損失を達成します。三モデル設定では、1.4Bスケールで24.80%のFLOPで言語損失を達成します。Ablation Studyでは、デコープリングコンポーネントの解釈を行い、共同の解釈が個別の変更よりもより大きな効果を得ることが明らかになりました。これらの結果は、モデル毎の隠れサインを効果的な設計原理として、TransformersからSSMへと影響を延長し、多モデル予習学習の新たなベンチマークを設定します。コードは、https://github.com/Weixin-Liang/Mixture-of-Mambaからアクセスできます。",
      "upvotes": 1,
      "discussionId": "67986cd7bdc99911a989b0ea"
    },
    "publishedAt": "2025-01-28T00:36:31.841Z",
    "title": "Mixture-of-Mamba: Enhancing Multi-Modal State-Space Models with Modality-Aware Sparsity",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.16295.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5828
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.14912",
      "authors": [
        {
          "_id": "67986d764fccd4b95149db0b",
          "name": "Juan Ramirez",
          "hidden": false
        },
        {
          "_id": "67986d764fccd4b95149db0c",
          "name": "Ignacio Hounie",
          "hidden": false
        },
        {
          "_id": "67986d764fccd4b95149db0d",
          "name": "Juan Elenter",
          "hidden": false
        },
        {
          "_id": "67986d764fccd4b95149db0e",
          "name": "Jose Gallego-Posada",
          "hidden": false
        },
        {
          "_id": "67986d764fccd4b95149db0f",
          "name": "Meraj Hashemizadeh",
          "hidden": false
        },
        {
          "_id": "67986d764fccd4b95149db10",
          "name": "Alejandro Ribeiro",
          "hidden": false
        },
        {
          "_id": "67986d764fccd4b95149db11",
          "name": "Simon Lacoste-Julien",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-24T20:39:38.000Z",
      "title": "Feasible Learning\n\nこのテキストはすでに日本語であるため、翻訳は不要です。",
      "summary": "Feasible Learning (FL) を紹介します。FL はサンプルセンタリックな学習パラダイムで、モデルは各トレーニングサンプルの損失を制限する可能性問題を解くことでトレーニングされます。普遍的な Empirical Risk Minimization (ERM) フレームワークと比較して、ERM は平均的な性能を最適化しますが、FL はそれほどのデータ点それぞれに満足した性能を求めます。モデルが指定された性能シリードを満たすものは、FL の正当な解として認められますが、最適化アルゴリズムの選択およびその動態は、結果として得られる解の性質を形成する重要な役割を果たします。特に、実際の問題の解決に向けて、学習中にそれぞれのサンプルの重要性を動的に再評価するための主観-対観的アプローチを研究しています。実際の問題の解決に向けて、有意なシリードを設定する難題を解決するために、最小なノルムのスラック変数を含むFLの放題を導入します。画像分類、年齢回帰、大規模な言語モデルの好み最適化を含む実験分析では、FL によってトレーニングされたモデルは、ERM と比較して平均的な性能にさらなる影響を与えないものの、データから学習しながらもテールバイエローを改善した性能を示します。",
      "upvotes": 0,
      "discussionId": "67986d784fccd4b95149db6b"
    },
    "publishedAt": "2025-01-28T00:39:11.423Z",
    "title": "Feasible Learning",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.14912.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5828
    },
    "isAuthorParticipating": false
  }
]