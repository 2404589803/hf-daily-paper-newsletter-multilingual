[
  {
    "paper": {
      "id": "2502.18411",
      "authors": [
        {
          "_id": "67be834ae7b05f9e43b172b2",
          "user": {
            "_id": "6530e62f536dbca918e71c3e",
            "avatarUrl": "/avatars/efc93bc767e561c6c6d429f65c23382d.svg",
            "isPro": false,
            "fullname": "Xiangyu Z",
            "user": "PhoenixZ",
            "type": "user"
          },
          "name": "Xiangyu Zhao",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-26T08:26:02.247Z",
          "hidden": false
        },
        {
          "_id": "67be834ae7b05f9e43b172b3",
          "user": {
            "_id": "646cd947da8e99940b6e55cf",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/646cd947da8e99940b6e55cf/9c0P0WppFqNW9pdo8LgOS.jpeg",
            "isPro": false,
            "fullname": "Shengyuan Ding",
            "user": "ChrisDing1105",
            "type": "user"
          },
          "name": "Shengyuan Ding",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-26T08:25:59.887Z",
          "hidden": false
        },
        {
          "_id": "67be834ae7b05f9e43b172b4",
          "user": {
            "_id": "675aa937ab6aa7ecd09341ce",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/d_CNUsNOw92pg7MVhf9Vm.png",
            "isPro": false,
            "fullname": "Zicheng Zhang",
            "user": "UniverseCA",
            "type": "user"
          },
          "name": "Zicheng Zhang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:49:10.028Z",
          "hidden": false
        },
        {
          "_id": "67be834ae7b05f9e43b172b5",
          "name": "Haian Huang",
          "hidden": false
        },
        {
          "_id": "67be834ae7b05f9e43b172b6",
          "name": "Maosong Cao",
          "hidden": false
        },
        {
          "_id": "67be834ae7b05f9e43b172b7",
          "user": {
            "_id": "619507e7b74b6c591f794340",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/619507e7b74b6c591f794340/JbPDoy6Ko1V1-6oJJwFV8.jpeg",
            "isPro": false,
            "fullname": "Weiyun Wang",
            "user": "Weiyun1025",
            "type": "user"
          },
          "name": "Weiyun Wang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:48:45.520Z",
          "hidden": false
        },
        {
          "_id": "67be834ae7b05f9e43b172b8",
          "user": {
            "_id": "64638c4d51fa6e63060521b5",
            "avatarUrl": "/avatars/c863ace5b1dc788a341bcf4ddbdfaec1.svg",
            "isPro": false,
            "fullname": "JIaqi",
            "user": "Jiaqiwang",
            "type": "user"
          },
          "name": "Jiaqi Wang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:48:38.876Z",
          "hidden": false
        },
        {
          "_id": "67be834ae7b05f9e43b172b9",
          "user": {
            "_id": "64f5f8dd9b17cd59c453c57f",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64f5f8dd9b17cd59c453c57f/MulhwLcePFUWUQel8LQZ8.jpeg",
            "isPro": false,
            "fullname": "Xinyu Fang",
            "user": "nebulae09",
            "type": "user"
          },
          "name": "Xinyu Fang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-26T08:26:04.433Z",
          "hidden": false
        },
        {
          "_id": "67be834ae7b05f9e43b172ba",
          "user": {
            "_id": "64d1c560c0c627dfa71bdbe0",
            "avatarUrl": "/avatars/f42794fe25bffcd870a1bcee69b95298.svg",
            "isPro": false,
            "fullname": "wenhai.wang",
            "user": "wangwhcore",
            "type": "user"
          },
          "name": "Wenhai Wang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:48:28.151Z",
          "hidden": false
        },
        {
          "_id": "67be834ae7b05f9e43b172bb",
          "name": "Guangtao Zhai",
          "hidden": false
        },
        {
          "_id": "67be834ae7b05f9e43b172bc",
          "user": {
            "_id": "63ee1379190ddd6214efd73a",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1676546883247-noauth.png",
            "isPro": false,
            "fullname": "HAODONG DUAN",
            "user": "KennyUTC",
            "type": "user"
          },
          "name": "Haodong Duan",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:48:20.155Z",
          "hidden": false
        },
        {
          "_id": "67be834ae7b05f9e43b172bd",
          "name": "Hua Yang",
          "hidden": false
        },
        {
          "_id": "67be834ae7b05f9e43b172be",
          "name": "Kai Chen",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-25T18:05:14.000Z",
      "title": "OmniAlign-V: 人間の好みとMLLMの対応向上のために",
      "summary": "最近の開放ソース多モデル大語言モデル（MLLM）の進展は、主に基盤的な能力を向上させることに焦点を当てていますが、人間の好みに合わせることについては大きな欠陥があります。本論文では、OmniAlign-Vという、200K件の高品質の訓練サンプルを特徴とした、様々な画像、複雑な質問、そして多様な回答形式を挙げる、一様的なデータセットを紹介します。これらは、MLLMの人間の好みに合わせることを改善することを目的としています。また、MM-AlignBenchという、人間の注釈されたベンチマークを紹介し、これはMLLMの人間の価値に合わせることを評価するために特に設計されています。実験結果によると、OmniAlign-Vを用いた、Supervised Fine-Tuning（SFT）またはDirect Preference Optimization（DPO）を用いたMLLMの微調節は、標準的なVQAベンチマークでの性能を維持または向上させながら、人間の好みに合わせることを大幅に向上させ、その基盤的な能力を保持することができます。我々のデータセット、ベンチマーク、コードとチェックポイントは、https://github.com/PhoenixZ810/OmniAlign-Vに公開されています。",
      "upvotes": 46,
      "discussionId": "67be834ce7b05f9e43b1730a"
    },
    "publishedAt": "2025-02-25T22:01:56.532Z",
    "title": "OmniAlign-V: Towards Enhanced Alignment of MLLMs with Human Preference",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.18411.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6530e62f536dbca918e71c3e",
      "avatarUrl": "/avatars/efc93bc767e561c6c6d429f65c23382d.svg",
      "fullname": "Xiangyu Z",
      "name": "PhoenixZ",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.18137",
      "authors": [
        {
          "_id": "67be8443ed8e258c0f70063a",
          "user": {
            "_id": "66c0a08bac74db25de8427ec",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/66c0a08bac74db25de8427ec/9D-piDBZqSt6KNkHImmkv.jpeg",
            "isPro": false,
            "fullname": "Jintao Zhang",
            "user": "jt-zhang",
            "type": "user"
          },
          "name": "Jintao Zhang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-26T08:25:57.704Z",
          "hidden": false
        },
        {
          "_id": "67be8443ed8e258c0f70063b",
          "user": {
            "_id": "6329bdbbde087eac2921e6a9",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1663679904323-noauth.jpeg",
            "isPro": false,
            "fullname": "Xiangchendong",
            "user": "Xiang-cd",
            "type": "user"
          },
          "name": "Chendong Xiang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:49:29.341Z",
          "hidden": false
        },
        {
          "_id": "67be8443ed8e258c0f70063c",
          "name": "Haofeng Huang",
          "hidden": false
        },
        {
          "_id": "67be8443ed8e258c0f70063d",
          "name": "Jia Wei",
          "hidden": false
        },
        {
          "_id": "67be8443ed8e258c0f70063e",
          "user": {
            "_id": "65d5a000ec7e31555e4db57e",
            "avatarUrl": "/avatars/aab8319fbaffdd53faff59a40ca5a5ea.svg",
            "isPro": false,
            "fullname": "Haocheng Xi",
            "user": "hxi0408",
            "type": "user"
          },
          "name": "Haocheng Xi",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:49:45.446Z",
          "hidden": false
        },
        {
          "_id": "67be8443ed8e258c0f70063f",
          "name": "Jun Zhu",
          "hidden": false
        },
        {
          "_id": "67be8443ed8e258c0f700640",
          "user": {
            "_id": "65fcad0ba0d7adc40b54fac2",
            "avatarUrl": "/avatars/7564b5642378fddb46ec3b5ae57c0402.svg",
            "isPro": false,
            "fullname": "Jianfei Chen",
            "user": "surfingtomchen",
            "type": "user"
          },
          "name": "Jianfei Chen",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:49:52.550Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-25T12:02:17.000Z",
      "title": "SpargeAttn: 正確なスパースアテンションです。これは、どのモデルの推論を加速するためのアプローチです。",
      "summary": "大モデルにおいて、効率的なアタションの実装が重要であるのは、その二次元時間複雑性からである。幸い、アタションは通常稀疏性を示す、すなわち、アタションマップにある多くの値が近似していることにより、相対的な計算を省略することができる。多くの研究は、稀疏パターンを利用してアタションを高速化することを試みている。しかし、現在の多数の研究は、特定のモデル内でのアタションの最適化を目的として、アタションマップの特定の稀疏パターンを利用している。多様なモデルの両方のスピードアップと端末から端末までの性能を保証する普遍的な稀疏アタションは、現在までに見つかりませんでした。本論文中では、SpargeAttnという普遍的な稀疏および量子化アタションを、どのモデルでも使用可能にするものを提案します。我々の方法は、二段階のオンラインフィルタを使用しています：最初の段階では、アタションマップを迅速に正確に予測し、アタションの一部の行列積をスキップすることを可能にします。第二の段階では、オンラインソフトマックスに関連付けられたフィルタを設計し、追加のオーバーヘッドを課しないもので、より多くの行列積をスキップすることができます。実験は、我々の方法が言語、画像、ビデオの生成など多様なモデルを高速化し、端末から端末までのメトリックを失わずに行うことを示しています。コードは、https://github.com/thu-ml/SpargeAttn に公開されています。",
      "upvotes": 33,
      "discussionId": "67be8447ed8e258c0f70075f"
    },
    "publishedAt": "2025-02-25T22:04:57.351Z",
    "title": "SpargeAttn: Accurate Sparse Attention Accelerating Any Model Inference",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.18137.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "66c0a08bac74db25de8427ec",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/66c0a08bac74db25de8427ec/9D-piDBZqSt6KNkHImmkv.jpeg",
      "fullname": "Jintao Zhang",
      "name": "jt-zhang",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.17363",
      "authors": [
        {
          "_id": "67bd6d2bbf6d46017e619f31",
          "user": {
            "_id": "66078994c50f8393c56ed837",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/aYYde45zaFACRllyEhJyU.jpeg",
            "isPro": true,
            "fullname": "Tianrui Zhu",
            "user": "xilluill",
            "type": "user"
          },
          "name": "Tianrui Zhu",
          "status": "extracted_confirmed",
          "statusLastChangedAt": "2025-02-25T07:24:35.845Z",
          "hidden": false
        },
        {
          "_id": "67bd6d2bbf6d46017e619f32",
          "user": {
            "_id": "6315d306a9456afe2b9bf34a",
            "avatarUrl": "/avatars/7285b4e7d84b528d1a50f8ee4eb10727.svg",
            "isPro": false,
            "fullname": "ElevenZ",
            "user": "shiyi0408",
            "type": "user"
          },
          "name": "Shiyi Zhang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-26T08:30:48.262Z",
          "hidden": false
        },
        {
          "_id": "67bd6d2bbf6d46017e619f33",
          "user": {
            "_id": "646c6985d072747f7ebf352a",
            "avatarUrl": "/avatars/8aaf92045687b21b56c257db62bf4fa5.svg",
            "isPro": false,
            "fullname": "Jiawei Shao",
            "user": "jewelshaw",
            "type": "user"
          },
          "name": "Jiawei Shao",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:50:09.030Z",
          "hidden": false
        },
        {
          "_id": "67bd6d2bbf6d46017e619f34",
          "name": "Yansong Tang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-24T17:40:09.000Z",
      "title": "KV-Edit: トレーニング無しの画像編集技術で、正確な背景保存が可能",
      "summary": "背景一致性は、画像編集タスクでは重要な課題であり、現在の技術はこの課題について長年間開発してきました。現在の研究では、元画像との類似性を保つことと、目標に合わせた内容を生成することとの調和が難しいという課題が残されています。ここで、KV-Editというトレーニング不要のアプローチを提案します。KV-Editは、DiTsのKVキャッシュを使用して、背景の一致性を維持することで背景トークンを保存し、再生されないようにし、複雑な機構や費用の高いトレーニングが必要とならないようにし、ユーザーが提供した領域内で背景と無間断に新しい内容を生成することを目指しています。また、編集中のKVキャッシュのメモリ消費を詳細に調査し、反転無しの方法を用いて空間複雑さをO(1)に最適化しました。我々のアプローチは、追加のトレーニングを必要としないように、DiTベースの生成モデルとの拡張性を維持しています。実験により、KV-Editは背景と画像の品質の両方で、現在のアプローチを大幅に超えることを示し、トレーニングベースの方法を超えることも証明しました。プロジェクトのウェブページは、https://xilluill.github.io/projectpages/KV-Editに公開されています。",
      "upvotes": 22,
      "discussionId": "67bd6d2dbf6d46017e619f99"
    },
    "publishedAt": "2025-02-25T21:36:19.851Z",
    "title": "KV-Edit: Training-Free Image Editing for Precise Background Preservation",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.17363.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "66078994c50f8393c56ed837",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/aYYde45zaFACRllyEhJyU.jpeg",
      "fullname": "Tianrui Zhu",
      "name": "xilluill",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.18449",
      "authors": [
        {
          "_id": "67be845a8a5a80542314579f",
          "user": {
            "_id": "632a176259950c1d279d5ea7",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/632a176259950c1d279d5ea7/xsSGhBXalt9RaKzSKY8uk.jpeg",
            "isPro": false,
            "fullname": "Yuxiang Wei",
            "user": "yuxiang630",
            "type": "user"
          },
          "name": "Yuxiang Wei",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:50:44.837Z",
          "hidden": false
        },
        {
          "_id": "67be845a8a5a8054231457a0",
          "name": "Olivier Duchenne",
          "hidden": false
        },
        {
          "_id": "67be845a8a5a8054231457a1",
          "user": {
            "_id": "6481e0ac50b759c75d5fdad0",
            "avatarUrl": "/avatars/49f08d989ca505ae01bce5578a94f6fe.svg",
            "isPro": false,
            "fullname": "Jade Copet",
            "user": "JadeCopet",
            "type": "user"
          },
          "name": "Jade Copet",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:50:58.290Z",
          "hidden": false
        },
        {
          "_id": "67be845a8a5a8054231457a2",
          "name": "Quentin Carbonneaux",
          "hidden": false
        },
        {
          "_id": "67be845a8a5a8054231457a3",
          "user": {
            "_id": "656f473c14fa8cfccd14559e",
            "avatarUrl": "/avatars/8f4fef3d835a7a11c2ab66dbf04f3424.svg",
            "isPro": false,
            "fullname": "Lingming Zhang",
            "user": "lingming",
            "type": "user"
          },
          "name": "Lingming Zhang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:51:10.640Z",
          "hidden": false
        },
        {
          "_id": "67be845a8a5a8054231457a4",
          "name": "Daniel Fried",
          "hidden": false
        },
        {
          "_id": "67be845a8a5a8054231457a5",
          "user": {
            "_id": "630eac7931970d1cd4fbacf2",
            "avatarUrl": "/avatars/b7ccbddfa745db854dc342be1327cd53.svg",
            "isPro": false,
            "fullname": "Gabriel Synnaeve",
            "user": "gsynnaeve",
            "type": "user"
          },
          "name": "Gabriel Synnaeve",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:51:21.641Z",
          "hidden": false
        },
        {
          "_id": "67be845a8a5a8054231457a6",
          "user": {
            "_id": "6597e5a6420dcc68501a69e9",
            "avatarUrl": "/avatars/da48b13e07c367ecd5c891abfd6c3ded.svg",
            "isPro": false,
            "fullname": "Rishabh Singh",
            "user": "RishabhSingh021",
            "type": "user"
          },
          "name": "Rishabh Singh",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:51:28.321Z",
          "hidden": false
        },
        {
          "_id": "67be845a8a5a8054231457a7",
          "name": "Sida I. Wang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-25T18:45:04.000Z",
      "title": "SWE-RL: 開放ソフトウェア進化における強化学習によるLLM推論の進歩",
      "summary": "最近のDeepSeek-R1のリリースは、大規模言語モデル（LLMs）の一般的な理由能力を強化するために強化学習（RL）の巨大なポテンシャルを示しました。DeepSeek-R1および他の連続する仕事は主に強化学習を競馬コーディングおよび数学問題に適用していますが、この論文ではSWE-RL、RLベースのLLMの理由を実世界的なソフトウェアエンジニアリングに拡大する最初のアプローチを紹介します。軽量なルールベースの報酬（例えば、真実とLLM生成の解決策の類似スコア）を活用し、SWE-RLはLLMが開放ソースソフトウェアの進化データから開発者の理由プロセスと解決策を自動的に復元することを可能にします—ソフトウェアのシンテライサイクルの記録、コードスナップショット、コード変更、バグやリプレースリクエストなどのイベントを含む—。Llama 3の上にトレーニングした結果、我々の理由モデル、Llama3-SWE-RL-70Bは、SWE-bench Verified—GitHubの実世界的な問題の人間認証の集合—で41.0%の解決率を達成しました。私たちの知識によると、これは現在までに報告されている中型（<100B）LLMsの最良の性能で、GPT-4oなどの先進的な専有LLMsと比較的にも相当しています。驚くべきことに、ソフトウェア進化データに限り強化学習を行ったLlama3-SWE-RLは、拡張的な理由能力を発見しました。例えば、関数コーディング、ライブラリ使用、コード理由、数学、一般的な言語理解の5つの外域タスクで改善された結果を示し、観覧的な訓練ベース線形フィーチングは平均的に性能低下を招致しました。全体として、SWE-RLは、強化学習を大規模なソフトウェアエンジニアリングデータによってLLMの理由能力を向上させる新しい方向を開拓します。",
      "upvotes": 14,
      "discussionId": "67be845b8a5a8054231457d6"
    },
    "publishedAt": "2025-02-25T22:03:08.515Z",
    "title": "SWE-RL: Advancing LLM Reasoning via Reinforcement Learning on Open Software Evolution",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.18449.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 6218
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.17262",
      "authors": [
        {
          "_id": "67bd3870a917fc506d9f3d15",
          "user": {
            "_id": "66ab06956b8847339d449128",
            "avatarUrl": "/avatars/d71490acb91981459121005b84e556d8.svg",
            "isPro": false,
            "fullname": "Xu Chengyin",
            "user": "JerryXu98",
            "type": "user"
          },
          "name": "Chengyin Xu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-25T09:39:44.252Z",
          "hidden": false
        },
        {
          "_id": "67bd3870a917fc506d9f3d16",
          "user": {
            "_id": "636b4d796e6981ebad73f398",
            "avatarUrl": "/avatars/bcd405b98c12afaf1e32d85ad8ce7f23.svg",
            "isPro": false,
            "fullname": "Kaiyuan Chen",
            "user": "Lucky2022",
            "type": "user"
          },
          "name": "Kaiyuan Chen",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-25T09:40:01.532Z",
          "hidden": false
        },
        {
          "_id": "67bd3870a917fc506d9f3d17",
          "name": "Xiao Li",
          "hidden": false
        },
        {
          "_id": "67bd3870a917fc506d9f3d18",
          "user": {
            "_id": "645604eebabbbbd3486dc615",
            "avatarUrl": "/avatars/17a5ca8274e2bfc8f183a4af9878a930.svg",
            "isPro": false,
            "fullname": "shenke",
            "user": "shenke18",
            "type": "user"
          },
          "name": "Ke Shen",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-25T09:39:49.578Z",
          "hidden": false
        },
        {
          "_id": "67bd3870a917fc506d9f3d19",
          "name": "Chenggang Li",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-24T15:44:57.000Z",
      "title": "LLMの下流実績のスケーリングを明らかにする：クラスタリングベースの視点",
      "summary": "進歩の急速な計算機の進展は、大規模言語モデル（LLM）の訓練のスケールとコストを大幅に増加させます。モデル訓練前に下流タスクの性能を正確に予測することは、効率的なリソース配分に重要ですが、2つの主要な制約により難しいです：（1）「現象」、これにより下流の性能メトリックは詳細な訓練後に意味がありますが、これは小さなモデルを使用して予測する能力を制限します；（2）タスクの難易度分布の不均一さと一貫したスケーリング法則のないこと、メトリックの大幅な変動をもたらします。現在の性能予測方法は精度と信頼性の限界であり、LLMの潜在的な能力の評価に妨げます。これらの課題に対処するために、COD（Difficultyに基づくクラスタリング）下流性能予測フレームワークを提案します。CODは、難易度特徴に基づいてタスクをクラスタリングして予測可能なサポートサブセットを構築し、非現象的で非スケーリング的なクラスターを戦略的に除外します。選択されたサブセットのスコアは、全評価セットの下流性能に効果的な中間予測子として使用されます。理論的な支援をもち、予測可能なサブセットからの性能メトリックを全評価セットに変換する関数を得ます。提案された方法は、70B LLMの性能スケーリング予測に応用され、訓練リソースの配分に役立つ行動可能なエインサイドを提供し、訓練プロセスの観測に役立ちます。特に、CODは、小さなモデルのエンサンブルを利用して70B LLMで顕著な予測精度を達成し、8つの重要なLLM評価ベンチマークにおいて絶対的な平均異常度が1.36%でした。",
      "upvotes": 13,
      "discussionId": "67bd3872a917fc506d9f3d8f"
    },
    "publishedAt": "2025-02-25T22:18:24.064Z",
    "title": "Unveiling Downstream Performance Scaling of LLMs: A Clustering-Based Perspective",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.17262.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "636b4d796e6981ebad73f398",
      "avatarUrl": "/avatars/bcd405b98c12afaf1e32d85ad8ce7f23.svg",
      "fullname": "Kaiyuan Chen",
      "name": "Lucky2022",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.15499",
      "authors": [
        {
          "_id": "67be86743ea16c7e9491ff16",
          "name": "Ya Wang",
          "hidden": false
        },
        {
          "_id": "67be86743ea16c7e9491ff17",
          "user": {
            "_id": "66335b9c95c5b79ebf306f30",
            "avatarUrl": "/avatars/d57784ee65cbef014360c9bac1ad4119.svg",
            "isPro": false,
            "fullname": "Zhijian Zhuo",
            "user": "BryceZhuo",
            "type": "user"
          },
          "name": "Zhijian Zhuo",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:58:10.556Z",
          "hidden": false
        },
        {
          "_id": "67be86743ea16c7e9491ff18",
          "user": {
            "_id": "6371128eafbe42caa5a5222b",
            "avatarUrl": "/avatars/c3b2ab35949c38aa3dfb2657a1300aac.svg",
            "isPro": false,
            "fullname": "Yutao Zeng",
            "user": "Taoer",
            "type": "user"
          },
          "name": "Yutao Zeng",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-26T08:25:55.016Z",
          "hidden": false
        },
        {
          "_id": "67be86743ea16c7e9491ff19",
          "user": {
            "_id": "62533db4a06ec75172eeabe7",
            "avatarUrl": "/avatars/b1a4dad90afae5c00df97233a97777db.svg",
            "isPro": false,
            "fullname": "xunzhou",
            "user": "xunzhou",
            "type": "user"
          },
          "name": "Xun Zhou",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:52:26.974Z",
          "hidden": false
        },
        {
          "_id": "67be86743ea16c7e9491ff1a",
          "name": "Jian Yang",
          "hidden": false
        },
        {
          "_id": "67be86743ea16c7e9491ff1b",
          "user": {
            "_id": "64648638351adef1a847a7ad",
            "avatarUrl": "/avatars/7518e058fcf81ee81a06c96e996531e9.svg",
            "isPro": false,
            "fullname": "Xiaoqing Li",
            "user": "LLIXQ",
            "type": "user"
          },
          "name": "Xiaoqing Li",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:51:57.314Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-21T14:49:34.000Z",
      "title": "スケール分布の離脱：大規模言語モデルの安定したよく効果的な訓練を可能にする",
      "summary": "訓練の安定性は、大規模言語モデル（LLM）の事前学習において長期的な課題であり、特にPost-Norm Transformerなどのアーキテクチャが勾配の爆発と消散により脆弱です。本研究では、勾配の爆発と消散を防ぎ、訓練を安定化するために、勾配の伝播の安定化を実現する新しいアプローチ「スケール・分布の離脱（SDD）」を提案します。SDDは、全結合層の重み行列のスケールと分布を明示的に離脱し、活性化を調節する正規化機構と学習可能なスケーリングベクトルを用います。これにより、勾配の爆発と消散を防ぎ、最適化の効率化を実現します。この分離は、勾配の安定な伝播を確保し、特に深いネットワークでも効果的です。実験結果は、様々なLLMアーキテクチャでの訓練の安定性を確保し、異なる正規化設定でも既存の手法を上回ることを示します。また、提案された方法は軽量で、既存のフレームワークとの相性が良く、LLMの訓練の安定化の実用的な解決策として効果的です。コードはhttps://github.com/kaihemo/SDDから利用可能です。",
      "upvotes": 10,
      "discussionId": "67be86753ea16c7e9491ff49"
    },
    "publishedAt": "2025-02-25T22:26:11.421Z",
    "title": "Scale-Distribution Decoupling: Enabling Stable and Effective Training of Large Language Models",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/6371128eafbe42caa5a5222b/eu6jpeTjTn34I1SJ4_K1a.png",
      "https://cdn-uploads.huggingface.co/production/uploads/6371128eafbe42caa5a5222b/P6mXXagZPsH6fwQ6myMlr.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.15499.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6371128eafbe42caa5a5222b",
      "avatarUrl": "/avatars/c3b2ab35949c38aa3dfb2657a1300aac.svg",
      "fullname": "Yutao Zeng",
      "name": "Taoer",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.18364",
      "authors": [
        {
          "_id": "67be81414084d82ee69ad4a2",
          "user": {
            "_id": "647e83257f9ad5e44babe82a",
            "avatarUrl": "/avatars/2d9593775c49856fe5dfa5bd23dfcda7.svg",
            "isPro": false,
            "fullname": "yifan pu",
            "user": "yifanpu001",
            "type": "user"
          },
          "name": "Yifan Pu",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:58:24.942Z",
          "hidden": false
        },
        {
          "_id": "67be81414084d82ee69ad4a3",
          "user": {
            "_id": "65e78ebf24a38e0fc5e149e6",
            "avatarUrl": "/avatars/d05e267f29de7de226c4fc0ae37c95ff.svg",
            "isPro": false,
            "fullname": "Yiming Zhao",
            "user": "2JZ",
            "type": "user"
          },
          "name": "Yiming Zhao",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:58:30.860Z",
          "hidden": false
        },
        {
          "_id": "67be81414084d82ee69ad4a4",
          "name": "Zhicong Tang",
          "hidden": false
        },
        {
          "_id": "67be81414084d82ee69ad4a5",
          "name": "Ruihong Yin",
          "hidden": false
        },
        {
          "_id": "67be81414084d82ee69ad4a6",
          "user": {
            "_id": "65229f2f6b01183a67e86370",
            "avatarUrl": "/avatars/b218207fce28497b30e22c807d44b2d2.svg",
            "isPro": false,
            "fullname": "Haoxing Ye",
            "user": "131131yhx",
            "type": "user"
          },
          "name": "Haoxing Ye",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:58:52.821Z",
          "hidden": false
        },
        {
          "_id": "67be81414084d82ee69ad4a7",
          "name": "Yuhui Yuan",
          "hidden": false
        },
        {
          "_id": "67be81414084d82ee69ad4a8",
          "user": {
            "_id": "666470a28f5513b0cf11e850",
            "avatarUrl": "/avatars/7beea758882677ad32a12ce56d4d084a.svg",
            "isPro": false,
            "fullname": "Dong Chen",
            "user": "DongChen06",
            "type": "user"
          },
          "name": "Dong Chen",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:59:16.526Z",
          "hidden": false
        },
        {
          "_id": "67be81414084d82ee69ad4a9",
          "user": {
            "_id": "646b2f4bb1202bc77c0fb396",
            "avatarUrl": "/avatars/6b09dec5d5affe817ad6acda60f61740.svg",
            "isPro": false,
            "fullname": "Jianmin_bao",
            "user": "JianminBao",
            "type": "user"
          },
          "name": "Jianmin Bao",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:59:22.654Z",
          "hidden": false
        },
        {
          "_id": "67be81414084d82ee69ad4aa",
          "user": {
            "_id": "64f7f119a92703ef65d9a717",
            "avatarUrl": "/avatars/118524faab66cecba6d4da622034b44b.svg",
            "isPro": false,
            "fullname": "Sirui Zhang",
            "user": "zsr200901",
            "type": "user"
          },
          "name": "Sirui Zhang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:59:30.766Z",
          "hidden": false
        },
        {
          "_id": "67be81414084d82ee69ad4ab",
          "user": {
            "_id": "67965a5a9f57883759a6efc3",
            "avatarUrl": "/avatars/9138a879fbe1f60c2f4720810bfdfda6.svg",
            "isPro": false,
            "fullname": "Yanbin Wang",
            "user": "yanbinwang",
            "type": "user"
          },
          "name": "Yanbin Wang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:59:38.138Z",
          "hidden": false
        },
        {
          "_id": "67be81414084d82ee69ad4ac",
          "name": "Lin Liang",
          "hidden": false
        },
        {
          "_id": "67be81414084d82ee69ad4ad",
          "user": {
            "_id": "6672e20d1dbdf7da8310dd92",
            "avatarUrl": "/avatars/5d2fb23f92a7f9ff025a5be17a26de4d.svg",
            "isPro": false,
            "fullname": "lijuanwang",
            "user": "lijuanwang228",
            "type": "user"
          },
          "name": "Lijuan Wang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T09:00:05.520Z",
          "hidden": false
        },
        {
          "_id": "67be81414084d82ee69ad4ae",
          "name": "Ji Li",
          "hidden": false
        },
        {
          "_id": "67be81414084d82ee69ad4af",
          "name": "Xiu Li",
          "hidden": false
        },
        {
          "_id": "67be81414084d82ee69ad4b0",
          "user": {
            "_id": "64c882f7527d7636555bbb2c",
            "avatarUrl": "/avatars/578a118a945dd6fa62fd3be9d6e4e986.svg",
            "isPro": false,
            "fullname": "Zhouhui Lian",
            "user": "lianzhouhui",
            "type": "user"
          },
          "name": "Zhouhui Lian",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:59:57.943Z",
          "hidden": false
        },
        {
          "_id": "67be81414084d82ee69ad4b1",
          "name": "Gao Huang",
          "hidden": false
        },
        {
          "_id": "67be81414084d82ee69ad4b2",
          "name": "Baining Guo",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-25T16:57:04.000Z",
      "title": "ART: 変数多層透明画像生成のための匿名領域Transformer",
      "summary": "多層画像生成は、ユーザーが特定の画像レイヤーを孤立、選択、編集することを可能にし、生成モデルとの相互作用を革命的に変える基本的な任務です。本論文では、グローバルのテキストプラントと匿名な領域配置に基づいて変数の多層透明画像を直接生成するAnonymous Region Transformer（ART）を介して、これを導入します。シンプタティー理論による知識の構造化をモデルとして、先行の主導的な語意的な領域配置と異なり、ARTは生成モデルが自動的にテキストトークンとビジュアルトークンの対応を決定することを可能にします。また、層ごとの領域クロップ機構は、各匿名領域に属するビジュアルトークンのみを選択することで、注意計算コストを大幅に減少し、多層（例えば50以上）の画像の効率的な生成を可能にします。全注意アプローチに比べて12倍以上速く、レイヤーの衝突が少なくなります。また、ARTは、効率的な層の生成と可視性の精密な制御を可能にし、新しいインタラクティブなコンテンツ作成パラダイムを構築します。",
      "upvotes": 7,
      "discussionId": "67be81464084d82ee69ad576"
    },
    "publishedAt": "2025-02-25T21:50:19.941Z",
    "title": "ART: Anonymous Region Transformer for Variable Multi-Layer Transparent Image Generation",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.18364.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "646f69a6041e48e1c4728de3",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/646f69a6041e48e1c4728de3/U5OaW6PgsXTXnfG03xs9Q.png",
      "fullname": "GlyphByT5",
      "name": "GlyphByT5",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 34
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.18461",
      "authors": [
        {
          "_id": "67bea0cc2d6011a72335f704",
          "user": {
            "_id": "67be9daa65ae638b17e461e9",
            "avatarUrl": "/avatars/30ab04b8a6a4d3e1d211943c0344b95e.svg",
            "isPro": false,
            "fullname": "Ziheng Ouyang",
            "user": "oyzh2005",
            "type": "user"
          },
          "name": "Ziheng Ouyang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-26T08:25:46.941Z",
          "hidden": false
        },
        {
          "_id": "67bea0cc2d6011a72335f705",
          "name": "Zhen Li",
          "hidden": false
        },
        {
          "_id": "67bea0cc2d6011a72335f706",
          "name": "Qibin Hou",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-25T18:59:12.000Z",
      "title": "K-LoRA: どのセクトとスタイルのLoRAを無料で融合する方法",
      "summary": "最近の研究は、学習済みのスタイルと内容を共に生成するために異なるLoRAを組み合わせる方法を検討しています。しかし、現在の方法は、両方の元の主題とスタイルを同時に有効に保存することができないか、または追加的な訓練が必要となる場合が多いです。本論文では、LoRAの内在的な特性が拡散モデルに学習済みの主題とスタイルを融合させることを有効にガイドすることができることを主張します。この見通しに基づいて、K-LoRAという簡単で効果的な訓練不要のLoRA融合アプローチを提案します。各アテンション層では、K-LoRAは融合するLoRAのTop-K要素を比較し、最適な融合に適したLoRAを選択します。この選択機構は、融合プロセスで主題とスタイルの最も代表的な特徴を保持することを確保し、それらの貢献を効果的にバランスします。実験結果は、提案した方法が元のLoRAが学習した主題とスタイル情報を有効に統合し、質的的および量的な結果で最先端の訓練基準のアプローチを上回ることを示しています。",
      "upvotes": 6,
      "discussionId": "67bea0cf2d6011a72335f7aa"
    },
    "publishedAt": "2025-02-26T00:56:27.275Z",
    "title": "K-LoRA: Unlocking Training-Free Fusion of Any Subject and Style LoRAs",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.18461.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6285a9133ab6642179158944",
      "avatarUrl": "/avatars/6e10fa07c94141fcdbe0cab02bb731ca.svg",
      "fullname": "Zhen Li",
      "name": "Paper99",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 14
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.18356",
      "authors": [
        {
          "_id": "67be8866823e790d21a2bb90",
          "user": {
            "_id": "6529aa1460e706730575baa9",
            "avatarUrl": "/avatars/550fac58a6ebf937a65d19a48e71eb45.svg",
            "isPro": false,
            "fullname": "George Thomas",
            "user": "georgethomas",
            "type": "user"
          },
          "name": "George Thomas",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T09:06:53.500Z",
          "hidden": false
        },
        {
          "_id": "67be8866823e790d21a2bb91",
          "user": {
            "_id": "636c1e4415cd58e915bc45df",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/636c1e4415cd58e915bc45df/KnPgdPe0G5ngvXaCBua6R.jpeg",
            "isPro": false,
            "fullname": "Alex J. Chan",
            "user": "XanderJC",
            "type": "user"
          },
          "name": "Alex J. Chan",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-02-26T03:20:08.029Z",
          "hidden": false
        },
        {
          "_id": "67be8866823e790d21a2bb92",
          "name": "Jikun Kang",
          "hidden": false
        },
        {
          "_id": "67be8866823e790d21a2bb93",
          "user": {
            "_id": "63a2f1dfc8a2aa5d9e85f8f6",
            "avatarUrl": "/avatars/f2191e3a0ce92563f9bfe83283d8d966.svg",
            "isPro": false,
            "fullname": "Wenqi Wu",
            "user": "BiggieW",
            "type": "user"
          },
          "name": "Wenqi Wu",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T09:08:43.843Z",
          "hidden": false
        },
        {
          "_id": "67be8866823e790d21a2bb94",
          "user": {
            "_id": "64f46b681d337935d0495d4d",
            "avatarUrl": "/avatars/cce5a4910617931fb13062b832e14ef8.svg",
            "isPro": false,
            "fullname": "Filippos Christianos",
            "user": "semitable",
            "type": "user"
          },
          "name": "Filippos Christianos",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T09:08:23.534Z",
          "hidden": false
        },
        {
          "_id": "67be8866823e790d21a2bb95",
          "user": {
            "_id": "5f195784925b9863e28ad610",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1595496291585-noauth.png",
            "isPro": false,
            "fullname": "Fraser Greenlee",
            "user": "Fraser",
            "type": "user"
          },
          "name": "Fraser Greenlee",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T09:08:16.380Z",
          "hidden": false
        },
        {
          "_id": "67be8866823e790d21a2bb96",
          "name": "Andy Toulis",
          "hidden": false
        },
        {
          "_id": "67be8866823e790d21a2bb97",
          "user": {
            "_id": "6787c4a970c0f5272f456968",
            "avatarUrl": "/avatars/bdfa53add57b0f0a9e4e94e24115b354.svg",
            "isPro": false,
            "fullname": "Marvin Purtorab",
            "user": "comvergent-marvin",
            "type": "user"
          },
          "name": "Marvin Purtorab",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T09:07:42.610Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-25T16:45:08.000Z",
      "title": "WebGames: 難しい一般用ホームページ検索AIアガント",
      "summary": "WebGamesは、一般的なウェブブローシングAIアグェントの評価を目的とした50点以上の相互作用的な課題のコレクションをもとに設計された厳密なベンチマークシートです。これらの課題は、人間にとって簡単であるように特別に設計され、現在のAIシステムの基本的なブラウザインタラクション、高度な入力処理、認知的なタスク、ワークフロー自動化、インタラクティブなエンターテインメントにおける制限をシステマティックに検証することを目的としています。フレームワークは、ハーミックなテスト環境で外部依存を除外し、再現可能な評価を保証します。GPT-4o、Claude Computer-Use、Gemini-1.5-Pro、Qwen2-VLなどの先進的な視覚言語モデルを人間の性能と比較して評価します。結果は、大きな能力の間違いがあり、最も良いAIシステムは人間の性能と比べて95.7%の成功率を達成できる43.1%で、人間が直感的に理解する一般的なウェブインタラクションパターンの処理能力の根本的な制限を明らかにしています。ベンチマークはwebgames.convergence.aiで公開でき、軽量でクライアント側の実装を提供し、迅速な評価サイクルを促進します。モジュラーなアーキテクチャと標準化された課題規格をもって、WebGamesは、より有能なウェブブローシングアグェントの開発の進歩を測定する堅固な基盤を提供します。",
      "upvotes": 4,
      "discussionId": "67be8868823e790d21a2bbea"
    },
    "publishedAt": "2025-02-25T22:20:16.916Z",
    "title": "WebGames: Challenging General-Purpose Web-Browsing AI Agents",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.18356.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 6218
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.16794",
      "authors": [
        {
          "_id": "67be86a78a5a80542314f0e6",
          "user": {
            "_id": "6531a65daed617662c7f1007",
            "avatarUrl": "/avatars/ea2e504780dc40719f7501ab2c7d9c91.svg",
            "isPro": false,
            "fullname": "Xilin Jiang",
            "user": "xi-j",
            "type": "user"
          },
          "name": "Xilin Jiang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-26T08:25:52.841Z",
          "hidden": false
        },
        {
          "_id": "67be86a78a5a80542314f0e7",
          "user": {
            "_id": "661361993bb67cb4f356c3de",
            "avatarUrl": "/avatars/b707c07f9c70d2ed1e8cd8cff2551c69.svg",
            "isPro": false,
            "fullname": "Sukru Samet Dindar",
            "user": "susameddin",
            "type": "user"
          },
          "name": "Sukru Samet Dindar",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T09:11:37.706Z",
          "hidden": false
        },
        {
          "_id": "67be86a78a5a80542314f0e8",
          "user": {
            "_id": "670e8671ba29b3fca221b8c9",
            "avatarUrl": "/avatars/20f6479bd5218d6d3e304539df5003f9.svg",
            "isPro": false,
            "fullname": "Vishal Choudhari",
            "user": "vchoudhari",
            "type": "user"
          },
          "name": "Vishal Choudhari",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T09:11:45.258Z",
          "hidden": false
        },
        {
          "_id": "67be86a78a5a80542314f0e9",
          "name": "Stephan Bickel",
          "hidden": false
        },
        {
          "_id": "67be86a78a5a80542314f0ea",
          "name": "Ashesh Mehta",
          "hidden": false
        },
        {
          "_id": "67be86a78a5a80542314f0eb",
          "name": "Guy M McKhann",
          "hidden": false
        },
        {
          "_id": "67be86a78a5a80542314f0ec",
          "name": "Adeen Flinker",
          "hidden": false
        },
        {
          "_id": "67be86a78a5a80542314f0ed",
          "name": "Daniel Friedman",
          "hidden": false
        },
        {
          "_id": "67be86a78a5a80542314f0ee",
          "name": "Nima Mesgarani",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-24T03:06:45.000Z",
      "title": "AAD-LLM: ニューラルアテンション駆動音響スケーン理解",
      "summary": "音響基盤モデル、特に音響大語言モデル（LLMs）を含むものは、すべての音声入力を等しく処理し、聴き手の認識に依存しない。しかし、人間の音響認識は固有の選択性を持っている：聴き手は複雑な音響スケーンで特定のスピーカーを焦点にし、その他を無視する。現在のモデルはこの選択性を載せていないため、認識に合わせたレスポンスを生成する能力が限定されている。これに対して、私たちはIntention-Informed Auditory Scene Understanding（II-ASU）を導入し、Brain Signalsを統合して聴き手の注意を推定するプロトタイプシステム、Auditory Attention-Driven LLM（AAD-LLM）を紹介します。AAD-LLMは、脳内電楕値プログラミング（iEEG）の記録を統合して、聴き手が注目しているスピーカーを解釈し、相殺しに応じたレスポンスを改良するものです。モデルは、神経活性から注目しているスピーカーを予測し、この推定された注意状態に基づいてレスポンスの生成を条件付ける。AAD-LLMは、多タイラースケーンでのスピーカー説明、スピーチ訳注、抽出、問答ニュースにおいて、主観的および客観的評価を通じて、聴き手の意図に合わせたレジストンを向上させることを示しています。このワークは、意図に関する音響AIの最初のステップを踏み出し、聴き手の認識が機械の聴きを情報として提供する新しいパラダイムを探ることを試みています。デモとコードは以下のURLから利用可能です：https://aad-llm.github.io.",
      "upvotes": 4,
      "discussionId": "67be86a98a5a80542314f16e"
    },
    "publishedAt": "2025-02-25T22:20:08.416Z",
    "title": "AAD-LLM: Neural Attention-Driven Auditory Scene Understanding",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.16794.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "6531a65daed617662c7f1007",
      "avatarUrl": "/avatars/ea2e504780dc40719f7501ab2c7d9c91.svg",
      "fullname": "Xilin Jiang",
      "name": "xi-j",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.17425",
      "authors": [
        {
          "_id": "67bddd63c7d8b835b82ced9a",
          "user": {
            "_id": "635364b3c41f548fe39db945",
            "avatarUrl": "/avatars/ad1916bbfabca0b6651c8eabacc5eba8.svg",
            "isPro": false,
            "fullname": "Runpeng Yu",
            "user": "rp-yu",
            "type": "user"
          },
          "name": "Runpeng Yu",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T09:14:07.580Z",
          "hidden": false
        },
        {
          "_id": "67bddd63c7d8b835b82ced9b",
          "user": {
            "_id": "64396ebc21221ac7411852b3",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64396ebc21221ac7411852b3/SR0dC8N0bdj9tZFxYPpSf.jpeg",
            "isPro": false,
            "fullname": "Xinyin Ma",
            "user": "horseee",
            "type": "user"
          },
          "name": "Xinyin Ma",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T09:14:13.670Z",
          "hidden": false
        },
        {
          "_id": "67bddd63c7d8b835b82ced9c",
          "user": {
            "_id": "63fc03a50aab060792ffef39",
            "avatarUrl": "/avatars/9d5b1bb2a41928e08176b703935133ab.svg",
            "isPro": false,
            "fullname": "Wangxinchao",
            "user": "wxcTest",
            "type": "user"
          },
          "name": "Xinchao Wang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T09:14:53.838Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-24T18:56:12.000Z",
      "title": "Visual Perception TokenをMultimodal Large Language Modelに組み込むことを紹介します。",
      "summary": "ビジュアル情報の利用により、多モダル大語言モデル（MLLM）は、その視覚エンコーダーの認識プロセスを依存しています。視覚認識の完全性と精度は、空間的論理、細かい理解、その他のタスクの精度に大きな影響を及ぼします。しかし、MLLMは、例えば画像の特定の領域を選択的に検討するや、特定の物体カテゴリに関連する情報を焦点化するような自動制御能力を持っていません。本研究では、Visual Perception Tokenの概念を提案し、MLLMにその視覚認識プロセスを制御する機構を付与することを目的としています。Region Selection TokenとVision Re-Encoding Tokenの2種類のVisual Perception Tokenを設計し、MLLMはこれらのトークンを生成し、それらを使用して追加の視覚認識アクションを起動します。Region Selection Tokenは画像の特定の領域を明記し、その領域について進みます。Vision Re-Encoding Tokenは、その隠れ状態を制御信号として使用し、追加の視覚認識プロセスをガイドします。拡張された実験は、これらのトークンが空間的論理、細かい理解、その他のタスクにおいての優勢を示しています。平均的に、Visual Perception Tokenの導入は2Bモデルの性能を23.6%上げ、スコアを0.572から0.708に上げ、7Bパラメータモデルを13.4%超え（0.624から）します。ローカルをご確認ください https://github.com/yu-rp/VisualPerceptionToken",
      "upvotes": 3,
      "discussionId": "67bddd64c7d8b835b82cee5a"
    },
    "publishedAt": "2025-02-26T02:37:36.287Z",
    "title": "Introducing Visual Perception Token into Multimodal Large Language Model",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.17425.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "635364b3c41f548fe39db945",
      "avatarUrl": "/avatars/ad1916bbfabca0b6651c8eabacc5eba8.svg",
      "fullname": "Runpeng Yu",
      "name": "rp-yu",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.17535",
      "authors": [
        {
          "_id": "67beaec94a1d9d7e368a7840",
          "user": {
            "_id": "66a4a319a1711696948b045c",
            "avatarUrl": "/avatars/1d92d57a949332cb8227697b9a0c2f39.svg",
            "isPro": false,
            "fullname": "Zhenheng Tang",
            "user": "coolzhtang",
            "type": "user"
          },
          "name": "Zhenheng Tang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T09:15:34.971Z",
          "hidden": false
        },
        {
          "_id": "67beaec94a1d9d7e368a7841",
          "name": "Xiang Liu",
          "hidden": false
        },
        {
          "_id": "67beaec94a1d9d7e368a7842",
          "name": "Qian Wang",
          "hidden": false
        },
        {
          "_id": "67beaec94a1d9d7e368a7843",
          "name": "Peijie Dong",
          "hidden": false
        },
        {
          "_id": "67beaec94a1d9d7e368a7844",
          "name": "Bingsheng He",
          "hidden": false
        },
        {
          "_id": "67beaec94a1d9d7e368a7845",
          "user": {
            "_id": "6676935fcd0b89a0115174b0",
            "avatarUrl": "/avatars/4caca1b672d29e787814f9a30bf20bcc.svg",
            "isPro": false,
            "fullname": "Xiaowen Chu",
            "user": "wenxinsiju",
            "type": "user"
          },
          "name": "Xiaowen Chu",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T09:15:41.884Z",
          "hidden": false
        },
        {
          "_id": "67beaec94a1d9d7e368a7846",
          "name": "Bo Li",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-24T15:39:35.000Z",
      "title": "ロッテリーLLM仮説、LLM圧縮時にどの能力を保つべきかを再考する",
      "summary": "モデルの計算コストとストレージコストを減少することをモチベーションに、LLMsのモデル圧縮とKVキャッシュ圧縮が研究者によって注目されています。しかし、現在の方法は主に圧縮されたLLMsの性能を測定するための気難易性または単純な精度を維持することを優先しています。このブログでは、LLMsに関連した検索アウゲージ生成、多段階論理、外部ツール、計算的表現性の最近の進歩について、性能を大幅に向上させることを目的として簡単なレビューを提供します。次に、多段階論理と外部ツールの助けを受けて同じ性能を発揮できる小さなラティングLLMの存在を前提としたラティングLLM仮説を提案します。現在のLLMsの進歩についてのレビューを基に、ラティングLLMとKVキャッシュ圧縮が必要とする基本的な能力を議論し、現行法では見落とされているものを説明します。",
      "upvotes": 3,
      "discussionId": "67beaeca4a1d9d7e368a7875"
    },
    "publishedAt": "2025-02-26T01:04:23.776Z",
    "title": "The Lottery LLM Hypothesis, Rethinking What Abilities Should LLM Compression Preserve?",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.17535.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "63024676056ec3a2a8714b24",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1661093436322-noauth.jpeg",
      "fullname": "Xiang Liu",
      "name": "Dominic789654",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 4
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.17092",
      "authors": [
        {
          "_id": "67bea8cc7e54112af6c372aa",
          "user": {
            "_id": "63d9e09f1cae35c27bf80cb2",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1675223055197-noauth.jpeg",
            "isPro": true,
            "fullname": "Syed Abdul Gaffar Shakhadri",
            "user": "SyedAbdul",
            "type": "user"
          },
          "name": "Syed Abdul Gaffar Shakhadri",
          "status": "extracted_confirmed",
          "statusLastChangedAt": "2025-02-26T05:52:19.355Z",
          "hidden": false
        },
        {
          "_id": "67bea8cc7e54112af6c372ab",
          "user": {
            "_id": "5fb7ae48e6ae537272bdeb3c",
            "avatarUrl": "/avatars/e5d01cb428f4b22161e0d17895a5c678.svg",
            "isPro": false,
            "fullname": "Kruthika",
            "user": "kruthika",
            "type": "user"
          },
          "name": "Kruthika KR",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-02-26T05:38:21.529Z",
          "hidden": false
        },
        {
          "_id": "67bea8cc7e54112af6c372ac",
          "user": {
            "_id": "677cc34fe4cf361eedccd085",
            "avatarUrl": "/avatars/e97a3f9a84ed258ab4b75c12865562d6.svg",
            "isPro": false,
            "fullname": "Kartik Basavaraj Angadi",
            "user": "KartikAngadi",
            "type": "user"
          },
          "name": "Kartik Basavaraj Angadi",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-02-26T05:38:21.529Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-24T12:15:07.000Z",
      "title": "Shakti-VLMs: 企業AI向けのスケーラブルなビジョン・ラングワードモデル",
      "summary": "Shakti VLMは、1Bと4Bパラメーターのビジョン・ラングラジウムモデルの家族です。これらのモデルは、多モーダル学習のデータ効率性の課題を解決するために設計されています。最近のVLMは、膨大なトレーニングデータにより強力な性能を達成していますが、Shaktiモデルはアーキテクチャの革新を活用して、少ないトークンで競争的な結果を収めることができます。主な進歩点として、QK-Normalization（アテンションの安定化）、ハイブリッドノルマライゼーション手法、位置付けエンコーディングの向上が挙げられます。3段階トレーニング戦略は、学習効率を進化させます。評価によると、Shakti-VLM-1BとShakti-VLM-4Bは、文書理解、Visual Reasoning、OCR抜粋化、一般的な多モーダル理由において優れています。我々の結果から、高い性能はモデルの設計とトレーニング戦略により実現でき、それがデータサイズのみではなく、企業サイズの多モーダルタスクに対して効率的な解決策となることが明らかになります。",
      "upvotes": 2,
      "discussionId": "67bea8cd7e54112af6c37305"
    },
    "publishedAt": "2025-02-26T00:38:42.527Z",
    "title": "Shakti-VLMs: Scalable Vision-Language Models for Enterprise AI",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.17092.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "63d9e09f1cae35c27bf80cb2",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1675223055197-noauth.jpeg",
      "fullname": "Syed Abdul Gaffar Shakhadri",
      "name": "SyedAbdul",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isMod": false,
      "followerCount": 6
    },
    "isAuthorParticipating": true
  }
]