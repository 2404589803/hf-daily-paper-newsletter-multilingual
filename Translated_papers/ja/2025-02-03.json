[
  {
    "paper": {
      "id": "2501.19393",
      "authors": [
        {
          "_id": "67a02dd80e751b0476a1bcc6",
          "name": "Niklas Muennighoff",
          "hidden": false
        },
        {
          "_id": "67a02dd80e751b0476a1bcc7",
          "name": "Zitong Yang",
          "hidden": false
        },
        {
          "_id": "67a02dd80e751b0476a1bcc8",
          "name": "Weijia Shi",
          "hidden": false
        },
        {
          "_id": "67a02dd80e751b0476a1bcc9",
          "name": "Xiang Lisa Li",
          "hidden": false
        },
        {
          "_id": "67a02dd80e751b0476a1bcca",
          "name": "Li Fei-Fei",
          "hidden": false
        },
        {
          "_id": "67a02dd80e751b0476a1bccb",
          "name": "Hannaneh Hajishirzi",
          "hidden": false
        },
        {
          "_id": "67a02dd80e751b0476a1bccc",
          "name": "Luke Zettlemoyer",
          "hidden": false
        },
        {
          "_id": "67a02dd80e751b0476a1bccd",
          "name": "Percy Liang",
          "hidden": false
        },
        {
          "_id": "67a02dd80e751b0476a1bcce",
          "name": "Emmanuel Candès",
          "hidden": false
        },
        {
          "_id": "67a02dd80e751b0476a1bccf",
          "name": "Tatsunori Hashimoto",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-31T18:48:08.000Z",
      "title": "s1: 簡単なテストタイムスケーリング",
      "summary": "テスト時スケーリングは、訓練時の計算量を追加して性能を向上させる新しい言語モデルの手法です。最近、OpenAIのo1モデルはこの能力を示したが、メソッドを公開していないため、複数の再現努力が行われました。私たちは、テスト時スケーリングと強い理由論性能を実現するために最も簡単なアプローチを探しています。\n\nまず、私たちは、難易度、多様性、品質の3つの評価基準を通じて、1,000問のデータセットs1Kを選びます。このデータセットは、理由論トレースを含む問題と回答の組み合わせです。次に、テスト時の計算量を制御するために、モデルの思考過程を強制的に終了させるようなマネージメントを開発します。これにより、モデルが回答を終わらせようとすると、「ウェイト」を複数追加して思考過程を延長します。これにより、モデルが答えをもう一度検証し、間違った理由論ステップを修正することができます。\n\nQwen2.5-32B-Instruct言語モデルをs1Kによる規範化調整後、マネージメントを付け加えたものがモデルs1です。このモデルは、o1-previewよりも、コンペティションマジャーズ問題で27%程度の改善を収めました（MATHとAIME24）。また、マネージメントを用いてs1をスケーリングすることで、テスト時の対策を必要とさせない性能の拡大を実現できます。AIME24では、50%から57%までの改善が見られました。私たちのモデル、データ、コードは、https://github.com/simplescaling/s1で公開されています。",
      "upvotes": 21,
      "discussionId": "67a02dd90e751b0476a1bd02"
    },
    "publishedAt": "2025-02-02T21:45:49.841Z",
    "title": "s1: Simple test-time scaling",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.19393.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5912
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.19324",
      "authors": [
        {
          "_id": "67a04151dd7b3a4aba880589",
          "name": "Baohao Liao",
          "hidden": false
        },
        {
          "_id": "67a04151dd7b3a4aba88058a",
          "name": "Yuhui Xu",
          "hidden": false
        },
        {
          "_id": "67a04151dd7b3a4aba88058b",
          "name": "Hanze Dong",
          "hidden": false
        },
        {
          "_id": "67a04151dd7b3a4aba88058c",
          "name": "Junnan Li",
          "hidden": false
        },
        {
          "_id": "67a04151dd7b3a4aba88058d",
          "name": "Christof Monz",
          "hidden": false
        },
        {
          "_id": "67a04151dd7b3a4aba88058e",
          "name": "Silvio Savarese",
          "hidden": false
        },
        {
          "_id": "67a04151dd7b3a4aba88058f",
          "name": "Doyen Sahoo",
          "hidden": false
        },
        {
          "_id": "67a04151dd7b3a4aba880590",
          "name": "Caiming Xiong",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-31T17:19:57.000Z",
      "title": "リベンジガイドドリフェクティブデコーディングを用いた効率的なLLM計算",
      "summary": "We introduce Reward-Guided Speculative Decoding (RSD), a novel framework aimed at improving the efficiency of inference in large language models (LLMs). RSD synergistically combines a lightweight draft model with a more powerful target model, incorporating a controlled bias to prioritize high-reward outputs, in contrast to existing speculative decoding methods that enforce strict unbiasedness. RSD employs a process reward model to evaluate intermediate decoding steps and dynamically decide whether to invoke the target model, optimizing the trade-off between computational cost and output quality. We theoretically demonstrate that a threshold-based mixture strategy achieves an optimal balance between resource utilization and performance. Extensive evaluations on challenging reasoning benchmarks, including Olympiad-level tasks, show that RSD delivers significant efficiency gains against decoding with the target model only (up to 4.4x fewer FLOPs), while achieving significantly better accuracy than parallel decoding method on average (up to +3.5). These results highlight RSD as a robust and cost-effective approach for deploying LLMs in resource-intensive scenarios.",
      "upvotes": 15,
      "discussionId": "67a04152dd7b3a4aba8805c0"
    },
    "publishedAt": "2025-02-02T23:10:16.068Z",
    "title": "Reward-Guided Speculative Decoding for Efficient LLM Reasoning",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.19324.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6602869253a0518b2a98cafd",
      "avatarUrl": "/avatars/c14b5953a716f42c83ad28147f8308ae.svg",
      "fullname": "Yuhui Xu",
      "name": "yuhuixu",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.18837",
      "authors": [
        {
          "_id": "67a04e7ab6fd93f91c65457b",
          "name": "Mrinank Sharma",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c65457c",
          "name": "Meg Tong",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c65457d",
          "name": "Jesse Mu",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c65457e",
          "name": "Jerry Wei",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c65457f",
          "name": "Jorrit Kruthoff",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c654580",
          "name": "Scott Goodfriend",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c654581",
          "name": "Euan Ong",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c654582",
          "name": "Alwin Peng",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c654583",
          "name": "Raj Agarwal",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c654584",
          "name": "Cem Anil",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c654585",
          "name": "Amanda Askell",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c654586",
          "name": "Nathan Bailey",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c654587",
          "name": "Joe Benton",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c654588",
          "name": "Emma Bluemke",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c654589",
          "name": "Samuel R. Bowman",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c65458a",
          "name": "Eric Christiansen",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c65458b",
          "name": "Hoagy Cunningham",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c65458c",
          "name": "Andy Dau",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c65458d",
          "name": "Anjali Gopal",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c65458e",
          "name": "Rob Gilson",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c65458f",
          "name": "Logan Graham",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c654590",
          "name": "Logan Howard",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c654591",
          "user": {
            "_id": "66fc4c692408eb3bdeba876f",
            "avatarUrl": "/avatars/66ba18ccb95d150e66d7b6930d4eb938.svg",
            "isPro": false,
            "fullname": "Nimit Kalra",
            "user": "nimitkalra",
            "type": "user"
          },
          "name": "Nimit Kalra",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-03T08:14:42.317Z",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c654592",
          "name": "Taesung Lee",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c654593",
          "name": "Kevin Lin",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c654594",
          "name": "Peter Lofgren",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c654595",
          "name": "Francesco Mosconi",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c654596",
          "name": "Clare O'Hara",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c654597",
          "name": "Catherine Olsson",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c654598",
          "name": "Linda Petrini",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c654599",
          "name": "Samir Rajani",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c65459a",
          "name": "Nikhil Saxena",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c65459b",
          "name": "Alex Silverstein",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c65459c",
          "name": "Tanya Singh",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c65459d",
          "name": "Theodore Sumers",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c65459e",
          "name": "Leonard Tang",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c65459f",
          "name": "Kevin K. Troy",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c6545a0",
          "name": "Constantin Weisser",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c6545a1",
          "name": "Ruiqi Zhong",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c6545a2",
          "name": "Giulio Zhou",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c6545a3",
          "name": "Jan Leike",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c6545a4",
          "name": "Jared Kaplan",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c6545a5",
          "name": "Ethan Perez",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-31T01:09:32.000Z",
      "title": "憲法チャクチャライヤーズ：様々なジャイルブレイクを防ぐために、数千時間のテストチームテストを通じて",
      "summary": "大語言モデル（LLMs）は、普遍的なジャイルブレイク（universal jailbreaks）に脆弱です。これは、モデルのセキュリティガードをシステマティックに回避し、ユーザーが複数のモデルインターフェースを通じて行う有害なプロセスを可能にします。例えば、大規模な非法物質の製造など。これらの攻撃に対処するために、私たちは、自然語法ルール（つまり、憲法）で指定された許可されたおよび制限された内容をモデルに提示して生成される合成データを用いて訓練されたセキュリティガード「憲法クラスファイザー」を導入します。約3,000時間の赤チームテストで、赤チームの参加者は、早期のクラスファイザーガードされたLLMから情報を抽出できる普遍的なジャイルブレイクを見つけませんでした。自動評価では、強化されたクラスファイザーは、引き続き範囲外ドメインの特定のジャイルブレイクに対して強固な防御を示します。これらのクラスファイザーは、生産データの拒否率が絶対に0.38%増加し、推論オーバーヘッドが23.7%になりますが、実用的な機能性を維持します。私たちの研究は、普遍的なジャイルブレイクを防ぐ同時に実用的な機能性を維持することが可能であることを示します。",
      "upvotes": 2,
      "discussionId": "67a04e7bb6fd93f91c6545bc"
    },
    "publishedAt": "2025-02-03T00:05:21.087Z",
    "title": "Constitutional Classifiers: Defending against Universal Jailbreaks across Thousands of Hours of Red Teaming",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.18837.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5912
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.18841",
      "authors": [
        {
          "_id": "67a02c75221b701e4c04da7f",
          "name": "Wojciech Zaremba",
          "hidden": false
        },
        {
          "_id": "67a02c75221b701e4c04da80",
          "name": "Evgenia Nitishinskaya",
          "hidden": false
        },
        {
          "_id": "67a02c75221b701e4c04da81",
          "name": "Boaz Barak",
          "hidden": false
        },
        {
          "_id": "67a02c75221b701e4c04da82",
          "name": "Stephanie Lin",
          "hidden": false
        },
        {
          "_id": "67a02c75221b701e4c04da83",
          "name": "Sam Toyer",
          "hidden": false
        },
        {
          "_id": "67a02c75221b701e4c04da84",
          "name": "Yaodong Yu",
          "hidden": false
        },
        {
          "_id": "67a02c75221b701e4c04da85",
          "name": "Rachel Dias",
          "hidden": false
        },
        {
          "_id": "67a02c75221b701e4c04da86",
          "name": "Eric Wallace",
          "hidden": false
        },
        {
          "_id": "67a02c75221b701e4c04da87",
          "name": "Kai Xiao",
          "hidden": false
        },
        {
          "_id": "67a02c75221b701e4c04da88",
          "name": "Johannes Heidecke",
          "hidden": false
        },
        {
          "_id": "67a02c75221b701e4c04da89",
          "name": "Amelia Glaese",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-31T01:20:44.000Z",
      "title": "トレーディングインフェアンスタイムコンピュートを相殺強固性に交換する",
      "summary": "実験を行い、推理モデル（特にOpenAI o1-previewとo1-mini）に対する対抗攻撃に対する強固性について調査します。多様な攻撃において、推論時の計算量の増加は強固性の向上につながります。多くの場合（重要な例外を除く）、テスト時の計算量が増加すると攻撃が成功するモデルのサンプル割合はほとんど0になります。研究においては対抗的な訓練を行いません。また、推論時の計算量を増やすためには、モデルが計算時間を多く使うことで実現します。この結果は、大規模言語モデルの対抗的な強固性向上において計算量の増加が可能性を持つことを示しています。また、推理モデルに対する新しい攻撃や推論時の計算量が信頼性向上につながらない場合を調査し、その理由や対策方法を検討しています。",
      "upvotes": 2,
      "discussionId": "67a02c76221b701e4c04daf5"
    },
    "publishedAt": "2025-02-02T21:40:11.158Z",
    "title": "Trading Inference-Time Compute for Adversarial Robustness",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.18841.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5912
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2404.07097",
      "authors": [
        {
          "_id": "67a07a4b605a6c919dea84ec",
          "name": "Yoni Kasten",
          "hidden": false
        },
        {
          "_id": "67a07a4b605a6c919dea84ed",
          "name": "Wuyue Lu",
          "hidden": false
        },
        {
          "_id": "67a07a4b605a6c919dea84ee",
          "name": "Haggai Maron",
          "hidden": false
        }
      ],
      "publishedAt": "2024-04-10T15:37:00.000Z",
      "title": "Fast Encoder-Based 3D from Casual Videos via Point Track Processing\n\nポイントトラック処理によるカサルビデオからの高速エンコーダベース3D生成",
      "summary": "この論文は、動的な内容を含むビデオから3D構造を再構築する長年の難題に取り組みます。現在の手法は、標準カメラで撮影された普通のビデオに対して動作し、長い最適化時間が必要とすることを設計していません。\n\nこの論文では、前の手法の効率を大幅に向上させることを目的として、TracksTo4Dという学習基づいたアプローチを提案します。TracksTo4Dは、動的な内容からのビデオから1回の効率的な前向きパスを使用して3D構造とカメラの位置を推定することができます。これを実現するために、2D点トラックを直接操作し、2D点トラックの処理に適したアーキテクチャを提案します。提案されたアーキテクチャは、2つの重要な原則に基づいて設計されています：1. 入力点トラックデータに存在する固有の対称性を考慮しています。2. 動きパターンは低ランク近似を用いて効果的に表現できると仮定しています。TracksTo4Dは、ビデオから抽出された2D点トラックだけを使用して、3Dサブジェクトラベルを含むカスタムビデオデータセットで無制限学習されます。実験結果によると、TracksTo4Dは状態の最先端の方法と同じ精度で、ビデオの時系列点ポイントクラウドとカメラの位置を再構築でき、運行時間を95%削減できます。また、TracksTo4Dは、推論時に未見のビデオの未見の語意カテゴリーにも広範囲に対応しています。",
      "upvotes": 1,
      "discussionId": "67a07a4d605a6c919dea8555"
    },
    "publishedAt": "2025-02-03T03:12:19.292Z",
    "title": "Fast Encoder-Based 3D from Casual Videos via Point Track Processing",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.07097.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "5f1158120c833276f61f1a84",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1608042047613-5f1158120c833276f61f1a84.jpeg",
      "fullname": "Niels Rogge",
      "name": "nielsr",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 742
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2411.04983",
      "authors": [
        {
          "_id": "67a0783a1b24595484396c4d",
          "name": "Gaoyue Zhou",
          "hidden": false
        },
        {
          "_id": "67a0783a1b24595484396c4e",
          "name": "Hengkai Pan",
          "hidden": false
        },
        {
          "_id": "67a0783a1b24595484396c4f",
          "name": "Yann LeCun",
          "hidden": false
        },
        {
          "_id": "67a0783a1b24595484396c50",
          "name": "Lerrel Pinto",
          "hidden": false
        }
      ],
      "publishedAt": "2024-11-07T18:54:37.000Z",
      "title": "DINO-WM: 予習ビジュアル特徴モデル上のワールドモデルによるゼロショットプランニング",
      "summary": "将来の結果を予測する能力は、物理的な理由にとって根本的である。しかし、この予測モデル、通常は世界モデルと呼ばれているものは、学習が難しく、通常はタスク専門的な解決策においてオンラインポリシー学習を行うものである。私たちは、世界モデルの本質的な潛力は、それが多様な問題を理由と計画する能力にあることを主張する。具象的には、世界モデルは以下の3つの特徴を持つ必要がある：1）オフラインで、事前に集められたトラジェクトで学習可能である、2）テスト時の行動最適化をサポートする、3）タスク無関係的な理由を促進する。これを実現するために、私たちはDINO World Model（DINO-WM）を提出する。DINO-WMは、視覚的な動作をモデル化する新しい方法で、視覚的な世界を再構築することなく、視覚的な動作をモデル化する。DINO-WMは、DINOv2で予った空間パッチ特徴を利用し、オフラインの行動トラジェクトから学習することを可能にし、将来のパッチ特徴を予測する。この設計は、DINO-WMが行動シーケンス最適化を通じて観察的な目標を達成することを可能にし、望ましい目標パッチ特徴を予測ターゲットとしてタスク無関係的な行動計画を促進することを可能にします。DINO-WMは、迷路探索、テーブル上のポッション、粒子操作などの多様な領域で評価され、エキスパートの示唆、報酬モデリング、または事前学習された逆モデルに依存しないように、テスト時にゼロショットの行動解決策を生成することを示し、先進的なワールドモデルに比べて強い一般化能力を示している。特に、DINO-WMは、任意の設計の迷路、形状の異なるポッション操作、多粒子シナリオなどの多様なタスクフamiliesに適応することを示している。",
      "upvotes": 1,
      "discussionId": "67a0783d1b24595484396cca"
    },
    "publishedAt": "2025-02-03T03:10:08.761Z",
    "title": "DINO-WM: World Models on Pre-trained Visual Features enable Zero-shot Planning",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.04983.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "5f1158120c833276f61f1a84",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1608042047613-5f1158120c833276f61f1a84.jpeg",
      "fullname": "Niels Rogge",
      "name": "nielsr",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 742
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.18128",
      "authors": [
        {
          "_id": "679e04b792d873dfa23d0ba6",
          "user": {
            "_id": "647d79a736e109abce419102",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/647d79a736e109abce419102/S8Hby6eO4WdPQrct0Ix3c.png",
            "isPro": false,
            "fullname": "Abdurrahman Odabaşı",
            "user": "odabashi",
            "type": "user"
          },
          "name": "Abdurrahman Odabaşı",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-03T08:14:51.873Z",
          "hidden": false
        },
        {
          "_id": "679e04b792d873dfa23d0ba7",
          "name": "Göksel Biricik",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-30T04:20:16.000Z",
      "title": "新聞摘要のための言語モデルの能力の解明",
      "summary": "最近、複数の言語モデルの導入と、自然言語処理（NLP）タスクの改善の進行を背景に、この研究は、20つの最近の言語モデルの詳細なベンチマークを提供し、特にニュース摘要の課題で小さなモデルを優先して評価しています。本研究では、3つの異なるデータセットで書かれた異なるスタイルのニュース記事の要約においてこれらのモデルの能力と効果性をシステマティックに検証します。特に、この研究では、zero-shotとfew-shot学習の設定を焦点とし、自動評価指標、人間評価、LLM-as-a-judgeの複数の評価概念を統合した強固な評価方法を適用しています。興味深いながら、few-shot学習の設定で示唆例を含めることは、モデルの性能を向上させることではなく、生成された要約の質を悪くすることもあります。この問題は、参照要約の金質の悪い質であることによって主に原因となり、モデルの性能に負面影響を与えています。また、本研究の結果は、GPT-3.5-TurboとGPT-4の特別な性能を示し、これらのモデルは進歩的な能力により一般的に優勢を占めています。しかし、公共的なモデルの評価において、Qwen1.5-7B、SOLAR-10.7B-Instruct-v1.0、Meta-Llama-3-8B、Zephyr-7B-Betaなどのモデルが期待的な結果を示し、これらのモデルはニュース要約の課題で大きなモデルとの競争的な代替として显著なポテンシャルを示しています。",
      "upvotes": 0,
      "discussionId": "679e04b892d873dfa23d0bd3"
    },
    "publishedAt": "2025-02-03T04:01:13.509Z",
    "title": "Unraveling the Capabilities of Language Models in News Summarization",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.18128.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "647d79a736e109abce419102",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/647d79a736e109abce419102/S8Hby6eO4WdPQrct0Ix3c.png",
      "fullname": "Abdurrahman Odabaşı",
      "name": "odabashi",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  }
]