[
  {
    "paper": {
      "id": "2501.17703",
      "authors": [
        {
          "_id": "679ae76cf211c66bd702f5d5",
          "user": {
            "_id": "636a35eff8d9af4aea181608",
            "avatarUrl": "/avatars/d9c5cf3491243d1f2b1c5df1873ee8e7.svg",
            "isPro": false,
            "fullname": "yubo",
            "user": "ubowang",
            "type": "user"
          },
          "name": "Yubo Wang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-01-30T08:39:49.375Z",
          "hidden": false
        },
        {
          "_id": "679ae76cf211c66bd702f5d6",
          "name": "Xiang Yue",
          "hidden": false
        },
        {
          "_id": "679ae76cf211c66bd702f5d7",
          "user": {
            "_id": "6313a86154e6e5d9f0f94e04",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1662232951344-6313a86154e6e5d9f0f94e04.jpeg",
            "isPro": false,
            "fullname": "Wenhu Chen",
            "user": "wenhu",
            "type": "user"
          },
          "name": "Wenhu Chen",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-01-30T02:43:59.302Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-29T15:20:30.000Z",
      "title": "批判微调：批判学习比模仿学习更有效",
      "summary": "Supervised Fine-Tuning (SFT)は、与えられた指示に対して注釈された回答を模倣することで言語モデルを訓練する方法で一般的に使用されています。本論文では、このパラダイムを挑戦し、Critique Fine-Tuning (CFT)を提案します。CFTは、モデルが噪音のある回答を批判することで学習するような戦略で、人間の学習過程における批判的思考を重視していることをモデル化しています。標準的なSFTでは見落とされる深い分析と複雑な理解の特徴を奨励します。CFTの効果を評価するために、WebInstructから50Kサンプルのデータセットを構築し、GPT-4oを教師として(input=[クエリ；噪音のある回答], output=批判)の形式で批判を生成しました。このデータセットに対するCFTは、6つの数学ベンチマークでSFTより続けて4-10%の改善を収め、基礎モデルとしてQwen2.5、Qwen2.5-Math、DeepSeek-Mathを使用しました。また、MetaMathとNuminaMathデータセットに拡張し、SFTより同様の効果を見出しました。特に、Qwen2.5-Math-CFTモデルは、それぞれ2Mサンプルを使用したよりも優れているエースマジックとQwen2.5-Math-Instructとの比較で、多くのベンチマークで匹敵または上回りました。消滅研究により、CFTは噪音のある回答の元と教師の批判モデルの元に対して強固であることが示されました。これらの発見から、批判的な学習を用いた訓練は言語モデルの理由論の進歩によりより効果的な代替として提唱することを主張します。",
      "upvotes": 12,
      "discussionId": "679ae770f211c66bd702f697"
    },
    "publishedAt": "2025-01-29T21:51:11.227Z",
    "title": "Critique Fine-Tuning: Learning to Critique is More Effective than Learning to Imitate",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.17703.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "636a35eff8d9af4aea181608",
      "avatarUrl": "/avatars/d9c5cf3491243d1f2b1c5df1873ee8e7.svg",
      "fullname": "yubo",
      "name": "ubowang",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 4
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2501.14334",
      "authors": [
        {
          "_id": "679a7546805383520ce065af",
          "user": {
            "_id": "644156da1a80f6d83cb1667c",
            "avatarUrl": "/avatars/106d30a576b0fb58118ac4333b17260b.svg",
            "isPro": false,
            "fullname": "Clement Desroches",
            "user": "clementdesroches",
            "type": "user"
          },
          "name": "Clément Desroches",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-01-29T21:06:17.418Z",
          "hidden": false
        },
        {
          "_id": "679a7546805383520ce065b0",
          "user": {
            "_id": "66221f6295e8f09a668f07f0",
            "avatarUrl": "/avatars/f7c943996c814630ab5dcfaaaba01a83.svg",
            "isPro": false,
            "fullname": "Martin Chauvin",
            "user": "Neyri56",
            "type": "user"
          },
          "name": "Martin Chauvin",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-01-30T09:38:17.235Z",
          "hidden": false
        },
        {
          "_id": "679a7546805383520ce065b1",
          "name": "Louis Ladan",
          "hidden": false
        },
        {
          "_id": "679a7546805383520ce065b2",
          "name": "Caroline Vateau",
          "hidden": false
        },
        {
          "_id": "679a7546805383520ce065b3",
          "name": "Simon Gosset",
          "hidden": false
        },
        {
          "_id": "679a7546805383520ce065b4",
          "name": "Philippe Cordier",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-24T08:58:49.000Z",
      "title": "AIの持続可能なスケーリングの謎を探る：企業のAI環境影響の予測的研究",
      "summary": "人工知能（AI）の急速な成長、特に大規模言語モデル（LLMs）による成長は、環境効果についての懸念を増やし、ガス排出物の環境影響を超えて、硬質の製造と寿命終了のプロセスも含む。主な提供者からの不透明性は、企業がAIに関連する環境影響を評価し、ネットゼロターゲットを達成することを難しくする。\n\n本論文では、企業のAIポートフォリオの環境影響を評価する方法を提案し、詳細なAIと生命サイクル評価（LCA）の専門知識を必要とすることを避けるように行動可能な洞察を提供する。結果は、大規模な生成AIモデルは傳統的なモデルに比べて最大4600倍のエネルギーを消費することを確認した。我々のモデリングアプローチは、IPCCのシナリオに沿った電気混合の変化を考慮し、AIの使用量の増加、硬質の計算効率、およびガス排出物の環境影響を評価するために、2030年までのAIの電気使用量を予測した。高い採用シナリオでは、広範囲の生成AIとエージェントの採用により、コンプリクスなモデルとフレームワークの拡大により、AIの電気使用量は24.4倍に上がる予測される。\n\n2030年までに生成AIの環境影響を軽減するには、AI価値鏈全体の協調的な努力が必要である。硬質の計算効率、モデルの計算効率、またはガス排出物の改善の孤立的な措置は十分ではない。我々は、環境評価の標準化フレームワーク、価値鏈全体のオーナーからのより透明性、および「環境の報酬」メトリクスの導入を主張し、AIの開発をネットゼロターゲットに合わせることを提唱する。",
      "upvotes": 11,
      "discussionId": "679a7548805383520ce065f5"
    },
    "publishedAt": "2025-01-30T03:05:08.789Z",
    "title": "Exploring the sustainable scaling of AI dilemma: A projective study of corporations' AI environmental impacts",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.14334.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "644156da1a80f6d83cb1667c",
      "avatarUrl": "/avatars/106d30a576b0fb58118ac4333b17260b.svg",
      "fullname": "Clement Desroches",
      "name": "clementdesroches",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2501.17749",
      "authors": [
        {
          "_id": "679ae5eab898ac90bf4480b6",
          "user": {
            "_id": "657b3a44de028a439ea2ed9d",
            "avatarUrl": "/avatars/9f05e8eb6809a0ce1b50cd1fc9b5a044.svg",
            "isPro": false,
            "fullname": "Aitor Arrieta",
            "user": "aitorarrieta",
            "type": "user"
          },
          "name": "Aitor Arrieta",
          "status": "extracted_confirmed",
          "statusLastChangedAt": "2025-01-30T08:45:20.561Z",
          "hidden": false
        },
        {
          "_id": "679ae5eab898ac90bf4480b7",
          "name": "Miriam Ugarte",
          "hidden": false
        },
        {
          "_id": "679ae5eab898ac90bf4480b8",
          "user": {
            "_id": "65001514f322f9156663f096",
            "avatarUrl": "/avatars/e8712f60d4e8b7c70ac02c532ad547ef.svg",
            "isPro": false,
            "fullname": "Pablo Valle",
            "user": "pablovalle",
            "type": "user"
          },
          "name": "Pablo Valle",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-30T09:39:30.629Z",
          "hidden": false
        },
        {
          "_id": "679ae5eab898ac90bf4480b9",
          "user": {
            "_id": "63527de67e4cc3135fd16651",
            "avatarUrl": "/avatars/5eb8076d448d0b6746e256c24e1440e0.svg",
            "isPro": false,
            "fullname": "José Antonio Parejo Maestre",
            "user": "japarejo",
            "type": "user"
          },
          "name": "José Antonio Parejo",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-30T09:39:06.958Z",
          "hidden": false
        },
        {
          "_id": "679ae5eab898ac90bf4480ba",
          "user": {
            "_id": "6790d642a1863df579840ae3",
            "avatarUrl": "/avatars/a10a6f4af327c1bb67513c56d7f84820.svg",
            "isPro": false,
            "fullname": "Sergio Segura",
            "user": "ssegura",
            "type": "user"
          },
          "name": "Sergio Segura",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-01-30T02:37:35.516Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-29T16:36:53.000Z",
      "title": "OpenAIのo3-miniの早期外部安全検証：部署前評価からのフィードバック",
      "summary": "大語言モデル（LLMs）は、我々の日常生活の重要な部分となりました。しかし、それらは個人のプライバシーを損なえ、偏見を継続させ、不實情報を広めるリスクを伴います。これらのリスクは、責任的な機能を確保するために強力的な安全機構、倫理的な指針、そして詳細なテストの必要性を強調しています。LLMsの安全性は、モデルが機械学習モデルとして機能している前に、一般的なユーザーにアクセス可能になるまでに、詳細にテストする必要がある重要な特徴です。この論文では、モンドラゴン大学とセビリア大学の研究者がOpenAIの新しいo3-mini LLMに対して行われた外部安全テストの経験を報告しています。特に、私たちのツール、ASTRALを用いて、最新の不安全なテスト入力（つまり、プロンプト）を自動的にシステマティックに生成し、それらを用いてLLMsの異なる安全性カテゴリをテストし、評価します。o3-mini beta版に対して、自動的に生成し、実行しました。ASTRALが分類した不安全なテストケースを手動的に確認し、87件の実際の不安全なLLMの行動のインスタンスを見つけました。この最新のLLMの機能前の外部テストフェーズで発見した重要なインサイトと発見を特に挙げます。",
      "upvotes": 7,
      "discussionId": "679ae5f0b898ac90bf44826c"
    },
    "publishedAt": "2025-01-29T21:38:42.464Z",
    "title": "Early External Safety Testing of OpenAI's o3-mini: Insights from the Pre-Deployment Evaluation",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.17749.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5860
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.17433",
      "authors": [
        {
          "_id": "679b1319f87b99a2a7c41e36",
          "user": {
            "_id": "67325283b318faa97f7ae5f7",
            "avatarUrl": "/avatars/2f83452768148b323c540c43ad695ee6.svg",
            "isPro": false,
            "fullname": "TianshengHuang",
            "user": "TianshengHuang",
            "type": "user"
          },
          "name": "Tiansheng Huang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-01-30T08:39:47.548Z",
          "hidden": false
        },
        {
          "_id": "679b1319f87b99a2a7c41e37",
          "user": {
            "_id": "6539cab119c3ef6679794706",
            "avatarUrl": "/avatars/a88691ff5a547c7a1384edcc615c8209.svg",
            "isPro": false,
            "fullname": "Sihao Hu",
            "user": "SihaoHu",
            "type": "user"
          },
          "name": "Sihao Hu",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-30T09:39:58.723Z",
          "hidden": false
        },
        {
          "_id": "679b1319f87b99a2a7c41e38",
          "user": {
            "_id": "647615b995a4dc98e58c24f2",
            "avatarUrl": "/avatars/7f73999246526c1aef4d019d5f5595ad.svg",
            "isPro": false,
            "fullname": "Fatih Ilhan",
            "user": "tawreos",
            "type": "user"
          },
          "name": "Fatih Ilhan",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-30T09:40:06.004Z",
          "hidden": false
        },
        {
          "_id": "679b1319f87b99a2a7c41e39",
          "user": {
            "_id": "65aae89948c718a57434db6f",
            "avatarUrl": "/avatars/6c0fae8dafad9b9265098a9bc3bfc102.svg",
            "isPro": false,
            "fullname": "selim tekin",
            "user": "sftekin25",
            "type": "user"
          },
          "name": "Selim Furkan Tekin",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-30T09:40:16.339Z",
          "hidden": false
        },
        {
          "_id": "679b1319f87b99a2a7c41e3a",
          "user": {
            "_id": "65c998005e17dbeaf147db84",
            "avatarUrl": "/avatars/6fb47b1e095971b93ff7dcd10369f926.svg",
            "isPro": false,
            "fullname": "Ling Liu",
            "user": "ling1119",
            "type": "user"
          },
          "name": "Ling Liu",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-30T09:40:37.075Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-29T06:24:58.000Z",
      "title": "ウイルス: 大規模言語モデルを通過した有害な微調節攻撃",
      "summary": "最近の研究によると、大規模言語モデル（LLMs）は有害な微調整攻撃に脆弱であり、幾つかの有害なサンプルに対して微調整されたら安全性の調整能力が失われます。リスクの軽減には、通常、ガードラインを使用して微調整前に有害なサンプルをフィルタリングします。この論文では、新しいレッドチームミッションを設計し、ガードラインのモデレーションによるデータフィルタリングに完全に信頼することは信頼できません。本論文で提案された攻撃方法、ヴァイラスは、有害なデータを少しだけ変更することでガードラインのモデレーションを回避することができます。実験結果によると、ヴァイラスが最適化した有害なデータはガードラインで100%の漏れ率で検出できなく、同時に優れた攻撃性能を達成できます。最後に、この論文で伝えた主なメッセージは、ガードラインのモデレーションを有害な微調整攻撃に対する効果的な解決策として考慮することは危険であることです。ガードラインのモデレーションは、事前学習されたLLMsの固有の安全性問題を解決することはできません。コードは、https://github.com/git-disl/Virus から利用できます。",
      "upvotes": 2,
      "discussionId": "679b131bf87b99a2a7c41ede"
    },
    "publishedAt": "2025-01-30T01:30:18.013Z",
    "title": "Virus: Harmful Fine-tuning Attack for Large Language Models Bypassing Guardrail Moderation",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/67325283b318faa97f7ae5f7/1hJo5gEfGEXAwYB5a6yWY.png",
      "https://cdn-uploads.huggingface.co/production/uploads/67325283b318faa97f7ae5f7/8SaMXA1izw5vcfwtU2Nhj.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.17433.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "67325283b318faa97f7ae5f7",
      "avatarUrl": "/avatars/2f83452768148b323c540c43ad695ee6.svg",
      "fullname": "TianshengHuang",
      "name": "TianshengHuang",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2501.17195",
      "authors": [
        {
          "_id": "679ae7655c55250b48483742",
          "name": "Andrei Alexandru",
          "hidden": false
        },
        {
          "_id": "679ae7655c55250b48483743",
          "user": {
            "_id": "66e184e86048d62cd8fb4e52",
            "avatarUrl": "/avatars/dc459c692fe9fce0911fa1229df0aeee.svg",
            "isPro": false,
            "fullname": "Antonia Calvi",
            "user": "NinaCalvi",
            "type": "user"
          },
          "name": "Antonia Calvi",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-30T09:40:54.827Z",
          "hidden": false
        },
        {
          "_id": "679ae7655c55250b48483744",
          "name": "Henry Broomfield",
          "hidden": false
        },
        {
          "_id": "679ae7655c55250b48483745",
          "name": "Jackson Golden",
          "hidden": false
        },
        {
          "_id": "679ae7655c55250b48483746",
          "name": "Kyle Dai",
          "hidden": false
        },
        {
          "_id": "679ae7655c55250b48483747",
          "name": "Mathias Leys",
          "hidden": false
        },
        {
          "_id": "679ae7655c55250b48483748",
          "name": "Maurice Burger",
          "hidden": false
        },
        {
          "_id": "679ae7655c55250b48483749",
          "name": "Max Bartolo",
          "hidden": false
        },
        {
          "_id": "679ae7655c55250b4848374a",
          "name": "Roman Engeler",
          "hidden": false
        },
        {
          "_id": "679ae7655c55250b4848374b",
          "name": "Sashank Pisupati",
          "hidden": false
        },
        {
          "_id": "679ae7655c55250b4848374c",
          "name": "Toby Drane",
          "hidden": false
        },
        {
          "_id": "679ae7655c55250b4848374d",
          "name": "Young Sun Park",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-27T15:09:08.000Z",
      "title": "Atla Selene Mini: 一般用評価モデル",
      "summary": "アトラ・セレネ・ミニ、最先端の小型言語モデルを判定者として提供するSLMJ（Small Language Model as a Judge）を紹介します。セレネ・ミニは一般的な用途の評価者で、11つの分布外ベンチマークにおいて全体的な性能で最も良いSLMJとGPT-4o-miniを超えています。これは絶対スコア、クラス分類、ペアリング偏好タスクを含むものです。RewardBenchでは8Bジェネレーターの最高スコアを記録し、GPT-4oや特殊化された判定者の強いベースラインを超えています。これを達成するために、公開データセットを合成的に生成された評価に増強し、フィルタリングとデータセットの消去を通じて高い品質を確保するデータカレーティオン戦略を開発しました。モデルは直接好み最適化（DPO）と観学微調練習（SFT）の損失関数を組み合わせて訓練され、高度なプロンプタブルな評価者として優れています。セレネ・ミニは金融および医療業のデータセットでの人間の専門家の評価とのゼロショットアgreementが大幅に向上し、プロンプトの形式の変化に対しても強固です。初期の結果から、セレネ・ミニはライブ、コミュニティを駆動するJudge Arenaでトップランキングの評価者として評価されています。モデルの重みはHuggingFace（https://hf.co/AtlaAI/Selene-1-Mini-Llama-3.1-8B）とOllamaで公開し、幅広いコミュニティの採用を促しています。",
      "upvotes": 2,
      "discussionId": "679ae76b5c55250b484838e0"
    },
    "publishedAt": "2025-01-29T21:44:37.041Z",
    "title": "Atla Selene Mini: A General Purpose Evaluation Model",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.17195.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5860
    },
    "isAuthorParticipating": false
  }
]