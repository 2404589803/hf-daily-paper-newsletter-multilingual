[
  {
    "paper": {
      "id": "2501.17703",
      "authors": [
        {
          "_id": "679ae76cf211c66bd702f5d5",
          "user": {
            "_id": "636a35eff8d9af4aea181608",
            "avatarUrl": "/avatars/d9c5cf3491243d1f2b1c5df1873ee8e7.svg",
            "isPro": false,
            "fullname": "yubo",
            "user": "ubowang",
            "type": "user"
          },
          "name": "Yubo Wang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-01-30T08:39:49.375Z",
          "hidden": false
        },
        {
          "_id": "679ae76cf211c66bd702f5d6",
          "name": "Xiang Yue",
          "hidden": false
        },
        {
          "_id": "679ae76cf211c66bd702f5d7",
          "user": {
            "_id": "6313a86154e6e5d9f0f94e04",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1662232951344-6313a86154e6e5d9f0f94e04.jpeg",
            "isPro": false,
            "fullname": "Wenhu Chen",
            "user": "wenhu",
            "type": "user"
          },
          "name": "Wenhu Chen",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-01-30T02:43:59.302Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-29T15:20:30.000Z",
      "title": "ファイナルチューニングの批判：批判を学ぶことは誤りを学ぶことよりも効果的です",
      "summary": "Supervised Fine-Tuning (SFT)は、与えられた指示に対する注釈された回答を模倣して言語モデルを訓練するために通常に使用されます。本論文では、このパラダイムを挑戦し、Critique Fine-Tuning (CFT)という戦略を提案します。これはモデルが噪音のある回答を批判することで、正しい回答を単に模倣することではなく学習します。人間の学習プロセスによりつながり、CFTは批判的思考を重視し、標準的なSFTによって過去に間違っていた特徴をより深い分析と複雑な理解を促します。CFTの効果を証明するために、WebInstructから50Kサンプルのデータセットを構築し、GPT-4oを教師として(input=[クエリ；噪音のある回答], output=批判)の形式で批判を生成します。このデータセットに対するCFTは、Qwen2.5、Qwen2.5-Math、DeepSeek-Mathなどの異なる基盤モデルを使用して6つの数学ベンチマークでSFTより確率的に4-10%の向上を見出します。また、MetaMathとNuminaMathデータセットに拡張し、SFTより同様の向上を見出します。特に、Qwen2.5-Math-CFTモデルは、ほとんど2Mサンプルを使用したよりも強力なモデルとして、AceMathとQwen2.5-Math-Instructを超えることが見出されます。消極的な研究によると、CFTは噪音のある回答のソースと教師の批判モデルに対して強固であることが示されます。これらの発見から、批判的な訓練は言語モデルの理由論を進めるためにより効果的な代替として提唱します。",
      "upvotes": 12,
      "discussionId": "679ae770f211c66bd702f697"
    },
    "publishedAt": "2025-01-29T21:51:11.227Z",
    "title": "Critique Fine-Tuning: Learning to Critique is More Effective than Learning to Imitate",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.17703.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "636a35eff8d9af4aea181608",
      "avatarUrl": "/avatars/d9c5cf3491243d1f2b1c5df1873ee8e7.svg",
      "fullname": "yubo",
      "name": "ubowang",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 4
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2501.14334",
      "authors": [
        {
          "_id": "679a7546805383520ce065af",
          "user": {
            "_id": "644156da1a80f6d83cb1667c",
            "avatarUrl": "/avatars/106d30a576b0fb58118ac4333b17260b.svg",
            "isPro": false,
            "fullname": "Clement Desroches",
            "user": "clementdesroches",
            "type": "user"
          },
          "name": "Clément Desroches",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-01-29T21:06:17.418Z",
          "hidden": false
        },
        {
          "_id": "679a7546805383520ce065b0",
          "user": {
            "_id": "66221f6295e8f09a668f07f0",
            "avatarUrl": "/avatars/f7c943996c814630ab5dcfaaaba01a83.svg",
            "isPro": false,
            "fullname": "Martin Chauvin",
            "user": "Neyri56",
            "type": "user"
          },
          "name": "Martin Chauvin",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-01-30T09:38:17.235Z",
          "hidden": false
        },
        {
          "_id": "679a7546805383520ce065b1",
          "name": "Louis Ladan",
          "hidden": false
        },
        {
          "_id": "679a7546805383520ce065b2",
          "name": "Caroline Vateau",
          "hidden": false
        },
        {
          "_id": "679a7546805383520ce065b3",
          "name": "Simon Gosset",
          "hidden": false
        },
        {
          "_id": "679a7546805383520ce065b4",
          "name": "Philippe Cordier",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-24T08:58:49.000Z",
      "title": "AIの持続可能なスケーリングの謎を探る：企業のAI環境影響の予測的研究",
      "summary": "人工知能（AI）の急速な成長、特に大規模言語モデル（LLMs）については、環境的影響についての懸念が出てきた。これは、CO2排出物よりももっとも、硬質の製造と終生プロセスも含めたものである。主要な提供者の不透明性は、会社がAIに関連する環境的影響を評価し、ネットゼロターゲットを達成することに妨げている。\n\nこの論文では、会社のAIポートフォリオの環境的影響を評価する方法を提案し、実用的なアイデアを提供するために、AIと生命サイクル評価（LCA）の専門知識が必要とすることはないことを確認している。結果は、大規模な生成AIモデルは、伝統的なモデルよりも4600倍のエネルギーを消費することを確認している。我々のモデリングアプローチは、IPCCのシナリオに沿った電力の混合の変化、AIの使用量の増加、コンピュータの計算効率の向上を考慮して、2030までのAIの電力使用量を予測している。高い採用シナリオでは、広泛な生成AIとアガントの採用により、もっとも複雑なモデルとフレームワークによって、AIの電力使用量は24.4倍の増加を予測されている。\n\n2030年に生成AIの環境的影響を軽減するには、AI価値鏈全体の協調的な努力が必要である。硬質の効率、モデルの効率、またはグリッドの改善の孤立的な措置は十分ではない。我々は、環境的評価フレームワークの標準化、価値鏈全体のオーナーのより透明性、および「環境の報酬」メトリクスの導入を主張し、AIの開発とネットゼロターゲットを一致させることを提唱している。",
      "upvotes": 11,
      "discussionId": "679a7548805383520ce065f5"
    },
    "publishedAt": "2025-01-30T03:05:08.789Z",
    "title": "Exploring the sustainable scaling of AI dilemma: A projective study of corporations' AI environmental impacts",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.14334.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "644156da1a80f6d83cb1667c",
      "avatarUrl": "/avatars/106d30a576b0fb58118ac4333b17260b.svg",
      "fullname": "Clement Desroches",
      "name": "clementdesroches",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2501.17749",
      "authors": [
        {
          "_id": "679ae5eab898ac90bf4480b6",
          "user": {
            "_id": "657b3a44de028a439ea2ed9d",
            "avatarUrl": "/avatars/9f05e8eb6809a0ce1b50cd1fc9b5a044.svg",
            "isPro": false,
            "fullname": "Aitor Arrieta",
            "user": "aitorarrieta",
            "type": "user"
          },
          "name": "Aitor Arrieta",
          "status": "extracted_confirmed",
          "statusLastChangedAt": "2025-01-30T08:45:20.561Z",
          "hidden": false
        },
        {
          "_id": "679ae5eab898ac90bf4480b7",
          "name": "Miriam Ugarte",
          "hidden": false
        },
        {
          "_id": "679ae5eab898ac90bf4480b8",
          "user": {
            "_id": "65001514f322f9156663f096",
            "avatarUrl": "/avatars/e8712f60d4e8b7c70ac02c532ad547ef.svg",
            "isPro": false,
            "fullname": "Pablo Valle",
            "user": "pablovalle",
            "type": "user"
          },
          "name": "Pablo Valle",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-30T09:39:30.629Z",
          "hidden": false
        },
        {
          "_id": "679ae5eab898ac90bf4480b9",
          "user": {
            "_id": "63527de67e4cc3135fd16651",
            "avatarUrl": "/avatars/5eb8076d448d0b6746e256c24e1440e0.svg",
            "isPro": false,
            "fullname": "José Antonio Parejo Maestre",
            "user": "japarejo",
            "type": "user"
          },
          "name": "José Antonio Parejo",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-30T09:39:06.958Z",
          "hidden": false
        },
        {
          "_id": "679ae5eab898ac90bf4480ba",
          "user": {
            "_id": "6790d642a1863df579840ae3",
            "avatarUrl": "/avatars/a10a6f4af327c1bb67513c56d7f84820.svg",
            "isPro": false,
            "fullname": "Sergio Segura",
            "user": "ssegura",
            "type": "user"
          },
          "name": "Sergio Segura",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-01-30T02:37:35.516Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-29T16:36:53.000Z",
      "title": "OpenAIのo3-miniの早期外部安全検証：部署前評価からのインサイト",
      "summary": "大語言モデル（LLMs）は私たちの日常生活の重要な部分になっています。しかし、それらは個人のプライバシーを損なえ、偏見を継続させ、不正情報を広めるリスクを伴います。これらのリスクは、責任的な機能化に向けた強力な安全機構、倫理的ガイドライン、および詳細なテストの必要性を明らかにしています。LLMsの安全性は、モデルが機能している前に詳細にテストされ、一般的なユーザーにアクセス可能になる前に確認する必要がある重要な特徴です。本論文では、モンドラゴン大学とセビリア大学の研究者がOpenAIの新しいo3-mini LLMをセキュリティテストプログラムの一部として行った外部安全テスト経験を報告します。特に、私たちのツール、ASTRALを使用して、最新の不安全なテスト入力（プロンプト）を自動的にシステマティックに生成し、LLMsの異なる安全カテゴリーをテストし、評価することができます。o3-mini beta版に対して、ASTRALで分類された不安全なテストケースを手動的に確認し、その後、87件の実際の不安全なLLMの行動のインスタンスを特定しました。本論文では、OpenAIの最新のLLMの機能化前の外部テスト期間における重要なインサイトと発見を明らかにしています。",
      "upvotes": 7,
      "discussionId": "679ae5f0b898ac90bf44826c"
    },
    "publishedAt": "2025-01-29T21:38:42.464Z",
    "title": "Early External Safety Testing of OpenAI's o3-mini: Insights from the Pre-Deployment Evaluation",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.17749.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5860
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.17433",
      "authors": [
        {
          "_id": "679b1319f87b99a2a7c41e36",
          "user": {
            "_id": "67325283b318faa97f7ae5f7",
            "avatarUrl": "/avatars/2f83452768148b323c540c43ad695ee6.svg",
            "isPro": false,
            "fullname": "TianshengHuang",
            "user": "TianshengHuang",
            "type": "user"
          },
          "name": "Tiansheng Huang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-01-30T08:39:47.548Z",
          "hidden": false
        },
        {
          "_id": "679b1319f87b99a2a7c41e37",
          "user": {
            "_id": "6539cab119c3ef6679794706",
            "avatarUrl": "/avatars/a88691ff5a547c7a1384edcc615c8209.svg",
            "isPro": false,
            "fullname": "Sihao Hu",
            "user": "SihaoHu",
            "type": "user"
          },
          "name": "Sihao Hu",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-30T09:39:58.723Z",
          "hidden": false
        },
        {
          "_id": "679b1319f87b99a2a7c41e38",
          "user": {
            "_id": "647615b995a4dc98e58c24f2",
            "avatarUrl": "/avatars/7f73999246526c1aef4d019d5f5595ad.svg",
            "isPro": false,
            "fullname": "Fatih Ilhan",
            "user": "tawreos",
            "type": "user"
          },
          "name": "Fatih Ilhan",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-30T09:40:06.004Z",
          "hidden": false
        },
        {
          "_id": "679b1319f87b99a2a7c41e39",
          "user": {
            "_id": "65aae89948c718a57434db6f",
            "avatarUrl": "/avatars/6c0fae8dafad9b9265098a9bc3bfc102.svg",
            "isPro": false,
            "fullname": "selim tekin",
            "user": "sftekin25",
            "type": "user"
          },
          "name": "Selim Furkan Tekin",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-30T09:40:16.339Z",
          "hidden": false
        },
        {
          "_id": "679b1319f87b99a2a7c41e3a",
          "user": {
            "_id": "65c998005e17dbeaf147db84",
            "avatarUrl": "/avatars/6fb47b1e095971b93ff7dcd10369f926.svg",
            "isPro": false,
            "fullname": "Ling Liu",
            "user": "ling1119",
            "type": "user"
          },
          "name": "Ling Liu",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-30T09:40:37.075Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-29T06:24:58.000Z",
      "title": "ウイルス: ガードレールモデレーションを通過する大規模言語モデルの有害な微調整攻撃",
      "summary": "最近の研究によると、大規模言語モデル（LLMs）は有害な微調節攻撃に脆弱です -- モデルは幾つかの有害なサンプルによる微調節後、安全性のアライメント能力が失われます。リスク軽減のために、通常は、微調節前に有害なサンプルをフィルタリングするガードラインが使用されます。この論文では、新しいロードテニング方法を設計し、データフィルタリングによってそのひとつだけのガードラインの制限を依存しては信頼できないことを示します。提案された攻撃方法、ヴァイラスによる有害なデータの最適化は、微調節ガードラインの検出に対しては100%の漏れ率ではなく、同時に優れた攻撃性能を達成できます。最終的に、この論文で伝えたキーメッセージは、有害な微調節攻撃に対するガードラインの制限をそのままつかさずに見逃すことは危険であることです。その理由は、これは事前学習されたLLMsの固有の安全性問題を解決できないからです。コードは、https://github.com/git-disl/Virusに公開されています。",
      "upvotes": 2,
      "discussionId": "679b131bf87b99a2a7c41ede"
    },
    "publishedAt": "2025-01-30T01:30:18.013Z",
    "title": "Virus: Harmful Fine-tuning Attack for Large Language Models Bypassing Guardrail Moderation",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/67325283b318faa97f7ae5f7/1hJo5gEfGEXAwYB5a6yWY.png",
      "https://cdn-uploads.huggingface.co/production/uploads/67325283b318faa97f7ae5f7/8SaMXA1izw5vcfwtU2Nhj.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.17433.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "67325283b318faa97f7ae5f7",
      "avatarUrl": "/avatars/2f83452768148b323c540c43ad695ee6.svg",
      "fullname": "TianshengHuang",
      "name": "TianshengHuang",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2501.17195",
      "authors": [
        {
          "_id": "679ae7655c55250b48483742",
          "name": "Andrei Alexandru",
          "hidden": false
        },
        {
          "_id": "679ae7655c55250b48483743",
          "user": {
            "_id": "66e184e86048d62cd8fb4e52",
            "avatarUrl": "/avatars/dc459c692fe9fce0911fa1229df0aeee.svg",
            "isPro": false,
            "fullname": "Antonia Calvi",
            "user": "NinaCalvi",
            "type": "user"
          },
          "name": "Antonia Calvi",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-30T09:40:54.827Z",
          "hidden": false
        },
        {
          "_id": "679ae7655c55250b48483744",
          "name": "Henry Broomfield",
          "hidden": false
        },
        {
          "_id": "679ae7655c55250b48483745",
          "name": "Jackson Golden",
          "hidden": false
        },
        {
          "_id": "679ae7655c55250b48483746",
          "name": "Kyle Dai",
          "hidden": false
        },
        {
          "_id": "679ae7655c55250b48483747",
          "name": "Mathias Leys",
          "hidden": false
        },
        {
          "_id": "679ae7655c55250b48483748",
          "name": "Maurice Burger",
          "hidden": false
        },
        {
          "_id": "679ae7655c55250b48483749",
          "name": "Max Bartolo",
          "hidden": false
        },
        {
          "_id": "679ae7655c55250b4848374a",
          "name": "Roman Engeler",
          "hidden": false
        },
        {
          "_id": "679ae7655c55250b4848374b",
          "name": "Sashank Pisupati",
          "hidden": false
        },
        {
          "_id": "679ae7655c55250b4848374c",
          "name": "Toby Drane",
          "hidden": false
        },
        {
          "_id": "679ae7655c55250b4848374d",
          "name": "Young Sun Park",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-27T15:09:08.000Z",
      "title": "Atla Selene Mini: 一般用評価モデル",
      "summary": "アトラ・セレネ・ミニ、最先端の小型言語モデルである言語判定機能（SLMJ）を介して紹介します。セレネ・ミニは、11つの分布外ベンチマークでの全体的な性能において、最良のSLMJとGPT-4o-miniを超える一般的な用途の評価者です。絶対スコア、クラス分類、二つのものの偏好タスクを含む幅広い範囲での性能を上回ります。RewardBenchでは8B生成モデルの最高スコアを記録し、GPT-4oや専門的な判定者の強いベースラインを超えます。これを達成するために、公共データセットに合成的に生成された評価を追加し、フィルタリングとデータセットの削除を通じて高い品質を確保します。モデルは直接好み最適化（DPO）と観学微調練習（SFT）のロスを結合して訓練され、高度なプロンプタブルな評価者として優れています。セレネ・ミニは、金融および医療業のデータセットでの人間の専門家の評価とのゼロショットアgreementが大幅に向上し、プロンプト形式の変化に対しても強固です。初期結果から、セレネ・ミニは実際的なジャッジアーネームで最も高位の評価者として評価されています。モデルの重みはHuggingFace（https://hf.co/AtlaAI/Selene-1-Mini-Llama-3.1-8B）とOllamaで公開し、広範囲でのコミュニティの採用を促しています。",
      "upvotes": 2,
      "discussionId": "679ae76b5c55250b484838e0"
    },
    "publishedAt": "2025-01-29T21:44:37.041Z",
    "title": "Atla Selene Mini: A General Purpose Evaluation Model",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.17195.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5860
    },
    "isAuthorParticipating": false
  }
]