[
  {
    "paper": {
      "id": "2503.02682",
      "authors": [
        {
          "_id": "67c7c3d073299239b63f5378",
          "name": "Weimin Xiong",
          "hidden": false
        },
        {
          "_id": "67c7c3d073299239b63f5379",
          "name": "Yifan Song",
          "hidden": false
        },
        {
          "_id": "67c7c3d073299239b63f537a",
          "name": "Qingxiu Dong",
          "hidden": false
        },
        {
          "_id": "67c7c3d073299239b63f537b",
          "name": "Bingchan Zhao",
          "hidden": false
        },
        {
          "_id": "67c7c3d073299239b63f537c",
          "name": "Feifan Song",
          "hidden": false
        },
        {
          "_id": "67c7c3d073299239b63f537d",
          "name": "Xun Wang",
          "hidden": false
        },
        {
          "_id": "67c7c3d073299239b63f537e",
          "name": "Sujian Li",
          "hidden": false
        }
      ],
      "publishedAt": "2025-03-04T14:54:45.000Z",
      "title": "MPO: Meta Plan Optimizationを用いてLLMアガントを強化する",
      "summary": "最近の大語言モデル（LLMs）の進歩により、LLMベースのアガイントが相互作用計画タスクを成功して解決することができました。しかし、その成功に伴い、現在のアプローチは計画ハラシューション（planning hallucinations）を含む問題を多く見出し、新たなアガイントに対してはリトレーニングが必要となります。これらの課題に対して、私たちはメタ計画最適化（MPO）フレームワークを提案します。これはアガイントの計画能力を直接的に明示的なガイドラインを採用することで強化します。前の方法と違って、複雑な知識をもとにしたものであり、それらは大幅な人間の努力が必要であるか、品質保証が欠けている場合もありますが、MPOはメタ計画を通じて高レベルの一般的なガイドラインを利用し、アガイントの計画を助け、アガイントのタスク実行からのフィードバックに基づいてメタ計画の継続的な最適化を可能にします。私たちは代表的な2つのタスクにおいて実験を行い、MPOが現在の基準と比較して显著に優れていることを示しました。また、分析によると、MPOは以前の見たないシナリオでも仕事の完了の効率と一般化能力を両方向上に向上させるポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイントとポイントとなるようなポイント",
      "upvotes": 12,
      "discussionId": "67c7c3d173299239b63f53d6",
      "githubRepo": "https://github.com/WeiminXiong/MPO"
    },
    "publishedAt": "2025-03-04T22:30:53.253Z",
    "title": "MPO: Boosting LLM Agents with Meta Plan Optimization",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.02682.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6225a9983207dfc568407204",
      "avatarUrl": "/avatars/c970db6232d84ae8c0fa5f11d561d67c.svg",
      "fullname": "xwm",
      "name": "xwm",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2503.02846",
      "authors": [
        {
          "_id": "67c7c3ce6f68759bf368533c",
          "name": "Yuzhe Gu",
          "hidden": false
        },
        {
          "_id": "67c7c3ce6f68759bf368533d",
          "name": "Wenwei Zhang",
          "hidden": false
        },
        {
          "_id": "67c7c3ce6f68759bf368533e",
          "name": "Chengqi Lyu",
          "hidden": false
        },
        {
          "_id": "67c7c3ce6f68759bf368533f",
          "name": "Dahua Lin",
          "hidden": false
        },
        {
          "_id": "67c7c3ce6f68759bf3685340",
          "name": "Kai Chen",
          "hidden": false
        }
      ],
      "publishedAt": "2025-03-04T18:20:24.000Z",
      "title": "Mask-DPO: モデルの一般化可能な、細分化の事実性のアラインメント",
      "summary": "大語言モデル（LLMs）は、多様な領域でAIアシスタントとして機能する際に、ハウシャルレーション（即、不忠実または無意味な情報）を示す。LLMsの回答には、真実的な内容が常に含まれているため、以前の事実性の一致方法は、レスポンスレベルの好み学習を行う際に、トレーニング中にノイズを引き込むことが避けられなかった。そこで、本論文では、Direct Preference Optimization（DPO）に基づく細かい事実性の一致方法を提案し、Mask-DPOとしています。文書レベルの事実性をマスク信号として採用し、Mask-DPOは、好みサンプルからの事実的な文書だけを学習し、不偏好サンプルにおける事実的な内容の懲罰を防ぐことで、好み学習の不明確性を解決します。広範囲の実験結果表明、Mask-DPOは、LLMsの回答の事実性を大幅に向上させ、データセットの領域内と外れデータセットからの質問に対しても、トレーニング時に見ぬ質問とその相応トピックを含むものでも効果的です。そして、ANAHテストセットでのLlama3.1-8B-Instructのスコアは、49.19%から77.53%に改善され、同時に、外れデータセットのBiographyデータセットでのFactScoreも30.29%から39.39%に改善されます。また、Mask-DPOの一般化性能を研究するために、異なるトレーニングサンプルスケーリング戦略を使用し、トピックの数をスケールすることが問題数をスケールすることよりも効果的であることを見出しました。また、LLMsにおける事実性の一致はどのように行われるか、この現象の意味や、その証明のための実験を行いました。将来の研究における事実性の一致のスケーリングについての研究の道がつくります。",
      "upvotes": 11,
      "discussionId": "67c7c3d06f68759bf3685489",
      "githubRepo": "https://github.com/open-compass/ANAH"
    },
    "publishedAt": "2025-03-04T22:25:15.163Z",
    "title": "Mask-DPO: Generalizable Fine-grained Factuality Alignment of LLMs",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.02846.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6601196cc91ba4c08ad6e270",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6601196cc91ba4c08ad6e270/X2YPNzUOQXBz5Gv-xR9LW.jpeg",
      "fullname": "yuzhe gu",
      "name": "vanilla1116",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2503.01935",
      "authors": [
        {
          "_id": "67c7ba7f19b236e0564d1172",
          "user": {
            "_id": "66554507e6ea63012f35824c",
            "avatarUrl": "/avatars/b82de75bd60890e7bb524fc3754b131c.svg",
            "isPro": false,
            "fullname": "Kunlun_Zhu",
            "user": "Leozkl",
            "type": "user"
          },
          "name": "Kunlun Zhu",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-03-05T02:44:18.739Z",
          "hidden": false
        },
        {
          "_id": "67c7ba7f19b236e0564d1173",
          "name": "Hongyi Du",
          "hidden": false
        },
        {
          "_id": "67c7ba7f19b236e0564d1174",
          "name": "Zhaochen Hong",
          "hidden": false
        },
        {
          "_id": "67c7ba7f19b236e0564d1175",
          "name": "Xiaocheng Yang",
          "hidden": false
        },
        {
          "_id": "67c7ba7f19b236e0564d1176",
          "name": "Shuyi Guo",
          "hidden": false
        },
        {
          "_id": "67c7ba7f19b236e0564d1177",
          "name": "Zhe Wang",
          "hidden": false
        },
        {
          "_id": "67c7ba7f19b236e0564d1178",
          "name": "Zhenhailong Wang",
          "hidden": false
        },
        {
          "_id": "67c7ba7f19b236e0564d1179",
          "name": "Cheng Qian",
          "hidden": false
        },
        {
          "_id": "67c7ba7f19b236e0564d117a",
          "name": "Xiangru Tang",
          "hidden": false
        },
        {
          "_id": "67c7ba7f19b236e0564d117b",
          "name": "Heng Ji",
          "hidden": false
        },
        {
          "_id": "67c7ba7f19b236e0564d117c",
          "name": "Jiaxuan You",
          "hidden": false
        }
      ],
      "publishedAt": "2025-03-03T05:18:50.000Z",
      "title": "MultiAgentBench: LLM アガントの協力と競争の評価",
      "summary": "大語言モデル（LLMs）は、自動転移アガントとしての卓越した能力を示していますが、現在のベンチマークは、単一アガントのタスクだけに焦点を当てているか、狭い領域に限定されていて、多アガントの協調と競争の動態を捉えられていません。本論文では、多アガントベンチマーク（MultiAgentBench）を紹介します。これは、LLMベースの多アガントシステムを多様な、相互作用するスケーナーで評価するために設計された詳細なベンチマークです。フレームワークは、タスクの完了度合いだけでなく、新しい、マージンストーンベースの主なパフォーマンス指標を用いて協調と競争の品質を評価します。また、星形、鏈状、木構造、グラフ構造などの協調プロトコルと、グループ議論、認知計画などの革新的な戦略を評価しています。特に、gpt-4o-miniは平均的に最高のタスクスコアを達成し、研究スケーナーではグラフ構造が最も優れていて、認知計画はマージンストーン達成率を3%上げます。コードとデータセットは、https://github.com/MultiagentBench/MARBLEから公開です。",
      "upvotes": 7,
      "discussionId": "67c7ba8219b236e0564d124a",
      "githubRepo": "https://github.com/MultiagentBench/MARBLE"
    },
    "publishedAt": "2025-03-04T21:46:46.873Z",
    "title": "MultiAgentBench: Evaluating the Collaboration and Competition of LLM agents",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.01935.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "64c090a9f613170e7be93d2f",
      "avatarUrl": "/avatars/ccbdf444e1f2386d2281e8e42059ebb0.svg",
      "fullname": "KunlunZhu",
      "name": "KunlunZhu",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2503.01328",
      "authors": [
        {
          "_id": "67c7b5900b05ab9c7e805433",
          "name": "Xinyi Wan",
          "hidden": false
        },
        {
          "_id": "67c7b5900b05ab9c7e805434",
          "name": "Penghui Qi",
          "hidden": false
        },
        {
          "_id": "67c7b5900b05ab9c7e805435",
          "name": "Guangxing Huang",
          "hidden": false
        },
        {
          "_id": "67c7b5900b05ab9c7e805436",
          "name": "Jialin Li",
          "hidden": false
        },
        {
          "_id": "67c7b5900b05ab9c7e805437",
          "name": "Min Lin",
          "hidden": false
        }
      ],
      "publishedAt": "2025-03-03T09:11:06.000Z",
      "title": "PipeOffload: メモリオペレーションによるパイプライン並行化のスケーラビリティ向上",
      "summary": "パイプライン並行化（PP）は、大規模な言語モデル（LLMs）の訓練に広く使用されていますが、PPのスケーラビリティは、ミクロバッチの数がPPの程度に増えると高いアクティベーションメモリ消費量によって制限されます。本論文では、この課題を解決するために、PPで調査不足しているメモリオフロード戦略を活用します。実験的な研究により、標準的な設定の多くの場合、アクティベーションの少なくとも半分、そして潜在的にすべてを、無視できる微觀的なオーバーヘッドでオフロードできることが見出されました。全オフロードが可能でない場合、アクティベーションメモリの峰値を比較的線形以上に減少させる新しい選択的なオフロード戦略を導入します。また、メモリオフロードを他の技術と統合し、全体のトランシットとメモリ制限を共に考慮します。実験により、各デバイスのアクティベーションメモリは、全体のステージ数によって効果的に減少し、PPはTPより強い選択肢となり、さらにメモリ消費量が低く、19%の加速が証明されました。実装は以下のURLでオープンソースに公開されています。\nhttps://github.com/sail-sg/zero-bubble-pipeline-parallelism{このURL}",
      "upvotes": 7,
      "discussionId": "67c7b5970b05ab9c7e8055a1",
      "githubRepo": "https://github.com/sail-sg/zero-bubble"
    },
    "publishedAt": "2025-03-04T21:30:49.808Z",
    "title": "PipeOffload: Improving Scalability of Pipeline Parallelism with Memory Optimization",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.01328.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "63510eea0b94548566dad923",
      "avatarUrl": "/avatars/629eaaf810718259bf7588dc2e6cc0d5.svg",
      "fullname": "Xinyi Wan",
      "name": "ufotalent",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 5
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2503.02879",
      "authors": [
        {
          "_id": "67c7c42269d99dd25c5ba0ce",
          "name": "Siming Huang",
          "hidden": false
        },
        {
          "_id": "67c7c42269d99dd25c5ba0cf",
          "name": "Yuliang Xu",
          "hidden": false
        },
        {
          "_id": "67c7c42269d99dd25c5ba0d0",
          "user": {
            "_id": "67890323f8796231c857231e",
            "avatarUrl": "/avatars/f5ccd5186968d880fee9c36324a5f713.svg",
            "isPro": false,
            "fullname": "Mingmeng Geng",
            "user": "mgeng",
            "type": "user"
          },
          "name": "Mingmeng Geng",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-03-05T03:25:23.013Z",
          "hidden": false
        },
        {
          "_id": "67c7c42269d99dd25c5ba0d1",
          "name": "Yao Wan",
          "hidden": false
        },
        {
          "_id": "67c7c42269d99dd25c5ba0d2",
          "name": "Dongping Chen",
          "hidden": false
        }
      ],
      "publishedAt": "2025-03-04T18:58:13.000Z",
      "title": "Wikipedia ドキュメントの時代における LLM: 進化とリスク",
      "summary": "この論文では、Wikipediaに対するLarge Language Models（LLMs）の影響について詳細な分析を行い、現在のデータを用いてWikipediaの進化を調査し、潜在的なリスクをシミュレーションを用いて探求します。まず、ページ見込みと記事内容を分析し、Wikipediaの最近の変化を研究し、LLMsの影響を評価します。次に、LLMsがWikipediaに関連する各種の自然言語処理（NLP）タスクにどのような影響を与えているかを評価します。これらの発見とシミュレーション結果によれば、Wikipediaの記事はLLMsにより影響を受け、特定のカテゴリにおいて約1%-2%の影響を及ぼしていることが明らかです。Wikipediaに基づく機械翻訳ベンチマークがLLMsに影響を受ける場合、モデルのスコアが膨脹し、モデル間の比較結果も変化する可能性があります。また、RAGの効果がLLM生成のコンテンツによって汚染された知識ベースによって低下する可能性もあります。LLMsはWikipediaの言語と知識構造を完全に変更していませんが、我々は実験的な発見から、将来的なリスクについて慎重に検討する必要があることを信じています。",
      "upvotes": 6,
      "discussionId": "67c7c42369d99dd25c5ba103",
      "githubRepo": "https://github.com/HSM316/LLM_Wikipedia"
    },
    "publishedAt": "2025-03-04T22:25:53.653Z",
    "title": "Wikipedia in the Era of LLMs: Evolution and Risks",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.02879.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "643be8879f5d314db2d9ed23",
      "avatarUrl": "/avatars/64e9bb2c4e10fbe03e2b81afedf40865.svg",
      "fullname": "Chen Dongping",
      "name": "shuaishuaicdp",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 5
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2503.02368",
      "authors": [
        {
          "_id": "67c80f94ccc2e04adfa67079",
          "name": "Zhenhua Liu",
          "hidden": false
        },
        {
          "_id": "67c80f94ccc2e04adfa6707a",
          "name": "Lijun Li",
          "hidden": false
        },
        {
          "_id": "67c80f94ccc2e04adfa6707b",
          "name": "Ruizhe Chen",
          "hidden": false
        },
        {
          "_id": "67c80f94ccc2e04adfa6707c",
          "name": "Yuxian Jiang",
          "hidden": false
        },
        {
          "_id": "67c80f94ccc2e04adfa6707d",
          "name": "Tong Zhu",
          "hidden": false
        },
        {
          "_id": "67c80f94ccc2e04adfa6707e",
          "name": "Wenliang Chen",
          "hidden": false
        },
        {
          "_id": "67c80f94ccc2e04adfa6707f",
          "name": "Jing Shao",
          "hidden": false
        }
      ],
      "publishedAt": "2025-03-04T07:49:10.000Z",
      "title": "イテレーションドリーミング値関数最適化を用いたガイドデコーディング",
      "summary": "RLHF（Human Feedbackの強化学習）は、言語モデルの出力を制御するために主な方法となりましたが、高い計算コストとトレーニング不穩定に悩まされています。Guided decoding、特に価値ガイドされた方法は、モデルの再トレーニングを避けて出力を制御するためにコスト効率的な代替として提唱されています。しかし、価値関数の精度が価値ガイドされた解码の精度に重要です。不正確性は最適な決策を引き起こし、性能の低下につながります。現在の方法は、最適な価値関数の正確な推定に苦戦し、効果的な制御に成功しませんでした。私たちは、Monte Carlo Value EstimationとIterative On-Policy Optimizationの2つのキーコンポーネントを採用した新しいフレームワーク、Iterative Value Function Optimizationを提唱します。これらのコンポーネントは、多様なタロイの探索で推定の分散を減らし、価値ガイドされたポリシーからのタロイの収集で価値推定を進行的に改善します。文摘、多ターンダイアロジー、指示従いの極めて幅広い実験により、価値ガイドされた解码アプローチの効果性を示し、これらのアプローチは、価値関数の原理的な最適化を活用して効率的かつ効果的な制御を実現し、計算コストを大幅に削減します。",
      "upvotes": 5,
      "discussionId": "67c80f94ccc2e04adfa670b2"
    },
    "publishedAt": "2025-03-05T03:48:51.408Z",
    "title": "Iterative Value Function Optimization for Guided Decoding",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.02368.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "619b00dd4b0db5ca9d3ea35f",
      "avatarUrl": "/avatars/fce5ac388b7f10cbbc63e9992a5a799f.svg",
      "fullname": "Zhenhua Liu",
      "name": "zhliu",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.14856",
      "authors": [
        {
          "_id": "67bee83509a4524abf899511",
          "name": "Weilin Zhao",
          "hidden": false
        },
        {
          "_id": "67bee83509a4524abf899512",
          "name": "Tengyu Pan",
          "hidden": false
        },
        {
          "_id": "67bee83509a4524abf899513",
          "name": "Xu Han",
          "hidden": false
        },
        {
          "_id": "67bee83509a4524abf899514",
          "name": "Yudi Zhang",
          "hidden": false
        },
        {
          "_id": "67bee83509a4524abf899515",
          "name": "Ao Sun",
          "hidden": false
        },
        {
          "_id": "67bee83509a4524abf899516",
          "name": "Yuxiang Huang",
          "hidden": false
        },
        {
          "_id": "67bee83509a4524abf899517",
          "name": "Kaihuo Zhang",
          "hidden": false
        },
        {
          "_id": "67bee83509a4524abf899518",
          "name": "Weilun Zhao",
          "hidden": false
        },
        {
          "_id": "67bee83509a4524abf899519",
          "name": "Yuxuan Li",
          "hidden": false
        },
        {
          "_id": "67bee83509a4524abf89951a",
          "name": "Jianyong Wang",
          "hidden": false
        },
        {
          "_id": "67bee83509a4524abf89951b",
          "name": "Zhiyuan Liu",
          "hidden": false
        },
        {
          "_id": "67bee83509a4524abf89951c",
          "name": "Maosong Sun",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-20T18:58:10.000Z",
      "title": "FR-Spec: ランキングされた頻度による推測的なサンプリングをよそって大規模な単語ボキャブラリーの言語モデルを加速する",
      "summary": "スペシュラティブサンプリングは、大規模言語モデル（LLMs）の自動回帰生成プロセスを加速する重要な手法として現れた。これは、ドラフトして確認するメカニズムを利用して、1つの順伝播で複数のトークンを生成することである。最先端のスペシュラティブサンプリング手法は、印象的な層の圧縮を達成するために、単一の層と言語モデリング（LM）ヘッドをドラフトモデルとして使用しているが、ビジオカロリーの大規模なLLMs（例：Llama-3-8B、128kトークンのビジオカロリー）に対して、効率の向上は大幅に減少している。これに対して、我々は、ビジオカロリー空間の圧縮によるドラフト候補選択の最適化を実現するために、頻度ランク付けされたスペシュラティブサンプリングフレームワークFR-Specを提案している。頻度優先のトークンサブセットにドラフト検索を制限することで、我々の方法は、最終的な出力分布の等価性を確保しながらLM Headの計算オーバーヘッドを75%削減する。多くのデータセットでの実験は、最先端のスペシュラティブサンプリング手法EAGLE-2を超える平均1.12倍のスピードアップを示している。",
      "upvotes": 5,
      "discussionId": "67bee83609a4524abf899550",
      "githubRepo": "https://github.com/thunlp/FR-Spec"
    },
    "publishedAt": "2025-03-05T00:36:34.146Z",
    "title": "FR-Spec: Accelerating Large-Vocabulary Language Models via Frequency-Ranked Speculative Sampling",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.14856.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64b8ff3d95bd42c770878042",
      "avatarUrl": "/avatars/564a4dccdf9e5b813a99979b0ef58183.svg",
      "fullname": "Weilin Zhao",
      "name": "Achazwl",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 9
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2503.00955",
      "authors": [
        {
          "_id": "67c7dbff25d0b3348ddace44",
          "name": "Nam V. Nguyen",
          "hidden": false
        },
        {
          "_id": "67c7dbff25d0b3348ddace45",
          "name": "Dien X. Tran",
          "hidden": false
        },
        {
          "_id": "67c7dbff25d0b3348ddace46",
          "name": "Thanh T. Tran",
          "hidden": false
        },
        {
          "_id": "67c7dbff25d0b3348ddace47",
          "name": "Anh T. Hoang",
          "hidden": false
        },
        {
          "_id": "67c7dbff25d0b3348ddace48",
          "name": "Tai V. Duong",
          "hidden": false
        },
        {
          "_id": "67c7dbff25d0b3348ddace49",
          "name": "Di T. Le",
          "hidden": false
        },
        {
          "_id": "67c7dbff25d0b3348ddace4a",
          "name": "Phuc-Lu Le",
          "hidden": false
        }
      ],
      "publishedAt": "2025-03-02T16:22:46.000Z",
      "title": "SemViQA: ベトナム情報の意味を理解する質問回答システム ファクトチェック",
      "summary": "ミスデータの増加、GPTやGeminiなどの大規模言語モデル（LLMs）によって拡大されたもので、低リソース言語のように越南語に対しては強力的な事実検証ソリューションが必要となります。現在の方法は、意味の不明確性、同音語と複雑な言語構造に対して苦労し、精度と効率の間を補います。私たちは、セマンティックベースの証拠検索（SER）と2ステップの判定分類（TVC）を統合した新しい越南語事実検証フレームワークSemViQAを紹介します。私たちのアプローチは精度と速さをバランスにし、ISE-DSC01での厳格な精度78.97％とViWikiFCでの80.82％で最先端の結果を収め、UIT Data Science Challengeで1位を獲得しました。また、SemViQA Fasterは精度を維持するまで7倍速く推論速度を向上させます。SemViQAは越南語の事実確認に新たなベンチマークを設定し、ミスデータの戦いに進むことを促します。ソースコードは以下のURLから利用可能です：https://github.com/DAVID-NGUYEN-S16/SemViQA。",
      "upvotes": 5,
      "discussionId": "67c7dc0025d0b3348ddace64",
      "githubRepo": "https://github.com/DAVID-NGUYEN-S16/SemViQA"
    },
    "publishedAt": "2025-03-05T00:08:53.214Z",
    "title": "SemViQA: A Semantic Question Answering System for Vietnamese Information Fact-Checking",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.00955.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64c2bea2ada7df214276913b",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64c2bea2ada7df214276913b/QFCtmCn439Afsr7uqyoMT.jpeg",
      "fullname": "Nguyen Van Nam",
      "name": "DavidNguyen",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2503.01342",
      "authors": [
        {
          "_id": "67c6b46e8389d77f5ba87179",
          "user": {
            "_id": "6585493b53c37507639fe3ba",
            "avatarUrl": "/avatars/b7e71d4fa5ebb89a7ed6b2a8313687b5.svg",
            "isPro": false,
            "fullname": "Hao Tang",
            "user": "kanashi6",
            "type": "user"
          },
          "name": "Hao Tang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-03-04T08:34:43.034Z",
          "hidden": false
        },
        {
          "_id": "67c6b46e8389d77f5ba8717a",
          "name": "Chenwei Xie",
          "hidden": false
        },
        {
          "_id": "67c6b46e8389d77f5ba8717b",
          "name": "Haiyang Wang",
          "hidden": false
        },
        {
          "_id": "67c6b46e8389d77f5ba8717c",
          "name": "Xiaoyi Bao",
          "hidden": false
        },
        {
          "_id": "67c6b46e8389d77f5ba8717d",
          "name": "Tingyu Weng",
          "hidden": false
        },
        {
          "_id": "67c6b46e8389d77f5ba8717e",
          "name": "Pandeng Li",
          "hidden": false
        },
        {
          "_id": "67c6b46e8389d77f5ba8717f",
          "name": "Yun Zheng",
          "hidden": false
        },
        {
          "_id": "67c6b46e8389d77f5ba87180",
          "name": "Liwei Wang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-03-03T09:27:24.000Z",
      "title": "UFO: 開放範囲の言語インターフェースを通じた細部視覚認識の統一アプローチ",
      "summary": "一般化モデルは、言語と視覚-言語タスクで驚異的な成功を収め、一連のモデリングの可能性を示しています。しかし、検出や分割のような細かい視覚認識タスクをこれらのモデルに有効に統合することは大変な課題です。これは、これらのタスクが多くは特定のデザインやアーキテクチャに依存し、モデリングプロセスを複雑化するからです。この課題を解決するために、我々は、言語インターフェースを開放的に用いて細かい視覚認識タスクを統合するフレームワークを提案します。すべての認識ターゲットを言語スペースに変換し、我々のフレームワークは物体レベルの検出、ピクセルレベルの分割、画像レベルの視覚-言語タスクを一つのモデルに統合します。また、我々は、言語インターフェースをだけに依存した新しい埋め込み検索アプローチを導入し、分割タスクをサポートします。我々のフレームワークは、細かい視覚認識タスクと視覚-言語タスクの間の隙間を結びつけ、構造設計や訓練戦略を大幅に簡単化し、複雑なタスク特化デザインの方法と比較的または上位の性能を達成します。5つの標準的な視覚認識データセットに対する多タスク訓練後、我々のフレームワークは、COCO インスタンス分割で前最優秀の一般化モデルを12.3 mAP より上回り、ADE20K 語意分割では3.3 mIoU より上回ります。また、我々の方法は、現存するMLLMとセミアスペクトを無難に統合し、細かい視覚認識能力と先進的な言語能力を有効に組み合わせ、理由分割やその他の難しいタスクを実現することを可能にします。コードとモデルは公開的に提供されます。",
      "upvotes": 4,
      "discussionId": "67c6b4728389d77f5ba8724d",
      "githubRepo": "https://github.com/nnnth/UFO"
    },
    "publishedAt": "2025-03-04T23:55:08.057Z",
    "title": "UFO: A Unified Approach to Fine-grained Visual Perception via Open-ended Language Interface",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.01342.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6585493b53c37507639fe3ba",
      "avatarUrl": "/avatars/b7e71d4fa5ebb89a7ed6b2a8313687b5.svg",
      "fullname": "Hao Tang",
      "name": "kanashi6",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2503.02197",
      "authors": [
        {
          "_id": "67c7c183203958ca9c09171a",
          "name": "Zhixun Chen",
          "hidden": false
        },
        {
          "_id": "67c7c183203958ca9c09171b",
          "name": "Ming Li",
          "hidden": false
        },
        {
          "_id": "67c7c183203958ca9c09171c",
          "name": "Yuxuan Huang",
          "hidden": false
        },
        {
          "_id": "67c7c183203958ca9c09171d",
          "name": "Yali Du",
          "hidden": false
        },
        {
          "_id": "67c7c183203958ca9c09171e",
          "name": "Meng Fang",
          "hidden": false
        },
        {
          "_id": "67c7c183203958ca9c09171f",
          "name": "Tianyi Zhou",
          "hidden": false
        }
      ],
      "publishedAt": "2025-03-04T02:14:55.000Z",
      "title": "ATLaS: エージェント調整による学習の重要なステップ",
      "summary": "大語言モデル（LLM）アガエントは、多様なデータタスクにおいて驚異的な一般化能力を示しています。現在のアガエント調整アプローチは、通常、全てのエクスパートトラジェクトに対する規範的調整を行います。しかし、全トラジェクトのビジョンクローニングは、エクスパートバイアスを引き起こし、エクスパートデータによらない状態に対する一般化を弱めることがあります。また、計画、中間サブタスクの複雑な理由、そして戦略的な決定の重要なステップは、アガエントタスクの成功において不可欠です。これらのステップを学習することが、LLMアガエントの向上において鍵となります。より効果的で効率的なアガエント調整を実現するために、ATLaSを提案します。ATLaSは、エクスパートトラジェクトの重要なステップを特定し、それらのみに対してLLMを調整し、費用を減らします。トレーニングの焦点を少なくとも重要なステップに向けることで、我々の方法は、全トラジェクトの過学習リスクを軽減し、異なる環境とタスクにおける一般化を促進します。拡大の実験では、ATLaSが選択した30%の重要なステップにおいて調整されたLLMは、全ステップに対する調整されたLLMおよび最近のオープンソースLLMアガエントに対して上回りました。ATLaSは、多様な環境とエコシステムとの相互作用を行うジャンプアガエントの基本的なスキルを保持し、向上させます。",
      "upvotes": 4,
      "discussionId": "67c7c185203958ca9c091751"
    },
    "publishedAt": "2025-03-04T22:17:48.386Z",
    "title": "ATLaS: Agent Tuning via Learning Critical Steps",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.02197.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "647f5af5b0e96764589f3b2a",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/VJ4cDyjp5M3V5WmI5gPIU.jpeg",
      "fullname": "Tianyi Zhou",
      "name": "zhoutianyi",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 12
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2503.02878",
      "authors": [
        {
          "_id": "67c7bf7c40de8b1b534d23fa",
          "user": {
            "_id": "635d76ce94e5b275ca74b967",
            "avatarUrl": "/avatars/5d9a389e5fd558c0b8f0724bf0838a3e.svg",
            "isPro": false,
            "fullname": "Ethan Mendes",
            "user": "emendes3",
            "type": "user"
          },
          "name": "Ethan Mendes",
          "status": "extracted_confirmed",
          "statusLastChangedAt": "2025-03-05T03:06:00.588Z",
          "hidden": false
        },
        {
          "_id": "67c7bf7c40de8b1b534d23fb",
          "name": "Alan Ritter",
          "hidden": false
        }
      ],
      "publishedAt": "2025-03-04T18:58:11.000Z",
      "title": "言語モデルは、状態価値の評価を自動的に改善し、より良い検索を実現することができます。",
      "summary": "グルードデータのタスク完了報酬または人間の示唆を集めるための多段階推理タスクには、通常は費用と時間がかかり、特にウェブタスクのような相互作用領域ではさらに困難です。このボトルネックを解決するために、私たちは、状態遷移ダイナミクスを活用した自動転勤を学ぶ方法を提案します。この方法は、言語モデル制御された探索を効果的に指導する価値モデルを訓練するために役立ちます。私たちは、中間サイズ（8億パラメータ）の開放重みの価値モデルが、自動転勤を学ぶことで、フロンティアのLLM（例：gpt-4o）を用いた価値モデルと同等の性能を達成できることを見出しました。また、自動転勤を学ぶことで、前回のLLMベースの木検索に比べて、効果が20%向上し、37倍のコスト削減が見られ、グルードデータの報酬に依存しないように改善されます。",
      "upvotes": 4,
      "discussionId": "67c7bf7e40de8b1b534d2491",
      "githubRepo": "https://github.com/ethanm88/self-taught-lookahead"
    },
    "publishedAt": "2025-03-04T22:07:18.480Z",
    "title": "Language Models can Self-Improve at State-Value Estimation for Better Search",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.02878.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "635d76ce94e5b275ca74b967",
      "avatarUrl": "/avatars/5d9a389e5fd558c0b8f0724bf0838a3e.svg",
      "fullname": "Ethan Mendes",
      "name": "emendes3",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2503.02876",
      "authors": [
        {
          "_id": "67c7bd7149b52e85403758f8",
          "user": {
            "_id": "6308bae5c038bf42d56a98e5",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/yrslTwUe_vy_ZJha1H83m.png",
            "isPro": false,
            "fullname": "Dmitry Nechaev",
            "user": "mgvz",
            "type": "user"
          },
          "name": "Dmitry Nechaev",
          "status": "extracted_confirmed",
          "statusLastChangedAt": "2025-03-05T03:07:52.944Z",
          "hidden": false
        },
        {
          "_id": "67c7bd7149b52e85403758f9",
          "user": {
            "_id": "6655b0b9d6c043f39719eaaf",
            "avatarUrl": "/avatars/66138e67ef3be41f29857b285b37adff.svg",
            "isPro": false,
            "fullname": "Alex Pchelnikov",
            "user": "alpchel",
            "type": "user"
          },
          "name": "Alexey Pchelnikov",
          "status": "extracted_confirmed",
          "statusLastChangedAt": "2025-03-05T03:07:35.092Z",
          "hidden": false
        },
        {
          "_id": "67c7bd7149b52e85403758fa",
          "name": "Ekaterina Ivanova",
          "hidden": false
        }
      ],
      "publishedAt": "2025-03-04T18:57:12.000Z",
      "title": "スパイダー：一つの詳細な多器官サブジェクトデータセットとベースラインモデル",
      "summary": "AIの計算病理学の進展には、大規模的な高品質で多様なデータセットが必要ですが、現在の公開データセットは、器官の多様性、クラスのカバー、またはアノテーションの品質については限界です。この隙を埋めるために、SPIDER（サブジューティード・パチンゴレス・イメージ・ディスクラプション・リポジトリ）を紹介します。SPIDERは、複数の器官タイプを含む最大の公開データセットです。器官ごとに完全なクラスカバーを提供し、スキン、カロリンチュラル、サーボックスを含む。SPIDERは、専門家のパチンゴレスをチェックした高品質のアノテーションを提供し、周囲のコンテキストパチンゴレスを含み、空間的なコンテキストを提供して分類性能を向上させます。\n\nSPIDERのデータセットと同時に、ヒボー-Lの基盤モデルを特徴抽出器として、アテンションベースの分類ヘッドと組み合わせたSPIDERでトレーニングされたベースラインモデルを紹介します。これらのモデルは、複数の組織カテゴリにおいて最先端の性能を達成し、将来のデジタルパチンゴレス研究の強いベンチマークとして役立ちます。パチンゴレス分類よりも、このモデルは重要な領域の迅速な識別、定量的な組織メトリックを可能にし、多モードアプローチの基盤を築きます。\n\nデータセットとトレーニングされたモデルは、研究の進歩、再現性、AI駆動のパチンゴレス開発において公開されています。以下のURLからアクセスしてください：https://github.com/HistAI/SPIDER",
      "upvotes": 2,
      "discussionId": "67c7bd7649b52e8540375a34"
    },
    "publishedAt": "2025-03-04T22:08:26.811Z",
    "title": "SPIDER: A Comprehensive Multi-Organ Supervised Pathology Dataset and Baseline Models",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.02876.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6308bae5c038bf42d56a98e5",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/yrslTwUe_vy_ZJha1H83m.png",
      "fullname": "Dmitry Nechaev",
      "name": "mgvz",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2503.02268",
      "authors": [
        {
          "_id": "67c7ebafdf15f5978ac987c3",
          "name": "Wenjia Jiang",
          "hidden": false
        },
        {
          "_id": "67c7ebafdf15f5978ac987c4",
          "name": "Yangyang Zhuang",
          "hidden": false
        },
        {
          "_id": "67c7ebafdf15f5978ac987c5",
          "name": "Chenxi Song",
          "hidden": false
        },
        {
          "_id": "67c7ebafdf15f5978ac987c6",
          "name": "Xu Yang",
          "hidden": false
        },
        {
          "_id": "67c7ebafdf15f5978ac987c7",
          "name": "Chi Zhang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-03-04T04:34:09.000Z",
      "title": "AppAgentX: GUIアガントの進化 - スマートフォンの専門家としての機能性",
      "summary": "最近の大語言モデル（LLM）の進歩により、GUI（グラフィックユーザーインターフェース）と相互作用できる知能的なLLMベースのアガントの開発が進められています。これらのアガントは強い理由能力と適応性を示し、通常に定義されたルールが必要とされた複雑な任務を行うことができます。しかし、LLMベースのアガントではステップごとの理由の依存関係が通常の任務において不適切で、特にルーチン的な任務においては効率が低くなります。対して、傳統的なルールベースのシステムは効率が高いが、新しいシナリオに適応する知能と柔軟性が欠けています。この課題を解決するために、私たちはGUIアガントに対して新しい進化的なフレームワークを提案し、効率を高めながら知能と柔軟性を維持することを目指しています。私たちのアプローチはアガントのタスク実行歴を記録するメモリ機能を採用しています。この歴史を分析することで、アガントは再現する行動シーケンスを特定し、ハイレベルの行動を進化させ、これらの低レベルの操作を置き換え、効率を向上させることができます。これにより、アガントは複雑な理由を必要とする任務に焦点を当て、ルーチン的な行動を簡単にすることができます。複数のベンチマークタスクにおいて実験結果を示すことにより、私たちのアプローチは現在の方法と比較して両方とも効率と精度の向上が明らかに見られます。コードは開源され、進める研究にサポートを提供します。",
      "upvotes": 1,
      "discussionId": "67c7ebb5df15f5978ac98975"
    },
    "publishedAt": "2025-03-05T01:15:42.467Z",
    "title": "AppAgentX: Evolving GUI Agents as Proficient Smartphone Users",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/64196320ed725fef64419c2a/dUDWK6xfRd9uVZz77V0K6.mp4"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.02268.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64196320ed725fef64419c2a",
      "avatarUrl": "/avatars/96feb22fb5e8931d6c9e0ea06148266f.svg",
      "fullname": "Chi Zhang",
      "name": "DrChiZhang",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 3
    },
    "isAuthorParticipating": false
  }
]