[
  {
    "paper": {
      "id": "2502.01506",
      "authors": [
        {
          "_id": "67a4214f12b90b15dc5a648e",
          "name": "Yuzhe Yang",
          "hidden": false
        },
        {
          "_id": "67a4214f12b90b15dc5a648f",
          "name": "Yifei Zhang",
          "hidden": false
        },
        {
          "_id": "67a4214f12b90b15dc5a6490",
          "name": "Minghao Wu",
          "hidden": false
        },
        {
          "_id": "67a4214f12b90b15dc5a6491",
          "name": "Kaidi Zhang",
          "hidden": false
        },
        {
          "_id": "67a4214f12b90b15dc5a6492",
          "name": "Yunmiao Zhang",
          "hidden": false
        },
        {
          "_id": "67a4214f12b90b15dc5a6493",
          "name": "Honghai Yu",
          "hidden": false
        },
        {
          "_id": "67a4214f12b90b15dc5a6494",
          "name": "Yan Hu",
          "hidden": false
        },
        {
          "_id": "67a4214f12b90b15dc5a6495",
          "name": "Benyou Wang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-03T16:39:48.000Z",
      "title": "ツインマーク：金融市場の可換的な行動と社会証明",
      "summary": "社会現象の研究は長年社会学の中心的な焦点であった。ルールベースのAgent-Based Models（ABMs）などの伝統的なモデリングアプローチは、特に行動経済学で強調される無理性的要素を含む人類の行動の多様性と複雑性を捉えられなかった。最近、大規模言語モデル（LLM）アガントは、社会学における人類の行動のモデリングやロールプレイアプリケーションのシミュレーションツールとして採用され始めている。研究は、LLMが認知バイアス、感情の変動や他の非理性的影響を考慮できることを示し、より写実的な社会経済ダイナミクスのシミュレーションを可能にしていることを示している。本論文では、TwinMarketという新しい多エージェントフレームワークを介して、LLMを用いて社会経済システムをシミュレートする方法を紹介する。特に、個人の行動が相互作用とフィードバック機構を通じて集団的なダイナミクスや現象を生み出すことを見る。シミュレーションされた株市場環境での実験を通じて、個人の行動が集団的な行動を引き起こし、金融バブルや不揃いなどの現象を生み出すことを示し、個人の決策と集団的な社会経済パターンの複雑な相互作用について有價値な見解を提供する。",
      "upvotes": 21,
      "discussionId": "67a4215212b90b15dc5a650a"
    },
    "publishedAt": "2025-02-05T21:44:36.248Z",
    "title": "TwinMarket: A Scalable Behavioral and Social Simulation for Financial Markets",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01506.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "643c047326f177a3e41627b6",
      "avatarUrl": "/avatars/ade75cebd049daf080ba80a80d516240.svg",
      "fullname": "Yifei Zhang",
      "name": "amstrongzyf",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.03373",
      "authors": [
        {
          "_id": "67a42c079a4fb11b11cc4f6f",
          "name": "Edward Yeo",
          "hidden": false
        },
        {
          "_id": "67a42c079a4fb11b11cc4f70",
          "name": "Yuxuan Tong",
          "hidden": false
        },
        {
          "_id": "67a42c079a4fb11b11cc4f71",
          "name": "Morry Niu",
          "hidden": false
        },
        {
          "_id": "67a42c079a4fb11b11cc4f72",
          "name": "Graham Neubig",
          "hidden": false
        },
        {
          "_id": "67a42c079a4fb11b11cc4f73",
          "name": "Xiang Yue",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-05T17:13:32.000Z",
      "title": "長いチェーンの思い出を理解するLLMの謎を解明する",
      "summary": "スケーリングインフェリンス計算は、大規模言語モデル（LLMs）の推理における理由論を強化します。長いチェーンオブコンシュー（CoTs）を利用して、バックトラッキングや誤り修正などの戦略を実行することができます。強化学習（RL）はこれらの能力の開発に重要な方法として現れましたが、長いCoTsが出現する条件が明確ではありません。また、RLの訓練は謹密な設計選択を必要とします。本研究では、長いCoTsの理由論の機構を系統的に調査し、モデルが長いCoTsのトラジェクトを生成するための要因を特定しました。複数の監督的訓練（SFT）とRL実験を通じて、以下の4つの主な発見を示します：1. SFTは厳密に必要ではありませんが、訓練を簡単にし、効率を向上させます。2. 理由論の能力は訓練計算量が増加することによって発見されますが、その開発は確実ではありません。そのため、報酬のシフトはCoTsの長さの成長を安定させるために重要です。3. 報酬のスケーリングがRLにおける重要な見通しです。報酬信号をノイズを含むウェブ抜粋された解決策を利用し、フィルタリング機構を使用することで強い可能性が見出され、特に分布外（OOD）タスクの場合に効果的です。4. 誤り修正などの基本的な能力はベースモデルに固有ですが、複雑なタスクでこれらのスキルを効果的に奨励するためには、計算量が大きくなり、その発見は複雑なアプローチが必要です。これらの見解は、LLMsの長いCoTsの理由論を強化するための訓練戦略の最適化に実用的なガイドを提供します。コードは以下のURLで公開されています：https://github.com/eddycmu/demystify-long-cot。",
      "upvotes": 15,
      "discussionId": "67a42c089a4fb11b11cc4fae"
    },
    "publishedAt": "2025-02-05T22:27:48.348Z",
    "title": "Demystifying Long Chain-of-Thought Reasoning in LLMs",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.03373.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "6230d750d93e84e233882dbc",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6230d750d93e84e233882dbc/4MGEekLW3oWzqeFWDWvIK.jpeg",
      "fullname": "Xiang Yue",
      "name": "yuexiang96",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 26
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.03387",
      "authors": [
        {
          "_id": "67a445ccbdd74b63b4e52a7d",
          "name": "Yixin Ye",
          "hidden": false
        },
        {
          "_id": "67a445ccbdd74b63b4e52a7e",
          "name": "Zhen Huang",
          "hidden": false
        },
        {
          "_id": "67a445ccbdd74b63b4e52a7f",
          "name": "Yang Xiao",
          "hidden": false
        },
        {
          "_id": "67a445ccbdd74b63b4e52a80",
          "name": "Ethan Chern",
          "hidden": false
        },
        {
          "_id": "67a445ccbdd74b63b4e52a81",
          "name": "Shijie Xia",
          "hidden": false
        },
        {
          "_id": "67a445ccbdd74b63b4e52a82",
          "name": "Pengfei Liu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-05T17:23:45.000Z",
      "title": "LIMO: 理由のためには少ないほうが良い",
      "summary": "ここでは、複雑な理由論が大規模な言語モデルでどのように現れるかを理解することを課題にしています。通常の知見は、複雑な理由論タスクは複雑なトレーニングデータ（100,000例以上）が必要とすると伝えていますが、我々は、話題的な少数の例（817例）で複雑な数学的な理由論能力を有効に引き出すことができることを示します。詳細な実験を通じて、我々が提案したモデルLIMOは、前所未有の数学的理由論の性能を示します。817例の訓練データを用いて、LIMOはAIMEで57.1%の精度、MATHで94.8%の精度を達成します。前のSFTベースのモデルの6.5%と59.2%に対して、これらの性能が向上し、前のアプローチによって必要とされた訓練データの1%だけを使用しました。LIMOは、10種類の多様なベンチマークで40.5%の絶対的な向上を達成し、100倍以上のデータで訓練されたモデルを上回り、SFTは記憶化よりも一般化によることを質疑します。これらの結果に基づいて、我々は、複雑な理由論の発見閾値を決定する2つの要因を示します：1）訓練前に完全にエンコードされたモデルの知識の基礎の完全性、2）訓練後の例の有效性である「認知テンプレート」がモデルがどのように知識ベースを利用して複雑な理由論タスクを解決するかを示すことで、このヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモヘモ",
      "upvotes": 9,
      "discussionId": "67a445cdbdd74b63b4e52af7"
    },
    "publishedAt": "2025-02-06T00:26:02.483Z",
    "title": "LIMO: Less is More for Reasoning",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.03387.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5956
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.02737",
      "authors": [
        {
          "_id": "67a446a9430e358f5d5ac4c3",
          "name": "Loubna Ben Allal",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4c4",
          "name": "Anton Lozhkov",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4c5",
          "name": "Elie Bakouch",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4c6",
          "name": "Gabriel Martín Blázquez",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4c7",
          "name": "Guilherme Penedo",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4c8",
          "name": "Lewis Tunstall",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4c9",
          "name": "Andrés Marafioti",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4ca",
          "name": "Hynek Kydlíček",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4cb",
          "name": "Agustín Piqueres Lajarín",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4cc",
          "name": "Vaibhav Srivastav",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4cd",
          "name": "Joshua Lochner",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4ce",
          "name": "Caleb Fahlgren",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4cf",
          "name": "Xuan-Son Nguyen",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4d0",
          "name": "Clémentine Fourrier",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4d1",
          "name": "Ben Burtenshaw",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4d2",
          "name": "Hugo Larcher",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4d3",
          "name": "Haojun Zhao",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4d4",
          "name": "Cyril Zakka",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4d5",
          "name": "Mathieu Morlon",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4d6",
          "name": "Colin Raffel",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4d7",
          "user": {
            "_id": "6284b359eac6d6ca13879514",
            "avatarUrl": "/avatars/2dcca0f0d21cbe1a54eedac759adc61c.svg",
            "isPro": false,
            "fullname": "evaluate-bot",
            "user": "evaluate-bot",
            "type": "user"
          },
          "name": "Leandro von Werra",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-02-06T05:20:41.925Z",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4d8",
          "name": "Thomas Wolf",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-04T21:43:16.000Z",
      "title": "スモルLM2: スモルが大きくなると　データセンター的な訓練で小語言モデルを学習する",
      "summary": "この論文では、「SmolLM2」という最先端の「小さい」（170億パラメータ）言語モデルの開発を記録しています。SmolLM2は、ネットワークテキストと数学、コード、指示従いデータを混ぜた多段階学習プロセスを使用して、約11兆トークンのデータで過学習させています。また、既存のデータセットが問題的に小さいか低品質な場合には、新たな特殊化されたデータセット（FineMath、Stack-Edu、SmolTalk）を追加しています。デザイン決定を支援するためには、小規模な消去試験および手動での精進プロセスを行い、各段階でのパフォーマンスに基づいてデータセットの混合率を更新しています。最終的に、SmolLM2は最近の他の小さなLM（Qwen2.5-1.5B、Llama3.2-1B）を超える性能を示しています。将来のLM開発研究および小さなLMのアプリケーションについての研究を促進するために、SmolLM2およびこのプロジェクト中に準備したすべてのデータセットを公開しています。",
      "upvotes": 9,
      "discussionId": "67a446a9430e358f5d5ac4f8"
    },
    "publishedAt": "2025-02-06T00:20:51.704Z",
    "title": "SmolLM2: When Smol Goes Big -- Data-Centric Training of a Small Language Model",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.02737.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5956
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.02339",
      "authors": [
        {
          "_id": "67a3262873bdaf626f1e9eab",
          "name": "Jinyang Wu",
          "hidden": false
        },
        {
          "_id": "67a3262873bdaf626f1e9eac",
          "name": "Mingkuan Feng",
          "hidden": false
        },
        {
          "_id": "67a3262873bdaf626f1e9ead",
          "name": "Shuai Zhang",
          "hidden": false
        },
        {
          "_id": "67a3262873bdaf626f1e9eae",
          "name": "Ruihan Jin",
          "hidden": false
        },
        {
          "_id": "67a3262873bdaf626f1e9eaf",
          "name": "Feihu Che",
          "hidden": false
        },
        {
          "_id": "67a3262873bdaf626f1e9eb0",
          "name": "Zengqi Wen",
          "hidden": false
        },
        {
          "_id": "67a3262873bdaf626f1e9eb1",
          "name": "Jianhua Tao",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-04T14:18:29.000Z",
      "title": "MCTSによる構造化された思考を用いた多モデル論理の向上",
      "summary": "多タイプ大語言モデル（MLLMs）は、驚異的な能力を示していますが、複雑な視覚的推理ではまだ課題があります。最近の努力は、OpenAI o1-likeの構造化された思考を明示的な検索構造や教師ガイドされた煉熱によって、MLLMsの推理を向上させようとしていますが、これらは性能と効率のバランスを保つことが難しく、様々なデータや検索空間を重視することで、低効率のインプリットインサイト抽出とデータ利用において限界があります。これらの問題を解決するために、我々は、Monte Carlo Tree Search（MCTS）を用いた自動化構造化思考パラダイムであるAStarを提案します。AStarは、限られたデータからMCTSによる階層的構造を用いて高レベルの認知的思考パターンを自動的に得ります。これらの明示的なパターンに基づいて、我々は、モデルの内部の思考能力と外部の思考ガイドラインを無間に統合するユニットレーティング推理フレームワークを設計します。このフレームワークは、最小限の木のイテレーションで効率的な推論を可能にします。この新しいパラダイムは、性能と効率のバランスを強く取り扱います。詳細な実験は、MathVerseベンチマークでのAStarの効果を示し、54.0%の上位精度を達成し、GPT-4o（50.2%）を超える同時に、大規模なデータと計算効率を維持しました。",
      "upvotes": 7,
      "discussionId": "67a3262973bdaf626f1e9edb"
    },
    "publishedAt": "2025-02-05T21:45:32.304Z",
    "title": "Boosting Multimodal Reasoning with MCTS-Automated Structured Thinking",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.02339.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6747de57f8cab58c22ec94a2",
      "avatarUrl": "/avatars/5bae0341862fac24564781c0fa32aac5.svg",
      "fullname": "Jinyang Wu",
      "name": "Jinyang23",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 4
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.01154",
      "authors": [
        {
          "_id": "67a4609af2e553c1d0da914d",
          "name": "Yu-Ling Hsu",
          "hidden": false
        },
        {
          "_id": "67a4609af2e553c1d0da914e",
          "name": "Hsuan Su",
          "hidden": false
        },
        {
          "_id": "67a4609af2e553c1d0da914f",
          "name": "Shang-Tse Chen",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-03T08:44:24.000Z",
      "title": "Universalプロンプトを用いたジェイルブレイク",
      "summary": "大語言モデル（LLMs）は近年において急速な進歩を遂げ、多様なアプリケーションに革命的な影響を与え、便利性と生産性を大幅に向上させています。しかし、その評価的な能力に伴い、倫理的な懸念と新しい攻撃タイプ、例えばジャイルブレイク（jailbreaking）などが現れています。プロンプト技術は主に個別の場合に対して対抗的な入力を最適化することを焦点とし、大規模なデータセットに対して対応する際に計算コストが高まります。一方、より一般的な設定で、普遍的な攻撃者を訓練し、見ぬタスクにも対応できるような研究は少なく、これを調査していません。本論文では、普遍的なプロンプトを用いてLLMsをジャイルブレイクするためのプロンプト基づきの方法を紹介します。これを防御のために応用した方法をDUMPとしています。実験結果によると、我々の普遍的なプロンプトを最適化する方法は、既存の技術よりも優れていることが示されています。",
      "upvotes": 3,
      "discussionId": "67a4609bf2e553c1d0da9181"
    },
    "publishedAt": "2025-02-06T02:11:41.374Z",
    "title": "Jailbreaking with Universal Multi-Prompts",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01154.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "608abf1272b50b02c4b02865",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1619708309549-608abf1272b50b02c4b02865.jpeg",
      "fullname": "Hsuan Su",
      "name": "jacksukk",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.01105",
      "authors": [
        {
          "_id": "67a45c85e73ad243c0b9529e",
          "name": "Yiren Song",
          "hidden": false
        },
        {
          "_id": "67a45c85e73ad243c0b9529f",
          "name": "Danze Chen",
          "hidden": false
        },
        {
          "_id": "67a45c85e73ad243c0b952a0",
          "user": {
            "_id": "63a55320ce5763e06f78519c",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1671779060549-noauth.jpeg",
            "isPro": false,
            "fullname": "Mike Shou",
            "user": "mikeshou",
            "type": "user"
          },
          "name": "Mike Zheng Shou",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-02-06T06:54:02.195Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-03T06:49:58.000Z",
      "title": "LayerTracer: 認知対応ライヤー構造のSVG合成をディフュージョンとTransformerによって実現",
      "summary": "コンピューターによる層次的SVGの生成は、現在の方法がシンプル化されすぎた単一層の出力または最適化による形状の冗須性に傾向しているため、難しいといわれています。我々は、新しい順序的デザイン操作データセットからデザイナーの層次的SVGの作成プロセスを学習することでこの隙を埋めるためにLayerTracerを提案します。このフレームワークは、ディフュージョントランザフォーマーを基盤にしています。我々のアプローチは2つのステップから構成されています：最初に、テキスト条件付きのDiTは、人間のデザインワークフローを模倣するために多段階のレスターゼイズ化された構造計画書を生成します。次に、レイヤーごとのベクトル化とパス削減を行い、クリーンな可編集可能なSVGを生成します。画像のベクトル化において、我々は、参照画像を潜在トークンにエンコードし、構造的な整備性を保ちながら階層的な再構築をガイドする条件付きディフュージョン機構を導入します。拡散的な実験は、最適化ベースとニューラルベース線形に対して生成品質と可編集性の向上を示し、AIが生成したベクトルを専門家のデザイン認知と一致させることができることを証明しました。",
      "upvotes": 3,
      "discussionId": "67a45c8ae73ad243c0b953ea"
    },
    "publishedAt": "2025-02-06T01:55:37.207Z",
    "title": "LayerTracer: Cognitive-Aligned Layered SVG Synthesis via Diffusion Transformer",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01105.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64311a95034ecbefddd141ef",
      "avatarUrl": "/avatars/b6dc5ca373bedbaa368208517954c375.svg",
      "fullname": "Yiren Song",
      "name": "yiren98",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.01618",
      "authors": [
        {
          "_id": "67a438d26bb8caaab06f5a5e",
          "user": {
            "_id": "64c2abe8c43875b438efef25",
            "avatarUrl": "/avatars/6efda081f52cf56db2d29a5ec05cb557.svg",
            "isPro": false,
            "fullname": "isha",
            "user": "ishapuri-mit",
            "type": "user"
          },
          "name": "Isha Puri",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-02-06T04:21:39.202Z",
          "hidden": false
        },
        {
          "_id": "67a438d26bb8caaab06f5a5f",
          "name": "Shivchander Sudalairaj",
          "hidden": false
        },
        {
          "_id": "67a438d26bb8caaab06f5a60",
          "name": "Guangxuan Xu",
          "hidden": false
        },
        {
          "_id": "67a438d26bb8caaab06f5a61",
          "name": "Kai Xu",
          "hidden": false
        },
        {
          "_id": "67a438d26bb8caaab06f5a62",
          "name": "Akash Srivastava",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-03T18:50:50.000Z",
      "title": "LLMの推論時スケーリングにおける粒子ベースモンテカルロ法を用いた確率推論手法",
      "summary": "大語言モデル（LLMs）は、モデルサイズとデータの拡大により顕著な性能向上を達成しました。しかし、最近の証拠から、これらのアプローチによる効果が減少することが明らかになり、推論時間の計算量を拡大することを促しています。現在の推論時間拡大手法は、通常報酬モデルを用いて、タスクを探索問題として扱い、報酬モデルの近似誤差による報酬ハッキングに脆弱なことがあります。本論文では、推論時間拡大を確率論的推論タスクとし、近似可能性を用いた状態空間モデルの状態分布の通常集合を探索するサンプリングベースの手法を活用します。これにより、モデルのモードを直接最適化しないようにします。本論文では、このタスクに粒子ベースのモンテカルロ法を適用し、新しい推論時間拡大アプローチを提案します。実験評価により、決定論的探索と比較して、多様な難しい数学的論理タスクで4-16倍の拡大率を示しました。本アプローチを用いて、Qwen2.5-Math-1.5B-Instructは4回のロードアウトでGPT-4oの精度を超え、Qwen2.5-Math-7B-Instructは32回のロードアウトでo1レベルの精度を達成しました。本論文は、推論時間拡大の効果的な方法を提供し、確率論的推論の豊富な文献とLLMsの推論時間拡大との連携を通じて、将来の研究でより強固なアルゴリズムの開発に貢献します。コードと追加情報は、https://probabilistic-inference-scaling.github.ioに提供されています。",
      "upvotes": 3,
      "discussionId": "67a438d36bb8caaab06f5a87"
    },
    "publishedAt": "2025-02-05T23:23:08.428Z",
    "title": "A Probabilistic Inference Approach to Inference-Time Scaling of LLMs using Particle-Based Monte Carlo Methods",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/648b3f3208c4a9d807a90a99/gwgJD14Bd0fdz7xpcHdHe.mp4",
      "https://cdn-uploads.huggingface.co/production/uploads/648b3f3208c4a9d807a90a99/KHcaqxZL3wiloAm7x-7nA.mp4"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01618.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "648b3f3208c4a9d807a90a99",
      "avatarUrl": "/avatars/03634b4e7f8afe9b589a2d7370e29960.svg",
      "fullname": "Akash Srivastava",
      "name": "akashsri",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 8
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.03275",
      "authors": [
        {
          "_id": "67a448b69ca42c642a723a7d",
          "name": "DiJia Su",
          "hidden": false
        },
        {
          "_id": "67a448b69ca42c642a723a7e",
          "name": "Hanlin Zhu",
          "hidden": false
        },
        {
          "_id": "67a448b69ca42c642a723a7f",
          "name": "Yingchen Xu",
          "hidden": false
        },
        {
          "_id": "67a448b69ca42c642a723a80",
          "name": "Jiantao Jiao",
          "hidden": false
        },
        {
          "_id": "67a448b69ca42c642a723a81",
          "name": "Yuandong Tian",
          "hidden": false
        },
        {
          "_id": "67a448b69ca42c642a723a82",
          "name": "Qinqing Zheng",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-05T15:33:00.000Z",
      "title": "トークン組み合わせ：潜在トークンとテキストトークンの混ぜ合わせによる言語モデルの理由論理の改善",
      "summary": "大語言モデル（LLMs）は、chain-of-thought（CoT）データにチューニングされた場合、ステップごとの思いつきプロセスが明記しているようになり、理由論理や計画に特別に優れています。しかし、これは、許多の単語が文字の連貫性に対しては核心的な理由論理情報に対して貢献し、これらの入力の処理は複雑な計算リソースを必要とします。本稿では、理由論理プロセスのハイブリッド表現を提案し、VQ-VAEによって生成される潜在的な離散トークンを使用して、最初の理由論理ステップを一部抽象化し、理由論理プロセスの長さを大幅に減らすことを目的としています。潜在的なトレース抽象化の使用を2つのシナリオで検討します：1）Keys-Finding Maze問題のモデルのスタートからの訓練、2）このハイブリッドデータに対するLLMsの微調節、これらは両方論理的および数学的理由論理問題を含む。効果的な学習を促進するために、潜在的なトークンと文脈トークンをランダムに混ぜる簡単な訓練手順を導入し、新しい潜在的なトークンに対して高速に適応することを可能にします。我々のアプローチは、様々なベンチマークでベースラインメソッドを一致的に超えています。",
      "upvotes": 2,
      "discussionId": "67a448b89ca42c642a723ac6"
    },
    "publishedAt": "2025-02-06T00:29:44.686Z",
    "title": "Token Assorted: Mixing Latent and Text Tokens for Improved Language Model Reasoning",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.03275.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5956
    },
    "isAuthorParticipating": false
  }
]