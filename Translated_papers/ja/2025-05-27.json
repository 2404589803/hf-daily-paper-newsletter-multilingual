[
  {
    "paper": {
      "id": "2505.19147",
      "authors": [
        {
          "_id": "68353258d005e45149d2d384",
          "user": {
            "_id": "66a0caa1a7a6ed88ad1c0ddf",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/66a0caa1a7a6ed88ad1c0ddf/WoOP24-ruuHy4ryNhRp0D.jpeg",
            "isPro": false,
            "fullname": "Xuyang Liu",
            "user": "xuyang-liu16",
            "type": "user"
          },
          "name": "Xuyang Liu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T08:23:05.932Z",
          "hidden": false
        },
        {
          "_id": "68353258d005e45149d2d385",
          "user": {
            "_id": "653b8c3e97a4d71d950e2f20",
            "avatarUrl": "/avatars/b68880022e14556d0be58c69615db3be.svg",
            "isPro": false,
            "fullname": "Zichen Wen",
            "user": "zichenwen",
            "type": "user"
          },
          "name": "Zichen Wen",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T07:50:45.710Z",
          "hidden": false
        },
        {
          "_id": "68353258d005e45149d2d386",
          "user": {
            "_id": "66968099c952e09a4cb29f78",
            "avatarUrl": "/avatars/bd3a361fe5315e26e9ae328071704eed.svg",
            "isPro": false,
            "fullname": "Wang",
            "user": "Steven-Shaobo",
            "type": "user"
          },
          "name": "Shaobo Wang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T07:50:41.853Z",
          "hidden": false
        },
        {
          "_id": "68353258d005e45149d2d387",
          "user": {
            "_id": "652f8642338c761caf474169",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/mq5jjqqNaFxVboWGDEocJ.jpeg",
            "isPro": false,
            "fullname": "Junjie Chen",
            "user": "coderchen01",
            "type": "user"
          },
          "name": "Junjie Chen",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T07:50:48.148Z",
          "hidden": false
        },
        {
          "_id": "68353258d005e45149d2d388",
          "user": {
            "_id": "679f280ffb07d74f084520b6",
            "avatarUrl": "/avatars/b378000f68c7faf8d4fee8074dd2db5b.svg",
            "isPro": false,
            "fullname": "Zhishan Tao",
            "user": "Pppeach33",
            "type": "user"
          },
          "name": "Zhishan Tao",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T07:50:43.758Z",
          "hidden": false
        },
        {
          "_id": "68353258d005e45149d2d389",
          "name": "Yubo Wang",
          "hidden": false
        },
        {
          "_id": "68353258d005e45149d2d38a",
          "user": {
            "_id": "64abcbfde144ba0eb9bb8419",
            "avatarUrl": "/avatars/6ccea0e755bad384aaabd5c455bd962e.svg",
            "isPro": false,
            "fullname": "Xiangqi Jin",
            "user": "Lueci4er",
            "type": "user"
          },
          "name": "Xiangqi Jin",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-05-27T08:21:21.961Z",
          "hidden": false
        },
        {
          "_id": "68353258d005e45149d2d38b",
          "name": "Chang Zou",
          "hidden": false
        },
        {
          "_id": "68353258d005e45149d2d38c",
          "name": "Yiyu Wang",
          "hidden": false
        },
        {
          "_id": "68353258d005e45149d2d38d",
          "name": "Chenfei Liao",
          "hidden": false
        },
        {
          "_id": "68353258d005e45149d2d38e",
          "name": "Xu Zheng",
          "hidden": false
        },
        {
          "_id": "68353258d005e45149d2d38f",
          "name": "Honggang Chen",
          "hidden": false
        },
        {
          "_id": "68353258d005e45149d2d390",
          "name": "Weijia Li",
          "hidden": false
        },
        {
          "_id": "68353258d005e45149d2d391",
          "name": "Xuming Hu",
          "hidden": false
        },
        {
          "_id": "68353258d005e45149d2d392",
          "user": {
            "_id": "63f9fca8d4349b157a109eec",
            "avatarUrl": "/avatars/fa1f2ae7972d7cde99dab178136ccbb0.svg",
            "isPro": false,
            "fullname": "Conghui He",
            "user": "conghui",
            "type": "user"
          },
          "name": "Conghui He",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-05-27T08:22:15.329Z",
          "hidden": false
        },
        {
          "_id": "68353258d005e45149d2d393",
          "user": {
            "_id": "642ec9831d1737803dc1c30a",
            "avatarUrl": "/avatars/c9ded838bad09004c15a27200e66a108.svg",
            "isPro": false,
            "fullname": "linfeng zhang",
            "user": "linfengZ",
            "type": "user"
          },
          "name": "Linfeng Zhang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-05-27T08:22:07.787Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-25T13:51:17.000Z",
      "submittedOnDailyAt": "2025-05-27T02:06:05.849Z",
      "title": "AIの効率化をモデルセンタリックからデータセンタリックの圧縮に移し替える",
      "submittedOnDailyBy": {
        "_id": "653b8c3e97a4d71d950e2f20",
        "avatarUrl": "/avatars/b68880022e14556d0be58c69615db3be.svg",
        "isPro": false,
        "fullname": "Zichen Wen",
        "user": "zichenwen",
        "type": "user"
      },
      "summary": "大語言モデル（LLMs）と多モーダル大語言モデル（MLLMs）の急速な進歩は、モデルセンタリックスケーリングによるパラメータ数の増加から始まり、数億から数百億に達し、性能向上を駆動していました。しかし、モデルサイズによるハードウェアの制限に近づいているにつれ、主な計算バッファーは、長文脈の自動注意の二次コストに変換し、超長文脈、高解像度画像、長続きのビデオにより駆動されています。この立場論文では、効率的なAIの研究の焦点がモデルセンタリック圧縮からデータセンタリック圧縮へと変換していることを主張します。トークン圧縮を新たな前鋒とし、モデルのトークン数の減少によりAIの効率を向上させることを主張します。詳細な分析を通じて、まず、長文脈AIの最近の進展を様々な領域で検討し、現存するモデルの効率化戦略の統一的な数学的フレームワークを構築し、トークン圧縮が長文脈オーバーヘッドを解決するための重要なパラダイムの変換を示します。次に、トークン圧縮の研究の状況をシステマティックに調査し、その基本的な利益と多様なシナリオでの誘奪的な優れた点を分析します。また、トークン圧縮研究の現在の課題に深い分析を提供し、有望な将来の方向を説明します。最終的に、我々の仕事はAIの効率性について新しい視点を提供し、現存する研究を合成し、AIコミュニティの進歩における長文脈長の課題を解決するための創新の開発を促進しようとします。",
      "upvotes": 75,
      "discussionId": "68353259d005e45149d2d3c0",
      "projectPage": "https://github.com/xuyang-liu16/Awesome-Token-level-Model-Compression",
      "githubRepo": "https://github.com/xuyang-liu16/Awesome-Token-level-Model-Compression",
      "ai_summary": "The focus in AI research is shifting from model-centric to data-centric compression, with token compression identified as key to improving efficiency in handling long-context scenarios.",
      "ai_keywords": [
        "large language models",
        "multi-modal LLMs",
        "self-attention",
        "token compression",
        "long-context AI",
        "mathematical framework",
        "model efficiency",
        "long-context overhead",
        "current challenges",
        "future directions"
      ]
    },
    "publishedAt": "2025-05-25T09:51:17.000Z",
    "title": "Shifting AI Efficiency From Model-Centric to Data-Centric Compression",
    "summary": "The rapid advancement of large language models (LLMs) and multi-modal LLMs\n(MLLMs) has historically relied on model-centric scaling through increasing\nparameter counts from millions to hundreds of billions to drive performance\ngains. However, as we approach hardware limits on model size, the dominant\ncomputational bottleneck has fundamentally shifted to the quadratic cost of\nself-attention over long token sequences, now driven by ultra-long text\ncontexts, high-resolution images, and extended videos. In this position paper,\nwe argue that the focus of research for efficient AI is shifting from\nmodel-centric compression to data-centric compression. We position token\ncompression as the new frontier, which improves AI efficiency via reducing the\nnumber of tokens during model training or inference. Through comprehensive\nanalysis, we first examine recent developments in long-context AI across\nvarious domains and establish a unified mathematical framework for existing\nmodel efficiency strategies, demonstrating why token compression represents a\ncrucial paradigm shift in addressing long-context overhead. Subsequently, we\nsystematically review the research landscape of token compression, analyzing\nits fundamental benefits and identifying its compelling advantages across\ndiverse scenarios. Furthermore, we provide an in-depth analysis of current\nchallenges in token compression research and outline promising future\ndirections. Ultimately, our work aims to offer a fresh perspective on AI\nefficiency, synthesize existing research, and catalyze innovative developments\nto address the challenges that increasing context lengths pose to the AI\ncommunity's advancement.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.19147.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "653b8c3e97a4d71d950e2f20",
      "avatarUrl": "/avatars/b68880022e14556d0be58c69615db3be.svg",
      "fullname": "Zichen Wen",
      "name": "zichenwen",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 3
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.19457",
      "authors": [
        {
          "_id": "683536ec70d215849adfc236",
          "user": {
            "_id": "6440f70f1a80f6d83cadfd16",
            "avatarUrl": "/avatars/04790922837dac81747e80bd0ee0a1cf.svg",
            "isPro": false,
            "fullname": "luguilong",
            "user": "guilong",
            "type": "user"
          },
          "name": "Guilong Lu",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-05-27T08:23:29.797Z",
          "hidden": false
        },
        {
          "_id": "683536ec70d215849adfc237",
          "user": {
            "_id": "672b138db4215fd3888e0a8f",
            "avatarUrl": "/avatars/e90fe671a1db66401db88429fae9a763.svg",
            "isPro": false,
            "fullname": "guo",
            "user": "xuntao",
            "type": "user"
          },
          "name": "Xuntao Guo",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-05-27T08:23:39.616Z",
          "hidden": false
        },
        {
          "_id": "683536ec70d215849adfc238",
          "user": {
            "_id": "6555df426947208b7741b637",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6555df426947208b7741b637/b7ply-HyaPKXrPvRNh21K.jpeg",
            "isPro": false,
            "fullname": "Rongjunchen Zhang",
            "user": "Tinker250",
            "type": "user"
          },
          "name": "Rongjunchen Zhang",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-05-27T03:52:17.018Z",
          "hidden": false
        },
        {
          "_id": "683536ec70d215849adfc239",
          "user": {
            "_id": "648add6aff6123185eb185a8",
            "avatarUrl": "/avatars/e37dfa680c1bb86c721165f03eb79e97.svg",
            "isPro": false,
            "fullname": "WNQzhu",
            "user": "Qlisp",
            "type": "user"
          },
          "name": "Wenqiao Zhu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T07:49:28.216Z",
          "hidden": false
        },
        {
          "_id": "683536ec70d215849adfc23a",
          "name": "Ji Liu",
          "hidden": false
        }
      ],
      "mediaUrls": [
        "https://cdn-uploads.huggingface.co/production/uploads/6555df426947208b7741b637/48jI0LlYjRwO4-0kHRV0V.png",
        "https://cdn-uploads.huggingface.co/production/uploads/6555df426947208b7741b637/atuM30TNh72kJtm8zGxoc.png"
      ],
      "publishedAt": "2025-05-26T03:23:02.000Z",
      "submittedOnDailyAt": "2025-05-27T02:28:08.336Z",
      "title": "BizFinBench: 企業ドリブンドの実世界の財務ベンチャーマークでLLMの評価",
      "submittedOnDailyBy": {
        "_id": "6555df426947208b7741b637",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6555df426947208b7741b637/b7ply-HyaPKXrPvRNh21K.jpeg",
        "isPro": false,
        "fullname": "Rongjunchen Zhang",
        "user": "Tinker250",
        "type": "user"
      },
      "summary": "大語言モデルは一般的なタスクで優れていますが、論理の重い、精度の重要な領域での信頼性の評価は難しいです。これに対処し、私たちは、実世界的な金融アプリケーションでLLMsを評価するための最初のベンチマーク、BizFinBenchを紹介します。BizFinBenchは、数値計算、理由、情報抽出、予測認識、知識ベースの質問回答の5つの次元をまとめ、9つの細かいカテゴリに分類された6,781件のよく注釈されたクエリを構成しています。ベンチマークは主観的と客観的メトリックを含みます。また、IteraJudgeという新しいLLM評価方法を紹介し、客観的メトリックでのLLMsの評価時にバイアスを減らすことができます。25つのモデルを評価し、それぞれのプロプライエーションやオープンソースシステムを含みます。拡大の実験は、すべてのタスクでモデルが優れているものがあることを示します。評価は、明確な能力パターンを示します：数値計算では、Claude-3.5-Sonnet（63.18）とDeepSeek-R1（64.04）が先頭ですが、Qwen2.5-VL-3B（15.92）は显著に落ちています。理由では、プロプライエーションモデルが優れています（ChatGPT-o3: 83.58, Gemini-2.0-Flash: 81.15）、オープンソースモデルは19.49点程度落ちています。情報抽出では、性能の幅が最大で、DeepSeek-R1は71.46で、Qwen3-1.7Bは11.23です。予測認識では、性能の変化は最小で、最高のモデルは39.16から50.00までです。現在のLLMsは、例行的な金融クエリを妥当に処理しますが、複雑なスキーマによる跨概念の理由を必要とする場合では困難になります。BizFinBenchは、将来の研究に向けて厳格な、ビジネスに合わせたベンチマークを提供します。コードとデータセットは、https://github.com/HiThink-Research/BizFinBenchで利用可能です。",
      "upvotes": 45,
      "discussionId": "683536f170d215849adfc35e",
      "projectPage": "https://hithink-research.github.io/BizFinBench/",
      "githubRepo": "https://github.com/HiThink-Research/BizFinBench",
      "ai_summary": "BizFinBench is a benchmark for evaluating large language models in financial applications, revealing distinct performance patterns across various tasks.",
      "ai_keywords": [
        "large language models",
        "BizFinBench",
        "numerical calculation",
        "reasoning",
        "information extraction",
        "prediction recognition",
        "knowledge-based question answering",
        "IteraJudge",
        "Claude-3.5-Sonnet",
        "DeepSeek-R1",
        "Qwen2.5-VL-3B",
        "ChatGPT-o3",
        "Gemini-2.0-Flash",
        "Qwen3-1.7B"
      ]
    },
    "publishedAt": "2025-05-25T23:23:02.000Z",
    "title": "BizFinBench: A Business-Driven Real-World Financial Benchmark for\n  Evaluating LLMs",
    "summary": "Large language models excel in general tasks, yet assessing their reliability\nin logic-heavy, precision-critical domains like finance, law, and healthcare\nremains challenging. To address this, we introduce BizFinBench, the first\nbenchmark specifically designed to evaluate LLMs in real-world financial\napplications. BizFinBench consists of 6,781 well-annotated queries in Chinese,\nspanning five dimensions: numerical calculation, reasoning, information\nextraction, prediction recognition, and knowledge-based question answering,\ngrouped into nine fine-grained categories. The benchmark includes both\nobjective and subjective metrics. We also introduce IteraJudge, a novel LLM\nevaluation method that reduces bias when LLMs serve as evaluators in objective\nmetrics. We benchmark 25 models, including both proprietary and open-source\nsystems. Extensive experiments show that no model dominates across all tasks.\nOur evaluation reveals distinct capability patterns: (1) In Numerical\nCalculation, Claude-3.5-Sonnet (63.18) and DeepSeek-R1 (64.04) lead, while\nsmaller models like Qwen2.5-VL-3B (15.92) lag significantly; (2) In Reasoning,\nproprietary models dominate (ChatGPT-o3: 83.58, Gemini-2.0-Flash: 81.15), with\nopen-source models trailing by up to 19.49 points; (3) In Information\nExtraction, the performance spread is the largest, with DeepSeek-R1 scoring\n71.46, while Qwen3-1.7B scores 11.23; (4) In Prediction Recognition,\nperformance variance is minimal, with top models scoring between 39.16 and\n50.00. We find that while current LLMs handle routine finance queries\ncompetently, they struggle with complex scenarios requiring cross-concept\nreasoning. BizFinBench offers a rigorous, business-aligned benchmark for future\nresearch. The code and dataset are available at\nhttps://github.com/HiThink-Research/BizFinBench.",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/6555df426947208b7741b637/48jI0LlYjRwO4-0kHRV0V.png",
      "https://cdn-uploads.huggingface.co/production/uploads/6555df426947208b7741b637/atuM30TNh72kJtm8zGxoc.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.19457.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6555df426947208b7741b637",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6555df426947208b7741b637/b7ply-HyaPKXrPvRNh21K.jpeg",
      "fullname": "Rongjunchen Zhang",
      "name": "Tinker250",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.17894",
      "authors": [
        {
          "_id": "683577db7733c0f27e945847",
          "user": {
            "_id": "65276c7911a8a521c91bc10f",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65276c7911a8a521c91bc10f/39dbuUtqQTJERTJ_WkxSh.jpeg",
            "isPro": false,
            "fullname": "Khalil Hennara",
            "user": "Hennara",
            "type": "user"
          },
          "name": "Khalil Hennara",
          "status": "extracted_confirmed",
          "statusLastChangedAt": "2025-05-27T09:23:49.563Z",
          "hidden": false
        },
        {
          "_id": "683577db7733c0f27e945848",
          "user": {
            "_id": "6496df4b3c64d75523a11973",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6496df4b3c64d75523a11973/I_Qn5-3Czngle-NsGmabO.jpeg",
            "isPro": false,
            "fullname": "Muhammad Hreden",
            "user": "hr99",
            "type": "user"
          },
          "name": "Muhammad Hreden",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T10:03:33.725Z",
          "hidden": false
        },
        {
          "_id": "683577db7733c0f27e945849",
          "user": {
            "_id": "63aa7667769a10efc404fbbc",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63aa7667769a10efc404fbbc/tn8ZxUmTEMS0Gze7_F7JL.jpeg",
            "isPro": false,
            "fullname": "Mohamed Motasim Hamed",
            "user": "Moatasem444",
            "type": "user"
          },
          "name": "Mohamed Motaism Hamed",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-05-27T08:29:16.168Z",
          "hidden": false
        },
        {
          "_id": "683577db7733c0f27e94584a",
          "user": {
            "_id": "65704741e1cfce1764ce652e",
            "avatarUrl": "/avatars/9189aaf417426af4ebe381ed364a6c0e.svg",
            "isPro": false,
            "fullname": "Zeina Aldallal",
            "user": "ZeinaD",
            "type": "user"
          },
          "name": "Zeina Aldallal",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-05-27T08:29:16.168Z",
          "hidden": false
        },
        {
          "_id": "683577db7733c0f27e94584b",
          "name": "Sara Chrouf",
          "hidden": false
        },
        {
          "_id": "683577db7733c0f27e94584c",
          "name": "Safwan AlModhayan",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-23T13:42:21.000Z",
      "submittedOnDailyAt": "2025-05-27T07:07:04.517Z",
      "title": "ムタルジム: 小規模言語モデルを用いた双方向アラビア語-英語翻訳の進歩",
      "submittedOnDailyBy": {
        "_id": "65276c7911a8a521c91bc10f",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65276c7911a8a521c91bc10f/39dbuUtqQTJERTJ_WkxSh.jpeg",
        "isPro": false,
        "fullname": "Khalil Hennara",
        "user": "Hennara",
        "type": "user"
      },
      "summary": "ユニバーサルモデルでは、Mutarjimという小さながったらでも強力な双方向的なアラビア語-英語翻訳用言語モデルを紹介します。大規模なLLMは、自然言語処理タスク、特に機械翻訳において驚異的な進歩を示していますが、より小さなモデルも存在します。このヒントを活用し、Kuwain-1.5Bというアラビア語と英語の両方に適合した言語モデルに基づいてMutarjimを開発しました。Mutarjimは、小さなサイズでも、設定された評価ベンチマークではより大きなモデルを上回ります。これは、最適化された2段階トレーニングアプローチとより高品質なトレーニングコーパスの選択によって実現されました。実験結果から、Mutarjimは20倍以上のモデルよりも類似した性能を示し、計算コストとトレーニング要求を大幅に減少します。また、Tarjama-25という新しいベンチマークを紹介します。これは、現在のアラビア語-英語ベンチマークデータセットの制限を克服するために設計されています。その制限として、ドライブネスの狭い範囲、短い文の長さ、英語のソースバイアスなどがあります。Tarjama-25は、5,000件の専門家のレビューされた文のペアを含み、広い範囲のドライブネスを拡張し、より詳細かつ平衡的な評価フレームワークを提供します。特に、MutarjimはTarjama-25の英語からアラビア語タスクで最先端の性能を達成し、GPT-4o miniやそれよりも大きくて専有のモデルを上回ります。Tarjama-25は、将来の研究やアラビア語-英語翻訳システムの評価の進歩を支援するために公開します。",
      "upvotes": 38,
      "discussionId": "683577dc7733c0f27e94588d",
      "ai_summary": "Mutarjim is a compact Arabic-English translation model that outperforms larger models on established benchmarks and achieves state-of-the-art performance on a new comprehensive Tarjama-25 benchmark.",
      "ai_keywords": [
        "language model",
        "bidirectional Arabic-English translation",
        "LLMs",
        "Kuwain-1.5B",
        "two-phase training",
        "high-quality training corpus",
        "Tarjama-25",
        "domain narrowness",
        "English-source bias",
        "GPT-4"
      ]
    },
    "publishedAt": "2025-05-23T09:42:21.000Z",
    "title": "Mutarjim: Advancing Bidirectional Arabic-English Translation with a\n  Small Language Model",
    "summary": "We introduce Mutarjim, a compact yet powerful language model for\nbidirectional Arabic-English translation. While large-scale LLMs have shown\nimpressive progress in natural language processing tasks, including machine\ntranslation, smaller models. Leveraging this insight, we developed Mutarjim\nbased on Kuwain-1.5B , a language model tailored for both Arabic and English.\nDespite its modest size, Mutarjim outperforms much larger models on several\nestablished benchmarks, achieved through an optimized two-phase training\napproach and a carefully curated, high-quality training corpus.. Experimental\nresults show that Mutarjim rivals models up to 20 times larger while\nsignificantly reducing computational costs and training requirements. We also\nintroduce Tarjama-25, a new benchmark designed to overcome limitations in\nexisting Arabic-English benchmarking datasets, such as domain narrowness, short\nsentence lengths, and English-source bias. Tarjama-25 comprises 5,000\nexpert-reviewed sentence pairs and spans a wide range of domains, offering a\nmore comprehensive and balanced evaluation framework. Notably, Mutarjim\nachieves state-of-the-art performance on the English-to-Arabic task in\nTarjama-25, surpassing even significantly larger and proprietary models like\nGPT-4o mini. We publicly release Tarjama-25 to support future research and\nadvance the evaluation of Arabic-English translation systems.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.17894.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "65276c7911a8a521c91bc10f",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65276c7911a8a521c91bc10f/39dbuUtqQTJERTJ_WkxSh.jpeg",
      "fullname": "Khalil Hennara",
      "name": "Hennara",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 12
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.16348",
      "authors": [
        {
          "_id": "6835365d2925bc8bb23a57c7",
          "user": {
            "_id": "636b529ef796304dd67d139c",
            "avatarUrl": "/avatars/7a64d5095fcb1da558b52ad48177ad76.svg",
            "isPro": false,
            "fullname": "Taeyoon Kwon",
            "user": "Connoriginal",
            "type": "user"
          },
          "name": "Taeyoon Kwon",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T07:50:26.210Z",
          "hidden": false
        },
        {
          "_id": "6835365d2925bc8bb23a57c8",
          "name": "Dongwook Choi",
          "hidden": false
        },
        {
          "_id": "6835365d2925bc8bb23a57c9",
          "name": "Sunghwan Kim",
          "hidden": false
        },
        {
          "_id": "6835365d2925bc8bb23a57ca",
          "name": "Hyojun Kim",
          "hidden": false
        },
        {
          "_id": "6835365d2925bc8bb23a57cb",
          "user": {
            "_id": "6420f4f55bccaa42484496e5",
            "avatarUrl": "/avatars/4996ba26955f8423c946b1ecd3989964.svg",
            "isPro": false,
            "fullname": "Seung Jun Moon",
            "user": "Lune-Blue",
            "type": "user"
          },
          "name": "Seungjun Moon",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-05-27T08:24:40.306Z",
          "hidden": false
        },
        {
          "_id": "6835365d2925bc8bb23a57cc",
          "user": {
            "_id": "64b72a408ba7d6c922c73054",
            "avatarUrl": "/avatars/6d9797430bc36f05fb950b84aa6a9374.svg",
            "isPro": false,
            "fullname": "Beong Woo Kwak",
            "user": "bwookwak",
            "type": "user"
          },
          "name": "Beong-woo Kwak",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-05-27T08:24:46.911Z",
          "hidden": false
        },
        {
          "_id": "6835365d2925bc8bb23a57cd",
          "user": {
            "_id": "658a57b4126b8d7eae07b983",
            "avatarUrl": "/avatars/8d908cb3da697793564d24206a333782.svg",
            "isPro": false,
            "fullname": "Kuan-Hao Huang",
            "user": "ej0cl6",
            "type": "user"
          },
          "name": "Kuan-Hao Huang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-05-27T08:24:53.502Z",
          "hidden": false
        },
        {
          "_id": "6835365d2925bc8bb23a57ce",
          "user": {
            "_id": "682e91865fa8c5df85b3d8e5",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/XWTfZoOjCdMnqaFEBBYWe.png",
            "isPro": false,
            "fullname": "Jinyoung Yeo",
            "user": "jinyeo",
            "type": "user"
          },
          "name": "Jinyoung Yeo",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-05-27T08:25:01.610Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-22T08:00:10.000Z",
      "submittedOnDailyAt": "2025-05-27T02:20:10.067Z",
      "title": "Embodied Agents は、個人化されたアシスタンスを提供するために、メモリの利用を検討しています。",
      "submittedOnDailyBy": {
        "_id": "636b529ef796304dd67d139c",
        "avatarUrl": "/avatars/7a64d5095fcb1da558b52ad48177ad76.svg",
        "isPro": false,
        "fullname": "Taeyoon Kwon",
        "user": "Connoriginal",
        "type": "user"
      },
      "summary": "大語言モデル（LLMs）を支える具象化アグェントは、家裏の物件の並び替えタスクで強い性能を示しています。しかし、これらのタスクは主に簡単な指示との一回だけの相互作用を焦点にしていますが、これは実際にユーザーに意味のある助けを提供する課題を正確に反映していません。個性化された助けを提供するために、具象化アグェントは、先の相互作用の履歴を活用して物理世界にユーザーが割り当てた独自の意味論を理解する必要があります。しかし、具象化アグェントがメモリーを利用して個性化された助けを提供する効果性は、大きく調査されていません。この空間を補うために、MEMENTOという個性化された具象化アグェント評価フレームワークを紹介します。このフレームワークは、メモリーの利用による効果を評価するための二段階のメモリー評価プロセスデザインを採用しています。このプロセスは、物件の並び替えタスクでの個性化キャンパスの理解を評価するために、目標の理解の役割を焦点にしています：1）個人的な意味（物件の意味論）に基づいて目標物件を特定する能力と、2）ユーザーのパターンから物件の位置配置を推論する能力です。LLMsの様々なタイプの実験により、メモリーの利用における显著な制限が明らかになりました。特に、GPT-4oのような先進モデルも、複数のメモリーを参照する必要がある場合には30.5%の性能低下を見落とします。これらの発見と詳細な分析やケーススタディ、将来の研究における個性化された具象化アグェントの開発において有價値なヒントを提供します。プロジェクトウェブサイト：https://connoriginal.github.io/MEMENTO",
      "upvotes": 38,
      "discussionId": "683536612925bc8bb23a58e1",
      "projectPage": "https://connoriginal.github.io/MEMENTO/",
      "githubRepo": "https://github.com/Connoriginal/MEMENTO",
      "ai_summary": "MEMENTO evaluates personalized memory utilization in embodied agents, revealing limitations in understanding user semantics and routines.",
      "ai_keywords": [
        "embodied agents",
        "large language models (LLMs)",
        "object rearrangement tasks",
        "user semantics",
        "prior interaction history",
        "memory utilization",
        "personalized assistance",
        "goal interpretation",
        "object semantics",
        "user patterns"
      ]
    },
    "publishedAt": "2025-05-22T04:00:10.000Z",
    "title": "Embodied Agents Meet Personalization: Exploring Memory Utilization for\n  Personalized Assistance",
    "summary": "Embodied agents empowered by large language models (LLMs) have shown strong\nperformance in household object rearrangement tasks. However, these tasks\nprimarily focus on single-turn interactions with simplified instructions, which\ndo not truly reflect the challenges of providing meaningful assistance to\nusers. To provide personalized assistance, embodied agents must understand the\nunique semantics that users assign to the physical world (e.g., favorite cup,\nbreakfast routine) by leveraging prior interaction history to interpret\ndynamic, real-world instructions. Yet, the effectiveness of embodied agents in\nutilizing memory for personalized assistance remains largely underexplored. To\naddress this gap, we present MEMENTO, a personalized embodied agent evaluation\nframework designed to comprehensively assess memory utilization capabilities to\nprovide personalized assistance. Our framework consists of a two-stage memory\nevaluation process design that enables quantifying the impact of memory\nutilization on task performance. This process enables the evaluation of agents'\nunderstanding of personalized knowledge in object rearrangement tasks by\nfocusing on its role in goal interpretation: (1) the ability to identify target\nobjects based on personal meaning (object semantics), and (2) the ability to\ninfer object-location configurations from consistent user patterns, such as\nroutines (user patterns). Our experiments across various LLMs reveal\nsignificant limitations in memory utilization, with even frontier models like\nGPT-4o experiencing a 30.5% performance drop when required to reference\nmultiple memories, particularly in tasks involving user patterns. These\nfindings, along with our detailed analyses and case studies, provide valuable\ninsights for future research in developing more effective personalized embodied\nagents. Project website: https://connoriginal.github.io/MEMENTO",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.16348.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "636b529ef796304dd67d139c",
      "avatarUrl": "/avatars/7a64d5095fcb1da558b52ad48177ad76.svg",
      "fullname": "Taeyoon Kwon",
      "name": "Connoriginal",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.20258",
      "authors": [
        {
          "_id": "68352b5803548b71276c1a6f",
          "user": {
            "_id": "64f2a228f40f35cfa3e8edfd",
            "avatarUrl": "/avatars/0671cb4df8f3d3bcaaa95aad3d0a46c2.svg",
            "isPro": false,
            "fullname": "Siye Wu",
            "user": "Siye01",
            "type": "user"
          },
          "name": "Siye Wu",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-05-27T08:25:16.627Z",
          "hidden": false
        },
        {
          "_id": "68352b5803548b71276c1a70",
          "user": {
            "_id": "62d65139667051e0a29bffe7",
            "avatarUrl": "/avatars/0252aa2bcd4cf1c8e4b87e5f164b6da5.svg",
            "isPro": false,
            "fullname": "Jian Xie",
            "user": "hsaest",
            "type": "user"
          },
          "name": "Jian Xie",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T07:50:53.006Z",
          "hidden": false
        },
        {
          "_id": "68352b5803548b71276c1a71",
          "user": {
            "_id": "63e8b792ca4fc7d30de6975b",
            "avatarUrl": "/avatars/57237f54d61d479df15209497a3f531e.svg",
            "isPro": false,
            "fullname": "Yikai Zhang",
            "user": "Arist12",
            "type": "user"
          },
          "name": "Yikai Zhang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-05-27T08:25:41.797Z",
          "hidden": false
        },
        {
          "_id": "68352b5803548b71276c1a72",
          "name": "Aili Chen",
          "hidden": false
        },
        {
          "_id": "68352b5803548b71276c1a73",
          "name": "Kai Zhang",
          "hidden": false
        },
        {
          "_id": "68352b5803548b71276c1a74",
          "name": "Yu Su",
          "hidden": false
        },
        {
          "_id": "68352b5803548b71276c1a75",
          "name": "Yanghua Xiao",
          "hidden": false
        }
      ],
      "mediaUrls": [
        "https://cdn-uploads.huggingface.co/production/uploads/62d65139667051e0a29bffe7/W2uaapL3hKBPi-TA-KDef.mp4"
      ],
      "publishedAt": "2025-05-26T17:38:50.000Z",
      "submittedOnDailyAt": "2025-05-27T01:44:27.885Z",
      "title": "ARM: アダプティブ・リジェクション・モデル",
      "submittedOnDailyBy": {
        "_id": "62d65139667051e0a29bffe7",
        "avatarUrl": "/avatars/0252aa2bcd4cf1c8e4b87e5f164b6da5.svg",
        "isPro": false,
        "fullname": "Jian Xie",
        "user": "hsaest",
        "type": "user"
      },
      "summary": "大型推理モデルは複雑なタスクで強い性能を示しますが、タスクの難易度に応じて理由証明トークンの使用を調整する能力を持っていません。これは「過度説明」問題につながります—過度して必要ない説明—、これは人間の介入でトークンバッジを制御することで軽減されることはありますが、完全な自動軍事インフォメーションの目標と基本的に矛盾します。本論文中では、Adaptive Reasoning Model（ARM）を提案します。ARMは手順ごとに適切な理由証明フォーマットを選択する能力を持っています。これらのフォーマットは、Direct Answer、Short CoT、Codeという3つの効率的なフォーマットと、Long CoTという詳細なフォーマットを含みます。ARMの訓練には、Group Relative Policy Optimization（GRPO）の適応版 Ada-GRPO を導入します。これは傳統的なGRPOのフォーマット崩壊問題を解決します。Ada-GRPO により、ARMはトークンの使用を30%平均で、Long CoTモデルに比べて70%減少し、性能を維持することができます。また、トークン生成の減少により推論エフィシェンスを向上させ、学習速度を2倍にします。ARMは、デフォルトのAdaptive Modeを除き、2つの追加の理由証明モードをサポートします：1）Instruction-Guided Mode、ユーザーが特殊トークンを用いて理由証明フォーマットを明記して指定することができるモードで、バッチのタスクに適したフォーマットが知られている場合は理想的です。2）Consensus-Guided Mode、3つの効率的なフォーマットの出力を統合し、違いがある場合はLong CoTを使用し、トークン使用量が高い場合に優先します。",
      "upvotes": 32,
      "discussionId": "68352b5903548b71276c1a9f",
      "projectPage": "https://team-arm.github.io/arm/",
      "githubRepo": "https://github.com/TEAM-ARM/arm",
      "ai_summary": "Adaptive Reasoning Model (ARM) uses Ada-GRPO to reduce token usage and improve efficiency across different reasoning modes.",
      "ai_keywords": [
        "Adaptive Reasoning Model",
        "ARM",
        "Ada-GRPO",
        "Group Relative Policy Optimization",
        "GRPO",
        "format collapse",
        "token efficiency",
        "inference efficiency",
        "Direct Answer",
        "Short CoT",
        "Code",
        "Long CoT",
        "Adaptive Mode",
        "Instruction-Guided Mode",
        "Consensus-Guided Mode"
      ]
    },
    "publishedAt": "2025-05-26T13:38:50.000Z",
    "title": "ARM: Adaptive Reasoning Model",
    "summary": "While large reasoning models demonstrate strong performance on complex tasks,\nthey lack the ability to adjust reasoning token usage based on task difficulty.\nThis often leads to the \"overthinking\" problem -- excessive and unnecessary\nreasoning -- which, although potentially mitigated by human intervention to\ncontrol the token budget, still fundamentally contradicts the goal of achieving\nfully autonomous AI. In this work, we propose Adaptive Reasoning Model (ARM), a\nreasoning model capable of adaptively selecting appropriate reasoning formats\nbased on the task at hand. These formats include three efficient ones -- Direct\nAnswer, Short CoT, and Code -- as well as a more elaborate format, Long CoT. To\ntrain ARM, we introduce Ada-GRPO, an adaptation of Group Relative Policy\nOptimization (GRPO), which addresses the format collapse issue in traditional\nGRPO. Ada-GRPO enables ARM to achieve high token efficiency, reducing tokens by\nan average of 30%, and up to 70%, while maintaining performance comparable to\nthe model that relies solely on Long CoT. Furthermore, not only does it improve\ninference efficiency through reduced token generation, but it also brings a 2x\nspeedup in training. In addition to the default Adaptive Mode, ARM supports two\nadditional reasoning modes: 1) Instruction-Guided Mode, which allows users to\nexplicitly specify the reasoning format via special tokens -- ideal when the\nappropriate format is known for a batch of tasks. 2) Consensus-Guided Mode,\nwhich aggregates the outputs of the three efficient formats and resorts to Long\nCoT in case of disagreement, prioritizing performance with higher token usage.",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/62d65139667051e0a29bffe7/W2uaapL3hKBPi-TA-KDef.mp4"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.20258.png",
    "numComments": 3,
    "submittedBy": {
      "_id": "62d65139667051e0a29bffe7",
      "avatarUrl": "/avatars/0252aa2bcd4cf1c8e4b87e5f164b6da5.svg",
      "fullname": "Jian Xie",
      "name": "hsaest",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 9
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.19914",
      "authors": [
        {
          "_id": "68353e41f995630ab88c198b",
          "user": {
            "_id": "606ed1884ffe81d1e03e81e5",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1639375346654-606ed1884ffe81d1e03e81e5.png",
            "isPro": false,
            "fullname": "Jiangjie Chen",
            "user": "jiangjiechen",
            "type": "user"
          },
          "name": "Jiangjie Chen",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T07:49:21.006Z",
          "hidden": false
        },
        {
          "_id": "68353e41f995630ab88c198c",
          "user": {
            "_id": "636b36351340f879a2ec2bb1",
            "avatarUrl": "/avatars/260a1c15f9c14c967125469072020946.svg",
            "isPro": false,
            "fullname": "QianyuHe",
            "user": "Abbey4799",
            "type": "user"
          },
          "name": "Qianyu He",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T07:49:23.290Z",
          "hidden": false
        },
        {
          "_id": "68353e41f995630ab88c198d",
          "name": "Siyu Yuan",
          "hidden": false
        },
        {
          "_id": "68353e41f995630ab88c198e",
          "name": "Aili Chen",
          "hidden": false
        },
        {
          "_id": "68353e41f995630ab88c198f",
          "name": "Zhicheng Cai",
          "hidden": false
        },
        {
          "_id": "68353e41f995630ab88c1990",
          "name": "Weinan Dai",
          "hidden": false
        },
        {
          "_id": "68353e41f995630ab88c1991",
          "name": "Hongli Yu",
          "hidden": false
        },
        {
          "_id": "68353e41f995630ab88c1992",
          "name": "Qiying Yu",
          "hidden": false
        },
        {
          "_id": "68353e41f995630ab88c1993",
          "name": "Xuefeng Li",
          "hidden": false
        },
        {
          "_id": "68353e41f995630ab88c1994",
          "name": "Jiaze Chen",
          "hidden": false
        },
        {
          "_id": "68353e41f995630ab88c1995",
          "name": "Hao Zhou",
          "hidden": false
        },
        {
          "_id": "68353e41f995630ab88c1996",
          "name": "Mingxuan Wang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-26T12:40:31.000Z",
      "submittedOnDailyAt": "2025-05-27T02:57:13.989Z",
      "title": "エニグマタ：大規模言語モデルにおけるロジック推論の拡大における合成的に可確認可能なパズル",
      "submittedOnDailyBy": {
        "_id": "62d62b333bf5e059f7d2b286",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1668513815771-62d62b333bf5e059f7d2b286.jpeg",
        "isPro": false,
        "fullname": "Siyu Yuan",
        "user": "siyuyuan",
        "type": "user"
      },
      "summary": "大語言モデル（LLMs）は、OpenAIのo1とDeepSeekのR1などが、数学やコーディングなどの進歩的な理由論タスクをReinforcement Learning with Verifiable Rewards（RLVR）を用いて優れているが、人間がドメイン知識を持たずに解く謎問題に対しては難しい。私たちは、謎問題の理由論スキルを改善するための最初の詳細なセットを紹介します。これは、7つのカテゴリーの中で36つのタスクを含み、1) 構造体で無限の例を生成でき、制御可能な難易度を持つものと2) ルールベースの検証機関で自動評価を行うものを含む。この生成器・検証機関設計は、スケーラブルな、多タスクRLトレーニング、細かい分析、そして無間断なRLVR統合をサポートします。また、私たちは、厳密なベンチマークとしてEnigmata-Evalを提案し、最適化された多タスクRLVRステラテジーを開発します。私たちが訓練したモデル、Qwen2.5-32B-Enigmataは、謎問題の理由論ベンチマークでo3-mini-highとo1を超え、ARC-AGI（32.8%）、ARC-AGI 2（0.6%）などのベンチマークで統一的です。そして、外ドメインの謎問題ベンチマークおよび数学的な理由論にもより良い一般化が見られます。モデル訓練には、Seed1.5-Thinking（20B活性化パラメータと200B総パラメータ）などの大きなモデルを使用した場合、Enigmataの謎問題データは、AIME（2024-2025）、BeyondAIME、GPQA（Diamond）などの先進的な数学とSTEM理由論タスクの最先端の性能を示し、Enigmataの一般化利益が良く見られます。この研究は、LLMsの理由論の進歩をユニークで制御可能なフレームワークを提供します。この研究のリソースは、https://seed-enigmata.github.ioに見つかります。",
      "upvotes": 26,
      "discussionId": "68353e42f995630ab88c19dc",
      "ai_summary": "Enigmata is a comprehensive suite for improving LLMs in puzzle reasoning through scalable multi-task RL training, leading to better performance on benchmarks and advanced math tasks.",
      "ai_keywords": [
        "Large Language Models",
        "OpenAI's o1",
        "DeepSeek's R1",
        "Reinforcement Learning with Verifiable Rewards",
        "Enigmata",
        "Enigmata-Eval",
        "multi-task RL training",
        "puzzle reasoning",
        "rule-based verifier",
        "ARC-AGI",
        "Qwen2.5-32B-Enigmata",
        "Seed1.5-Thinking",
        "AIME",
        "BeyondAIME",
        "GPQA"
      ]
    },
    "publishedAt": "2025-05-26T08:40:31.000Z",
    "title": "Enigmata: Scaling Logical Reasoning in Large Language Models with\n  Synthetic Verifiable Puzzles",
    "summary": "Large Language Models (LLMs), such as OpenAI's o1 and DeepSeek's R1, excel at\nadvanced reasoning tasks like math and coding via Reinforcement Learning with\nVerifiable Rewards (RLVR), but still struggle with puzzles solvable by humans\nwithout domain knowledge. We introduce Enigmata, the first comprehensive suite\ntailored for improving LLMs with puzzle reasoning skills. It includes 36 tasks\nacross seven categories, each with 1) a generator that produces unlimited\nexamples with controllable difficulty and 2) a rule-based verifier for\nautomatic evaluation. This generator-verifier design supports scalable,\nmulti-task RL training, fine-grained analysis, and seamless RLVR integration.\nWe further propose Enigmata-Eval, a rigorous benchmark, and develop optimized\nmulti-task RLVR strategies. Our trained model, Qwen2.5-32B-Enigmata,\nconsistently surpasses o3-mini-high and o1 on the puzzle reasoning benchmarks\nlike Enigmata-Eval, ARC-AGI (32.8%), and ARC-AGI 2 (0.6%). It also generalizes\nwell to out-of-domain puzzle benchmarks and mathematical reasoning, with little\nmulti-tasking trade-off. When trained on larger models like Seed1.5-Thinking\n(20B activated parameters and 200B total parameters), puzzle data from Enigmata\nfurther boosts SoTA performance on advanced math and STEM reasoning tasks such\nas AIME (2024-2025), BeyondAIME and GPQA (Diamond), showing nice generalization\nbenefits of Enigmata. This work offers a unified, controllable framework for\nadvancing logical reasoning in LLMs. Resources of this work can be found at\nhttps://seed-enigmata.github.io.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.19914.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "62d62b333bf5e059f7d2b286",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1668513815771-62d62b333bf5e059f7d2b286.jpeg",
      "fullname": "Siyu Yuan",
      "name": "siyuyuan",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 4
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2505.19297",
      "authors": [
        {
          "_id": "68354c05f7b44d5d505262c7",
          "user": {
            "_id": "63725a2eacef705233c62876",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63725a2eacef705233c62876/QlRm8oq7O8THzUhATYQlH.jpeg",
            "isPro": false,
            "fullname": "Valerii",
            "user": "sharfikeg",
            "type": "user"
          },
          "name": "Valerii Startsev",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T07:51:23.082Z",
          "hidden": false
        },
        {
          "_id": "68354c05f7b44d5d505262c8",
          "name": "Alexander Ustyuzhanin",
          "hidden": false
        },
        {
          "_id": "68354c05f7b44d5d505262c9",
          "name": "Alexey Kirillov",
          "hidden": false
        },
        {
          "_id": "68354c05f7b44d5d505262ca",
          "name": "Dmitry Baranchuk",
          "hidden": false
        },
        {
          "_id": "68354c05f7b44d5d505262cb",
          "name": "Sergey Kastryulin",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-25T20:08:20.000Z",
      "submittedOnDailyAt": "2025-05-27T07:55:09.983Z",
      "title": "アルケミスト：公開テキストから画像を生成するための生成的な金を作る",
      "submittedOnDailyBy": {
        "_id": "63725a2eacef705233c62876",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63725a2eacef705233c62876/QlRm8oq7O8THzUhATYQlH.jpeg",
        "isPro": false,
        "fullname": "Valerii",
        "user": "sharfikeg",
        "type": "user"
      },
      "summary": "予習学習は、テキストから画像（T2I）モデルに広い世界知識をもたらしますが、これだけで高い美術的質と一致性を達成することは通常では不足します。そのため、観学の微調節（SFT）が進段な精進に必要となりますが、その効果は微調節データセットの質に大きく依存します。現在の公開データセットは、狭い領域（例：アニメや特定のアートスタイル）を目指していることが多いです。高品質で一般的な用途を持つSFTデータセットの作成は重大な課題です。現在のカレーデーション方法は通常高コストであり、真の影響を与えるサンプルを特定することが難しいです。この課題は、公開の一般的な用途のデータセットの不足によりさらに複雑化されています。先鋒のモデルは、大きな、プロプライティドで、記述不足の内部データを主に依存しているため、より広い研究進歩を妨げています。本論文では、高影響力的なトレーニングサンプルの評価器として利用された予習学習ジェネレータモデルを拡張して一般的な用途のSFTデータセットの作成に新しいメソッドを紹介します。この方法をアルケミスト（3,350サンプル）という小さなデータセットを構築し、公開しました。実験は、アルケミストが五つの公開テキストから画像モデルの生成質を大幅に向上させ、多様性とスタイルを保ったことを示しました。また、微調節モデルの重みを公開しました。",
      "upvotes": 26,
      "discussionId": "68354c07f7b44d5d50526322",
      "ai_summary": "A new method using a pre-trained generative model helps construct a high-impact SFT dataset, Alchemist, which improves the generative quality of text-to-image models while maintaining diversity.",
      "ai_keywords": [
        "text-to-image",
        "fine-tuning",
        "pre-trained generative model",
        "general-purpose datasets",
        "aesthetic quality",
        "alignment",
        "curated datasets"
      ]
    },
    "publishedAt": "2025-05-25T16:08:20.000Z",
    "title": "Alchemist: Turning Public Text-to-Image Data into Generative Gold",
    "summary": "Pre-training equips text-to-image (T2I) models with broad world knowledge,\nbut this alone is often insufficient to achieve high aesthetic quality and\nalignment. Consequently, supervised fine-tuning (SFT) is crucial for further\nrefinement. However, its effectiveness highly depends on the quality of the\nfine-tuning dataset. Existing public SFT datasets frequently target narrow\ndomains (e.g., anime or specific art styles), and the creation of high-quality,\ngeneral-purpose SFT datasets remains a significant challenge. Current curation\nmethods are often costly and struggle to identify truly impactful samples. This\nchallenge is further complicated by the scarcity of public general-purpose\ndatasets, as leading models often rely on large, proprietary, and poorly\ndocumented internal data, hindering broader research progress. This paper\nintroduces a novel methodology for creating general-purpose SFT datasets by\nleveraging a pre-trained generative model as an estimator of high-impact\ntraining samples. We apply this methodology to construct and release Alchemist,\na compact (3,350 samples) yet highly effective SFT dataset. Experiments\ndemonstrate that Alchemist substantially improves the generative quality of\nfive public T2I models while preserving diversity and style. Additionally, we\nrelease the fine-tuned models' weights to the public.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.19297.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "63725a2eacef705233c62876",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63725a2eacef705233c62876/QlRm8oq7O8THzUhATYQlH.jpeg",
      "fullname": "Valerii",
      "name": "sharfikeg",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.18545",
      "authors": [
        {
          "_id": "6835217ee759f596d018f72c",
          "user": {
            "_id": "6631fd5961a4305e5610d403",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6631fd5961a4305e5610d403/P1Dtxzn-KIbYDDsiw60nr.jpeg",
            "isPro": true,
            "fullname": "An Vo",
            "user": "anvo25",
            "type": "user"
          },
          "name": "An Vo",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T07:52:08.994Z",
          "hidden": false
        },
        {
          "_id": "6835217ee759f596d018f72d",
          "user": {
            "_id": "6039478ab3ecf716b1a5fd4d",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg",
            "isPro": true,
            "fullname": "taesiri",
            "user": "taesiri",
            "type": "user"
          },
          "name": "Mohammad Reza Taesiri",
          "status": "extracted_confirmed",
          "statusLastChangedAt": "2025-05-27T02:21:46.082Z",
          "hidden": false
        },
        {
          "_id": "6835217ee759f596d018f72e",
          "name": "Daeyoung Kim",
          "hidden": false
        },
        {
          "_id": "6835217ee759f596d018f72f",
          "user": {
            "_id": "60e85b3fcd1cf4e418fff651",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1645625108920-60e85b3fcd1cf4e418fff651.jpeg",
            "isPro": false,
            "fullname": "Anh (Totti) Nguyen",
            "user": "anhng8",
            "type": "user"
          },
          "name": "Anh Totti Nguyen",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-05-27T02:20:46.958Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-24T06:23:52.000Z",
      "submittedOnDailyAt": "2025-05-27T00:50:49.797Z",
      "title": "B-score: ラージュラー言語モデルの偏見検出における応答履歴の使用",
      "submittedOnDailyBy": {
        "_id": "6039478ab3ecf716b1a5fd4d",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg",
        "isPro": true,
        "fullname": "taesiri",
        "user": "taesiri",
        "type": "user"
      },
      "summary": "大語言モデル（LLMs）は、例えば女性に対する偏見や数字7に対する好感を示していることが多い。私たちは、LLMsが同じ質問に対して先ほどの答えを見ていることで偏見を少なく出力できるかを調査した。質問のタイプについて理解しようとして、私たちは9つの主題を拡張し、主観的、ランダム、対象的な3つのタイプの質問によるLLMsを検証した。興味深いことに、LLMsはランダムで無偏見な答えを求める質問に対して、多ターンコンバーションで自らの偏見を「脱偏見」できることを見出した。また、私たちは、主観的、ランダム、Easy、Hardの質問に対する偏見を検出する効果的な新しいメトリックB-scoreを提案した。MMLU、HLE、CSQAでは、B-scoreを活用することで、LLMsの答えの検証精度（即ち、正しい答えを受け入れ、不正な答えを拒否する）が、単一ターンの答えの頻度や言語化された信頼度スコアに比べて大幅に向上した。コードとデータは、https://b-score.github.io にアクセス可能です。",
      "upvotes": 23,
      "discussionId": "6835217ee759f596d018f794",
      "projectPage": "https://b-score.github.io/",
      "githubRepo": "https://github.com/anvo25/b-score",
      "ai_summary": "LLMs can reduce biases in multi-turn conversations for certain types of questions, and a novel B-score metric improves the accuracy of verifying LLM answers.",
      "ai_keywords": [
        "large language models",
        "biases",
        "multi-turn conversation",
        "B-score",
        "MMLU",
        "HLE",
        "CSQA",
        "verification accuracy",
        "verbalized confidence scores"
      ]
    },
    "publishedAt": "2025-05-24T02:23:52.000Z",
    "title": "B-score: Detecting biases in large language models using response\n  history",
    "summary": "Large language models (LLMs) often exhibit strong biases, e.g, against women\nor in favor of the number 7. We investigate whether LLMs would be able to\noutput less biased answers when allowed to observe their prior answers to the\nsame question in a multi-turn conversation. To understand which types of\nquestions invite more biased answers, we test LLMs on our proposed set of\nquestions that span 9 topics and belong to three types: (1) Subjective; (2)\nRandom; and (3) Objective. Interestingly, LLMs are able to \"de-bias\" themselves\nin a multi-turn conversation in response to questions that seek an Random,\nunbiased answer. Furthermore, we propose B-score, a novel metric that is\neffective in detecting biases to Subjective, Random, Easy, and Hard questions.\nOn MMLU, HLE, and CSQA, leveraging B-score substantially improves the\nverification accuracy of LLM answers (i.e, accepting LLM correct answers and\nrejecting incorrect ones) compared to using verbalized confidence scores or the\nfrequency of single-turn answers alone. Code and data are available at:\nhttps://b-score.github.io.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.18545.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6039478ab3ecf716b1a5fd4d",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg",
      "fullname": "taesiri",
      "name": "taesiri",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 84
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.19815",
      "authors": [
        {
          "_id": "683523b21a2911c0774a1dc5",
          "user": {
            "_id": "643d26979347842571bc9613",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/3heFf7h3jbhhJWJ4JfGfh.jpeg",
            "isPro": false,
            "fullname": "Junnan Liu",
            "user": "jnanliu",
            "type": "user"
          },
          "name": "Junnan Liu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T07:51:56.495Z",
          "hidden": false
        },
        {
          "_id": "683523b21a2911c0774a1dc6",
          "name": "Hongwei Liu",
          "hidden": false
        },
        {
          "_id": "683523b21a2911c0774a1dc7",
          "name": "Linchen Xiao",
          "hidden": false
        },
        {
          "_id": "683523b21a2911c0774a1dc8",
          "user": {
            "_id": "654ce87af0b05673196a9f45",
            "avatarUrl": "/avatars/7b9c854eb98e487e3057479b1c7860ac.svg",
            "isPro": false,
            "fullname": "Shudong Liu",
            "user": "Sudanl",
            "type": "user"
          },
          "name": "Shudong Liu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T08:15:12.824Z",
          "hidden": false
        },
        {
          "_id": "683523b21a2911c0774a1dc9",
          "name": "Taolin Zhang",
          "hidden": false
        },
        {
          "_id": "683523b21a2911c0774a1dca",
          "name": "Zihan Ma",
          "hidden": false
        },
        {
          "_id": "683523b21a2911c0774a1dcb",
          "user": {
            "_id": "630716d11801ecc7d2595021",
            "avatarUrl": "/avatars/2d36a880ce4a3cf7efc5ff3987dbeaf3.svg",
            "isPro": false,
            "fullname": "Songyang Zhang",
            "user": "zsytony",
            "type": "user"
          },
          "name": "Songyang Zhang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T07:51:54.358Z",
          "hidden": false
        },
        {
          "_id": "683523b21a2911c0774a1dcc",
          "name": "Kai Chen",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-26T10:52:17.000Z",
      "submittedOnDailyAt": "2025-05-27T01:00:26.595Z",
      "title": "トラジェクト協力付きLLM論理解析の解読：最適化の視点から",
      "submittedOnDailyBy": {
        "_id": "630716d11801ecc7d2595021",
        "avatarUrl": "/avatars/2d36a880ce4a3cf7efc5ff3987dbeaf3.svg",
        "isPro": false,
        "fullname": "Songyang Zhang",
        "user": "zsytony",
        "type": "user"
      },
      "summary": "We propose a novel framework for comprehending the reasoning capabilities of large language models (LLMs) through the perspective of meta-learning. By conceptualizing reasoning trajectories as pseudo-gradient descent updates to the LLM's parameters, we identify parallels between LLM reasoning and various meta-learning paradigms. We formalize the training process for reasoning tasks as a meta-learning setup, with each question treated as an individual task, and reasoning trajectories serving as the inner loop optimization for adapting model parameters. Once trained on a diverse set of questions, the LLM develops fundamental reasoning capabilities that can generalize to previously unseen questions. Extensive empirical evaluations substantiate the strong connection between LLM reasoning and meta-learning, exploring several issues of significant interest from a meta-learning standpoint. Our work not only enhances the understanding of LLM reasoning but also provides practical insights for improving these models through established meta-learning techniques.",
      "upvotes": 22,
      "discussionId": "683523b41a2911c0774a1e78",
      "githubRepo": "https://github.com/open-compass/RaML",
      "ai_summary": "LLM reasoning is understood through a meta-learning framework, treating reasoning as pseudo-gradient descent and questions as individual tasks, which enhances generalization and provides practical insights for improvement.",
      "ai_keywords": [
        "large language models",
        "meta-learning",
        "pseudo-gradient descent",
        "inner loop optimization",
        "generalization",
        "fundamental reasoning capabilities"
      ]
    },
    "publishedAt": "2025-05-26T06:52:17.000Z",
    "title": "Deciphering Trajectory-Aided LLM Reasoning: An Optimization Perspective",
    "summary": "We propose a novel framework for comprehending the reasoning capabilities of\nlarge language models (LLMs) through the perspective of meta-learning. By\nconceptualizing reasoning trajectories as pseudo-gradient descent updates to\nthe LLM's parameters, we identify parallels between LLM reasoning and various\nmeta-learning paradigms. We formalize the training process for reasoning tasks\nas a meta-learning setup, with each question treated as an individual task, and\nreasoning trajectories serving as the inner loop optimization for adapting\nmodel parameters. Once trained on a diverse set of questions, the LLM develops\nfundamental reasoning capabilities that can generalize to previously unseen\nquestions. Extensive empirical evaluations substantiate the strong connection\nbetween LLM reasoning and meta-learning, exploring several issues of\nsignificant interest from a meta-learning standpoint. Our work not only\nenhances the understanding of LLM reasoning but also provides practical\ninsights for improving these models through established meta-learning\ntechniques.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.19815.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "630716d11801ecc7d2595021",
      "avatarUrl": "/avatars/2d36a880ce4a3cf7efc5ff3987dbeaf3.svg",
      "fullname": "Songyang Zhang",
      "name": "zsytony",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 17
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.19250",
      "authors": [
        {
          "_id": "68355ce06a9c239ada09f97b",
          "user": {
            "_id": "66e0404662d6ab4f1107580f",
            "avatarUrl": "/avatars/ef71694fea5482078a637a3869e30d19.svg",
            "isPro": false,
            "fullname": "Yi Wang",
            "user": "Yi53",
            "type": "user"
          },
          "name": "Yi Wang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T07:49:06.169Z",
          "hidden": false
        },
        {
          "_id": "68355ce06a9c239ada09f97c",
          "user": {
            "_id": "68356f5db243fb809813a715",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/68356f5db243fb809813a715/grhHvANfDRp75rMJxWlQo.jpeg",
            "isPro": false,
            "fullname": "LiuJunxiao",
            "user": "master-lan",
            "type": "user"
          },
          "name": "Junxiao Liu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T07:55:01.261Z",
          "hidden": false
        },
        {
          "_id": "68355ce06a9c239ada09f97d",
          "name": "Shimao Zhang",
          "hidden": false
        },
        {
          "_id": "68355ce06a9c239ada09f97e",
          "name": "Jiajun Chen",
          "hidden": false
        },
        {
          "_id": "68355ce06a9c239ada09f97f",
          "name": "Shujian Huang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-25T17:58:50.000Z",
      "submittedOnDailyAt": "2025-05-27T07:16:47.391Z",
      "title": "PATS: プロセスレベルの適応的な思考モードの切り替え",
      "submittedOnDailyBy": {
        "_id": "66e0404662d6ab4f1107580f",
        "avatarUrl": "/avatars/ef71694fea5482078a637a3869e30d19.svg",
        "isPro": false,
        "fullname": "Yi Wang",
        "user": "Yi53",
        "type": "user"
      },
      "summary": "現在の大規模言語モデル（LLMs）は、すべての問題に対して固定した論理戦略を適用していますが、その複雑さは問題の難易度に依存しません。このような論理プロセスの複雑さの変化を無視することにより、性能と効率の間の不平衡が生じています。現在の方法は、問題の難易度を変えることにより対処するためのトレーニング無しの高速・遅速の思考システムの切り替えを実装しようとしていますが、解決策レベルの粗略な戦略調整に制限されています。この問題に対処するために、我々は新しい論理パラダイムを提案します：Process-Level Adaptive Thinking Mode Switching（PATS）。これは、LLMsが各ステップの難易度に基づいて論理戦略を動的に調整することを可能にし、精度と計算効率の間のバランスを最適化します。我々のアプローチは、Process Reward Models（PRMs）とBeam Searchを統合し、進歩的なモード切り替えとバッドステップのペナルティ機構を含めています。多様な数学ベンチマークでの実験により、我々の方法が高精度を維持しながら中度のトークン使用量を維持することを示しています。この研究は、プロセスレベルでの難易度に関する論理戦略の変換の重要性を強調し、LLMsの効率的な推論における有價値なヒントを提供します。",
      "upvotes": 22,
      "discussionId": "68355ce16a9c239ada09f9a9",
      "ai_summary": "PATS enhances LLM efficiency by dynamically adjusting reasoning strategies based on task difficulty, leveraging PRMs and Beam Search.",
      "ai_keywords": [
        "large-language models (LLMs)",
        "reasoning strategy",
        "task and reasoning process complexity",
        "training-free fast-slow thinking system switching",
        "Process-Level Adaptive Thinking Mode Switching (PATS)",
        "Process Reward Models (PRMs)",
        "Beam Search",
        "progressive mode switching",
        "bad-step penalty mechanisms",
        "mathematical benchmarks",
        "process-level",
        "difficulty-aware reasoning strategy adaptation"
      ]
    },
    "publishedAt": "2025-05-25T13:58:50.000Z",
    "title": "PATS: Process-Level Adaptive Thinking Mode Switching",
    "summary": "Current large-language models (LLMs) typically adopt a fixed reasoning\nstrategy, either simple or complex, for all questions, regardless of their\ndifficulty. This neglect of variation in task and reasoning process complexity\nleads to an imbalance between performance and efficiency. Existing methods\nattempt to implement training-free fast-slow thinking system switching to\nhandle problems of varying difficulty, but are limited by coarse-grained\nsolution-level strategy adjustments. To address this issue, we propose a novel\nreasoning paradigm: Process-Level Adaptive Thinking Mode Switching (PATS),\nwhich enables LLMs to dynamically adjust their reasoning strategy based on the\ndifficulty of each step, optimizing the balance between accuracy and\ncomputational efficiency. Our approach integrates Process Reward Models (PRMs)\nwith Beam Search, incorporating progressive mode switching and bad-step penalty\nmechanisms. Experiments on diverse mathematical benchmarks demonstrate that our\nmethodology achieves high accuracy while maintaining moderate token usage. This\nstudy emphasizes the significance of process-level, difficulty-aware reasoning\nstrategy adaptation, offering valuable insights into efficient inference for\nLLMs.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.19250.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "66e0404662d6ab4f1107580f",
      "avatarUrl": "/avatars/ef71694fea5482078a637a3869e30d19.svg",
      "fullname": "Yi Wang",
      "name": "Yi53",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.20259",
      "authors": [
        {
          "_id": "6835346b2fdc5f8e8ea1e3cf",
          "name": "Haoyu Wang",
          "hidden": false
        },
        {
          "_id": "6835346b2fdc5f8e8ea1e3d0",
          "name": "Zeyu Qin",
          "hidden": false
        },
        {
          "_id": "6835346b2fdc5f8e8ea1e3d1",
          "name": "Yifei Zhao",
          "hidden": false
        },
        {
          "_id": "6835346b2fdc5f8e8ea1e3d2",
          "name": "Chao Du",
          "hidden": false
        },
        {
          "_id": "6835346b2fdc5f8e8ea1e3d3",
          "name": "Min Lin",
          "hidden": false
        },
        {
          "_id": "6835346b2fdc5f8e8ea1e3d4",
          "name": "Xueqian Wang",
          "hidden": false
        },
        {
          "_id": "6835346b2fdc5f8e8ea1e3d5",
          "name": "Tianyu Pang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-26T17:40:40.000Z",
      "submittedOnDailyAt": "2025-05-27T02:13:04.341Z",
      "title": "Lifelong Safety Alignment for Language Models",
      "submittedOnDailyBy": {
        "_id": "63d91b6d255ef6add20e1b38",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1675921369867-63d91b6d255ef6add20e1b38.jpeg",
        "isPro": false,
        "fullname": "Tianyu Pang",
        "user": "P2333",
        "type": "user"
      },
      "summary": "LLMsは驚異的な進歩を達成していますが、その拡大する能力は、安全性の対位を回避するためのフレックスブルなjailbreaking攻撃に脆弱性を持ちます。現在の防御戦略は、知られている攻撃の種類に焦点を当てていますが、部署中に発生する未知の攻撃に対応することがより重要です。これに対処するために、私たちは、LLMsが新しいおよび進化しているjailbreaking戦略に連続的に適応できるような生涯的安全性対位フレームワークを提案します。このフレームワークでは、2つの要素の相対的な戦略を導入しています：Meta-Attackerは新しいjailbreaking戦略を主動的に発見するために訓練されていますが、Defenderはそれらを抵抗するために訓練されています。Meta-Attackerを効果的に暖まらせるためには、最初にGPT-4o APIを利用して、大規模なjailbreak-related研究論文からキーインサイトを抽出します。反復的な訓練を通じて、最初の反復では、Meta-AttackerはRRで73%の攻撃成功率（ASR）を達成し、LATでは単一ターン攻撃を用いて57%の転移ASRを達成します。一方では、Defenderは進歩的に強固性を向上させ、最終的にMeta-Attackerの成功率を7%に抑え、LLMsが開放的な環境で安全かつ信頼性のある部署を可能にします。コードは、https://github.com/sail-sg/LifelongSafetyAlignmentに公開されています。",
      "upvotes": 21,
      "discussionId": "6835346c2fdc5f8e8ea1e407",
      "githubRepo": "https://github.com/sail-sg/LifelongSafetyAlignment",
      "ai_summary": "A lifecycle safety alignment framework employs a Meta-Attacker and Defender to adapt LLMs to novel jailbreaking strategies, improving robustness in deployment.",
      "ai_keywords": [
        "LLMs",
        "jailbreaking attacks",
        "safety alignment",
        "lifelong safety alignment framework",
        "Meta-Attacker",
        "Defender",
        "GPT-4o API",
        "attack success rate",
        "transfer attack success rate",
        "single-turn attacks"
      ]
    },
    "publishedAt": "2025-05-26T13:40:40.000Z",
    "title": "Lifelong Safety Alignment for Language Models",
    "summary": "LLMs have made impressive progress, but their growing capabilities also\nexpose them to highly flexible jailbreaking attacks designed to bypass safety\nalignment. While many existing defenses focus on known types of attacks, it is\nmore critical to prepare LLMs for unseen attacks that may arise during\ndeployment. To address this, we propose a lifelong safety alignment framework\nthat enables LLMs to continuously adapt to new and evolving jailbreaking\nstrategies. Our framework introduces a competitive setup between two\ncomponents: a Meta-Attacker, trained to actively discover novel jailbreaking\nstrategies, and a Defender, trained to resist them. To effectively warm up the\nMeta-Attacker, we first leverage the GPT-4o API to extract key insights from a\nlarge collection of jailbreak-related research papers. Through iterative\ntraining, the first iteration Meta-Attacker achieves a 73% attack success rate\n(ASR) on RR and a 57% transfer ASR on LAT using only single-turn attacks.\nMeanwhile, the Defender progressively improves its robustness and ultimately\nreduces the Meta-Attacker's success rate to just 7%, enabling safer and more\nreliable deployment of LLMs in open-ended environments. The code is available\nat https://github.com/sail-sg/LifelongSafetyAlignment.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.20259.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "63d91b6d255ef6add20e1b38",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1675921369867-63d91b6d255ef6add20e1b38.jpeg",
      "fullname": "Tianyu Pang",
      "name": "P2333",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 3
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2505.18675",
      "authors": [
        {
          "_id": "68351dde0c0aff775f3933ee",
          "user": {
            "_id": "67a4a26d5e65aa63c6d30e68",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/67a4a26d5e65aa63c6d30e68/GtodlJGw-_IL2DTXQTucz.jpeg",
            "isPro": false,
            "fullname": "FENG SICHENG",
            "user": "FSCCS",
            "type": "user"
          },
          "name": "Sicheng Feng",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T07:52:13.406Z",
          "hidden": false
        },
        {
          "_id": "68351dde0c0aff775f3933ef",
          "name": "Song Wang",
          "hidden": false
        },
        {
          "_id": "68351dde0c0aff775f3933f0",
          "name": "Shuyi Ouyang",
          "hidden": false
        },
        {
          "_id": "68351dde0c0aff775f3933f1",
          "name": "Lingdong Kong",
          "hidden": false
        },
        {
          "_id": "68351dde0c0aff775f3933f2",
          "name": "Zikai Song",
          "hidden": false
        },
        {
          "_id": "68351dde0c0aff775f3933f3",
          "name": "Jianke Zhu",
          "hidden": false
        },
        {
          "_id": "68351dde0c0aff775f3933f4",
          "user": {
            "_id": "62b624f3b52bef716e248fd7",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62b624f3b52bef716e248fd7/AllcccKH-eBWduA8KVnOQ.png",
            "isPro": false,
            "fullname": "Huan Wang",
            "user": "Huan-WhoRegisteredMyName",
            "type": "user"
          },
          "name": "Huan Wang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T07:52:11.085Z",
          "hidden": false
        },
        {
          "_id": "68351dde0c0aff775f3933f5",
          "name": "Xinchao Wang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-24T12:33:52.000Z",
      "submittedOnDailyAt": "2025-05-27T00:35:52.585Z",
      "title": "MLLMsは私を帰ってくれるか？ 交通機関マップからの細分化可視化論理のベンチマーク研究",
      "submittedOnDailyBy": {
        "_id": "67a4a26d5e65aa63c6d30e68",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/67a4a26d5e65aa63c6d30e68/GtodlJGw-_IL2DTXQTucz.jpeg",
        "isPro": false,
        "fullname": "FENG SICHENG",
        "user": "FSCCS",
        "type": "user"
      },
      "summary": "多モダル大語言モデル（MLLMs）は、視覚タスクにおいて、意味的なスケーン理解とテキスト・イメージのアラインメントなどにおいて最近に顕著な進歩を達し、数学や論理に関する複雑なタスクにおける性能を向上させるための理由的な変体が導入されました。しかし、理由的なタスクにおける細かい視覚的理解の機能は十分に評価されていません。\n\nこの欠点を解決するために、我々は、MLLMsの細かい視覚的理解と空間的理由の能力を評価するためのReasonMapベンチマークを紹介します。ReasonMapは、13国の30都市からの高解像度の交通地図を含み、2つの質問タイプと3つのテンプレートを通じて1,008の質問・回答ペアを構成しています。また、答えの正確さと品質を正確に評価するために、2段階の評価プインプルを設計しました。15つのプロパートのMLLMs（これらは基礎モデルと理由的な変体の両方を含む）の詳細な評価を行い、直感的なパターンを示すことがわかりました：開放ソースモデルでは基礎モデルが理由的なモデルよりも優れている一方、閉めソースモデルでは逆の傾向が見られます。また、視覚的な入力がマスクされた場合には性能が一般的に低下し、これはMLLMsはその知識を利用していくことであるが、細かい視覚的な理由的タスクは強い性能を示すには本物の視覚的な認識が必要であることを示しています。我々のベンチマーク研究は、視覚的な理由について新しいエンドワークを提供し、開放ソースと閉めソースモデルの間の間違いを調査することに貢献します。",
      "upvotes": 21,
      "discussionId": "68351de10c0aff775f39347a",
      "projectPage": "https://fscdc.github.io/Reason-Map/",
      "githubRepo": "https://github.com/fscdc/ReasonMap",
      "ai_summary": "ReasonMap evaluates the fine-grained visual understanding and spatial reasoning abilities of multimodal large language models, revealing that base models often outperform reasoning variants and highlighting the importance of genuine visual perception for complex tasks.",
      "ai_keywords": [
        "multimodal large language models",
        "MLLMs",
        "semantic scene understanding",
        "text-image alignment",
        "reasoning variants",
        "ReasonMap",
        "high-resolution transit maps",
        "question-answer pairs",
        "two-level evaluation pipeline",
        "open-source models",
        "closed-source models",
        "visual reasoning"
      ]
    },
    "publishedAt": "2025-05-24T08:33:52.000Z",
    "title": "Can MLLMs Guide Me Home? A Benchmark Study on Fine-Grained Visual\n  Reasoning from Transit Maps",
    "summary": "Multimodal large language models (MLLMs) have recently achieved significant\nprogress in visual tasks, including semantic scene understanding and text-image\nalignment, with reasoning variants enhancing performance on complex tasks\ninvolving mathematics and logic. However, their capacity for reasoning tasks\ninvolving fine-grained visual understanding remains insufficiently evaluated.\nTo address this gap, we introduce ReasonMap, a benchmark designed to assess the\nfine-grained visual understanding and spatial reasoning abilities of MLLMs.\nReasonMap encompasses high-resolution transit maps from 30 cities across 13\ncountries and includes 1,008 question-answer pairs spanning two question types\nand three templates. Furthermore, we design a two-level evaluation pipeline\nthat properly assesses answer correctness and quality. Comprehensive\nevaluations of 15 popular MLLMs, including both base and reasoning variants,\nreveal a counterintuitive pattern: among open-source models, base models\noutperform reasoning ones, while the opposite trend is observed in\nclosed-source models. Additionally, performance generally degrades when visual\ninputs are masked, indicating that while MLLMs can leverage prior knowledge to\nanswer some questions, fine-grained visual reasoning tasks still require\ngenuine visual perception for strong performance. Our benchmark study offers\nnew insights into visual reasoning and contributes to investigating the gap\nbetween open-source and closed-source models.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.18675.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "67a4a26d5e65aa63c6d30e68",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/67a4a26d5e65aa63c6d30e68/GtodlJGw-_IL2DTXQTucz.jpeg",
      "fullname": "FENG SICHENG",
      "name": "FSCCS",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 0
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.19209",
      "authors": [
        {
          "_id": "683529e8ddbf19d1df9038fb",
          "user": {
            "_id": "646a11791556443f24b582e9",
            "avatarUrl": "/avatars/b54d416ddca2f124492ba51bc4b95fd2.svg",
            "isPro": false,
            "fullname": "Zonglin Yang",
            "user": "ZonglinY",
            "type": "user"
          },
          "name": "Zonglin Yang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T07:50:55.453Z",
          "hidden": false
        },
        {
          "_id": "683529e8ddbf19d1df9038fc",
          "name": "Wanhao Liu",
          "hidden": false
        },
        {
          "_id": "683529e8ddbf19d1df9038fd",
          "name": "Ben Gao",
          "hidden": false
        },
        {
          "_id": "683529e8ddbf19d1df9038fe",
          "name": "Yujie Liu",
          "hidden": false
        },
        {
          "_id": "683529e8ddbf19d1df9038ff",
          "name": "Wei Li",
          "hidden": false
        },
        {
          "_id": "683529e8ddbf19d1df903900",
          "name": "Tong Xie",
          "hidden": false
        },
        {
          "_id": "683529e8ddbf19d1df903901",
          "name": "Lidong Bing",
          "hidden": false
        },
        {
          "_id": "683529e8ddbf19d1df903902",
          "name": "Wanli Ouyang",
          "hidden": false
        },
        {
          "_id": "683529e8ddbf19d1df903903",
          "name": "Erik Cambria",
          "hidden": false
        },
        {
          "_id": "683529e8ddbf19d1df903904",
          "name": "Dongzhan Zhou",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-25T16:13:46.000Z",
      "submittedOnDailyAt": "2025-05-27T01:30:07.083Z",
      "title": "MOOSE-Chem2: エフィンショナルな科学の仮説の探索におけるLLMの限界を探る：階層的な検索を通じて",
      "submittedOnDailyBy": {
        "_id": "646a11791556443f24b582e9",
        "avatarUrl": "/avatars/b54d416ddca2f124492ba51bc4b95fd2.svg",
        "isPro": false,
        "fullname": "Zonglin Yang",
        "user": "ZonglinY",
        "type": "user"
      },
      "summary": "大語言モデル（LLMs）は、科学的仮説生成の自動化に望ましい結果を示していますが、現在のアプローチは主に粗略な仮説を生成し、重要な方法学的および実験的詳細を欠くことが多いです。私たちは、細かい科学の仮説発見の新しいタスクを介紹し、正式的に定義します。これは、粗略な最初の研究方向から細かい、実験的に行動可能な仮説を生成することを意味します。これを組み合わせの最適化問題とし、LLMsの解決力の上限を最大限に活用した場合にそれを解くことができるかを調べます。具体的には、4つの基礎的な問題について調査します: (1) LLMの内部のヒューリスティクスをどのように活用して、それ自身が生成するすべての可能な仮説の中で最も望ましいものを決定するか; (2) LLMが判断したより良い仮説が真の仮説に強く一致するか; (3) 同じ能力の多様なLLMのアンサンブルを使用してレWARDランドスケープを形成することが最強のLLMの繰り返しインスタンスで定義することに比べてよい結果を得るか; (4) 同じLLMのアンサンブルが単一のLLMよりも更に信頼性のあるレWARDランドスケープを提供するか。これらの問題を解決するために、仮説の詳細を進歩的に追加し、一般的な概念から具体的な実験設定へと進むヒューリスティックな探索方法を提案します。この階層的なプロセスは、レWARDランドスケープを平滑化し、より効果的な最適化を可能にします。最近の化学文献からの専門家のアノテーションの細かい仮説の新しいベンチマークでの実験的評価により、私たちの方法が強い基準に比べて一貫して優れていることが示されます。",
      "upvotes": 20,
      "discussionId": "683529e9ddbf19d1df903939",
      "ai_summary": "A method is proposed to generate detailed scientific hypotheses using LLMs by defining and optimizing a latent reward landscape, outperforming baselines in benchmark evaluations.",
      "ai_keywords": [
        "large language models",
        "fine-grained scientific hypothesis discovery",
        "combinatorial optimization",
        "latent reward landscape",
        "hierarchical search method"
      ]
    },
    "publishedAt": "2025-05-25T12:13:46.000Z",
    "title": "MOOSE-Chem2: Exploring LLM Limits in Fine-Grained Scientific Hypothesis\n  Discovery via Hierarchical Search",
    "summary": "Large language models (LLMs) have shown promise in automating scientific\nhypothesis generation, yet existing approaches primarily yield coarse-grained\nhypotheses lacking critical methodological and experimental details. We\nintroduce and formally define the novel task of fine-grained scientific\nhypothesis discovery, which entails generating detailed, experimentally\nactionable hypotheses from coarse initial research directions. We frame this as\na combinatorial optimization problem and investigate the upper limits of LLMs'\ncapacity to solve it when maximally leveraged. Specifically, we explore four\nfoundational questions: (1) how to best harness an LLM's internal heuristics to\nformulate the fine-grained hypothesis it itself would judge as the most\npromising among all the possible hypotheses it might generate, based on its own\ninternal scoring-thus defining a latent reward landscape over the hypothesis\nspace; (2) whether such LLM-judged better hypotheses exhibit stronger alignment\nwith ground-truth hypotheses; (3) whether shaping the reward landscape using an\nensemble of diverse LLMs of similar capacity yields better outcomes than\ndefining it with repeated instances of the strongest LLM among them; and (4)\nwhether an ensemble of identical LLMs provides a more reliable reward landscape\nthan a single LLM. To address these questions, we propose a hierarchical search\nmethod that incrementally proposes and integrates details into the hypothesis,\nprogressing from general concepts to specific experimental configurations. We\nshow that this hierarchical process smooths the reward landscape and enables\nmore effective optimization. Empirical evaluations on a new benchmark of\nexpert-annotated fine-grained hypotheses from recent chemistry literature show\nthat our method consistently outperforms strong baselines.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.19209.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "646a11791556443f24b582e9",
      "avatarUrl": "/avatars/b54d416ddca2f124492ba51bc4b95fd2.svg",
      "fullname": "Zonglin Yang",
      "name": "ZonglinY",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.18536",
      "authors": [
        {
          "_id": "68351f7a06b4dae20a214442",
          "name": "Haoyuan Sun",
          "hidden": false
        },
        {
          "_id": "68351f7a06b4dae20a214443",
          "name": "Jiaqi Wu",
          "hidden": false
        },
        {
          "_id": "68351f7a06b4dae20a214444",
          "name": "Bo Xia",
          "hidden": false
        },
        {
          "_id": "68351f7a06b4dae20a214445",
          "name": "Yifu Luo",
          "hidden": false
        },
        {
          "_id": "68351f7a06b4dae20a214446",
          "name": "Yifei Zhao",
          "hidden": false
        },
        {
          "_id": "68351f7a06b4dae20a214447",
          "name": "Kai Qin",
          "hidden": false
        },
        {
          "_id": "68351f7a06b4dae20a214448",
          "name": "Xufei Lv",
          "hidden": false
        },
        {
          "_id": "68351f7a06b4dae20a214449",
          "name": "Tiantian Zhang",
          "hidden": false
        },
        {
          "_id": "68351f7a06b4dae20a21444a",
          "name": "Yongzhe Chang",
          "hidden": false
        },
        {
          "_id": "68351f7a06b4dae20a21444b",
          "name": "Xueqian Wang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-24T06:01:48.000Z",
      "submittedOnDailyAt": "2025-05-27T00:43:18.404Z",
      "title": "強化調整による多タイプ大語言モデルの推論能力を強化する",
      "submittedOnDailyBy": {
        "_id": "65e2d43f9fb58a5115253049",
        "avatarUrl": "/avatars/46bd4ae27eaa23802cef3d91626897b5.svg",
        "isPro": false,
        "fullname": "Haoyuan Sun",
        "user": "xiaonengmiao",
        "type": "user"
      },
      "summary": "2025年に立ち、人工知能（AGI）の追求の關連する重要な時期に立ち、強化調整（RFT）は、大語言モデル（LLMs）の理由能力を高めるために重要なポテンシャルを示し、OpenAI-o1やDeepSeek-R1といった先端的なAIモデルの開発につながった。また、RFTの効率的な応用により、多モデル大語言モデル（MLLMs）の理由能力を高めることには、コミュニティから広く注目されている。この立場論文では、RFTはMLLMの理由能力を支えることを主張し、最初に、この分野に興味を持つ研究者に必要な基本的な知識について詳細に紹介し、また、RFTがMLLMの理由能力を高めるための改善点を5つのポイントで細かく要約します：多様なモディュール、多様なタスクと領域、より良い学習アルゴリズム、豊富なベンチマーク、活躍しているエンジニアリングフレームワーク。最後に、コミュニティが考慮することのできる未来の研究の5つの有望な方向を提案します。この立場論文は、AGIへの進展の關連する重要なステップでコミュニティに有價しいヒントを提供することを望む。RFTをMLLMに応用した研究の概要は、https://github.com/Sun-Haoyuan23/Awesome-RL-based-Reasoning-MLLMsにアクセスできます。",
      "upvotes": 16,
      "discussionId": "68351f7b06b4dae20a2144b5",
      "projectPage": "https://github.com/Sun-Haoyuan23/Awesome-RL-based-Reasoning-MLLMs",
      "githubRepo": "https://github.com/Sun-Haoyuan23/Awesome-RL-based-Reasoning-MLLMs",
      "ai_summary": "Reinforcement fine-tuning significantly enhances the reasoning capabilities of multimodal large language models through diverse modalities, tasks, algorithms, benchmarks, and frameworks.",
      "ai_keywords": [
        "reinforcement fine-tuning",
        "multimodal large language models",
        "OpenAI-o1",
        "DeepSeek-R1",
        "diverse modalities",
        "diverse tasks and domains",
        "better training algorithms",
        "abundant benchmarks",
        "thriving engineering frameworks"
      ]
    },
    "publishedAt": "2025-05-24T02:01:48.000Z",
    "title": "Reinforcement Fine-Tuning Powers Reasoning Capability of Multimodal\n  Large Language Models",
    "summary": "Standing in 2025, at a critical juncture in the pursuit of Artificial General\nIntelligence (AGI), reinforcement fine-tuning (RFT) has demonstrated\nsignificant potential in enhancing the reasoning capability of large language\nmodels (LLMs) and has led to the development of cutting-edge AI models such as\nOpenAI-o1 and DeepSeek-R1. Moreover, the efficient application of RFT to\nenhance the reasoning capability of multimodal large language models (MLLMs)\nhas attracted widespread attention from the community. In this position paper,\nwe argue that reinforcement fine-tuning powers the reasoning capability of\nmultimodal large language models. To begin with, we provide a detailed\nintroduction to the fundamental background knowledge that researchers\ninterested in this field should be familiar with. Furthermore, we meticulously\nsummarize the improvements of RFT in powering reasoning capability of MLLMs\ninto five key points: diverse modalities, diverse tasks and domains, better\ntraining algorithms, abundant benchmarks and thriving engineering frameworks.\nFinally, we propose five promising directions for future research that the\ncommunity might consider. We hope that this position paper will provide\nvaluable insights to the community at this pivotal stage in the advancement\ntoward AGI. Summary of works done on RFT for MLLMs is available at\nhttps://github.com/Sun-Haoyuan23/Awesome-RL-based-Reasoning-MLLMs.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.18536.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "65e2d43f9fb58a5115253049",
      "avatarUrl": "/avatars/46bd4ae27eaa23802cef3d91626897b5.svg",
      "fullname": "Haoyuan Sun",
      "name": "xiaonengmiao",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2505.19439",
      "authors": [
        {
          "_id": "68355784bb7d114755346770",
          "name": "Rihui Xin",
          "hidden": false
        },
        {
          "_id": "68355784bb7d114755346771",
          "name": "Han Liu",
          "hidden": false
        },
        {
          "_id": "68355784bb7d114755346772",
          "name": "Zecheng Wang",
          "hidden": false
        },
        {
          "_id": "68355784bb7d114755346773",
          "name": "Yupeng Zhang",
          "hidden": false
        },
        {
          "_id": "68355784bb7d114755346774",
          "name": "Dianbo Sui",
          "hidden": false
        },
        {
          "_id": "68355784bb7d114755346775",
          "name": "Xiaolin Hu",
          "hidden": false
        },
        {
          "_id": "68355784bb7d114755346776",
          "name": "Bingning Wang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-26T02:56:22.000Z",
      "submittedOnDailyAt": "2025-05-27T04:41:46.037Z",
      "title": "フォーマットと長さからの代理信号：ガロフォードエフェクトを解決するための強化学習",
      "submittedOnDailyBy": {
        "_id": "62e52483a944e2a56cd2c6ca",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62e52483a944e2a56cd2c6ca/pG44O-1qD00q5CEJMMyFQ.jpeg",
        "isPro": false,
        "fullname": "Jiejun Tan",
        "user": "zstanjj",
        "type": "user"
      },
      "summary": "大語言モデルは、自然言語処理タスクで驚異的な成功を収め、強化学習が特定のアプリケーションに適応する際に重要な役割を果たしています。しかし、数理問題解決におけるLLMの訓練において、正解のデータを得ることは通常難しく、コストの高いことであり、その時は実現不可能です。本研究では、形式と長さを代理信号として数理問題解決におけるLLMの訓練を行う方法を検討し、正解のデータを必要とする傳統的な方法を回避しています。本研究では、形式の正確性だけに中心した報酬関数が初期段階で性能向上を収めることが示されました。形式だけの報酬の局限性を認識し、長さベースの報酬を採用しました。これにより、形式と長さの代理信号を利用するGRPOアプローチは、正解のデータを基にした単一のGRPOアプローチを超え、特定のシナリオではAIME2024で40.0%の正確率を達成しました。この研究は、数理問題解決におけるLLMの訓練の実用的な解決策を提供し、極端な正解データの収集の依存性を減らすことを可能にします。また、ラベル無しアプローチが成功する理由を明らかにします：基礎モデルは既に数学と論理的推理スキルを学んでいるような優秀な学生のように見え、ただし、テスト紙での表現が劣り、それだけでは優秀な結果を収めることができないので、問題解決の習慣を養うことで、テストでの優秀な結果を収めることができることを意味します。",
      "upvotes": 15,
      "discussionId": "68355785bb7d1147553467b8",
      "ai_summary": "The research demonstrates that using format and length as surrogate signals can improve LLMs' performance in mathematical problem-solving, matching or surpassing traditional methods without extensive ground truth data.",
      "ai_keywords": [
        "Large Language Models",
        "Reinforcement Learning",
        "mathematical problem-solving",
        "GRPO algorithm",
        "format correctness",
        "length-based rewards",
        "AIME2024"
      ]
    },
    "publishedAt": "2025-05-25T22:56:22.000Z",
    "title": "Surrogate Signals from Format and Length: Reinforcement Learning for\n  Solving Mathematical Problems without Ground Truth Answers",
    "summary": "Large Language Models have achieved remarkable success in natural language\nprocessing tasks, with Reinforcement Learning playing a key role in adapting\nthem to specific applications. However, obtaining ground truth answers for\ntraining LLMs in mathematical problem-solving is often challenging, costly, and\nsometimes unfeasible. This research delves into the utilization of format and\nlength as surrogate signals to train LLMs for mathematical problem-solving,\nbypassing the need for traditional ground truth answers.Our study shows that a\nreward function centered on format correctness alone can yield performance\nimprovements comparable to the standard GRPO algorithm in early phases.\nRecognizing the limitations of format-only rewards in the later phases, we\nincorporate length-based rewards. The resulting GRPO approach, leveraging\nformat-length surrogate signals, not only matches but surpasses the performance\nof the standard GRPO algorithm relying on ground truth answers in certain\nscenarios, achieving 40.0\\% accuracy on AIME2024 with a 7B base model. Through\nsystematic exploration and experimentation, this research not only offers a\npractical solution for training LLMs to solve mathematical problems and\nreducing the dependence on extensive ground truth data collection, but also\nreveals the essence of why our label-free approach succeeds: base model is like\nan excellent student who has already mastered mathematical and logical\nreasoning skills, but performs poorly on the test paper, it simply needs to\ndevelop good answering habits to achieve outstanding results in exams , in\nother words, to unlock the capabilities it already possesses.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.19439.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "62e52483a944e2a56cd2c6ca",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62e52483a944e2a56cd2c6ca/pG44O-1qD00q5CEJMMyFQ.jpeg",
      "fullname": "Jiejun Tan",
      "name": "zstanjj",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 10
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2505.18601",
      "authors": [
        {
          "_id": "6835268212dd354d6acdacbf",
          "name": "Jongwoo Ko",
          "hidden": false
        },
        {
          "_id": "6835268212dd354d6acdacc0",
          "user": {
            "_id": "63f0c2ac9cf89c9ed1bdd25c",
            "avatarUrl": "/avatars/856b2cb482250fb83c6fe793e29dfd74.svg",
            "isPro": false,
            "fullname": "Sungnyun Kim",
            "user": "sungnyun",
            "type": "user"
          },
          "name": "Sungnyun Kim",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T08:15:10.751Z",
          "hidden": false
        },
        {
          "_id": "6835268212dd354d6acdacc1",
          "name": "Sungwoo Cho",
          "hidden": false
        },
        {
          "_id": "6835268212dd354d6acdacc2",
          "name": "Se-Young Yun",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-24T08:50:53.000Z",
      "submittedOnDailyAt": "2025-05-27T01:14:15.443Z",
      "title": "Flex-Judge: 一度考えて、どこでも判断できます。",
      "submittedOnDailyBy": {
        "_id": "63f0c2ac9cf89c9ed1bdd25c",
        "avatarUrl": "/avatars/856b2cb482250fb83c6fe793e29dfd74.svg",
        "isPro": false,
        "fullname": "Sungnyun Kim",
        "user": "sungnyun",
        "type": "user"
      },
      "summary": "人間が生成した報酬信号は、生成モデルと人間の好みを一致させるために重要であり、学習および推論時の評価を指導することができます。大規模な言語モデル（LLM）を代理評価者として使用することで、手動注釈に関連するコストを大幅に減少することができますが、これらは通常、様々な多タイプ課題に広く一般化できるための幅広いモデル特化の訓練データが必要で、その実践的な効果が限定されています。本論文では、最小限の文脈的な理由を利用した理由をガイドする多タイプ評判モデル「Flex-Judge」を提案し、複数のモデルと評価形式を広く一般化できるようにします。本論文の核心の直感は、構造化された文脈的な理由には一般化可能な判断パターンが内蔵されていることで、例えば画像や映像を含む多タイプ判断に効果的なタンスファーが可能です。実験結果によると、Flex-Judgeは文脈データの量が大幅に少ないことにもかかわらず、最先端の商業APIと広範囲訓練された多タイプ評判モデルに比べて、競争的なまたは優れた性能を達成します。特に、分子モデルなど、詳細な評価ベンチマークが少ないモデルでも広く影響を及ぼし、資源制限された領域での実用的な価値を強調します。本フレームワークは、理由ベースの文脈サブプロバイションを傳統的な注釈ヘビーなアプローチの代わりとして強力な、コスト効率的なソリューションとしての可能性を明らかにし、可換スケーラブルな多タイプモデルのジャッジを大幅に進めます。",
      "upvotes": 15,
      "discussionId": "6835268312dd354d6acdad1e",
      "projectPage": "https://flex-judge.github.io/",
      "githubRepo": "https://github.com/jongwooko/flex-judge",
      "ai_summary": "Flex-Judge uses minimal textual reasoning data to generalize across multiple modalities and evaluation formats, outperforming state-of-the-art models in multimodal evaluations.",
      "ai_keywords": [
        "reasoning-guided multimodal judge model",
        "structured textual reasoning explanations",
        "generalizable decision-making patterns",
        "multimodal judgments",
        "molecule evaluations",
        "reasoning-based text supervision",
        "scalable multimodal model-as-a-judge"
      ]
    },
    "publishedAt": "2025-05-24T04:50:53.000Z",
    "title": "Flex-Judge: Think Once, Judge Anywhere",
    "summary": "Human-generated reward signals are critical for aligning generative models\nwith human preferences, guiding both training and inference-time evaluations.\nWhile large language models (LLMs) employed as proxy evaluators, i.e.,\nLLM-as-a-Judge, significantly reduce the costs associated with manual\nannotations, they typically require extensive modality-specific training data\nand fail to generalize well across diverse multimodal tasks. In this paper, we\npropose Flex-Judge, a reasoning-guided multimodal judge model that leverages\nminimal textual reasoning data to robustly generalize across multiple\nmodalities and evaluation formats. Our core intuition is that structured\ntextual reasoning explanations inherently encode generalizable decision-making\npatterns, enabling an effective transfer to multimodal judgments, e.g., with\nimages or videos. Empirical results demonstrate that Flex-Judge, despite being\ntrained on significantly fewer text data, achieves competitive or superior\nperformance compared to state-of-the-art commercial APIs and extensively\ntrained multimodal evaluators. Notably, Flex-Judge presents broad impact in\nmodalities like molecule, where comprehensive evaluation benchmarks are scarce,\nunderscoring its practical value in resource-constrained domains. Our framework\nhighlights reasoning-based text supervision as a powerful, cost-effective\nalternative to traditional annotation-intensive approaches, substantially\nadvancing scalable multimodal model-as-a-judge.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.18601.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "63f0c2ac9cf89c9ed1bdd25c",
      "avatarUrl": "/avatars/856b2cb482250fb83c6fe793e29dfd74.svg",
      "fullname": "Sungnyun Kim",
      "name": "sungnyun",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.19949",
      "authors": [
        {
          "_id": "68352aac38e5ca9eb5349c2f",
          "name": "Siqi Kou",
          "hidden": false
        },
        {
          "_id": "68352aac38e5ca9eb5349c30",
          "name": "Qingyuan Tian",
          "hidden": false
        },
        {
          "_id": "68352aac38e5ca9eb5349c31",
          "name": "Hanwen Xu",
          "hidden": false
        },
        {
          "_id": "68352aac38e5ca9eb5349c32",
          "name": "Zihao Zeng",
          "hidden": false
        },
        {
          "_id": "68352aac38e5ca9eb5349c33",
          "name": "Zhijie Deng",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-26T13:15:26.000Z",
      "submittedOnDailyAt": "2025-05-27T01:30:37.130Z",
      "title": "データの属性は、数学とコードの理由論を刺激することができるのか？影響関数を用いた調査",
      "submittedOnDailyBy": {
        "_id": "654e330f350abceb30a1390b",
        "avatarUrl": "/avatars/e54a8be788fa1bdc7acefecc208215bb.svg",
        "isPro": false,
        "fullname": "KouSiqi",
        "user": "karrykkk",
        "type": "user"
      },
      "summary": "大語言モデル（LLMs）は、数学とコーディングにおいて、鎖の思いつき（CoTs）を生成する強化モデルによる後学習をもって、非凡の論理能力を示しています。しかし、現在のデータのカレーラティングの戦略は主にヒューリスティックに基づいていますので、一般化可能性が限られ、データの軽微な部分を捉えずにいます。これらの制限を解決するために、我々は、影響関数を使用して、LLMsの数学とコーディングの論理能力を個々の学習サンプル、シーケンス、トークンによってシステマティックに割り当てることに掛けつけます。このようなシステム的なアタッチにより、我々の影響関数に基づく論理割り当て（Infra）は、数学とコーディングタスクの横断的な効果を非単調的に明らかにします：高難度の数学サンプルは数学とコードの両方の論理を向上させ、低難度のコーディングタスクはコードの論理に最大限の利益を与えます。これらの発見に基づいて、我々は、タスクの難易度を反転させる簡単で効果的なデータセットの再重み付け戦略を紹介します。これにより、AIME24の精度は10%から20%に、Qwen2.5-7B-InstructのLiveCodeBenchの精度は33.8%から35.3%に増加します。また、我々の細かい割り当ては、シーケンスレベルの探索的な行動が数学とコーディングの両方で論理性能を向上させ、トークンレベルの影響パターンは数学とコーディングの論理にそれぞれ異なります：前者は自然言語の論理コネクターを好み、後者は構文を強調しています。",
      "upvotes": 13,
      "discussionId": "68352aad38e5ca9eb5349c6f",
      "ai_summary": "Influence functions are used to attribute LLMs' reasoning in math and coding to individual training elements, revealing cross-domain effects and enabling a reweighting strategy that improves model accuracy.",
      "ai_keywords": [
        "Large language models (LLMs)",
        "chain-of-thoughts (CoTs)",
        "influence functions",
        "attribution",
        "data curation",
        "reasoning ability",
        "high-difficulty math examples",
        "low-difficulty code tasks",
        "dataset reweighting strategy",
        "AIME24 accuracy",
        "LiveCodeBench accuracy",
        "sequence-level exploratory behaviors",
        "token-level influence patterns",
        "natural language logic connectors",
        "structural syntax",
        "parameter-efficient fine-tuning"
      ]
    },
    "publishedAt": "2025-05-26T09:15:26.000Z",
    "title": "Which Data Attributes Stimulate Math and Code Reasoning? An\n  Investigation via Influence Functions",
    "summary": "Large language models (LLMs) have demonstrated remarkable reasoning\ncapabilities in math and coding, often bolstered by post-training on the\nchain-of-thoughts (CoTs) generated by stronger models. However, existing\nstrategies for curating such training data predominantly rely on heuristics,\nlimiting generalizability and failing to capture subtleties underlying in data.\nTo address these limitations, we leverage influence functions to systematically\nattribute LLMs' reasoning ability on math and coding to individual training\nexamples, sequences, and tokens, enabling deeper insights into effective data\ncharacteristics. Our Influence-based Reasoning Attribution (Infra) uncovers\nnontrivial cross-domain effects across math and coding tasks: high-difficulty\nmath examples improve both math and code reasoning, while low-difficulty code\ntasks most effectively benefit code reasoning. Based on these findings, we\nintroduce a simple yet effective dataset reweighting strategy by flipping task\ndifficulty, which doubles AIME24 accuracy from 10\\% to 20\\% and boosts\nLiveCodeBench accuracy from 33.8\\% to 35.3\\% for Qwen2.5-7B-Instruct. Moreover,\nour fine-grained attribution reveals that the sequence-level exploratory\nbehaviors enhance reasoning performance in both math and code, and the\ntoken-level influence patterns are distinct for math and code reasoning: the\nformer prefers natural language logic connectors and the latter emphasizes\nstructural syntax.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.19949.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "654e330f350abceb30a1390b",
      "avatarUrl": "/avatars/e54a8be788fa1bdc7acefecc208215bb.svg",
      "fullname": "KouSiqi",
      "name": "karrykkk",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 4
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2505.20256",
      "authors": [
        {
          "_id": "68352e44c829f2ea1e0484b5",
          "name": "Hao Zhong",
          "hidden": false
        },
        {
          "_id": "68352e44c829f2ea1e0484b6",
          "name": "Muzhi Zhu",
          "hidden": false
        },
        {
          "_id": "68352e44c829f2ea1e0484b7",
          "name": "Zongze Du",
          "hidden": false
        },
        {
          "_id": "68352e44c829f2ea1e0484b8",
          "name": "Zheng Huang",
          "hidden": false
        },
        {
          "_id": "68352e44c829f2ea1e0484b9",
          "user": {
            "_id": "646efd223dd912a539e0bd46",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/EOFAv5xvOgJOzuDgh4nSb.png",
            "isPro": false,
            "fullname": "Canyu Zhao",
            "user": "Canyu",
            "type": "user"
          },
          "name": "Canyu Zhao",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T07:50:50.579Z",
          "hidden": false
        },
        {
          "_id": "68352e44c829f2ea1e0484ba",
          "name": "Mingyu Liu",
          "hidden": false
        },
        {
          "_id": "68352e44c829f2ea1e0484bb",
          "name": "Wen Wang",
          "hidden": false
        },
        {
          "_id": "68352e44c829f2ea1e0484bc",
          "name": "Hao Chen",
          "hidden": false
        },
        {
          "_id": "68352e44c829f2ea1e0484bd",
          "name": "Chunhua Shen",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-26T17:34:06.000Z",
      "submittedOnDailyAt": "2025-05-27T01:47:33.260Z",
      "title": "Omni-R1: 二システム協力によるオムニモード論理の強化学習",
      "submittedOnDailyBy": {
        "_id": "632179745fc60c44fd91fc33",
        "avatarUrl": "/avatars/37d4fefbcc19f091dccffefec9706de2.svg",
        "isPro": false,
        "fullname": "zhumuzhi",
        "user": "Z-MU-Z",
        "type": "user"
      },
      "summary": "長期ビデオアウディオ推論と細かなピクセル理解が、全視覚モデルに対して相違する要求を課しています：密な時間的カバーは、複数の低解像度フレームを必要としますが、正確なグラウンドリングは高解像度の入力を求めます。私たちは、このトレードオフを二つのシステムアーキテクチャで解決します：Global Reasoning Systemは情報のあるキーフレームを選択し、空間的コストでタスクを改編しますが、Detail Understanding Systemは選択された高解像度のスニペットにピクセルレベルのグラウンドリングを行います。「最適」なキーフレーム選択と改編は不明確で規範的であり、これらを学習させることは難しいため、私たちは、Group Relative Policy Optimizationによる端末からの強化学習（RL）問題にして、Omni-R1を提案します。Omni-R1は、Detail Understanding Systemとのオンライン協力によって得られるスタイアップ報酬を用いてGlobal Reasoning Systemを学習させ、小さなタスク分割において一エポックのRLで学習するだけです。\n\nReferring Audio-Visual Segmentation（RefAVS）とReasoning Video Object Segmentation（REVOS）の2つの難しいベンチマークに対する実験は、Omni-R1は強制学習ベースラインティングを超え、専門的な最先端モデルを超え、ディスクリミネーションの拡大と多模態のハロウィングを抑えることで、より強力な性能を示します。私たちの結果は、RLを大規模な全視覚推論に最初に成功にさせた事実を示し、拡張可能なパスを示します。",
      "upvotes": 11,
      "discussionId": "68352e47c829f2ea1e048539",
      "projectPage": "https://aim-uofa.github.io/OmniR1/",
      "githubRepo": "https://github.com/aim-uofa/Omni-R1",
      "ai_summary": "An end-to-end reinforcement learning framework, Omni-R1, achieves superior performance in long-horizon video-audio reasoning and fine-grained pixel understanding tasks by combining global reasoning and detail understanding systems.",
      "ai_keywords": [
        "reinforcement learning",
        "Group Relative Policy Optimization",
        "hierarchical rewards",
        "Referring Audio-Visual Segmentation",
        "Reasoning Video Object Segmentation",
        "out-of-domain generalization",
        "multimodal hallucination",
        "universally foundation models"
      ]
    },
    "publishedAt": "2025-05-26T13:34:06.000Z",
    "title": "Omni-R1: Reinforcement Learning for Omnimodal Reasoning via Two-System\n  Collaboration",
    "summary": "Long-horizon video-audio reasoning and fine-grained pixel understanding\nimpose conflicting requirements on omnimodal models: dense temporal coverage\ndemands many low-resolution frames, whereas precise grounding calls for\nhigh-resolution inputs. We tackle this trade-off with a two-system\narchitecture: a Global Reasoning System selects informative keyframes and\nrewrites the task at low spatial cost, while a Detail Understanding System\nperforms pixel-level grounding on the selected high-resolution snippets.\nBecause ``optimal'' keyframe selection and reformulation are ambiguous and hard\nto supervise, we formulate them as a reinforcement learning (RL) problem and\npresent Omni-R1, an end-to-end RL framework built on Group Relative Policy\nOptimization. Omni-R1 trains the Global Reasoning System through hierarchical\nrewards obtained via online collaboration with the Detail Understanding System,\nrequiring only one epoch of RL on small task splits.\n  Experiments on two challenging benchmarks, namely Referring Audio-Visual\nSegmentation (RefAVS) and Reasoning Video Object Segmentation (REVOS), show\nthat Omni-R1 not only surpasses strong supervised baselines but also\noutperforms specialized state-of-the-art models, while substantially improving\nout-of-domain generalization and mitigating multimodal hallucination. Our\nresults demonstrate the first successful application of RL to large-scale\nomnimodal reasoning and highlight a scalable path toward universally foundation\nmodels.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.20256.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "632179745fc60c44fd91fc33",
      "avatarUrl": "/avatars/37d4fefbcc19f091dccffefec9706de2.svg",
      "fullname": "zhumuzhi",
      "name": "Z-MU-Z",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 3
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2505.19788",
      "authors": [
        {
          "_id": "68352630363d6fd2fff5d07f",
          "name": "Zihao Zeng",
          "hidden": false
        },
        {
          "_id": "68352630363d6fd2fff5d080",
          "user": {
            "_id": "6721dacfc5309c08451d21d5",
            "avatarUrl": "/avatars/ac8be5ac8b8ee5b5533214e526b72dad.svg",
            "isPro": false,
            "fullname": "Huang Xuyao",
            "user": "ElysiaTrue",
            "type": "user"
          },
          "name": "Xuyao Huang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T07:51:44.216Z",
          "hidden": false
        },
        {
          "_id": "68352630363d6fd2fff5d081",
          "name": "Boxiu Li",
          "hidden": false
        },
        {
          "_id": "68352630363d6fd2fff5d082",
          "name": "Hao Zhang",
          "hidden": false
        },
        {
          "_id": "68352630363d6fd2fff5d083",
          "name": "Zhijie Deng",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-26T10:18:57.000Z",
      "submittedOnDailyAt": "2025-05-27T01:59:02.853Z",
      "title": "完了より完全なものよりも良い：構造化された多段階分解による効率的な理由の解放",
      "submittedOnDailyBy": {
        "_id": "6721dacfc5309c08451d21d5",
        "avatarUrl": "/avatars/ac8be5ac8b8ee5b5533214e526b72dad.svg",
        "isPro": false,
        "fullname": "Huang Xuyao",
        "user": "ElysiaTrue",
        "type": "user"
      },
      "summary": "大論理モデル（LRMs）は、最終的な答えを得るために過度に長いChain-of-Thought（CoT）を使用し、最初のトークンと全体の遅延が高いことで批判されています。通常、LRMsのCoTは複数の思い出単位を混ぜています。各単位は元のクエリに対して候補の答えを生成しようとしています。そこで、効率を向上させる自然なアイデアは、単位の数を減らすことです。しかし、ベージャーのCoTでは思い出単位は明記的に管理できないことにより、これを難しくすることになります。本論文では、Multi-Turn Decomposition（MinD）を導入し、単一のCoTを明記的な、構造化された、ターンごとの相互作用の列に変換し、この間違いを埋めることを目指します。MinDでは、モデルはクエリに対してマルチターンの回答を提供し、各ターンには思い出単位が含まれ、相應する答えを出すことができます。後続のターンは、前回の思い出と答えの両方に対して反省、検証、修正または代替的手法を探索することができます。これは答えをより早く提供することを可能にし、イテレーション的な論理プロセスを明記的に制御することもできます（例えば、ユーザーはどのターンでも停止または続行することができます）。私たちは、SFT（Supervised Fine-Tuning）を後にRL（Reinforcement Learning）パラダイムを適用してMinDを実現します。まず、LRMの出力をマルチターンの形式にリプライズするために、他のLLMをプロンプトし、そのデータでLRMを調整します。調整されたモデルが元のモデルよりももっとトークンを使用することを見出し、その理由は多くのトークンを追加したマルチターンの形式ができるかもしれないことによることを主張しています。GRPO（Generalized Proximal Policy Optimization）などのRLアルゴリズムを利用して、少ないターンで正しい出力を優先することを主張しています。MATHデータセットを用いてR1-Distillモデルで訓練されたMinDは、出力トークンの使用量と最初のトークンの時間（TTFT）を約70%減少させ、MATH-500、AIME24、AMC23、GPQA-Diamondなどの論理ベンチマークで優れた性能を維持することができます。",
      "upvotes": 11,
      "discussionId": "68352631363d6fd2fff5d0b9",
      "ai_summary": "Multi-Turn Decomposition improves efficiency in large reasoning models by breaking down chain-of-thought into manageable turns, reducing token usage and latency while maintaining performance.",
      "ai_keywords": [
        "Chain-of-Thought",
        "large reasoning models",
        "multi-turn decomposition",
        "thinking units",
        "iterative reasoning process",
        "supervised fine-tuning",
        "reinforcement learning",
        "MATH dataset",
        "R1-Distill models",
        "MATH-500",
        "AIME24",
        "AMC23",
        "GPQA-Diamond"
      ]
    },
    "publishedAt": "2025-05-26T06:18:57.000Z",
    "title": "Done Is Better than Perfect: Unlocking Efficient Reasoning by Structured\n  Multi-Turn Decomposition",
    "summary": "Large Reasoning Models (LRMs) are criticized for the excessively lengthy\nChain-of-Thought (CoT) to derive the final answer, suffering from high\nfirst-token and overall latency. Typically, the CoT of LRMs mixes multiple\nthinking units; each unit attempts to produce a candidate answer to the\noriginal query. Hence, a natural idea to improve efficiency is to reduce the\nunit number. Yet, the fact that the thinking units in vanilla CoT cannot be\nexplicitly managed renders doing so challenging. This paper introduces\nMulti-Turn Decomposition (MinD) to decode conventional CoT into a sequence of\nexplicit, structured, and turn-wise interactions to bridge the gap. In MinD,\nthe model provides a multi-turn response to the query, where each turn embraces\na thinking unit and yields a corresponding answer. The subsequent turns can\nreflect, verify, revise, or explore alternative approaches to both the thinking\nand answer parts of earlier ones. This not only makes the answer delivered more\nswiftly, but also enables explicit controls over the iterative reasoning\nprocess (i.e., users may halt or continue at any turn). We follow a supervised\nfine-tuning (SFT) then reinforcement learning (RL) paradigm to realize MinD. We\nfirst rephrase the outputs of an LRM into multi-turn formats by prompting\nanother LLM, and then tune the LRM with such data. Observing that the tuned\nmodel tends to consume even more tokens than the original one (probably due to\nthat the multi-turn formats introduce additional answer tokens), we advocate\nleveraging RL algorithms like GRPO to prioritize correct outputs with fewer\nturns. Trained on the MATH dataset using R1-Distill models, MinD can achieve up\nto ~70% reduction in both output token usage and time to first token (TTFT),\nwhile maintaining competitive performance on reasoning benchmarks such as\nMATH-500, AIME24, AMC23, and GPQA-Diamond.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.19788.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6721dacfc5309c08451d21d5",
      "avatarUrl": "/avatars/ac8be5ac8b8ee5b5533214e526b72dad.svg",
      "fullname": "Huang Xuyao",
      "name": "ElysiaTrue",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.19752",
      "authors": [
        {
          "_id": "683527ba3762eb8b3ea1de34",
          "user": {
            "_id": "62649e2b1ed8d81e47ad9b4e",
            "avatarUrl": "/avatars/f33a0b727822fd2ea99dce37fbda3d17.svg",
            "isPro": false,
            "fullname": "Li",
            "user": "henry12348",
            "type": "user"
          },
          "name": "Hengli Li",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T07:51:37.403Z",
          "hidden": false
        },
        {
          "_id": "683527ba3762eb8b3ea1de35",
          "user": {
            "_id": "60b9e6837946aff342f734ae",
            "avatarUrl": "/avatars/a711a6aa35757dfd7b78b26098a964fc.svg",
            "isPro": false,
            "fullname": "Yuxuan Wang",
            "user": "ColorfulAI",
            "type": "user"
          },
          "name": "Yuxuan Wang",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-05-27T02:47:22.991Z",
          "hidden": false
        },
        {
          "_id": "683527ba3762eb8b3ea1de36",
          "name": "Song-Chun Zhu",
          "hidden": false
        },
        {
          "_id": "683527ba3762eb8b3ea1de37",
          "name": "Ying Nian Wu",
          "hidden": false
        },
        {
          "_id": "683527ba3762eb8b3ea1de38",
          "user": {
            "_id": "63a95a6a7930fa8c7dd63d4e",
            "avatarUrl": "/avatars/d9d0420f7ddfe2f3a7e029fb05f1c89f.svg",
            "isPro": false,
            "fullname": "Zilong Zheng",
            "user": "zlzheng",
            "type": "user"
          },
          "name": "Zilong Zheng",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-05-27T02:47:22.991Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-26T09:32:12.000Z",
      "submittedOnDailyAt": "2025-05-27T01:18:56.411Z",
      "title": "離散マルコフ橋",
      "submittedOnDailyBy": {
        "_id": "62649e2b1ed8d81e47ad9b4e",
        "avatarUrl": "/avatars/f33a0b727822fd2ea99dce37fbda3d17.svg",
        "isPro": false,
        "fullname": "Li",
        "user": "henry12348",
        "type": "user"
      },
      "summary": "離散ディフュージョンは最近離散データモデリングの中で望ましいパラダイムとして現れてきました。しかし、現在の方法は通常学習時に固定したレートの遷移行列を利用しています。これは、変分方法の基本的な強さである潜在表現の表現力を制限し、全体の設計空間を制限しています。これらの制限を解決するために、Discrete Markov Bridgeという新しいフレームワークを提案します。このフレームワークは特に離散表現学習に設計されています。私たちのアプローチはMatrix LearningとScore Learningの2つのキーコンポーネントに基づいて構築されています。厳密な理論的な分析を行い、Matrix Learningの正式な性能保証を立て、全体のフレームワークの収束を証明しました。また、先行研究で明らかにされた実用的な制約に対応し、本方法の空間複雑さを分析しました。拡張的な実験評価は、提案されたDiscrete Markov Bridgeの効果性を証明し、Text8データセットでは確率下限（ELBO）1.38を達成し、既存のベースラインを超えました。また、提案されたモデルはCIFAR-10データセットでも比較的な性能を示し、画像特化された生成アプローチによる結果と比較的な結果を得ました。",
      "upvotes": 11,
      "discussionId": "683527bb3762eb8b3ea1de6c",
      "projectPage": "https://github.com/Henry839/Discrete-Markov-Bridge/tree/main",
      "githubRepo": "https://github.com/Henry839/Discrete-Markov-Bridge/tree/main",
      "ai_summary": "A novel framework, Discrete Markov Bridge, is introduced for discrete data modeling with Matrix Learning and Score Learning components, demonstrating superior performance compared to existing methods on Text8 and CIFAR-10 datasets.",
      "ai_keywords": [
        "discrete diffusion",
        "variational methods",
        "Discrete Markov Bridge",
        "Matrix Learning",
        "Score Learning",
        "Evidence Lower Bound",
        "ELBO"
      ]
    },
    "publishedAt": "2025-05-26T05:32:12.000Z",
    "title": "Discrete Markov Bridge",
    "summary": "Discrete diffusion has recently emerged as a promising paradigm in discrete\ndata modeling. However, existing methods typically rely on a fixed rate\ntransition matrix during training, which not only limits the expressiveness of\nlatent representations, a fundamental strength of variational methods, but also\nconstrains the overall design space. To address these limitations, we propose\nDiscrete Markov Bridge, a novel framework specifically designed for discrete\nrepresentation learning. Our approach is built upon two key components: Matrix\nLearning and Score Learning. We conduct a rigorous theoretical analysis,\nestablishing formal performance guarantees for Matrix Learning and proving the\nconvergence of the overall framework. Furthermore, we analyze the space\ncomplexity of our method, addressing practical constraints identified in prior\nstudies. Extensive empirical evaluations validate the effectiveness of the\nproposed Discrete Markov Bridge, which achieves an Evidence Lower Bound (ELBO)\nof 1.38 on the Text8 dataset, outperforming established baselines. Moreover,\nthe proposed model demonstrates competitive performance on the CIFAR-10\ndataset, achieving results comparable to those obtained by image-specific\ngeneration approaches.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.19752.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "62649e2b1ed8d81e47ad9b4e",
      "avatarUrl": "/avatars/f33a0b727822fd2ea99dce37fbda3d17.svg",
      "fullname": "Li",
      "name": "henry12348",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.20152",
      "authors": [
        {
          "_id": "6835385ebd4d4208167d15ac",
          "name": "Kai Sun",
          "hidden": false
        },
        {
          "_id": "6835385ebd4d4208167d15ad",
          "name": "Yushi Bai",
          "hidden": false
        },
        {
          "_id": "6835385ebd4d4208167d15ae",
          "name": "Zhen Yang",
          "hidden": false
        },
        {
          "_id": "6835385ebd4d4208167d15af",
          "name": "Jiajie Zhang",
          "hidden": false
        },
        {
          "_id": "6835385ebd4d4208167d15b0",
          "name": "Ji Qi",
          "hidden": false
        },
        {
          "_id": "6835385ebd4d4208167d15b1",
          "name": "Lei Hou",
          "hidden": false
        },
        {
          "_id": "6835385ebd4d4208167d15b2",
          "name": "Juanzi Li",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-26T15:55:28.000Z",
      "submittedOnDailyAt": "2025-05-27T02:29:13.927Z",
      "title": "硬負対比較学習による大規模多モデルでの細かい幾何的理解",
      "submittedOnDailyBy": {
        "_id": "66cdd285c51a915bd5f2d017",
        "avatarUrl": "/avatars/14e5794307e4672b1b51d26b31227e0f.svg",
        "isPro": false,
        "fullname": "Jiajie Zhang",
        "user": "NeoZ123",
        "type": "user"
      },
      "summary": "バニフィングサイズの大規模な自然スケーン画像上で対比的に訓練された視覚エンコーダーを利用して、大規模多タイプモデル（LMMs）は多様な視覚認識タスクで驚異的な性能を収めました。しかし、対比学習が要約された説明に対しての固有の制限は、細かい推理の能力を本質的に制限し、特に幾何問題解決の重要なシナリオでの効果を限定しています。幾何的理解を向上させるために、我々は、図形生成コードによる生成ベースの難易度の高い負例と、変更された幾何説明からのルールベースの負例と、キャプション類似度に基づく検索ベースの負例を用いた画像ベースと文脈ベースの対比的学習を組み合わせた新しい難易度の高い負例対比的学習フレームワークを提案します。我々は、この強力な負例学習方法を用いてCLIPを訓練し、後に幾何問題解決に向けたLMMを訓練します。実験は、我々の訓練モデルMMGeoLMは3つの幾何推理ベンチマーク上で他の開放ソースモデルを大幅に上回りました。サイズが7Bでも、GPT-4oといった強力なクローズドソースモデルと対抗できます。また、異なる負例サンプル構築方法と負例サンプルの数値がLMMの幾何推理性能に与える影響を進一歩研究し、豊かな結論を得ました。コードとデータセットは、https://github.com/THU-KEG/MMGeoLMに公開されています。",
      "upvotes": 10,
      "discussionId": "6835385fbd4d4208167d15f0",
      "ai_summary": "A novel hard negative contrastive learning framework improves geometric reasoning in Large Multimodal Models, significantly enhancing their performance compared to existing models.",
      "ai_keywords": [
        "contrastively trained visual encoders",
        "Large Multimodal Models",
        "geometric problem-solving",
        "hard negative contrastive learning",
        "generation-based hard negatives",
        "rule-based negatives",
        "retrieval-based negatives",
        "CLIP",
        "MMCLIP",
        "multimodal math clip",
        "MMGeoLM",
        "geometric reasoning benchmarks"
      ]
    },
    "publishedAt": "2025-05-26T11:55:28.000Z",
    "title": "Hard Negative Contrastive Learning for Fine-Grained Geometric\n  Understanding in Large Multimodal Models",
    "summary": "Benefiting from contrastively trained visual encoders on large-scale natural\nscene images, Large Multimodal Models (LMMs) have achieved remarkable\nperformance across various visual perception tasks. However, the inherent\nlimitations of contrastive learning upon summarized descriptions fundamentally\nrestrict the capabilities of models in meticulous reasoning, particularly in\ncrucial scenarios of geometric problem-solving. To enhance geometric\nunderstanding, we propose a novel hard negative contrastive learning framework\nfor the vision encoder, which combines image-based contrastive learning using\ngeneration-based hard negatives created by perturbing diagram generation code,\nand text-based contrastive learning using rule-based negatives derived from\nmodified geometric descriptions and retrieval-based negatives selected based on\ncaption similarity. We train CLIP using our strong negative learning method,\nnamely MMCLIP (Multimodal Math CLIP), and subsequently train an LMM for\ngeometric problem-solving. Experiments show that our trained model, MMGeoLM,\nsignificantly outperforms other open-source models on three geometric reasoning\nbenchmarks. Even with a size of 7B, it can rival powerful closed-source models\nlike GPT-4o. We further study the impact of different negative sample\nconstruction methods and the number of negative samples on the geometric\nreasoning performance of LMM, yielding fruitful conclusions. The code and\ndataset are available at https://github.com/THU-KEG/MMGeoLM.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.20152.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "66cdd285c51a915bd5f2d017",
      "avatarUrl": "/avatars/14e5794307e4672b1b51d26b31227e0f.svg",
      "fullname": "Jiajie Zhang",
      "name": "NeoZ123",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2505.18759",
      "authors": [
        {
          "_id": "683551c54f3166e8677b43bb",
          "name": "Ruichen Zhang",
          "hidden": false
        },
        {
          "_id": "683551c54f3166e8677b43bc",
          "name": "Rana Muhammad Shahroz Khan",
          "hidden": false
        },
        {
          "_id": "683551c54f3166e8677b43bd",
          "name": "Zhen Tan",
          "hidden": false
        },
        {
          "_id": "683551c54f3166e8677b43be",
          "user": {
            "_id": "6474e1afb68461d5cf7c41cc",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6474e1afb68461d5cf7c41cc/bcoiD_qPrjHUBlB259djg.png",
            "isPro": false,
            "fullname": "Dawei Li",
            "user": "wjldw",
            "type": "user"
          },
          "name": "Dawei Li",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T07:49:14.749Z",
          "hidden": false
        },
        {
          "_id": "683551c54f3166e8677b43bf",
          "name": "Song Wang",
          "hidden": false
        },
        {
          "_id": "683551c54f3166e8677b43c0",
          "name": "Tianlong Chen",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-24T15:54:19.000Z",
      "submittedOnDailyAt": "2025-05-27T04:17:34.631Z",
      "title": "効率的な理由の探求：データセンタリックベンチマークとCoTの結合",
      "submittedOnDailyBy": {
        "_id": "6474e1afb68461d5cf7c41cc",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6474e1afb68461d5cf7c41cc/bcoiD_qPrjHUBlB259djg.png",
        "isPro": false,
        "fullname": "Dawei Li",
        "user": "wjldw",
        "type": "user"
      },
      "summary": "データ中心的な煉熱、データアュメンテーション、選択、混合を含む、小さくなり、より効率的な学生の大規模言語モデル（LLMs）を作成するための有望な道筋を提供します。しかし、それぞれの煉熱アプローチの効果をシステマティックに評価するための詳細なベンチマークはまだ存在しません。本論文では、Chain-of-Thought（CoT）煉熱のデータ操作を方法、モデル、データの3つの角度から調査する最初のデータ中心的なベンチマークDC-CoTを介して、効果を評価することを目的とします。多様な教師モデル（例：o4-mini、Gemini-Pro、Claude-3.5）と学生アーキテクチャ（例：3B、7Bパラメータ）を使用し、複数の理由データセットでの学生モデルの性能に対するこれらのデータ操作の影響を厳密に評価します。特に、分布内（IID）と分布外（OOD）の一般化、データ領域の移行を焦点とします。我々の見つけた結果は、データ中心的な手法を用いたCoT煉熱の最適化による行動可能なインサイトと最善の実践を提供することを目的とし、よりアクセス可能で能力のある理由モデルの開発を促進することを目指します。データはhttps://huggingface.co/datasets/rana-shahroz/DC-COTに見つかり、コードはhttps://anonymous.4open.science/r/DC-COT-FF4C/に共有されています。",
      "upvotes": 10,
      "discussionId": "683551c64f3166e8677b4424",
      "ai_summary": "DC-CoT provides a comprehensive benchmark for assessing data-centric distillation techniques in chain-of-thought distillation, focusing on performance and generalization across different models and datasets.",
      "ai_keywords": [
        "data-centric distillation",
        "data augmentation",
        "data selection",
        "data mixing",
        "chain-of-thought (CoT)",
        "in-distribution (IID)",
        "out-of-distribution (OOD)",
        "cross-domain transfer"
      ]
    },
    "publishedAt": "2025-05-24T11:54:19.000Z",
    "title": "The Quest for Efficient Reasoning: A Data-Centric Benchmark to CoT\n  Distillation",
    "summary": "Data-centric distillation, including data augmentation, selection, and\nmixing, offers a promising path to creating smaller, more efficient student\nLarge Language Models (LLMs) that retain strong reasoning abilities. However,\nthere still lacks a comprehensive benchmark to systematically assess the effect\nof each distillation approach. This paper introduces DC-CoT, the first\ndata-centric benchmark that investigates data manipulation in chain-of-thought\n(CoT) distillation from method, model and data perspectives. Utilizing various\nteacher models (e.g., o4-mini, Gemini-Pro, Claude-3.5) and student\narchitectures (e.g., 3B, 7B parameters), we rigorously evaluate the impact of\nthese data manipulations on student model performance across multiple reasoning\ndatasets, with a focus on in-distribution (IID) and out-of-distribution (OOD)\ngeneralization, and cross-domain transfer. Our findings aim to provide\nactionable insights and establish best practices for optimizing CoT\ndistillation through data-centric techniques, ultimately facilitating the\ndevelopment of more accessible and capable reasoning models. The dataset can be\nfound at https://huggingface.co/datasets/rana-shahroz/DC-COT, while our code is\nshared in https://anonymous.4open.science/r/DC-COT-FF4C/.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.18759.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "6474e1afb68461d5cf7c41cc",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6474e1afb68461d5cf7c41cc/bcoiD_qPrjHUBlB259djg.png",
      "fullname": "Dawei Li",
      "name": "wjldw",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.19602",
      "authors": [
        {
          "_id": "6835239e7309025530c85ba3",
          "user": {
            "_id": "6540ef0e733c1ce6a6fc989a",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6540ef0e733c1ce6a6fc989a/lyDLbmJ-h4nUmkWZCvWtg.jpeg",
            "isPro": false,
            "fullname": "Kunjun Li",
            "user": "stargazerx0",
            "type": "user"
          },
          "name": "Kunjun Li",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T07:51:58.885Z",
          "hidden": false
        },
        {
          "_id": "6835239e7309025530c85ba4",
          "name": "Zigeng Chen",
          "hidden": false
        },
        {
          "_id": "6835239e7309025530c85ba5",
          "name": "Cheng-Yen Yang",
          "hidden": false
        },
        {
          "_id": "6835239e7309025530c85ba6",
          "name": "Jenq-Neng Hwang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-26T07:11:42.000Z",
      "submittedOnDailyAt": "2025-05-27T01:00:44.064Z",
      "title": "メモリ効率的な可視的自動復元モデリングにおけるスケール適応KVキャッシュ縮小",
      "submittedOnDailyBy": {
        "_id": "65811eeaa2284a018e51f1ba",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/dH8UZj6Kk5HJkI1DItCNm.jpeg",
        "isPro": true,
        "fullname": "Zigeng Chen",
        "user": "Zigeng",
        "type": "user"
      },
      "summary": "Visual Autoregressive (VAR)モデリングは、次世代予測アプローチにより、効率性、スケーラビリティ、ゼロショットジェネレーションにおいて大幅な向上を収め、その間で注目を集めています。しかし、VARにおける固有の粗略から細かい手法は、推論時にKVキャッシュの指数的な増大を帯び、相当なメモリ消費と計算冗長を招くことになります。これらのボトルネックに対処するために、私たちは、VARアーキテクチャに適した新しいKVキャッシュ圧縮フレームワーク、ScaleKVを紹介します。ScaleKVは、Transformerレイヤー間の異なるキャッシュ要求と、異なるスケールで異なる注意パターンの2つの重要な観察から構築されています。これらのフィードバックに基づいて、ScaleKVはTransformerレイヤーを2つの機能グループに分類します：ディライターとリファイナー。ディライターは、複数のスケールで分散的な注意を示し、より大きなキャッシュ容量を必要とします。一方で、リファイナーは現在のトークンマップに注意を集中し、局所的な詳細を処理するため、大幅に減少されたキャッシュ容量を必要とします。ScaleKVは、スケール特有のディライターとリファイナーを識別し、各スケールに合わせた差異化キャッシュ管理を実現するための多スケール推論プイプラインを最適化します。最先端の文から画像へのVARモデルフamiliy、Infinityに対する評価により、私たちのアプローチは、画素レベルの忠実性を維持する同時に必要なKVキャッシュメモリを10%に抑えることができることを示します。",
      "upvotes": 9,
      "discussionId": "683523a07309025530c85c45",
      "ai_summary": "ScaleKV compresses the KV cache in Visual Autoregressive models by differentiating drafters and refiners across transformer layers, reducing memory consumption while maintaining high fidelity.",
      "ai_keywords": [
        "Visual Autoregressive",
        "VAR",
        "KV cache",
        "transformer layers",
        "drafters",
        "refiners",
        "memory consumption",
        "Infinity",
        "pixel-level fidelity"
      ]
    },
    "publishedAt": "2025-05-26T03:11:42.000Z",
    "title": "Memory-Efficient Visual Autoregressive Modeling with Scale-Aware KV\n  Cache Compression",
    "summary": "Visual Autoregressive (VAR) modeling has garnered significant attention for\nits innovative next-scale prediction approach, which yields substantial\nimprovements in efficiency, scalability, and zero-shot generalization.\nNevertheless, the coarse-to-fine methodology inherent in VAR results in\nexponential growth of the KV cache during inference, causing considerable\nmemory consumption and computational redundancy. To address these bottlenecks,\nwe introduce ScaleKV, a novel KV cache compression framework tailored for VAR\narchitectures. ScaleKV leverages two critical observations: varying cache\ndemands across transformer layers and distinct attention patterns at different\nscales. Based on these insights, ScaleKV categorizes transformer layers into\ntwo functional groups: drafters and refiners. Drafters exhibit dispersed\nattention across multiple scales, thereby requiring greater cache capacity.\nConversely, refiners focus attention on the current token map to process local\ndetails, consequently necessitating substantially reduced cache capacity.\nScaleKV optimizes the multi-scale inference pipeline by identifying\nscale-specific drafters and refiners, facilitating differentiated cache\nmanagement tailored to each scale. Evaluation on the state-of-the-art\ntext-to-image VAR model family, Infinity, demonstrates that our approach\neffectively reduces the required KV cache memory to 10% while preserving\npixel-level fidelity.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.19602.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "65811eeaa2284a018e51f1ba",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/dH8UZj6Kk5HJkI1DItCNm.jpeg",
      "fullname": "Zigeng Chen",
      "name": "Zigeng",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 5
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2505.19590",
      "authors": [
        {
          "_id": "683523bcb0f9c65224abd710",
          "user": {
            "_id": "6275a465597c70eb8949fce5",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6275a465597c70eb8949fce5/ph4UogqMurMB0hSXZC38w.png",
            "isPro": false,
            "fullname": "Xuandong Zhao",
            "user": "Xuandong",
            "type": "user"
          },
          "name": "Xuandong Zhao",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T07:51:51.514Z",
          "hidden": false
        },
        {
          "_id": "683523bcb0f9c65224abd711",
          "name": "Zhewei Kang",
          "hidden": false
        },
        {
          "_id": "683523bcb0f9c65224abd712",
          "name": "Aosong Feng",
          "hidden": false
        },
        {
          "_id": "683523bcb0f9c65224abd713",
          "name": "Sergey Levine",
          "hidden": false
        },
        {
          "_id": "683523bcb0f9c65224abd714",
          "name": "Dawn Song",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-26T07:01:06.000Z",
      "submittedOnDailyAt": "2025-05-27T01:00:44.089Z",
      "title": "学習する理由を外部的な報酬によらず",
      "submittedOnDailyBy": {
        "_id": "6275a465597c70eb8949fce5",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6275a465597c70eb8949fce5/ph4UogqMurMB0hSXZC38w.png",
        "isPro": false,
        "fullname": "Xuandong Zhao",
        "user": "Xuandong",
        "type": "user"
      },
      "summary": "大語言モデル（LLMs）の複雑な理由論を強化学習によって学習する方法は、有効ですが、コスト高い、領域特有のステラバンの依存関係によって制限されています。我々は、外部レベルやラベルデータを必要としないLLMsが内在的な信号から学習することを可能にするReinforcement Learning from Internal Feedback（RLIF）フレームワークについて検討します。IntuitorというRLIFの方法を提案します。Intuitorは、自分自身の信頼性を「自確信」と呼ぶものをそのシンボルレベルとして唯一のレベル信号として使用します。IntuitorはGroup Relative Policy Optimization（GRPO）での外部レベルを自確信スコアに置き換え、完全な無ステラバン学習を可能にします。実験は、Intuitorは数学ベンチマークでGRPOの性能を追い越し、コード生成のような領域外タスクに対してより優れた一般化を実現し、金レベルソリューションやテストケースを必要としないことを示します。我々の発見は、固有のモデル信号が領域拡がりの効果的な学習を駆動することを示し、RLVRに対する可換性のあるスケーラブルな代替として自動プロジェクトのAIシステムでは、可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるスケーラブルな代替として可換性のあるス",
      "upvotes": 8,
      "discussionId": "683523bcb0f9c65224abd736",
      "githubRepo": "https://github.com/sunblaze-ucb/Intuitor",
      "ai_summary": "Intuitor, a Reinforcement Learning from Internal Feedback method, uses self-certainty as a reward signal to enable unsupervised learning of large language models, achieving performance comparable to GRPO on benchmarks and superior generalization.",
      "ai_keywords": [
        "Reinforcement Learning with Verifiable Rewards",
        "Reinforcement Learning from Internal Feedback",
        "Group Relative Policy Optimization",
        "self-certainty",
        "unsupervised learning"
      ]
    },
    "publishedAt": "2025-05-26T03:01:06.000Z",
    "title": "Learning to Reason without External Rewards",
    "summary": "Training large language models (LLMs) for complex reasoning via Reinforcement\nLearning with Verifiable Rewards (RLVR) is effective but limited by reliance on\ncostly, domain-specific supervision. We explore Reinforcement Learning from\nInternal Feedback (RLIF), a framework that enables LLMs to learn from intrinsic\nsignals without external rewards or labeled data. We propose Intuitor, an RLIF\nmethod that uses a model's own confidence, termed self-certainty, as its sole\nreward signal. Intuitor replaces external rewards in Group Relative Policy\nOptimization (GRPO) with self-certainty scores, enabling fully unsupervised\nlearning. Experiments demonstrate that Intuitor matches GRPO's performance on\nmathematical benchmarks while achieving superior generalization to\nout-of-domain tasks like code generation, without requiring gold solutions or\ntest cases. Our findings show that intrinsic model signals can drive effective\nlearning across domains, offering a scalable alternative to RLVR for autonomous\nAI systems where verifiable rewards are unavailable. Code is available at\nhttps://github.com/sunblaze-ucb/Intuitor",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.19590.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6275a465597c70eb8949fce5",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6275a465597c70eb8949fce5/ph4UogqMurMB0hSXZC38w.png",
      "fullname": "Xuandong Zhao",
      "name": "Xuandong",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.16972",
      "authors": [
        {
          "_id": "68351e269f4e0a0f048ea664",
          "name": "Tianduo Wang",
          "hidden": false
        },
        {
          "_id": "68351e269f4e0a0f048ea665",
          "name": "Lu Xu",
          "hidden": false
        },
        {
          "_id": "68351e269f4e0a0f048ea666",
          "name": "Wei Lu",
          "hidden": false
        },
        {
          "_id": "68351e269f4e0a0f048ea667",
          "name": "Shanbo Cheng",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-22T17:51:05.000Z",
      "submittedOnDailyAt": "2025-05-27T00:36:56.992Z",
      "title": "テンズオフォーハーズトゥテンズオフォーウィンドズ: スピーチ認識のためのバックトレンス転訳のスケーリング",
      "submittedOnDailyBy": {
        "_id": "6352aa7b6cfb8f149814de5e",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1666361939036-noauth.jpeg",
        "isPro": false,
        "fullname": "Tianduo Wang",
        "user": "Tianduo",
        "type": "user"
      },
      "summary": "最近の言語認識（ASR）の進展は、巨大な言語コーパスによって主に促進されています。しかし、資源が限られた多様な言語におけるカバーを拡大することは厳しい挑戦です。本論文では、スペースブックトレンス（Speech Back-Translation）というスケーラブルなパイプラインを介して、オフショットのテキストから声（TTS）モデルを用いて大規模なテキストコーパスを合成的な声に変換し、多言語ASRモデルを改善する方法を紹介します。私たちは、約数十時間の実際の読み上げされた声によってTTSモデルを学習させ、合成的な声の量を元の量の数百倍に増やしながら高い品質を維持することができることを示します。合成的な声の質を評価するために、読解性に基づく評価フレームワークを開発し、合成データがASRの学習に利益を及ぼす時期の明確なステップブールを設定します。スペースブックトレンスを用いて、10言語において50万時間以上の合成的な声を生成し、Whisper-large-v3の追加学習を行い、平均的な読み上げ誤り率の30％以上の減少を達成しました。これらの結果は、スペースブックトレンスが多言語ASRシステムを強化するためのスケーラビリティと効果性を示していることを明らかにしています。",
      "upvotes": 8,
      "discussionId": "68351e279f4e0a0f048ea689",
      "githubRepo": "https://github.com/TianduoWang/Speech-BT",
      "ai_summary": "Speech Back-Translation enhances multilingual ASR systems by generating high-quality synthetic speech from text corpora, significantly reducing transcription errors.",
      "ai_keywords": [
        "Automatic Speech Recognition",
        "Speech Back-Translation",
        "multilingual ASR",
        "text-to-speech",
        "synthetic speech",
        "intelligibility-based assessment",
        "Whisper-large-v3",
        "transcription error reduction"
      ]
    },
    "publishedAt": "2025-05-22T13:51:05.000Z",
    "title": "From Tens of Hours to Tens of Thousands: Scaling Back-Translation for\n  Speech Recognition",
    "summary": "Recent advances in Automatic Speech Recognition (ASR) have been largely\nfueled by massive speech corpora. However, extending coverage to diverse\nlanguages with limited resources remains a formidable challenge. This paper\nintroduces Speech Back-Translation, a scalable pipeline that improves\nmultilingual ASR models by converting large-scale text corpora into synthetic\nspeech via off-the-shelf text-to-speech (TTS) models. We demonstrate that just\ntens of hours of real transcribed speech can effectively train TTS models to\ngenerate synthetic speech at hundreds of times the original volume while\nmaintaining high quality. To evaluate synthetic speech quality, we develop an\nintelligibility-based assessment framework and establish clear thresholds for\nwhen synthetic data benefits ASR training. Using Speech Back-Translation, we\ngenerate more than 500,000 hours of synthetic speech in ten languages and\ncontinue pre-training Whisper-large-v3, achieving average transcription error\nreductions of over 30\\%. These results highlight the scalability and\neffectiveness of Speech Back-Translation for enhancing multilingual ASR\nsystems.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.16972.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6352aa7b6cfb8f149814de5e",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1666361939036-noauth.jpeg",
      "fullname": "Tianduo Wang",
      "name": "Tianduo",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 6
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2505.13426",
      "authors": [
        {
          "_id": "682c641925f124206513d14d",
          "name": "Liang Chen",
          "hidden": false
        },
        {
          "_id": "682c641925f124206513d14e",
          "name": "Hongcheng Gao",
          "hidden": false
        },
        {
          "_id": "682c641925f124206513d14f",
          "name": "Tianyu Liu",
          "hidden": false
        },
        {
          "_id": "682c641925f124206513d150",
          "name": "Zhiqi Huang",
          "hidden": false
        },
        {
          "_id": "682c641925f124206513d151",
          "name": "Flood Sung",
          "hidden": false
        },
        {
          "_id": "682c641925f124206513d152",
          "name": "Xinyu Zhou",
          "hidden": false
        },
        {
          "_id": "682c641925f124206513d153",
          "name": "Yuxin Wu",
          "hidden": false
        },
        {
          "_id": "682c641925f124206513d154",
          "name": "Baobao Chang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-19T17:54:39.000Z",
      "submittedOnDailyAt": "2025-05-27T00:09:52.653Z",
      "title": "G1: 視覚言語モデルの認識と推理能力を強化学習によってスタートアップ",
      "submittedOnDailyBy": {
        "_id": "61b0a4ce1b3d95b3d1ed9251",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/Wwjr26vdudX5KYVTb8Q0a.png",
        "isPro": false,
        "fullname": "Liang Chen",
        "user": "leonardPKU",
        "type": "user"
      },
      "summary": "Vision-Language Models (VLMs)は、複数の直接的多模調タスクで優れていますが、互換的で視覚的に豊富な環境（例：ゲーム）での有効な決策を取ることには難しく、「知ることを行うこと」の間違いが大きく限りをもたらしています。この間違いは、自動転移アガントの潜力を大きく限定しています。リーダーのVLMsは、簡単なゲームでもバズラしています。これに対して、VLM-Gymを紹介します。VLM-Gymは、統一的なインターフェースと可調節的な、組み合わせられた難易度を特徴とした多様な視覚的なゲームを採用したリファーム学習（RL）環境です。VLM-Gymを利用して、G0モデルを純粋なRL駆動の自己進化を通じて訓練し、発見的な視覚的知識と理由論的パターンを示します。ゲームの多様性による課題をさらに軽減するために、G1モデルを開発します。G1は、RL調整の前に視覚知識を強化した初期状態を採用しています。その結果、G1モデルはすべてのゲームでティーチャーを超え、Claude-3.7-Sonnet-Thinkingといったリーダーモデルを上回ります。システマティックな分析から、興味深い発見が明らかになりました。視覚的知識と理由論の能力は、RL訓練プロセス中に相互にボーストしています。VLM-GymとRL訓練を含むソースコードは、https://github.com/chenllliang/G1で公開されており、VLMsを有能な互換的なアガントとして進化させる未来の研究につなぎあっています。",
      "upvotes": 7,
      "discussionId": "682c641a25f124206513d1d5",
      "githubRepo": "https://github.com/chenllliang/G1",
      "ai_summary": "VLM-Gym addresses the \"knowing-doing\" gap in Vision-Language Models by training them in a diverse RL environment, leading to enhanced perception and reasoning abilities that surpass existing models in interactive games.",
      "ai_keywords": [
        "Vision-Language Models",
        "VLM-Gym",
        "reinforcement learning",
        "RL",
        "G0 models",
        "self-evolution",
        "G1 models",
        "perception-enhanced cold start",
        "RL fine-tuning"
      ]
    },
    "publishedAt": "2025-05-19T13:54:39.000Z",
    "title": "G1: Bootstrapping Perception and Reasoning Abilities of Vision-Language\n  Model via Reinforcement Learning",
    "summary": "Vision-Language Models (VLMs) excel in many direct multimodal tasks but\nstruggle to translate this prowess into effective decision-making within\ninteractive, visually rich environments like games. This ``knowing-doing'' gap\nsignificantly limits their potential as autonomous agents, as leading VLMs\noften performing badly in simple games. To address this, we introduce VLM-Gym,\na curated reinforcement learning (RL) environment featuring diverse visual\ngames with unified interfaces and adjustable, compositional difficulty,\nspecifically designed for scalable multi-game parallel training. Leveraging\nVLM-Gym, we train G0 models using pure RL-driven self-evolution, which\ndemonstrate emergent perception and reasoning patterns. To further mitigate\nchallenges arising from game diversity, we develop G1 models. G1 incorporates a\nperception-enhanced cold start prior to RL fine-tuning. Our resulting G1 models\nconsistently surpass their teacher across all games and outperform leading\nproprietary models like Claude-3.7-Sonnet-Thinking. Systematic analysis reveals\nan intriguing finding: perception and reasoning abilities mutually bootstrap\neach other throughout the RL training process. Source code including VLM-Gym\nand RL training are released at https://github.com/chenllliang/G1 to foster\nfuture research in advancing VLMs as capable interactive agents.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.13426.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "61b0a4ce1b3d95b3d1ed9251",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/Wwjr26vdudX5KYVTb8Q0a.png",
      "fullname": "Liang Chen",
      "name": "leonardPKU",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 16
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2505.19731",
      "authors": [
        {
          "_id": "683588a1650d51732cab05de",
          "user": {
            "_id": "6262880c5eb4fa93219f0064",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6262880c5eb4fa93219f0064/6yyBvRK4Oh7OhjaaweaVN.jpeg",
            "isPro": false,
            "fullname": "Daniil Tiapkin",
            "user": "dtiapkin",
            "type": "user"
          },
          "name": "Daniil Tiapkin",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T10:03:29.430Z",
          "hidden": false
        },
        {
          "_id": "683588a1650d51732cab05df",
          "name": "Daniele Calandriello",
          "hidden": false
        },
        {
          "_id": "683588a1650d51732cab05e0",
          "name": "Denis Belomestny",
          "hidden": false
        },
        {
          "_id": "683588a1650d51732cab05e1",
          "name": "Eric Moulines",
          "hidden": false
        },
        {
          "_id": "683588a1650d51732cab05e2",
          "name": "Alexey Naumov",
          "hidden": false
        },
        {
          "_id": "683588a1650d51732cab05e3",
          "user": {
            "_id": "629f3b18ee05727ce328ccbe",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1669189789447-629f3b18ee05727ce328ccbe.jpeg",
            "isPro": false,
            "fullname": "Kashif Rasul",
            "user": "kashif",
            "type": "user"
          },
          "name": "Kashif Rasul",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-05-27T09:40:50.326Z",
          "hidden": false
        },
        {
          "_id": "683588a1650d51732cab05e4",
          "user": {
            "_id": "651e97156d92456bdf5ace6b",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/651e97156d92456bdf5ace6b/KKfdZGPAcWPdqycp9SulH.jpeg",
            "isPro": false,
            "fullname": "Michal Valko",
            "user": "misovalko",
            "type": "user"
          },
          "name": "Michal Valko",
          "status": "extracted_confirmed",
          "statusLastChangedAt": "2025-05-27T10:00:09.731Z",
          "hidden": false
        },
        {
          "_id": "683588a1650d51732cab05e5",
          "name": "Pierre Menard",
          "hidden": false
        }
      ],
      "mediaUrls": [
        "https://cdn-uploads.huggingface.co/production/uploads/6262880c5eb4fa93219f0064/F7nWvm2sO5QXTLRnB1k6e.png",
        "https://cdn-uploads.huggingface.co/production/uploads/6262880c5eb4fa93219f0064/Fuzzt-cOiMSOCevLVjkW-.png"
      ],
      "publishedAt": "2025-05-26T09:17:32.000Z",
      "submittedOnDailyAt": "2025-05-27T08:13:23.799Z",
      "title": "Accelerating Nash Learning from Human Feedback via Mirror Prox",
      "submittedOnDailyBy": {
        "_id": "6262880c5eb4fa93219f0064",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6262880c5eb4fa93219f0064/6yyBvRK4Oh7OhjaaweaVN.jpeg",
        "isPro": false,
        "fullname": "Daniil Tiapkin",
        "user": "dtiapkin",
        "type": "user"
      },
      "summary": "強化学習による価値観の学習（RLHF）は、報酬モデルを中心にしていますが、ブラデリー-テリーモデルのような偏好構造を前提としていることが多いですが、実際の人間の複雑な偏好（例えば、不傳遞性）を正確に捉えることは難しいです。ナース学習による価値観の学習（NLHF）は、これらの偏好によるゲームのナース均衡を見つけることを問題として、これらの問題を直接に解決します。本研究では、マイラープロクスの最適化スキームを活用したナースミラープロクス（Nash-MP）のオンラインNLHFアルゴリズムを紹介します。理論的な分析では、Nash-MPは、beta正規化ナース均衡に対して最終的計算の線形収束を示します。特に、最適策に対するKL分散が（1+2beta）^{-N/2}のレートで減少することを示します。また、計算可能性の間違いの間違いとログ確率のスパン半ノルムの統一的な線形収束も示し、これらのレートは行動空間のサイズに依存しません。また、プロクスステップをランダム策勾配を用いて評価した近似版のNash-MPを提案し、アプリケーションに近づけることを試みます。最後に、大規模な言語モデルの微調節の実用的な実装戦略を詳細に説明し、現有手法との相性と強力な性能を示す実験を行います。",
      "upvotes": 5,
      "discussionId": "683588a2650d51732cab0612",
      "ai_summary": "Nash Mirror Prox is an online algorithm for Nash Learning from Human Feedback that achieves linear convergence to the Nash equilibrium and is applicable for fine-tuning language models.",
      "ai_keywords": [
        "Nash Learning from Human Feedback",
        "Nash Mirror Prox",
        "Mirror Prox",
        "KL-divergence",
        "Nash equilibrium",
        "exploitability gap",
        "span semi-norm",
        "log-probabilities",
        "stochastic policy gradients",
        "fine-tuning",
        "large language models"
      ]
    },
    "publishedAt": "2025-05-26T05:17:32.000Z",
    "title": "Accelerating Nash Learning from Human Feedback via Mirror Prox",
    "summary": "Traditional Reinforcement Learning from Human Feedback (RLHF) often relies on\nreward models, frequently assuming preference structures like the Bradley-Terry\nmodel, which may not accurately capture the complexities of real human\npreferences (e.g., intransitivity). Nash Learning from Human Feedback (NLHF)\noffers a more direct alternative by framing the problem as finding a Nash\nequilibrium of a game defined by these preferences. In this work, we introduce\nNash Mirror Prox (Nash-MP), an online NLHF algorithm that leverages\nthe Mirror Prox optimization scheme to achieve fast and stable convergence to\nthe Nash equilibrium. Our theoretical analysis establishes that Nash-MP\nexhibits last-iterate linear convergence towards the beta-regularized Nash\nequilibrium. Specifically, we prove that the KL-divergence to the optimal\npolicy decreases at a rate of order (1+2beta)^{-N/2}, where N is a number\nof preference queries. We further demonstrate last-iterate linear convergence\nfor the exploitability gap and uniformly for the span semi-norm of\nlog-probabilities, with all these rates being independent of the size of the\naction space. Furthermore, we propose and analyze an approximate version of\nNash-MP where proximal steps are estimated using stochastic policy gradients,\nmaking the algorithm closer to applications. Finally, we detail a practical\nimplementation strategy for fine-tuning large language models and present\nexperiments that demonstrate its competitive performance and compatibility with\nexisting methods.",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/6262880c5eb4fa93219f0064/F7nWvm2sO5QXTLRnB1k6e.png",
      "https://cdn-uploads.huggingface.co/production/uploads/6262880c5eb4fa93219f0064/Fuzzt-cOiMSOCevLVjkW-.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.19731.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6262880c5eb4fa93219f0064",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6262880c5eb4fa93219f0064/6yyBvRK4Oh7OhjaaweaVN.jpeg",
      "fullname": "Daniil Tiapkin",
      "name": "dtiapkin",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 4
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.19640",
      "authors": [
        {
          "_id": "68353e3f9f4e0a0f0496d0c6",
          "name": "Roy Xie",
          "hidden": false
        },
        {
          "_id": "68353e3f9f4e0a0f0496d0c7",
          "name": "David Qiu",
          "hidden": false
        },
        {
          "_id": "68353e3f9f4e0a0f0496d0c8",
          "name": "Deepak Gopinath",
          "hidden": false
        },
        {
          "_id": "68353e3f9f4e0a0f0496d0c9",
          "name": "Dong Lin",
          "hidden": false
        },
        {
          "_id": "68353e3f9f4e0a0f0496d0ca",
          "name": "Yanchao Sun",
          "hidden": false
        },
        {
          "_id": "68353e3f9f4e0a0f0496d0cb",
          "name": "Chong Wang",
          "hidden": false
        },
        {
          "_id": "68353e3f9f4e0a0f0496d0cc",
          "name": "Saloni Potdar",
          "hidden": false
        },
        {
          "_id": "68353e3f9f4e0a0f0496d0cd",
          "name": "Bhuwan Dhingra",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-26T07:58:17.000Z",
      "submittedOnDailyAt": "2025-05-27T02:56:39.316Z",
      "title": "インターライブド・レジェンスリング学習による大規模言語モデルの連続的論理",
      "submittedOnDailyBy": {
        "_id": "6555a124a6554059711b58a2",
        "avatarUrl": "/avatars/222bb6b8f252d6c2bbd4cf35a54fc1c9.svg",
        "isPro": false,
        "fullname": "Roy",
        "user": "RRoy233",
        "type": "user"
      },
      "summary": "長い連鎖コンティンユーサイン（CoT）は、大規模言語モデル（LLM）の理由能力を大幅に向上させます。しかし、長い理由トレースは、無駄さと最初のトークの時間（TTFT）の時間が長くなることにより、エフィシェンスを低下させます。私たちは、強化学習（RL）を用いて理由LLMsをコンティンユーサインと回答を交互に行う新しい学習パラダイムを提案します。私たちは、モデルが固有に交互に理由を行う能力を持っていることを観察し、これをさらに強化することが可能であることを確認しました。私たちは、簡単で効果的なルールベースの報酬を導入し、正しい中間ステップを奨励することで、交互に理由を行うことで生成される中間信号を利用して正しい理由パスに向かってポリシーモデルを導くことを示します。5つの多様なデータセットと3つのRLアルゴリズム（PPO、GRPO、REINFORCE++）を通じて行われた拡大調査は、傳統的な考え回答理由に対して統一的な向上を示し、外部ツールの使用は必要とされません。特に、私たちのアプローチは平均でTTFTを80%以上削減し、Pass@1の精度を19.3%まで向上させます。また、私たちの方法は、問題回答と論理理由データセットにだけ学習されたことで、複雑な理由データセット（例：MATH、GPQA、MMLU）に強い一般化能力を示します。また、私たちは、条件付き報酬モデリングについて詳細な分析を行い、数多くの有價値なフィードバックを提供します。",
      "upvotes": 5,
      "discussionId": "68353e409f4e0a0f0496d0fb",
      "ai_summary": "A reinforcement learning-guided training paradigm enhances large language models' reasoning efficiency and performance for multi-hop questions by interleaving thinking and answering.",
      "ai_keywords": [
        "chain-of-thought",
        "large language models",
        "reasoning capabilities",
        "time-to-first-token",
        "reinforcement learning",
        "interleaved reasoning",
        "rule-based reward",
        "reward modeling",
        "multi-hop questions",
        "think-answer reasoning",
        "Pass@1 accuracy",
        "MATH",
        "GPQA",
        "MMLU",
        "PPO",
        "GRPO",
        "REINFORCE++"
      ]
    },
    "publishedAt": "2025-05-26T03:58:17.000Z",
    "title": "Interleaved Reasoning for Large Language Models via Reinforcement\n  Learning",
    "summary": "Long chain-of-thought (CoT) significantly enhances large language models'\n(LLM) reasoning capabilities. However, the extensive reasoning traces lead to\ninefficiencies and an increased time-to-first-token (TTFT). We propose a novel\ntraining paradigm that uses reinforcement learning (RL) to guide reasoning LLMs\nto interleave thinking and answering for multi-hop questions. We observe that\nmodels inherently possess the ability to perform interleaved reasoning, which\ncan be further enhanced through RL. We introduce a simple yet effective\nrule-based reward to incentivize correct intermediate steps, which guides the\npolicy model toward correct reasoning paths by leveraging intermediate signals\ngenerated during interleaved reasoning. Extensive experiments conducted across\nfive diverse datasets and three RL algorithms (PPO, GRPO, and REINFORCE++)\ndemonstrate consistent improvements over traditional think-answer reasoning,\nwithout requiring external tools. Specifically, our approach reduces TTFT by\nover 80% on average and improves up to 19.3% in Pass@1 accuracy. Furthermore,\nour method, trained solely on question answering and logical reasoning\ndatasets, exhibits strong generalization ability to complex reasoning datasets\nsuch as MATH, GPQA, and MMLU. Additionally, we conduct in-depth analysis to\nreveal several valuable insights into conditional reward modeling.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.19640.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6555a124a6554059711b58a2",
      "avatarUrl": "/avatars/222bb6b8f252d6c2bbd4cf35a54fc1c9.svg",
      "fullname": "Roy",
      "name": "RRoy233",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2505.19427",
      "authors": [
        {
          "_id": "683525ac1c31d709ba52273e",
          "name": "Sihan Chen",
          "hidden": false
        },
        {
          "_id": "683525ac1c31d709ba52273f",
          "name": "Dan Zhao",
          "hidden": false
        },
        {
          "_id": "683525ac1c31d709ba522740",
          "name": "Jongwoo Ko",
          "hidden": false
        },
        {
          "_id": "683525ac1c31d709ba522741",
          "name": "Colby Banbury",
          "hidden": false
        },
        {
          "_id": "683525ac1c31d709ba522742",
          "name": "Huiping Zhuang",
          "hidden": false
        },
        {
          "_id": "683525ac1c31d709ba522743",
          "name": "Luming Liang",
          "hidden": false
        },
        {
          "_id": "683525ac1c31d709ba522744",
          "user": {
            "_id": "64ad94f05a4a60156925ec96",
            "avatarUrl": "/avatars/643bdb076e703bfcc89cec6fccb756c6.svg",
            "isPro": false,
            "fullname": "Tianyi Chen",
            "user": "tianyic",
            "type": "user"
          },
          "name": "Tianyi Chen",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T07:51:46.088Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-26T02:37:32.000Z",
      "submittedOnDailyAt": "2025-05-27T01:10:19.909Z",
      "title": "WINA: 重み情報に基づくニューロン活性化による大規模言語モデル推論の加速",
      "submittedOnDailyBy": {
        "_id": "64ad94f05a4a60156925ec96",
        "avatarUrl": "/avatars/643bdb076e703bfcc89cec6fccb756c6.svg",
        "isPro": false,
        "fullname": "Tianyi Chen",
        "user": "tianyic",
        "type": "user"
      },
      "summary": "大語言モデル（LLMs）の計算負担の増加により、効率的な推論と活性化戦略が重要になります。最近のアプローチでは、Mixture-of-Experts（MoE）などが選択的な活性化を利用していますが、これらは特別なトレーニングが必要です。トレーニング不要なスパース活性化方法は、プラグインとプレインプレイの設計で広く適用可能で、資源効率が高いです。しかし、多くの現在の方法は、隠れ状態の大きさだけで活性化を決定し、高い近似誤差と不適切な推論精度を帯びます。これらの制限を解決するために、私たちは、Weight Informed Neuron Activation（WINA）という新しい、簡単な、トレーニング不要なスパース活性化フレームワークを提案します。これは、隠れ状態の大きさと重み行列の列方向のell_2ノルムを併せて考慮します。これにより、理論的な保証で実際の技術より緊密な最適な近似誤差の上限を得るスパーシファイズティング戦略を実現できます。実験的にも、WINAは同じスパーシファイズレベルで、多様なLLMアーキテクチャとデータセットで最先端の方法（例：TEAL）を上回り、平均性能において2.94%以上の改善を収めます。これらの結果は、WINAがLLM推論のトレーニング不要なスパース活性化の新たな性能境界に立ち、トレーニング不要なスパース活性化方法の進展と効率的な推論のベースラインを設定します。ソースコードは、https://github.com/microsoft/wina から利用できます。",
      "upvotes": 5,
      "discussionId": "683525ac1c31d709ba52277c",
      "ai_summary": "WINA, a training-free sparse activation framework for large language models, improves inference accuracy by considering hidden state magnitudes and weight matrix norms, outperforming existing methods.",
      "ai_keywords": [
        "Mixture-of-Experts (MoE)",
        "sparse activation",
        "hidden state magnitudes",
        "column-wise $\\ell_2$-norms",
        "weight matrices",
        "sparsification strategy",
        "approximation error bounds",
        "training-free sparse activation",
        "large language models"
      ]
    },
    "publishedAt": "2025-05-25T22:37:32.000Z",
    "title": "WINA: Weight Informed Neuron Activation for Accelerating Large Language\n  Model Inference",
    "summary": "The growing computational demands of large language models (LLMs) make\nefficient inference and activation strategies increasingly critical. While\nrecent approaches, such as Mixture-of-Experts (MoE), leverage selective\nactivation but require specialized training, training-free sparse activation\nmethods offer broader applicability and superior resource efficiency through\ntheir plug-and-play design. However, many existing methods rely solely on\nhidden state magnitudes to determine activation, resulting in high\napproximation errors and suboptimal inference accuracy. To address these\nlimitations, we propose WINA (Weight Informed Neuron Activation), a novel,\nsimple, and training-free sparse activation framework that jointly considers\nhidden state magnitudes and the column-wise ell_2-norms of weight matrices.\nWe show that this leads to a sparsification strategy that obtains optimal\napproximation error bounds with theoretical guarantees tighter than existing\ntechniques. Empirically, WINA also outperforms state-of-the-art methods (e.g.,\nTEAL) by up to 2.94% in average performance at the same sparsity levels,\nacross a diverse set of LLM architectures and datasets. These results position\nWINA as a new performance frontier for training-free sparse activation in LLM\ninference, advancing training-free sparse activation methods and setting a\nrobust baseline for efficient inference. The source code is available at\nhttps://github.com/microsoft/wina.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.19427.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64ad94f05a4a60156925ec96",
      "avatarUrl": "/avatars/643bdb076e703bfcc89cec6fccb756c6.svg",
      "fullname": "Tianyi Chen",
      "name": "tianyic",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.18822",
      "authors": [
        {
          "_id": "683528d8c682e155a8b9a80f",
          "user": {
            "_id": "64ce05c631c655ff8a2e183c",
            "avatarUrl": "/avatars/f2de7f8a1348b05f46946085e3e9718e.svg",
            "isPro": false,
            "fullname": "Shijue Huang",
            "user": "JoeYing",
            "type": "user"
          },
          "name": "Shijue Huang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T10:03:37.508Z",
          "hidden": false
        },
        {
          "_id": "683528d8c682e155a8b9a810",
          "name": "Hongru Wang",
          "hidden": false
        },
        {
          "_id": "683528d8c682e155a8b9a811",
          "name": "Wanjun Zhong",
          "hidden": false
        },
        {
          "_id": "683528d8c682e155a8b9a812",
          "name": "Zhaochen Su",
          "hidden": false
        },
        {
          "_id": "683528d8c682e155a8b9a813",
          "name": "Jiazhan Feng",
          "hidden": false
        },
        {
          "_id": "683528d8c682e155a8b9a814",
          "name": "Bowen Cao",
          "hidden": false
        },
        {
          "_id": "683528d8c682e155a8b9a815",
          "name": "Yi R. Fung",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-24T18:46:50.000Z",
      "submittedOnDailyAt": "2025-05-27T07:17:54.612Z",
      "title": "AdaCtrl: 難易度に関するバジューディングを通じての適応的および制御可能な理由論のためのアプローチ",
      "submittedOnDailyBy": {
        "_id": "64ce05c631c655ff8a2e183c",
        "avatarUrl": "/avatars/f2de7f8a1348b05f46946085e3e9718e.svg",
        "isPro": false,
        "fullname": "Shijue Huang",
        "user": "JoeYing",
        "type": "user"
      },
      "summary": "現代の大規模な理由論モデルは、複雑な理由論戦略を用いて、印象的な問題解決能力を示しています。しかし、それらは、効率と効果性のバランスを取ることが難しく、簡単な問題でも必要なく長い理由論鍵を生成することがあります。本稿では、AdaCtrlという新しいフレームワークを提案します。これは、難易度に関する自覚的な理由論バジューメントと理由論の深さの明示的なユーザー制御をサポートします。AdaCtrlは、問題の難易度に基づいて理由論の長さを動的に調整し、ユーザーが理由論バジューを手動で制御して効率や効果性の優先を選択できるようになります。これは、2段階の訓練パイプラインで実現されます：最初の冷やめスタートの微調節フェイズで、自覚的な難易度と理由論バジューの調整能力を習得し、次に、難易度に関する強化学習（RL）ステージで、モデルの適応的な理由論戦略を精確化し、ユーザーの難易度評価を調整します。直感的なユーザーインタラクティブモードを促進するために、長さに基づく明示的なタグを設計します。実験結果は、AdaCtrlは評価された難易度に基づいて理由論の長さを変更し、標準の訓練ベースラインと同様に微調節とRLを含む場合に比べ、パフォーマンスの向上を示し、AIME2024とAIME2025データセットでは10.06%と12.14%の回答の長さを削減し、MATH500とGSM8Kデータセットでは62.05%と91.04%の回答の長さを大幅に削減します。また、AdaCtrlは理由論バジューの精密なユーザー制御を可能にし、特定の需要に合わせた回答を提供できます。",
      "upvotes": 5,
      "discussionId": "683528d9c682e155a8b9a852",
      "ai_summary": "AdaCtrl, a novel framework, dynamically adjusts reasoning length based on problem difficulty and user control, improving performance and reducing response length across various datasets compared to standard training methods.",
      "ai_keywords": [
        "AdaCtrl",
        "adaptive reasoning budget allocation",
        "self-assessed problem difficulty",
        "difficulty-aware reinforcement learning",
        "two-stage training pipeline",
        "cold-start fine-tuning"
      ]
    },
    "publishedAt": "2025-05-24T14:46:50.000Z",
    "title": "AdaCtrl: Towards Adaptive and Controllable Reasoning via\n  Difficulty-Aware Budgeting",
    "summary": "Modern large reasoning models demonstrate impressive problem-solving\ncapabilities by employing sophisticated reasoning strategies. However, they\noften struggle to balance efficiency and effectiveness, frequently generating\nunnecessarily lengthy reasoning chains for simple problems. In this work, we\npropose AdaCtrl, a novel framework to support both difficulty-aware adaptive\nreasoning budget allocation and explicit user control over reasoning depth.\nAdaCtrl dynamically adjusts its reasoning length based on self-assessed problem\ndifficulty, while also allowing users to manually control the budget to\nprioritize either efficiency or effectiveness. This is achieved through a\ntwo-stage training pipeline: an initial cold-start fine-tuning phase to instill\nthe ability to self-aware difficulty and adjust reasoning budget, followed by a\ndifficulty-aware reinforcement learning (RL) stage that refines the model's\nadaptive reasoning strategies and calibrates its difficulty assessments based\non its evolving capabilities during online training. To enable intuitive user\ninteraction, we design explicit length-triggered tags that function as a\nnatural interface for budget control. Empirical results show that AdaCtrl\nadapts reasoning length based on estimated difficulty, compared to the standard\ntraining baseline that also incorporates fine-tuning and RL, it yields\nperformance improvements and simultaneously reduces response length by 10.06%\nand 12.14% on the more challenging AIME2024 and AIME2025 datasets, which\nrequire elaborate reasoning, and by 62.05% and 91.04% on the MATH500 and GSM8K\ndatasets, where more concise responses are sufficient. Furthermore, AdaCtrl\nenables precise user control over the reasoning budget, allowing for tailored\nresponses to meet specific needs.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.18822.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64ce05c631c655ff8a2e183c",
      "avatarUrl": "/avatars/f2de7f8a1348b05f46946085e3e9718e.svg",
      "fullname": "Shijue Huang",
      "name": "JoeYing",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 9
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.20278",
      "authors": [
        {
          "_id": "68353261bc28496925a185c9",
          "name": "Hoyeon Chang",
          "hidden": false
        },
        {
          "_id": "68353261bc28496925a185ca",
          "name": "Jinho Park",
          "hidden": false
        },
        {
          "_id": "68353261bc28496925a185cb",
          "name": "Hanseul Cho",
          "hidden": false
        },
        {
          "_id": "68353261bc28496925a185cc",
          "name": "Sohee Yang",
          "hidden": false
        },
        {
          "_id": "68353261bc28496925a185cd",
          "name": "Miyoung Ko",
          "hidden": false
        },
        {
          "_id": "68353261bc28496925a185ce",
          "name": "Hyeonbin Hwang",
          "hidden": false
        },
        {
          "_id": "68353261bc28496925a185cf",
          "name": "Seungpil Won",
          "hidden": false
        },
        {
          "_id": "68353261bc28496925a185d0",
          "name": "Dohaeng Lee",
          "hidden": false
        },
        {
          "_id": "68353261bc28496925a185d1",
          "name": "Youbin Ahn",
          "hidden": false
        },
        {
          "_id": "68353261bc28496925a185d2",
          "name": "Minjoon Seo",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-26T17:55:15.000Z",
      "submittedOnDailyAt": "2025-05-27T02:04:40.615Z",
      "title": "カバレッジ原則：構成的拡張性を理解するフレームワーク",
      "submittedOnDailyBy": {
        "_id": "64d0d6684dfd5df70744b237",
        "avatarUrl": "/avatars/4ea57bfd407e8cb727c624f64af75478.svg",
        "isPro": false,
        "fullname": "Chang",
        "user": "Hoyeon",
        "type": "user"
      },
      "summary": "大語言モデルはパターンマッチングに特化していますが、システマティックな構成的な一般化には欠点があります。私たちはカバージョン原則を提案します：データセンター的なフレームワークで、主にパターンマッチングを依存したモデルは、同じコンテキストで同じ結果を得るようなフレームを置換することでは、信頼性のある一般化を行うことができません。私たちは、このフレームワークがトランスフォーマーの一般化能力に強い予測力を持つことを示します。まず、2ホップの一般化に必要なトークンセットサイズに対して少なくとも二乗的に増加し、20倍のパラメータスケーリングでデータの効率化は改善しません。次に、パスの不明確性がある構成的なタスクで、1つの変数は複数の計算パスを経由して出力に影響します。トランスフォーマーは、両方の性能と互換性を破壊するようなコンテキスト依存的な状態表現を学習します。三つ目に、Chain-of-Thoughtのサブジェクトは多ホップタスクのデータの効率化を改善しますが、パスの不明確性に難問を抱えます。最後に、機構ベースのタクソニムを記述し、神経ネットワークが一般化する3つの方法を区別します：構造ベース（カバージョンに制限される）、属性ベース（代数的不変性を利用する）、共有オペレーター（関数の再利用を通じて）。この概念的なレンズでは、私たちの結果をコンテキスト化し、新しいアーキテクチャの考え方が必要となる場所を明らかにします。全体として、カバージョン原則は構成的な理由を理解するための統一的なレンズを提供し、根本的なアーキテクチャまたはトレーニングの革新が必要としています。",
      "upvotes": 4,
      "discussionId": "68353261bc28496925a185ef",
      "ai_summary": "The coverage principle highlights limitations in Transformers' compositional generalization, emphasizing the need for new architectures or training methods to achieve systematic compositionality by distinguishing different mechanisms of generalization.",
      "ai_keywords": [
        "coverage principle",
        "data-centric framework",
        "sequential application",
        "pattern matching",
        "compositional generalization",
        "Transformers",
        "two-hop generalization",
        "token set size",
        "training data efficiency",
        "context-dependent state representations",
        "performance",
        "interoperability",
        "Chain-of-Thought supervision",
        "multi-hop tasks",
        "path ambiguity",
        "structure-based",
        "property-based",
        "shared-operator",
        "architectural innovations"
      ]
    },
    "publishedAt": "2025-05-26T13:55:15.000Z",
    "title": "The Coverage Principle: A Framework for Understanding Compositional\n  Generalization",
    "summary": "Large language models excel at pattern matching, yet often fall short in\nsystematic compositional generalization. We propose the coverage principle: a\ndata-centric framework showing that models relying primarily on pattern\nmatching for compositional tasks cannot reliably generalize beyond substituting\nfragments that yield identical results when used in the same contexts. We\ndemonstrate that this framework has a strong predictive power for the\ngeneralization capabilities of Transformers. First, we derive and empirically\nconfirm that the training data required for two-hop generalization grows at\nleast quadratically with the token set size, and the training data efficiency\ndoes not improve with 20x parameter scaling. Second, for compositional tasks\nwith path ambiguity where one variable affects the output through multiple\ncomputational paths, we show that Transformers learn context-dependent state\nrepresentations that undermine both performance and interoperability. Third,\nChain-of-Thought supervision improves training data efficiency for multi-hop\ntasks but still struggles with path ambiguity. Finally, we outline a\nmechanism-based taxonomy that distinguishes three ways neural networks\ncan generalize: structure-based (bounded by coverage), property-based\n(leveraging algebraic invariances), and shared-operator (through function\nreuse). This conceptual lens contextualizes our results and highlights where\nnew architectural ideas are needed to achieve systematic compositionally.\nOverall, the coverage principle provides a unified lens for understanding\ncompositional reasoning, and underscores the need for fundamental architectural\nor training innovations to achieve truly systematic compositionality.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.20278.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64d0d6684dfd5df70744b237",
      "avatarUrl": "/avatars/4ea57bfd407e8cb727c624f64af75478.svg",
      "fullname": "Chang",
      "name": "Hoyeon",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 4
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2505.20254",
      "authors": [
        {
          "_id": "683528109f968fc5c604495f",
          "user": {
            "_id": "5f12485c0c833276f61f1afb",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1595033594228-noauth.jpeg",
            "isPro": false,
            "fullname": "Xiangchen Song",
            "user": "xiangchensong",
            "type": "user"
          },
          "name": "Xiangchen Song",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-05-27T02:48:53.929Z",
          "hidden": false
        },
        {
          "_id": "683528109f968fc5c6044960",
          "user": {
            "_id": "64755a83e0b188d3cb2579d8",
            "avatarUrl": "/avatars/2c50590905f4bd398a4c9991e1b4b5bb.svg",
            "isPro": false,
            "fullname": "Aashiq Muhamed",
            "user": "aashiqmuhamed",
            "type": "user"
          },
          "name": "Aashiq Muhamed",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T07:51:25.328Z",
          "hidden": false
        },
        {
          "_id": "683528109f968fc5c6044961",
          "name": "Yujia Zheng",
          "hidden": false
        },
        {
          "_id": "683528109f968fc5c6044962",
          "name": "Lingjing Kong",
          "hidden": false
        },
        {
          "_id": "683528109f968fc5c6044963",
          "name": "Zeyu Tang",
          "hidden": false
        },
        {
          "_id": "683528109f968fc5c6044964",
          "name": "Mona T. Diab",
          "hidden": false
        },
        {
          "_id": "683528109f968fc5c6044965",
          "name": "Virginia Smith",
          "hidden": false
        },
        {
          "_id": "683528109f968fc5c6044966",
          "name": "Kun Zhang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-26T17:31:36.000Z",
      "submittedOnDailyAt": "2025-05-27T01:20:40.055Z",
      "title": "Position: 機械的説明性は、SAEsの特徴ベクトルの一致性を優先するべきです。",
      "submittedOnDailyBy": {
        "_id": "64755a83e0b188d3cb2579d8",
        "avatarUrl": "/avatars/2c50590905f4bd398a4c9991e1b4b5bb.svg",
        "isPro": false,
        "fullname": "Aashiq Muhamed",
        "user": "aashiqmuhamed",
        "type": "user"
      },
      "summary": "Sparse Autoencoders (SAEs)は機械的説明性（MI）での重要なツールで、ニューラルネットワークの活性化を解釈可能な特徴量に分解する。しかし、学習されたSAEの特徴量が異なる学習ロードで不連続であることが見られ、これはMI研究の信頼性と効率に影響を及ぼしている。この立場論文は、機械的説明性はSAEの特徴量の一致性を優先するべきであると主張し、独立したロードで等価な特徴量セットの信頼的な収束を目指す。ここでは、Pairwise Dictionary Mean Correlation Coefficient (PW-MCC)を実用的なメトリックとして使用することを提案し、適切なアーキテクチャの選択で高いレベル（LLM活性化のTopK SAEsでは0.80）が達成できることを示している。私たちの貢献は、一致性を優先することの利点を詳細に説明し、モデルオーガニズムを使用して理論的な基礎と合成的な検証を提供し、PW-MCCが真の値の回収の信頼的な代理としての信頼性を証明することを含む。また、これらの発見を実世界的なLLMデータに拡張し、高い特徴量の一致性は学習された特徴量解釈の語意的類似性と強い関連を示していることを示している。コミュニティ全体で特徴量の一致性をシステマティックに測定することを呼びかけ、MIの堅固な累積的な進歩を促進することを求めている。",
      "upvotes": 4,
      "discussionId": "683528159f968fc5c6044aff",
      "githubRepo": "https://github.com/xiangchensong/sae-feature-consistency",
      "ai_summary": "Prioritizing feature consistency in sparse autoencoders improves mechanistic interpretability of neural networks by ensuring reliable and interpretable features.",
      "ai_keywords": [
        "Sparse Autoencoders (SAEs)",
        "mechanistic interpretability (MI)",
        "feature consistency",
        "Pairwise Dictionary Mean Correlation Coefficient (PW-MCC)",
        "TopK SAEs",
        "LLM activations",
        "synthetic validation",
        "semantic similarity",
        "learned feature explanations"
      ]
    },
    "publishedAt": "2025-05-26T13:31:36.000Z",
    "title": "Position: Mechanistic Interpretability Should Prioritize Feature\n  Consistency in SAEs",
    "summary": "Sparse Autoencoders (SAEs) are a prominent tool in mechanistic\ninterpretability (MI) for decomposing neural network activations into\ninterpretable features. However, the aspiration to identify a canonical set of\nfeatures is challenged by the observed inconsistency of learned SAE features\nacross different training runs, undermining the reliability and efficiency of\nMI research. This position paper argues that mechanistic interpretability\nshould prioritize feature consistency in SAEs -- the reliable convergence to\nequivalent feature sets across independent runs. We propose using the Pairwise\nDictionary Mean Correlation Coefficient (PW-MCC) as a practical metric to\noperationalize consistency and demonstrate that high levels are achievable\n(0.80 for TopK SAEs on LLM activations) with appropriate architectural choices.\nOur contributions include detailing the benefits of prioritizing consistency;\nproviding theoretical grounding and synthetic validation using a model\norganism, which verifies PW-MCC as a reliable proxy for ground-truth recovery;\nand extending these findings to real-world LLM data, where high feature\nconsistency strongly correlates with the semantic similarity of learned feature\nexplanations. We call for a community-wide shift towards systematically\nmeasuring feature consistency to foster robust cumulative progress in MI.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.20254.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64755a83e0b188d3cb2579d8",
      "avatarUrl": "/avatars/2c50590905f4bd398a4c9991e1b4b5bb.svg",
      "fullname": "Aashiq Muhamed",
      "name": "aashiqmuhamed",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.19955",
      "authors": [
        {
          "_id": "68354470650d51732c992a4e",
          "user": {
            "_id": "61166c4328c98bfd5b92e7c5",
            "avatarUrl": "/avatars/f4bb0f0cc2c5b84428c28bddaa479b61.svg",
            "isPro": false,
            "fullname": "Hui Chen",
            "user": "chchenhui",
            "type": "user"
          },
          "name": "Hui Chen",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T08:47:12.560Z",
          "hidden": false
        },
        {
          "_id": "68354470650d51732c992a4f",
          "user": {
            "_id": "6530cf34e7535baecd9620a7",
            "avatarUrl": "/avatars/e6058a932d88e42b4957734f653cbcfd.svg",
            "isPro": false,
            "fullname": "Miao Xiong",
            "user": "happymio",
            "type": "user"
          },
          "name": "Miao Xiong",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T10:03:35.714Z",
          "hidden": false
        },
        {
          "_id": "68354470650d51732c992a50",
          "name": "Yujie Lu",
          "hidden": false
        },
        {
          "_id": "68354470650d51732c992a51",
          "name": "Wei Han",
          "hidden": false
        },
        {
          "_id": "68354470650d51732c992a52",
          "name": "Ailin Deng",
          "hidden": false
        },
        {
          "_id": "68354470650d51732c992a53",
          "name": "Yufei He",
          "hidden": false
        },
        {
          "_id": "68354470650d51732c992a54",
          "name": "Jiaying Wu",
          "hidden": false
        },
        {
          "_id": "68354470650d51732c992a55",
          "name": "Yibo Li",
          "hidden": false
        },
        {
          "_id": "68354470650d51732c992a56",
          "name": "Yue Liu",
          "hidden": false
        },
        {
          "_id": "68354470650d51732c992a57",
          "name": "Bryan Hooi",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-26T13:18:37.000Z",
      "submittedOnDailyAt": "2025-05-27T07:30:37.766Z",
      "title": "MLR-Bench: 開放終端の機械学習研究におけるAIアガントの評価",
      "submittedOnDailyBy": {
        "_id": "61166c4328c98bfd5b92e7c5",
        "avatarUrl": "/avatars/f4bb0f0cc2c5b84428c28bddaa479b61.svg",
        "isPro": false,
        "fullname": "Hui Chen",
        "user": "chchenhui",
        "type": "user"
      },
      "summary": "最近のAIアガントの進展は、科学の発見における潜力を示しています。本研究では、開放的な機械学習研究を評価するための詳細なベンチマーク、MLR-Benchを紹介します。MLR-Benchは3つのキーコンポーネントを含みます：(1) NeurIPS、ICLR、ICMLワークショップからの201つの研究タスク、多様なMLトピックを収録しています；(2) MLR-Judge、LLMベースのレビュー者と謹重に設計されたレビューラボリィュームを組み合わせた自動評価フレームワーク、研究質の評価を行います；(3) MLR-Agent、モジュール化可能なアガントスケーフ、アイデア生成、提案形成、実験、論文書き上げの4つのステージで研究タスクを完了することができます。フレームワークは、これらの異なる研究ステージのステップごとの評価と最終研究論文の端末からの評価を支えます。次に、MLR-Benchを使用して6つの先端LLMと高度なコーディングアガントを評価し、LLMはコネクティブなアイデアと構造的な論文を生成することが効果的であることを調査し、現在のコーディングアガントは常に（例えば80%の場合）製造や無効化された実験結果を生成し、科学の信頼性に重大な障壁をつけていることを示しました。MLR-Judgeは人間評価により評価され、専門家レビュー者との高い同意率を示し、研究評価のスケーラブルなツールとしての可能性を証明しました。MLR-Benchは、信頼できるおさましい科学の発見へのAI研究アガントのベンチマーク、診断、改善に役立てるようにオープンソース化します。",
      "upvotes": 4,
      "discussionId": "68354471650d51732c992a81",
      "githubRepo": "https://github.com/chchenhui/mlrbench",
      "ai_summary": "MLR-Bench evaluates AI agents in scientific research through modular stages, revealing that while LLMs perform well in ideation and writing, coding agents often produce unreliable experimental results.",
      "ai_keywords": [
        "MLR-Bench",
        "MLR-Judge",
        "MLR-Agent",
        "LLM-based reviewers",
        "review rubrics",
        "research evaluation",
        "idea generation",
        "proposal formulation",
        "experimentation",
        "paper writing"
      ]
    },
    "publishedAt": "2025-05-26T09:18:37.000Z",
    "title": "MLR-Bench: Evaluating AI Agents on Open-Ended Machine Learning Research",
    "summary": "Recent advancements in AI agents have demonstrated their growing potential to\ndrive and support scientific discovery. In this work, we introduce MLR-Bench, a\ncomprehensive benchmark for evaluating AI agents on open-ended machine learning\nresearch. MLR-Bench includes three key components: (1) 201 research tasks\nsourced from NeurIPS, ICLR, and ICML workshops covering diverse ML topics; (2)\nMLR-Judge, an automated evaluation framework combining LLM-based reviewers with\ncarefully designed review rubrics to assess research quality; and (3)\nMLR-Agent, a modular agent scaffold capable of completing research tasks\nthrough four stages: idea generation, proposal formulation, experimentation,\nand paper writing. Our framework supports both stepwise assessment across these\ndistinct research stages, and end-to-end evaluation of the final research\npaper. We then use MLR-Bench to evaluate six frontier LLMs and an advanced\ncoding agent, finding that while LLMs are effective at generating coherent\nideas and well-structured papers, current coding agents frequently (e.g., in\n80% of the cases) produce fabricated or invalidated experimental\nresults--posing a major barrier to scientific reliability. We validate\nMLR-Judge through human evaluation, showing high agreement with expert\nreviewers, supporting its potential as a scalable tool for research evaluation.\nWe open-source MLR-Bench to help the community benchmark, diagnose, and improve\nAI research agents toward trustworthy and transparent scientific discovery.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.19955.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "61166c4328c98bfd5b92e7c5",
      "avatarUrl": "/avatars/f4bb0f0cc2c5b84428c28bddaa479b61.svg",
      "fullname": "Hui Chen",
      "name": "chchenhui",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.19443",
      "authors": [
        {
          "_id": "683517bf6bb42c7e99bd3b5c",
          "user": {
            "_id": "67ddd80896ac367438d400a6",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/C1NY6Nv5i0erwLnzCrTUM.png",
            "isPro": false,
            "fullname": "Ranjan Sapkota",
            "user": "RanjanSapkota",
            "type": "user"
          },
          "name": "Ranjan Sapkota",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T07:53:14.365Z",
          "hidden": false
        },
        {
          "_id": "683517bf6bb42c7e99bd3b5d",
          "name": "Konstantinos I. Roumeliotis",
          "hidden": false
        },
        {
          "_id": "683517bf6bb42c7e99bd3b5e",
          "name": "Manoj Karkee",
          "hidden": false
        }
      ],
      "mediaUrls": [
        "https://cdn-uploads.huggingface.co/production/uploads/67ddd80896ac367438d400a6/ASTag4z8Os01guAbKpxI6.jpeg",
        "https://cdn-uploads.huggingface.co/production/uploads/67ddd80896ac367438d400a6/EgtU3Vsfc22Hko-FbRQ51.jpeg"
      ],
      "publishedAt": "2025-05-26T03:00:21.000Z",
      "submittedOnDailyAt": "2025-05-27T00:12:16.499Z",
      "title": "ビーブコーディング vs. アジェンティックコーディング：アジェンティックAIの基本と実用的な影響",
      "submittedOnDailyBy": {
        "_id": "67ddd80896ac367438d400a6",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/C1NY6Nv5i0erwLnzCrTUM.png",
        "isPro": false,
        "fullname": "Ranjan Sapkota",
        "user": "RanjanSapkota",
        "type": "user"
      },
      "summary": "このレビューは、AIを支援するソフトウェア開発における2つの新しいパラダイム、ビーブコーディングとアジェンティーコーディングについての詳細な分析を提供します。両者は、大規模な言語モデル（LLMs）を利用しているが、自律性、アーキテクチャデザイン、開発者の役割において本質的な違いがあります。ビーブコーディングは、直感的な、人間がロープ内のインタラクションを強調し、プロンプトベースでの会話ワークフローを通じてアイデアショップ、実験、創造的な検索をサポートします。対照的に、アジェンティーコーディングは、最小限の人間の介入を伴わずに目標を駆使したアジェントが計画、実行、テスト、イテレーションを行うことで自律的なソフトウェア開発を可能にします。我々は、概念的基礎、実行モデル、フィードバックループ、安全機構、デバッグ戦略、実世界的なツールエコシステムを統合した詳細なタクロロジーを提案します。比較的ワークフロー分析と20件の詳細な使用ケースを通じて、ビーブシステムは早期階段のプロトタイプ作成と教育で活発に生き続け、アジェンティーシステムは企業レベルのアutomation、コードベースのリファクタリング、CI/CDの統合で優れます。また、自然言語インターフェースと自律的な実行パイプラインを組み合わせたハイブリッドアーキテクチャの新興トレンドについても検討します。最後に、アジェンティーAIの将来のロードマップを明確にし、信頼できる、説明できる、コラボレーション的なシステムのための必要なインフラを記述します。我々の発見は、成功したAIソフトウェアエンジニアリングは、一つのパラダイムを選ぶものではなく、統一的な、人間中心的な開発ライフサイクルにおいてそれらの強みをハーモニックに調和することに依存することを示しています。",
      "upvotes": 4,
      "discussionId": "683517c06bb42c7e99bd3b92",
      "ai_summary": "A review contrasts vibe coding and agentic coding paradigms, highlighting their differences in interaction, autonomy, and application areas in AI-assisted software development.",
      "ai_keywords": [
        "large language models",
        "vibe coding",
        "agentic coding",
        "prompt-based",
        "conversational workflows",
        "goal-driven agents",
        "execution models",
        "feedback loops",
        "safety mechanisms",
        "debugging strategies",
        "tool ecosystems",
        "hybrid architectures",
        "autonomous execution pipelines",
        "trustworthy",
        "explainable",
        "collaborative systems",
        "unified",
        "human-centered development lifecycle"
      ]
    },
    "publishedAt": "2025-05-25T23:00:21.000Z",
    "title": "Vibe Coding vs. Agentic Coding: Fundamentals and Practical Implications\n  of Agentic AI",
    "summary": "This review presents a comprehensive analysis of two emerging paradigms in\nAI-assisted software development: vibe coding and agentic coding. While both\nleverage large language models (LLMs), they differ fundamentally in autonomy,\narchitectural design, and the role of the developer. Vibe coding emphasizes\nintuitive, human-in-the-loop interaction through prompt-based, conversational\nworkflows that support ideation, experimentation, and creative exploration. In\ncontrast, agentic coding enables autonomous software development through\ngoal-driven agents capable of planning, executing, testing, and iterating tasks\nwith minimal human intervention. We propose a detailed taxonomy spanning\nconceptual foundations, execution models, feedback loops, safety mechanisms,\ndebugging strategies, and real-world tool ecosystems. Through comparative\nworkflow analysis and 20 detailed use cases, we illustrate how vibe systems\nthrive in early-stage prototyping and education, while agentic systems excel in\nenterprise-grade automation, codebase refactoring, and CI/CD integration. We\nfurther examine emerging trends in hybrid architectures, where natural language\ninterfaces are coupled with autonomous execution pipelines. Finally, we\narticulate a future roadmap for agentic AI, outlining the infrastructure needed\nfor trustworthy, explainable, and collaborative systems. Our findings suggest\nthat successful AI software engineering will rely not on choosing one paradigm,\nbut on harmonizing their strengths within a unified, human-centered development\nlifecycle.",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/67ddd80896ac367438d400a6/ASTag4z8Os01guAbKpxI6.jpeg",
      "https://cdn-uploads.huggingface.co/production/uploads/67ddd80896ac367438d400a6/EgtU3Vsfc22Hko-FbRQ51.jpeg"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.19443.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "67ddd80896ac367438d400a6",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/C1NY6Nv5i0erwLnzCrTUM.png",
      "fullname": "Ranjan Sapkota",
      "name": "RanjanSapkota",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.17652",
      "authors": [
        {
          "_id": "6835264edf7cbb5c08ce28a5",
          "user": {
            "_id": "65a0aade5fafc248c2156e95",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65a0aade5fafc248c2156e95/S9YjJMTuKc-U1cFizqUMA.jpeg",
            "isPro": false,
            "fullname": "DeyangKong",
            "user": "DeyangKong",
            "type": "user"
          },
          "name": "Deyang Kong",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T07:51:42.197Z",
          "hidden": false
        },
        {
          "_id": "6835264edf7cbb5c08ce28a6",
          "name": "Qi Guo",
          "hidden": false
        },
        {
          "_id": "6835264edf7cbb5c08ce28a7",
          "user": {
            "_id": "63edb098679c2cc40abc6c2e",
            "avatarUrl": "/avatars/288c7229937c2c3f29fda6d17c7df2eb.svg",
            "isPro": false,
            "fullname": "Xiangyu",
            "user": "xixy",
            "type": "user"
          },
          "name": "Xiangyu Xi",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T07:51:39.843Z",
          "hidden": false
        },
        {
          "_id": "6835264edf7cbb5c08ce28a8",
          "name": "Wei Wang",
          "hidden": false
        },
        {
          "_id": "6835264edf7cbb5c08ce28a9",
          "name": "Jingang Wang",
          "hidden": false
        },
        {
          "_id": "6835264edf7cbb5c08ce28aa",
          "name": "Xunliang Cai",
          "hidden": false
        },
        {
          "_id": "6835264edf7cbb5c08ce28ab",
          "name": "Shikun Zhang",
          "hidden": false
        },
        {
          "_id": "6835264edf7cbb5c08ce28ac",
          "name": "Wei Ye",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-23T09:15:26.000Z",
      "submittedOnDailyAt": "2025-05-27T01:12:37.832Z",
      "title": "リティディング・レイニング・ラーニングのサンプリング・クリティライズに関する考え方\n  能力・難易度の一致の視点からの理由論",
      "submittedOnDailyBy": {
        "_id": "65a0aade5fafc248c2156e95",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65a0aade5fafc248c2156e95/S9YjJMTuKc-U1cFizqUMA.jpeg",
        "isPro": false,
        "fullname": "DeyangKong",
        "user": "DeyangKong",
        "type": "user"
      },
      "summary": "強化学習は、大規模言語モデルの理由能力を向上させる可能性を示していますが、実行フェーズでのサンプル効率の低さによりスケーリングが難しいです。現在の方法は、問題の難易度に基づいて問題をスケジューリングして効率を向上させようとしていますが、これらのアプローチは、問題の難易度の不穩定なおびれた推定とバイアスを受け、強化学習トレーニングでのモデルの能力と問題の難易度の一致性を捉えず、最適な結果に至らないことを見落としています。これらの制限を克服するために、本論文では、問題の難易度の精度と安定性を確保するために、歴史の効果を集計した問題の性能の差を利用した能力-難易度一致サンプリング（CDAS）を導入しています。次に、モデルの能力を定量化し、固定点システムを使用して現在のモデルの能力に合わせた難易度の問題を適応的に選択することができます。多様な難しい数学ベンチマークでの実験結果から、CDASは精度と効率において大幅な向上を収めています。CDASはベースラインと比べて最も高い平均精度を達成し、DAPOでの競争的な戦略としてのDynamic Samplingと比べて2.33倍のスピード優勢を示しています。",
      "upvotes": 4,
      "discussionId": "6835264fdf7cbb5c08ce28f9",
      "ai_summary": "CDAS addresses low sample efficiency in reinforcement learning by aligning model competence with problem difficulty, improving both accuracy and efficiency in mathematical benchmarks.",
      "ai_keywords": [
        "reinforcement learning",
        "competence-difficulty alignment sampling",
        "CDAS",
        "historical performance discrepancies",
        "fixed-point system",
        "dynamic sampling",
        "DAPO"
      ]
    },
    "publishedAt": "2025-05-23T05:15:26.000Z",
    "title": "Rethinking the Sampling Criteria in Reinforcement Learning for LLM\n  Reasoning: A Competence-Difficulty Alignment Perspective",
    "summary": "Reinforcement learning exhibits potential in enhancing the reasoning\nabilities of large language models, yet it is hard to scale for the low sample\nefficiency during the rollout phase. Existing methods attempt to improve\nefficiency by scheduling problems based on problem difficulties. However, these\napproaches suffer from unstable and biased estimations of problem difficulty\nand fail to capture the alignment between model competence and problem\ndifficulty in RL training, leading to suboptimal results. To tackle these\nlimitations, this paper introduces Competence-Difficulty\nAlignment Sampling (CDAS), which enables accurate\nand stable estimation of problem difficulties by aggregating historical\nperformance discrepancies of problems. Then the model competence is quantified\nto adaptively select problems whose difficulty is in alignment with the model's\ncurrent competence using a fixed-point system. Experimental results across a\nrange of challenging mathematical benchmarks show that CDAS achieves great\nimprovements in both accuracy and efficiency. CDAS attains the highest average\naccuracy against baselines and exhibits significant speed advantages compared\nto Dynamic Sampling, a competitive strategy in DAPO, which is 2.33\ntimes slower than CDAS.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.17652.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "65a0aade5fafc248c2156e95",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65a0aade5fafc248c2156e95/S9YjJMTuKc-U1cFizqUMA.jpeg",
      "fullname": "DeyangKong",
      "name": "DeyangKong",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 3
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.10887",
      "authors": [
        {
          "_id": "682b5387f1e88185bddb0643",
          "user": {
            "_id": "648a2042e8bee533291da413",
            "avatarUrl": "/avatars/83b918ddd7e2130a1c72ae74606068dc.svg",
            "isPro": false,
            "fullname": "Bin Lei",
            "user": "Bin12345",
            "type": "user"
          },
          "name": "Bin Lei",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-20T07:22:15.514Z",
          "hidden": false
        },
        {
          "_id": "682b5387f1e88185bddb0644",
          "name": "Weitai Kang",
          "hidden": false
        },
        {
          "_id": "682b5387f1e88185bddb0645",
          "name": "Zijian Zhang",
          "hidden": false
        },
        {
          "_id": "682b5387f1e88185bddb0646",
          "name": "Winson Chen",
          "hidden": false
        },
        {
          "_id": "682b5387f1e88185bddb0647",
          "name": "Xi Xie",
          "hidden": false
        },
        {
          "_id": "682b5387f1e88185bddb0648",
          "name": "Shan Zuo",
          "hidden": false
        },
        {
          "_id": "682b5387f1e88185bddb0649",
          "name": "Mimi Xie",
          "hidden": false
        },
        {
          "_id": "682b5387f1e88185bddb064a",
          "name": "Ali Payani",
          "hidden": false
        },
        {
          "_id": "682b5387f1e88185bddb064b",
          "name": "Mingyi Hong",
          "hidden": false
        },
        {
          "_id": "682b5387f1e88185bddb064c",
          "name": "Yan Yan",
          "hidden": false
        },
        {
          "_id": "682b5387f1e88185bddb064d",
          "name": "Caiwen Ding",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-16T05:43:27.000Z",
      "submittedOnDailyAt": "2025-05-27T01:07:44.773Z",
      "title": "InfantAgent-Next: 自動コンピュータインタラクション向けの多模態一般主義アグェント",
      "submittedOnDailyBy": {
        "_id": "648a2042e8bee533291da413",
        "avatarUrl": "/avatars/83b918ddd7e2130a1c72ae74606068dc.svg",
        "isPro": false,
        "fullname": "Bin Lei",
        "user": "Bin12345",
        "type": "user"
      },
      "summary": "この論文では、InfantAgent-Nextという一般的なアガントを紹介します。このアガントは、テキスト、画像、音声、ビデオといった多様なモデルでのコンピューターとの相互作用を可能にします。既存のアプローチとは異なり、単一の大きなモデルを中心に複雑なワークフローを構築したり、ワークフローのモジュラーティを提供したりしません。我々のアガントは、高度なモジュラーティのアーキテクチャにツールベースアガントと純粋なビジョンアガントを統合し、異なるモデルが連携して、ステップごとに解決できるような解離されたタスクを実現します。我々の一般性は、ビジョンベースの実世界ベンチマーク（例：OSWorld）の評価だけでなく、より一般的かつツールを重視するベンチマーク（例：GAIAとSWE-Bench）でも評価できることを示しています。特に、OSWorldでは7.27%の精度を達成し、Claude-Computer-Useよりも高い精度を収めました。コードと評価スクリプトは、https://github.com/bin123apple/InfantAgent に開放されています。",
      "upvotes": 3,
      "discussionId": "682b5389f1e88185bddb070d",
      "githubRepo": "https://github.com/bin123apple/InfantAgent",
      "ai_summary": "InfantAgent-Next is a multimodal agent that integrates tool-based and vision models in a modular architecture to solve various benchmarks, including OSWorld, GAIA, and SWE-Bench.",
      "ai_keywords": [
        "multimodal agent",
        "tool-based agents",
        "pure vision agents",
        "modular architecture",
        "OSWorld",
        "GAIA",
        "SWE-Bench"
      ]
    },
    "publishedAt": "2025-05-16T01:43:27.000Z",
    "title": "InfantAgent-Next: A Multimodal Generalist Agent for Automated Computer\n  Interaction",
    "summary": "This paper introduces InfantAgent-Next, a generalist agent capable\nof interacting with computers in a multimodal manner, encompassing text,\nimages, audio, and video. Unlike existing approaches that either build\nintricate workflows around a single large model or only provide workflow\nmodularity, our agent integrates tool-based and pure vision agents within a\nhighly modular architecture, enabling different models to collaboratively solve\ndecoupled tasks in a step-by-step manner. Our generality is demonstrated by our\nability to evaluate not only pure vision-based real-world benchmarks (i.e.,\nOSWorld), but also more general or tool-intensive benchmarks (e.g., GAIA and\nSWE-Bench). Specifically, we achieve 7.27% accuracy on OSWorld,\nhigher than Claude-Computer-Use. Codes and evaluation scripts are open-sourced\nat https://github.com/bin123apple/InfantAgent.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.10887.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "648a2042e8bee533291da413",
      "avatarUrl": "/avatars/83b918ddd7e2130a1c72ae74606068dc.svg",
      "fullname": "Bin Lei",
      "name": "Bin12345",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 20
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.20294",
      "authors": [
        {
          "_id": "683552b7d34b8e5da4d9dfe3",
          "user": {
            "_id": "653cb25c394886efebf9971a",
            "avatarUrl": "/avatars/bca0a20c305e178a3f316581a2636cb6.svg",
            "isPro": false,
            "fullname": "Xiao Chen",
            "user": "Xiao-HF",
            "type": "user"
          },
          "name": "Xiao Chen",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T07:49:12.484Z",
          "hidden": false
        },
        {
          "_id": "683552b7d34b8e5da4d9dfe4",
          "name": "Tai Wang",
          "hidden": false
        },
        {
          "_id": "683552b7d34b8e5da4d9dfe5",
          "name": "Quanyi Li",
          "hidden": false
        },
        {
          "_id": "683552b7d34b8e5da4d9dfe6",
          "name": "Tao Huang",
          "hidden": false
        },
        {
          "_id": "683552b7d34b8e5da4d9dfe7",
          "name": "Jiangmiao Pang",
          "hidden": false
        },
        {
          "_id": "683552b7d34b8e5da4d9dfe8",
          "name": "Tianfan Xue",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-26T17:59:52.000Z",
      "submittedOnDailyAt": "2025-05-27T06:49:31.312Z",
      "title": "GLEAM: 学習可能な探索ポリシーを用いた複雑な3D室内スペースでのアクティブマッピング",
      "submittedOnDailyBy": {
        "_id": "653cb25c394886efebf9971a",
        "avatarUrl": "/avatars/bca0a20c305e178a3f316581a2636cb6.svg",
        "isPro": false,
        "fullname": "Xiao Chen",
        "user": "Xiao-HF",
        "type": "user"
      },
      "summary": "従来の方法は、不足しているトレーニングデータと保守的な探索戦略に制限されて、ディバーセールな並列や複雑な接続を持つ場所での一般化可能なアクティブマッピングに限られています。スケーラブルなトレーニングと信頼性のある評価を可能にするために、GLEAM-Benchという、最初の大規模なベンチマークを導入します。これは、合成データセットと実測データセットからの1,152種類のディバーセールな3Dスケーンを扱う一般化可能なアクティブマッピングのために設計されています。この基盤により、GLEAMという、一つの一般化可能なアクティブマッピングの一般化可能な探索ポリシーを提案します。その上位の一般化可能な性能は、セマンティックな表現、長期的な探索可能なゴール、ランダム化された戦略によって主に得られています。128種類の見たことない複雑なスケーンで、状況のコバーワード率が66.50%（+9.49%）、効率的なプロジェクトと改善されたマッピング精度を達成します。プロジェクトページ：https://xiao-chen.tech/gleam/",
      "upvotes": 2,
      "discussionId": "683552b9d34b8e5da4d9e050",
      "ai_summary": "A new benchmark and policy, GLEAM-Bench and GLEAM, improve the scalability and reliability of active mapping in complex environments through semantic representations and efficient exploration strategies.",
      "ai_keywords": [
        "active mapping",
        "generalizable exploration",
        "semantic representations",
        "navigable goals",
        "randomized strategies",
        "3D scenes",
        "synthetic datasets",
        "real-scan datasets",
        "benchmark",
        "mapping accuracy",
        "coverage",
        "trajectories"
      ]
    },
    "publishedAt": "2025-05-26T13:59:52.000Z",
    "title": "GLEAM: Learning Generalizable Exploration Policy for Active Mapping in\n  Complex 3D Indoor Scenes",
    "summary": "Generalizable active mapping in complex unknown environments remains a\ncritical challenge for mobile robots. Existing methods, constrained by\ninsufficient training data and conservative exploration strategies, exhibit\nlimited generalizability across scenes with diverse layouts and complex\nconnectivity. To enable scalable training and reliable evaluation, we introduce\nGLEAM-Bench, the first large-scale benchmark designed for generalizable active\nmapping with 1,152 diverse 3D scenes from synthetic and real-scan datasets.\nBuilding upon this foundation, we propose GLEAM, a unified generalizable\nexploration policy for active mapping. Its superior generalizability comes\nmainly from our semantic representations, long-term navigable goals, and\nrandomized strategies. It significantly outperforms state-of-the-art methods,\nachieving 66.50% coverage (+9.49%) with efficient trajectories and improved\nmapping accuracy on 128 unseen complex scenes. Project page:\nhttps://xiao-chen.tech/gleam/.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.20294.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "653cb25c394886efebf9971a",
      "avatarUrl": "/avatars/bca0a20c305e178a3f316581a2636cb6.svg",
      "fullname": "Xiao Chen",
      "name": "Xiao-HF",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.20139",
      "authors": [
        {
          "_id": "6835744884d4600675a4449c",
          "name": "Jialin Yang",
          "hidden": false
        },
        {
          "_id": "6835744884d4600675a4449d",
          "name": "Dongfu Jiang",
          "hidden": false
        },
        {
          "_id": "6835744884d4600675a4449e",
          "name": "Lipeng He",
          "hidden": false
        },
        {
          "_id": "6835744884d4600675a4449f",
          "name": "Sherman Siu",
          "hidden": false
        },
        {
          "_id": "6835744884d4600675a444a0",
          "name": "Yuxuan Zhang",
          "hidden": false
        },
        {
          "_id": "6835744884d4600675a444a1",
          "name": "Disen Liao",
          "hidden": false
        },
        {
          "_id": "6835744884d4600675a444a2",
          "name": "Zhuofeng Li",
          "hidden": false
        },
        {
          "_id": "6835744884d4600675a444a3",
          "name": "Huaye Zeng",
          "hidden": false
        },
        {
          "_id": "6835744884d4600675a444a4",
          "name": "Yiming Jia",
          "hidden": false
        },
        {
          "_id": "6835744884d4600675a444a5",
          "name": "Haozhe Wang",
          "hidden": false
        },
        {
          "_id": "6835744884d4600675a444a6",
          "name": "Benjamin Schneider",
          "hidden": false
        },
        {
          "_id": "6835744884d4600675a444a7",
          "name": "Chi Ruan",
          "hidden": false
        },
        {
          "_id": "6835744884d4600675a444a8",
          "name": "Wentao Ma",
          "hidden": false
        },
        {
          "_id": "6835744884d4600675a444a9",
          "name": "Zhiheng Lyu",
          "hidden": false
        },
        {
          "_id": "6835744884d4600675a444aa",
          "name": "Yifei Wang",
          "hidden": false
        },
        {
          "_id": "6835744884d4600675a444ab",
          "name": "Yi Lu",
          "hidden": false
        },
        {
          "_id": "6835744884d4600675a444ac",
          "name": "Quy Duc Do",
          "hidden": false
        },
        {
          "_id": "6835744884d4600675a444ad",
          "name": "Ziyan Jiang",
          "hidden": false
        },
        {
          "_id": "6835744884d4600675a444ae",
          "name": "Ping Nie",
          "hidden": false
        },
        {
          "_id": "6835744884d4600675a444af",
          "name": "Wenhu Chen",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-26T15:40:42.000Z",
      "submittedOnDailyAt": "2025-05-27T06:46:45.076Z",
      "title": "StructEval: 構造的な出力を生成するLLMの能力をベンチマークする",
      "submittedOnDailyBy": {
        "_id": "62567c86d444a9b5a0ec51c1",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62567c86d444a9b5a0ec51c1/1vXJf2uGztPcXpkwyTBr6.png",
        "isPro": false,
        "fullname": "Dongfu Jiang",
        "user": "DongfuJiang",
        "type": "user"
      },
      "summary": "ラーグ・ラングジャングルモデル（LLMs）がソフトウェア開発ワークフローに重要な部分となることになるにつれ、その構造化された出力を生成する能力が非常に重要になってきました。StructEvalという、LLMsの構造化されたフォーマットの生成能力を評価するための詳細なベンチマークを紹介します。先行のベンチマークと異なり、StructEvalは2つのパラダイムで構造的な忠実性をシステマティックに評価しています：1）生成タスクでは、自然言語プロンプトから構造化された出力を生成し、2）変換タスクでは、構造化されたフォーマットを相互に翻訳します。ベンチマークは18つのフォーマットと44つのタスクタイプを含み、フォーマットの適合性と構造的な正確性に関する新しいメトリックを使用しています。結果から、显著な性能間隔が明らかになりました。例えば、state-of-the-artモデルのo1-miniは平均75.58のスコアを達成し、オープンソースの代替品はそれより約10点ほど落ちています。生成タスクは変換タスクよりも難しく、テキストだけの構造を生成することは正しい可視内容を生成することよりも簡単でした。",
      "upvotes": 2,
      "discussionId": "6835744884d4600675a444d3",
      "ai_summary": "StructEval benchmarks Large Language Models for generating and converting structured outputs, highlighting performance gaps and challenges in producing visual content.",
      "ai_keywords": [
        "Large Language Models (LLMs)",
        "StructEval",
        "structured outputs",
        "JSON",
        "YAML",
        "CSV",
        "HTML",
        "React",
        "SVG",
        "generation tasks",
        "conversion tasks",
        "format adherence",
        "structural correctness"
      ]
    },
    "publishedAt": "2025-05-26T11:40:42.000Z",
    "title": "StructEval: Benchmarking LLMs' Capabilities to Generate Structural\n  Outputs",
    "summary": "As Large Language Models (LLMs) become integral to software development\nworkflows, their ability to generate structured outputs has become critically\nimportant. We introduce StructEval, a comprehensive benchmark for evaluating\nLLMs' capabilities in producing both non-renderable (JSON, YAML, CSV) and\nrenderable (HTML, React, SVG) structured formats. Unlike prior benchmarks,\nStructEval systematically evaluates structural fidelity across diverse formats\nthrough two paradigms: 1) generation tasks, producing structured output from\nnatural language prompts, and 2) conversion tasks, translating between\nstructured formats. Our benchmark encompasses 18 formats and 44 types of task,\nwith novel metrics for format adherence and structural correctness. Results\nreveal significant performance gaps, even state-of-the-art models like o1-mini\nachieve only 75.58 average score, with open-source alternatives lagging\napproximately 10 points behind. We find generation tasks more challenging than\nconversion tasks, and producing correct visual content more difficult than\ngenerating text-only structures.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.20139.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "62567c86d444a9b5a0ec51c1",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62567c86d444a9b5a0ec51c1/1vXJf2uGztPcXpkwyTBr6.png",
      "fullname": "Dongfu Jiang",
      "name": "DongfuJiang",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 22
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2505.19706",
      "authors": [
        {
          "_id": "6835182873a16b09c94ac4d2",
          "name": "Tej Deep Pala",
          "hidden": false
        },
        {
          "_id": "6835182873a16b09c94ac4d3",
          "name": "Panshul Sharma",
          "hidden": false
        },
        {
          "_id": "6835182873a16b09c94ac4d4",
          "name": "Amir Zadeh",
          "hidden": false
        },
        {
          "_id": "6835182873a16b09c94ac4d5",
          "name": "Chuan Li",
          "hidden": false
        },
        {
          "_id": "6835182873a16b09c94ac4d6",
          "name": "Soujanya Poria",
          "hidden": false
        }
      ],
      "mediaUrls": [
        "https://cdn-uploads.huggingface.co/production/uploads/626b626405fe1cb65725aca1/OPFuTq1oRiXqqwJPyKgUx.png",
        "https://cdn-uploads.huggingface.co/production/uploads/626b626405fe1cb65725aca1/VsJ0SH2BgYbBQTS55nWSB.png",
        "https://cdn-uploads.huggingface.co/production/uploads/626b626405fe1cb65725aca1/qreWH-gdINsiHnTwLQcOL.png"
      ],
      "publishedAt": "2025-05-26T08:56:36.000Z",
      "submittedOnDailyAt": "2025-05-27T00:29:18.345Z",
      "title": "エラータイピングをよりスマートな報酬に向けて：エラーに関心のある階層的ハイパーバイアスでプロセス報酬モデルを改善する",
      "submittedOnDailyBy": {
        "_id": "626b626405fe1cb65725aca1",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/626b626405fe1cb65725aca1/aa-Lata46I3fXOmMetvXH.jpeg",
        "isPro": false,
        "fullname": "Soujanya Poria",
        "user": "soujanyaporia",
        "type": "user"
      },
      "summary": "大語言モデル（LLMs）は、特に数学問題解決のような多段階と理由的なタスクで、ハロケーション（ハロケーション）に容易になります。結果報酬モデルは最終的な答えのみを確認しますが、プロセス報酬モデル（PRMs）は各中間ステップをスコア化し、コラーゼな解決策への生成を制御します。私たちは、PathFinder-PRM、新しい階層的、誤りに関心のある対応PRMを紹介します。これは、各ステップで数学や一致性の誤りを最初に分類し、これらの細かい信号を統合してステップの正確性を推定します。PathFinder-PRMの訓練には、人間の注釈されたPRM800KコーパスとRLHFlow Mistralのトレースを3次元ステップレベルのラベルで豊富にした400Kサンプルデータセットを構築しました。PRMBenchでは、PathFinder-PRMは新しい最先端のPRMScore（67.7）を達成し、前の最善を上回ります（65.5）し、3倍の少ないデータを使用しました。報酬ガイドされたgreedy searchに適用されると、我々のモデルはprm@8 48.3を収め、最強なベースラインより+1.5点の収益を示します。これらの結果は、分離された誤り検出と報酬推定は、細かい誤り検出を促進し、もっとも大きなデータエフィシェンスをもつ終端からの、報酬ガイドされた数学的な理由を大幅に向上させることを示します。",
      "upvotes": 2,
      "discussionId": "6835182973a16b09c94ac514",
      "githubRepo": "https://github.com/declare-lab/PathFinder-PRM",
      "ai_summary": "PathFinder-PRM, a hierarchical and error-aware Process Reward Model, improves mathematical problem-solving by fine-grained error classification and step correctness estimation, achieving state-of-the-art PRMScore with reduced data usage.",
      "ai_keywords": [
        "Large Language Models",
        "hallucination",
        "mathematical problem solving",
        "Outcome Reward Models",
        "Process Reward Models",
        "PathFinder-PRM",
        "hierarchical",
        "error-aware",
        "discriminative PRM",
        "math errors",
        "consistency errors",
        "step correctness",
        "PRMBench",
        "PRMScore",
        "reward guided greedy search",
        "prm@8",
        "data efficiency"
      ]
    },
    "publishedAt": "2025-05-26T04:56:36.000Z",
    "title": "Error Typing for Smarter Rewards: Improving Process Reward Models with\n  Error-Aware Hierarchical Supervision",
    "summary": "Large Language Models (LLMs) are prone to hallucination, especially during\nmulti-hop and reasoning-intensive tasks such as mathematical problem solving.\nWhile Outcome Reward Models verify only final answers, Process Reward Models\n(PRMs) score each intermediate step to steer generation toward coherent\nsolutions. We introduce PathFinder-PRM, a novel hierarchical, error-aware\ndiscriminative PRM that first classifies math and consistency errors at each\nstep, then combines these fine-grained signals to estimate step correctness. To\ntrain PathFinder-PRM, we construct a 400K-sample dataset by enriching the\nhuman-annotated PRM800K corpus and RLHFlow Mistral traces with\nthree-dimensional step-level labels. On PRMBench, PathFinder-PRM achieves a new\nstate-of-the-art PRMScore of 67.7, outperforming the prior best (65.5) while\nusing 3 times less data. When applied to reward guided greedy search, our model\nyields prm@8 48.3, a +1.5 point gain over the strongest baseline. These results\ndemonstrate that decoupled error detection and reward estimation not only boost\nfine-grained error detection but also substantially improve end-to-end,\nreward-guided mathematical reasoning with greater data efficiency.",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/626b626405fe1cb65725aca1/OPFuTq1oRiXqqwJPyKgUx.png",
      "https://cdn-uploads.huggingface.co/production/uploads/626b626405fe1cb65725aca1/VsJ0SH2BgYbBQTS55nWSB.png",
      "https://cdn-uploads.huggingface.co/production/uploads/626b626405fe1cb65725aca1/qreWH-gdINsiHnTwLQcOL.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.19706.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "626b626405fe1cb65725aca1",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/626b626405fe1cb65725aca1/aa-Lata46I3fXOmMetvXH.jpeg",
      "fullname": "Soujanya Poria",
      "name": "soujanyaporia",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 7
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2505.19630",
      "authors": [
        {
          "_id": "683522abd68b329aeb799c46",
          "name": "Yichun Feng",
          "hidden": false
        },
        {
          "_id": "683522abd68b329aeb799c47",
          "user": {
            "_id": "64060b49a577649430bf6974",
            "avatarUrl": "/avatars/74d0d6ed656b593e4c101b09edf18c7a.svg",
            "isPro": false,
            "fullname": "Jiawei Wang",
            "user": "Jarvis1111",
            "type": "user"
          },
          "name": "Jiawei Wang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T07:52:01.364Z",
          "hidden": false
        },
        {
          "_id": "683522abd68b329aeb799c48",
          "name": "Lu Zhou",
          "hidden": false
        },
        {
          "_id": "683522abd68b329aeb799c49",
          "name": "Yixue Li",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-26T07:48:14.000Z",
      "submittedOnDailyAt": "2025-05-27T00:56:34.903Z",
      "title": "DoctorAgent-RL: 多ターンクリニックダイアロジーの多エージェント協力可能な再励励強化学習システム",
      "submittedOnDailyBy": {
        "_id": "64060b49a577649430bf6974",
        "avatarUrl": "/avatars/74d0d6ed656b593e4c101b09edf18c7a.svg",
        "isPro": false,
        "fullname": "Jiawei Wang",
        "user": "Jarvis1111",
        "type": "user"
      },
      "summary": "大語言モデル（LLMs）は、生体医学問い合わせ領域で優れた能力を示していますが、実世界的な診療会話においては核心的な課題が残っています。現在のシステムは、患者が症状を一回で完全に説明する必要がある一方通ぎ情報傳達モードを採用しており、症状が不明確な場合には非特異的な診断推薦が出されます。傳統的な多ターンダイアローグ手法は、監督学習に基づいているため、静的なデータ駆動パラダイムに制限され、一般化能力がなく、重要な診療情報を適切に抽出することが難しいです。これらの制限に対処するために、我々は、不確実性のある動的な決策プロセスによる医療会話をモデル化するための強化学習（RL）に基づく複数のアガントの協力フレームワーク「DoctorAgent-RL」を提案しています。医師アガントは、患者アガントとの多ターンの相互作用によりRLフレームワーク内で質問の戦略を最適化し、診察評価者からの詳細な報酬に基づいて情報の集約パスを動的に調整します。このRLの微調込み機構により、LLMsは臨床理由のロジックに合わせた相互作用戦略を自動的に開発することができ、現在のダイアローグデータのパターンを表面的に模倣しないようにします。特に、我々は、最初の英語の多ターン医療会話データセット「MTMedDialog」を構築しました。実験は、DoctorAgent-RLは現在のモデルに比べて、多ターンの理由能力と最終的な診断性能においても優れていることを示し、診療会話を支援する実用的な価値を示しています。https://github.com/JarvisUSTC/DoctorAgent-RL",
      "upvotes": 2,
      "discussionId": "683522add68b329aeb799cc4",
      "githubRepo": "https://github.com/JarvisUSTC/DoctorAgent-RL",
      "ai_summary": "DoctorAgent-RL, a reinforcement learning-based multi-agent framework, enhances multi-turn reasoning and diagnostic performance in medical consultations compared to existing systems.",
      "ai_keywords": [
        "reinforcement learning",
        "multi-agent collaborative framework",
        "dynamic decision-making",
        "uncertainty",
        "questioning strategy",
        "interaction strategy",
        "clinical reasoning",
        "multi-turn medical consultation dataset",
        "diagnostic performance"
      ]
    },
    "publishedAt": "2025-05-26T03:48:14.000Z",
    "title": "DoctorAgent-RL: A Multi-Agent Collaborative Reinforcement Learning\n  System for Multi-Turn Clinical Dialogue",
    "summary": "Large language models (LLMs) have demonstrated excellent capabilities in the\nfield of biomedical question answering, but their application in real-world\nclinical consultations still faces core challenges. Existing systems rely on a\none-way information transmission mode where patients must fully describe their\nsymptoms in a single round, leading to nonspecific diagnostic recommendations\nwhen complaints are vague. Traditional multi-turn dialogue methods based on\nsupervised learning are constrained by static data-driven paradigms, lacking\ngeneralizability and struggling to intelligently extract key clinical\ninformation. To address these limitations, we propose DoctorAgent-RL, a\nreinforcement learning (RL)-based multi-agent collaborative framework that\nmodels medical consultations as a dynamic decision-making process under\nuncertainty. The doctor agent continuously optimizes its questioning strategy\nwithin the RL framework through multi-turn interactions with the patient agent,\ndynamically adjusting its information-gathering path based on comprehensive\nrewards from the Consultation Evaluator. This RL fine-tuning mechanism enables\nLLMs to autonomously develop interaction strategies aligned with clinical\nreasoning logic, rather than superficially imitating patterns in existing\ndialogue data. Notably, we constructed MTMedDialog, the first English\nmulti-turn medical consultation dataset capable of simulating patient\ninteractions. Experiments demonstrate that DoctorAgent-RL outperforms existing\nmodels in both multi-turn reasoning capability and final diagnostic\nperformance, demonstrating practical value in assisting clinical consultations.\nhttps://github.com/JarvisUSTC/DoctorAgent-RL",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.19630.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64060b49a577649430bf6974",
      "avatarUrl": "/avatars/74d0d6ed656b593e4c101b09edf18c7a.svg",
      "fullname": "Jiawei Wang",
      "name": "Jarvis1111",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.19223",
      "authors": [
        {
          "_id": "68357a21d0fbc64a8e829088",
          "name": "Fengqi Zhu",
          "hidden": false
        },
        {
          "_id": "68357a21d0fbc64a8e829089",
          "name": "Rongzhen Wang",
          "hidden": false
        },
        {
          "_id": "68357a21d0fbc64a8e82908a",
          "name": "Shen Nie",
          "hidden": false
        },
        {
          "_id": "68357a21d0fbc64a8e82908b",
          "user": {
            "_id": "67513d6d3b8586521cda5d76",
            "avatarUrl": "/avatars/0f95cc5c23a0a1da289aa785bd33b616.svg",
            "isPro": false,
            "fullname": "Xiaolu  Zhang",
            "user": "xiaolu0714",
            "type": "user"
          },
          "name": "Xiaolu Zhang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-05-27T08:45:40.970Z",
          "hidden": false
        },
        {
          "_id": "68357a21d0fbc64a8e82908c",
          "name": "Chunwei Wu",
          "hidden": false
        },
        {
          "_id": "68357a21d0fbc64a8e82908d",
          "name": "Jun Hu",
          "hidden": false
        },
        {
          "_id": "68357a21d0fbc64a8e82908e",
          "name": "Jun Zhou",
          "hidden": false
        },
        {
          "_id": "68357a21d0fbc64a8e82908f",
          "user": {
            "_id": "65fcad0ba0d7adc40b54fac2",
            "avatarUrl": "/avatars/7564b5642378fddb46ec3b5ae57c0402.svg",
            "isPro": false,
            "fullname": "Jianfei Chen",
            "user": "surfingtomchen",
            "type": "user"
          },
          "name": "Jianfei Chen",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-05-27T08:45:00.594Z",
          "hidden": false
        },
        {
          "_id": "68357a21d0fbc64a8e829090",
          "user": {
            "_id": "657a651e1433ea7d44de6397",
            "avatarUrl": "/avatars/ccfc76f94595a38ff4a80f77c911eabf.svg",
            "isPro": false,
            "fullname": "Yankai Lin",
            "user": "lyk423",
            "type": "user"
          },
          "name": "Yankai Lin",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-05-27T08:44:53.835Z",
          "hidden": false
        },
        {
          "_id": "68357a21d0fbc64a8e829091",
          "user": {
            "_id": "64b8c89052b7353d8c6a1013",
            "avatarUrl": "/avatars/cd59fffe81f6b07b4519540b8ff3d95f.svg",
            "isPro": false,
            "fullname": "Ji-Rong Wen",
            "user": "jrwen",
            "type": "user"
          },
          "name": "Ji-Rong Wen",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-05-27T08:44:47.347Z",
          "hidden": false
        },
        {
          "_id": "68357a21d0fbc64a8e829092",
          "user": {
            "_id": "64c07b488e2612254361153b",
            "avatarUrl": "/avatars/ade0f783cc4c2d3e73f402637f595471.svg",
            "isPro": false,
            "fullname": "chongxuan li",
            "user": "zhenxuan00",
            "type": "user"
          },
          "name": "Chongxuan Li",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-05-27T08:44:37.114Z",
          "hidden": false
        }
      ],
      "mediaUrls": [
        "https://cdn-uploads.huggingface.co/production/uploads/63a369d98c0c89dcae3b8329/HQWTRZ5gL3-RFJ6PSJ3NC.jpeg"
      ],
      "publishedAt": "2025-05-25T16:36:20.000Z",
      "submittedOnDailyAt": "2025-05-27T07:14:06.300Z",
      "title": "LLaDA 1.5: 大語言変分減少の好み最適化モデル",
      "submittedOnDailyBy": {
        "_id": "63a369d98c0c89dcae3b8329",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63a369d98c0c89dcae3b8329/6OUJ7Hc9T1jXynYH3FGaf.png",
        "isPro": false,
        "fullname": "Adina Yakefu",
        "user": "AdinaY",
        "type": "user"
      },
      "summary": "マスクドディフュージョンモデル（MDM）の例としてLLaDAなどが、言語モデリングの新しいパラダイムを提案しているが、これらのモデルが人間の好みに合わせるための強化学習による調整には相対的に少しの努力がありません。主な課題は、好み最適化に必要なELBO（証拠下限）に基づく似然推定の高い分散性にあります。この問題に対処するために、我々はVariance-Reduced Preference Optimization（VRPO）を提案します。VRPOはELBO推定の分散性を正式的に分析し、好み最適化勾配のバイアスと分散の両方の制限を与えるフレームワークです。この理論的な基盤に基づき、無偏の分散削減戦略を導入し、最適なモンテカルロバブル割当と反対サンプリングを含む、MDMの調整性能を大幅に向上させるために使用されます。VRPOの効果を示すために、LLaDAに適用し、結果のモデルLLaDA 1.5は、数学（GSM8K +4.7）、コード（HumanEval +3.0、MBPP +1.8）、調整ベンチマーク（IFEval +4.0、Arena-Hard +4.3）の各分野で、その前のSFTだけのモデルを絶えずとも積極的に優秀であることを示します。また、LLaDA 1.5は強力な言語MDMとARMと比較して、高度に競争力のある数学的な性能を示します。プロジェクトページ：https://ml-gsai.github.io/LLaDA-1.5-Demo/",
      "upvotes": 2,
      "discussionId": "68357a21d0fbc64a8e8290ba",
      "ai_summary": "VRPO is a variance-reduced preference optimization framework for Masked Diffusion Models that significantly enhances their alignment with human preferences and performance across various benchmarks.",
      "ai_keywords": [
        "Masked Diffusion Models",
        "LLaDA",
        "Variance-Reduced Preference Optimization",
        "VRPO",
        "Evidence Lower Bound",
        "ELBO",
        "bias",
        "variance",
        "preference optimization",
        "unbiased variance reduction",
        "optimal Monte Carlo budget allocation",
        "antithetic sampling",
        "GSM8K",
        "HumanEval",
        "MBPP",
        "IFEval",
        "Arena-Hard",
        "ARMs"
      ]
    },
    "publishedAt": "2025-05-25T12:36:20.000Z",
    "title": "LLaDA 1.5: Variance-Reduced Preference Optimization for Large Language\n  Diffusion Models",
    "summary": "While Masked Diffusion Models (MDMs), such as LLaDA, present a promising\nparadigm for language modeling, there has been relatively little effort in\naligning these models with human preferences via reinforcement learning. The\nchallenge primarily arises from the high variance in Evidence Lower Bound\n(ELBO)-based likelihood estimates required for preference optimization. To\naddress this issue, we propose Variance-Reduced Preference Optimization (VRPO),\na framework that formally analyzes the variance of ELBO estimators and derives\nbounds on both the bias and variance of preference optimization gradients.\nBuilding on this theoretical foundation, we introduce unbiased variance\nreduction strategies, including optimal Monte Carlo budget allocation and\nantithetic sampling, that significantly improve the performance of MDM\nalignment. We demonstrate the effectiveness of VRPO by applying it to LLaDA,\nand the resulting model, LLaDA 1.5, outperforms its SFT-only predecessor\nconsistently and significantly across mathematical (GSM8K +4.7), code\n(HumanEval +3.0, MBPP +1.8), and alignment benchmarks (IFEval +4.0, Arena-Hard\n+4.3). Furthermore, LLaDA 1.5 demonstrates a highly competitive mathematical\nperformance compared to strong language MDMs and ARMs. Project page:\nhttps://ml-gsai.github.io/LLaDA-1.5-Demo/.",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/63a369d98c0c89dcae3b8329/HQWTRZ5gL3-RFJ6PSJ3NC.jpeg"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.19223.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "63a369d98c0c89dcae3b8329",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63a369d98c0c89dcae3b8329/6OUJ7Hc9T1jXynYH3FGaf.png",
      "fullname": "Adina Yakefu",
      "name": "AdinaY",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 702
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2505.19084",
      "authors": [
        {
          "_id": "6835334e0c0aff775f3eb6e2",
          "user": {
            "_id": "640c64779e5247967ff1e0b2",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1678533946170-640c64779e5247967ff1e0b2.jpeg",
            "isPro": false,
            "fullname": "Yifeng Xu",
            "user": "xyfJASON",
            "type": "user"
          },
          "name": "Yifeng Xu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T08:15:08.170Z",
          "hidden": false
        },
        {
          "_id": "6835334e0c0aff775f3eb6e3",
          "name": "Zhenliang He",
          "hidden": false
        },
        {
          "_id": "6835334e0c0aff775f3eb6e4",
          "name": "Meina Kan",
          "hidden": false
        },
        {
          "_id": "6835334e0c0aff775f3eb6e5",
          "name": "Shiguang Shan",
          "hidden": false
        },
        {
          "_id": "6835334e0c0aff775f3eb6e6",
          "name": "Xilin Chen",
          "hidden": false
        }
      ],
      "mediaUrls": [
        "https://cdn-uploads.huggingface.co/production/uploads/640c64779e5247967ff1e0b2/Mqa2jx5wM-f5Fc1pdd6sz.jpeg",
        "https://cdn-uploads.huggingface.co/production/uploads/640c64779e5247967ff1e0b2/-ubqvKPbhrxAjIKnj7dPU.jpeg",
        "https://cdn-uploads.huggingface.co/production/uploads/640c64779e5247967ff1e0b2/Y4ub2WOy0Adp1TfcT90R3.jpeg",
        "https://cdn-uploads.huggingface.co/production/uploads/640c64779e5247967ff1e0b2/lvdM2FUHFI2ut7cgELTh9.jpeg"
      ],
      "publishedAt": "2025-05-25T10:40:52.000Z",
      "submittedOnDailyAt": "2025-05-27T07:40:01.653Z",
      "title": "ジョーディ：ビジュアル生成と理解の統合を共にモデリングによって実現",
      "submittedOnDailyBy": {
        "_id": "640c64779e5247967ff1e0b2",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1678533946170-640c64779e5247967ff1e0b2.jpeg",
        "isPro": false,
        "fullname": "Yifeng Xu",
        "user": "xyfJASON",
        "type": "user"
      },
      "summary": "ビジュアル生成と理解は、人間の知能の二つの深く関連付けられた面であり、それらは機械学習では単独で処理されていました。本論文では、ビジュアル生成と理解を統合するために提案したディフュージョンフレームワーク「Jodi」を紹介します。Jodiは、画像領域と複数のラベル領域を共にモデル化することで、画像生成と理解を一様化しています。特に、Jodiは線形ディフュージョントランスフォーマーと役割切り替え機能を採用して、以下の3つの特徴付きタスクを実行できます：画像と複数のラベルを同時に生成する「共通生成」、任意のラベルの組み合わせに基づいて画像を生成する「制御可能生成」、ある画像から複数のラベルを同時に予測する「画像認識」。また、これらの機能を示すために、200,000枚の高品質画像、7つの視覚領域の自動ラベル、LLM生成されたキャプションを含む「Joint-1.6Mデータセット」を紹介します。拡張性が強いため、Jodiはビジュアル生成と理解の両方のタスクで優れていることが証明され、より広い範囲の視覚領域においても強力な性能を示しています。コードは、https://github.com/VIPL-GENUN/Jodi から利用できます。",
      "upvotes": 2,
      "discussionId": "683533510c0aff775f3eb7ab",
      "ai_summary": "Jodi, a diffusion framework using a linear diffusion transformer and role switch mechanism, unifies visual generation and understanding, performing joint, controllable, and perceptual tasks effectively across multiple visual domains.",
      "ai_keywords": [
        "diffusion framework",
        "linear diffusion transformer",
        "role switch mechanism",
        "joint generation",
        "controllable generation",
        "image perception",
        "Joint-1.6M dataset",
        "visual domains",
        "LLM-generated captions"
      ]
    },
    "publishedAt": "2025-05-25T06:40:52.000Z",
    "title": "Jodi: Unification of Visual Generation and Understanding via Joint\n  Modeling",
    "summary": "Visual generation and understanding are two deeply interconnected aspects of\nhuman intelligence, yet they have been traditionally treated as separate tasks\nin machine learning. In this paper, we propose Jodi, a diffusion framework that\nunifies visual generation and understanding by jointly modeling the image\ndomain and multiple label domains. Specifically, Jodi is built upon a linear\ndiffusion transformer along with a role switch mechanism, which enables it to\nperform three particular types of tasks: (1) joint generation, where the model\nsimultaneously generates images and multiple labels; (2) controllable\ngeneration, where images are generated conditioned on any combination of\nlabels; and (3) image perception, where multiple labels can be predicted at\nonce from a given image. Furthermore, we present the Joint-1.6M dataset, which\ncontains 200,000 high-quality images collected from public sources, automatic\nlabels for 7 visual domains, and LLM-generated captions. Extensive experiments\ndemonstrate that Jodi excels in both generation and understanding tasks and\nexhibits strong extensibility to a wider range of visual domains. Code is\navailable at https://github.com/VIPL-GENUN/Jodi.",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/640c64779e5247967ff1e0b2/Mqa2jx5wM-f5Fc1pdd6sz.jpeg",
      "https://cdn-uploads.huggingface.co/production/uploads/640c64779e5247967ff1e0b2/-ubqvKPbhrxAjIKnj7dPU.jpeg",
      "https://cdn-uploads.huggingface.co/production/uploads/640c64779e5247967ff1e0b2/Y4ub2WOy0Adp1TfcT90R3.jpeg",
      "https://cdn-uploads.huggingface.co/production/uploads/640c64779e5247967ff1e0b2/lvdM2FUHFI2ut7cgELTh9.jpeg"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.19084.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "640c64779e5247967ff1e0b2",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1678533946170-640c64779e5247967ff1e0b2.jpeg",
      "fullname": "Yifeng Xu",
      "name": "xyfJASON",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 3
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.18773",
      "authors": [
        {
          "_id": "6835727f9da2b91fb4e30473",
          "name": "Jamie Hayes",
          "hidden": false
        },
        {
          "_id": "6835727f9da2b91fb4e30474",
          "name": "Ilia Shumailov",
          "hidden": false
        },
        {
          "_id": "6835727f9da2b91fb4e30475",
          "name": "Christopher A. Choquette-Choo",
          "hidden": false
        },
        {
          "_id": "6835727f9da2b91fb4e30476",
          "name": "Matthew Jagielski",
          "hidden": false
        },
        {
          "_id": "6835727f9da2b91fb4e30477",
          "name": "George Kaissis",
          "hidden": false
        },
        {
          "_id": "6835727f9da2b91fb4e30478",
          "name": "Katherine Lee",
          "hidden": false
        },
        {
          "_id": "6835727f9da2b91fb4e30479",
          "name": "Milad Nasr",
          "hidden": false
        },
        {
          "_id": "6835727f9da2b91fb4e3047a",
          "name": "Sahra Ghalebikesabi",
          "hidden": false
        },
        {
          "_id": "6835727f9da2b91fb4e3047b",
          "name": "Niloofar Mireshghallah",
          "hidden": false
        },
        {
          "_id": "6835727f9da2b91fb4e3047c",
          "name": "Meenatchi Sundaram Mutu Selva Annamalai",
          "hidden": false
        },
        {
          "_id": "6835727f9da2b91fb4e3047d",
          "name": "Igor Shilov",
          "hidden": false
        },
        {
          "_id": "6835727f9da2b91fb4e3047e",
          "name": "Matthieu Meeus",
          "hidden": false
        },
        {
          "_id": "6835727f9da2b91fb4e3047f",
          "name": "Yves-Alexandre de Montjoye",
          "hidden": false
        },
        {
          "_id": "6835727f9da2b91fb4e30480",
          "name": "Franziska Boenisch",
          "hidden": false
        },
        {
          "_id": "6835727f9da2b91fb4e30481",
          "name": "Adam Dziedzic",
          "hidden": false
        },
        {
          "_id": "6835727f9da2b91fb4e30482",
          "user": {
            "_id": "663c3b587e7bc3d3e4a54ffb",
            "avatarUrl": "/avatars/681abf7e4a85184667015cefefa226c6.svg",
            "isPro": false,
            "fullname": "A. Feder Cooper",
            "user": "pasta41",
            "type": "user"
          },
          "name": "A. Feder Cooper",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-05-27T08:06:24.708Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-24T16:23:43.000Z",
      "submittedOnDailyAt": "2025-05-27T06:39:29.837Z",
      "title": "大きなデータセットと（中度）大きな言語モデルに対する強力なメンバーシップ推論攻撃",
      "submittedOnDailyBy": {
        "_id": "6475c2794766357252e69e9f",
        "avatarUrl": "/avatars/db428715dfd2239df2aeaaff1282323f.svg",
        "isPro": false,
        "fullname": "i",
        "user": "iliashum",
        "type": "user"
      },
      "summary": "最先進のメンバーシップ推論攻撃（MIA）は、複数の参照モデルを訓練する必要があり、これが大規模な事前学習済み言語モデル（LLM）に対してスケーリングできなくなる。その結果、先行研究は、弱い攻撃を回避するために参照モデルの訓練を避ける（例：微調節攻撃）か、小規模のモデルやデータセットに対して強い攻撃を適用することを依存していました。しかし、弱い攻撃は脆弱であり、近似任意の成功を達成することができることが示され、簡略化された設定での強い攻撃からのディスカッションは、現在のLLMに対してはそのまま適用できないことがわかりました。これらの課題により重要な質問が出てきました：先行研究で見られた制限は攻撃の設計選択によるものであるか、またはMIAは本質的にLLMに対して無効であるか？この質問に対して、LiRA（最強のMIAの一つ）をGPT-2アーキテクチャー（パラメータ数が10Mから1Bまで）にスケーリングし、C4データセットから200億トークンを参照モデルに訓練することで解決策を求めました。我々の結果は、LLM上のMIAに関する理解を3つの重要な点で進めました：（1）強いMIAは事前学習済みLLMに成功できる；（2）その効果性は実用的な設定では限定されている（例：AUC<0.7）；（3）MIAの成功と関連するプライバシーメトリックとの関係は、先行研究で示されているようなものとは異なりません。",
      "upvotes": 2,
      "discussionId": "683572809da2b91fb4e30513",
      "ai_summary": "Scaling LiRA membership inference attacks to large pre-trained language models shows that while these attacks can succeed, their effectiveness is limited and does not definitively correlate with privacy metrics.",
      "ai_keywords": [
        "membership inference attacks",
        "MIAs",
        "reference models",
        "fine-tuning attacks",
        "pre-trained language models",
        "LLMs",
        "LiRA",
        "GPT-2",
        "tokens",
        "C4 dataset",
        "AUC",
        "privacy metrics"
      ]
    },
    "publishedAt": "2025-05-24T12:23:43.000Z",
    "title": "Strong Membership Inference Attacks on Massive Datasets and (Moderately)\n  Large Language Models",
    "summary": "State-of-the-art membership inference attacks (MIAs) typically require\ntraining many reference models, making it difficult to scale these attacks to\nlarge pre-trained language models (LLMs). As a result, prior research has\neither relied on weaker attacks that avoid training reference models (e.g.,\nfine-tuning attacks), or on stronger attacks applied to small-scale models and\ndatasets. However, weaker attacks have been shown to be brittle - achieving\nclose-to-arbitrary success - and insights from strong attacks in simplified\nsettings do not translate to today's LLMs. These challenges have prompted an\nimportant question: are the limitations observed in prior work due to attack\ndesign choices, or are MIAs fundamentally ineffective on LLMs? We address this\nquestion by scaling LiRA - one of the strongest MIAs - to GPT-2 architectures\nranging from 10M to 1B parameters, training reference models on over 20B tokens\nfrom the C4 dataset. Our results advance the understanding of MIAs on LLMs in\nthree key ways: (1) strong MIAs can succeed on pre-trained LLMs; (2) their\neffectiveness, however, remains limited (e.g., AUC<0.7) in practical settings;\nand, (3) the relationship between MIA success and related privacy metrics is\nnot as straightforward as prior work has suggested.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.18773.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6475c2794766357252e69e9f",
      "avatarUrl": "/avatars/db428715dfd2239df2aeaaff1282323f.svg",
      "fullname": "i",
      "name": "iliashum",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 4
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2505.18384",
      "authors": [
        {
          "_id": "68354f30d795fadab0623699",
          "user": {
            "_id": "65319bd7f85995389d4f019c",
            "avatarUrl": "/avatars/657858b8435b220c9a29918c0dae9c6d.svg",
            "isPro": false,
            "fullname": "Boyi Wei",
            "user": "boyiwei",
            "type": "user"
          },
          "name": "Boyi Wei",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T07:49:18.459Z",
          "hidden": false
        },
        {
          "_id": "68354f30d795fadab062369a",
          "name": "Benedikt Stroebl",
          "hidden": false
        },
        {
          "_id": "68354f30d795fadab062369b",
          "name": "Jiacen Xu",
          "hidden": false
        },
        {
          "_id": "68354f30d795fadab062369c",
          "name": "Joie Zhang",
          "hidden": false
        },
        {
          "_id": "68354f30d795fadab062369d",
          "name": "Zhou Li",
          "hidden": false
        },
        {
          "_id": "68354f30d795fadab062369e",
          "name": "Peter Henderson",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-23T21:18:59.000Z",
      "submittedOnDailyAt": "2025-05-27T04:06:40.688Z",
      "title": "動的リスク評価における攻撃的セキュリティアウトリジスト",
      "submittedOnDailyBy": {
        "_id": "65319bd7f85995389d4f019c",
        "avatarUrl": "/avatars/657858b8435b220c9a29918c0dae9c6d.svg",
        "isPro": false,
        "fullname": "Boyi Wei",
        "user": "boyiwei",
        "type": "user"
      },
      "summary": "基礎モデルは、自動的なプログラマーとしての性能が進歩しています、それにより攻撃的なサイバーオペレーションも自動化される可能性があります。現在の最先端モデルの評価は、これらのアウトプッティングエージェントのサイバーセキュリティリスクを調査していますが、ほとんどが対手が実世界での自由度を考慮していません。特に、強力なバリデーターと財務的な奨励を受ける場合、攻撃的なサイバーセキュリティのためのアウトプッティングエージェントは、対手が試行錯誤で改善することができます。私たちは、サイバーセキュリティのコンテキストで拡張された威脅モデルを考慮するべきであると主張しています、対手が状態付きや非状態付き環境での自由度を強調します。私たちは、対手が固定した計算バジューで（本研究では8 H100 GPU時間）インターコードCTFでのサイバーセキュリティ能力を40％以上改善することができることを示します。これらの結果は、アウトプッティングエージェントのサイバーセキュリティリスクを動的に評価する必要を強調し、リスクの代表的な画像を描く必要を示しています。",
      "upvotes": 2,
      "discussionId": "68354f30d795fadab06236fe",
      "githubRepo": "https://github.com/boyiwei/Dynamic-Risk-Assessment",
      "ai_summary": "Adversaries can significantly enhance foundation model capabilities in offensive cybersecurity with limited computational resources, underscoring the need for dynamic threat model assessments.",
      "ai_keywords": [
        "foundation models",
        "autonomous programmers",
        "offensive cybersecurity",
        "model audits",
        "cybersecurity risks",
        "verifiers",
        "financial incentives",
        "iterative improvement",
        "threat model",
        "stateful environments",
        "non-stateful environments",
        "compute budget",
        "InterCode CTF"
      ]
    },
    "publishedAt": "2025-05-23T17:18:59.000Z",
    "title": "Dynamic Risk Assessments for Offensive Cybersecurity Agents",
    "summary": "Foundation models are increasingly becoming better autonomous programmers,\nraising the prospect that they could also automate dangerous offensive\ncyber-operations. Current frontier model audits probe the cybersecurity risks\nof such agents, but most fail to account for the degrees of freedom available\nto adversaries in the real world. In particular, with strong verifiers and\nfinancial incentives, agents for offensive cybersecurity are amenable to\niterative improvement by would-be adversaries. We argue that assessments should\ntake into account an expanded threat model in the context of cybersecurity,\nemphasizing the varying degrees of freedom that an adversary may possess in\nstateful and non-stateful environments within a fixed compute budget. We show\nthat even with a relatively small compute budget (8 H100 GPU Hours in our\nstudy), adversaries can improve an agent's cybersecurity capability on\nInterCode CTF by more than 40\\% relative to the baseline -- without any\nexternal assistance. These results highlight the need to evaluate agents'\ncybersecurity risk in a dynamic manner, painting a more representative picture\nof risk.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.18384.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "65319bd7f85995389d4f019c",
      "avatarUrl": "/avatars/657858b8435b220c9a29918c0dae9c6d.svg",
      "fullname": "Boyi Wei",
      "name": "boyiwei",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.16312",
      "authors": [
        {
          "_id": "6830109ea20ebb4738e76931",
          "user": {
            "_id": "6747d38098fe79433a8c4580",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/BrcsTfusqfu9p9uv1NeX6.png",
            "isPro": false,
            "fullname": "Jiawei Liu",
            "user": "Jiawei1222",
            "type": "user"
          },
          "name": "Jiawei Liu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-26T08:15:09.111Z",
          "hidden": false
        },
        {
          "_id": "6830109ea20ebb4738e76932",
          "name": "Qisi Chen",
          "hidden": false
        },
        {
          "_id": "6830109ea20ebb4738e76933",
          "name": "Jianshu Zhang",
          "hidden": false
        },
        {
          "_id": "6830109ea20ebb4738e76934",
          "name": "Quan Liu",
          "hidden": false
        },
        {
          "_id": "6830109ea20ebb4738e76935",
          "name": "Defu Lian",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-22T07:07:43.000Z",
      "submittedOnDailyAt": "2025-05-27T05:04:30.217Z",
      "title": "EquivPruner: ライブラリーモデルベースド検索の効率化と質の向上によるアクションプリニング",
      "submittedOnDailyBy": {
        "_id": "6747d38098fe79433a8c4580",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/BrcsTfusqfu9p9uv1NeX6.png",
        "isPro": false,
        "fullname": "Jiawei Liu",
        "user": "Jiawei1222",
        "type": "user"
      },
      "summary": "大語言モデル（LLMs）は、複雑な理由を通じて探索アルゴリズムを優れていますが、現在の戦略は、意味的に等価なステップの冗長な探索により、タグン消費が大幅に増加しています。既存の意味的な類似性方法は、数理論や数学的な論理などの領域特有のコンテキストで、その等価性を正確に識別することが難しいです。これに対して、私たちはEquivPrunerを提案します。EquivPrunerは、LLMの理由の探索時に意味的に等価なアクションを識別し、削除する簡単で効果的なアプローチです。また、私たちは、数理表現の等価性を学習するためのデータセットMathEquivを初めて作成しました。これにより、軽量の等価性検出器の訓練が可能になります。様々なモデルとタスクの幅広い範囲での検証により、EquivPrunerはタグン消費を大幅に減少し、探索の効率を向上させ、理由の正確性を強化します。例えば、GSM8Kに対してQwen2.5-Math-7B-Instructに適用した場合、EquivPrunerはタグン消費を48.1%減少させ、精度も向上しました。私たちのコードは、https://github.com/Lolo1222/EquivPrunerに公開されています。",
      "upvotes": 2,
      "discussionId": "6830109fa20ebb4738e769a3",
      "githubRepo": "https://github.com/Lolo1222/EquivPruner",
      "ai_summary": "EquivPruner reduces token consumption and improves reasoning accuracy by pruning semantically equivalent actions in LLM searches, leveraging a new dataset for mathematical equivalence.",
      "ai_keywords": [
        "Large Language Models (LLMs)",
        "semantic similarity",
        "semantically equivalent actions",
        "EquivPruner",
        "MathEquiv",
        "equivalence detector",
        "GSM8K"
      ]
    },
    "publishedAt": "2025-05-22T03:07:43.000Z",
    "title": "EquivPruner: Boosting Efficiency and Quality in LLM-Based Search via\n  Action Pruning",
    "summary": "Large Language Models (LLMs) excel at complex reasoning through search\nalgorithms, yet current strategies often suffer from massive token consumption\ndue to redundant exploration of semantically equivalent steps. Existing\nsemantic similarity methods struggle to accurately identify such equivalence in\ndomain-specific contexts like mathematical reasoning. To address this, we\npropose EquivPruner, a simple yet effective approach that identifies and prunes\nsemantically equivalent actions during LLM reasoning search. We also introduce\nMathEquiv, the first dataset we created for mathematical statement equivalence,\nwhich enables the training of a lightweight equivalence detector. Extensive\nexperiments across various models and tasks demonstrate that EquivPruner\nsignificantly reduces token consumption, improving searching efficiency and\noften bolstering reasoning accuracy. For instance, when applied to\nQwen2.5-Math-7B-Instruct on GSM8K, EquivPruner reduced token consumption by\n48.1\\% while also improving accuracy. Our code is available at\nhttps://github.com/Lolo1222/EquivPruner.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.16312.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "6747d38098fe79433a8c4580",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/BrcsTfusqfu9p9uv1NeX6.png",
      "fullname": "Jiawei Liu",
      "name": "Jiawei1222",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.19800",
      "authors": [
        {
          "_id": "68356e736bb42c7e99d2d266",
          "user": {
            "_id": "5f04bd384ec31d33a72116d1",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1594145966049-noauth.jpeg",
            "isPro": false,
            "fullname": "Zaid Alyafeai",
            "user": "Zaid",
            "type": "user"
          },
          "name": "Zaid Alyafeai",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-27T08:47:10.858Z",
          "hidden": false
        },
        {
          "_id": "68356e736bb42c7e99d2d267",
          "name": "Maged S. Al-Shaibani",
          "hidden": false
        },
        {
          "_id": "68356e736bb42c7e99d2d268",
          "name": "Bernard Ghanem",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-26T10:31:26.000Z",
      "submittedOnDailyAt": "2025-05-27T07:09:18.429Z",
      "title": "モール：科学論文でのデータベース抽出と検証を用いたLLMs",
      "submittedOnDailyBy": {
        "_id": "5f04bd384ec31d33a72116d1",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1594145966049-noauth.jpeg",
        "isPro": false,
        "fullname": "Zaid Alyafeai",
        "user": "Zaid",
        "type": "user"
      },
      "summary": "メタデータの抽出は、データセットのカテゴリりと保存に重要であり、科学研究の効果的な研究発見と再現性を促進するために必要です。現在の科学研究の指数的な成長の背景下、これが特に重要です。また、Masader（Alyafeai et al., 2021）は、アラビア語のNLPデータセットの学術論文から幅広くのメタデータ属性を抽出するための基盤を立てましたが、手動注釈により重く依存しています。本論文では、MOLEというフレームワークを提案し、これは大規模言語モデル（LLMs）を使ってアラビア語以外の言語のデータセットを含む科学論文からメタデータ属性を自動的に抽出することを可能にします。フォーマットの複数種類のドキュメント全体を処理し、一致した出力を確保するための強力的な検証機構を採用しています。また、このタスクの研究進歩を評価するために新たなベンチマークを導入します。コンテキスト長、few-shot learning、ホームブラウズ統合のシステマ的な分析を通じて、現代のLLMsがこのタスクの自動化において希望的な結果を示し、これは将来的な工夫の必要性を強調します。これらの研究コミュニティには、コードをリリースします：https://github.com/IVUL-KAUST/MOLE、データセットをリリースします：https://huggingface.co/datasets/IVUL-KAUST/MOLE。",
      "upvotes": 1,
      "discussionId": "68356e746bb42c7e99d2d2af",
      "projectPage": "https://ivul-kaust.github.io/MOLE/blog",
      "githubRepo": "https://github.com/IVUL-KAUST/MOLE",
      "ai_summary": "A framework leveraging Large Language Models (LLMs) is introduced for automatic metadata extraction from scientific papers, with a focus on datasets from languages other than Arabic.",
      "ai_keywords": [
        "Large Language Models (LLMs)",
        "schema-driven methodology",
        "benchmark",
        "few-shot learning",
        "web browsing integration"
      ]
    },
    "publishedAt": "2025-05-26T06:31:26.000Z",
    "title": "MOLE: Metadata Extraction and Validation in Scientific Papers Using LLMs",
    "summary": "Metadata extraction is essential for cataloging and preserving datasets,\nenabling effective research discovery and reproducibility, especially given the\ncurrent exponential growth in scientific research. While Masader (Alyafeai et\nal.,2021) laid the groundwork for extracting a wide range of metadata\nattributes from Arabic NLP datasets' scholarly articles, it relies heavily on\nmanual annotation. In this paper, we present MOLE, a framework that leverages\nLarge Language Models (LLMs) to automatically extract metadata attributes from\nscientific papers covering datasets of languages other than Arabic. Our\nschema-driven methodology processes entire documents across multiple input\nformats and incorporates robust validation mechanisms for consistent output.\nAdditionally, we introduce a new benchmark to evaluate the research progress on\nthis task. Through systematic analysis of context length, few-shot learning,\nand web browsing integration, we demonstrate that modern LLMs show promising\nresults in automating this task, highlighting the need for further future work\nimprovements to ensure consistent and reliable performance. We release the\ncode: https://github.com/IVUL-KAUST/MOLE and dataset:\nhttps://huggingface.co/datasets/IVUL-KAUST/MOLE for the research community.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.19800.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "5f04bd384ec31d33a72116d1",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1594145966049-noauth.jpeg",
      "fullname": "Zaid Alyafeai",
      "name": "Zaid",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 48
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.19056",
      "authors": [
        {
          "_id": "68357c8ef0b7aba41a858b61",
          "name": "Harethah Abu Shairah",
          "hidden": false
        },
        {
          "_id": "68357c8ef0b7aba41a858b62",
          "name": "Hasan Abed Al Kader Hammoud",
          "hidden": false
        },
        {
          "_id": "68357c8ef0b7aba41a858b63",
          "name": "Bernard Ghanem",
          "hidden": false
        },
        {
          "_id": "68357c8ef0b7aba41a858b64",
          "name": "George Turkiyyah",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-25T09:18:24.000Z",
      "submittedOnDailyAt": "2025-05-27T07:21:18.247Z",
      "title": "「LLM Abliteration Attacks」に対するシンプルな防御法",
      "submittedOnDailyBy": {
        "_id": "642b51385bf2355d02a23d15",
        "avatarUrl": "/avatars/87985347643b2647555f2453fa4d94fb.svg",
        "isPro": true,
        "fullname": "Hasan Abed Al Kader Hammoud",
        "user": "hammh0a",
        "type": "user"
      },
      "summary": "大語言モデル（LLMs）は通常安全ガイドラインに従うために有害な指示を拒否することで対応しています。最近の攻撃では、abliterationと呼ばれている攻撃では、拒否行為に最も責任を負う単一の潜在的な方向を孤立して抑制し、モデルが不道德な内容を生成することを可能にします。私たちは、モデルが拒否を生成する方法を変更する防御策を提案しています。私たちは、有害なプロンプトと完全な回答を含む拒否理由を説明するデータセットを構築しました。次に、私たちは拡張拒否データセットを用いてLlama-2-7B-ChatとQwen2.5-Instruct（150Mと3Bパラメータ）を微調適し、その結果のシステムを有害なプロンプトのセットにおいて評価しました。私たちの実験では、拡張拒否モデルは高い拒否率を維持し、最大で10%だけ減少しますが、基準モデルの拒否率はabliteration後に70-80%減少します。安全性と有用性の広範囲評価により、拡張拒否の微調適はabliteration攻撃を中和し、一般的な性能を保つことを示しています。",
      "upvotes": 1,
      "discussionId": "68357c8ff0b7aba41a858b96",
      "ai_summary": "Modifying models to generate justified refusals through fine-tuning on an extended-refusal dataset mitigates ablation attacks while maintaining high refusal rates and general performance.",
      "ai_keywords": [
        "large language models",
        "LLMs",
        "ablation",
        "latent direction",
        "refusal behavior",
        "extended-refusal dataset",
        "Llama-2-7B-Chat",
        "Qwen2.5-Instruct",
        "parameter-efficient fine-tuning"
      ]
    },
    "publishedAt": "2025-05-25T05:18:24.000Z",
    "title": "An Embarrassingly Simple Defense Against LLM Abliteration Attacks",
    "summary": "Large language models (LLMs) are typically aligned to comply with safety\nguidelines by refusing harmful instructions. A recent attack, termed\nabliteration, isolates and suppresses the single latent direction most\nresponsible for refusal behavior, enabling the model to generate unethical\ncontent. We propose a defense that modifies how models generate refusals. We\nconstruct an extended-refusal dataset that contains harmful prompts with a full\nresponse that justifies the reason for refusal. We then fine-tune\nLlama-2-7B-Chat and Qwen2.5-Instruct (1.5B and 3B parameters) on our\nextended-refusal dataset, and evaluate the resulting systems on a set of\nharmful prompts. In our experiments, extended-refusal models maintain high\nrefusal rates, dropping at most by 10%, whereas baseline models' refusal rates\ndrop by 70-80% after abliteration. A broad evaluation of safety and utility\nshows that extended-refusal fine-tuning neutralizes the abliteration attack\nwhile preserving general performance.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.19056.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "642b51385bf2355d02a23d15",
      "avatarUrl": "/avatars/87985347643b2647555f2453fa4d94fb.svg",
      "fullname": "Hasan Abed Al Kader Hammoud",
      "name": "hammh0a",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 5
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2505.18323",
      "authors": [
        {
          "_id": "683573bc0830dfc67834f1b5",
          "name": "Nicolas Küchler",
          "hidden": false
        },
        {
          "_id": "683573bc0830dfc67834f1b6",
          "name": "Ivan Petrov",
          "hidden": false
        },
        {
          "_id": "683573bc0830dfc67834f1b7",
          "name": "Conrad Grobler",
          "hidden": false
        },
        {
          "_id": "683573bc0830dfc67834f1b8",
          "name": "Ilia Shumailov",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-23T19:28:45.000Z",
      "submittedOnDailyAt": "2025-05-27T06:44:57.820Z",
      "title": "アーキテクチャルバックドラッグフォラティングバッチデータステイティングとモデル推論操作",
      "submittedOnDailyBy": {
        "_id": "6475c2794766357252e69e9f",
        "avatarUrl": "/avatars/db428715dfd2239df2aeaaff1282323f.svg",
        "isPro": false,
        "fullname": "i",
        "user": "iliashum",
        "type": "user"
      },
      "summary": "近10年間、学術界はニューラルネットワークのバックドアーに焦点を当て、主に分類タスクで敵対者がモデルの予測を操作することに焦点を当てていました。これらの予測変更攻撃は明確に悪意を持っていますが、これらの攻撃が実際にどのような影響を与えるかは明確ではありませんでした。本論文では、最近のアーキテクチャーバックドアーの進歩に基づいた新しいより強力なバックドアーのクラスを介して、これらのバックドアーがバッチごとの推論を利用したハードウェア利用の一般的な手法を採用して、大規模なユーザデータの操作と盗難を可能にします。バッチごとの処理を目指し、これらのアーキテクチャーバックドアーは、並行したユーザーリクエスト間の情報流出を促成し、攻撃者が同じバッチ内の他のユーザーに対するモデルのレスポンスを完全に制御できるようにします。言い換えれば、モデルのアーキテクチャを変更できる攻撃者は、同じバッチ内の他のユーザーのモデルの入力と出力を設定し、盗難できます。これらの攻撃は、その可能性や効果性が警戒に必要なものであり、実際に導入されているモデルアーキテクチャに簡単に注入でき、ユーザープライバリやシステムの整備性に真の悪意の脅威を見せています。重要なことに、これらの新しいクラスの脆弱性を対処するために、我々は、先行研究のように大語言モデルを依存した攻撃ベクトルに対する正式的な保証を提供することで、確定的な対策戦略を提案します。我々の対策戦略は、モデルグラフを分析し、同じバッチ内の異なるユーザーの入力の非干渉性を証明する新しい情報流コントロール機構を使用しています。我々の対策戦略を用いて、Hugging Faceでホストされているモデルに対して大規模な分析を行い、動的なディジタル化の使用によってバッチのエントリー間での情報流出を引き起こすモデルが200点以上あることを発見しました。",
      "upvotes": 1,
      "discussionId": "683573bc0830dfc67834f212",
      "ai_summary": "A novel class of backdoors in neural network architectures exploits batched inference to enable large-scale data manipulation, demonstrating information leakage and control over user inputs and outputs, with a proposed mitigation strategy using Information Flow Control.",
      "ai_keywords": [
        "backdoors",
        "neural networks",
        "classification tasks",
        "batched inference",
        "hardware utilization",
        "information leakage",
        "mitagation strategy",
        "Information Flow Control",
        "Hugging Face",
        "dynamic quantization"
      ]
    },
    "publishedAt": "2025-05-23T15:28:45.000Z",
    "title": "Architectural Backdoors for Within-Batch Data Stealing and Model\n  Inference Manipulation",
    "summary": "For nearly a decade the academic community has investigated backdoors in\nneural networks, primarily focusing on classification tasks where adversaries\nmanipulate the model prediction. While demonstrably malicious, the immediate\nreal-world impact of such prediction-altering attacks has remained unclear. In\nthis paper we introduce a novel and significantly more potent class of\nbackdoors that builds upon recent advancements in architectural backdoors. We\ndemonstrate how these backdoors can be specifically engineered to exploit\nbatched inference, a common technique for hardware utilization, enabling\nlarge-scale user data manipulation and theft. By targeting the batching\nprocess, these architectural backdoors facilitate information leakage between\nconcurrent user requests and allow attackers to fully control model responses\ndirected at other users within the same batch. In other words, an attacker who\ncan change the model architecture can set and steal model inputs and outputs of\nother users within the same batch. We show that such attacks are not only\nfeasible but also alarmingly effective, can be readily injected into prevalent\nmodel architectures, and represent a truly malicious threat to user privacy and\nsystem integrity. Critically, to counteract this new class of vulnerabilities,\nwe propose a deterministic mitigation strategy that provides formal guarantees\nagainst this new attack vector, unlike prior work that relied on Large Language\nModels to find the backdoors. Our mitigation strategy employs a novel\nInformation Flow Control mechanism that analyzes the model graph and proves\nnon-interference between different user inputs within the same batch. Using our\nmitigation strategy we perform a large scale analysis of models hosted through\nHugging Face and find over 200 models that introduce (unintended) information\nleakage between batch entries due to the use of dynamic quantization.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.18323.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6475c2794766357252e69e9f",
      "avatarUrl": "/avatars/db428715dfd2239df2aeaaff1282323f.svg",
      "fullname": "i",
      "name": "iliashum",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 4
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2505.15957",
      "authors": [
        {
          "_id": "6830745670e219f5de8ad360",
          "user": {
            "_id": "646fa3016441111304fec68d",
            "avatarUrl": "/avatars/923629340f3785ae8c6e52cf3674d5c2.svg",
            "isPro": false,
            "fullname": "Chih-Kai Yang",
            "user": "zenyn",
            "type": "user"
          },
          "name": "Chih-Kai Yang",
          "status": "extracted_confirmed",
          "statusLastChangedAt": "2025-05-23T13:21:28.397Z",
          "hidden": false
        },
        {
          "_id": "6830745670e219f5de8ad361",
          "name": "Neo S. Ho",
          "hidden": false
        },
        {
          "_id": "6830745670e219f5de8ad362",
          "name": "Hung-yi Lee",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-21T19:17:29.000Z",
      "submittedOnDailyAt": "2025-05-27T01:41:21.824Z",
      "title": "ホリスティックな評価に向けた大規模な音声-言語モデルの評価：一貫した調査",
      "submittedOnDailyBy": {
        "_id": "646fa3016441111304fec68d",
        "avatarUrl": "/avatars/923629340f3785ae8c6e52cf3674d5c2.svg",
        "isPro": false,
        "fullname": "Chih-Kai Yang",
        "user": "zenyn",
        "type": "user"
      },
      "summary": "LALM（大規模音声言語モデル）の進歩により、大規模言語モデル（LLM）に音声能力を追加したモデルが、多様な音声タスクで普遍的な優秀性を示すことが期待されています。これらのモデルの性能を評価するためには、数多くのベンチマークが出現しましたが、それらは分断していて、構造化されたタクロニミーを欠いています。この隙を埋めるために、私たちは詳細な調査を行い、LALMの評価に適したシステマティックなタクロニミーを提案します。これらのタクロニミーは、目的に基づいて4つの次元に分類されます：（1）一般的な音声認識と処理、（2）知識と理由論、（3）ダイラウォール向きの能力、（4）公平性、安全性と信頼性。各カテゴリ内で詳細な概要を提供し、この分野での課題を明らかにし、将来的な可能性を示す方向についてのヒントを提供します。私たちの知識の限りでは、これはLALMの評価に特化した最初の調査であり、コミュニティに明確なガイドラインを提供します。調査した論文の集まりを公開し、その更新を活発に行い、この分野の進歩をサポートします。",
      "upvotes": 1,
      "discussionId": "6830745770e219f5de8ad38b",
      "projectPage": "https://github.com/ckyang1124/LALM-Evaluation-Survey",
      "githubRepo": "https://github.com/ckyang1124/LALM-Evaluation-Survey",
      "ai_summary": "A survey proposes a systematic taxonomy for evaluating large audio-language models across dimensions including auditory awareness, knowledge reasoning, dialogue ability, and fairness, to address fragmented benchmarks in the field.",
      "ai_keywords": [
        "large audio-language models",
        "LALMs",
        "large language models",
        "LLMs",
        "auditory capabilities",
        "general auditory awareness",
        "processing",
        "knowledge and reasoning",
        "dialogue-oriented ability",
        "fairness",
        "safety",
        "trustworthiness",
        "taxonomy",
        "evaluations",
        "benchmark",
        "survey",
        "guidelines"
      ]
    },
    "publishedAt": "2025-05-21T15:17:29.000Z",
    "title": "Towards Holistic Evaluation of Large Audio-Language Models: A\n  Comprehensive Survey",
    "summary": "With advancements in large audio-language models (LALMs), which enhance large\nlanguage models (LLMs) with auditory capabilities, these models are expected to\ndemonstrate universal proficiency across various auditory tasks. While numerous\nbenchmarks have emerged to assess LALMs' performance, they remain fragmented\nand lack a structured taxonomy. To bridge this gap, we conduct a comprehensive\nsurvey and propose a systematic taxonomy for LALM evaluations, categorizing\nthem into four dimensions based on their objectives: (1) General Auditory\nAwareness and Processing, (2) Knowledge and Reasoning, (3) Dialogue-oriented\nAbility, and (4) Fairness, Safety, and Trustworthiness. We provide detailed\noverviews within each category and highlight challenges in this field, offering\ninsights into promising future directions. To the best of our knowledge, this\nis the first survey specifically focused on the evaluations of LALMs, providing\nclear guidelines for the community. We will release the collection of the\nsurveyed papers and actively maintain it to support ongoing advancements in the\nfield.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.15957.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "646fa3016441111304fec68d",
      "avatarUrl": "/avatars/923629340f3785ae8c6e52cf3674d5c2.svg",
      "fullname": "Chih-Kai Yang",
      "name": "zenyn",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": true
  }
]