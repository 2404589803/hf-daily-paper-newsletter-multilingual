[
  {
    "paper": {
      "id": "2502.13923",
      "authors": [
        {
          "_id": "67b6b0688b56622e70b9e83e",
          "name": "Shuai Bai",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e83f",
          "name": "Keqin Chen",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e840",
          "name": "Xuejing Liu",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e841",
          "name": "Jialin Wang",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e842",
          "name": "Wenbin Ge",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e843",
          "name": "Sibo Song",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e844",
          "name": "Kai Dang",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e845",
          "name": "Peng Wang",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e846",
          "name": "Shijie Wang",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e847",
          "name": "Jun Tang",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e848",
          "name": "Humen Zhong",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e849",
          "name": "Yuanzhi Zhu",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e84a",
          "user": {
            "_id": "6417fa211f1f3b0fa811edc0",
            "avatarUrl": "/avatars/fa9e1ef1472a736c2ceebe12b77d6c89.svg",
            "isPro": false,
            "fullname": "Mingkun Yang",
            "user": "ayumiymk",
            "type": "user"
          },
          "name": "Mingkun Yang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-20T09:35:44.878Z",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e84b",
          "name": "Zhaohai Li",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e84c",
          "name": "Jianqiang Wan",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e84d",
          "name": "Pengfei Wang",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e84e",
          "name": "Wei Ding",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e84f",
          "name": "Zheren Fu",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e850",
          "name": "Yiheng Xu",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e851",
          "name": "Jiabo Ye",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e852",
          "name": "Xi Zhang",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e853",
          "name": "Tianbao Xie",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e854",
          "name": "Zesen Cheng",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e855",
          "name": "Hang Zhang",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e856",
          "name": "Zhibo Yang",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e857",
          "user": {
            "_id": "645b10e80c73ea27d13f7aca",
            "avatarUrl": "/avatars/95e565306472a15067440b5b43e07a6f.svg",
            "isPro": false,
            "fullname": "xuhaiyang",
            "user": "xhyandwyy",
            "type": "user"
          },
          "name": "Haiyang Xu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-20T09:35:42.372Z",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e858",
          "name": "Junyang Lin",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-19T18:00:14.000Z",
      "title": "Qwen2.5-VL 技術報告",
      "summary": "Qwen2.5-VLは、最新のフラグシップモデルであり、ビジョン言語シリーズの旗手として、基盤的な能力と創新的な機能において著しい進歩を示しています。Qwen2.5-VLは、拡張された視覚認識、正確な物体位置指定、強固な文書解析、長経画の理解において大幅な進歩を遂げています。Qwen2.5-VLの特徴的な機能として、物体の位置指定をボウンディングボックスまたは点を使用して正確に行うことができます。そして、会計書類、フォーム、テーブルから強固な構造化データ抽出、およびチャート、ディアグラム、ラウターの詳細な分析を行うことができます。複雑な入力を処理するために、Qwen2.5-VLは動的な解像度処理と絶対時間エンコーディングを導入し、画像のサイズの異なるものや延長時間のビデオ（最高は数時間）を秒レベルのイベント位置指定で処理することができます。これにより、モデルはスペーススケールと時間動力学を原生的に理解でき、傳統的な正規化手法に依存しないようになります。原生の動的解像度のVision Transformer（ViT）を始めて学習し、ウィンドウアタションを組み込むことで、計算オーバーヘッドを減らしながら、原生の解像度を維持することができます。その結果、Qwen2.5-VLは静的な画像と文書の理解においても、コンピュータや携帯電話の操作などの実世界のスキームでの訳理、ツール使用、タスク実行のための相互作用的なビジョンアガントとしても優れています。Qwen2.5-VLは、エッジAIから高性能計算までの多様な使用ケースを扱うために、3つのサイズで提供されています。フラグシップモデルとして、Qwen2.5-VL-72BはGPT-4oやClaude 3.5 Sonnetと同じレベルの最新モデルと匹敵し、特に文書とディアグラムの理解に優れています。また、Qwen2.5-VLは、Qwen2.5 LLMの核心言語能力を保持しながら、強固な言語性能を維持しています。",
      "upvotes": 48,
      "discussionId": "67b6b0688b56622e70b9e875"
    },
    "publishedAt": "2025-02-19T23:35:06.194Z",
    "title": "Qwen2.5-VL Technical Report",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13923.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "63451cf0a05b51f7ded25505",
      "avatarUrl": "/avatars/dec4bbee4a82b773fc58dfc2dce9dbeb.svg",
      "fullname": "shuai bai",
      "name": "bluelike",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 11
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.13144",
      "authors": [
        {
          "_id": "67b55c7fba22c1ddbb8d5746",
          "user": {
            "_id": "6536187bd34e9f02b9df1c3b",
            "avatarUrl": "/avatars/0b34d62868b93053b0a05062a018b5bd.svg",
            "isPro": false,
            "fullname": "Hao Gao",
            "user": "Hao605",
            "type": "user"
          },
          "name": "Hao Gao",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-19T09:00:48.944Z",
          "hidden": false
        },
        {
          "_id": "67b55c7fba22c1ddbb8d5747",
          "name": "Shaoyu Chen",
          "hidden": false
        },
        {
          "_id": "67b55c7fba22c1ddbb8d5748",
          "name": "Bo Jiang",
          "hidden": false
        },
        {
          "_id": "67b55c7fba22c1ddbb8d5749",
          "name": "Bencheng Liao",
          "hidden": false
        },
        {
          "_id": "67b55c7fba22c1ddbb8d574a",
          "name": "Yiang Shi",
          "hidden": false
        },
        {
          "_id": "67b55c7fba22c1ddbb8d574b",
          "name": "Xiaoyang Guo",
          "hidden": false
        },
        {
          "_id": "67b55c7fba22c1ddbb8d574c",
          "name": "Yuechuan Pu",
          "hidden": false
        },
        {
          "_id": "67b55c7fba22c1ddbb8d574d",
          "name": "Haoran Yin",
          "hidden": false
        },
        {
          "_id": "67b55c7fba22c1ddbb8d574e",
          "name": "Xiangyu Li",
          "hidden": false
        },
        {
          "_id": "67b55c7fba22c1ddbb8d574f",
          "name": "Xinbang Zhang",
          "hidden": false
        },
        {
          "_id": "67b55c7fba22c1ddbb8d5750",
          "name": "Ying Zhang",
          "hidden": false
        },
        {
          "_id": "67b55c7fba22c1ddbb8d5751",
          "name": "Wenyu Liu",
          "hidden": false
        },
        {
          "_id": "67b55c7fba22c1ddbb8d5752",
          "name": "Qian Zhang",
          "hidden": false
        },
        {
          "_id": "67b55c7fba22c1ddbb8d5753",
          "name": "Xinggang Wang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-18T18:59:21.000Z",
      "title": "RAD: 3DGSベースの大規模な強化学習を用いた終端から終端までの運転ポリシーの訓練",
      "summary": "現在の端末から端末までの自動運転（AD）アルゴリズムは通常、イマチェーション学習（IL）パラダイムを軌跡にしています。これは原因の混同と閉路間違いなどの課題を見せています。本研究では、3DGSに基づく閉路リンダストレーニングパラダイムを構築します。3DGSテクニックを活用して、実際の物理世界の写真写真のデジタルリプリカを構築し、ADポリシーが状態空間を広範囲に探索し、大規模な試行錯誤で分布外のシナリオを扱うことができます。安全性向上のために、特設の報酬を設計し、ポリシーが安全的なイベントに対して効果的に対応し、実世界的な原因関係を理解するようにガイドします。人間の運転行動とのマッチングを改善するために、ILはリンダストレーニングの正規化項として組み込まれます。多様な以前に見ぬ3DGS環境を構成した閉路評価ベンチマークを介して、ILベースの方法と比較してRADは大きく多数の閉路メトリックで強い性能を達成し、特に3倍低い衝突率を収めます。詳細な閉路結果は、https://hgao-cv.github.io/RADに公開されています。",
      "upvotes": 22,
      "discussionId": "67b55c80ba22c1ddbb8d579c"
    },
    "publishedAt": "2025-02-19T22:13:49.764Z",
    "title": "RAD: Training an End-to-End Driving Policy via Large-Scale 3DGS-based Reinforcement Learning",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13144.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6536187bd34e9f02b9df1c3b",
      "avatarUrl": "/avatars/0b34d62868b93053b0a05062a018b5bd.svg",
      "fullname": "Hao Gao",
      "name": "Hao605",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.13128",
      "authors": [
        {
          "_id": "67b6c696e9b901edeaf320d5",
          "name": "Zihan Liu",
          "hidden": false
        },
        {
          "_id": "67b6c696e9b901edeaf320d6",
          "name": "Shuangrui Ding",
          "hidden": false
        },
        {
          "_id": "67b6c696e9b901edeaf320d7",
          "name": "Zhixiong Zhang",
          "hidden": false
        },
        {
          "_id": "67b6c696e9b901edeaf320d8",
          "name": "Xiaoyi Dong",
          "hidden": false
        },
        {
          "_id": "67b6c696e9b901edeaf320d9",
          "name": "Pan Zhang",
          "hidden": false
        },
        {
          "_id": "67b6c696e9b901edeaf320da",
          "name": "Yuhang Zang",
          "hidden": false
        },
        {
          "_id": "67b6c696e9b901edeaf320db",
          "name": "Yuhang Cao",
          "hidden": false
        },
        {
          "_id": "67b6c696e9b901edeaf320dc",
          "name": "Dahua Lin",
          "hidden": false
        },
        {
          "_id": "67b6c696e9b901edeaf320dd",
          "name": "Jiaqi Wang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-18T18:52:21.000Z",
      "title": "SongGen: テキストから歌を生成するための一ステップの自動帰納的チャネルフォーマップ",
      "summary": "歌曲生成は、テキスト入力からのボーカルと伴奏の作成であり、領域の複雑さとデータの不足が大きな課題になっています。現在の手法は、多段階生成プロセスを用いていることが多いため、複雑な学習と推論プロセスが生じます。本論文では、完全にオープンソースの単一ステージの自動復元チャネルドライブングツールマシンを提案しています。この提案モデルは、歌詞や楽器の構成、ジャンル、気分、音色などの多様な音楽属性における細かい制御を可能にします。また、ボイスクローニングのための3秒の参照クリップを選択できるようにしています。一つの統一的な自動復元フレームワーク内で、SongGenは、ボーカルと伴奏の混合モードと、ダブルトラックモードをサポートします。ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラックモードでは、ダブルトラック",
      "upvotes": 20,
      "discussionId": "67b6c698e9b901edeaf321a7"
    },
    "publishedAt": "2025-02-20T01:07:44.785Z",
    "title": "SongGen: A Single Stage Auto-regressive Transformer for Text-to-Song Generation",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13128.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64b4eec4faa3181a5eab9c46",
      "avatarUrl": "/avatars/bcc9bf5cbf67546ad2b4c9ec8b96ac96.svg",
      "fullname": "Jiaqi Wang",
      "name": "myownskyW7",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isMod": false,
      "followerCount": 16
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.13685",
      "authors": [
        {
          "_id": "67b6dc1ba7567156c6547880",
          "name": "Jusen Du",
          "hidden": false
        },
        {
          "_id": "67b6dc1ba7567156c6547881",
          "user": {
            "_id": "6246bb33da617c00b48e4d92",
            "avatarUrl": "/avatars/0304a9f6eb7f5dee4d933d03222f94e9.svg",
            "isPro": false,
            "fullname": "Weigao Sun",
            "user": "weigao266",
            "type": "user"
          },
          "name": "Weigao Sun",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-02-20T07:39:08.547Z",
          "hidden": false
        },
        {
          "_id": "67b6dc1ba7567156c6547882",
          "name": "Disen Lan",
          "hidden": false
        },
        {
          "_id": "67b6dc1ba7567156c6547883",
          "name": "Jiaxi Hu",
          "hidden": false
        },
        {
          "_id": "67b6dc1ba7567156c6547884",
          "name": "Yu Cheng",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-19T12:53:55.000Z",
      "title": "MoM: 混淆のメモリーを用いた線形シーケンスモデリング",
      "summary": "線形シーケンスモデリングメソッド、例えば線形アタション、ステートスペースモデリング、および線形RNN、訓練と推論の複雑性を減少することで、顕著な効率向上を提供します。しかし、これらのメソッドは通常、全体の入力シーケンスを1つの固定サイズのメモリ状態に圧縮し、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干渉を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干済を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干済を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干済を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干済を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干済を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干済を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干済を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干済を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干済を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干済を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干済を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干済を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干済を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干済を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干済を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干済を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干済を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干済を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干済を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干済を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干済を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干済を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干済を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干済を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干済を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干済を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干済を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干済を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干済を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干済を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干済を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干済を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干済を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干済を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干済を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干済を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干済を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干済を軽減するために脳の長期記憶を維持する能力を学び、これにより、記憶干",
      "upvotes": 16,
      "discussionId": "67b6dc1ca7567156c65478b8"
    },
    "publishedAt": "2025-02-20T02:40:09.567Z",
    "title": "MoM: Linear Sequence Modeling with Mixture-of-Memories",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13685.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6246bb33da617c00b48e4d92",
      "avatarUrl": "/avatars/0304a9f6eb7f5dee4d933d03222f94e9.svg",
      "fullname": "Weigao Sun",
      "name": "weigao266",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.13347",
      "authors": [
        {
          "_id": "67b6a7e83ef3656c48f149b9",
          "user": {
            "_id": "6135eeeb5bc6ecdf86b60f0d",
            "avatarUrl": "/avatars/43cedcf20ab6b0801a662787400e1384.svg",
            "isPro": false,
            "fullname": "Shi Yu",
            "user": "yushi",
            "type": "user"
          },
          "name": "Shi Yu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-20T09:35:47.487Z",
          "hidden": false
        },
        {
          "_id": "67b6a7e83ef3656c48f149ba",
          "name": "Zhiyuan Liu",
          "hidden": false
        },
        {
          "_id": "67b6a7e83ef3656c48f149bb",
          "name": "Chenyan Xiong",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-19T00:31:43.000Z",
      "title": "Craw4LLM: LLM予習の効率的なWebクローリング",
      "summary": "Web crawlは、大規模な言語モデル（LLMs）の事前訓練データの主な資源ですが、事前訓練において低いデータ質の多くのクロールされたウェブページは捨てられています。本論文では、LLMの事前訓練の好みに基づいてウェブグラフを検索する効率的なウェブクローリング方法、Crawl4LLMを紹介します。特に、LLMの事前訓練でのウェブページの影響をクローリングスケジューラーの優先順位とし、標準的なグラフの接続性に基づく優先順位を置き換えています。商業的なサーチエンジンのインデックスから9億ページのウェブグラフに対しての実験では、Crawl4LLMが高品質の事前訓練データを得る効率性を示しました。21%のURLをクロールするだけで、Crawl4LLMデータによる事前訓練されたLLMは前回のクローリングと同じ下流性能を達成し、クローリングのエネルギー消費を大幅に減少し、ウェブサイトの負担を緩和しました。コードは、https://github.com/cxcscmu/Crawl4LLMで公開しています。",
      "upvotes": 16,
      "discussionId": "67b6a7e93ef3656c48f149f1"
    },
    "publishedAt": "2025-02-19T22:57:23.298Z",
    "title": "Craw4LLM: Efficient Web Crawling for LLM Pretraining",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13347.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6135eeeb5bc6ecdf86b60f0d",
      "avatarUrl": "/avatars/43cedcf20ab6b0801a662787400e1384.svg",
      "fullname": "Shi Yu",
      "name": "yushi",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 7
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.13922",
      "authors": [
        {
          "_id": "67b6948dbef24bad725b5d4b",
          "name": "Guanzheng Chen",
          "hidden": false
        },
        {
          "_id": "67b6948dbef24bad725b5d4c",
          "name": "Xin Li",
          "hidden": false
        },
        {
          "_id": "67b6948dbef24bad725b5d4d",
          "name": "Michael Qizhe Shieh",
          "hidden": false
        },
        {
          "_id": "67b6948dbef24bad725b5d4e",
          "name": "Lidong Bing",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-19T17:59:03.000Z",
      "title": "LongPO: 大語言モデルの長文脈自動進化を通じて\n短文から長文への好み最適化",
      "summary": "大型言語モデル（LLMs）は予習とアラインメントにより驚異的な能力を示しています。しかし、長文脈の場合には、長文脈のアラインメントが十分でないため、上位の短文脈LLMsは性能が低下しそうです。長文脈のアラインメントは、長文脈の人間のアノテーションの不実用性と短文脈と長文脈の性能のバランスの難しさにより、課題が残っています。これらの課題を解決するために、LongPOを紹介します。LongPOは、短文脈LLMsが内部的に短文脈の能力を転移させて、長文脈タスクで優れていくことを可能にします。LongPOは、LLMsから自己生成された短文脈から長文脈への偏好データを学習することで、同じ指示で生成された長文脈入力とその圧縮された短文脈のペアのレスポンスを含みます。この偏好は、短文脈アラインメント期間に養ったLLMsの能力と可能性を示し、長文脈のアラインメントで低下することがあることを示します。また、LongPOは、長文脈アラインメント期間に短文脈の性能の低下を軽減するために短文脈から長文脈へのKL制約を採用しています。Mistral-7B-Instruct-v0.2を128Kから512Kの文脈長に適用した場合、LongPOは短文脈の性能を完全に保持し、長文脈および短文脈のタスクでナイフなSFTとDPOを大幅に超えます。特に、LongPOによって訓練されたモデルは、長文脈ベンチマーク上での結果を、長文脈の広範囲のアノテーションと大きなパラメータスケールを持つ上位のLLMs（例：GPT-4-128K）と比較的または超えることができます。",
      "upvotes": 16,
      "discussionId": "67b6948ebef24bad725b5d84"
    },
    "publishedAt": "2025-02-19T21:35:20.931Z",
    "title": "LongPO: Long Context Self-Evolution of Large Language Models through Short-to-Long Preference Optimization",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13922.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "645475e2548f22be59847604",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/645475e2548f22be59847604/EhSurrZ25u31qQ2TVXQXt.jpeg",
      "fullname": "Chen",
      "name": "Guanzheng",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.12143",
      "authors": [
        {
          "_id": "67b4d05a9f8a8ab661450397",
          "name": "Yuetai Li",
          "hidden": false
        },
        {
          "_id": "67b4d05a9f8a8ab661450398",
          "name": "Xiang Yue",
          "hidden": false
        },
        {
          "_id": "67b4d05a9f8a8ab661450399",
          "user": {
            "_id": "653df1323479e9ebbe3eb6cc",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/653df1323479e9ebbe3eb6cc/K_g-r1iMRNKj99LXPuYF3.jpeg",
            "isPro": true,
            "fullname": "Zhangchen Xu",
            "user": "flydust",
            "type": "user"
          },
          "name": "Zhangchen Xu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-20T09:37:32.715Z",
          "hidden": false
        },
        {
          "_id": "67b4d05a9f8a8ab66145039a",
          "name": "Fengqing Jiang",
          "hidden": false
        },
        {
          "_id": "67b4d05a9f8a8ab66145039b",
          "name": "Luyao Niu",
          "hidden": false
        },
        {
          "_id": "67b4d05a9f8a8ab66145039c",
          "name": "Bill Yuchen Lin",
          "hidden": false
        },
        {
          "_id": "67b4d05a9f8a8ab66145039d",
          "name": "Bhaskar Ramasubramanian",
          "hidden": false
        },
        {
          "_id": "67b4d05a9f8a8ab66145039e",
          "name": "Radha Poovendran",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-17T18:56:15.000Z",
      "title": "小さなモデルは強い理由者から学習することが難しい",
      "summary": "大語言モデル（LLMs）は複雑な理由論タスクで優れています。その理由論能力を小さなモデルに収納することが実験的に成功しています。しかし、私たちは有趣な現象を発見しました。これを「小さなモデルの学習性の間違い」と呼びます。小さなモデル（3Bパラメータ以下）は長いChain-of-Thought（CoT）理由論や大きなモデルからのディスティルさよりも、短い、簡単な理由論チェーンでより良い性能を示すことが見られます。代わりに、それらは短い、簡単な理由論チェーンでより良い性能を示すことが見られます。これに対処するために、私たちは「Mix Distillation」という簡単で効果的な戦略を提案します。これは長いおよび短いCoT例または大きなおよび小さなモデルからの理由論を組み合わせて理由論の複雑さをバランスします。私たちの実験は、Mix Distillationは小さなモデルの理由論性能をそれぞれのデータだけで学習した場合に比べて大幅に向上させることを示します。これらの発見は直接強力なモデルディスティルの限界を明らかにし、理由論の複雑さの適切な調整が有効な理由論能力の移行に重要であることを強調します。",
      "upvotes": 12,
      "discussionId": "67b4d05b9f8a8ab6614503cb"
    },
    "publishedAt": "2025-02-19T21:38:13.468Z",
    "title": "Small Models Struggle to Learn from Strong Reasoners",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.12143.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "653df1323479e9ebbe3eb6cc",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/653df1323479e9ebbe3eb6cc/K_g-r1iMRNKj99LXPuYF3.jpeg",
      "fullname": "Zhangchen Xu",
      "name": "flydust",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isMod": false,
      "followerCount": 8
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.13965",
      "authors": [
        {
          "_id": "67b6a3fa09841367596a1db5",
          "name": "Michael Luo",
          "hidden": false
        },
        {
          "_id": "67b6a3fa09841367596a1db6",
          "name": "Xiaoxiang Shi",
          "hidden": false
        },
        {
          "_id": "67b6a3fa09841367596a1db7",
          "name": "Colin Cai",
          "hidden": false
        },
        {
          "_id": "67b6a3fa09841367596a1db8",
          "name": "Tianjun Zhang",
          "hidden": false
        },
        {
          "_id": "67b6a3fa09841367596a1db9",
          "name": "Justin Wong",
          "hidden": false
        },
        {
          "_id": "67b6a3fa09841367596a1dba",
          "user": {
            "_id": "626e3449e7914f0d5ea78ad1",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/626e3449e7914f0d5ea78ad1/pVzdmdPMpNcxuj94qiIvB.jpeg",
            "isPro": false,
            "fullname": "Yichuan",
            "user": "Chrisyichuan",
            "type": "user"
          },
          "name": "Yichuan Wang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-20T09:35:50.487Z",
          "hidden": false
        },
        {
          "_id": "67b6a3fa09841367596a1dbb",
          "name": "Chi Wang",
          "hidden": false
        },
        {
          "_id": "67b6a3fa09841367596a1dbc",
          "name": "Yanping Huang",
          "hidden": false
        },
        {
          "_id": "67b6a3fa09841367596a1dbd",
          "name": "Zhifeng Chen",
          "hidden": false
        },
        {
          "_id": "67b6a3fa09841367596a1dbe",
          "name": "Joseph E. Gonzalez",
          "hidden": false
        },
        {
          "_id": "67b6a3fa09841367596a1dbf",
          "name": "Ion Stoica",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-19T18:59:30.000Z",
      "title": "オーテリックス：LLM アガントの効率的なサービングエンジン（一般的なプログラム）",
      "summary": "大語言モデル（LLM）アプリケーションは、簡単なチャットボットを超えて、動的な一般的な用途のエージェントプログラムに進化しています。これらのプログラムは、LLMの呼び出しと出力トークンをスケーリングし、AIエージェントが複雑なタスクを理由的に、探索し、解決するように役立つ。しかし、現在のLLMサービングシステムは、プログラムと呼び出しの間の依存関係を無視し、重要な最適化の機会を失います。我々の分析によると、LLMサービングエンジンに提出されるプログラムは、主に、個々のLLMのリクエストとプログラムのヘッドオブラインブロッキングにより、長い積算待機時間を課しています。これに対して、我々は、プログラムを一等公民として扱うLLMサービングシステム「Autellix」を紹介します。Autellixは、プログラムからのLLMの呼び出しを挿入し、スケジューラーにプログラムレベルのコンテキストを付与します。我々は、単スレッドおよび分散プログラムに対して、プログラムの前回の完了した呼び出しに基づいてLLMの呼び出しを優先順位付けと予備的な処理する2つのスケジューリングアルゴリズムを提案します。我々の評価によると、多様なLLMとエージェントワークロードにおいて、Autellixは、同じ経過時間で、最先端のシステム（例えばvLLM）と比較して、プログラムのトランシットを4～15倍に改善します。",
      "upvotes": 11,
      "discussionId": "67b6a3fb09841367596a1e06"
    },
    "publishedAt": "2025-02-19T22:42:06.502Z",
    "title": "Autellix: An Efficient Serving Engine for LLM Agents as General Programs",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13965.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "654037be97949fd2304aab7f",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/654037be97949fd2304aab7f/2cSME81gcwYa2OTeVlq5Q.jpeg",
      "fullname": "Michael Luo",
      "name": "michaelzhiluo",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.13946",
      "authors": [
        {
          "_id": "67b6b416b4ad845374143c31",
          "name": "Chak Tou Leong",
          "hidden": false
        },
        {
          "_id": "67b6b416b4ad845374143c32",
          "name": "Qingyu Yin",
          "hidden": false
        },
        {
          "_id": "67b6b416b4ad845374143c33",
          "name": "Jian Wang",
          "hidden": false
        },
        {
          "_id": "67b6b416b4ad845374143c34",
          "name": "Wenjie Li",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-19T18:42:45.000Z",
      "title": "安全保護された船が沈まないのはなぜか？アラインされた大規模言語モデルの安全機構はテンプレート領域にほぼ固定されている",
      "summary": "大語言モデル（LLMs）の安全性アライメントは脆弱であり、その初期の行動は、それほど複雑な攻撃でも簡単にジャイルブレイクされることがある。既存のLLMsでは、入力指示と最初のモデル出力の間に固定テンプレートを埋め込むことが通常の実践であるため、このテンプレートが脆弱性の鍵となることを仮定しています：LLMsの安全性関連デザインは、テンプレート領域からの統合情報に過度に依存し、これがこれらのモデルの安全行動に大きな影響を及ぼしています。この問題にはテンプレートアノーテーションサファイティーアライメントと呼ばれています。この論文では、拡張された実験を行い、テンプレートアノーテーションサファイティーアライメントが多くのアライメントされたLLMsで広く存在することを証明しています。機構的な分析により、これが推論時ジャイルブレイク攻撃に遭遇する際のモデルの脆弱性を招くようにどのように影響を及ぼしているかを示しています。また、安全機能からテンプレート領域を離させることがジャイルブレイク攻撃の脆弱性を抑制することが望ましいことを示しています。将来の研究において、テンプレート領域に依存したことを減らすことでより強固な安全性アライメントテクニックの開発を促しています。",
      "upvotes": 7,
      "discussionId": "67b6b416b4ad845374143c5b"
    },
    "publishedAt": "2025-02-19T23:54:57.669Z",
    "title": "Why Safeguarded Ships Run Aground? Aligned Large Language Models' Safety Mechanisms Tend to Be Anchored in The Template Region",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13946.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "631326d6289cf15634c52369",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/631326d6289cf15634c52369/lmPWGHLsQ36H556cqcXjT.jpeg",
      "fullname": "Cooper Leong",
      "name": "cooperleong00",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 5
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.13173",
      "authors": [
        {
          "_id": "67b6b014f7e569081326494f",
          "name": "Wang Yang",
          "hidden": false
        },
        {
          "_id": "67b6b014f7e5690813264950",
          "name": "Hongye Jin",
          "hidden": false
        },
        {
          "_id": "67b6b014f7e5690813264951",
          "name": "Jingfeng Yang",
          "hidden": false
        },
        {
          "_id": "67b6b014f7e5690813264952",
          "name": "Vipin Chaudhary",
          "hidden": false
        },
        {
          "_id": "67b6b014f7e5690813264953",
          "name": "Xiaotian Han",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-17T19:56:21.000Z",
      "title": "Thinking Preference Optimization",
      "summary": "Supervised Fine-Tuning (SFT)は、大きなLLMから得られる長いChain-of-Thought (CoT) レスポンスを用いて、相対的に小さなLLMの長いCoT論理能力を向上させるための有効な方法であり、これはSFTによる補習として利用されています。長いCoT論理能力を継続的に向上させるためには、新しい高品質の長いCoT論理のSFTデータを収集するか、現存するSFTデータセットを再訓練することが考えられます。しかし、新しい長いCoTのSFTデータを取得するのは高額で限界であり、繰り返し訓練は性能のプラターンまたは低下を招きます。SFTデータをさらに性能向上させるために、Thinking Preference Optimization (ThinkPO)という簡単で効果的なSFT後の方法を提案します。ThinkPOは、新しい長いCoTレスポンスが不要であり、短いCoT論理レスポンスを捨てられた回答として、同じ質問の長いCoTレスポンスを選択した回答として利用します。そして、直接的な好み最適化を適用して、モデルが長い論理出力を好ませるように励まします。実験は、ThinkPOはSFTされたモデルの論理性能をさらに向上させ、例えば数学論理の正答率を8.6%へと上げ、出力長さを25.9%へと増加させることを示しています。特に、ThinkPOは公開されたSFTモデルの性能を継続的に向上させることができ、例えばDeepSeek-R1-Distill-Qwen-7BのMATH500の性能を87.4%から91.2%へと上げることができます。",
      "upvotes": 7,
      "discussionId": "67b6b015f7e56908132649a0"
    },
    "publishedAt": "2025-02-19T23:31:36.410Z",
    "title": "Thinking Preference Optimization",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13173.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 6149
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.13962",
      "authors": [
        {
          "_id": "67b691751f861500916ecd5d",
          "user": {
            "_id": "6372bc95c4267fd7cd77f4d0",
            "avatarUrl": "/avatars/17a24af68f45487e601687d777b352b6.svg",
            "isPro": false,
            "fullname": "William Jurayj",
            "user": "wjurayj",
            "type": "user"
          },
          "name": "William Jurayj",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-20T09:36:09.674Z",
          "hidden": false
        },
        {
          "_id": "67b691751f861500916ecd5e",
          "name": "Jeffrey Cheng",
          "hidden": false
        },
        {
          "_id": "67b691751f861500916ecd5f",
          "name": "Benjamin Van Durme",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-19T18:58:31.000Z",
      "title": "それがあなたの最終的な答えですか？テストタイムスケーリングは選択問題の回答を改善する",
      "summary": "スカライングされたテスト時の計算量を増やした大規模な言語モデルは、理由論ベンチマークで驚異的な性能を示しました。しかし、現在のテスト時スカライングの評価は、理由論システムが与えられた質問に答える必要があると強制的な仮定を立っています。これは、モデルが答えに自信があるかどうか、そして常に回答を提供することが適切かどうかに関する懸念を飛ばしています。これらの懸念に対処するために、理由論の際にコンフィデンススコアを抽出してモデルの回答をシーティングします。これにより、推論時の計算バッジを増やすことは、モデルが正しく答えることを増やし、正しい回答に対してのコンフィデンスを高めることもできます。そして、現在の評価時の無リスク回答のパラダイムを拡張し、回答リスクが非ゼロの設定を考慮して評価を報告する方法を提案します。",
      "upvotes": 6,
      "discussionId": "67b691761f861500916ecd8e"
    },
    "publishedAt": "2025-02-19T23:34:43.424Z",
    "title": "Is That Your Final Answer? Test-Time Scaling Improves Selective Question Answering",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13962.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 6149
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.13233",
      "authors": [
        {
          "_id": "67b689aeba514d2c2c969289",
          "user": {
            "_id": "64beb6b6140491ca9f803ebf",
            "avatarUrl": "/avatars/0daa2e813a13668b8b708cd8c12763d9.svg",
            "isPro": false,
            "fullname": "Yucheng SHi",
            "user": "YuchengShi",
            "type": "user"
          },
          "name": "Yucheng Shi",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-20T09:36:18.925Z",
          "hidden": false
        },
        {
          "_id": "67b689aeba514d2c2c96928a",
          "name": "Tianze Yang",
          "hidden": false
        },
        {
          "_id": "67b689aeba514d2c2c96928b",
          "name": "Canyu Chen",
          "hidden": false
        },
        {
          "_id": "67b689aeba514d2c2c96928c",
          "name": "Quanzheng Li",
          "hidden": false
        },
        {
          "_id": "67b689aeba514d2c2c96928d",
          "name": "Tianming Liu",
          "hidden": false
        },
        {
          "_id": "67b689aeba514d2c2c96928e",
          "name": "Xiang Li",
          "hidden": false
        },
        {
          "_id": "67b689aeba514d2c2c96928f",
          "name": "Ninghao Liu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-18T19:12:15.000Z",
      "title": "SearchRAG: サーチエンジンは、LLMベースの医療問い合わせの回答に役立つでしょうか？",
      "summary": "大語言モデル（LLMs）は、一般的な領域では卓越した能力を示していますが、専門的な知識が必要なタスクでは時に難しいことがあります。通常のリテラシーバージュジェネレーション（RAG）手法は、静的な知識ベースから外部情報を取得しますが、これらは過期せずに不完全で、正確な医療問い合わせのための細かな臨床詳細を欠くこともあります。本論文では、リテラシーバージュジェネレーションの限界を克服するために、実時間サーチエンジンを活用した新しいフレームワーク「SearchRAG」を提案します。我々の方法は、合成キャッシュ生成を用いて複雑な医療問い合わせをサーチエンジンによって扱えるクエリに変換し、確率ベースの知識選択を用いて最も関連性の高い情報をフィルタリングしてLLMの入力に含めます。実験結果は、我々の方法が医療問い合わせの回答の正確性を大幅に向上させ、特に詳細な最新情報が必要な複雑な問題に対しては特に効果的であることを示しています。",
      "upvotes": 6,
      "discussionId": "67b689aeba514d2c2c9692b9"
    },
    "publishedAt": "2025-02-19T22:27:22.403Z",
    "title": "SearchRAG: Can Search Engines Be Helpful for LLM-based Medical Question Answering?",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13233.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64beb6b6140491ca9f803ebf",
      "avatarUrl": "/avatars/0daa2e813a13668b8b708cd8c12763d9.svg",
      "fullname": "Yucheng SHi",
      "name": "YuchengShi",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.13943",
      "authors": [
        {
          "_id": "67b6a9a7c721bee91cac2888",
          "name": "Yuliang Liu",
          "hidden": false
        },
        {
          "_id": "67b6a9a7c721bee91cac2889",
          "name": "Junjie Lu",
          "hidden": false
        },
        {
          "_id": "67b6a9a7c721bee91cac288a",
          "name": "Zhaoling Chen",
          "hidden": false
        },
        {
          "_id": "67b6a9a7c721bee91cac288b",
          "name": "Chaofeng Qu",
          "hidden": false
        },
        {
          "_id": "67b6a9a7c721bee91cac288c",
          "name": "Jason Klein Liu",
          "hidden": false
        },
        {
          "_id": "67b6a9a7c721bee91cac288d",
          "name": "Chonghan Liu",
          "hidden": false
        },
        {
          "_id": "67b6a9a7c721bee91cac288e",
          "name": "Zefan Cai",
          "hidden": false
        },
        {
          "_id": "67b6a9a7c721bee91cac288f",
          "name": "Yunhui Xia",
          "hidden": false
        },
        {
          "_id": "67b6a9a7c721bee91cac2890",
          "name": "Li Zhao",
          "hidden": false
        },
        {
          "_id": "67b6a9a7c721bee91cac2891",
          "name": "Jiang Bian",
          "hidden": false
        },
        {
          "_id": "67b6a9a7c721bee91cac2892",
          "name": "Chuheng Zhang",
          "hidden": false
        },
        {
          "_id": "67b6a9a7c721bee91cac2893",
          "name": "Wei Shen",
          "hidden": false
        },
        {
          "_id": "67b6a9a7c721bee91cac2894",
          "name": "Zhouhan Lin",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-19T18:35:55.000Z",
      "title": "AdaptiveStep: モデルの信頼度を通じて理由論のステップを自動的に分割する",
      "summary": "現在のProcess Reward Models (PRMs) の訓練アプローチは、ルールベースの手法を使用して、回答を複数の理由論のステップに分解しています。例えば、予約された占い符タグを使用し、理由論のステップの長さを固定サイズに設定することがあります。これらのアプローチは、特定の言葉が文の実際の決定点をマークすることを間違えていることを見落としています。これに対して、私たちはAdaptiveStepを提案します。AdaptiveStepは、モデルが次の言葉を予測する自信に基づいて理由論のステップを分割します。この分割方法は、各ステップで決策情報をより多く提供し、下流タスクの効果を向上させます。また、私たちの方法は手動注釈が必要ではありません。数学的理由論とコード生成のタスクでAdaptiveStepを用いたPRMsの訓練を通じて、その効果を実験で示します。実験結果は、PRMが最先端のBest-of-N性能を達成し、トークンレベルの値ガイドデコーディングを用いたgreedy search戦略を超え、既存の開放ソースPRMsと比較して30%以上の構築コストを削減できることを示しています。また、PRMの性能、トランジティビティ、一般化能力について詳細な分析とケーススタディを提供します。",
      "upvotes": 5,
      "discussionId": "67b6a9a8c721bee91cac28e7"
    },
    "publishedAt": "2025-02-19T23:07:01.367Z",
    "title": "AdaptiveStep: Automatically Dividing Reasoning Step through Model Confidence",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13943.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6529f79e802e3d1a4f8ec662",
      "avatarUrl": "/avatars/d05320c370a6497d8792ef5acb563dd5.svg",
      "fullname": "Yuliang Liu",
      "name": "yuliang03181",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.12638",
      "authors": [
        {
          "_id": "67b6acdb3a3df2f965e7af0b",
          "name": "Zhiyuan Liu",
          "hidden": false
        },
        {
          "_id": "67b6acdb3a3df2f965e7af0c",
          "name": "Yanchen Luo",
          "hidden": false
        },
        {
          "_id": "67b6acdb3a3df2f965e7af0d",
          "name": "Han Huang",
          "hidden": false
        },
        {
          "_id": "67b6acdb3a3df2f965e7af0e",
          "name": "Enzhi Zhang",
          "hidden": false
        },
        {
          "_id": "67b6acdb3a3df2f965e7af0f",
          "name": "Sihang Li",
          "hidden": false
        },
        {
          "_id": "67b6acdb3a3df2f965e7af10",
          "name": "Junfeng Fang",
          "hidden": false
        },
        {
          "_id": "67b6acdb3a3df2f965e7af11",
          "name": "Yaorui Shi",
          "hidden": false
        },
        {
          "_id": "67b6acdb3a3df2f965e7af12",
          "user": {
            "_id": "65fca775fa59bdf4737b1a84",
            "avatarUrl": "/avatars/a161b510bde8f57e7686cbb0b4aa6a52.svg",
            "isPro": false,
            "fullname": "Xiang Wang",
            "user": "xiangwang1223",
            "type": "user"
          },
          "name": "Xiang Wang",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-02-20T04:17:33.860Z",
          "hidden": false
        },
        {
          "_id": "67b6acdb3a3df2f965e7af13",
          "name": "Kenji Kawaguchi",
          "hidden": false
        },
        {
          "_id": "67b6acdb3a3df2f965e7af14",
          "name": "Tat-Seng Chua",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-18T08:40:13.000Z",
      "title": "NExT-Mol: 3Dディフュージョンと1D言語モデリングによる3D分子生成",
      "summary": "3D 分子生成は薬物発見と材料設計に重要です。先行の試みは、3D ディフュージョンモデルの利点を焦点にしていますが、1D SELFIES ベースの言語モデル（LM）の優めた点を見過ごしています。LM は 100% 有効な分子を生成でき、10 億スケールの 1D 分子データセットを活用できます。これらの利点を統合して 3D 分子生成に向けて、NExT-Mol: 3D ディフュージョンと 1D 言語モデリングの結合を提案します。NExT-Mol は広範囲的に予えられた分子 LM を使用して 1D 分子生成を行い、生成された分子の 3D 構造を予測します。LM のモデルサイズを拡大、ディフュージョンニューラルアーキテクチャを精進、1D から 3D のトランスフェームラーニングを適用して NExT-Mol の性能を向上させます。特に、1D 分子 LM は有効性を確保しながら分布的な類似性において基準に優れています。また、3D ディフュージョンモデルは構造予測で先駆的な性能を達成しています。1D および 3D モデリングの向上により、NExT-Mol は GEOM-DRUGS 上での新規 3D 生成において 3D FCD で 26% の相対的な向上を達成し、QM9-2014 上での条件付き 3D 生成において 13% の平均相対的な効果を達成します。我々のコードと予えられたチェックポイントは https://github.com/acharkq/NExT-Mol に公開されています。",
      "upvotes": 3,
      "discussionId": "67b6acdd3a3df2f965e7af85"
    },
    "publishedAt": "2025-02-19T23:18:32.647Z",
    "title": "NExT-Mol: 3D Diffusion Meets 1D Language Modeling for 3D Molecule Generation",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.12638.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6310a3cd531cc21f9e06de6a",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6310a3cd531cc21f9e06de6a/aTGMx3O41lUARK9s3dAik.jpeg",
      "fullname": "Zhiyuan Liu",
      "name": "acharkq",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.13581",
      "authors": [
        {
          "_id": "67b6ee04412c9eccae5151f5",
          "user": {
            "_id": "64a62c2f500beb50968e5c9c",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/wfL3ojJmXqyzGUmCblPf4.jpeg",
            "isPro": false,
            "fullname": "Yupeng Hou",
            "user": "hyp1231",
            "type": "user"
          },
          "name": "Yupeng Hou",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-20T09:35:14.498Z",
          "hidden": false
        },
        {
          "_id": "67b6ee04412c9eccae5151f6",
          "name": "Jianmo Ni",
          "hidden": false
        },
        {
          "_id": "67b6ee04412c9eccae5151f7",
          "name": "Zhankui He",
          "hidden": false
        },
        {
          "_id": "67b6ee04412c9eccae5151f8",
          "name": "Noveen Sachdeva",
          "hidden": false
        },
        {
          "_id": "67b6ee04412c9eccae5151f9",
          "name": "Wang-Cheng Kang",
          "hidden": false
        },
        {
          "_id": "67b6ee04412c9eccae5151fa",
          "name": "Ed H. Chi",
          "hidden": false
        },
        {
          "_id": "67b6ee04412c9eccae5151fb",
          "name": "Julian McAuley",
          "hidden": false
        },
        {
          "_id": "67b6ee04412c9eccae5151fc",
          "name": "Derek Zhiyuan Cheng",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-19T09:45:29.000Z",
      "title": "ActionPiece: コンテキストに基づくアクションシーケンスのトークニゼーションを用いた生成的リコメンド",
      "summary": "生成推薦（GR）は、ユーザーの行動を離散トークンパターンに変換し、自動帰戻し的に予測されるようになった新しいパラダイムです。しかし、現在のGRモデルは、各行動を独立にトークン化し、全シーケンスで同じ行動に同じ固定トークンを割り当て、その際に文脈関係を考慮していません。この文脈知識の欠如は、同じ行動が周囲の文脈によって異なる意味を持つことを考慮しないため、最適な性能を獲得できないことにより、モデルの性能が低下する可能性があります。この問題に対処するために、我々はActionPieceを提案します。ActionPieceでは、行動シーケンスをトークン化する際に明示的に文脈を考慮します。ActionPieceでは、各行動はアイテムの特徴ベクトルの集合で表現され、これらの特徴ベクトルは初期トークンとして使用されます。行動シーケンスコRPデータを元に、特徴ベクトルのパターンを新しいトークンとして結合し、その共起頻度を考慮してボキャブラリーを構築します。特徴ベクトルの集合の無順序性を考慮し、さらに集合の置換正規化を導入し、同じ意味を持つ行動シーケンスの複数の分割を生成します。公開データセット上での実験結果は、ActionPieceは既存の行動トークン化手法を一致的に上回り、NDCG@10の値を6.00%〜12.82%程度上げました。",
      "upvotes": 2,
      "discussionId": "67b6ee04412c9eccae515223"
    },
    "publishedAt": "2025-02-20T03:56:54.121Z",
    "title": "ActionPiece: Contextually Tokenizing Action Sequences for Generative Recommendation",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13581.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64a62c2f500beb50968e5c9c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/wfL3ojJmXqyzGUmCblPf4.jpeg",
      "fullname": "Yupeng Hou",
      "name": "hyp1231",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 5
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.11995",
      "authors": [
        {
          "_id": "67b65bbe0d878eff1a6b111d",
          "name": "Siddhesh Pawar",
          "hidden": false
        },
        {
          "_id": "67b65bbe0d878eff1a6b111e",
          "name": "Arnav Arora",
          "hidden": false
        },
        {
          "_id": "67b65bbe0d878eff1a6b111f",
          "name": "Lucie-Aimée Kaffee",
          "hidden": false
        },
        {
          "_id": "67b65bbe0d878eff1a6b1120",
          "user": {
            "_id": "608918b7df398c3b285ce960",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1621507769190-608918b7df398c3b285ce960.jpeg",
            "isPro": false,
            "fullname": "Isabelle Augenstein",
            "user": "IAugenstein",
            "type": "user"
          },
          "name": "Isabelle Augenstein",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-20T09:36:32.278Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-17T16:35:15.000Z",
      "title": "推定の文化識別：名前がLLMの回答をどのように影響しているか",
      "summary": "名前は深く人間の識別に結びついています。それらは個人性、文化財、個人歴史のマーカーとして役立ちます。しかし、名前を識別の中心的な指標として使用することは、複雑な識別を簡単化することにつながります。LLMとのインタラクションでは、ユーザーの名前は個性化の重要な情報源として重要です。名前は直接のユーザーの入力（チャットボットが要求したもの）によってチャットボット対話に入り、タスクコンテキストの一部として（CVのレビューなど）または、ユーザー情報を個性化のために格納するビルトインメモリ機能として名前が入ります。私たちは、名前に関連するバイアスを調査し、LLMが普通の建議を探しているクエリに対して生成される回答での文化の予想を測定しています。これらの分析は、複数の文化におけるLLM生成で名前に関連する文化識別の強い予想を示しています。我々の研究は、バイアスを避けながら意味のあるカスタマイズを維持するためのより複雑なプロセスシステムの設計に影響を及ぼしています。",
      "upvotes": 1,
      "discussionId": "67b65bbf0d878eff1a6b1174"
    },
    "publishedAt": "2025-02-20T01:20:46.431Z",
    "title": "Presumed Cultural Identity: How Names Shape LLM Responses",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.11995.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60c50f18754747f54fa37114",
      "avatarUrl": "/avatars/648ae58b81806dbd93a68546666047e3.svg",
      "fullname": "Siddhesh",
      "name": "sidicity",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.11573",
      "authors": [
        {
          "_id": "67b6f629d9da6999328e38f5",
          "name": "Congkai Xie",
          "hidden": false
        },
        {
          "_id": "67b6f629d9da6999328e38f6",
          "name": "Shuo Cai",
          "hidden": false
        },
        {
          "_id": "67b6f629d9da6999328e38f7",
          "name": "Wenjun Wang",
          "hidden": false
        },
        {
          "_id": "67b6f629d9da6999328e38f8",
          "name": "Pengxiang Li",
          "hidden": false
        },
        {
          "_id": "67b6f629d9da6999328e38f9",
          "name": "Zhijie Sang",
          "hidden": false
        },
        {
          "_id": "67b6f629d9da6999328e38fa",
          "name": "Kejing Yang",
          "hidden": false
        },
        {
          "_id": "67b6f629d9da6999328e38fb",
          "name": "Yiming Zhang",
          "hidden": false
        },
        {
          "_id": "67b6f629d9da6999328e38fc",
          "name": "Zhen Li",
          "hidden": false
        },
        {
          "_id": "67b6f629d9da6999328e38fd",
          "name": "Guanghao Zhu",
          "hidden": false
        },
        {
          "_id": "67b6f629d9da6999328e38fe",
          "name": "Zeyu Liu",
          "hidden": false
        },
        {
          "_id": "67b6f629d9da6999328e38ff",
          "name": "Yang Yu",
          "hidden": false
        },
        {
          "_id": "67b6f629d9da6999328e3900",
          "name": "Yuhang Liu",
          "hidden": false
        },
        {
          "_id": "67b6f629d9da6999328e3901",
          "name": "Su Lu",
          "hidden": false
        },
        {
          "_id": "67b6f629d9da6999328e3902",
          "name": "Baoyi He",
          "hidden": false
        },
        {
          "_id": "67b6f629d9da6999328e3903",
          "name": "Qi Zhou",
          "hidden": false
        },
        {
          "_id": "67b6f629d9da6999328e3904",
          "name": "Xiaotian Han",
          "hidden": false
        },
        {
          "_id": "67b6f629d9da6999328e3905",
          "name": "Jianbo Yuan",
          "hidden": false
        },
        {
          "_id": "67b6f629d9da6999328e3906",
          "name": "Shengyu Zhang",
          "hidden": false
        },
        {
          "_id": "67b6f629d9da6999328e3907",
          "name": "Fei Wu",
          "hidden": false
        },
        {
          "_id": "67b6f629d9da6999328e3908",
          "name": "Hongxia Yang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-17T09:07:32.000Z",
      "title": "InfiR : 理由での効果的な小語言モデルと多モデル小語言モデルの作り方",
      "summary": "Large Language Models (LLMs) と Multimodal Large Language Models (MLLMs) は、理由能力の進歩に大きな進展を遂げています。しかし、これらは高い計算要求とプライバシーの懸念などの課題を見せています。本論文は、強力な理由能力を維持するために、効率的な Small Language Models (SLMs) と Multimodal Small Language Models (MSLMs) の開発に焦点を当てています。我々は、理由能力を高めることと、エッジデバイス上での実装を促進するための新しいトレーニングパイプラインを紹介し、最先端の性能を達成しながら開発コストを最小限に抑えることを目指しています。\\InfR~は、理由能力の向上、採用障害の削減、プライバシーの懸念を解決するための小さなモデルサイズを通じて、AIシステムの進歩を促進することを目的としています。リソースは、https://github.com/Reallm-Labs/InfiR から利用可能です。",
      "upvotes": 0,
      "discussionId": "67b6f62ad9da6999328e3955"
    },
    "publishedAt": "2025-02-20T04:32:22.011Z",
    "title": "InfiR : Crafting Effective Small Language Models and Multimodal Small Language Models in Reasoning",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.11573.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "618c1ad1c74578e0a4a4d074",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/618c1ad1c74578e0a4a4d074/8u_AkeHt4d6xtQ8hzaffU.jpeg",
      "fullname": "Drishti Sharma",
      "name": "DrishtiSharma",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 60
    },
    "isAuthorParticipating": false
  }
]