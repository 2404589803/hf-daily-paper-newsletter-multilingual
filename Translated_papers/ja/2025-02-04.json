[
  {
    "paper": {
      "id": "2502.01237",
      "authors": [
        {
          "_id": "67a1c1428747511e7b9a1965",
          "user": {
            "_id": "62897fce5d9e25c10e4f319d",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62897fce5d9e25c10e4f319d/bMlfAyzkNNZlkQ5mCW6Vc.jpeg",
            "isPro": false,
            "fullname": "Alexey Gorbatovski",
            "user": "Myashka",
            "type": "user"
          },
          "name": "Alexey Gorbatovski",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-04T09:39:00.767Z",
          "hidden": false
        },
        {
          "_id": "67a1c1428747511e7b9a1966",
          "name": "Boris Shaposhnikov",
          "hidden": false
        },
        {
          "_id": "67a1c1428747511e7b9a1967",
          "user": {
            "_id": "6416272d986557e8cac64ece",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6416272d986557e8cac64ece/s3CLjNN_pGj-vJDcENFD2.jpeg",
            "isPro": false,
            "fullname": "Viacheslav",
            "user": "ummagumm-a",
            "type": "user"
          },
          "name": "Viacheslav Sinii",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-04T09:38:52.039Z",
          "hidden": false
        },
        {
          "_id": "67a1c1428747511e7b9a1968",
          "user": {
            "_id": "636e71b2b0ebc04888157b71",
            "avatarUrl": "/avatars/957ba705d470e3a01792741d7f0ff038.svg",
            "isPro": false,
            "fullname": "Alexey Malakhov",
            "user": "ZeL1k7",
            "type": "user"
          },
          "name": "Alexey Malakhov",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-04T09:38:54.121Z",
          "hidden": false
        },
        {
          "_id": "67a1c1428747511e7b9a1969",
          "user": {
            "_id": "62a9c8edc19f92ae443ab37f",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1669110208492-62a9c8edc19f92ae443ab37f.png",
            "isPro": false,
            "fullname": "Daniil Gavrilov",
            "user": "kefirski",
            "type": "user"
          },
          "name": "Daniil Gavrilov",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-04T09:38:57.087Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-03T10:54:14.000Z",
      "title": "直接アラインメントアルゴリズムの違いはブルーフィードに似ています。",
      "summary": "Direct Alignment Algorithms (DAAs)は、Reinforcement Learning from Human Feedback (RLHF)の強化学習(RL)と報酬モデリング(RM)を直接の政策最適化に置き換えて、言語モデルのアラインメントを簡単にする。DAAsは、ランキング損失（pairwise vs. pointwise）、その損失に使用される報酬（例：政策と参照政策の確率比、または確率比）、またはSupervised Fine-Tuning (SFT)のスフェーズが必要かどうか（two-stage vs. one-stage）によって分類される。まず、one-stageの方法がtwo-stageの方法より劣り込みを示していることを示し、明示的なSFTスフェーズを挟むこととbetaパラメータの導入（政策の好み最適化の強さを制御する）をone-stageのORPOとASFTに採用し、これらの改良はAlpaca Eval 2での性能を+3.46（ORPO）と+8.27（ASFT）の改善により、two-stageの方法とDPOと同じく高い性能を示す。さらにの分析は、pairwiseまたはpointwiseの目標を使用するかどうかが、具体的な隠れた報酬または損失関数によってはないことを示し、これらの結果は、過早な性能向上や全体的なアラインメントアルゴリズムの優れていることを主張することを避けるための詳細な評価の重要性を強調している。",
      "upvotes": 33,
      "discussionId": "67a1c1438747511e7b9a19ae"
    },
    "publishedAt": "2025-02-04T03:10:49.348Z",
    "title": "The Differences Between Direct Alignment Algorithms are a Blur",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/62897fce5d9e25c10e4f319d/ndKErkZSfT5LvqKfIrC7f.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01237.png",
    "numComments": 0,
    "submittedBy": {
      "_id": "62897fce5d9e25c10e4f319d",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62897fce5d9e25c10e4f319d/bMlfAyzkNNZlkQ5mCW6Vc.jpeg",
      "fullname": "Alexey Gorbatovski",
      "name": "Myashka",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 6
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.01456",
      "authors": [
        {
          "_id": "67a19d705efa4fab15497775",
          "user": {
            "_id": "650eba9555dc1e841746f132",
            "avatarUrl": "/avatars/af6f5ee78f161d25ec0afc45d2def8eb.svg",
            "isPro": false,
            "fullname": "Ganqu Cui",
            "user": "ganqu",
            "type": "user"
          },
          "name": "Ganqu Cui",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-04T09:39:23.889Z",
          "hidden": false
        },
        {
          "_id": "67a19d705efa4fab15497776",
          "name": "Lifan Yuan",
          "hidden": false
        },
        {
          "_id": "67a19d705efa4fab15497777",
          "name": "Zefan Wang",
          "hidden": false
        },
        {
          "_id": "67a19d705efa4fab15497778",
          "user": {
            "_id": "6321152b8c0da827c72c7c16",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1678783813705-6321152b8c0da827c72c7c16.jpeg",
            "isPro": false,
            "fullname": "Hanbin Wang",
            "user": "hanbin",
            "type": "user"
          },
          "name": "Hanbin Wang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-04T09:39:25.869Z",
          "hidden": false
        },
        {
          "_id": "67a19d705efa4fab15497779",
          "name": "Wendi Li",
          "hidden": false
        },
        {
          "_id": "67a19d705efa4fab1549777a",
          "name": "Bingxiang He",
          "hidden": false
        },
        {
          "_id": "67a19d705efa4fab1549777b",
          "name": "Yuchen Fan",
          "hidden": false
        },
        {
          "_id": "67a19d705efa4fab1549777c",
          "name": "Tianyu Yu",
          "hidden": false
        },
        {
          "_id": "67a19d705efa4fab1549777d",
          "name": "Qixin Xu",
          "hidden": false
        },
        {
          "_id": "67a19d705efa4fab1549777e",
          "name": "Weize Chen",
          "hidden": false
        },
        {
          "_id": "67a19d705efa4fab1549777f",
          "name": "Jiarui Yuan",
          "hidden": false
        },
        {
          "_id": "67a19d705efa4fab15497780",
          "name": "Huayu Chen",
          "hidden": false
        },
        {
          "_id": "67a19d705efa4fab15497781",
          "name": "Kaiyan Zhang",
          "hidden": false
        },
        {
          "_id": "67a19d705efa4fab15497782",
          "name": "Xingtai Lv",
          "hidden": false
        },
        {
          "_id": "67a19d705efa4fab15497783",
          "name": "Shuo Wang",
          "hidden": false
        },
        {
          "_id": "67a19d705efa4fab15497784",
          "name": "Yuan Yao",
          "hidden": false
        },
        {
          "_id": "67a19d705efa4fab15497785",
          "name": "Xu Han",
          "hidden": false
        },
        {
          "_id": "67a19d705efa4fab15497786",
          "name": "Hao Peng",
          "hidden": false
        },
        {
          "_id": "67a19d705efa4fab15497787",
          "name": "Yu Cheng",
          "hidden": false
        },
        {
          "_id": "67a19d705efa4fab15497788",
          "name": "Zhiyuan Liu",
          "hidden": false
        },
        {
          "_id": "67a19d705efa4fab15497789",
          "name": "Maosong Sun",
          "hidden": false
        },
        {
          "_id": "67a19d705efa4fab1549778a",
          "name": "Bowen Zhou",
          "hidden": false
        },
        {
          "_id": "67a19d705efa4fab1549778b",
          "name": "Ning Ding",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-03T15:43:48.000Z",
      "title": "隠れた報酬による強化処理",
      "summary": "密集報酬は、大規模言語モデル（LLMs）の推論時スケーリングにおいて、結果レベルのスパース報酬に比べて、複雑な多段階論理が必要なタスクでより効果的な代替として証明されています。しかし、LLMsの強化学習（RL）においても、これらの細かい報酬が結果報酬の本質的な問題を解決することができることを見出すように、細かい報酬が吸引力を持っています。しかし、この可能性はまだ大きく実現されていません。これは、現在の手法では、プロセス報酬モデル（PRMs）の線上訓練において、高品質なプロセスラベルの収集が高額であり、報酬ハッキングに脆弱なことによるものです。これらの課題を解決するために、PRIME（IMplicit報酬を通じたプロセス強化学習）を提案します。PRIMEは、政策ロールアウトと結果ラベルをそのみ用いて線上のPRM更新を可能にします。PRIMEは現在の手法によって必要とされる専用報酬モデルの訓練ステップを省略し、デバイスオーバーヘッドを大幅に減少します。PRIMEの効果は、比較的数学とコーディングにおいて示されます。Qwen2.5-Math-7B-Baseから始め、PRIMEはSFTモデルを超えることができます。特に、我々の結果として得られたモデル、Eurus-2-7B-PRIMEは、Qwen2.5-Math-7B-Instructを超えることができ、その訓練データの10%を使用しています。",
      "upvotes": 26,
      "discussionId": "67a19d705efa4fab154977d0"
    },
    "publishedAt": "2025-02-04T00:02:39.922Z",
    "title": "Process Reinforcement through Implicit Rewards",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01456.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6321152b8c0da827c72c7c16",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1678783813705-6321152b8c0da827c72c7c16.jpeg",
      "fullname": "Hanbin Wang",
      "name": "hanbin",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 12
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.01534",
      "authors": [
        {
          "_id": "67a1ad77d797fac51fa80770",
          "name": "Dawei Li",
          "hidden": false
        },
        {
          "_id": "67a1ad77d797fac51fa80771",
          "user": {
            "_id": "653a195b0da86d726c9c580c",
            "avatarUrl": "/avatars/61649e1d600fdc1edc50ead0dfa99fdd.svg",
            "isPro": false,
            "fullname": "Renliang Sun",
            "user": "RLSNLP",
            "type": "user"
          },
          "name": "Renliang Sun",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-04T09:39:11.035Z",
          "hidden": false
        },
        {
          "_id": "67a1ad77d797fac51fa80772",
          "name": "Yue Huang",
          "hidden": false
        },
        {
          "_id": "67a1ad77d797fac51fa80773",
          "name": "Ming Zhong",
          "hidden": false
        },
        {
          "_id": "67a1ad77d797fac51fa80774",
          "name": "Bohan Jiang",
          "hidden": false
        },
        {
          "_id": "67a1ad77d797fac51fa80775",
          "name": "Jiawei Han",
          "hidden": false
        },
        {
          "_id": "67a1ad77d797fac51fa80776",
          "name": "Xiangliang Zhang",
          "hidden": false
        },
        {
          "_id": "67a1ad77d797fac51fa80777",
          "name": "Wei Wang",
          "hidden": false
        },
        {
          "_id": "67a1ad77d797fac51fa80778",
          "name": "Huan Liu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-03T17:13:03.000Z",
      "title": "偏好泄漏：LLM-as-a-judge 中的污染问题",
      "summary": "大語言モデル（LLMs）を判定者としての役割とLLMベースのデータ合成は、モデル開発の2つの基本的なLLM駆動データ注釈方法として登場しました。これらの組み合わせはモデルの訓練と評価の効率向上に大きな貢献を果たしますが、この新しいモデル開発パラダイムによる潜在的な汚染に対しては少しも注目を向けていませんでした。本論文では、LLMを判定者としての偏り漏れ、合成データ生成器とLLMベースの評価者の関連性による汚染問題を明らかにします。この問題を研究するために、まずデータ生成用LLMと判定用LLMの間の3つの共通の関連性を定義します：同じモデルであること、継承関係を持つこと、同じモデル族に属すること。拡張された実験を通じて、記述偏りが好み漏れにより判定者が関連した学生モデルに対しての偏りを認識していることを実験的に確認します。進めた分析は、好み漏れは以前に認識されたLLMを判定者としての場合の偏りと比較して検出に難しい広範囲な問題であることを示します。これらのすべての発見は、好み漏れはLLMを判定者としての領域で広範囲で難解な問題であることを意味します。すべてのコードとデータを以下のURLで公開します：https://github.com/David-Li0406/Preference-Leakage。",
      "upvotes": 11,
      "discussionId": "67a1ad78d797fac51fa807c1"
    },
    "publishedAt": "2025-02-04T01:04:33.630Z",
    "title": "Preference Leakage: A Contamination Problem in LLM-as-a-judge",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01534.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6474e1afb68461d5cf7c41cc",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6474e1afb68461d5cf7c41cc/bcoiD_qPrjHUBlB259djg.png",
      "fullname": "Dawei Li",
      "name": "wjldw",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.01061",
      "authors": [
        {
          "_id": "67a1a7a166a8a88726963ef4",
          "name": "Gaojie Lin",
          "hidden": false
        },
        {
          "_id": "67a1a7a166a8a88726963ef5",
          "name": "Jianwen Jiang",
          "hidden": false
        },
        {
          "_id": "67a1a7a166a8a88726963ef6",
          "name": "Jiaqi Yang",
          "hidden": false
        },
        {
          "_id": "67a1a7a166a8a88726963ef7",
          "name": "Zerong Zheng",
          "hidden": false
        },
        {
          "_id": "67a1a7a166a8a88726963ef8",
          "name": "Chao Liang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-03T05:17:32.000Z",
      "title": "OmniHuman-1: 1ステージ条件付き人間アニメーションモデルのスケーリングアップを再考する",
      "summary": "端到端の人間アニメーション、例えば音頻駆動テーブル人間生成について、最近数年において顕著な進歩が見られています。しかし、現在の方法は、大規模な一般的なビデオ生成モデルとしてスケールアップできないことにより、実世界的なアプリケーションでの可能性を制限しています。本論文では、データのスケールアップを効果的に行うために、動作に関連する条件を学習ステップに混ぜることでスケーラブルなフレームワークを提案します。これにより、動作に関連する条件に対する2つの学習原則を導入し、相応のモデル構造と推論戦略を提案します。これらの設計は、OmniHumanがデータ駆動の動作生成を最大限に活用し、高度に写実な人間ビデオ生成を実現することを可能にします。より重要なのは、OmniHumanは、顔の近接、肖像、半身、全身などの多様な肖像内容をサポートし、話し声と歌唱をサポートし、人間とオブジェクトの相互作用と難しい体姿勢を処理し、異なる画像スタイルを扱うことができます。現在の端到端の音頻駆動方法に比べ、OmniHumanは写実なビデオを生成し、入力の柔軟性が高まります。また、複数の駆動モード（音頻駆動、ビデオ駆動、結合ドライバー信号）をサポートします。ビデオサンプルは、ttfamilyプロジェクトページ（https://omnihuman-lab.github.io）に提供されています。",
      "upvotes": 11,
      "discussionId": "67a1a7a466a8a88726963f90"
    },
    "publishedAt": "2025-02-04T00:37:57.949Z",
    "title": "OmniHuman-1: Rethinking the Scaling-Up of One-Stage Conditioned Human Animation Models",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01061.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5927
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.18636",
      "authors": [
        {
          "_id": "67a1bfc314cba2eba6da4b2b",
          "name": "Xun Liang",
          "hidden": false
        },
        {
          "_id": "67a1bfc314cba2eba6da4b2c",
          "name": "Simin Niu",
          "hidden": false
        },
        {
          "_id": "67a1bfc314cba2eba6da4b2d",
          "name": "Zhiyu Li",
          "hidden": false
        },
        {
          "_id": "67a1bfc314cba2eba6da4b2e",
          "name": "Sensen Zhang",
          "hidden": false
        },
        {
          "_id": "67a1bfc314cba2eba6da4b2f",
          "user": {
            "_id": "669e0b93c7cb0568dac6e92e",
            "avatarUrl": "/avatars/a39ea77d7391f164af8a80f94f85f2ca.svg",
            "isPro": false,
            "fullname": "hanyu Wang",
            "user": "UglyToilet",
            "type": "user"
          },
          "name": "Hanyu Wang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-04T09:39:04.452Z",
          "hidden": false
        },
        {
          "_id": "67a1bfc314cba2eba6da4b30",
          "name": "Feiyu Xiong",
          "hidden": false
        },
        {
          "_id": "67a1bfc314cba2eba6da4b31",
          "name": "Jason Zhaoxin Fan",
          "hidden": false
        },
        {
          "_id": "67a1bfc314cba2eba6da4b32",
          "name": "Bo Tang",
          "hidden": false
        },
        {
          "_id": "67a1bfc314cba2eba6da4b33",
          "name": "Shichao Song",
          "hidden": false
        },
        {
          "_id": "67a1bfc314cba2eba6da4b34",
          "name": "Mengwei Wang",
          "hidden": false
        },
        {
          "_id": "67a1bfc314cba2eba6da4b35",
          "name": "Jiawei Yang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-28T17:01:31.000Z",
      "title": "SafeRAG: レビューアウガーデーションにおけるセキュリティベンチマーク",
      "summary": "レコード検索・生成パラダイムのレコード付き生成（RAG）は、大規模な言語モデル（LLMs）に外部キャンバスを統合して知識密集型タスクを解決するために非常に成功しています。しかし、外部キャンバスと未確認キャンバスの統合によりLLMsの脆弱性が増加し、攻撃者は知識を操作して攻撃タスクを行うことができます。本論文では、RAGセキュリティを評価するためのベンチマーク「SafeRAG」を介して、RAGセキュリティを評価します。まず、攻撃タスクを銀色ノイズ、コンテキスト間の衝突、ソフトアド、ホワイトデニアル・オブ・サービスと分類します。次に、各タスクに対して手動で主にRAGセキュリティ評価データセット（即、SafeRAGデータセット）を構築します。そして、SafeRAGデータセットを用いてRAGが遭遇するさまざまな攻撃シナリオをシミュレートします。14つの代表的なRAGコンポーネントに対して実験を行い、RAGはすべての攻撃タスクに脆弱であり、最も明らかな攻撃タスクは既存のレコード検索モジュール、フィルターまたは進歩的なLLMsを経由して簡単に通過することができ、RAGサービスの品質が低下することを示します。コードは以下のURLから利用可能です：https://github.com/IAAR-Shanghai/SafeRAG。",
      "upvotes": 8,
      "discussionId": "67a1bfc414cba2eba6da4b63"
    },
    "publishedAt": "2025-02-04T03:22:06.520Z",
    "title": "SafeRAG: Benchmarking Security in Retrieval-Augmented Generation of Large Language Model",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.18636.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "62a155e615eeab266b2f2243",
      "avatarUrl": "/avatars/e89ef156e73af028e3ce3664e6cb4e62.svg",
      "fullname": "Zhiyu Li",
      "name": "jimi888",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 4
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.01068",
      "authors": [
        {
          "_id": "67a1a75f6aa8429da4945eeb",
          "user": {
            "_id": "639ffbc6beb95d698de9640d",
            "avatarUrl": "/avatars/7ef1aaadd5b378d00e17dc548e42cb7e.svg",
            "isPro": false,
            "fullname": "Dongwon Jo",
            "user": "dongwonjo",
            "type": "user"
          },
          "name": "Dongwon Jo",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-04T09:39:16.125Z",
          "hidden": false
        },
        {
          "_id": "67a1a75f6aa8429da4945eec",
          "user": {
            "_id": "662672eaebdfec5cfdf1d034",
            "avatarUrl": "/avatars/61bc7add693c555e29ad3c1112215684.svg",
            "isPro": false,
            "fullname": "Jiwon Song",
            "user": "jiwonsong",
            "type": "user"
          },
          "name": "Jiwon Song",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-04T09:39:14.253Z",
          "hidden": false
        },
        {
          "_id": "67a1a75f6aa8429da4945eed",
          "name": "Yulhwa Kim",
          "hidden": false
        },
        {
          "_id": "67a1a75f6aa8429da4945eee",
          "name": "Jae-Joon Kim",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-03T05:25:09.000Z",
      "title": "FastKV: KV Cache Compression for Fast Long-Context Processing with Token-Selective Propagation",
      "summary": "大語言モデル（LLMs）は、長文脈シーケンスの処理に優れていますが、それらは、コンテキスト情報を保存するために、大きなキー値（KV）キャッシュを必要とし、これは計算効率とメモリ使用量に重い負担を加えます。従来のキャッシュ圧縮の試みは、メモリ要求を減らすだけに焦点を当てていたが、遅延の向上には限られていました。この問題を解決するために、FastKVという、長文脈シーケンスの遅延を向上させるためのキャッシュ圧縮方法を紹介します。処理速度を向上させながら精度を維持するために、FastKVは、LLMsの初期層で全てのコンテキスト情報を保持し、より深い層でその一部のみを選択的に伝播する新しいトークン選択的伝播（TSP）アプローチを採用しています。また、FastKVは、グループ化クエリアテンション（GQA）に関連付けられたKVキャッシュ圧縮を採用し、GQAのメモリと計算効率の利点を活用しています。実験結果によると、FastKVは、最先端のKVキャッシュ圧縮方法であるHeadKVと比較して、時間至一モード（TTFT）とトランソープにおいてそれぞれ2.00倍と1.40倍の改善を収めました。また、FastKVは、長文脈ベンチマークで精度を維持し、基準と比較的なレベルでの性能を実現しました。コードは、https://github.com/dongwonjo/FastKV に公開されています。",
      "upvotes": 7,
      "discussionId": "67a1a7616aa8429da4945f95"
    },
    "publishedAt": "2025-02-04T00:45:45.545Z",
    "title": "FastKV: KV Cache Compression for Fast Long-Context Processing with Token-Selective Propagation",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01068.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "639ffbc6beb95d698de9640d",
      "avatarUrl": "/avatars/7ef1aaadd5b378d00e17dc548e42cb7e.svg",
      "fullname": "Dongwon Jo",
      "name": "dongwonjo",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.00094",
      "authors": [
        {
          "_id": "67a185ab908f4534beb94b8c",
          "user": {
            "_id": "656864e12d73834278a8dea7",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/656864e12d73834278a8dea7/sfAWS2eyPtFHb_2GZIypp.jpeg",
            "isPro": true,
            "fullname": "Ahmed Heakl",
            "user": "ahmedheakl",
            "type": "user"
          },
          "name": "Ahmed Heakl",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-04T09:39:32.712Z",
          "hidden": false
        },
        {
          "_id": "67a185ab908f4534beb94b8d",
          "name": "Sara Ghaboura",
          "hidden": false
        },
        {
          "_id": "67a185ab908f4534beb94b8e",
          "name": "Omkar Thawkar",
          "hidden": false
        },
        {
          "_id": "67a185ab908f4534beb94b8f",
          "name": "Fahad Shahbaz Khan",
          "hidden": false
        },
        {
          "_id": "67a185ab908f4534beb94b90",
          "name": "Hisham Cholakkal",
          "hidden": false
        },
        {
          "_id": "67a185ab908f4534beb94b91",
          "name": "Rao Muhammad Anwer",
          "hidden": false
        },
        {
          "_id": "67a185ab908f4534beb94b92",
          "name": "Salman Khan",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-31T18:58:20.000Z",
      "title": "AIN: 阿拉伯インクルーシブ大規模多様化モデル",
      "summary": "ラージエール言語モデル（LLMs）の迅速な進歩とその向こうへの大規模多モーダルモデル（LMMs）の進化の中間、英語や中国語のような資源豊富な言語においては顕著な進展が見られています。一方、アラビア語のLLMsは顕著な進展を見せていますが、LMMsはまだ多くの面で調査されていません、特に言語の特定の面や視覚理解に焦点を当てています。この隙を埋めるために、アラビア語のシングルモーダルモデルとしてはまだ調査されていません。この隙を埋めるために、アラビア語のシングルモーダルモデルとしてはまだ調査されていません。この隙を埋めるために、アラビア語のシングルモーダルモデルとしてはまだ調査されていません。この隙を埋めるために、アラビア語のシングルモーダルモデルとしてはまだ調査されていません。\n\nAIN-アラビア語のシングルモーダルモデルとしてはまだ調査されていません。AINは英語とアラビア語を専門的に勝手に専門的に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝手に勝",
      "upvotes": 7,
      "discussionId": "67a185b0908f4534beb94c49"
    },
    "publishedAt": "2025-02-03T22:22:44.375Z",
    "title": "AIN: The Arabic INclusive Large Multimodal Model",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/656864e12d73834278a8dea7/mmf9V_8rdsi9hN-QdFZV8.png",
      "https://cdn-uploads.huggingface.co/production/uploads/656864e12d73834278a8dea7/uLq0E1qq75-P4P1KV4xWF.png",
      "https://cdn-uploads.huggingface.co/production/uploads/656864e12d73834278a8dea7/1eixiKjHGNVm6RaJpdWeq.png",
      "https://cdn-uploads.huggingface.co/production/uploads/656864e12d73834278a8dea7/XVJSPAgIQcQn8Zi4gUVwi.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.00094.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "656864e12d73834278a8dea7",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/656864e12d73834278a8dea7/sfAWS2eyPtFHb_2GZIypp.jpeg",
      "fullname": "Ahmed Heakl",
      "name": "ahmedheakl",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isMod": false,
      "followerCount": 17
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.01081",
      "authors": [
        {
          "_id": "67a1a56d83c3565727d22f0c",
          "name": "Vernon Y. H. Toh",
          "hidden": false
        },
        {
          "_id": "67a1a56d83c3565727d22f0d",
          "name": "Yew Ken Chia",
          "hidden": false
        },
        {
          "_id": "67a1a56d83c3565727d22f0e",
          "name": "Deepanway Ghosal",
          "hidden": false
        },
        {
          "_id": "67a1a56d83c3565727d22f0f",
          "name": "Soujanya Poria",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-03T05:47:04.000Z",
      "title": "ジャンプイング・レジニング・クローブ？ 多モデル謎の解き方の進化を軌跡追いる\nGPT-[n]とo-[n]モデルでの理由論の性能の進化を調べる",
      "summary": "OpenAIのo1とo3のリリースは、大規模言語モデルにおける進歩的な理由能力の向上についての重要なパラダイムシフトを記録しています。特に、o3は、人工一般知能（AGI）の抽象化と理由のコーパスでの新しい問題解決とスキル習得において人間を超えた性能を示しました。しかし、このベンチマークは符号的なパターンのみに限定されており、人間はこれらを含む視覚と言語データを含む多様なシナリオにおける認識と理由を行うことが多いため、多様性の理由能力の進歩を調査する必要が急迫的です。このため、GPT-[n]とo-[n]シリーズモデルの進化を追跡し、複雑な多様性のパズルでの詳細な視覚認識と抽象的またはアルゴリズム的理由を必要とすることを通じて、理由能力の向上を調べています。o1の上位の性能は、GPT-4oの計算コストに近い750倍であり、これについての効率についての疑問があります。我々の結果から、モデルのイテレーションにおいて理由能力の明らかな向上の傾向が見出され、GPTシリーズモデルからo1へと顕著な性能の跳ね上がりが見られます。しかし、o1モデルは抽象的理由に必要とする簡単な多様性のパズルでは苦戦しています。また、アルゴリズム的パズルでの性能はまだ悪いということが分かります。我々は、このシリーズの新しいモデルを継続的に追跡し、この論文に応じて結果を更新することを計画しています。この評価に使用されたすべてのリソースは公開的に利用可能です（https://github.com/declare-lab/LLM-PuzzleTest）。",
      "upvotes": 5,
      "discussionId": "67a1a57083c3565727d22fc6"
    },
    "publishedAt": "2025-02-04T00:28:35.436Z",
    "title": "The Jumping Reasoning Curve? Tracking the Evolution of Reasoning Performance in GPT-[n] and o-[n] Models on Multimodal Puzzles",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01081.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5927
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.01142",
      "authors": [
        {
          "_id": "67a1b4630e9634919de9bc52",
          "user": {
            "_id": "643407dd4b34368fdb0149e8",
            "avatarUrl": "/avatars/9477b9267d5692a4fe59e30590e9639d.svg",
            "isPro": false,
            "fullname": "Xinyan Guan",
            "user": "xinyan233333",
            "type": "user"
          },
          "name": "Xinyan Guan",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-04T09:39:08.849Z",
          "hidden": false
        },
        {
          "_id": "67a1b4630e9634919de9bc53",
          "name": "Jiali Zeng",
          "hidden": false
        },
        {
          "_id": "67a1b4630e9634919de9bc54",
          "name": "Fandong Meng",
          "hidden": false
        },
        {
          "_id": "67a1b4630e9634919de9bc55",
          "name": "Chunlei Xin",
          "hidden": false
        },
        {
          "_id": "67a1b4630e9634919de9bc56",
          "name": "Yaojie Lu",
          "hidden": false
        },
        {
          "_id": "67a1b4630e9634919de9bc57",
          "name": "Hongyu Lin",
          "hidden": false
        },
        {
          "_id": "67a1b4630e9634919de9bc58",
          "name": "Xianpei Han",
          "hidden": false
        },
        {
          "_id": "67a1b4630e9634919de9bc59",
          "name": "Le Sun",
          "hidden": false
        },
        {
          "_id": "67a1b4630e9634919de9bc5a",
          "name": "Jie Zhou",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-03T08:22:45.000Z",
      "title": "DeepRAG: ステップごとに検索ステップを考えるための大規模言語モデル",
      "summary": "大語言モデル（LLMs）は、時間性、精度、カバーの効果性によって、事実的なハロケーションに苦戦しながら、理由論理の可能性を示しています。一方で、理由論理と検索アウゲージ生成（RAG）の統合は、有効なタスク分解と冗長な検索によって、ノイズの導入と回答質の低下を原因として難しいです。本論文では、検索アウゲージ論理をマルコフ決定プロセス（MDP）としてモデル化し、戦略的かつ適応的な検索を可能にするDeepRAGフレームワークを提案します。DeepRAGは、クエリを連続的に分解し、各ステップで外部知識を検索するかパラメトリック論理に依存するかを動的に決定します。実験結果によると、DeepRAGは検索効率を向上させながら、回答の正確性を21.99%上げ、検索アウゲージ論理の最適化において効果的であることを示しています。",
      "upvotes": 3,
      "discussionId": "67a1b4640e9634919de9bc8b"
    },
    "publishedAt": "2025-02-04T04:35:57.149Z",
    "title": "DeepRAG: Thinking to Retrieval Step by Step for Large Language Models",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01142.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "643407dd4b34368fdb0149e8",
      "avatarUrl": "/avatars/9477b9267d5692a4fe59e30590e9639d.svg",
      "fullname": "Xinyan Guan",
      "name": "xinyan233333",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.01100",
      "authors": [
        {
          "_id": "67a1a649f4aecd0dfc96ebf4",
          "user": {
            "_id": "607f666a4ad99100d63ce35c",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/607f666a4ad99100d63ce35c/QxhxnvfeV6efkxwUFHwjI.png",
            "isPro": false,
            "fullname": "Bill Yuchen Lin",
            "user": "yuchenlin",
            "type": "user"
          },
          "name": "Bill Yuchen Lin",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-04T09:39:17.972Z",
          "hidden": false
        },
        {
          "_id": "67a1a649f4aecd0dfc96ebf5",
          "user": {
            "_id": "635049104e753c9940fefd71",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/635049104e753c9940fefd71/HgR43XIFw3dneY5ufrAE8.jpeg",
            "isPro": false,
            "fullname": "Ronan Le Bras",
            "user": "ronanlb",
            "type": "user"
          },
          "name": "Ronan Le Bras",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-02-04T05:31:56.722Z",
          "hidden": false
        },
        {
          "_id": "67a1a649f4aecd0dfc96ebf6",
          "name": "Kyle Richardson",
          "hidden": false
        },
        {
          "_id": "67a1a649f4aecd0dfc96ebf7",
          "name": "Ashish Sabharwal",
          "hidden": false
        },
        {
          "_id": "67a1a649f4aecd0dfc96ebf8",
          "name": "Radha Poovendran",
          "hidden": false
        },
        {
          "_id": "67a1a649f4aecd0dfc96ebf9",
          "name": "Peter Clark",
          "hidden": false
        },
        {
          "_id": "67a1a649f4aecd0dfc96ebfa",
          "name": "Yejin Choi",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-03T06:44:49.000Z",
      "title": "ゼブラロジック：LLMの数理論理推論のスケーリング限界",
      "summary": "ロジックグリッドパズルからの制約満足問題(CSPs)から得られるパズルのLLMの理由論性能を評価するために、ZebraLogicという詳細な評価フレームワークを導入します。ZebraLogicは、構造調節可能で定量的に複雑なパズルを生成することができ、Llama、o1モデル、DeepSeek-R1などのモデルのスケーリング限界をシステマティックに研究することを促進します。検索スペースの複雑さと多様なロジック制約を揃え、評価環境を構築し、難易度が増加することによる理由論を評価するための構造化された環境を提供します。\n\n我々の結果から、問題の複雑さが増加すると精度が显著に低下することが明らかになります。この現象を「複雑さの呪い」と呼び、現在のLLMの理由論能力に存在する固有の制限を示しています。また、ロジックシンテキングの向上のための戦略を検討し、Best-of-Nサンプリング、バックトラッキング機構、自動証明プロンプトなどを挙げます。我々の発見は、LLMの理由論のスケーリングに関する重要な見解を提供し、基本的な制限を明らかにし、改善の可能性の方向を示します。",
      "upvotes": 3,
      "discussionId": "67a1a64cf4aecd0dfc96ecb8"
    },
    "publishedAt": "2025-02-04T00:32:03.929Z",
    "title": "ZebraLogic: On the Scaling Limits of LLMs for Logical Reasoning",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01100.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5927
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.01441",
      "authors": [
        {
          "_id": "67a189e8fbbab3ce03462fb3",
          "user": {
            "_id": "63e083e6f351dc0745745d17",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63e083e6f351dc0745745d17/N0GE4uLrkm14blAQMnm2E.jpeg",
            "isPro": false,
            "fullname": "Quan Dao",
            "user": "quandao10",
            "type": "user"
          },
          "name": "Quan Dao",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-04T09:39:30.529Z",
          "hidden": false
        },
        {
          "_id": "67a189e8fbbab3ce03462fb4",
          "name": "Khanh Doan",
          "hidden": false
        },
        {
          "_id": "67a189e8fbbab3ce03462fb5",
          "name": "Di Liu",
          "hidden": false
        },
        {
          "_id": "67a189e8fbbab3ce03462fb6",
          "user": {
            "_id": "66db7db231e772c5ec4c5576",
            "avatarUrl": "/avatars/aa0eb054bd6c881054431a22daf1aea1.svg",
            "isPro": false,
            "fullname": "Trung Le",
            "user": "trungleuc",
            "type": "user"
          },
          "name": "Trung Le",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-02-04T03:30:50.175Z",
          "hidden": false
        },
        {
          "_id": "67a189e8fbbab3ce03462fb7",
          "name": "Dimitris Metaxas",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-03T15:25:58.000Z",
      "title": "改良された潜在的一致性モデルのトレーニング手法",
      "summary": "一致性モデルは、シングルステップまたは複数ステップで高品質のサンプルを生成できる新しい生成モデルの家族です。最近、一致性モデルは印象的な性能を示し、画素空間での結果とディフュージョンモデルの同等の結果を実現しました。しかし、一致性トレーニングを大規模なデータセットに拡大する成功は、特に文から画像および映像生成タスクにおいて、潜在空間での性能によって決まります。本稿では、画素空間と潜在空間の統計的な違いを分析し、潜在データが高いインプルスのアウトライアーを含んでいて、潜在空間でのiCTの性能を大幅に低下させていることを発見しました。これを解決するために、Pseudo-Huber損失をCauchy損失に置き換え、アウトライアーの影響を効果的に軽減しました。また、早期ステップでディフュージョン損失を導入し、最適輸送（OT）コピングを使用して性能を進めました。最後に、適応スケジューラーを導入し、ノンスケーリング LayerNormを構造に採用して特徴量の統計をより良く捉え、アウトライアーの影響を減らしました。これらの戦略を用いて、一つまたは二つのステップで高品質のサンプリングを可能にし、潜在一致性とディフュージョンモデルの性能の間の間違いを大幅に狭めました。実装は以下のリンクで公開されています：https://github.com/quandao10/sLCT/",
      "upvotes": 2,
      "discussionId": "67a189eafbbab3ce0346300b"
    },
    "publishedAt": "2025-02-03T22:32:23.956Z",
    "title": "Improved Training Technique for Latent Consistency Models",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01441.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "63e083e6f351dc0745745d17",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63e083e6f351dc0745745d17/N0GE4uLrkm14blAQMnm2E.jpeg",
      "fullname": "Quan Dao",
      "name": "quandao10",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.01636",
      "authors": [
        {
          "_id": "67a1aa5dc7fa0ccf0a32ceb1",
          "user": {
            "_id": "64e8f4a24f3f7b0b84834315",
            "avatarUrl": "/avatars/242bb68c7ccffe5061c2d1c229ea3b0b.svg",
            "isPro": false,
            "fullname": "Akshat Gupta",
            "user": "akshat57",
            "type": "user"
          },
          "name": "Akshat Gupta",
          "status": "extracted_confirmed",
          "statusLastChangedAt": "2025-02-04T05:53:11.213Z",
          "hidden": false
        },
        {
          "_id": "67a1aa5dc7fa0ccf0a32ceb2",
          "name": "Phudish Prateepamornkul",
          "hidden": false
        },
        {
          "_id": "67a1aa5dc7fa0ccf0a32ceb3",
          "name": "Maochuan Lu",
          "hidden": false
        },
        {
          "_id": "67a1aa5dc7fa0ccf0a32ceb4",
          "name": "Ahmed Alaa",
          "hidden": false
        },
        {
          "_id": "67a1aa5dc7fa0ccf0a32ceb5",
          "name": "Thomas Hartvigsen",
          "hidden": false
        },
        {
          "_id": "67a1aa5dc7fa0ccf0a32ceb6",
          "name": "Gopala Anumanchipalli",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-03T18:59:14.000Z",
      "title": "Lifelong Sequential Knowledge Editing without Model Degradation",
      "summary": "先行研究においてパラメータ変更された知識編集について、大規模な順序的な編集はモデルの損傷による重大な影響を示していることが明らかになっています。本論文では、この現象の理由を調べ、元モデルの下流性能を維持するもとで10,000回の順序的な知識編集を実現することを試みます。まず、「位置指定して編集」の知識編集手法が編集された事実に過学習を引き起こすことを示します。また、これらの手法を連続的に使用すると、編集された行列のノルムの不均衡な成長を引き起こすことも明らかになります。次に、「位置指定して編集」手法の内部機能について重要なコンプレックスな見解を提供します。ノルムの成長は、これらの手法が提供する「重要性ハック」として、編集された層から生成される出力アクティベーションにより大きな重要性を与えるための隠れたタクニックであることを示します。この「重要性ハック」により、編集された層はモデルの出力に大きな貢献を提供します。これらの問題を軽減するために、ENCORE（早期停止とノルム制約された強固な知識編集）を提案します。ENCOREは過学習とノルムの不均衡な成長を抑制し、長期的な順序的な編集を可能にし、下流性能の損失を避けるものとして、10,000回の順序的な編集を実現できます。また、Llama3-8BではMEMITより61%速く、AlphaEditより64%速く効率的に動作します。",
      "upvotes": 1,
      "discussionId": "67a1aa5fc7fa0ccf0a32cf90"
    },
    "publishedAt": "2025-02-04T00:50:46.370Z",
    "title": "Lifelong Sequential Knowledge Editing without Model Degradation",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01636.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64e8f4a24f3f7b0b84834315",
      "avatarUrl": "/avatars/242bb68c7ccffe5061c2d1c229ea3b0b.svg",
      "fullname": "Akshat Gupta",
      "name": "akshat57",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.01637",
      "authors": [
        {
          "_id": "67a1a51e6aa8429da493d0b5",
          "name": "Da Yu",
          "hidden": false
        },
        {
          "_id": "67a1a51e6aa8429da493d0b6",
          "name": "Edith Cohen",
          "hidden": false
        },
        {
          "_id": "67a1a51e6aa8429da493d0b7",
          "name": "Badih Ghazi",
          "hidden": false
        },
        {
          "_id": "67a1a51e6aa8429da493d0b8",
          "name": "Yangsibo Huang",
          "hidden": false
        },
        {
          "_id": "67a1a51e6aa8429da493d0b9",
          "name": "Pritish Kamath",
          "hidden": false
        },
        {
          "_id": "67a1a51e6aa8429da493d0ba",
          "name": "Ravi Kumar",
          "hidden": false
        },
        {
          "_id": "67a1a51e6aa8429da493d0bb",
          "name": "Daogao Liu",
          "hidden": false
        },
        {
          "_id": "67a1a51e6aa8429da493d0bc",
          "name": "Chiyuan Zhang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-03T18:59:32.000Z",
      "title": "スケーリング・エンベッディング・レイヤーズ・イン・ランゲージ・モデル",
      "summary": "スコーン（スケーラブル、コンテキスト付き、オフライド、N-gram 埋め込み）を提案します。スコーンは、層サイズが拡大するときに言語モデルの性能を向上させるための方法です。汎用性のあるN-gramの埋め込みを追加しながら、元の単語ボキャベリオリーを保持します。これらの埋め込みは、それぞれの入力トークンについてコンテキスト付きの表現を提供し、別のモデルで訓練されます。推論時には、最小限の推論スピードの影響を与えないように、オフライドメモリに事前計算され、格納されます。スコーンは、2つの新しいスケーリング戦略を可能にします：キャッシュされたN-gram埋め込みの数を増やすことと、それらを学習するモデルのスケーリング、すべて推論時間のFLOPSを固定して行います。両方のスケーリングを行うことで、スコーンは、1.9Bパラメータのベースラインを超えることを示し、その他多様なコーパスでも、推論時間のFLOPSを半分に抑えながら、より優れた性能を示します。",
      "upvotes": 1,
      "discussionId": "67a1a51e6aa8429da493d0d5"
    },
    "publishedAt": "2025-02-04T00:27:13.960Z",
    "title": "Scaling Embedding Layers in Language Models",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01637.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5927
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.01591",
      "authors": [
        {
          "_id": "67a1a4b72bf092a7612b36eb",
          "name": "Antoine Dedieu",
          "hidden": false
        },
        {
          "_id": "67a1a4b72bf092a7612b36ec",
          "name": "Joseph Ortiz",
          "hidden": false
        },
        {
          "_id": "67a1a4b72bf092a7612b36ed",
          "name": "Xinghua Lou",
          "hidden": false
        },
        {
          "_id": "67a1a4b72bf092a7612b36ee",
          "name": "Carter Wendelken",
          "hidden": false
        },
        {
          "_id": "67a1a4b72bf092a7612b36ef",
          "name": "Wolfgang Lehrach",
          "hidden": false
        },
        {
          "_id": "67a1a4b72bf092a7612b36f0",
          "name": "J Swaroop Guntupalli",
          "hidden": false
        },
        {
          "_id": "67a1a4b72bf092a7612b36f1",
          "name": "Miguel Lazaro-Gredilla",
          "hidden": false
        },
        {
          "_id": "67a1a4b72bf092a7612b36f2",
          "name": "Kevin Patrick Murphy",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-03T18:25:17.000Z",
      "title": "TransformerワールドモデルをデータエフエクティブなRLに向けて改善する",
      "summary": "モデルベースのRLに適したアプローチを提案し、難しいCraftax-classicベンチマークで新たな最先端の性能を実現します。このオープンワールドの2D生存ゲームでは、強い一般的な能力を示す必要があります。我々は、サンプルエフィシェンスを向上させるための調整を行い、MBRLアルゴリズムでは1M環境ステップでも67.4%の報酬を達成し、DreamerV3の53.2%を大幅に超え、また初めて人間の性能65.0%を超えました。我々の方法は、SOTAのモデル無しベースラインを構築し、新しいポリシーアーキテクチャを使用します。その後、標準のMBRLセットアップに3つの改善を追加します：(a) \"Dyna with warmup\"、実データと想像データでポリシーを学習する、(b) \"nearest neighbor tokenizer\"、画像パッチに対して、Transformer World Model (TWM)の入力を作成する枠組みを改善する、(c) \"block teacher forcing\"、TWMが次の時間ステップの未来トークンを共に理由にするものです。",
      "upvotes": 1,
      "discussionId": "67a1a4b82bf092a7612b371b"
    },
    "publishedAt": "2025-02-04T00:25:52.071Z",
    "title": "Improving Transformer World Models for Data-Efficient RL",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01591.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5927
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.01584",
      "authors": [
        {
          "_id": "67a1e658a68ad21bcdffead6",
          "name": "Carolyn Jane Anderson",
          "hidden": false
        },
        {
          "_id": "67a1e658a68ad21bcdffead7",
          "name": "Joydeep Biswas",
          "hidden": false
        },
        {
          "_id": "67a1e658a68ad21bcdffead8",
          "name": "Aleksander Boruch-Gruszecki",
          "hidden": false
        },
        {
          "_id": "67a1e658a68ad21bcdffead9",
          "name": "Federico Cassano",
          "hidden": false
        },
        {
          "_id": "67a1e658a68ad21bcdffeada",
          "name": "Molly Q Feldman",
          "hidden": false
        },
        {
          "_id": "67a1e658a68ad21bcdffeadb",
          "name": "Arjun Guha",
          "hidden": false
        },
        {
          "_id": "67a1e658a68ad21bcdffeadc",
          "name": "Francesca Lucchetti",
          "hidden": false
        },
        {
          "_id": "67a1e658a68ad21bcdffeadd",
          "name": "Zixuan Wu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-03T18:10:38.000Z",
      "title": "PhD Knowledge Not Required: A Reasoning Challenge for Large Language Models",
      "summary": "現在の先鋒モデルのベンチマークは、非専門家が理解しにくい「ファインドライバーレベル」の専門的な知識を測定しています。対照的に、私たちは、一般的な知識を必要とするNPRの日曜日のパズル挑戦に基づくベンチマークを提供します。私たちのベンチマークは両方人間とモデルにとって難しいですが、正しい解決策は簡単に確認でき、モデルの誤りは簡単に検出できます。\n\n私たちの研究は、現在のベンチマークでは明らかでない能力の欠陥を明らかにします：OpenAI o1は、専門的な知識を測定するベンチマークで同等のレベルの他の理由モデルに比べて显著に優位しています。さらに、理由の出力の分析で新しいフェイルドの失敗を見つけました。DeepSeek R1の例では、「もう計策しません」として知られているように、知り合いの間違った回答を提供する前に「もう計策しません」として知られています。R1はもちろん、出力にも「不安」であることが驚異的です。そして、コサイドの場合、「考え終わっていない」というようになり、モデルが推論時の手法を「終わりを引き終わる」必要があることを示しています。また、R1とGemini Thinkingの長期の理由の効果を定量化し、ベンチマークでの正確性を向上させるためにより長期の理由が必要な限界を特定することを試みました。",
      "upvotes": 0,
      "discussionId": "67a1e659a68ad21bcdffeb04"
    },
    "publishedAt": "2025-02-04T05:06:50.415Z",
    "title": "PhD Knowledge Not Required: A Reasoning Challenge for Large Language Models",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01584.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "62d8315bad693a1a962864b3",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1664332914111-62d8315bad693a1a962864b3.png",
      "fullname": "Arjun Guha",
      "name": "arjunguha",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 12
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.18055",
      "authors": [
        {
          "_id": "67a197099b2f48315e74dcde",
          "user": {
            "_id": "67225dd94201755d88e104c4",
            "avatarUrl": "/avatars/6da69788ce0cd41c86f9dd0bf8d092aa.svg",
            "isPro": false,
            "fullname": "Edwin D. de Jong",
            "user": "EdwinDdeJong",
            "type": "user"
          },
          "name": "Edwin D. de Jong",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-04T09:39:28.120Z",
          "hidden": false
        },
        {
          "_id": "67a197099b2f48315e74dcdf",
          "name": "Eric Marcus",
          "hidden": false
        },
        {
          "_id": "67a197099b2f48315e74dce0",
          "name": "Jonas Teuwen",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-29T23:38:14.000Z",
      "title": "現在の病理学基盤モデルは医療機関の違いに対して脆弱です。",
      "summary": "病理学基礎モデル（FM）は医療において大きな可能性を持っています。それらが臨床実践に使用されるまでには、医療機関間の差異に強固であることが重要です。病理学FMが細胞や癌の種類の生物学的特徴に焦点を当てているか、やはり染色法や他の差異によって引き起こされる医療機関のサインに焦点を当てているかを評価します。ロバストフィックスコンフォーマンス指数（Robustness Index）を導入します。この新しいロバスト性メトリックは、生物学的特徴がサイン特徴に対してどの程度優位を占めているかを反映します。現在公開されている10つの病理学FMを評価します。現在の病理学FMは、医療機関の特徴を強く表現しています。ロバストフィックスコンフォーマンス指数に関する顕著な差異が見られます。現在までには、それほどロバストではありませんが、生物学的特徴がサイン特徴に対してちょっとも優位を占めているモデルはありません。医療機関の差異がFMベースの予測性能に与える影響を定量的に評価する方法を説明します。ロバストフィックスモデルの不変性が下流モデルの分類性能に与える影響を分析し、癌の種類の分類誤りはランダムではなく、同じ医療機関のサインに特に対応していることを見出します：同じ医療機関からの他のクラスの画像。FMの埋め込み空間を可視化し、これらは生物学的要因よりも医療機関によってより強く組織されています。その結果、医療機関の起源が組織の源と癌の種類よりもより正確に予測されます。ここで導入されたロバストフィックスコンフォーマンス指数は、強固で信頼性のある病理学FMの臨床採用への進歩を促進するために提供されています。",
      "upvotes": 0,
      "discussionId": "67a1970b9b2f48315e74dd5d"
    },
    "publishedAt": "2025-02-04T04:59:22.696Z",
    "title": "Current Pathology Foundation Models are unrobust to Medical Center Differences",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/67225dd94201755d88e104c4/oD8gcxl4D9G3FPXWGVGiz.png",
      "https://cdn-uploads.huggingface.co/production/uploads/67225dd94201755d88e104c4/_jrPyZDKwbr3K9-Q4_sCH.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.18055.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "67225dd94201755d88e104c4",
      "avatarUrl": "/avatars/6da69788ce0cd41c86f9dd0bf8d092aa.svg",
      "fullname": "Edwin D. de Jong",
      "name": "EdwinDdeJong",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.00314",
      "authors": [
        {
          "_id": "67a1d1ca167bea74d520eb59",
          "name": "Moein Heidari",
          "hidden": false
        },
        {
          "_id": "67a1d1ca167bea74d520eb5a",
          "name": "Ehsan Khodapanah Aghdam",
          "hidden": false
        },
        {
          "_id": "67a1d1ca167bea74d520eb5b",
          "name": "Alexander Manzella",
          "hidden": false
        },
        {
          "_id": "67a1d1ca167bea74d520eb5c",
          "name": "Daniel Hsu",
          "hidden": false
        },
        {
          "_id": "67a1d1ca167bea74d520eb5d",
          "name": "Rebecca Scalabrino",
          "hidden": false
        },
        {
          "_id": "67a1d1ca167bea74d520eb5e",
          "name": "Wenjin Chen",
          "hidden": false
        },
        {
          "_id": "67a1d1ca167bea74d520eb5f",
          "name": "David J. Foran",
          "hidden": false
        },
        {
          "_id": "67a1d1ca167bea74d520eb60",
          "name": "Ilker Hacihaliloglu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-01T04:25:28.000Z",
      "title": "U-Net の改良版の性能に関する研究 - 腹膜后腫瘍分割における",
      "summary": "腹膜后部には多様な腫瘍があり、稀に見られる良性と悪性の腫瘍も含まれ、それらの不頻繁性と重要構造の近接から診断と治療に課題が生じる。腫瘍の体積を推定するのは、形状の不均質性により難しいです。手動での分割は時間がかかります。U-Netやその変体を用いた自動分割は、計算量の高さに難問がありますが、有望な成果を示しています。これを解決するために、Mamba State Space Model（SSM）とExtended Long-Short Term Memory（xLSTM）のようなアーキテクチャが、長距離依存関係を処理するために資源の消費を低減することで効率的な解決策を提供しています。本研究では、新規の内部CTデータセットと公共の器官分割データセットにおいて、U-Netの拡張版（CNN、ViT、Mamba、xLSTM）を評価します。提案されたViLU-Netモデルは、Vi-blocksを用いて分割を改善しています。結果からxLSTMがU-Netフレームワークでの効率性を示していることが明らかになります。コードはGitHubで公開にあります。",
      "upvotes": 0,
      "discussionId": "67a1d1cd167bea74d520ebf6"
    },
    "publishedAt": "2025-02-04T03:38:34.899Z",
    "title": "A Study on the Performance of U-Net Modifications in Retroperitoneal Tumor Segmentation",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.00314.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "61ba19bf6122a4fd29049371",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1639586194527-noauth.jpeg",
      "fullname": "Moein Heidari",
      "name": "moein99",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": false
  }
]