[
  {
    "paper": {
      "id": "2502.01362",
      "authors": [
        {
          "_id": "67a2ad6ac7caec9bf5a45e61",
          "name": "Nikita Gushchin",
          "hidden": false
        },
        {
          "_id": "67a2ad6ac7caec9bf5a45e62",
          "name": "David Li",
          "hidden": false
        },
        {
          "_id": "67a2ad6ac7caec9bf5a45e63",
          "name": "Daniil Selikhanovych",
          "hidden": false
        },
        {
          "_id": "67a2ad6ac7caec9bf5a45e64",
          "name": "Evgeny Burnaev",
          "hidden": false
        },
        {
          "_id": "67a2ad6ac7caec9bf5a45e65",
          "name": "Dmitry Baranchuk",
          "hidden": false
        },
        {
          "_id": "67a2ad6ac7caec9bf5a45e66",
          "name": "Alexander Korotin",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-03T13:56:03.000Z",
      "title": "역 브릿지 매칭 스타일",
      "summary": "학습 디피유션 브릿지 모달은 간단하지만, 이를 고속화하여 실용적으로 만드는 것은 예술적입니다. 디피유션 브릿지 모달(DBMs)은 이미지에 대한 이미지 변환의 적용에 있어 기대되는 디피유션 모달의 확장입니다. 그러나 다른 현대적인 디피유션 모달이나 플로우 모달과 마찬가지로, DBMs는 추론 속도가 느린 문제를 보지 않았습니다. 이를 해결하기 위해, 우리는 역 브릿지 매칭의 기초에立的 새로운 디스틸 메소드를 제안하고, 실제 문제를 해결하기 위한 계산 가능한 오브젝트를 계산합니다. 이전에 개발된 DBM 디스틸 메소드와 달리, 제안된 방법은 조건부 및 비조건부 두 가지의 DBMs를 모두 디스틸할 수 있으며, 한 단계의 생성자로 디스틸하고, 그 밖에 파괴된 이미지만을 사용하여 훈련할 수 있습니다. 조건부 및 비조건부 브릿지 매칭의 두 가지를 대상으로 광범위한 설정에서 평가하고, 초해상도, JPEG 리프터م, 스케치 오브젝트에 대한 이미지 변환과 같은 다른 태스크에 대해, 우리의 디스틸 메소드가 DBMs의 추론 속도를 4배에서 100배 이상 가속화하고, 티어 모달의 생성 품질을 초과할 수 있는 것을 보여주었습니다.",
      "upvotes": 16,
      "discussionId": "67a2ad70c7caec9bf5a45fb0"
    },
    "publishedAt": "2025-02-05T03:01:40.464Z",
    "title": "Inverse Bridge Matching Distillation",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01362.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "672503c59f68afdd63cc81a2",
      "avatarUrl": "/avatars/91207207b56a1fc2b4a8197b1ab3a7f9.svg",
      "fullname": "Nikita Gushchin",
      "name": "ngushchin",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.01718",
      "authors": [
        {
          "_id": "67a2d995c97974764a8c294c",
          "name": "Huaye Zeng",
          "hidden": false
        },
        {
          "_id": "67a2d995c97974764a8c294d",
          "name": "Dongfu Jiang",
          "hidden": false
        },
        {
          "_id": "67a2d995c97974764a8c294e",
          "name": "Haozhe Wang",
          "hidden": false
        },
        {
          "_id": "67a2d995c97974764a8c294f",
          "name": "Ping Nie",
          "hidden": false
        },
        {
          "_id": "67a2d995c97974764a8c2950",
          "name": "Xiaotong Chen",
          "hidden": false
        },
        {
          "_id": "67a2d995c97974764a8c2951",
          "name": "Wenhu Chen",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-03T18:46:04.000Z",
      "title": "ACECODER: 자동 테스트 케이스 합성에 의한 랜덤 포레스트에서 코딩의 승리",
      "summary": "최근의 코드 모델의 발전은 주로 관측적 미세 조정(SFT)에 의해 추진되어 왔지만, 강화 학습(RL)의 잠재력은 코드 영역에서 신뢰할 수 있는 보상 데이터와 모델의 부족으로 인해 크게 탐색되지 않았습니다. 본 논문에서는 이러한 도전을 해결하기 위해 자동화된 대규모 테스트 케이스 합성을 활용하여 코드 모델의 훈련을 강화합니다. 특히, 기존의 코드 데이터에서 Detailed (문제, 테스트 케이스) 쌍을 생성하는 파이프라인을 설계합니다. 이러한 테스트 케이스를 사용하여 샘플링 된 프로그램의 통과율에 기반하여 Bradley-Lee 손실을 사용하여 보상 모델을 훈련합니다. 이는 Llama-3.1-8B-Ins에서 평균 10점, Qwen2.5-Coder-7B-Ins에서 5점의 개선을 보여주고, 32회의 32개 샘플링에서 7B 모델이 DeepSeek-V2.5의 236B 모델과 동일한 수준으로 도달하는 것을 보여주었습니다. 또한 보상 모델과 테스트 케이스 통과 보상을 사용하여 강화 학습을 수행하고, HumanEval, MBPP, BigCodeBench, LiveCodeBench(V4)에서 일관된 개선을 얻었습니다. 특히, R1 스타일의 훈련을 적용하여 Qwen2.5-Coder-base에서 직접 시작하여 HumanEval-plus에서 25% 이상, MBPP-plus에서 6%의 개선을 보여주었습니다. 우리는 이러한 결과를 통해 강화 학습이 코드 모델에서 큰 잠재력을 보여주고 있음을 믿습니다.",
      "upvotes": 12,
      "discussionId": "67a2d996c97974764a8c29a1"
    },
    "publishedAt": "2025-02-04T22:23:07.858Z",
    "title": "ACECODER: Acing Coder RL via Automated Test-Case Synthesis",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01718.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5946
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.02492",
      "authors": [
        {
          "_id": "67a2ec904ea0e3138ac966f2",
          "user": {
            "_id": "6181c72cdcc1df2c9de8a4d8",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1655248010394-6181c72cdcc1df2c9de8a4d8.jpeg",
            "isPro": false,
            "fullname": "Hila Chefer",
            "user": "Hila",
            "type": "user"
          },
          "name": "Hila Chefer",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-02-05T04:44:03.218Z",
          "hidden": false
        },
        {
          "_id": "67a2ec904ea0e3138ac966f3",
          "name": "Uriel Singer",
          "hidden": false
        },
        {
          "_id": "67a2ec904ea0e3138ac966f4",
          "name": "Amit Zohar",
          "hidden": false
        },
        {
          "_id": "67a2ec904ea0e3138ac966f5",
          "name": "Yuval Kirstain",
          "hidden": false
        },
        {
          "_id": "67a2ec904ea0e3138ac966f6",
          "name": "Adam Polyak",
          "hidden": false
        },
        {
          "_id": "67a2ec904ea0e3138ac966f7",
          "name": "Yaniv Taigman",
          "hidden": false
        },
        {
          "_id": "67a2ec904ea0e3138ac966f8",
          "name": "Lior Wolf",
          "hidden": false
        },
        {
          "_id": "67a2ec904ea0e3138ac966f9",
          "name": "Shelly Sheynin",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-04T17:07:10.000Z",
      "title": "VideoJAM: 비디오 모델에서 기능성을 향상시키는 공통적인 외관-행동 표현\n\n(Note: The original text appears to be a title or heading rather than a full sentence, and the translation maintains the original structure and meaning.)",
      "summary": "최근의 과거에 의한 엄청난 진보에도 불구하고, 생성 비디오 모델은 실제 세계의 움직임, 역학, 그리고 물리를 이해하는 데 어려움을 겪습니다. 우리는 이러한 제한이 전통적인 픽셀 재구성의 목표에 의해 발생하며, 이 목표는 모델이 동적인 일관성을 잃는 것을 보여줍니다. 이를 해결하기 위해, 우리는 VideoJAM라는 새로운 프레임워크를 소개하며, 모델이 공통의 외관-동작 표현을 학습하도록 유도하여, 비디오 생성기에 효과적인 움직임을 제공하도록 합니다. VideoJAM는 두 개의 보간 단위로 구성되어 있습니다. 훈련 중, 목표를 확장하고, 생성된 픽셀과 대응하는 움직임을 예측함으로써, 한 가지 학습된 표현으로 만들 수 있습니다. 추론 중, 우리는 Inner-Guidance라는 구조를 도입하며, 모델의 자체적으로 진화하는 움직임 예측을 동적인 가이드라인 신호로 활용하여, 일관된 움직임에 대한 생성을 제어하는 것입니다. 특히, 우리의 프레임워크는 최소한의 변경 없이, 훈련 데이터나 모델의 스케일링에 의한 변경이 필요하지 않는 것을 특징으로, 동적인 일관성을 위해 가장 先端의 성능을 달성하고, 높은 경쟁력의 프로필리모르 모델을 초월하며, 동시에 생성물의 시각적 질량을 향상시킵니다. 이러한 발견은 외관과 움직임은 보간적이며, 효과적으로 통합되어, 비디오 생성의 시각적 질량과 일관성을 둘 다 향상시키는 것을 강조합니다. 프로젝트 웹 사이트: https://hila-chefer.github.io/videojam-paper.github.io/",
      "upvotes": 11,
      "discussionId": "67a2ec934ea0e3138ac9678e"
    },
    "publishedAt": "2025-02-04T23:46:17.626Z",
    "title": "VideoJAM: Joint Appearance-Motion Representations for Enhanced Motion Generation in Video Models",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.02492.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6181c72cdcc1df2c9de8a4d8",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1655248010394-6181c72cdcc1df2c9de8a4d8.jpeg",
      "fullname": "Hila Chefer",
      "name": "Hila",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 8
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.02584",
      "authors": [
        {
          "_id": "67a2d59fd5ad3369a66ff394",
          "name": "Zongyu Lin",
          "hidden": false
        },
        {
          "_id": "67a2d59fd5ad3369a66ff395",
          "name": "Yao Tang",
          "hidden": false
        },
        {
          "_id": "67a2d59fd5ad3369a66ff396",
          "name": "Xingcheng Yao",
          "hidden": false
        },
        {
          "_id": "67a2d59fd5ad3369a66ff397",
          "name": "Da Yin",
          "hidden": false
        },
        {
          "_id": "67a2d59fd5ad3369a66ff398",
          "name": "Ziniu Hu",
          "hidden": false
        },
        {
          "_id": "67a2d59fd5ad3369a66ff399",
          "name": "Yizhou Sun",
          "hidden": false
        },
        {
          "_id": "67a2d59fd5ad3369a66ff39a",
          "name": "Kai-Wei Chang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-04T18:58:31.000Z",
      "title": "QLASS: Q-Guided Stepwise Search를 통해 언어 어셈블리 출력 추론을 향상시킴",
      "summary": "언어 에이전트는 복잡한 상호작용 태스크에 대한 유망한 해결책으로 자리잡고 있으며, 성공의 핵심 중 하나는 에이전트워크 흐름의궤도상의 보상 모델입니다. 이 모델은 학습 또는 추론 중에 유효한 지도를 제공합니다. 그러나 중간적인 상호작용의 설명이 부족하기 때문에, 많은 기존 연구에서는 결과 보상 모델을 사용하며, 전체적인궤도를 구성하는 정책을 최적화합니다. 이는 최적의 정책을 얻을 수 없고 전체적인 성능을 저해할 수 있습니다. 이를 해결하기 위해, QLASS(Q-GUIDED 언어 에이전트 스텝스케일 서치)를 제안하고, 오픈 프레임워크의 언어 에이전트에 대해 단계별로 Q값을 추정하여 자동적으로 설명을 생성하여 중간적인 지도를 제공합니다. 이유의 나무를 놔서, 과정 보상 모델링을 수행함으로써, QLASS는 각 단계에 효과적인 중간적인 지도를 제공합니다. 단계별 지도를 기반으로, QLASS는 장기적인 가치에 의한 더 좋은 적응성을 부여하고, 복잡한 상호작용 에이전트 태스크의 모델 추론 중의 성능 향상을 실현합니다. 특히, 절반 가까운 설명 데이터만을 사용하며도 강력한 성능을 유지하며, 제한된 슈퍼바이온에 대한 효율성을 보여주며, 또한 질적인 분석을 통해 QLASS가 더 효율적인 결정을 촉진하는 것을 실험적으로 증명합니다. 코드와 데이터는 공개됩니다.",
      "upvotes": 7,
      "discussionId": "67a2d5a0d5ad3369a66ff3d4"
    },
    "publishedAt": "2025-02-04T22:08:25.652Z",
    "title": "QLASS: Boosting Language Agent Inference via Q-Guided Stepwise Search",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.02584.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "634e4670a51d5df8c2d92fce",
      "avatarUrl": "/avatars/c52d7150b4de6a2eb2d83b345d35cbc2.svg",
      "fullname": "Da Yin",
      "name": "DaYin",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.01941",
      "authors": [
        {
          "_id": "67a2e2a02dd2adbc88755a47",
          "name": "Xiang Liu",
          "hidden": false
        },
        {
          "_id": "67a2e2a02dd2adbc88755a48",
          "name": "Zhenheng Tang",
          "hidden": false
        },
        {
          "_id": "67a2e2a02dd2adbc88755a49",
          "name": "Hong Chen",
          "hidden": false
        },
        {
          "_id": "67a2e2a02dd2adbc88755a4a",
          "name": "Peijie Dong",
          "hidden": false
        },
        {
          "_id": "67a2e2a02dd2adbc88755a4b",
          "name": "Zeyu Li",
          "hidden": false
        },
        {
          "_id": "67a2e2a02dd2adbc88755a4c",
          "name": "Xiuze Zhou",
          "hidden": false
        },
        {
          "_id": "67a2e2a02dd2adbc88755a4d",
          "name": "Bo Li",
          "hidden": false
        },
        {
          "_id": "67a2e2a02dd2adbc88755a4e",
          "name": "Xuming Hu",
          "hidden": false
        },
        {
          "_id": "67a2e2a02dd2adbc88755a4f",
          "name": "Xiaowen Chu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-04T02:23:06.000Z",
      "title": "LLM은 KV 캐시 압축 아래 기본적인 능력을 유지할 수 있는지?",
      "summary": "이 논문은 대규모 언어 모델(LLMs)에서 조사되지 않은 문제에 대해 조사하고 있습니다: KV 캐시의 압축 방법이 LLMs의 기본적인 능력에 미치는 영향입니다. 기존의 방법들은 긴 문맥 벤치마크에서 놀라운 압축비를 달성하지만, 이들이 핵심 모델 능력에 미치는 영향은 아직 조사가 부족합니다. 우리는 세계 지식, 통상적 추론, 산술 추론, 코드 생성, 안전성, 긴 문맥의 이해 및 생성을 포함하는 다양한 태스크의 범위를 넓게 평가하는 주요 KV 캐시 압축 방법을 제공합니다. 분석에 따르면 KV 캐시 압축 방법은 특정 태스크에 따라 성능 저하를 나타냅니다. 산술 추론 태스크는 특히 심한 압축에 민감하며, 17.4%-43.3%의 성능 저하를 나타냅니다. 특히, DeepSeek R1 Distill 모델은 지시 훈련 모델과 비교하여 압축에 대한 저항성이 높으며, 9.67%-25.53%의 성능 저하를 나타냅니다. 우리는 주의 패턴과 크로스 태스크의 압축 성능을 평가하고, 새로운 압축 접근 방식인 ShotKV를 제안합니다. ShotKV는 prefill과 디코딩 단계를 개별적으로 처리하고, 쉼 레벨의 의미적인 연결성을 유지함으로써, 심한 압축 비율 아래에서 긴 문맥 생성 태스크에서 9%-18%의 성능 향상을 달성합니다.",
      "upvotes": 6,
      "discussionId": "67a2e2a22dd2adbc88755ab4"
    },
    "publishedAt": "2025-02-04T23:04:25.888Z",
    "title": "Can LLMs Maintain Fundamental Abilities under KV Cache Compression?",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/63024676056ec3a2a8714b24/XcgjmhpXd3dH6LnFZGupJ.png",
      "https://cdn-uploads.huggingface.co/production/uploads/63024676056ec3a2a8714b24/hxWz1iVOUcE76E_K5z-B0.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01941.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "63024676056ec3a2a8714b24",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1661093436322-noauth.jpeg",
      "fullname": "Xiang Liu",
      "name": "Dominic789654",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 3
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.02508",
      "authors": [
        {
          "_id": "67a2d1f9bc9d072d9459e857",
          "user": {
            "_id": "6553c985a7aded0380b5f928",
            "avatarUrl": "/avatars/36109d6f536d2b34d98822b88eac9608.svg",
            "isPro": false,
            "fullname": "Maohao Shen",
            "user": "maohaos2",
            "type": "user"
          },
          "name": "Maohao Shen",
          "status": "extracted_confirmed",
          "statusLastChangedAt": "2025-02-05T03:00:33.470Z",
          "hidden": false
        },
        {
          "_id": "67a2d1f9bc9d072d9459e858",
          "name": "Guangtao Zeng",
          "hidden": false
        },
        {
          "_id": "67a2d1f9bc9d072d9459e859",
          "name": "Zhenting Qi",
          "hidden": false
        },
        {
          "_id": "67a2d1f9bc9d072d9459e85a",
          "name": "Zhang-Wei Hong",
          "hidden": false
        },
        {
          "_id": "67a2d1f9bc9d072d9459e85b",
          "name": "Zhenfang Chen",
          "hidden": false
        },
        {
          "_id": "67a2d1f9bc9d072d9459e85c",
          "name": "Wei Lu",
          "hidden": false
        },
        {
          "_id": "67a2d1f9bc9d072d9459e85d",
          "name": "Gregory Wornell",
          "hidden": false
        },
        {
          "_id": "67a2d1f9bc9d072d9459e85e",
          "name": "Subhro Das",
          "hidden": false
        },
        {
          "_id": "67a2d1f9bc9d072d9459e85f",
          "name": "David Cox",
          "hidden": false
        },
        {
          "_id": "67a2d1f9bc9d072d9459e860",
          "name": "Chuang Gan",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-04T17:26:58.000Z",
      "title": "사토리: 행동의 연속으로의 생각에 기반한 강화학습이 LLM을 강화\n\n자동 추론에 의한 탐색에 의한 추론",
      "summary": "대 언어 모델(LLMs)은 다양한 분야에서 놀라울 정도로 논리적 판단 능력을 보여주고 있습니다. 최근의 연구에 따르면, 검증 시의 계산량의 증가가 LLMs의 논리적 판단 능력을 향상시키는 것으로 보입니다. 이는 일반적으로 추론 시 외부 LLM 검증 데이터에 의한 광범위한 샘플링을 포함하며, 이를 통해 두 개의 플레이어 시스템이 형성됩니다. 외부 가이드를 받지도 불구하고, 이 시스템의 효율성은 단일 LLM이 복잡한 작업을 해결할 수 있음을 보여줍니다. 따라서, 우리는 새로운 연구 문제를 제안합니다: 단일 LLM의 논리적 판단 능력을 근본적으로 향상시키기 위해, 탐색 능력을 내부화할 수 있는지 여부에 대해 연구를 진행합니다. 이 연구는 후 학습 LLMs에 초점을 맞추고, 확장된 논리적 판단 프로세스(즉, 자기 반성 및 새로운 전략의 자기 탐색을 포함하는 자동 협업 탐색)을 중점적으로 다루며, 직교 방향을 검토하고 있습니다. 이를 달성하기 위해, Chain-of-Action-Thought(COAT) 논리적 판단 및 2단계 학습 패러다임을 제안합니다: 1) COAT 논리적 판단의 형식을 내부화하는 소규모 형식 훈련 단계와, 2) 큰 규모의 자기 개선 단계에서 강화 학습을 활용합니다. 우리의 접근 방식은 오픈 소스 모델과 데이터로 훈련된 7B LLM인 「Satori」를 결과로 얻었습니다. 확장된 실험 평가에 따르면, Satori는 수학적 논리적 판단 벤치마크에서 가장 선진적인 성능을 달성하며, 외부 영역 작업에 대한 강력한 확장성을 보여줍니다. 코드, 데이터, 모델은 완전히 오픈 소스로 합니다.",
      "upvotes": 5,
      "discussionId": "67a2d1fcbc9d072d9459e91b"
    },
    "publishedAt": "2025-02-04T21:55:09.693Z",
    "title": "Satori: Reinforcement Learning with Chain-of-Action-Thought Enhances LLM Reasoning via Autoregressive Search",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.02508.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60ad0de755f970745d4ec28d",
      "avatarUrl": "/avatars/b0de0222b8ed5fdac8dc7cb0336d2ec7.svg",
      "fullname": "GtZeng",
      "name": "chaoscodes",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isMod": false,
      "followerCount": 11
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.01720",
      "authors": [
        {
          "_id": "67a2fddb4044bf1c86f765a3",
          "name": "Nupur Kumari",
          "hidden": false
        },
        {
          "_id": "67a2fddb4044bf1c86f765a4",
          "name": "Xi Yin",
          "hidden": false
        },
        {
          "_id": "67a2fddb4044bf1c86f765a5",
          "name": "Jun-Yan Zhu",
          "hidden": false
        },
        {
          "_id": "67a2fddb4044bf1c86f765a6",
          "name": "Ishan Misra",
          "hidden": false
        },
        {
          "_id": "67a2fddb4044bf1c86f765a7",
          "name": "Samaneh Azadi",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-03T18:59:41.000Z",
      "title": "멀티이미지의 합성 데이터 생성하여 텍스트로부터 이미지의 커스텀을 실현합니다.",
      "summary": "텍스트로부터 이미지 모델을 커스터마이징하여 사용자가 커스터마이징된 개념을 삽입하고, 이전에 본 적이 없는 설정에서 그 개념을 생성할 수 있도록 할 수 있습니다. 현재의 방법들은 비용 높은 테스트 시의 최적화에 의존하거나, 단일 이미지의 훈련 데이터 세트로 인코더를 훈련시키지만, 다수의 이미지의 슈퍼뷰러러를 포함하지 않아 이미지의 품질이 저하될 수 있습니다. 우리는 두 가지 제약을 해결하기 위해 간단한 접근법을 제안합니다. 먼저, 기존 텍스트와 이미지 모델, 3D 데이터 세트를 활용하여 동일한 물체의 다양한 조명, 배경, 그리고 자세의 이미지가 포함된 고품질의 Synthetic Customization Dataset (SynCD)을 생성합니다. 다음으로, 공유 어텐션 구조에 기반한 새로운 인코더 아키텍처를 제안하며, 입력 이미지에서의 미세한 시각적인 세부 사항을 더 잘 통합하는 것을 목표로 합니다. 마지막으로, 추론 시의 오버exposure 문제를 완화하기 위해 텍스트와 이미지의 Guide Vector를 정규화하는 새로운 추론 방법을 제안합니다. 확장된 실험을 통해, 우리의 모델은 제안된 인코더와 추론 알고리즘을 사용하여 합성 데이터 세트로 훈련되어, 표준적인 커스터마이징 벤치마크에서 현재의 토닝freie 방법을 초월하는 것을 보여주었습니다.",
      "upvotes": 2,
      "discussionId": "67a2fde34044bf1c86f767ba"
    },
    "publishedAt": "2025-02-05T00:59:11.275Z",
    "title": "Generating Multi-Image Synthetic Data for Text-to-Image Customization",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01720.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "62f6a894c3372328414c7021",
      "avatarUrl": "/avatars/e8b10912355712f38f10805c31bea962.svg",
      "fullname": "Nupur Kumari",
      "name": "nupurkmr9",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 4
    },
    "isAuthorParticipating": false
  }
]