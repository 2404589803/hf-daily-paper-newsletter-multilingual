[
  {
    "paper": {
      "id": "2501.15368",
      "authors": [
        {
          "_id": "67986c6822990ae89bb71fb9",
          "name": "Yadong Li",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fba",
          "name": "Jun Liu",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fbb",
          "name": "Tao Zhang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fbc",
          "name": "Tao Zhang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fbd",
          "name": "Song Chen",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fbe",
          "name": "Tianpeng Li",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fbf",
          "name": "Zehuan Li",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fc0",
          "name": "Lijun Liu",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fc1",
          "name": "Lingfeng Ming",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fc2",
          "name": "Guosheng Dong",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fc3",
          "name": "Da Pan",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fc4",
          "name": "Chong Li",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fc5",
          "name": "Yuanbo Fang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fc6",
          "name": "Dongdong Kuang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fc7",
          "name": "Mingrui Wang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fc8",
          "name": "Chenglin Zhu",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fc9",
          "name": "Youwei Zhang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fca",
          "name": "Hongyu Guo",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fcb",
          "name": "Fengyu Zhang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fcc",
          "name": "Yuran Wang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fcd",
          "name": "Bowen Ding",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fce",
          "name": "Wei Song",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fcf",
          "name": "Xu Li",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fd0",
          "name": "Yuqi Huo",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fd1",
          "name": "Zheng Liang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fd2",
          "name": "Shusen Zhang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fd3",
          "name": "Xin Wu",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fd4",
          "name": "Shuai Zhao",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fd5",
          "name": "Linchu Xiong",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fd6",
          "name": "Yozhen Wu",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fd7",
          "name": "Jiahui Ye",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fd8",
          "name": "Wenhao Lu",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fd9",
          "name": "Bowen Li",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fda",
          "name": "Yan Zhang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fdb",
          "name": "Yaqi Zhou",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fdc",
          "name": "Xin Chen",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fdd",
          "name": "Lei Su",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fde",
          "name": "Hongda Zhang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fdf",
          "name": "Fuzhong Chen",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fe0",
          "name": "Xuezhen Dong",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fe1",
          "name": "Na Nie",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fe2",
          "name": "Zhiying Wu",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fe3",
          "name": "Bin Xiao",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fe4",
          "name": "Ting Li",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fe5",
          "name": "Shunya Dang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fe6",
          "name": "Ping Zhang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fe7",
          "name": "Yijia Sun",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fe8",
          "name": "Jincheng Wu",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fe9",
          "name": "Jinjie Yang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fea",
          "name": "Xionghai Lin",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71feb",
          "name": "Zhi Ma",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fec",
          "name": "Kegeng Wu",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fed",
          "name": "Jia li",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fee",
          "name": "Aiyuan Yang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fef",
          "name": "Hui Liu",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71ff0",
          "name": "Jianqiang Zhang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71ff1",
          "name": "Xiaoxi Chen",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71ff2",
          "name": "Guangwei Ai",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71ff3",
          "name": "Wentao Zhang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71ff4",
          "name": "Yicong Chen",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71ff5",
          "name": "Xiaoqin Huang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71ff6",
          "name": "Kun Li",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71ff7",
          "name": "Wenjing Luo",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71ff8",
          "name": "Yifei Duan",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71ff9",
          "name": "Lingling Zhu",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71ffa",
          "name": "Ran Xiao",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71ffb",
          "name": "Zhe Su",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71ffc",
          "name": "Jiani Pu",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71ffd",
          "name": "Dian Wang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71ffe",
          "name": "Xu Jia",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fff",
          "name": "Tianyu Zhang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb72000",
          "name": "Mengyu Ai",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb72001",
          "name": "Mang Wang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb72002",
          "name": "Yujing Qiao",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb72003",
          "name": "Lei Zhang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb72004",
          "name": "Yanjun Shen",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb72005",
          "name": "Fan Yang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb72006",
          "name": "Miao Zhen",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb72007",
          "name": "Yijie Zhou",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb72008",
          "name": "Mingyang Chen",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb72009",
          "name": "Fei Li",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb7200a",
          "name": "Chenzheng Zhu",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb7200b",
          "name": "Keer Lu",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb7200c",
          "name": "Yaqi Zhao",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb7200d",
          "name": "Hao Liang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb7200e",
          "name": "Youquan Li",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb7200f",
          "name": "Yanzhao Qin",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb72010",
          "name": "Linzhuang Sun",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb72011",
          "name": "Jianhua Xu",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb72012",
          "name": "Haoze Sun",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb72013",
          "name": "Mingan Lin",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb72014",
          "name": "Zenan Zhou",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb72015",
          "name": "Weipeng Chen",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-26T02:19:03.000Z",
      "title": "Baichuan-Omni-1.5 기술보고서\n\n(注意：由于原文中没有提供具体的英文文本内容，上述翻译仅保留了原文的标题部分。如果您能提供具体的英文文本内容，我将能够为您提供完整的翻译。)",
      "summary": "Baichuan-Omni-1.5는 다양한 모델로 구성되어 있으며, 모델이 여러 모델을 이해할 수 있는 능력에 더해, 처음부터 끝까지 일관된 음성 생성 능력을 제공합니다. 모든 모델의 능력을 잃지 않고, 모델 간 순수한 고품질 상호작용을 구현하기 위해 3가지 중요한 측면에서 우선순위를 두었습니다. 먼저, 다양한 데이터의 콘텐츠 정제와 합성 파이프라인을 구축하여 약 500B의 고품질 데이터(텍스트, 음성, 시각)를 수집했습니다. 다음으로, 음성 토큰라이너(Baichuan-Audio-Tokenizer)을 설계하여 음성으로부터 언어적 및 음향적 정보를 추출하고, MLLM과 간섭이 없는 통합 및 확장성을 실현했습니다. 마지막으로, 다단계 훈련 전략을 설계하여 단계적으로 다양한 모델의 대응과 다양한 태스크의 微调을 통합하여 모든 모델 간 효과적인 조화를 보장했습니다. Baichuan-Omni-1.5는 현대 모델(GPT4o-mini, MiniCPM-o 2.6 포함)을 능가하며, 여러 모델의 세부적인 평가를 수행했습니다.",
      "upvotes": 18,
      "discussionId": "67986c6b22990ae89bb720aa"
    },
    "publishedAt": "2025-01-28T00:34:49.721Z",
    "title": "Baichuan-Omni-1.5 Technical Report",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.15368.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5828
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.15383",
      "authors": [
        {
          "_id": "67986c83b5e71350993d28eb",
          "name": "An Yang",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28ec",
          "name": "Bowen Yu",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28ed",
          "name": "Chengyuan Li",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28ee",
          "name": "Dayiheng Liu",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28ef",
          "name": "Fei Huang",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28f0",
          "name": "Haoyan Huang",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28f1",
          "name": "Jiandong Jiang",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28f2",
          "name": "Jianhong Tu",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28f3",
          "name": "Jianwei Zhang",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28f4",
          "name": "Jingren Zhou",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28f5",
          "name": "Junyang Lin",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28f6",
          "name": "Kai Dang",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28f7",
          "name": "Kexin Yang",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28f8",
          "name": "Le Yu",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28f9",
          "name": "Mei Li",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28fa",
          "name": "Minmin Sun",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28fb",
          "name": "Qin Zhu",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28fc",
          "name": "Rui Men",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28fd",
          "name": "Tao He",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28fe",
          "name": "Weijia Xu",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28ff",
          "name": "Wenbiao Yin",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d2900",
          "name": "Wenyuan Yu",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d2901",
          "name": "Xiafei Qiu",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d2902",
          "name": "Xingzhang Ren",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d2903",
          "name": "Xinlong Yang",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d2904",
          "name": "Yong Li",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d2905",
          "name": "Zhiying Xu",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d2906",
          "name": "Zipeng Zhang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-26T03:47:25.000Z",
      "title": "Qwen2.5-1M 기술보고서\n\n(注意：이 번역은 단순히 영어를 한국어로 번역한 결과입니다. 전문성과 정확성을 유지하였으나, 추가적인 설명이나 텍스트를 추가하지 않았습니다.)",
      "summary": "Qwen2.5-1M 모델 시리즈를 소개합니다. 이 모델 시리즈는 1,000,000 토큰의 컨텍스트 길이를 확장했습니다. 이전 128K 버전에 비해, 긴 컨텍스트 처리 능력이 크게 향상되었습니다. 긴 컨텍스트 학습과 후속 학습을 통해 긴 컨텍스트 성능을 효과적으로 향상시키고 학습 비용을 줄였습니다. 긴 데이터 합성, 발전된 예측 학습, 다단계의 매뉴얼 피드백 조정 등 주요 기술로 긴 컨텍스트 성능을 향상시키고 동시에 학습 비용을 줄였습니다.\n\n세계적인 사용자 기반으로 긴 컨텍스트 모델의 활용을 촉진하기 위해, 추론 프레임워크를 제공하고 소스 코드를 공개합니다. 이 프레임워크에는 추가 학습을 제외하면 모델의 컨텍스트 길이를 4배 이상 확장할 수 있는 긴 컨텍스트 추론 방법을 포함하고 있습니다. 추론 비용을 줄이기 위해, 희소 어텐션법과 블록 단위 필드 프리프이미징을 구현하고, 배치 시나리오에서 희소성을 개선하는 피드백을 구현했습니다. 또한 추론 엔진 최적화에 대해 상세히 설명하고, 커널 최적화, 파이프라인 병렬화, 스케줄링 최적화 등이 적용되어 전체 추론 성능이 크게 향상되었습니다. 이 프레임워크를 활용하면 1,000,000 토큰의 컨텍스트의 경우, 3배에서 7배의 필드 프리프이미징 속도 업그레이드가 가능합니다. 이 프레임워크는 긴 컨텍스트 처리를 필요로 하는 애플리케이션 개발에 효율적이고 강력한 해결책을 제공합니다.\n\n현재 Qwen2.5-1M 시리즈에는 오픈소스 모델 Qwen2.5-7B-Instruct-1M과 Qwen2.5-14B-Instruct-1M이 포함되어 있으며, API에 액세스 가능한 모델 Qwen2.5-Turbo도 포함되어 있습니다. 평가에 따르면 Qwen2.5-1M 모델은 긴 컨텍스트 태스크에서 크게 향상되었으며, 짧은 컨텍스트 시나리오에서 성능이 떨어지지 않습니다. 특히, Qwen2.5-14B-Instruct-1M 모델은 GPT-4o-mini보다 뚜렷한 우위를 취하며, 8배의 긴 컨텍스트를 지원합니다.",
      "upvotes": 7,
      "discussionId": "67986c84b5e71350993d2974"
    },
    "publishedAt": "2025-01-28T00:35:46.871Z",
    "title": "Qwen2.5-1M Technical Report",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.15383.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5828
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.15570",
      "authors": [
        {
          "_id": "679843ae7d7b7f8196c61ab7",
          "name": "Lin Yueyu",
          "hidden": false
        },
        {
          "_id": "679843ae7d7b7f8196c61ab8",
          "name": "Li Zhiyuan",
          "hidden": false
        },
        {
          "_id": "679843ae7d7b7f8196c61ab9",
          "name": "Peter Yue",
          "hidden": false
        },
        {
          "_id": "679843ae7d7b7f8196c61aba",
          "user": {
            "_id": "6176b32847ee6431f632981e",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6176b32847ee6431f632981e/02rZ_oLAI0Ll6Y6be7Q9F.jpeg",
            "isPro": false,
            "fullname": "IvanD",
            "user": "xiaol",
            "type": "user"
          },
          "name": "Liu Xiao",
          "status": "extracted_confirmed",
          "statusLastChangedAt": "2025-01-28T02:44:02.658Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-26T15:56:56.000Z",
      "title": "ARWKV: 학습 필요 없음, Transformer에서 탄생한 RNN-Attention 기반 언어 모델",
      "summary": "이제까지 알려진 것처럼, 여러 헤드 아키텍처에서 조합된 가바라이드 커버비크 및 서브커버비크 어텐션 모델은 Transformer 및 Linear RNN 모델을 초월하며, KV 복잡성의 감소와 효율 향상에 초점을 맞추고 있습니다. 또한 표현력 연구를 촉진하기 위해, Qwen 2.5에서부터의 원생 RWKV-7 어텐션 기반 모델 시리즈를 소개합니다. 이 모델들은 RNN의 표현력을 높일 수 있으며, Transformer를 초월하는 상태 추적 능력에 목표를 둔 것입니다. 또, QRWK 32B는 RWKV-6 아키텍처를 기반으로, 16 단백질 300X GPU를 사용하여 지식 처리 시간을 8시간에 제한하여 Qwen 2.5의 성능을 유지하면서, 지식 처리 시간을 크게 줄일 수 있습니다. 실제로, 디스틸루션 프로세스는 LLM의 종류에 제한이 없으며, 큰 LLM에서 작은 LLM까지의 지식 전달을 가능하게 합니다. 이러한 프로세스의 세부 사항 및 강력한 기초 모델의 구축에 대한 피드백을 공유합니다. 이는 계속해서 업데이트되는 진행 중인 작업입니다. 모델 체크포인트 및 소스 코드는 아래 URL에서 사용 가능합니다.",
      "upvotes": 3,
      "discussionId": "679843af7d7b7f8196c61b21"
    },
    "publishedAt": "2025-01-28T03:02:56.062Z",
    "title": "ARWKV: Pretrain is not what we need, an RNN-Attention-Based Language Model Born from Transformer",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.15570.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6176b32847ee6431f632981e",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6176b32847ee6431f632981e/02rZ_oLAI0Ll6Y6be7Q9F.jpeg",
      "fullname": "IvanD",
      "name": "xiaol",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 81
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2501.16142",
      "authors": [
        {
          "_id": "67986cbc7dbf69e4e38539b7",
          "name": "Scott Fujimoto",
          "hidden": false
        },
        {
          "_id": "67986cbc7dbf69e4e38539b8",
          "name": "Pierluca D'Oro",
          "hidden": false
        },
        {
          "_id": "67986cbc7dbf69e4e38539b9",
          "name": "Amy Zhang",
          "hidden": false
        },
        {
          "_id": "67986cbc7dbf69e4e38539ba",
          "name": "Yuandong Tian",
          "hidden": false
        },
        {
          "_id": "67986cbc7dbf69e4e38539bb",
          "name": "Michael Rabbat",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-27T15:36:37.000Z",
      "title": "Towards General-Purpose Model-Free Reinforcement Learning",
      "summary": "강화학습(RL)은 최근의 문제를 해결하는 프레임워크를 제공하기 위해 약속되어 있습니다. 실제로는 RL 알고리즘은 특정 벤치마크에 돋보였으며, 조정된 초 파라미터와 알고리즘의 선택에 의존합니다. 최근, 강력한 모델 기반의 RL 메소드는 복잡성과 느린 실행 시간으로 전체 벤치마크에서 놀라운 결과를 보여주지만, 이는 계획과 계산 로직에 관련된 비용을 줄이기 위해 모델 기반의 태스크 객체를 사용함으로써 실현되었습니다. 본 논문에서는 다양한 영역과 문제 설정을 다루는 통일된 모델 없는 깊은 RL 알고리즘을 탐구하고자 합니다. 이를 달성하기 위해, 모델 기반의 표현을 활용하고 가치 함수를 근사 선형화하고, 모델 기반의 RL에서 사용될 더 상세한 태스크 객체를 활용하면서, 계획과 계산 로직에 관련된 비용을 줄입니다. 우리의 알고리즘, MR.Q는 하나의 초 파라미터 세트로 다양한 일반적인 RL 벤치마크에 대해 평가되었으며, 영역 특화된 베이스라인과 일반적인 베이스라인과의 비교에서 경쟁적인 성능을 보여주며, 일반적인 모델 없는 깊은 RL 알고리즘의 구축에 대한 구체적인 단계를 제공합니다.",
      "upvotes": 2,
      "discussionId": "67986cbf7dbf69e4e3853a89"
    },
    "publishedAt": "2025-01-28T00:36:09.186Z",
    "title": "Towards General-Purpose Model-Free Reinforcement Learning",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.16142.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5828
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.15369",
      "authors": [
        {
          "_id": "6798706dabdc35456a92212d",
          "name": "Chuanyang Zheng",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-26T02:34:58.000Z",
      "title": "iFormer: 모바일 앱을 위한 ConvNet과 Transformer의 통합",
      "summary": "우리는 모바일 애플리케이션에서 지연 시간과 정확도를 최적화하기 위한 새로운 모바일 하이브리드 시각 네트워크 familiy를 소개합니다. 이 familiy는 iFormer로 불립니다. iFormer는 딥러닝의 빠른 지역 표현 용량과 자기 어텐션의 효율적인 글로벌 모델링 능력을 효과적으로 통합합니다. 지역 상호작용은 표준 컨볼루션 네트워크인 ConvNeXt를 변환하여 더 가벼운 모바일 네트워크를 설계하는 방식으로 추출됩니다. 우리는 새로운 모바일 modulation attention을 도입하여 MHA의 메모리 지출적인 연산을 제거하고 효율적인 modulation 메커니즘을 사용하여 동적인 글로벌 표현 용량을 향상시킵니다. 우리는 다양한 태스크에서 기존 가벼운 네트워크를 초과하는 성능을 보여주는 iFormer를 증명하기 위해 전담적인 실험을 수행했습니다. 특히, ImageNet-1k에서 Top-1 정확도가 80.4%를 달성하며 iPhone 13에서 1.10 ms의 지연 시간에서 수행하는 데서 놀라운 성능을 보입니다. 또한, COCO 객체 탐지, 인스턴스 분할, ADE20k 세ман틱 분할 등 하류 태스크에서 상당한 개선을 보였으며, 이러한 시나리오에서 고해상도 입력을 처리하는 데서 모바일 장치에서 낮은 지연 시간을 유지합니다.",
      "upvotes": 1,
      "discussionId": "6798706eabdc35456a92215a"
    },
    "publishedAt": "2025-01-28T00:51:51.263Z",
    "title": "iFormer: Integrating ConvNet and Transformer for Mobile Application",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.15369.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5828
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.16295",
      "authors": [
        {
          "_id": "67986cd6bdc99911a989b0a5",
          "name": "Weixin Liang",
          "hidden": false
        },
        {
          "_id": "67986cd6bdc99911a989b0a6",
          "name": "Junhong Shen",
          "hidden": false
        },
        {
          "_id": "67986cd6bdc99911a989b0a7",
          "name": "Genghan Zhang",
          "hidden": false
        },
        {
          "_id": "67986cd6bdc99911a989b0a8",
          "name": "Ning Dong",
          "hidden": false
        },
        {
          "_id": "67986cd6bdc99911a989b0a9",
          "name": "Luke Zettlemoyer",
          "hidden": false
        },
        {
          "_id": "67986cd6bdc99911a989b0aa",
          "name": "Lili Yu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-27T18:35:05.000Z",
      "title": "Mixture-of-Mamba: モダルティー에 대한 희소성을 가진 다 모델 상태 공간 모델을 강화하는 방법",
      "summary": "ステートスペースモデル（SSMs）는 Transformers를 효율적으로 대체하기 위한 시퀀스 모델링의 새로운 방법론으로 등장하지만, 각 모델의 고유한 특성을 활용할 수 없기 때문에, 다중 모델 학습에서의 성능이 제한되어 있습니다. 본 논문에서는, 각 모델의 고유한 특성을 활용하기 위해 새로운 SSM 아키텍처인 \"Mixture-of-Mamba\"를 제안합니다. 이 아키텍처는 Mixture-of-Transformers(W. Liang et al. arXiv:2411.04996; 2024)에 기반하여, SSM에 각 모델의 고유한 특성의 이점을 확장하고, 계산 효율성을 유지하는 것을 목표로 합니다. Mixture-of-Mamba는 Transfusion(교차된 텍스트와 연속 이미지 토큰), Chameleon(교차된 텍스트와 이진 이미지 토큰), 그리고 음성을 포함하는 3 모델 프레임워크의 3가지 다중 모델 학습 설정을 평가했습니다. Mixture-of-Mamba는 초기 학습 단계에서 동일한 손실값을 달성하고, 크게 계산 비용 감소를 확인했습니다. Transfusion 설정에서, 1.4B 규모로 34.76%의 학습 FLOP을 사용하여 유사한 이미지 손실을 달성했습니다. Chameleon 설정에서, 1.4B 규모로 42.50%의 FLOP을 사용하여 유사한 이미지 손실을 달성했으며, 65.40%의 FLOP을 사용하여 유사한 텍스트 손실을 달성했습니다. 3 모델 설정에서, 1.4B 규모로 24.80%의 FLOP을 사용하여 음성 손실을 달성했습니다. 이 결과는 각 모델의 고유한 특성을 효과적인 설계 원칙으로, Transformers를 SSM으로 확장하고, 다중 모델 학습의 새로운 벤치마크를 설정하는 데 기여합니다. 코드는 https://github.com/Weixin-Liang/Mixture-of-Mamba에서 접근할 수 있습니다.",
      "upvotes": 1,
      "discussionId": "67986cd7bdc99911a989b0ea"
    },
    "publishedAt": "2025-01-28T00:36:31.841Z",
    "title": "Mixture-of-Mamba: Enhancing Multi-Modal State-Space Models with Modality-Aware Sparsity",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.16295.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5828
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.14912",
      "authors": [
        {
          "_id": "67986d764fccd4b95149db0b",
          "name": "Juan Ramirez",
          "hidden": false
        },
        {
          "_id": "67986d764fccd4b95149db0c",
          "name": "Ignacio Hounie",
          "hidden": false
        },
        {
          "_id": "67986d764fccd4b95149db0d",
          "name": "Juan Elenter",
          "hidden": false
        },
        {
          "_id": "67986d764fccd4b95149db0e",
          "name": "Jose Gallego-Posada",
          "hidden": false
        },
        {
          "_id": "67986d764fccd4b95149db0f",
          "name": "Meraj Hashemizadeh",
          "hidden": false
        },
        {
          "_id": "67986d764fccd4b95149db10",
          "name": "Alejandro Ribeiro",
          "hidden": false
        },
        {
          "_id": "67986d764fccd4b95149db11",
          "name": "Simon Lacoste-Julien",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-24T20:39:38.000Z",
      "title": "Feasible Learning\n\n이것은 실용적인 학습의 의미입니다.",
      "summary": "Feasible Learning (FL)를 통해 샘플 중심적인 학습 패러다임에 대해 소개합니다. 이 패러다임에서 모델은 각 훈련 샘플의 손실을 제한하는 가능성 문제를 해결하여 훈련됩니다. 일반적인 경험 리스크 최소화 (ERM) 프레임워크와 비교하여, ERM는 평균적인 성능을 최적화하고 있지만, FL은 모든 개별 데이터 포인트에 만족하는 성능을 요구합니다. 지정된 성능 스로프를 만족하는 모델은 FL의 정당한 해답으로 인정되어, 최적화 알고리즘의 선택과 동적이 결과의 해의 특성을 형성하는 중요한 역할을 합니다. 특히, 실제 훈련 중 각 샘플의 중요성을 동적으로 재평가하는 원칙에 대응하는 접근 방식을 연구합니다. 최소 정규의 스ラック 변수를 포함하는 FL의 예外을 도입하여, 실제 설정에서 유의한 스로프의 설정에 대한挑戦를 해결합니다. 이미지 분류, 나이 예측, 대규모 언어 모델의 선호 최적화를 포함한 실험적 분석은, ERM에 비해 평균적인 성능에 약간의 영향을 미치나, FL에 의해 훈련된 모델이 데이터로부터 학습하고, タイルバイエクシズ를 개선하는 것을 보여주며, FL의 장점을 입증합니다.",
      "upvotes": 0,
      "discussionId": "67986d784fccd4b95149db6b"
    },
    "publishedAt": "2025-01-28T00:39:11.423Z",
    "title": "Feasible Learning",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.14912.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5828
    },
    "isAuthorParticipating": false
  }
]