[
  {
    "paper": {
      "id": "2501.15368",
      "authors": [
        {
          "_id": "67986c6822990ae89bb71fb9",
          "name": "Yadong Li",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fba",
          "name": "Jun Liu",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fbb",
          "name": "Tao Zhang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fbc",
          "name": "Tao Zhang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fbd",
          "name": "Song Chen",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fbe",
          "name": "Tianpeng Li",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fbf",
          "name": "Zehuan Li",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fc0",
          "name": "Lijun Liu",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fc1",
          "name": "Lingfeng Ming",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fc2",
          "name": "Guosheng Dong",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fc3",
          "name": "Da Pan",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fc4",
          "name": "Chong Li",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fc5",
          "name": "Yuanbo Fang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fc6",
          "name": "Dongdong Kuang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fc7",
          "name": "Mingrui Wang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fc8",
          "name": "Chenglin Zhu",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fc9",
          "name": "Youwei Zhang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fca",
          "name": "Hongyu Guo",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fcb",
          "name": "Fengyu Zhang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fcc",
          "name": "Yuran Wang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fcd",
          "name": "Bowen Ding",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fce",
          "name": "Wei Song",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fcf",
          "name": "Xu Li",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fd0",
          "name": "Yuqi Huo",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fd1",
          "name": "Zheng Liang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fd2",
          "name": "Shusen Zhang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fd3",
          "name": "Xin Wu",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fd4",
          "name": "Shuai Zhao",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fd5",
          "name": "Linchu Xiong",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fd6",
          "name": "Yozhen Wu",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fd7",
          "name": "Jiahui Ye",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fd8",
          "name": "Wenhao Lu",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fd9",
          "name": "Bowen Li",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fda",
          "name": "Yan Zhang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fdb",
          "name": "Yaqi Zhou",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fdc",
          "name": "Xin Chen",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fdd",
          "name": "Lei Su",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fde",
          "name": "Hongda Zhang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fdf",
          "name": "Fuzhong Chen",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fe0",
          "name": "Xuezhen Dong",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fe1",
          "name": "Na Nie",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fe2",
          "name": "Zhiying Wu",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fe3",
          "name": "Bin Xiao",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fe4",
          "name": "Ting Li",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fe5",
          "name": "Shunya Dang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fe6",
          "name": "Ping Zhang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fe7",
          "name": "Yijia Sun",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fe8",
          "name": "Jincheng Wu",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fe9",
          "name": "Jinjie Yang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fea",
          "name": "Xionghai Lin",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71feb",
          "name": "Zhi Ma",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fec",
          "name": "Kegeng Wu",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fed",
          "name": "Jia li",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fee",
          "name": "Aiyuan Yang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fef",
          "name": "Hui Liu",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71ff0",
          "name": "Jianqiang Zhang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71ff1",
          "name": "Xiaoxi Chen",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71ff2",
          "name": "Guangwei Ai",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71ff3",
          "name": "Wentao Zhang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71ff4",
          "name": "Yicong Chen",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71ff5",
          "name": "Xiaoqin Huang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71ff6",
          "name": "Kun Li",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71ff7",
          "name": "Wenjing Luo",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71ff8",
          "name": "Yifei Duan",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71ff9",
          "name": "Lingling Zhu",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71ffa",
          "name": "Ran Xiao",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71ffb",
          "name": "Zhe Su",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71ffc",
          "name": "Jiani Pu",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71ffd",
          "name": "Dian Wang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71ffe",
          "name": "Xu Jia",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fff",
          "name": "Tianyu Zhang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb72000",
          "name": "Mengyu Ai",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb72001",
          "name": "Mang Wang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb72002",
          "name": "Yujing Qiao",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb72003",
          "name": "Lei Zhang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb72004",
          "name": "Yanjun Shen",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb72005",
          "name": "Fan Yang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb72006",
          "name": "Miao Zhen",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb72007",
          "name": "Yijie Zhou",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb72008",
          "name": "Mingyang Chen",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb72009",
          "name": "Fei Li",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb7200a",
          "name": "Chenzheng Zhu",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb7200b",
          "name": "Keer Lu",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb7200c",
          "name": "Yaqi Zhao",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb7200d",
          "name": "Hao Liang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb7200e",
          "name": "Youquan Li",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb7200f",
          "name": "Yanzhao Qin",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb72010",
          "name": "Linzhuang Sun",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb72011",
          "name": "Jianhua Xu",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb72012",
          "name": "Haoze Sun",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb72013",
          "name": "Mingan Lin",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb72014",
          "name": "Zenan Zhou",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb72015",
          "name": "Weipeng Chen",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-26T02:19:03.000Z",
      "title": "Baichuan-Omni-1.5 기술보고서\n\n(请注意，虽然您要求不添加任何解释或额外的文本，但为了确保翻译的准确性和专业性，我将提供一个完整的翻译，不包含任何额外的解释或文本。)",
      "summary": "Baichuan-Omni-1.5는 다양한 모달의 이해 능력을 가지고 있으며, 추가적으로 오디오 생성 능력도 제공됩니다. 모델의 기능을 잃지 않고, 다양한 모달 간에 순조롭게 상호작용을 실현하기 위해 3가지 중요한 측면을 우선적으로 최적화했습니다. 먼저, 다모달 데이터의 콘텐츠 클리닝 및 합성 파이프라인을 구축하여 약 500B의 고품질 데이터(텍스트, 오디오, 비전)를 획득했습니다. 다음으로, 오디오 토크나이저(Baichuan-Audio-Tokenizer)를 설계하여 오디오에서 의미적 및 음향 정보를 추출하고, MLLM과의 무간차이 없이 기능 개선을 실현했습니다. 마지막으로, 다단계 학습 전략을 설계하여 단계적으로 다모달의 어레이멘드와 다 태스크의 최종 훈련을 통합하여 모든 모달 간에 효과적인 심플러젝스를 보장했습니다. Baichuan-Omni-1.5는 현대 모델(GPT4o-mini, MiniCPM-o 2.6 등)과 비교하여 다양한 모달의 세부 기능들을 가지고 있습니다. 특히, 다양한 다모달 의료 벤치마크에서 Qwen2-VL-72B와 비교적인 결과를 얻었습니다.",
      "upvotes": 18,
      "discussionId": "67986c6b22990ae89bb720aa"
    },
    "publishedAt": "2025-01-28T00:34:49.721Z",
    "title": "Baichuan-Omni-1.5 Technical Report",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.15368.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5828
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.15383",
      "authors": [
        {
          "_id": "67986c83b5e71350993d28eb",
          "name": "An Yang",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28ec",
          "name": "Bowen Yu",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28ed",
          "name": "Chengyuan Li",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28ee",
          "name": "Dayiheng Liu",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28ef",
          "name": "Fei Huang",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28f0",
          "name": "Haoyan Huang",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28f1",
          "name": "Jiandong Jiang",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28f2",
          "name": "Jianhong Tu",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28f3",
          "name": "Jianwei Zhang",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28f4",
          "name": "Jingren Zhou",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28f5",
          "name": "Junyang Lin",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28f6",
          "name": "Kai Dang",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28f7",
          "name": "Kexin Yang",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28f8",
          "name": "Le Yu",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28f9",
          "name": "Mei Li",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28fa",
          "name": "Minmin Sun",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28fb",
          "name": "Qin Zhu",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28fc",
          "name": "Rui Men",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28fd",
          "name": "Tao He",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28fe",
          "name": "Weijia Xu",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28ff",
          "name": "Wenbiao Yin",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d2900",
          "name": "Wenyuan Yu",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d2901",
          "name": "Xiafei Qiu",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d2902",
          "name": "Xingzhang Ren",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d2903",
          "name": "Xinlong Yang",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d2904",
          "name": "Yong Li",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d2905",
          "name": "Zhiying Xu",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d2906",
          "name": "Zipeng Zhang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-26T03:47:25.000Z",
      "title": "Qwen2.5-1M 기술보고서\n\n(注意：이 번역은 단순히 영어 텍스트를 한국어로 번역한 것입니다. 모든 내용이 정확한 번역이거나 기술적 측면에서 정확한 내용을 전달하는 것은 보장되지 않습니다.)",
      "summary": "Qwen2.5-1M 모델 시리즈를 소개합니다. 이 모델 시리즈는 1백만 토큰의 컨텍스트 길이를 확장합니다. 이전의 128K 버전에 비해, 긴 컨텍스트 처리 능력을 크게 향상시켰습니다. 긴 데이터 합성, 고급 프로토콜 훈련, 다단계 서브젝트 제어 최적화 등 주요 기술로 긴 컨텍스트 성능을 효과적으로 향상시키고 훈련 비용 감소를 목표로 합니다.\n\n더 많은 사용자 기반에서 긴 컨텍스트 모델의 활용을 촉진하기 위해, 추론 프레임워크를 제공하여 오픈소스화 합니다. 이 프레임워크는 추가 훈련 없이도 모델의 컨텍스트 길이를 최소 4배 이상 확장할 수 있는 긴 컨텍스트 확장 메소드를 포함합니다. 추론 비용 감소를 위해, 스パ르스 어텐션 메소드와 쉼표 기반 프리필링 최적화를 구현하고, 스파르스 정확화 메소드도 구현합니다. 또한 추론 엔진 최적화에 대해 상세히 설명하고, 커널 최적화, 파이프라인 병렬화, 스케줄링 최적화 등 전체 추론 성능을 크게 향상시킵니다.\n\n이 추론 프레임워크를 사용하면 1백만 토큰의 컨텍스트 상황에서는 3배에서 7배의 프리필링 속도 업그레이드 가능합니다. 이 프레임워크는 오픈소스 모델을 사용하여 긴 컨텍스트 처리의 애플리케이션 개발에 효율적이고 강력한 해결책을 제공합니다.\n\n현재, Qwen2.5-1M 시리즈는 오픈소스 모델인 Qwen2.5-7B-Instruct-1M, Qwen2.5-14B-Instruct-1M, 그리고 API에 접근 가능한 모델인 Qwen2.5-Turbo를 포함합니다. 평가에 따르면, Qwen2.5-1M 모델은 긴 컨텍스트 태스크에서 크게 향상되었으며, 짧은 컨텍스트 시나리오에서의 성능을 희생하지 않습니다. 특히, Qwen2.5-14B-Instruct-1M 모델은 긴 컨텍스트 태스크에서 GPT-4o-mini를 크게 초과하며, 8배의 긴 컨텍스트를 지원합니다.",
      "upvotes": 7,
      "discussionId": "67986c84b5e71350993d2974"
    },
    "publishedAt": "2025-01-28T00:35:46.871Z",
    "title": "Qwen2.5-1M Technical Report",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.15383.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5828
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.15570",
      "authors": [
        {
          "_id": "679843ae7d7b7f8196c61ab7",
          "name": "Lin Yueyu",
          "hidden": false
        },
        {
          "_id": "679843ae7d7b7f8196c61ab8",
          "name": "Li Zhiyuan",
          "hidden": false
        },
        {
          "_id": "679843ae7d7b7f8196c61ab9",
          "name": "Peter Yue",
          "hidden": false
        },
        {
          "_id": "679843ae7d7b7f8196c61aba",
          "user": {
            "_id": "6176b32847ee6431f632981e",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6176b32847ee6431f632981e/02rZ_oLAI0Ll6Y6be7Q9F.jpeg",
            "isPro": false,
            "fullname": "IvanD",
            "user": "xiaol",
            "type": "user"
          },
          "name": "Liu Xiao",
          "status": "extracted_confirmed",
          "statusLastChangedAt": "2025-01-28T02:44:02.658Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-26T15:56:56.000Z",
      "title": "ARWKV: 사전 학습이 필요하지 않음, Transformer에서 유래된 RNN-Attention 기반의 언어 모델",
      "summary": "이제까지 알려진 것처럼, 다헤드 아키텍처에서 하이브리드 2차원과 3차원 어텐션 모델은 Transformer나 Linear RNN 모델을 초월하고 있습니다. 이러한 연구들은 주로 KV 복잡성의 감소와 효율 향상에 초점을 맞추었습니다. 더 나은 표현력을 위해 Qwen 2.5에서 훈련된, 기본적인 RWKV-7 어텐션 기반 모델 시리즈를 소개합니다. 이 모델들은 RNN의 표현력을 높일 수 있으며, Transformer보다 상태 추적 능력도 나타냅니다. QRWK 32B는 RWKV-6 아키텍처를 기반으로, 16 도레이브의 AMD MI300X GPU를 사용하여 지식 처리 시간을 8시간에 제한하여 Qwen 2.5의 성능을 유지하도록 설계되었습니다. 실제로 훈련 과정에서 사용할 수 있는 LLM은 무엇인지, 큰 LLM에서 작은 LLM까지의 지식 전파를 가능하게 하는 과정을 설명하고, 강력한 기초 모델 구축에 대한 피드백을 공유합니다. 이것은 계속해서 업데이트되는 진행 중의 연구입니다. 모델 체크포인트와 소스 코드는 아래 URL에서 사용 가능합니다.\n\nhttps://github.com/yynil/RWKVInside\nhttps://huggingface.co/RWKV-Red-Team/ARWKV-7B-Preview-0.1",
      "upvotes": 3,
      "discussionId": "679843af7d7b7f8196c61b21"
    },
    "publishedAt": "2025-01-28T03:02:56.062Z",
    "title": "ARWKV: Pretrain is not what we need, an RNN-Attention-Based Language Model Born from Transformer",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.15570.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6176b32847ee6431f632981e",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6176b32847ee6431f632981e/02rZ_oLAI0Ll6Y6be7Q9F.jpeg",
      "fullname": "IvanD",
      "name": "xiaol",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 81
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2501.16142",
      "authors": [
        {
          "_id": "67986cbc7dbf69e4e38539b7",
          "name": "Scott Fujimoto",
          "hidden": false
        },
        {
          "_id": "67986cbc7dbf69e4e38539b8",
          "name": "Pierluca D'Oro",
          "hidden": false
        },
        {
          "_id": "67986cbc7dbf69e4e38539b9",
          "name": "Amy Zhang",
          "hidden": false
        },
        {
          "_id": "67986cbc7dbf69e4e38539ba",
          "name": "Yuandong Tian",
          "hidden": false
        },
        {
          "_id": "67986cbc7dbf69e4e38539bb",
          "name": "Michael Rabbat",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-27T15:36:37.000Z",
      "title": "일반적인 용어로 모델 없이 재강化学습 연구",
      "summary": "강화학습(RL)은 근사뿐만 아니라 문제 해결의 프레임워크를 제공함을 약속하고 있습니다. 실용적으로는, RL 알고리즘은 특정한 벤치마크에 적합하며, 조정된 초 파라미터와 알고리즘의 선택에 의존합니다. 최근, 강력한 모델 기반의 RL 메소드는 복잡성과 실행 시간의 확장에 따라, 여러 벤치마크에서 놀라운 일반적인 결과를 보여주고 있지만, 이는 광범위한 적용성을 제한하고 있습니다. 본 논문에서는 광범위한 도메인 및 문제 설정을 다루는 모델 없는 심층 RL 알고리즘을 하나 찾도록 시도합니다. 이를 달성하기 위해, 모델 기반의 표현을 활용하고, 모델 기반의 RL에서 사용될 더 밀접한 태스크 객체를 활용하면서, 계획이나 계산 기반의 트래지렉트에 관련된 비용을 피하기 위해, 가치 함수를 근사 선형화합니다. 우리 알고리즘, MR.Q는 하나의 초 파라미터 세트로 많은 일반적인 RL 벤치마크에서 평가되며, 도메인专用의 베이스라인과 일반적인 베이스라인과의 비교에서 경쟁적인 성능을 보여주고, 일반용의 모델 없는 심층 RL 알고리즘의 구축에 대한 구체적인 단계를 제공합니다.",
      "upvotes": 2,
      "discussionId": "67986cbf7dbf69e4e3853a89"
    },
    "publishedAt": "2025-01-28T00:36:09.186Z",
    "title": "Towards General-Purpose Model-Free Reinforcement Learning",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.16142.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5828
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.15369",
      "authors": [
        {
          "_id": "6798706dabdc35456a92212d",
          "name": "Chuanyang Zheng",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-26T02:34:58.000Z",
      "title": "iFormer: 모바일 앱에 대한 ConvNet과 Transformer의 통합",
      "summary": "이곳에서는, 모바일 앱에서 지연과 정확도를 최적화하기 위한 새로운 모바일 하이브리드 비전 네트워크의 가족인 \"iFormer\"을 소개합니다. iFormer은, 고속의 지역적 표현 능력과 효율적인 글로벌 모델링 능력을 효과적으로 통합하고 있습니다. 지역적 상호작용은, 표준의 컨볼루션 네트워크(ConvNeXt)를 변형하여, 더 가벼운 모바일 네트워크를 설계할 수 있습니다. 새로운 모바일 모델링 어텐션은, MHA의 메모리 부담을 줄이고, 효율적인 모델링 구조를 사용하여 동적인 글로벌 표현 능력을 향상시킬 수 있습니다. 상세한 실험을 수행하고, iFormer은 현재의 가벼운 네트워크를 초과하는 다양한 태스크에서 뛰어난 성능을 나타냅니다. 특히, ImageNet-1k에서 Top-1 정확도가 80.4%를 달성하며, iPhone 13에서 지연이 1.10ms입니다. 또한, 유사한 지연 제약 아래 최근 제안된 MobileNetV4를 초과하고, COCO 물체 검출, 인스턴스 분할, ADE20k 표기 분할 등 하위 태스크에서 뚜렷한 향상을 나타내며, 고해상도 입력을 사용할 때도 모바일 장치에서 낮은 지연을 유지합니다.",
      "upvotes": 1,
      "discussionId": "6798706eabdc35456a92215a"
    },
    "publishedAt": "2025-01-28T00:51:51.263Z",
    "title": "iFormer: Integrating ConvNet and Transformer for Mobile Application",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.15369.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5828
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.16295",
      "authors": [
        {
          "_id": "67986cd6bdc99911a989b0a5",
          "name": "Weixin Liang",
          "hidden": false
        },
        {
          "_id": "67986cd6bdc99911a989b0a6",
          "name": "Junhong Shen",
          "hidden": false
        },
        {
          "_id": "67986cd6bdc99911a989b0a7",
          "name": "Genghan Zhang",
          "hidden": false
        },
        {
          "_id": "67986cd6bdc99911a989b0a8",
          "name": "Ning Dong",
          "hidden": false
        },
        {
          "_id": "67986cd6bdc99911a989b0a9",
          "name": "Luke Zettlemoyer",
          "hidden": false
        },
        {
          "_id": "67986cd6bdc99911a989b0aa",
          "name": "Lili Yu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-27T18:35:05.000Z",
      "title": "Mixture-of-Mamba: 먄먄한 신호를 활용한 다모달 상태 공간 모델의 확장\n\n(Note: The original text seems to be a title or a heading, and the translation is provided as is, maintaining the exact structure and meaning of the original text.)",
      "summary": "ステートスペースモデル（SSMs）는 Transformers에 대한 효율적인 대체로 등장하였으나, 각 모델의 특성을 활용할 수 없기 때문에 다 모델 사전 학습의 성능에 한계가 있습니다. 여기서는 모델별 숨겨진 신호를 도입하는 새로운 SSM 아키텍처인 Mixture-of-Mamba를 제안합니다. 이 방법은 Mamba 블록의 모델별 파라미터화로 패턴적稀疏성을 도입합니다. Mixture-of-Transformers（W. Liang et al. arXiv:2411.04996; 2024）에 기초하여, SSM에서 모델별 숨겨진 신호의 이점을 확장하고 계산적 효율성을 유지합니다. Mixture-of-Mamba는 Transfusion（간접한 텍스트와 연속된 이미지 토큰과 디퓨전 손실）、Chameleon（간접한 텍스트와 이산한 이미지 토큰）、언어를 포함한 확장된 세 모델 프레임워크의 세 다 모델 사전 학습 설정을 평가합니다. Mixture-of-Mamba는 동일한 손실값을 초기 훈련 단계에서 달성하며, 계산 비용의 절감에 크게 기여합니다. Transfusion 설정에서 1.4B 스케일로 34.76%의 훈련 FLOP을 사용하여 등가한 이미지 손실을 달성합니다. Chameleon 설정에서 1.4B 스케일로 42.50%의 FLOP으로 유사한 이미지 손실, 65.40%의 FLOP으로 유사한 텍스트 손실을 달성합니다. 세 모델 설정에서 1.4B 스케일로 24.80%의 FLOP으로 언어 손실을 달성합니다. Ablation Study에서, 解釋을 수행하고, 공통의 解釈이 개인적인 변경보다 큰 효과를 보였습니다. 이러한 결과는 모델별 숨겨진 신호를 효과적인 설계 원리로, Transformers에서 SSM으로 영향을 확장하고, 다 모델 사전 학습의 새로운 벤치마크를 설정합니다. 코드는 https://github.com/Weixin-Liang/Mixture-of-Mamba에서 접근할 수 있습니다.",
      "upvotes": 1,
      "discussionId": "67986cd7bdc99911a989b0ea"
    },
    "publishedAt": "2025-01-28T00:36:31.841Z",
    "title": "Mixture-of-Mamba: Enhancing Multi-Modal State-Space Models with Modality-Aware Sparsity",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.16295.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5828
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.14912",
      "authors": [
        {
          "_id": "67986d764fccd4b95149db0b",
          "name": "Juan Ramirez",
          "hidden": false
        },
        {
          "_id": "67986d764fccd4b95149db0c",
          "name": "Ignacio Hounie",
          "hidden": false
        },
        {
          "_id": "67986d764fccd4b95149db0d",
          "name": "Juan Elenter",
          "hidden": false
        },
        {
          "_id": "67986d764fccd4b95149db0e",
          "name": "Jose Gallego-Posada",
          "hidden": false
        },
        {
          "_id": "67986d764fccd4b95149db0f",
          "name": "Meraj Hashemizadeh",
          "hidden": false
        },
        {
          "_id": "67986d764fccd4b95149db10",
          "name": "Alejandro Ribeiro",
          "hidden": false
        },
        {
          "_id": "67986d764fccd4b95149db11",
          "name": "Simon Lacoste-Julien",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-24T20:39:38.000Z",
      "title": "Feasible Learning\n\n이 텍스트는 이미 한국어로 되어있기 때문에, 번역이 필요하지 않습니다.",
      "summary": "Feasible Learning (FL)를 소개합니다. FL는 샘플 중심적인 학습 패러다임으로, 각 훈련 샘플의 손실을 제한하는 가능성 문제를 해결하면서 훈련됩니다. 일반적인 Empirical Risk Minimization (ERM) 프레임워크와 비교하여, ERM는 평균적인 성능을 최적화하지만, FL은 각 데이터 포인트마다如此程度의 만족하는 성능을 요구합니다. 지정된 성능 시퀀스를 만족하는 모델은 FL의 정당한 해로 인정되며, 최적화 알고리즘의 선택과 동적은 결과적으로 얻은 해의 특성을 형성하는 중요한 역할을 합니다. 특히, 실제 문제의 해결에 앞서, 학습 중 각각의 샘플의 중요성을 동적으로 재평가하기 위한 주관-관점적인 접근을 연구하고 있습니다. 실제 문제의 해결에 앞서, 의미있는 시퀀스를 설정하는 어려움을 해결하기 위해, 최소의 널의 스lack 변수를 포함하는 FL의 완화를 도입합니다. 이미지 분류, 나이 회귀, 대규모 언어 모델의 선호 최적화를 포함하는 실험 분석에서, FL로 훈련된 모델은 ERM과 비교하여 평균적인 성능에 더 큰 영향을 미치지만, 데이터로부터 학습하면서도 테일바이어스를 개선한 성능을 나타냅니다.",
      "upvotes": 0,
      "discussionId": "67986d784fccd4b95149db6b"
    },
    "publishedAt": "2025-01-28T00:39:11.423Z",
    "title": "Feasible Learning",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.14912.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5828
    },
    "isAuthorParticipating": false
  }
]