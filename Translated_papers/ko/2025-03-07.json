[
  {
    "paper": {
      "id": "2503.04625",
      "authors": [
        {
          "_id": "67ca670d3e81e3344dc4c2d9",
          "user": {
            "_id": "65294b334d7cf551ac50d6a6",
            "avatarUrl": "/avatars/75d21e20b711b871616ef3850bb900b7.svg",
            "isPro": false,
            "fullname": "ChengpengLi",
            "user": "ChengpengLi",
            "type": "user"
          },
          "name": "Chengpeng Li",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-07T09:12:37.350Z",
          "hidden": false
        },
        {
          "_id": "67ca670d3e81e3344dc4c2da",
          "user": {
            "_id": "5f8946925d083370c711f296",
            "avatarUrl": "/avatars/14246aae3b1f8b7ad050f8ff2c8b260e.svg",
            "isPro": false,
            "fullname": "Mingfeng Xue",
            "user": "mingfengxue",
            "type": "user"
          },
          "name": "Mingfeng Xue",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-07T09:12:28.354Z",
          "hidden": false
        },
        {
          "_id": "67ca670d3e81e3344dc4c2db",
          "user": {
            "_id": "64704e973601bb7b06643e98",
            "avatarUrl": "/avatars/52e51f4d1be6769e4397b8be2799cf32.svg",
            "isPro": false,
            "fullname": "Zhang",
            "user": "Zhenru",
            "type": "user"
          },
          "name": "Zhenru Zhang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-07T09:12:48.194Z",
          "hidden": false
        },
        {
          "_id": "67ca670d3e81e3344dc4c2dc",
          "user": {
            "_id": "646df403ad20c6fa4f30b7ec",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/646df403ad20c6fa4f30b7ec/Q64-XMghOcBoo3itZDGYA.jpeg",
            "isPro": false,
            "fullname": "Jiaxi Yang",
            "user": "jx-yang",
            "type": "user"
          },
          "name": "Jiaxi Yang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-07T09:12:57.082Z",
          "hidden": false
        },
        {
          "_id": "67ca670d3e81e3344dc4c2dd",
          "user": {
            "_id": "64b93578ee257c3a4cfceed1",
            "avatarUrl": "/avatars/e6188562254f75a09b4048b800860016.svg",
            "isPro": false,
            "fullname": "Beichen Zhang",
            "user": "BeichenZhang",
            "type": "user"
          },
          "name": "Beichen Zhang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-07T09:13:11.641Z",
          "hidden": false
        },
        {
          "_id": "67ca670d3e81e3344dc4c2de",
          "name": "Xiang Wang",
          "hidden": false
        },
        {
          "_id": "67ca670d3e81e3344dc4c2df",
          "user": {
            "_id": "6583ab7983a9e1460c67d876",
            "avatarUrl": "/avatars/74400bc448c3f07e23a4cd53d68a6af7.svg",
            "isPro": false,
            "fullname": "bowen",
            "user": "bowenYu",
            "type": "user"
          },
          "name": "Bowen Yu",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-07T09:13:30.530Z",
          "hidden": false
        },
        {
          "_id": "67ca670d3e81e3344dc4c2e0",
          "user": {
            "_id": "61e4c4ca1ab24785ac11ba69",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/61e4c4ca1ab24785ac11ba69/1Q1zhhyGSJ9RJG9MzwxVv.jpeg",
            "isPro": false,
            "fullname": "Binyuan Hui",
            "user": "huybery",
            "type": "user"
          },
          "name": "Binyuan Hui",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-07T09:13:37.341Z",
          "hidden": false
        },
        {
          "_id": "67ca670d3e81e3344dc4c2e1",
          "user": {
            "_id": "620760a26e3b7210c2ff1943",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/620760a26e3b7210c2ff1943/VC-rKqimF6yxGESNVlPoR.jpeg",
            "isPro": false,
            "fullname": "Junyang Lin",
            "user": "JustinLin610",
            "type": "user"
          },
          "name": "Junyang Lin",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-07T09:13:44.084Z",
          "hidden": false
        },
        {
          "_id": "67ca670d3e81e3344dc4c2e2",
          "user": {
            "_id": "6434d4989bd5a84b5dd0b0f5",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6434d4989bd5a84b5dd0b0f5/0Elf9qbfG9Hkgypm9pTGm.jpeg",
            "isPro": false,
            "fullname": "Dayiheng Liu",
            "user": "Losin94",
            "type": "user"
          },
          "name": "Dayiheng Liu",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-07T09:13:52.711Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-03-06T17:11:51.000Z",
      "title": "Self-taught Reasoner, using tools.",
      "summary": "대논리 모형（LRMs）의 오픈 AI-o1이나 DeepSeek-R1은 긴 Chain-of-thought（CoT）의 활용로 복잡한 논리 임무에서 뛰어난 능력을 보여주고 있습니다. 그러나 이러한 모델들은 단순히 내부 논리 프로세스를 의존하여 훌륭한 대화와 부적절한 표현을 동반할 수 있습니다. 본 논문에서는 외부 도구를 통합한 긴 CoT 논리의 LLM인 START（Self-Taught Reasoner with Tools）를 소개하며, 외부 도구의 활용로 논리 능력이 크게 향상됩니다. 코드 실행을 통해 START는 복잡한 계산, 자동 검증, 다양한 방법의 탐색, 자동 디버깅을 수행할 수 있으며, LRM의 한계점을 해결합니다. START의 핵심적인 혁신은 자동 학습 프레임워크이며, 두 가지 주요 기술로 구성됩니다: 1）Hint-infer：인공적으로 설계된 힌트（예: 「그곳에 Python을 사용하는 건 좋은 생각이야」）을 논리 프로세스의 오류에 삽입하여 LRM이 외부 도구를 활용할 수 있는 능력을 자극하는 것을 보여줍니다. Hint-infer는 간단하고 효과적인 순차 테스트 시간 스케일링 방법 중 하나입니다; 2）Hint Rejection Sampling Fine-Tuning（Hint-RFT）：Hint-infer와 RFT를 조합하여 Hint-infer로 생성된 LRM의 도구 호출에 의한 논리 프로세스를 점수, 필터링, 변경, 최종 튜닝을 수행합니다. 이 프레임워크를 통해 QwQ-32B 모델을 START에 최종 튜닝했습니다. 박사 수준의 과학 QA（GPQA）、경기 수준의 수학 벤치마크（AMC23, AIME24, AIME25）、경기 수준의 코드 벤치마크（LiveCodeBench）에서 정확도가 63.6%, 95.0%, 66.7%, 47.1%, 47.3%를 달성했습니다. 기본 QwQ-32B를 크게 초월하여 최신의 오픈 웨이트 모델 R1-Distill-Qwen-32B와 소유권 모델 o1-Preview의 성능과 동등한 성능을 달성했습니다.",
      "upvotes": 36,
      "discussionId": "67ca67103e81e3344dc4c366"
    },
    "publishedAt": "2025-03-06T22:35:47.725Z",
    "title": "START: Self-taught Reasoner with Tools",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.04625.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 6299
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2503.03803",
      "authors": [
        {
          "_id": "67ca874c3ac187dbbed924d6",
          "user": {
            "_id": "62b5777f593a2c49da69dc02",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1658152070753-62b5777f593a2c49da69dc02.jpeg",
            "isPro": false,
            "fullname": "Jingkang Yang",
            "user": "Jingkang",
            "type": "user"
          },
          "name": "Jingkang Yang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-03-07T09:09:32.949Z",
          "hidden": false
        },
        {
          "_id": "67ca874c3ac187dbbed924d7",
          "name": "Shuai Liu",
          "hidden": false
        },
        {
          "_id": "67ca874c3ac187dbbed924d8",
          "name": "Hongming Guo",
          "hidden": false
        },
        {
          "_id": "67ca874c3ac187dbbed924d9",
          "user": {
            "_id": "652965773a416e1f2173443b",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/652965773a416e1f2173443b/y9MB8YgHzbwCXAc4EI9T3.jpeg",
            "isPro": false,
            "fullname": "Yuhao Dong",
            "user": "THUdyh",
            "type": "user"
          },
          "name": "Yuhao Dong",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-07T09:15:21.671Z",
          "hidden": false
        },
        {
          "_id": "67ca874c3ac187dbbed924da",
          "name": "Xiamengwei Zhang",
          "hidden": false
        },
        {
          "_id": "67ca874c3ac187dbbed924db",
          "user": {
            "_id": "63f87c42b0ae1748524a9cfb",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63f87c42b0ae1748524a9cfb/I5ukv6iWoJVToWmcERmvx.jpeg",
            "isPro": false,
            "fullname": "Sicheng Zhang",
            "user": "fesvhtr",
            "type": "user"
          },
          "name": "Sicheng Zhang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-07T09:15:37.377Z",
          "hidden": false
        },
        {
          "_id": "67ca874c3ac187dbbed924dc",
          "user": {
            "_id": "62f113d3b58090c873d66481",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1659966415211-noauth.jpeg",
            "isPro": false,
            "fullname": "Pengyun Wang",
            "user": "Alarak",
            "type": "user"
          },
          "name": "Pengyun Wang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-07T09:15:44.290Z",
          "hidden": false
        },
        {
          "_id": "67ca874c3ac187dbbed924dd",
          "user": {
            "_id": "668eb3a1a2f3f9d5edf029eb",
            "avatarUrl": "/avatars/383636e449f5e48c790f428818dd6863.svg",
            "isPro": false,
            "fullname": "zhou zitang",
            "user": "Zzitang",
            "type": "user"
          },
          "name": "Zitang Zhou",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-07T09:15:56.178Z",
          "hidden": false
        },
        {
          "_id": "67ca874c3ac187dbbed924de",
          "user": {
            "_id": "63f886a99f87cc3e645c99a8",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63f886a99f87cc3e645c99a8/qwj16BrFaDjN0DPFsJ-6v.jpeg",
            "isPro": false,
            "fullname": "Binzhu Xie",
            "user": "Nicous",
            "type": "user"
          },
          "name": "Binzhu Xie",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-07T09:16:02.570Z",
          "hidden": false
        },
        {
          "_id": "67ca874c3ac187dbbed924df",
          "name": "Ziyue Wang",
          "hidden": false
        },
        {
          "_id": "67ca874c3ac187dbbed924e0",
          "name": "Bei Ouyang",
          "hidden": false
        },
        {
          "_id": "67ca874c3ac187dbbed924e1",
          "name": "Zhengyu Lin",
          "hidden": false
        },
        {
          "_id": "67ca874c3ac187dbbed924e2",
          "name": "Marco Cominelli",
          "hidden": false
        },
        {
          "_id": "67ca874c3ac187dbbed924e3",
          "user": {
            "_id": "652d06833b5997ed71ce5c46",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/xZTXEcnEogEmBm_ledJQr.jpeg",
            "isPro": false,
            "fullname": "Zhongang Cai",
            "user": "caizhongang",
            "type": "user"
          },
          "name": "Zhongang Cai",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-07T09:16:33.666Z",
          "hidden": false
        },
        {
          "_id": "67ca874c3ac187dbbed924e4",
          "user": {
            "_id": "62a993d80472c0b7f94027df",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62a993d80472c0b7f94027df/j5vp-IwLA2YBexylUHiQU.png",
            "isPro": false,
            "fullname": "Zhang Yuanhan",
            "user": "ZhangYuanhan",
            "type": "user"
          },
          "name": "Yuanhan Zhang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-07T09:16:45.989Z",
          "hidden": false
        },
        {
          "_id": "67ca874c3ac187dbbed924e5",
          "user": {
            "_id": "63565cc56d7fcf1bedb7d347",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63565cc56d7fcf1bedb7d347/XGcHP4VkO_oieA1gZ4IAX.jpeg",
            "isPro": false,
            "fullname": "Zhang Peiyuan",
            "user": "PY007",
            "type": "user"
          },
          "name": "Peiyuan Zhang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-07T09:16:57.532Z",
          "hidden": false
        },
        {
          "_id": "67ca874c3ac187dbbed924e6",
          "user": {
            "_id": "67443675924e80c3c8807b40",
            "avatarUrl": "/avatars/fb45422391e51d2ad641f09c8535653c.svg",
            "isPro": false,
            "fullname": "fangzhou HONG",
            "user": "h12345678",
            "type": "user"
          },
          "name": "Fangzhou Hong",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-07T09:17:05.845Z",
          "hidden": false
        },
        {
          "_id": "67ca874c3ac187dbbed924e7",
          "name": "Joerg Widmer",
          "hidden": false
        },
        {
          "_id": "67ca874c3ac187dbbed924e8",
          "name": "Francesco Gringoli",
          "hidden": false
        },
        {
          "_id": "67ca874c3ac187dbbed924e9",
          "name": "Lei Yang",
          "hidden": false
        },
        {
          "_id": "67ca874c3ac187dbbed924ea",
          "name": "Bo Li",
          "hidden": false
        },
        {
          "_id": "67ca874c3ac187dbbed924eb",
          "user": {
            "_id": "62ab1ac1d48b4d8b048a3473",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1656826685333-62ab1ac1d48b4d8b048a3473.png",
            "isPro": false,
            "fullname": "Ziwei Liu",
            "user": "liuziwei7",
            "type": "user"
          },
          "name": "Ziwei Liu",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-07T09:15:05.677Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-03-05T18:54:16.000Z",
      "title": "이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活アシスタントへの向け\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活アシスタントへ의 목표\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄 셈\n\n이거리生活을 도와줄 셈\n\nEgoLife: エゴモード의生活을 도와줄",
      "summary": "이 프로젝트는 エゴライフ와 AI プローブット フレーム를 사용하여 개발된 エゴセンティック 생활 보조기를 소개합니다. 이 보조기는 매일의 활동들을 카메라로 연속적으로 기록하고, AI グラス를 사용하여 다양한 エゴセンティック 비디오를 촬영하고, 3rd party의 시각을 반영한 비디오를 동시에 획득합니다. 이 연구에서 300시간의 エゴセンティック, 인터プレイヤル, 멀티 뷰, 멀티 모델의 일상 생활 데이터 세트와 エゴライフ 데이터 세트가 생성되었습니다. 이 데이터 세트를 활용하여, 매일의 생활에 의미 있는 도움을 제공하는 데 필요한 긴 컨텍스트, 생활 지향적인 질문응답 タスク シート, エゴライフ QA를 소개합니다. 구체적인 질문을 해결함으로써, 과거의 관련 사건을 기억하고, 건강 습관을 모니터링하고, 개인적인 추천을 제공할 수 있습니다. エゴビューティング 모델의 개발, 식별, 긴 컨텍ス트 질문의 답변에 대한 기술적 문제를 해결하기 위해, エゴバタール, エゴGPT와 エゴRAG의 통합 시스템을 소개합니다. エゴGPT는 エゴセンティック 데이터 세트를 사용하여 훈련된 オーマイン 모델で, エゴセンティック 비디오 이해에 가장 先端의 성능을 달성합니다. エゴRAG은 긴 컨텍ス트 질문을 답변하기 위한 검색 기반의 구성 요소입니다. 실험적 연구에서 그 기능 구조를 증명하고, 중요한 원인과 ボトルネック를 밝혀줍니다. 데이터 세트, 모델, 벤치마크를 공개하여, エゴセンティック AI 보조기의 발전을 촉진하는 것을 목표로 합니다.",
      "upvotes": 9,
      "discussionId": "67ca874f3ac187dbbed925cc",
      "projectPage": "https://egolife-ai.github.io/",
      "githubRepo": "https://github.com/EvolvingLMMs-Lab/EgoLife"
    },
    "publishedAt": "2025-03-07T00:44:13.546Z",
    "title": "EgoLife: Towards Egocentric Life Assistant",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.03803.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "62b5777f593a2c49da69dc02",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1658152070753-62b5777f593a2c49da69dc02.jpeg",
      "fullname": "Jingkang Yang",
      "name": "Jingkang",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 7
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2503.04598",
      "authors": [
        {
          "_id": "67ca69063a6e3e8656bcc1d2",
          "user": {
            "_id": "66335b9c95c5b79ebf306f30",
            "avatarUrl": "/avatars/d57784ee65cbef014360c9bac1ad4119.svg",
            "isPro": false,
            "fullname": "Zhijian Zhuo",
            "user": "BryceZhuo",
            "type": "user"
          },
          "name": "Zhijian Zhuo",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-07T09:27:08.401Z",
          "hidden": false
        },
        {
          "_id": "67ca69063a6e3e8656bcc1d3",
          "user": {
            "_id": "6371128eafbe42caa5a5222b",
            "avatarUrl": "/avatars/c3b2ab35949c38aa3dfb2657a1300aac.svg",
            "isPro": false,
            "fullname": "Yutao Zeng",
            "user": "Taoer",
            "type": "user"
          },
          "name": "Yutao Zeng",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-03-07T09:09:43.334Z",
          "hidden": false
        },
        {
          "_id": "67ca69063a6e3e8656bcc1d4",
          "name": "Ya Wang",
          "hidden": false
        },
        {
          "_id": "67ca69063a6e3e8656bcc1d5",
          "name": "Sijun Zhang",
          "hidden": false
        },
        {
          "_id": "67ca69063a6e3e8656bcc1d6",
          "name": "Jian Yang",
          "hidden": false
        },
        {
          "_id": "67ca69063a6e3e8656bcc1d7",
          "user": {
            "_id": "64648638351adef1a847a7ad",
            "avatarUrl": "/avatars/7518e058fcf81ee81a06c96e996531e9.svg",
            "isPro": false,
            "fullname": "Xiaoqing Li",
            "user": "LLIXQ",
            "type": "user"
          },
          "name": "Xiaoqing Li",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-07T09:26:45.058Z",
          "hidden": false
        },
        {
          "_id": "67ca69063a6e3e8656bcc1d8",
          "name": "Xun Zhou",
          "hidden": false
        },
        {
          "_id": "67ca69063a6e3e8656bcc1d9",
          "user": {
            "_id": "663a684d08778abaf0556df8",
            "avatarUrl": "/avatars/d95b517df5b80a8b42bac2b171604742.svg",
            "isPro": false,
            "fullname": "Majinwen",
            "user": "Breeze0417",
            "type": "user"
          },
          "name": "Jinwen Ma",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-07T09:27:23.639Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-03-06T16:40:48.000Z",
      "title": "HybridNorm: 안정적인, 낡은 오사마시운 오사마시운 Transformer 훈련에 대해, 하이브리드 노르마라이징을 통해",
      "summary": "Transformers는 광범위한 기계 학습 태스크에서 사실상의 아키텍처로 자리잡고 있으며, 특히 대규모 언어 모델(LLMs)에서도 그 효과가 높습니다. 뛰어난 성능을 초과하지 않지만, 깊은 Transformer 네트워크의 훈련에는 레이어 정규화의 위치에 대한 문제가 남아 있습니다. Pre-Norm 구조는 더 명확한 identity path를 가지고 훈련이 쉬워집니다. 그러나 Post-Norm에 비해 일반적으로 성능이 떨어집니다. 본 논문에서는 Pre-Norm과 Post-Norm의 장점을 통합하는 간단하고 효과적인 혼합 정규화 전략인 HybridNorm을 제안합니다. 특히, HybridNorm은 Attention 구조 내의 QKV 정규화를 사용하며, 각 Transformer 블록의 Feed-Forward Network(FFN)에서는 Post-Norm을 사용합니다. 이 설계는 훈련의 안정화와 성능의 향상을 동시에 달성하며, 특히 LLMs의 텍스트 생성 및 이해 분야에서 특히 효과적입니다. Dense와 Sparse 아키텍처의 두 가지 모두에서 상세한 실험을 수행하여, HybridNorm은 Pre-Norm과 Post-Norm을 비교하여 일관된 우수한 결과를 얻으며, 많은 벤치마크에서 최상위의 결과를 달성했습니다. 이러한 발견은 HybridNorm이 깊은 Transformer 모델의 훈련 및 성능 향상에 있어서 안정적이고 효과적인 방법으로서의 가능성에 대한 가능성을 보여주고 있습니다. %코드는 공개적으로 제공됩니다. 코드는 https://github.com/BryceZhuo/HybridNorm에서 사용 가능합니다.",
      "upvotes": 7,
      "discussionId": "67ca69073a6e3e8656bcc244",
      "projectPage": "https://github.com/BryceZhuo/HybridNorm",
      "githubRepo": "https://github.com/BryceZhuo/HybridNorm"
    },
    "publishedAt": "2025-03-06T23:04:06.421Z",
    "title": "HybridNorm: Towards Stable and Efficient Transformer Training via Hybrid Normalization",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/6371128eafbe42caa5a5222b/DB_sfuRG7M-k8w6UVTgXy.png",
      "https://cdn-uploads.huggingface.co/production/uploads/6371128eafbe42caa5a5222b/F0lAhIiju8M-0fKBaPATA.png",
      "https://cdn-uploads.huggingface.co/production/uploads/6371128eafbe42caa5a5222b/g_741Ez-YVcMK69EqCsPa.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.04598.png",
    "numComments": 4,
    "submittedBy": {
      "_id": "6371128eafbe42caa5a5222b",
      "avatarUrl": "/avatars/c3b2ab35949c38aa3dfb2657a1300aac.svg",
      "fullname": "Yutao Zeng",
      "name": "Taoer",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.20258",
      "authors": [
        {
          "_id": "67ca7b557436e6327ca877ff",
          "user": {
            "_id": "655efd24afee0e00788bb589",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/655efd24afee0e00788bb589/22guLxIWNybbJR3jI-c4w.jpeg",
            "isPro": false,
            "fullname": "Amr Mohamed",
            "user": "amr-mohamed",
            "type": "user"
          },
          "name": "Amr Mohamed",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-03-07T09:09:41.298Z",
          "hidden": false
        },
        {
          "_id": "67ca7b557436e6327ca87800",
          "user": {
            "_id": "67890323f8796231c857231e",
            "avatarUrl": "/avatars/f5ccd5186968d880fee9c36324a5f713.svg",
            "isPro": false,
            "fullname": "Mingmeng Geng",
            "user": "mgeng",
            "type": "user"
          },
          "name": "Mingmeng Geng",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-07T09:34:23.443Z",
          "hidden": false
        },
        {
          "_id": "67ca7b557436e6327ca87801",
          "name": "Michalis Vazirgiannis",
          "hidden": false
        },
        {
          "_id": "67ca7b557436e6327ca87802",
          "user": {
            "_id": "6087e598e2b7cc3a117b0dc5",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6087e598e2b7cc3a117b0dc5/Ctz_W-uo1gOQRBHXalD1P.png",
            "isPro": false,
            "fullname": "Guokan Shang",
            "user": "guokan-shang",
            "type": "user"
          },
          "name": "Guokan Shang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-03-07T09:09:38.933Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-27T16:46:23.000Z",
      "title": "LLM는 브래킷 텔레폰처럼, 반복적인 생성으로 정보가 왜곡되어 있습니다.",
      "summary": "대 언어 모델이 인터넷 콘텐츠에 대한 책임을 일시씩 지어나가는 가운데, 자신의 출력을 반복적으로 처리하는 영향에 대한 우려가 발생하고 있습니다. 인간의 연속적인 커뮤니케이션에서 '전화의 파손'의 효과를 참고하여, 본 연구는 LLM이 동일한 반복적인 생성에 의해 정보를 왜곡하는지 조사하고 있습니다. 번역에 기반한 실험을 통해, 왜곡은 시간이 지남에 따라 쌓이고, 언어의 선택과 연속의 복잡성에 영향을 받습니다. 그러나 악화는 피할 수 없지만, 전략적인 프롬프트 기술로 완화할 수 있습니다. 이러한 발견은 AI를 통한 정보 전파의 장기적 효과에 대한 논의에 기여하고, LLM을 통한 반복적인 작업 흐름에서 생성된 콘텐츠의 신뢰성에 대한 중요한 문제를 제기합니다.",
      "upvotes": 6,
      "discussionId": "67ca7b577436e6327ca878ec",
      "githubRepo": "https://github.com/amr-mohamedd/LLM-as-a-Broken-Telephone"
    },
    "publishedAt": "2025-03-06T23:56:18.841Z",
    "title": "LLM as a Broken Telephone: Iterative Generation Distorts Information",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.20258.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "655efd24afee0e00788bb589",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/655efd24afee0e00788bb589/22guLxIWNybbJR3jI-c4w.jpeg",
      "fullname": "Amr Mohamed",
      "name": "amr-mohamed",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 7
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2503.04094",
      "authors": [
        {
          "_id": "67ca7bcc06501013d727a5d7",
          "user": {
            "_id": "6658e1c8ce1b2838885b2d7f",
            "avatarUrl": "/avatars/8623555f14b62f40fd372da20cb59ccc.svg",
            "isPro": false,
            "fullname": "Seth Karten",
            "user": "milkkarten",
            "type": "user"
          },
          "name": "Seth Karten",
          "status": "extracted_confirmed",
          "statusLastChangedAt": "2025-03-07T06:07:26.564Z",
          "hidden": false
        },
        {
          "_id": "67ca7bcc06501013d727a5d8",
          "name": "Andy Luu Nguyen",
          "hidden": false
        },
        {
          "_id": "67ca7bcc06501013d727a5d9",
          "user": {
            "_id": "66749c510974bbc971139f6a",
            "avatarUrl": "/avatars/bfab9d8d8bc589bb9bd49925b76e04a4.svg",
            "isPro": false,
            "fullname": "Chi Jin",
            "user": "chijin",
            "type": "user"
          },
          "name": "Chi Jin",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-03-07T04:53:33.942Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-03-06T05:06:27.000Z",
      "title": "PokéChamp: エキスパートレベル의 미니맥스 언어 에이전트",
      "summary": "PokeChamp은 최소최대 에이전트 중 LLM를 포함하는 가장 작은 모델입니다. 일반적인 프레임워크를 기반으로 2인 플레이어의 대결에 적용되어 만들어졌으며, LLM의 일반적인 능력을 활용하여 최소최대 트리 탐색을 강화합니다. 구체적으로는 3개의 핵심 모듈을 대체하여 게임 플레이의 역사와 인간 지식에 기반하여 탐색 범위를 좁히고 부분 관측을 해결할 수 있습니다. 특히, 프레임워크는 추가적인 LLM 훈련이 필요하지 않습니다. PokeChamp는 Pokemon Showdown의 게임 포맷에서 평가됩니다. GPT-4o를 포터로 설정하면 최고의 LLM 기반 봇에 76%의 승률을, 가장 강력한 규칙 기반 봇에 84%의 승률을 달성하여 우수한 성능을 보입니다. 또한 8비트 파라미터의 오픈 소스 Llama 3.1 모델을 사용했을 때 GPT-4o를 포터로 설정한 Poke\\'ellmon을 초과하여 64%의 승률을 달성합니다. PokeChamp는 Pokemon Showdown 온라인 라더브에서 예측 1300-1500을 달성하여 인간 플레이어의 상위 30%-10%에 위치합니다. 또한 이 연구에서는 가장 큰 실제 플레이어의 Pokemonabteil 데이터베이스를 구축했으며, 300만 게임 이상과 50만 1300-1500의 매치가 포함됩니다. 이 데이터베이스를 기반으로 전투 벤치마크와 퍼즐을 설정하여 특정 전투 기술에 대한 평가 벤치마크와 퍼즐을 설정합니다. 또한 지역 게임 엔진에 중요한 업데이트를 제공합니다. 이 연구는 LLM 기술과 게임 이론 알고리즘을 일반적인 다 에이전트 문제에 대응하는 연구를 촉진하는 것을 희망합니다. 비디오, 코드, 데이터베이스는 아래 URL에서 사용 가능합니다. https://sites.google.com/view/pokechamp-llm",
      "upvotes": 5,
      "discussionId": "67ca7bcd06501013d727a668",
      "projectPage": "https://sites.google.com/view/pokechamp-llm",
      "githubRepo": "https://github.com/sethkarten/pokechamp"
    },
    "publishedAt": "2025-03-06T23:53:38.838Z",
    "title": "PokéChamp: an Expert-level Minimax Language Agent",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.04094.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 6299
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2503.04222",
      "authors": [
        {
          "_id": "67ca64cdd153739fa9b9dbe6",
          "user": {
            "_id": "64c9b0f28d2d187c24d1e6c1",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/1CPnAaB3gsupdpiNWaoDc.png",
            "isPro": false,
            "fullname": "ZiYi Yang",
            "user": "AALF",
            "type": "user"
          },
          "name": "Ziyi Yang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-03-07T09:09:46.287Z",
          "hidden": false
        },
        {
          "_id": "67ca64cdd153739fa9b9dbe7",
          "user": {
            "_id": "62ecbffd99112e99c5f7fded",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62ecbffd99112e99c5f7fded/U6iXAJbpm2vaC5qksEPiH.png",
            "isPro": false,
            "fullname": "Fanqi Wan",
            "user": "Wanfq",
            "type": "user"
          },
          "name": "Fanqi Wan",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-07T09:33:34.691Z",
          "hidden": false
        },
        {
          "_id": "67ca64cdd153739fa9b9dbe8",
          "user": {
            "_id": "62b6d20416ff90e6198301b6",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1656148456743-noauth.png",
            "isPro": false,
            "fullname": "Longguang Zhong",
            "user": "GGLS",
            "type": "user"
          },
          "name": "Longguang Zhong",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-07T09:33:41.092Z",
          "hidden": false
        },
        {
          "_id": "67ca64cdd153739fa9b9dbe9",
          "user": {
            "_id": "63b93e6921add32ac6190b5c",
            "avatarUrl": "/avatars/7aa6a94d48e7f7c2bc56f8734d6c4e3d.svg",
            "isPro": false,
            "fullname": "Canbin Huang",
            "user": "OnewayLab",
            "type": "user"
          },
          "name": "Canbin Huang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-07T09:33:47.458Z",
          "hidden": false
        },
        {
          "_id": "67ca64cdd153739fa9b9dbea",
          "name": "Guosheng Liang",
          "hidden": false
        },
        {
          "_id": "67ca64cdd153739fa9b9dbeb",
          "user": {
            "_id": "63b57d75bda8d44adf2ff3ff",
            "avatarUrl": "/avatars/8a387036758b2f7fc7d7529dea206669.svg",
            "isPro": false,
            "fullname": "Xiaojun Quan",
            "user": "passerqxj",
            "type": "user"
          },
          "name": "Xiaojun Quan",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-07T09:34:05.521Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-03-06T09:03:36.000Z",
      "title": "FuseChat-3.0: 선호 최적화와 다른 모델의 결합",
      "summary": "FuseChat-3.0는 다양한 소스 LLMs의 강점을 통합하기 위해 개발된 대형 언어 모델(LLMs) 시스템입니다. 소스 모델에는 강력한 Gemma-2-27B-it, Mistral-Large-Instruct-2407, Qwen-2.5-72B-Instruct, Llama-3.1-70B-Instruct가 포함됩니다. 타겟 모델에서는 주로 Llama-3.1-8B-Instruct, Gemma-2-9B-it, Qwen-2.5-7B-Instruct 등 3가지의 넓이 사용되고 있는 작은 버전을 중심으로 다루고 있습니다. 또한 Llama-3.2-3B-Instruct와 Llama-3.2-1B-Instruct 등 2가지의 초축 옵션도 포함됩니다. 이러한 소스 모델의 다양한 능력을 활용하기 위해, 각 태스크 및 분야에 맞는 특화된 데이터 구축 프로토콜을 개발했습니다. FuseChat-3.0의 훈련 파이프라인은 2개의 주요 단계로 구성됩니다: 1) 소프트 피드백(SFT)으로 타겟 모델과 소스 모델의 분포를 조정하고, 2) 직접 선호 최적화(DPO)로 여러 소스 LLMs의 선호를 적용하여 타겟 모델을 최적화합니다. 이러한 FuseChat-3.0 모델은 지시에 따라, 일반적인 지식, 수학, 코딩 등 다양한 태스크에서 상당한 성능 향상을 나타냅니다. 그림 1에 따르면, Llama-3.1-8B-Instruct를 타겟 모델로 설정할 때, 14개의 벤치마크의 평균적인 향상은 6.8점으로 나타났습니다. 또한, 지시에 따라 행동하는 벤치마크 AlpacaEval-2와 Arena-Hard에서 각각 37.1점과 30.1점의 놀라운 향상을 나타냅니다. 코드, 모델, 데이터 셋은 https://github.com/SLIT-AI/FuseChat-3.0에서 사용 가능합니다.",
      "upvotes": 5,
      "discussionId": "67ca64ced153739fa9b9dc1b",
      "projectPage": "https://slit-ai.github.io/FuseChat-3.0/",
      "githubRepo": "https://github.com/SLIT-AI/FuseChat-3.0"
    },
    "publishedAt": "2025-03-06T22:20:34.462Z",
    "title": "FuseChat-3.0: Preference Optimization Meets Heterogeneous Model Fusion",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/62ecbffd99112e99c5f7fded/nmr7w6NOioBYwMmNfezcf.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.04222.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "62ecbffd99112e99c5f7fded",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62ecbffd99112e99c5f7fded/U6iXAJbpm2vaC5qksEPiH.png",
      "fullname": "Fanqi Wan",
      "name": "Wanfq",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 29
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2503.04130",
      "authors": [
        {
          "_id": "67ca7baf6d5c2eafede56d35",
          "user": {
            "_id": "6449e5a3df4e6cb7eaefd2b8",
            "avatarUrl": "/avatars/a671cb507d5e02b238d8cd631e71649d.svg",
            "isPro": false,
            "fullname": "Jindong Jiang",
            "user": "jdps",
            "type": "user"
          },
          "name": "Jindong Jiang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-07T09:34:59.750Z",
          "hidden": false
        },
        {
          "_id": "67ca7baf6d5c2eafede56d36",
          "user": {
            "_id": "644570ba2d91b15b4c7f6311",
            "avatarUrl": "/avatars/d5e66012066d0c330b8f23718b1499d8.svg",
            "isPro": false,
            "fullname": "Xiuyu Li",
            "user": "xiuyul",
            "type": "user"
          },
          "name": "Xiuyu Li",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-07T09:35:06.739Z",
          "hidden": false
        },
        {
          "_id": "67ca7baf6d5c2eafede56d37",
          "user": {
            "_id": "650dac79b959b0e1d41d7378",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/650dac79b959b0e1d41d7378/mzbN0MFk3k8b94FQ40I7L.jpeg",
            "isPro": false,
            "fullname": "Zhijian Liu",
            "user": "zhijianliu",
            "type": "user"
          },
          "name": "Zhijian Liu",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-07T09:35:13.834Z",
          "hidden": false
        },
        {
          "_id": "67ca7baf6d5c2eafede56d38",
          "user": {
            "_id": "66d8b322cf789857d384e5c4",
            "avatarUrl": "/avatars/1276726b27d312f48e69f5ae982daa24.svg",
            "isPro": false,
            "fullname": "Muyang Li",
            "user": "MuyangLI",
            "type": "user"
          },
          "name": "Muyang Li",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-07T09:37:06.962Z",
          "hidden": false
        },
        {
          "_id": "67ca7baf6d5c2eafede56d39",
          "name": "Guo Chen",
          "hidden": false
        },
        {
          "_id": "67ca7baf6d5c2eafede56d3a",
          "user": {
            "_id": "672aae13b2f2dc21e18570e0",
            "avatarUrl": "/avatars/0253107a2116d197dc0fe18660c2af90.svg",
            "isPro": false,
            "fullname": "Zhiqi Li",
            "user": "zhiqilinv",
            "type": "user"
          },
          "name": "Zhiqi Li",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-07T09:36:57.283Z",
          "hidden": false
        },
        {
          "_id": "67ca7baf6d5c2eafede56d3b",
          "user": {
            "_id": "641d1c5ec3983aa94915c162",
            "avatarUrl": "/avatars/127985b837ecf61e43c835deee578b5e.svg",
            "isPro": false,
            "fullname": "De-An Huang",
            "user": "deahuang",
            "type": "user"
          },
          "name": "De-An Huang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-07T09:36:27.913Z",
          "hidden": false
        },
        {
          "_id": "67ca7baf6d5c2eafede56d3c",
          "user": {
            "_id": "6656eb16e50d7c40881a14f0",
            "avatarUrl": "/avatars/c6822a51c8d5918debf6ee1d25fe1825.svg",
            "isPro": false,
            "fullname": "GuilinLiu",
            "user": "GuilinLiu",
            "type": "user"
          },
          "name": "Guilin Liu",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-07T09:36:17.904Z",
          "hidden": false
        },
        {
          "_id": "67ca7baf6d5c2eafede56d3d",
          "user": {
            "_id": "66c8037c737ba92ae3fe0322",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/66c8037c737ba92ae3fe0322/WR_Yh5DWOVVh7IFlF24NM.jpeg",
            "isPro": false,
            "fullname": "Zhiding Yu",
            "user": "Zhiding",
            "type": "user"
          },
          "name": "Zhiding Yu",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-07T09:36:09.646Z",
          "hidden": false
        },
        {
          "_id": "67ca7baf6d5c2eafede56d3e",
          "user": {
            "_id": "6251bf4b183aa4266924ad91",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1678041834400-6251bf4b183aa4266924ad91.jpeg",
            "isPro": true,
            "fullname": "Kurt Keutzer",
            "user": "kurtkeutzer",
            "type": "user"
          },
          "name": "Kurt Keutzer",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-07T09:36:02.351Z",
          "hidden": false
        },
        {
          "_id": "67ca7baf6d5c2eafede56d3f",
          "user": {
            "_id": "60e1d6d3de3cd4c1bfb0c208",
            "avatarUrl": "/avatars/0bc59ede9074557f15447d2457aaf07b.svg",
            "isPro": false,
            "fullname": "Sungjin Ahn",
            "user": "sdstony",
            "type": "user"
          },
          "name": "Sungjin Ahn",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-07T09:35:54.160Z",
          "hidden": false
        },
        {
          "_id": "67ca7baf6d5c2eafede56d40",
          "name": "Jan Kautz",
          "hidden": false
        },
        {
          "_id": "67ca7baf6d5c2eafede56d41",
          "user": {
            "_id": "65a8b7f69aec1645994e7a15",
            "avatarUrl": "/avatars/debc086f3fea029db22847bde80799a0.svg",
            "isPro": false,
            "fullname": "Hongxu Yin",
            "user": "yinhongxu",
            "type": "user"
          },
          "name": "Hongxu Yin",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-07T09:35:40.242Z",
          "hidden": false
        },
        {
          "_id": "67ca7baf6d5c2eafede56d42",
          "name": "Yao Lu",
          "hidden": false
        },
        {
          "_id": "67ca7baf6d5c2eafede56d43",
          "name": "Song Han",
          "hidden": false
        },
        {
          "_id": "67ca7baf6d5c2eafede56d44",
          "user": {
            "_id": "66bf958296583c59b049085b",
            "avatarUrl": "/avatars/04df8dd45835b7ea0991e242784e7810.svg",
            "isPro": false,
            "fullname": "Wonmin Byeon",
            "user": "wbyeon",
            "type": "user"
          },
          "name": "Wonmin Byeon",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-07T09:35:32.527Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-03-06T06:17:38.000Z",
      "title": "긴 비디오 이해를 위한 토큰 효과적인 모델 및 다양한 LLM 모델",
      "summary": "최근의 이미지 기반의 다 모델 대 언어 모델(Video-LLMs)의 발전은 이미지를 이미지 프레임의 열로 처리하여 이미지 이해를 크게 향상시켰습니다. 그러나 현재의 방법들은 시각적 후보로 프레임을 독립적으로 처리하고 명시적인 시간의 모델링을 부족하여, 동적인 패턴을 파악하고 긴 영상에 효율적으로 처리할 능력이 제한되어 있습니다. 이러한 제한을 해결하기 위해, 우리는 STORM(Spatiotemporal TOken Reduction for Multimodal LLMs)을 소개합니다. 이것은 이미지 인코더와 LLM 사이에 특별한 시간의 인코더를 삽입하는 새로운 아키텍처입니다. 우리의 시간의 인코더는 Mamba State Space Model을 사용하여 이미지 토큰에 시간의 정보를 통합하고, 전체 영상 시퀀스에서 이미지 간의 동적인 패턴을 저장한 풍부한 표현을 생성합니다. 이 풍부한 인코딩은 영상의 논리 해석 능력을 향상시키고, 테스트 시간 샘플링과 학습 기반의 시간 및 공간의 팍링 등 토큰 감소 전략을 효과적으로 가능하게 하며, LLM의 계산 동역학을 크게 줄일 수 있습니다. 이 기술의 통합으로, 우리의 접근 방식은 동시에 훈련과 추론의 지연을 줄이고, 성능을 향상시키고, 확장된 시간적인 컨텍스트에서 효율적이고 강력한 영상 이해를 가능하게 합니다. 확장된 평가에 따라, STORM은 MLVU와 LongVideoBench의 거의 모든 긴 영상 이해 벤치마크에서 가장 先端의 결과를 달성하며, 고정된 입력 프레임 수로 8배의 계산 비용 절감과 2.4-2.9배의 解碼 지연 절감을 실현합니다. 프로젝트 페이지는 https://research.nvidia.com/labs/lpr/storm에 액세스할 수 있습니다.",
      "upvotes": 3,
      "discussionId": "67ca7bb16d5c2eafede56df1"
    },
    "publishedAt": "2025-03-06T23:53:09.588Z",
    "title": "Token-Efficient Long Video Understanding for Multimodal LLMs",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.04130.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 6299
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2503.04725",
      "authors": [
        {
          "_id": "67ca9092ba1ee2b914e3fa4a",
          "user": {
            "_id": "65e0027c960938e63e4a0157",
            "avatarUrl": "/avatars/c8ca0b082ee8e8004f47a23d9393df67.svg",
            "isPro": false,
            "fullname": "Zhuo Chen",
            "user": "zhuoc3",
            "type": "user"
          },
          "name": "Zhuo Chen",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-03-07T09:09:31.232Z",
          "hidden": false
        },
        {
          "_id": "67ca9092ba1ee2b914e3fa4b",
          "user": {
            "_id": "66e0619714d7a7711c6fc139",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/66e0619714d7a7711c6fc139/IZxEQ6Iv62DDHpCxFM-QG.jpeg",
            "isPro": false,
            "fullname": "Oriol Mayné i Comas",
            "user": "oriolmayne",
            "type": "user"
          },
          "name": "Oriol Mayné i Comas",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-07T09:37:41.309Z",
          "hidden": false
        },
        {
          "_id": "67ca9092ba1ee2b914e3fa4c",
          "name": "Zhuotao Jin",
          "hidden": false
        },
        {
          "_id": "67ca9092ba1ee2b914e3fa4d",
          "name": "Di Luo",
          "hidden": false
        },
        {
          "_id": "67ca9092ba1ee2b914e3fa4e",
          "name": "Marin Soljačić",
          "hidden": false
        }
      ],
      "publishedAt": "2025-03-06T18:59:48.000Z",
      "title": "L^2M: 긴 문맥 언어 모델링의 상호 정보량의 스케일링 법칙",
      "summary": "자연어 처리에서, 긴 거리 의존성을 지배하는 이분 다중 피보나치 정보 스케일링 방법을 엄밀하게 정의합니다. 이 스케일링 방법은 일반적인 두점 다중 피보나치 정보와 달리 독립적으로 스케일링하는 것을 보여줍니다. 이는 긴 문장 언어 모델링에 있어서 중요한 요소입니다. 이 스케일링 방법을 사용하여, 긴 문장의 유효한 모델링 능력을 나타내는 데, 과거의 정보를 저장하는 잠재 상태 크기의 스케일링과 관계가 있는 긴 문장 언어 모델링(L^2M) 조건을 정의합니다. 우리의 결과를 Transformer나 상태 공간 모델에 대해 실험적으로 검증했습니다. 이 연구는 대규모 언어 모델의 긴 문장 길이에 대한 개발에 대한 이론적 기초를 제공합니다.",
      "upvotes": 2,
      "discussionId": "67ca90c1ba1ee2b914e405b9",
      "projectPage": "https://github.com/LSquaredM/mutual_info_scaling_law",
      "githubRepo": "https://github.com/LSquaredM/mutual_info_scaling_law"
    },
    "publishedAt": "2025-03-07T01:42:13.847Z",
    "title": "L$^2$M: Mutual Information Scaling Law for Long-Context Language Modeling",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/65e0027c960938e63e4a0157/lMxohK6cMFgsw39hn0jga.jpeg",
      "https://cdn-uploads.huggingface.co/production/uploads/65e0027c960938e63e4a0157/EqSl1OwTeggMI59pVQzeR.jpeg"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.04725.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "65e0027c960938e63e4a0157",
      "avatarUrl": "/avatars/c8ca0b082ee8e8004f47a23d9393df67.svg",
      "fullname": "Zhuo Chen",
      "name": "zhuoc3",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2503.03983",
      "authors": [
        {
          "_id": "67ca66c1cb7e422997cbd148",
          "user": {
            "_id": "627a354cc488a8ce15a2dec5",
            "avatarUrl": "/avatars/0d99a2fea8b193993fe5b9b7e5b74f40.svg",
            "isPro": true,
            "fullname": "Sreyan Ghosh",
            "user": "SreyanG-NVIDIA",
            "type": "user"
          },
          "name": "Sreyan Ghosh",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-07T09:40:39.324Z",
          "hidden": false
        },
        {
          "_id": "67ca66c1cb7e422997cbd149",
          "user": {
            "_id": "652a4dfc36f031c5e6f8b8a6",
            "avatarUrl": "/avatars/9fb56b025dc25f91ca6c31136eaf74b2.svg",
            "isPro": false,
            "fullname": "Zhifeng Kong",
            "user": "ZhifengKong",
            "type": "user"
          },
          "name": "Zhifeng Kong",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-03-07T03:23:47.395Z",
          "hidden": false
        },
        {
          "_id": "67ca66c1cb7e422997cbd14a",
          "name": "Sonal Kumar",
          "hidden": false
        },
        {
          "_id": "67ca66c1cb7e422997cbd14b",
          "name": "S Sakshi",
          "hidden": false
        },
        {
          "_id": "67ca66c1cb7e422997cbd14c",
          "user": {
            "_id": "63fc1124a3c067e62897a73f",
            "avatarUrl": "/avatars/aa63337a7cd73181b7c1e92decf635f4.svg",
            "isPro": false,
            "fullname": "Jaehyeon Kim",
            "user": "firecomputer",
            "type": "user"
          },
          "name": "Jaehyeon Kim",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-07T09:41:17.053Z",
          "hidden": false
        },
        {
          "_id": "67ca66c1cb7e422997cbd14d",
          "name": "Wei Ping",
          "hidden": false
        },
        {
          "_id": "67ca66c1cb7e422997cbd14e",
          "user": {
            "_id": "6440ddd65d600fb09518daa8",
            "avatarUrl": "/avatars/ac5898afd2082d230e2ebf6fb867ad4f.svg",
            "isPro": false,
            "fullname": "Rafael Valle",
            "user": "rafaelvalle",
            "type": "user"
          },
          "name": "Rafael Valle",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-07T09:41:08.488Z",
          "hidden": false
        },
        {
          "_id": "67ca66c1cb7e422997cbd14f",
          "user": {
            "_id": "6537a569568d8be8fa096b8c",
            "avatarUrl": "/avatars/bfda5cb252d8b5bc3ad737d99c0d7f49.svg",
            "isPro": false,
            "fullname": "Dinesh Manocha",
            "user": "manocha",
            "type": "user"
          },
          "name": "Dinesh Manocha",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-07T09:41:01.710Z",
          "hidden": false
        },
        {
          "_id": "67ca66c1cb7e422997cbd150",
          "user": {
            "_id": "6311021788942700629e6247",
            "avatarUrl": "/avatars/e7adc1632b76e80e7e4a590033d1c20a.svg",
            "isPro": false,
            "fullname": "Bryan Catanzaro",
            "user": "ctnzr",
            "type": "user"
          },
          "name": "Bryan Catanzaro",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-07T09:40:55.626Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-03-06T00:10:26.000Z",
      "title": "Audio Flamingo 2: 긴 음성 녹음 이해와 전문가 레지언스 능력을 가진 음성 언어 모델",
      "summary": "非言語음과 음악을 이해하고 그 이유를 찾는 것은 인간과 AI 에이전트가 환경과 효과적으로 상호작용하는 데 중요한 요소입니다. 본 논문에서는, 음성 이해와 이유 능력이 있는 최신 오디오 언어 모델인 Audio Flamingo 2 (AF2)을 소개합니다. AF2는 (i) 사용자 정의 CLAP 모델, (ii) 미세한 음성 이유에 적합한 합성음성 QA 데이터, (iii) 다단계 학습 전략을 사용합니다. AF2는 3B 파라미터의 작은 언어 모델로도 가장 先進的性能를 달성했으며, 20개 이상의 벤치마크에서 오픈 소스 모델과 소유 모델을 초과했습니다. 이어서, 음성 이해를 긴 음성 섹션 (30초부터 5분)으로 확장하고, AF2의 긴 음성 캡처와 질문응답 태스크 학습에 적합한 새로운 큰 데이터 세트인 LongAudio를 제안합니다. LongAudio에서 AF2의 微调은, 긴 음성 이해 능력을 평가하기 위한 전문가 注記 벤치마크인 LongAudioBench에서 뛰어난 성능을 보였습니다. 분산 소멸 연구를 수행하고, 접근의 효과성을 확인했습니다. 프로젝트 웹 사이트: https://research.nvidia.com/labs/adlr/AF2/。",
      "upvotes": 2,
      "discussionId": "67ca66c3cb7e422997cbd178"
    },
    "publishedAt": "2025-03-07T00:12:47.515Z",
    "title": "Audio Flamingo 2: An Audio-Language Model with Long-Audio Understanding and Expert Reasoning Abilities",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.03983.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "62c9664eb34e600d7eaa4beb",
      "avatarUrl": "/avatars/ca23ecdec2d31c99ecce97d9b180ae0c.svg",
      "fullname": "Ghosh",
      "name": "Sreyan88",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2503.04606",
      "authors": [
        {
          "_id": "67ca7b8a2a2c299d98944909",
          "name": "Aoxiong Yin",
          "hidden": false
        },
        {
          "_id": "67ca7b8a2a2c299d9894490a",
          "name": "Kai Shen",
          "hidden": false
        },
        {
          "_id": "67ca7b8a2a2c299d9894490b",
          "user": {
            "_id": "64a0347b528a9bbe59d6e08c",
            "avatarUrl": "/avatars/6dd0bad84d711d1048a0a4169e621773.svg",
            "isPro": false,
            "fullname": "Yichong Leng",
            "user": "ustcscallion",
            "type": "user"
          },
          "name": "Yichong Leng",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-07T09:41:57.733Z",
          "hidden": false
        },
        {
          "_id": "67ca7b8a2a2c299d9894490c",
          "name": "Xu Tan",
          "hidden": false
        },
        {
          "_id": "67ca7b8a2a2c299d9894490d",
          "name": "Xinyu Zhou",
          "hidden": false
        },
        {
          "_id": "67ca7b8a2a2c299d9894490e",
          "user": {
            "_id": "67bc247b593452cc18965cb1",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/EA3kTYaaff0Hr7-dGiOOj.png",
            "isPro": false,
            "fullname": "JUNCHENG LI",
            "user": "JunchengLi",
            "type": "user"
          },
          "name": "Juncheng Li",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-07T09:42:06.818Z",
          "hidden": false
        },
        {
          "_id": "67ca7b8a2a2c299d9894490f",
          "name": "Siliang Tang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-03-06T16:53:14.000Z",
      "title": "최상의 두 가지: 비디오 생성에서 언어 모델과 확산 모델의 통합",
      "summary": "최근의 텍스트에서 비디오(T2V) 생성의 발전은 두 가지 경쟁하는 패러다임으로 구동되고 있습니다: 자동 복원 언어 모델과 분기 모델입니다. 그러나 각 패러다임은 내재적인 한계가 있습니다: 언어 모델은 시각적 품질과 오류의 누적에 어려움을 겪고, 분기 모델은 의미의 이해와 원인 모델링에 부족합니다. 본 논문에서는 coarse-to-fine 생성을 통해 두 패러다임의 강점을 융합하기 위해 LanDiff, 하이브리드 프레임워크를 제안합니다. 구조는 세 가지의 혁신을 도입하고 있습니다: (1) 3D 시각적 특징을 효율적인 의미적인 압축에 의해 간결한 1D 이산 표현으로 압축하는 의미 토큰라이저, sim14,000배의 압축비를 달성합니다; (2) 고 수준의 의미 관계를 가지는 의미 토큰을 생성하는 언어 모델; (3) coarse 의미를 고품질의 비디오로 精製하는 스트리밍 분기 모델입니다. 실험은 LanDiff, 5B 모델로 VBench T2V 벤치마크의 점수 85.43를 달성하고, 가장 先端的开放소스 모델인 ファンユアンビデオ(13B)와 シロー, ケリン, ハイルオ와 다른 상업 모델을 초월합니다. 또한, 긴 비디오 생성에서도 가장 先端의 성능을 달성하고, 이 분야의 다른 오픈소스 모델을 초월합니다. デモ는 https://landiff.github.io/에서 볼 수 있습니다.",
      "upvotes": 2,
      "discussionId": "67ca7b8d2a2c299d989449a8"
    },
    "publishedAt": "2025-03-06T23:52:33.338Z",
    "title": "The Best of Both Worlds: Integrating Language Models and Diffusion Models for Video Generation",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.04606.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 6299
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2503.02972",
      "authors": [
        {
          "_id": "67c96a61df4d64bfebd396d4",
          "name": "Jude Khouja",
          "hidden": false
        },
        {
          "_id": "67c96a61df4d64bfebd396d5",
          "name": "Karolina Korgul",
          "hidden": false
        },
        {
          "_id": "67c96a61df4d64bfebd396d6",
          "name": "Simi Hellsten",
          "hidden": false
        },
        {
          "_id": "67c96a61df4d64bfebd396d7",
          "name": "Lingyi Yang",
          "hidden": false
        },
        {
          "_id": "67c96a61df4d64bfebd396d8",
          "name": "Vlad Neacs",
          "hidden": false
        },
        {
          "_id": "67c96a61df4d64bfebd396d9",
          "name": "Harry Mayne",
          "hidden": false
        },
        {
          "_id": "67c96a61df4d64bfebd396da",
          "name": "Ryan Kearns",
          "hidden": false
        },
        {
          "_id": "67c96a61df4d64bfebd396db",
          "name": "Andrew Bean",
          "hidden": false
        },
        {
          "_id": "67c96a61df4d64bfebd396dc",
          "name": "Adam Mahdi",
          "hidden": false
        }
      ],
      "publishedAt": "2025-03-04T19:57:47.000Z",
      "title": "LINGOLY-TOO: 언어 템플릿화와 문자 배치의 혼란으로 기억과 논리 분리하기",
      "summary": "대 언어 모형(LLMs)의 추론 능력의 유효한 평가는 평가 벤치마크의 데이터 노출로 과도 평가되는 위험이 있습니다. 우리는 모델의 성능 평가에 있어서 기억의 영향을 줄이기 위해 언어 논리 문제의 생성 프레임워크를 통해 이 프레임워크를 활용하여 언어 논리의 어려운 평가 벤치마크인 'LINGOLY-TOO'를 개발했습니다. 정자 템플릿을 개발하여 실제 언어의 쓰기 기호를 동적으로 숨기고 여러 문제 변화를 생성했습니다. 이러한 변화는 각 해결책에 필요한 추론 단계를 유지하면서 특정 문제 예시가 모델의 학습 데이터에 포함될 가능성이 줄입니다. 실험에 따라 선진적인 추론에 적응되지 못하도록 OpenAI o1-preview, DeepSeem R1 등 선진 모형을 위협했습니다. 또한 같은 문제의 파라미터의 변화로 정확도의 차이를 명확히 한 반면, 모델의 원정자상의 문제가 나타날 경우 평균적으로 더 좋은 성능을 보입니다. 이러한 발견은 LLMs에서 답변 생성의 불투명성을 밝혀 선진 모형의 추론 능력의 과도 평가에 대한 선행 데이터 노출의 영향을 입증하고 있습니다.",
      "upvotes": 1,
      "discussionId": "67c96a62df4d64bfebd3976e"
    },
    "publishedAt": "2025-03-07T04:50:00.681Z",
    "title": "LINGOLY-TOO: Disentangling Memorisation from Reasoning with Linguistic Templatisation and Orthographic Obfuscation",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/671d7763572a9cfd9a6ea053/apKiu-1ILDtcrTYqiP53g.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.02972.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "671d7763572a9cfd9a6ea053",
      "avatarUrl": "/avatars/0a0225b50d949bb7ab0971bec531fc92.svg",
      "fullname": "Jude Khouja",
      "name": "jkhouja",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2503.01901",
      "authors": [
        {
          "_id": "67c90398ae4b9276f2d03643",
          "user": {
            "_id": "67bf67ade43da88cdfc1348e",
            "avatarUrl": "/avatars/7bd900ade802d99db7c562ad6c2f6661.svg",
            "isPro": false,
            "fullname": "Yuezhou Hu",
            "user": "yuezhouhu",
            "type": "user"
          },
          "name": "Yuezhou Hu",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-07T09:45:37.578Z",
          "hidden": false
        },
        {
          "_id": "67c90398ae4b9276f2d03644",
          "name": "Weiyu Huang",
          "hidden": false
        },
        {
          "_id": "67c90398ae4b9276f2d03645",
          "user": {
            "_id": "67286718746a95c09d04cb1d",
            "avatarUrl": "/avatars/317efa8459cca08c2ff56c3ab116e15c.svg",
            "isPro": false,
            "fullname": "Zichen Liang",
            "user": "zcliang22",
            "type": "user"
          },
          "name": "Zichen Liang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-07T09:45:50.605Z",
          "hidden": false
        },
        {
          "_id": "67c90398ae4b9276f2d03646",
          "name": "Chang Chen",
          "hidden": false
        },
        {
          "_id": "67c90398ae4b9276f2d03647",
          "user": {
            "_id": "66c0a08bac74db25de8427ec",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/66c0a08bac74db25de8427ec/9D-piDBZqSt6KNkHImmkv.jpeg",
            "isPro": false,
            "fullname": "Jintao Zhang",
            "user": "jt-zhang",
            "type": "user"
          },
          "name": "Jintao Zhang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-03-07T09:26:51.606Z",
          "hidden": false
        },
        {
          "_id": "67c90398ae4b9276f2d03648",
          "name": "Jun Zhu",
          "hidden": false
        },
        {
          "_id": "67c90398ae4b9276f2d03649",
          "user": {
            "_id": "65fcad0ba0d7adc40b54fac2",
            "avatarUrl": "/avatars/7564b5642378fddb46ec3b5ae57c0402.svg",
            "isPro": false,
            "fullname": "Jianfei Chen",
            "user": "surfingtomchen",
            "type": "user"
          },
          "name": "Jianfei Chen",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-07T09:46:07.369Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-28T07:04:19.000Z",
      "title": "후단 양자화 적분법으로 측정된 무게를 카테고리화하기 위한 방법",
      "summary": "LLM의 학습 후의 가중치 양자화는 메모리 범위 내의 크기를 줄이고, 加速에 대한 비트의 절약으로 비용 문제를 해결할 수 있습니다. 모든 가중치 차원은 동일한 중요성을 가지는 것이 아닙니다. 따라서, 이러한 방법을 통해, 가중치의 각 요소에 대한 손실 함수의 영향을 나타내는 민감도 메트릭을 사용하여, 원본 가중치를 더 좋은 양자화에 적합하게 사전 처리하여 가중치의 중요성을 평가합니다. 본 연구에서, 민감도 메트릭의 정확도에 대한 실험 연구를 수행했으며, 현재의 경사 및 헤시 행렬에 기반한 메트릭이 매우 부정확하다는 것을 발견했습니다: 이는 국소적인 2차 근사의 수렴 반경이 작기 때문에, 양자화 대책의 영향을 손실 함수에서 차례로 낮추는 데 사용되었습니다. 이러한 문제를 해결하기 위해, Post-quantization Integral (PQI)을 제안합니다. PQI는 이후 민감도를 정밀하게 평가하기 위한 정확한 메트릭입니다. 이러한 정확한 메트릭을 활용하기 위해, ReQuant라는 간단하고 강력한 프레임워크를 제안합니다. ReQuant는 자기조정 오프셋 선택과 단계별 중요한 가중치의 분리를 주요 구성 요소로 하는 두 개의 Dense-and-Sparse detach 구성 요소로 이루어집니다. 결과적으로, ReQuant는 학습 후의 가장 先进的 양자화 방법의 성능을 향상시키고, Llama 3.2 1B에 대해 QTIP을 사용하여 perplexity를 2.66으로 크게 향상시켰습니다.",
      "upvotes": 1,
      "discussionId": "67c90399ae4b9276f2d03671"
    },
    "publishedAt": "2025-03-07T04:23:41.486Z",
    "title": "Identifying Sensitive Weights via Post-quantization Integral",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.01901.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "66c0a08bac74db25de8427ec",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/66c0a08bac74db25de8427ec/9D-piDBZqSt6KNkHImmkv.jpeg",
      "fullname": "Jintao Zhang",
      "name": "jt-zhang",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 3
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2503.01375",
      "authors": [
        {
          "_id": "67c6bdf644c2f41804ca95c6",
          "user": {
            "_id": "64e57772b15cf1b5d017b8ee",
            "avatarUrl": "/avatars/24653ae6259a706d9d4ed63692eac5b7.svg",
            "isPro": false,
            "fullname": "Daniil Sherki",
            "user": "dsherki",
            "type": "user"
          },
          "name": "Daniil Sherki",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-03-04T09:44:52.446Z",
          "hidden": false
        },
        {
          "_id": "67c6bdf644c2f41804ca95c7",
          "user": {
            "_id": "6169a581d05945bfd8718dfa",
            "avatarUrl": "/avatars/1892ab06a7ddb557232777de3cbec470.svg",
            "isPro": false,
            "fullname": "Ivan Oseledets",
            "user": "oseledets",
            "type": "user"
          },
          "name": "Ivan Oseledets",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-07T09:46:17.295Z",
          "hidden": false
        },
        {
          "_id": "67c6bdf644c2f41804ca95c8",
          "name": "Ekaterina Muravleva",
          "hidden": false
        }
      ],
      "publishedAt": "2025-03-03T10:17:56.000Z",
      "title": "フローマッチング와 트랜스포머를 조합하여 베이즈 역문제의 효율적인 해결법",
      "summary": "효율적으로 베이즈 역문제를 해결하는 것은 후후분포의 복잡성과 전통적인 샘플링 방법의 계산 비용이 큰 문제로, 심각한 과제입니다. 관측 데이터 시퀀스 및 진행 모델이 제공되는 경우, 관측된 실험 데이터에 기반한 파라미터 분포를 복원하고자 합니다. Conditional Flow Mathcing (CFM)와 transformer 기반의 아키텍처를 조합하여, 관측 데이터의 변수 수의 조건에 따라 이러한 분포에서 효율적으로 샘플링할 수 있음을 보여줍니다.",
      "upvotes": 1,
      "discussionId": "67c6bdf744c2f41804ca960a"
    },
    "publishedAt": "2025-03-07T02:51:01.486Z",
    "title": "Combining Flow Matching and Transformers for Efficient Solution of Bayesian Inverse Problems",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.01375.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64e57772b15cf1b5d017b8ee",
      "avatarUrl": "/avatars/24653ae6259a706d9d4ed63692eac5b7.svg",
      "fullname": "Daniil Sherki",
      "name": "dsherki",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2503.02191",
      "authors": [
        {
          "_id": "67ca7fe72a83a60adcb6611a",
          "user": {
            "_id": "6331c3f618711776b468e9ec",
            "avatarUrl": "/avatars/af2c4bba031e474bf4fd2ea19e415aaf.svg",
            "isPro": false,
            "fullname": "Mia Mohammad Imran",
            "user": "imranraad",
            "type": "user"
          },
          "name": "Mia Mohammad Imran",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-03-07T09:09:36.214Z",
          "hidden": false
        },
        {
          "_id": "67ca7fe72a83a60adcb6611b",
          "name": "Robert Zita",
          "hidden": false
        },
        {
          "_id": "67ca7fe72a83a60adcb6611c",
          "name": "Rebekah Copeland",
          "hidden": false
        },
        {
          "_id": "67ca7fe72a83a60adcb6611d",
          "name": "Preetha Chatterjee",
          "hidden": false
        },
        {
          "_id": "67ca7fe72a83a60adcb6611e",
          "user": {
            "_id": "64085e1992033c150739aa74",
            "avatarUrl": "/avatars/621a5ef8aaf27d9c322c4a22c7bbcf5b.svg",
            "isPro": false,
            "fullname": "Rahat Rizvi Rahman",
            "user": "rahat-rizvi",
            "type": "user"
          },
          "name": "Rahat Rizvi Rahman",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-07T09:48:32.885Z",
          "hidden": false
        },
        {
          "_id": "67ca7fe72a83a60adcb6611f",
          "user": {
            "_id": "64ca97e1d469fc2cf822d9f6",
            "avatarUrl": "/avatars/efec75e454ada7026e8497137de5bceb.svg",
            "isPro": false,
            "fullname": "Kostadin Damevski",
            "user": "kdamevski",
            "type": "user"
          },
          "name": "Kostadin Damevski",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-07T09:48:25.771Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-03-04T02:01:37.000Z",
      "title": "택시코드 상의 유해한 컨버젼의 풀링 이해와 예측",
      "summary": "ソフトウェアプロジェクト는 다양한 배경에서 온 개인들의 참여와 기여로 번영합니다. 그러나 독특한 표현과 부정적인 상호작용은 기여자의 참여와 잔류를 방해하고, 신규 참여자를 제외시키는 데 영향을 미칩니다. 주동적인 Moderation 전략은 대화가 목적에서逸脱하는 듯한 독특한 표현을 예방하기 위해 노력합니다. 본 연구의 목적은 GitHub에서 독특한 표현으로 인한 대화의逸脱를 이해하고 예측하는 것입니다.\n\n이 연구를 촉진하기 위해, 우리는 GitHub에서 202개의 독특한 대화를 수집하여逸脱점을 표지한 데이터 세트를 만들었습니다. 이 데이터 세트는 696개의 독특하지 않은 대화를 포함합니다. 이 데이터 세트를 기반으로 독특한 대화와逸脱점의 특징을 특정하고, 언어적 마커, 제2人称 대명사, 부정어, Bitter Frustration과 Impatience의 분위기, 그리고 프로젝트의 기여자와 외부 참여자의 대화 다이나믹스 패턴을 포함합니다.\n\n이러한 실험적 관찰을 바탕으로, 우리는 잠재적으로 유해한 대화를 자동적으로 감지하고 대응하기 위해 Moderation을 위한 주동적인 접근을 제안합니다. 모델을 활용하여 GitHub 대화의 주제의 진화와逸脱의 초기 징후를 파악하기 위한 대화의 추적 기술로 대화의 요약 기술을 개발했습니다. 우리의 실험은 LLM을 통해 GitHub 대화의 요약을 제공하는 Prompt가逸脱를 예측하기 위해 69%의 F1 스코어를 달성하고, 기준 접근보다 강력한 향상을 보였습니다.",
      "upvotes": 1,
      "discussionId": "67ca7fe82a83a60adcb6615b",
      "githubRepo": "https://github.com/imranraad07/derailment-oss-replication"
    },
    "publishedAt": "2025-03-07T00:11:25.116Z",
    "title": "Understanding and Predicting Derailment in Toxic Conversations on GitHub",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.02191.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6331c3f618711776b468e9ec",
      "avatarUrl": "/avatars/af2c4bba031e474bf4fd2ea19e415aaf.svg",
      "fullname": "Mia Mohammad Imran",
      "name": "imranraad",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2503.04378",
      "authors": [
        {
          "_id": "67ca637e4cb4283da8ae2979",
          "name": "Zhilin Wang",
          "hidden": false
        },
        {
          "_id": "67ca637e4cb4283da8ae297a",
          "name": "Jiaqi Zeng",
          "hidden": false
        },
        {
          "_id": "67ca637e4cb4283da8ae297b",
          "user": {
            "_id": "6556379e10428134ff235afd",
            "avatarUrl": "/avatars/ec569729870d7392e806e59a02f37d0c.svg",
            "isPro": false,
            "fullname": "Olivier Delalleau",
            "user": "odelalleau",
            "type": "user"
          },
          "name": "Olivier Delalleau",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-07T09:51:28.127Z",
          "hidden": false
        },
        {
          "_id": "67ca637e4cb4283da8ae297c",
          "name": "Daniel Egert",
          "hidden": false
        },
        {
          "_id": "67ca637e4cb4283da8ae297d",
          "name": "Ellie Evans",
          "hidden": false
        },
        {
          "_id": "67ca637e4cb4283da8ae297e",
          "name": "Hoo-Chang Shin",
          "hidden": false
        },
        {
          "_id": "67ca637e4cb4283da8ae297f",
          "name": "Felipe Soares",
          "hidden": false
        },
        {
          "_id": "67ca637e4cb4283da8ae2980",
          "name": "Yi Dong",
          "hidden": false
        },
        {
          "_id": "67ca637e4cb4283da8ae2981",
          "name": "Oleksii Kuchaiev",
          "hidden": false
        }
      ],
      "publishedAt": "2025-03-06T12:30:24.000Z",
      "title": "전문적인 피드백과 편집 모델이 추론 시의 스케일링을 가능하게 하고, 개방된 일반적인 영역의 태스크에 대응합니다.",
      "summary": "推論 시 스케일링은 최근의 OpenAI o1, DeepSeek R1 등 모델의 성공에 있어 중요한 역할을 하고 있습니다. 그러나 추론 시 스케일링에 사용되는 기술은 답이 확인될 수 있는 작업에만 제한되어 있으며, 수학, 코딩, 로지스틱 인력 등 분야에 국한되어 있습니다. 인간이 초기의 시도를 통해 세부적인 피드백을 요구하고 피드백에 기반하여 개선하는 과정을 배워, 광범위한 개방적인 실험에서도 동일한 피드백을 받을 수 있도록 노력하고 있습니다. 이에 따라, 우리는 추론 시 스케일링을 위한专用 피드백 및 편집 모델의 데이터를 수집하고 훈련을 수행하고 있습니다. 우리 설정에서 하나의 모델이 초기의 답변을 생성하고, 그 답변에 따라 두 번째 모델이 피드백을 제공하고, 피드백에 따라 세 번째 모델이 답변을 편집하는 방식으로 설계되어 있습니다. 우리는 Arena Hard라는 벤치마크의 성능을 보여주며, 초기의 답변의 수, 유효한 피드백과 편집된 답변의 수를 스케일링하여 이 성능을 향상시킬 수 있음을 보여주고 있습니다. 최적의 스케일링에 따라 Llama 3 familiy의 70B 모델을 기반으로 한 우리의 설정은 2025년 3월 5일 Arena Hard에서 가장 先端의 성능을 달성할 수 있으며, OpenAI o1-preview-2024-09-12(90.4)와 DeepSeek R1(92.3)을 초월할 수 있습니다.",
      "upvotes": 1,
      "discussionId": "67ca63804cb4283da8ae29da"
    },
    "publishedAt": "2025-03-06T22:10:18.014Z",
    "title": "Dedicated Feedback and Edit Models Empower Inference-Time Scaling for Open-Ended General-Domain Tasks",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.04378.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 6299
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2503.04644",
      "authors": [
        {
          "_id": "67ca5d2783ac16a063a56241",
          "user": {
            "_id": "64dc29d9b5d625e0e9a6ecb9",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/QxGBsnk1cNsBEPqSx4ae-.jpeg",
            "isPro": false,
            "fullname": "Tingyu Song",
            "user": "songtingyu",
            "type": "user"
          },
          "name": "Tingyu Song",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-07T09:53:24.813Z",
          "hidden": false
        },
        {
          "_id": "67ca5d2783ac16a063a56242",
          "user": {
            "_id": "65dfeee3d16fb170031df293",
            "avatarUrl": "/avatars/05e6fe0e61d4bb87536554c782385dac.svg",
            "isPro": false,
            "fullname": "gan",
            "user": "guo9",
            "type": "user"
          },
          "name": "Guo Gan",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-03-07T09:09:52.646Z",
          "hidden": false
        },
        {
          "_id": "67ca5d2783ac16a063a56243",
          "name": "Mingsheng Shang",
          "hidden": false
        },
        {
          "_id": "67ca5d2783ac16a063a56244",
          "user": {
            "_id": "62f662bcc58915315c4eccea",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62f662bcc58915315c4eccea/zOAQLONfMP88zr70sxHK-.jpeg",
            "isPro": true,
            "fullname": "Yilun",
            "user": "yilunzhao",
            "type": "user"
          },
          "name": "Yilun Zhao",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-07T09:52:59.499Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-03-06T17:32:22.000Z",
      "title": "IFIR: 전문 분야 정보 검색에서 지침 준수 평가에 대한 일관된 벤치마크",
      "summary": "IFIR는 전문 분야에서 명령을 따라하는 정보 검색(IR)를 평가하기 위한 최초의 전담적인 벤치마크입니다. IFIR는 2,426건의 고품질의 예를 포함하고 있으며, 금융, 법, 의료, 과학문헌의 4가지 전문 분야의 8가지 세트를 커버하고 있습니다. 각 세트는 사용자定制된 명령이 중요한 현실적인 시나리오를 재현하고, 전문 분야 고유의 검색 태스크를 해결하고 있습니다. IFIR는 구조적인 복잡도가 다른 수준에서 명령을 처리하는 검색 능력에 대해 상세하게 분석할 수 있습니다. 또한, LLM 기반의 새로운 평가 방법을 제안하고, 모델의 성능을 더욱 정밀하고 신뢰성 있는 평가에 제공합니다. 15개의 선도적인 검색 모델(LLM 기반 모델도 포함)에 대해 확장된 실험을 수행하고, 현재의 모델이 복잡한, 전문 분야 고유의 명령을 효과적으로 따라가는 데 이르기까지의 중대한 문제점을 밝혀줍니다. 또한, 이러한 제한을 밝혀주기 위해 상세한 분석을 수행하고, 향후 진보에 연결된 유익한 팁을 제공합니다.",
      "upvotes": 0,
      "discussionId": "67ca5d2983ac16a063a562a1"
    },
    "publishedAt": "2025-03-07T04:37:52.576Z",
    "title": "IFIR: A Comprehensive Benchmark for Evaluating Instruction-Following in Expert-Domain Information Retrieval",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.04644.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "65dfeee3d16fb170031df293",
      "avatarUrl": "/avatars/05e6fe0e61d4bb87536554c782385dac.svg",
      "fullname": "gan",
      "name": "guo9",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  }
]