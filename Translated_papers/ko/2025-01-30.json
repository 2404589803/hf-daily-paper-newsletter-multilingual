[
  {
    "paper": {
      "id": "2501.17703",
      "authors": [
        {
          "_id": "679ae76cf211c66bd702f5d5",
          "user": {
            "_id": "636a35eff8d9af4aea181608",
            "avatarUrl": "/avatars/d9c5cf3491243d1f2b1c5df1873ee8e7.svg",
            "isPro": false,
            "fullname": "yubo",
            "user": "ubowang",
            "type": "user"
          },
          "name": "Yubo Wang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-01-30T08:39:49.375Z",
          "hidden": false
        },
        {
          "_id": "679ae76cf211c66bd702f5d6",
          "name": "Xiang Yue",
          "hidden": false
        },
        {
          "_id": "679ae76cf211c66bd702f5d7",
          "user": {
            "_id": "6313a86154e6e5d9f0f94e04",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1662232951344-6313a86154e6e5d9f0f94e04.jpeg",
            "isPro": false,
            "fullname": "Wenhu Chen",
            "user": "wenhu",
            "type": "user"
          },
          "name": "Wenhu Chen",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-01-30T02:43:59.302Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-29T15:20:30.000Z",
      "title": "최종 조정의 비판: 비판을 배우는 것은 오류를 배우는 것보다 효과적이다.",
      "summary": "Supervised Fine-Tuning (SFT)는 일반적으로 주어진 지시에 대한 주석된 답변을 모방하여 언어 모델을 훈련하는 데 사용됩니다. 본 논문에서는 이 패러다임에 도전하고, Critique Fine-Tuning (CFT)라는 전략을 제안합니다. 이 방법은 모델이 노이즈가 있는 답변을 비판하는 것이 아니라, 단순히 모방하는 것이 아니라 정확한 답변을 학습하는 것입니다. 인간의 학습 과정과 연결되어, CFT는 비판적 사고를 중시하고, 표준적인 SFT에 의해 과거에 틀린 특성을 더 깊은 분석과 복잡한 이해를 촉발합니다. CFT의 효과를 증명하기 위해, WebInstruct에서 50K 샘플의 데이터 세트를 구축하고, GPT-4o를 교사로 (input=[질문; 노이즈가 있는 답변], output=비평가) 형식으로 비평가를 생성합니다. 이 데이터 세트에 대한 CFT는 Qwen2.5, Qwen2.5-Math, DeepSeek-Math 등 다양한 기초 모델을 사용하여 6개의 수학 벤치마크에서 SFT보다 확률적으로 4-10%의 향상을 보입니다. 또한, MetaMath와 NuminaMath 데이터 세트에 확장하여 동일한 향상을 보입니다. 특히, Qwen2.5-Math-CFT 모델은 거의 2M 샘플을 사용했던 강력한 모델보다 더 강력한 모델로, AceMath와 Qwen2.5-Math-Instruct을 초월하는 것을 보입니다. 부정적인 연구에 따르면, CFT는 노이즈가 있는 답변의 소스와 교사의 비평가 모델에 대한 강건함을 보여줍니다. 이러한 발견으로부터, 언어 모델의 논리론을 진보시키기 위한 효과적인 대체로 비판적 훈련을 제안합니다.",
      "upvotes": 12,
      "discussionId": "679ae770f211c66bd702f697"
    },
    "publishedAt": "2025-01-29T21:51:11.227Z",
    "title": "Critique Fine-Tuning: Learning to Critique is More Effective than Learning to Imitate",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.17703.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "636a35eff8d9af4aea181608",
      "avatarUrl": "/avatars/d9c5cf3491243d1f2b1c5df1873ee8e7.svg",
      "fullname": "yubo",
      "name": "ubowang",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 4
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2501.14334",
      "authors": [
        {
          "_id": "679a7546805383520ce065af",
          "user": {
            "_id": "644156da1a80f6d83cb1667c",
            "avatarUrl": "/avatars/106d30a576b0fb58118ac4333b17260b.svg",
            "isPro": false,
            "fullname": "Clement Desroches",
            "user": "clementdesroches",
            "type": "user"
          },
          "name": "Clément Desroches",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-01-29T21:06:17.418Z",
          "hidden": false
        },
        {
          "_id": "679a7546805383520ce065b0",
          "user": {
            "_id": "66221f6295e8f09a668f07f0",
            "avatarUrl": "/avatars/f7c943996c814630ab5dcfaaaba01a83.svg",
            "isPro": false,
            "fullname": "Martin Chauvin",
            "user": "Neyri56",
            "type": "user"
          },
          "name": "Martin Chauvin",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-01-30T09:38:17.235Z",
          "hidden": false
        },
        {
          "_id": "679a7546805383520ce065b1",
          "name": "Louis Ladan",
          "hidden": false
        },
        {
          "_id": "679a7546805383520ce065b2",
          "name": "Caroline Vateau",
          "hidden": false
        },
        {
          "_id": "679a7546805383520ce065b3",
          "name": "Simon Gosset",
          "hidden": false
        },
        {
          "_id": "679a7546805383520ce065b4",
          "name": "Philippe Cordier",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-24T08:58:49.000Z",
      "title": "AI의 지속 가능한 스케일링의 미지의 탐색: 기업의 AI 환경 영향 예측 연구",
      "summary": "인공지능(AI)의 급격한 성장, 특히 대규모 언어 모델(LLMs)에 대해 환경적 영향에 대한 우려가 제기되었다. 이 문제는 CO2 배출물보다 더 많은硬質의 제조와 전체 생명주기를 포함하여 나타났다. 주요 제공자의 불투명한 특성은 기업이 AI와 관련된 환경적 영향을 평가하고 0의 목표를 달성하는 데 방해하고 있는 것이다.\n\n이 논문에서는 기업의 AI 포트폴리오의 환경적 영향을 평가하는 방법을 제안하고, AI와 생명주기 평가(LCA)의 전문 지식이 필요하지 않다는 사실은 확인하여 실질적인 아이디어를 제공하기 위해 있다. 결과는 대규모 생성 AI 모델은 전통적인 모델보다 4600배의 에너지를 소비하는 것을 확인했다. 우리의 모델링 접근법은 IPCC의 시나리오를 따른 전력의 혼합의 변화, AI의 사용량의 증가, 컴퓨터의 계산 효율의 향상을 고려하여 2030년까지의 AI의 전력 사용량을 예측하고 있다. 높은 도입 시나리오에서, 광범위한 생성 AI와 에이전트의 도입으로 가장 복잡한 모델과 프레임워크를 통해 AI의 전력 사용량은 24.4배의 증가를 예상된다.\n\n2030년까지 생성 AI의 환경적 영향을 줄이기 위해서는 AI 가치 체인의 전체적인 협조적인 노력을 필요로 한다.硬質의 효율, 모델의 효율, 또는 그리드의 개선의 독립적인 조치는 충분하지 않다. 우리는 환경적 평가 프레임워크의 표준화, 가치 체인의 전체 소유자의 더 투명성, 그리고 「환경의 보상」 메트릭스의 도입을 주장하고, AI의 개발과 0의 목표를 일치시키기 위해 주장하고 있다.",
      "upvotes": 11,
      "discussionId": "679a7548805383520ce065f5"
    },
    "publishedAt": "2025-01-30T03:05:08.789Z",
    "title": "Exploring the sustainable scaling of AI dilemma: A projective study of corporations' AI environmental impacts",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.14334.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "644156da1a80f6d83cb1667c",
      "avatarUrl": "/avatars/106d30a576b0fb58118ac4333b17260b.svg",
      "fullname": "Clement Desroches",
      "name": "clementdesroches",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2501.17749",
      "authors": [
        {
          "_id": "679ae5eab898ac90bf4480b6",
          "user": {
            "_id": "657b3a44de028a439ea2ed9d",
            "avatarUrl": "/avatars/9f05e8eb6809a0ce1b50cd1fc9b5a044.svg",
            "isPro": false,
            "fullname": "Aitor Arrieta",
            "user": "aitorarrieta",
            "type": "user"
          },
          "name": "Aitor Arrieta",
          "status": "extracted_confirmed",
          "statusLastChangedAt": "2025-01-30T08:45:20.561Z",
          "hidden": false
        },
        {
          "_id": "679ae5eab898ac90bf4480b7",
          "name": "Miriam Ugarte",
          "hidden": false
        },
        {
          "_id": "679ae5eab898ac90bf4480b8",
          "user": {
            "_id": "65001514f322f9156663f096",
            "avatarUrl": "/avatars/e8712f60d4e8b7c70ac02c532ad547ef.svg",
            "isPro": false,
            "fullname": "Pablo Valle",
            "user": "pablovalle",
            "type": "user"
          },
          "name": "Pablo Valle",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-30T09:39:30.629Z",
          "hidden": false
        },
        {
          "_id": "679ae5eab898ac90bf4480b9",
          "user": {
            "_id": "63527de67e4cc3135fd16651",
            "avatarUrl": "/avatars/5eb8076d448d0b6746e256c24e1440e0.svg",
            "isPro": false,
            "fullname": "José Antonio Parejo Maestre",
            "user": "japarejo",
            "type": "user"
          },
          "name": "José Antonio Parejo",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-30T09:39:06.958Z",
          "hidden": false
        },
        {
          "_id": "679ae5eab898ac90bf4480ba",
          "user": {
            "_id": "6790d642a1863df579840ae3",
            "avatarUrl": "/avatars/a10a6f4af327c1bb67513c56d7f84820.svg",
            "isPro": false,
            "fullname": "Sergio Segura",
            "user": "ssegura",
            "type": "user"
          },
          "name": "Sergio Segura",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-01-30T02:37:35.516Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-29T16:36:53.000Z",
      "title": "OpenAI의 o3-mini의 초기 외부 안전성 검증：배포 전 평가에서 얻은 통찰\n\n(注意：翻译时尽量保持原文的专业性和准确性，同时确保语法和用词的正确性。)",
      "summary": "대 언어 모델(LLMs)는 우리 일상 생활의 중요한 부분을 차지하고 있습니다. 그러나 이들은 개인의 프라이버시를 훼손, 편견을 지속시키고 비정상 정보를 확산하는 위험을 동반합니다. 이러한 위험은 책임 있는 기능화를 위해 강력한 보안 구조, 윤리적인 가이드라인, 그리고 세부적인 테스트가 필요함을 분명히 합니다. LLMs의 안전성은 모델이 작동하기 전에 상세하게 테스트되고 일반 사용자에게 접근할 수 있게 될 때까지 확인하는 중요한 특성입니다. 본 논문에서는, 몽드라고 대학과 세비리아 대학의 연구자들이 OpenAI의 새로운 o3-mini LLM을 보안 테스트 프로그램의 일부로 수행한 외부 보안 테스트 경험을 보고합니다. 특히, 우리 도구인 ASTRAL을 사용하여, 최신의 불안정한 테스트 입력(프로ン퓰트)을 자동적이고 체계적으로 생성하고, LLMs의 다양한 안전 카테고리를 테스트하고 평가할 수 있습니다. o3-mini beta 버전에 대해, ASTRAL로 분류된 불안정한 테스트 케이스를 직접 확인하고, 그 후 87건의 실제 불안정한 LLM의 행동의 인스턴스를 특정했습니다. 본 논문에서는, OpenAI의 최신 LLM의 기능화 전의 외부 테스트 기간에 대한 중요한 인젝트와 발견을 밝큽니다.",
      "upvotes": 7,
      "discussionId": "679ae5f0b898ac90bf44826c"
    },
    "publishedAt": "2025-01-29T21:38:42.464Z",
    "title": "Early External Safety Testing of OpenAI's o3-mini: Insights from the Pre-Deployment Evaluation",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.17749.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5860
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.17433",
      "authors": [
        {
          "_id": "679b1319f87b99a2a7c41e36",
          "user": {
            "_id": "67325283b318faa97f7ae5f7",
            "avatarUrl": "/avatars/2f83452768148b323c540c43ad695ee6.svg",
            "isPro": false,
            "fullname": "TianshengHuang",
            "user": "TianshengHuang",
            "type": "user"
          },
          "name": "Tiansheng Huang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-01-30T08:39:47.548Z",
          "hidden": false
        },
        {
          "_id": "679b1319f87b99a2a7c41e37",
          "user": {
            "_id": "6539cab119c3ef6679794706",
            "avatarUrl": "/avatars/a88691ff5a547c7a1384edcc615c8209.svg",
            "isPro": false,
            "fullname": "Sihao Hu",
            "user": "SihaoHu",
            "type": "user"
          },
          "name": "Sihao Hu",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-30T09:39:58.723Z",
          "hidden": false
        },
        {
          "_id": "679b1319f87b99a2a7c41e38",
          "user": {
            "_id": "647615b995a4dc98e58c24f2",
            "avatarUrl": "/avatars/7f73999246526c1aef4d019d5f5595ad.svg",
            "isPro": false,
            "fullname": "Fatih Ilhan",
            "user": "tawreos",
            "type": "user"
          },
          "name": "Fatih Ilhan",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-30T09:40:06.004Z",
          "hidden": false
        },
        {
          "_id": "679b1319f87b99a2a7c41e39",
          "user": {
            "_id": "65aae89948c718a57434db6f",
            "avatarUrl": "/avatars/6c0fae8dafad9b9265098a9bc3bfc102.svg",
            "isPro": false,
            "fullname": "selim tekin",
            "user": "sftekin25",
            "type": "user"
          },
          "name": "Selim Furkan Tekin",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-30T09:40:16.339Z",
          "hidden": false
        },
        {
          "_id": "679b1319f87b99a2a7c41e3a",
          "user": {
            "_id": "65c998005e17dbeaf147db84",
            "avatarUrl": "/avatars/6fb47b1e095971b93ff7dcd10369f926.svg",
            "isPro": false,
            "fullname": "Ling Liu",
            "user": "ling1119",
            "type": "user"
          },
          "name": "Ling Liu",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-30T09:40:37.075Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-29T06:24:58.000Z",
      "title": "바이러스: 게이드레일 모델링을 통과하는 대규모 언어 모델의 유해한 미세 조정 공격",
      "summary": "최근의 연구에 따르면 대규모 언어 모델(LLMs)은 유해한 미세 조정 공격에 취약합니다 - 모델은 일부 유해한 샘플에 의해 미세 조정 후, 안전성의 맞춤 능력이 손실됩니다. 위험 감소를 위해 일반적으로 미세 조정 전 유해한 샘플을 필터링하는 보호라인이 사용됩니다. 이 논문에서는 새로운 로드팅 방법론을 설계하여 데이터 필터링에 의존하는 하나의 보호라인의 한계를 보여주는 것입니다. 제안된 공격 방법인 ヴァイラス에 의한 유해 데이터의 최적화는 미세 조정 보호라인의 감지에 100%의 실패율을 가지지 않고, 동시에 우수한 공격 성능을 달성할 수 있습니다. 최종적으로, 이 논문에서 전달된 주요 메시지는 유해한 미세 조정 공격에 대한 보호라인의 한계를 그대로 무시하는 것이 위험하다는 것입니다. 그 이유는 사전 학습된 LLMs의 고유의 안전성 문제를 해결할 수 없기 때문입니다. 코드는 https://github.com/git-disl/Virus에 공개되어 있습니다.",
      "upvotes": 2,
      "discussionId": "679b131bf87b99a2a7c41ede"
    },
    "publishedAt": "2025-01-30T01:30:18.013Z",
    "title": "Virus: Harmful Fine-tuning Attack for Large Language Models Bypassing Guardrail Moderation",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/67325283b318faa97f7ae5f7/1hJo5gEfGEXAwYB5a6yWY.png",
      "https://cdn-uploads.huggingface.co/production/uploads/67325283b318faa97f7ae5f7/8SaMXA1izw5vcfwtU2Nhj.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.17433.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "67325283b318faa97f7ae5f7",
      "avatarUrl": "/avatars/2f83452768148b323c540c43ad695ee6.svg",
      "fullname": "TianshengHuang",
      "name": "TianshengHuang",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2501.17195",
      "authors": [
        {
          "_id": "679ae7655c55250b48483742",
          "name": "Andrei Alexandru",
          "hidden": false
        },
        {
          "_id": "679ae7655c55250b48483743",
          "user": {
            "_id": "66e184e86048d62cd8fb4e52",
            "avatarUrl": "/avatars/dc459c692fe9fce0911fa1229df0aeee.svg",
            "isPro": false,
            "fullname": "Antonia Calvi",
            "user": "NinaCalvi",
            "type": "user"
          },
          "name": "Antonia Calvi",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-30T09:40:54.827Z",
          "hidden": false
        },
        {
          "_id": "679ae7655c55250b48483744",
          "name": "Henry Broomfield",
          "hidden": false
        },
        {
          "_id": "679ae7655c55250b48483745",
          "name": "Jackson Golden",
          "hidden": false
        },
        {
          "_id": "679ae7655c55250b48483746",
          "name": "Kyle Dai",
          "hidden": false
        },
        {
          "_id": "679ae7655c55250b48483747",
          "name": "Mathias Leys",
          "hidden": false
        },
        {
          "_id": "679ae7655c55250b48483748",
          "name": "Maurice Burger",
          "hidden": false
        },
        {
          "_id": "679ae7655c55250b48483749",
          "name": "Max Bartolo",
          "hidden": false
        },
        {
          "_id": "679ae7655c55250b4848374a",
          "name": "Roman Engeler",
          "hidden": false
        },
        {
          "_id": "679ae7655c55250b4848374b",
          "name": "Sashank Pisupati",
          "hidden": false
        },
        {
          "_id": "679ae7655c55250b4848374c",
          "name": "Toby Drane",
          "hidden": false
        },
        {
          "_id": "679ae7655c55250b4848374d",
          "name": "Young Sun Park",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-27T15:09:08.000Z",
      "title": "Atla Selene Mini: 일반 평가 모델",
      "summary": "アトラ・セレネ・ミニ는 가장 先端의小型言語モデル로, 언어 판별 기능(SLMJ)을 통해 소개됩니다. セレネ・ミニ는 11개의 분포외 벤치마크에서 전체적인 성능을 평가하여, SLMJ와 GPT-4o-mini을 초과하는 일반적인 용도의 평가자입니다. 절대 스코어, 클래스 분류, 두 가지의 선호 태스크를 포함한 광범위한 범위에서 성능을 초과합니다. RewardBench에서 8B 생성 모델의 최고 스코어를 기록하고, GPT-4o와 전문 판별자의 강력한 기준을 초과합니다. 이를 달성하기 위해, 고품질을 보장하기 위해 필터링과 데이터셋의 제거를 통해 높은 품질을 보장합니다. 모델은 직접 선호 최적화(DPO)와 관学学习 미세 조정(SFT)의 손실을 결합하여 훈련되어, 높은 프로ンプタ블な 평가자として 뛰어납니다. セレネ・ミニ는 금융 및 의료 분야의 데이터셋에서 전문가의 평가와 0 shot agreement가 크게 향상되어, 프로ンプト 형식의 변화에 강건합니다. 초기 결과로부터, セレネ・ミニ는 실제 평가에서 가장 높은 평가자로 평가되어 있습니다. 모델의 가중치는 HuggingFace(https://hf.co/AtlaAI/Selene-1-Mini-Llama-3.1-8B)과 Ollama에서 공개되어, 광범위한 커뮤니티의 도입을 촉구하고 있습니다.",
      "upvotes": 2,
      "discussionId": "679ae76b5c55250b484838e0"
    },
    "publishedAt": "2025-01-29T21:44:37.041Z",
    "title": "Atla Selene Mini: A General Purpose Evaluation Model",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.17195.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5860
    },
    "isAuthorParticipating": false
  }
]