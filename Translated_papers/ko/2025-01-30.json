[
  {
    "paper": {
      "id": "2501.17703",
      "authors": [
        {
          "_id": "679ae76cf211c66bd702f5d5",
          "user": {
            "_id": "636a35eff8d9af4aea181608",
            "avatarUrl": "/avatars/d9c5cf3491243d1f2b1c5df1873ee8e7.svg",
            "isPro": false,
            "fullname": "yubo",
            "user": "ubowang",
            "type": "user"
          },
          "name": "Yubo Wang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-01-30T08:39:49.375Z",
          "hidden": false
        },
        {
          "_id": "679ae76cf211c66bd702f5d6",
          "name": "Xiang Yue",
          "hidden": false
        },
        {
          "_id": "679ae76cf211c66bd702f5d7",
          "user": {
            "_id": "6313a86154e6e5d9f0f94e04",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1662232951344-6313a86154e6e5d9f0f94e04.jpeg",
            "isPro": false,
            "fullname": "Wenhu Chen",
            "user": "wenhu",
            "type": "user"
          },
          "name": "Wenhu Chen",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-01-30T02:43:59.302Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-29T15:20:30.000Z",
      "title": "비평적 튜닝: 비평적 학습이 모방 학습보다 효과적입니다.",
      "summary": "Supervised Fine-Tuning (SFT)는 주어진 지시에 따라 설명된 대답을 모방하여 언어 모델을 훈련하는 일반적인 방법입니다. 본 논문에서는 이 패턴을 도전하고, Critique Fine-Tuning (CFT)를 제안합니다. CFT는 모델이 노이즈가 있는 대답을 비판하여 학습하는 전략이며, 인간의 학습 과정에서의 비판적 사고를 강조하여 모델화하고 있습니다. 표준의 SFT에서 미치지 못하는 깊은 분석과 복잡한 이해의 특징을 촉진합니다. CFT의 효과를 평가하기 위해, WebInstruct에서 50K 샘플의 데이터 세트를 구축하고, GPT-4o를 교사로 (input=[질문; 노이즈가 있는 대답], output=비평) 형식으로 비평을 생성했습니다. 이 데이터 세트에 대한 CFT는 6개의 수학 벤치마크에서 SFT보다 4-10%의 개선을 보였으며, 기본 모델인 Qwen2.5, Qwen2.5-Math, DeepSeek-Math를 사용했습니다. 또한, MetaMath와 NuminaMath 데이터 세트를 확장하여 SFT와 동일한 효과를 보였습니다. 특히, Qwen2.5-Math-CFT 모델은 각각 2M 샘플을 사용했을 때 더 뛰어난 성능을 보였으며, 이 모델은 많은 벤치마크에서 대등하거나 초과했습니다. 소멸 연구에 따르면, CFT는 노이즈가 있는 대답의 원인 및 교사의 비평 모델의 원인에 대한 강력한 구조를 보여줍니다. 이러한 발견들로부터, 비판적 학습을 이용한 훈련은 언어 모델의 논리론의 발전에 따라 더욱 효과적인 대체로 주장합니다.",
      "upvotes": 12,
      "discussionId": "679ae770f211c66bd702f697"
    },
    "publishedAt": "2025-01-29T21:51:11.227Z",
    "title": "Critique Fine-Tuning: Learning to Critique is More Effective than Learning to Imitate",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.17703.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "636a35eff8d9af4aea181608",
      "avatarUrl": "/avatars/d9c5cf3491243d1f2b1c5df1873ee8e7.svg",
      "fullname": "yubo",
      "name": "ubowang",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 4
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2501.14334",
      "authors": [
        {
          "_id": "679a7546805383520ce065af",
          "user": {
            "_id": "644156da1a80f6d83cb1667c",
            "avatarUrl": "/avatars/106d30a576b0fb58118ac4333b17260b.svg",
            "isPro": false,
            "fullname": "Clement Desroches",
            "user": "clementdesroches",
            "type": "user"
          },
          "name": "Clément Desroches",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-01-29T21:06:17.418Z",
          "hidden": false
        },
        {
          "_id": "679a7546805383520ce065b0",
          "user": {
            "_id": "66221f6295e8f09a668f07f0",
            "avatarUrl": "/avatars/f7c943996c814630ab5dcfaaaba01a83.svg",
            "isPro": false,
            "fullname": "Martin Chauvin",
            "user": "Neyri56",
            "type": "user"
          },
          "name": "Martin Chauvin",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-01-30T09:38:17.235Z",
          "hidden": false
        },
        {
          "_id": "679a7546805383520ce065b1",
          "name": "Louis Ladan",
          "hidden": false
        },
        {
          "_id": "679a7546805383520ce065b2",
          "name": "Caroline Vateau",
          "hidden": false
        },
        {
          "_id": "679a7546805383520ce065b3",
          "name": "Simon Gosset",
          "hidden": false
        },
        {
          "_id": "679a7546805383520ce065b4",
          "name": "Philippe Cordier",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-24T08:58:49.000Z",
      "title": "AI의 지속 가능한 스케일링의 미지의 탐구: 기업의 AI 환경 영향 예측 연구",
      "summary": "인공지능(AI)의 급속한 발전, 특히 대형 언어 모델(LLMs)에 의한 발전은 환경 효과에 대한 우려를 증가시키고, 가스 배출물의 환경 영향보다 더 심각하게硬質의 제조와 수명 종료 과정까지 포함하여 영향을 미치고 있다. 주요 제공자의 불투명성은 기업이 AI와 관련된 환경 영향 평가를 수행하고, ネットゼロ目標를 달성하는 데 어려움을 초래한다.\n\n본 논문에서는 기업의 AI 포트폴리오의 환경 영향을 평가하는 방법을 제안하고, 구체적인 AI와 생명 사이클 평가(LCA)의 전문 지식을 필요로 하지 않도록 가능한洞察를 제공하기 위해 수행하였다. 결과는 대규모 생성 AI 모델은 전통적인 모델과 비교하여 최대 4600배의 에너지를 소비하는 것을 확인하였다. 우리의 모델링 접근법은 IPCC의 시나리오를 따른 전기 혼합의 변화, AI 사용량의 증가,硬質의 계산 효율, 가스 배출물의 환경 영향 평가를 위해 2030년까지의 AI의 전기 사용량을 예측하였다. 높은 도입 시나리오에서, 광범위한 생성 AI와 에이전트의 도입으로 복잡한 모델과 프레임워크의 확장으로 AI의 전기 사용량은 24.4배 증가할 것으로 예상된다.\n\n2030년까지 생성 AI의 환경 영향을 완화하기 위해서는 AI 가치 체인의 전체적인 협업이 필요할 것이다.硬質의 계산 효율, 모델의 계산 효율, 가스 배출물의 개선의 독립적인 조치는 충분하지 않다. 우리는 환경 평가의 표준화 프레임워크, 가치 체인의 전체 소유자으로부터 더 투명성, 그리고 「환경의 보상」 메트릭스의 도입을 주장하고, AI의 개발을 ネットゼロ目標에 맞추는 것을 촉구한다.",
      "upvotes": 11,
      "discussionId": "679a7548805383520ce065f5"
    },
    "publishedAt": "2025-01-30T03:05:08.789Z",
    "title": "Exploring the sustainable scaling of AI dilemma: A projective study of corporations' AI environmental impacts",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.14334.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "644156da1a80f6d83cb1667c",
      "avatarUrl": "/avatars/106d30a576b0fb58118ac4333b17260b.svg",
      "fullname": "Clement Desroches",
      "name": "clementdesroches",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2501.17749",
      "authors": [
        {
          "_id": "679ae5eab898ac90bf4480b6",
          "user": {
            "_id": "657b3a44de028a439ea2ed9d",
            "avatarUrl": "/avatars/9f05e8eb6809a0ce1b50cd1fc9b5a044.svg",
            "isPro": false,
            "fullname": "Aitor Arrieta",
            "user": "aitorarrieta",
            "type": "user"
          },
          "name": "Aitor Arrieta",
          "status": "extracted_confirmed",
          "statusLastChangedAt": "2025-01-30T08:45:20.561Z",
          "hidden": false
        },
        {
          "_id": "679ae5eab898ac90bf4480b7",
          "name": "Miriam Ugarte",
          "hidden": false
        },
        {
          "_id": "679ae5eab898ac90bf4480b8",
          "user": {
            "_id": "65001514f322f9156663f096",
            "avatarUrl": "/avatars/e8712f60d4e8b7c70ac02c532ad547ef.svg",
            "isPro": false,
            "fullname": "Pablo Valle",
            "user": "pablovalle",
            "type": "user"
          },
          "name": "Pablo Valle",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-30T09:39:30.629Z",
          "hidden": false
        },
        {
          "_id": "679ae5eab898ac90bf4480b9",
          "user": {
            "_id": "63527de67e4cc3135fd16651",
            "avatarUrl": "/avatars/5eb8076d448d0b6746e256c24e1440e0.svg",
            "isPro": false,
            "fullname": "José Antonio Parejo Maestre",
            "user": "japarejo",
            "type": "user"
          },
          "name": "José Antonio Parejo",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-30T09:39:06.958Z",
          "hidden": false
        },
        {
          "_id": "679ae5eab898ac90bf4480ba",
          "user": {
            "_id": "6790d642a1863df579840ae3",
            "avatarUrl": "/avatars/a10a6f4af327c1bb67513c56d7f84820.svg",
            "isPro": false,
            "fullname": "Sergio Segura",
            "user": "ssegura",
            "type": "user"
          },
          "name": "Sergio Segura",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-01-30T02:37:35.516Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-29T16:36:53.000Z",
      "title": "OpenAI의 o3-mini의 초기 외부 안전성 검증: 배포 전 평가에서 얻은 피드백",
      "summary": "대 언어 모델(LLMs)는 우리 일상 생활의 중요한 부분을 이루고 있습니다. 그러나 이러한 모델은 개인의 프라이버시를 해칠 수 있으며, 편견을 유지하고 불실한 정보를 확산시키는 위험을 동반합니다. 이러한 위험은 책임 있는 기능을 보장하기 위해 강력한 안전 구조, 윤리적인 지침, 그리고 상세한 테스트의 필요성을 강조하고 있습니다. LLMs의 안전성은 기계 학습 모델로 동작하기 전에 일반 사용자에게 접근할 수 있게 되는 동안에, 상세하게 테스트하는 것이 중요합니다. 이 논문에서는 모던다고 대학과 세비리아 대학의 연구자들이 OpenAI의 새로운 o3-mini LLM에 대한 외부 안전 테스트의 경험을 보고하고 있습니다. 특히, 우리 도구인 ASTRAL을 사용하여, 최신의 불안정한 테스트 입력(즉, 프로ン퓰트)을 자동적으로 체계적으로 생성하고, 이를 사용하여 LLMs의 다양한 안전성 분류를 테스트하고 평가합니다. o3-mini beta 버전에 대해, 자동으로 생성하고 실행하였습니다. ASTRAL이 분류한 불안정한 테스트 케이스를 직접적으로 확인하였으며, 87건의 실제 불안정한 LLM의 행동의 인스턴스를 발견하였습니다. 이 최신 LLM의 기능 전에 발견한 중요한 인젝트와 발견을 특별히 언급합니다.",
      "upvotes": 7,
      "discussionId": "679ae5f0b898ac90bf44826c"
    },
    "publishedAt": "2025-01-29T21:38:42.464Z",
    "title": "Early External Safety Testing of OpenAI's o3-mini: Insights from the Pre-Deployment Evaluation",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.17749.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5860
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.17433",
      "authors": [
        {
          "_id": "679b1319f87b99a2a7c41e36",
          "user": {
            "_id": "67325283b318faa97f7ae5f7",
            "avatarUrl": "/avatars/2f83452768148b323c540c43ad695ee6.svg",
            "isPro": false,
            "fullname": "TianshengHuang",
            "user": "TianshengHuang",
            "type": "user"
          },
          "name": "Tiansheng Huang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-01-30T08:39:47.548Z",
          "hidden": false
        },
        {
          "_id": "679b1319f87b99a2a7c41e37",
          "user": {
            "_id": "6539cab119c3ef6679794706",
            "avatarUrl": "/avatars/a88691ff5a547c7a1384edcc615c8209.svg",
            "isPro": false,
            "fullname": "Sihao Hu",
            "user": "SihaoHu",
            "type": "user"
          },
          "name": "Sihao Hu",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-30T09:39:58.723Z",
          "hidden": false
        },
        {
          "_id": "679b1319f87b99a2a7c41e38",
          "user": {
            "_id": "647615b995a4dc98e58c24f2",
            "avatarUrl": "/avatars/7f73999246526c1aef4d019d5f5595ad.svg",
            "isPro": false,
            "fullname": "Fatih Ilhan",
            "user": "tawreos",
            "type": "user"
          },
          "name": "Fatih Ilhan",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-30T09:40:06.004Z",
          "hidden": false
        },
        {
          "_id": "679b1319f87b99a2a7c41e39",
          "user": {
            "_id": "65aae89948c718a57434db6f",
            "avatarUrl": "/avatars/6c0fae8dafad9b9265098a9bc3bfc102.svg",
            "isPro": false,
            "fullname": "selim tekin",
            "user": "sftekin25",
            "type": "user"
          },
          "name": "Selim Furkan Tekin",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-30T09:40:16.339Z",
          "hidden": false
        },
        {
          "_id": "679b1319f87b99a2a7c41e3a",
          "user": {
            "_id": "65c998005e17dbeaf147db84",
            "avatarUrl": "/avatars/6fb47b1e095971b93ff7dcd10369f926.svg",
            "isPro": false,
            "fullname": "Ling Liu",
            "user": "ling1119",
            "type": "user"
          },
          "name": "Ling Liu",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-30T09:40:37.075Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-29T06:24:58.000Z",
      "title": "바이러스: 규모가 큰 언어 모델을 통해 유해적인 미세 조정 공격",
      "summary": "최근의 연구에 따르면, 대규모 언어 모델(LLMs)은 유해한 미세 조정 공격에 취약하며, 일부 유해한 샘플에 대해 미세 조정되면 안전성 조정 능력이 손실됩니다. 위험 감소에는 일반적으로, 보호라인을 사용하여 미세 조정 전 유해한 샘플을 필터링하는 방법을 사용합니다. 이 논문에서는, 새로운 레드팀 미션을 설계하고, 보호라인의 모델링에 의한 데이터 필터링에 완전히 의존할 수 없다고 믿을 수 없습니다. 이 논문에서 제안된 공격 방법, ヴァイラス는, 유해한 데이터를 약간 변경하여 보호라인의 모델링을 회避할 수 있습니다. 실험 결과를 따르면, ヴァイラス가 최적화한 유해한 데이터는 보호라인에서 100%의 감지실패율을 나타내며, 동시에 우수한 공격 성능을 달성할 수 있습니다. 마지막으로, 이 논문에서 전달된 주요 메시지는, 유해한 미세 조정 공격에 대한 효과적인 해결책으로 보호라인의 모델링을 고려하는 것이 위험하다는 것입니다. 보호라인의 모델링은, 사전 학습된 LLMs의 고유한 안전성 문제를 해결할 수 없습니다. 코드는, https://github.com/git-disl/Virus에서 사용 가능합니다.",
      "upvotes": 2,
      "discussionId": "679b131bf87b99a2a7c41ede"
    },
    "publishedAt": "2025-01-30T01:30:18.013Z",
    "title": "Virus: Harmful Fine-tuning Attack for Large Language Models Bypassing Guardrail Moderation",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/67325283b318faa97f7ae5f7/1hJo5gEfGEXAwYB5a6yWY.png",
      "https://cdn-uploads.huggingface.co/production/uploads/67325283b318faa97f7ae5f7/8SaMXA1izw5vcfwtU2Nhj.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.17433.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "67325283b318faa97f7ae5f7",
      "avatarUrl": "/avatars/2f83452768148b323c540c43ad695ee6.svg",
      "fullname": "TianshengHuang",
      "name": "TianshengHuang",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2501.17195",
      "authors": [
        {
          "_id": "679ae7655c55250b48483742",
          "name": "Andrei Alexandru",
          "hidden": false
        },
        {
          "_id": "679ae7655c55250b48483743",
          "user": {
            "_id": "66e184e86048d62cd8fb4e52",
            "avatarUrl": "/avatars/dc459c692fe9fce0911fa1229df0aeee.svg",
            "isPro": false,
            "fullname": "Antonia Calvi",
            "user": "NinaCalvi",
            "type": "user"
          },
          "name": "Antonia Calvi",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-30T09:40:54.827Z",
          "hidden": false
        },
        {
          "_id": "679ae7655c55250b48483744",
          "name": "Henry Broomfield",
          "hidden": false
        },
        {
          "_id": "679ae7655c55250b48483745",
          "name": "Jackson Golden",
          "hidden": false
        },
        {
          "_id": "679ae7655c55250b48483746",
          "name": "Kyle Dai",
          "hidden": false
        },
        {
          "_id": "679ae7655c55250b48483747",
          "name": "Mathias Leys",
          "hidden": false
        },
        {
          "_id": "679ae7655c55250b48483748",
          "name": "Maurice Burger",
          "hidden": false
        },
        {
          "_id": "679ae7655c55250b48483749",
          "name": "Max Bartolo",
          "hidden": false
        },
        {
          "_id": "679ae7655c55250b4848374a",
          "name": "Roman Engeler",
          "hidden": false
        },
        {
          "_id": "679ae7655c55250b4848374b",
          "name": "Sashank Pisupati",
          "hidden": false
        },
        {
          "_id": "679ae7655c55250b4848374c",
          "name": "Toby Drane",
          "hidden": false
        },
        {
          "_id": "679ae7655c55250b4848374d",
          "name": "Young Sun Park",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-27T15:09:08.000Z",
      "title": "Atla Selene Mini: 일반 평가 모델",
      "summary": "アトラ・セレネ・ミニ, SLMJ(Small Language Model as a Judge)를 통해 가장 先端한小型언어모델을 평가자로 제공합니다. セレネ・ミニ는 일반적인 용도에 적합한 평가자로, 11개의 분포외 벤치마크에서 전체적인 성능에서 가장 뛰어난 SLMJ와 GPT-4o-mini을 초과하고 있습니다. 이는 절대 점수, 클래스 분류, 페어링 선호 태스크를 포함합니다. RewardBench에서 8B 생성기의 최고 점수를 기록하고, GPT-4o와 특수화된 평가자의 강력한 기준을 초과하고 있습니다. 이를 달성하기 위해, 공개 데이터셋을 합성적으로 생성된 평가에 강화하고, 필터링과 데이터셋의 제거를 통해 높은 품질을 보장하는 데이터 캐리톰 전략을 개발하였습니다. 모델은 직접 선호 최적화(DPO)와 관学学习 미세 조정(SFT)의 손실 함수를 조합하여 훈련되어, 높은 Prompt에 대한 평가자로 뛰어납니다. セレネ・ミニ는 금융 및 의료업의 데이터셋에서 전문가의 평가와 0샷 Agreement가 크게 향상되고, Prompt의 형식의 변화에 강건합니다. 초기의 결과를 통해, セレネ・ミニ는 라이브, 커뮤니티를 주도하는 Judge Arena에서 최상위 평가자로 평가되어 있습니다. 모델의 무게는 HuggingFace(https://hf.co/AtlaAI/Selene-1-Mini-Llama-3.1-8B)와 Ollama에서 공개되고, 광범위한 커뮤니티의 도입을 촉발하고 있습니다.",
      "upvotes": 2,
      "discussionId": "679ae76b5c55250b484838e0"
    },
    "publishedAt": "2025-01-29T21:44:37.041Z",
    "title": "Atla Selene Mini: A General Purpose Evaluation Model",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.17195.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5860
    },
    "isAuthorParticipating": false
  }
]