[
  {
    "paper": {
      "id": "2502.05173",
      "authors": [
        {
          "_id": "67a97a47174028234b74f687",
          "name": "Xilin Wei",
          "hidden": false
        },
        {
          "_id": "67a97a47174028234b74f688",
          "user": {
            "_id": "64f033ef82c6eea604c4da8b",
            "avatarUrl": "/avatars/51b93fea7fd68b4274ee03701245dcca.svg",
            "isPro": false,
            "fullname": "Liu Xiaoran",
            "user": "LiuXR",
            "type": "user"
          },
          "name": "Xiaoran Liu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-10T09:49:59.999Z",
          "hidden": false
        },
        {
          "_id": "67a97a47174028234b74f689",
          "user": {
            "_id": "63859cf3b2906edaf83af9f0",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63859cf3b2906edaf83af9f0/iUQm5FAomzqYi6fkqIn9F.jpeg",
            "isPro": false,
            "fullname": "Yuhang Zang",
            "user": "yuhangzang",
            "type": "user"
          },
          "name": "Yuhang Zang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-10T09:50:02.011Z",
          "hidden": false
        },
        {
          "_id": "67a97a47174028234b74f68a",
          "name": "Xiaoyi Dong",
          "hidden": false
        },
        {
          "_id": "67a97a47174028234b74f68b",
          "name": "Pan Zhang",
          "hidden": false
        },
        {
          "_id": "67a97a47174028234b74f68c",
          "name": "Yuhang Cao",
          "hidden": false
        },
        {
          "_id": "67a97a47174028234b74f68d",
          "name": "Jian Tong",
          "hidden": false
        },
        {
          "_id": "67a97a47174028234b74f68e",
          "name": "Haodong Duan",
          "hidden": false
        },
        {
          "_id": "67a97a47174028234b74f68f",
          "name": "Qipeng Guo",
          "hidden": false
        },
        {
          "_id": "67a97a47174028234b74f690",
          "name": "Jiaqi Wang",
          "hidden": false
        },
        {
          "_id": "67a97a47174028234b74f691",
          "name": "Xipeng Qiu",
          "hidden": false
        },
        {
          "_id": "67a97a47174028234b74f692",
          "name": "Dahua Lin",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-07T18:56:04.000Z",
      "title": "VideoRoPE: 어떤 조건이 좋은 비디오 로타리 포지션 인베딩을 생성하는가?",
      "summary": "로테이션 포지션 증거(RoPE) 및 그의 변체들은 긴 문맥을 이해할 수 있는 능력 때문에 광범위하게 사용되고 있지만, 1D RoPE를 이미지에 확장하여 복잡한 공간 시간 순서 구조를 갖는 이미지에서 여전히 개방된 도전으로 남아 있습니다. 본 연구에서는 RoPE의 효과적인 응용에 필요한 4가지 핵심적인 특성을 식별하고, 이전 연구에서 완전히 고려되지 않은 항목을 조사합니다. 분석의 일부에서, V-NIAH-D(비지컬 니드러 인 아 하이스택 웜 다이스트럭터)의 도전을 제안합니다. 이것은 V-NIAH에 주기적인 다이스트럭터를 추가하는 것입니다. V-NIAH-D의 임무는 이전의 RoPE의 변체가 적절한 시간 순서 차원을 부족하여, 다이스트럭터에 쉽게 오타를 일으키는 것을 보여주는 것입니다. 분석에 기반하여, VideoRoPE를 제안합니다. VideoRoPE는 공간 시간 순서 관계를 유지하기 위해 3D 구조를 설계합니다. VideoRoPE는 주기적인 진동을 억제하기 위해 저주파의 시간 순서 분배, 공간 대칭성을 유지하기 위해 경사 배치, 시간 순서와 공간 인덱스를 분리하기 위해 가변적인 시간 순서 공간을 특징으로 합니다. VideoRoPE는 긴 문맥 비디오 검색, 비디오 이해, 비디오 해너티브 등 다양한 하류 태스크에서 이전의 RoPE의 변체를 일치합니다. 코드는 https://github.com/Wiselnn570/VideoRoPE{https://github.com/Wiselnn570/VideoRoPE}에서 제공됩니다.",
      "upvotes": 32,
      "discussionId": "67a97a4a174028234b74f707"
    },
    "publishedAt": "2025-02-09T23:03:21.947Z",
    "title": "VideoRoPE: What Makes for Good Video Rotary Position Embedding?",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.05173.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64b4eec4faa3181a5eab9c46",
      "avatarUrl": "/avatars/bcc9bf5cbf67546ad2b4c9ec8b96ac96.svg",
      "fullname": "Jiaqi Wang",
      "name": "myownskyW7",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isMod": false,
      "followerCount": 15
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.04507",
      "authors": [
        {
          "_id": "67a98cd1b8b21202c9004628",
          "name": "Peiyuan Zhang",
          "hidden": false
        },
        {
          "_id": "67a98cd1b8b21202c9004629",
          "user": {
            "_id": "65416817271d3bc4d70f6745",
            "avatarUrl": "/avatars/55cc24918c62ab39540c4df813b026ef.svg",
            "isPro": false,
            "fullname": "Yongqi Chen",
            "user": "BrianChen1129",
            "type": "user"
          },
          "name": "Yongqi Chen",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-10T09:49:48.410Z",
          "hidden": false
        },
        {
          "_id": "67a98cd1b8b21202c900462a",
          "name": "Runlong Su",
          "hidden": false
        },
        {
          "_id": "67a98cd1b8b21202c900462b",
          "name": "Hangliang Ding",
          "hidden": false
        },
        {
          "_id": "67a98cd1b8b21202c900462c",
          "name": "Ion Stoica",
          "hidden": false
        },
        {
          "_id": "67a98cd1b8b21202c900462d",
          "name": "Zhenghong Liu",
          "hidden": false
        },
        {
          "_id": "67a98cd1b8b21202c900462e",
          "name": "Hao Zhang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-06T21:17:09.000Z",
      "title": "스ライディングタイル의 어텐션을 이용한 고속 비디오 생성",
      "summary": "Diffusion Transformers (DiTs)는 3D 전적주의를 사용하여 가장 先端的な 비디오 생성을 실현하지만, 계산 비용이 높습니다. 5초 동안의 720P 비디오를 생성할 때, 전적주의만 945초의 계산 시간 중 800초를 차지합니다. 본 논문에서는, 슬라이딩 스타일 어텐션 (STA)를 소개하여 이 문제를 해결합니다. STA는 사전 학습된 비디오 디퓨저 모델에서 어텐션 스코어가 주로 지역적인 3D 윈도우 내 집중되어 있는 것을 활용합니다. 지역적인 스펙트럴 시간 영역에 어텐션을 적용하여 전적주의에서의 비효율성을 줄입니다. 기존의 토큰별로 슬라이딩 윈도우 어텐션 (SWA)와 달리, STA는 새로운 하드웨어 인식의 슬라이딩 윈도우 설계를 사용하여 턴별로 동작하며 표현력을 유지하면서 하드웨어 효과적으로 됩니다. 인식 캔버스 수준의 조정을 수행하여, STA는 효율적인 2D/3D 슬라이딩 윈도우와 같은 어텐션 구현을 제공하며, 58.79%의 MFU를 달성합니다. 또한, STA는 FlashAttention-2 (FA2)를 2.8~17배, FlashAttention-3 (FA3)를 1.6~10배 고속화합니다. 先端의 비디오 DiT에서, STA는 최종적으로 945초에서 685초까지의 라틴티어를 억제하며, 질의 변화 없이 실행됩니다. 훈련 없이 실행 가능합니다. 최종 튜닝을 수행하여, 라틴티어는 268초로 억제되며, VBench의 디퓨저의 오차는 0.09%로 허용됩니다.",
      "upvotes": 30,
      "discussionId": "67a98cd7b8b21202c90047c5"
    },
    "publishedAt": "2025-02-10T00:22:26.568Z",
    "title": "Fast Video Generation with Sliding Tile Attention",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.04507.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "63565cc56d7fcf1bedb7d347",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63565cc56d7fcf1bedb7d347/XGcHP4VkO_oieA1gZ4IAX.jpeg",
      "fullname": "Zhang Peiyuan",
      "name": "PY007",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 80
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.05176",
      "authors": [
        {
          "_id": "67a9889dc1fbde5146aba8b1",
          "name": "Chung-Ho Wu",
          "hidden": false
        },
        {
          "_id": "67a9889dc1fbde5146aba8b2",
          "name": "Yang-Jung Chen",
          "hidden": false
        },
        {
          "_id": "67a9889dc1fbde5146aba8b3",
          "name": "Ying-Huan Chen",
          "hidden": false
        },
        {
          "_id": "67a9889dc1fbde5146aba8b4",
          "name": "Jie-Ying Lee",
          "hidden": false
        },
        {
          "_id": "67a9889dc1fbde5146aba8b5",
          "name": "Bo-Hsu Ke",
          "hidden": false
        },
        {
          "_id": "67a9889dc1fbde5146aba8b6",
          "name": "Chun-Wei Tuan Mu",
          "hidden": false
        },
        {
          "_id": "67a9889dc1fbde5146aba8b7",
          "name": "Yi-Chuan Huang",
          "hidden": false
        },
        {
          "_id": "67a9889dc1fbde5146aba8b8",
          "name": "Chin-Yang Lin",
          "hidden": false
        },
        {
          "_id": "67a9889dc1fbde5146aba8b9",
          "user": {
            "_id": "64ae22dd1aee69ece065cdcd",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64ae22dd1aee69ece065cdcd/JG7QaHIrr4i2k4uwR4pZK.png",
            "isPro": false,
            "fullname": "Min-Hung Chen",
            "user": "cmhungsteve",
            "type": "user"
          },
          "name": "Min-Hung Chen",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-10T09:49:50.370Z",
          "hidden": false
        },
        {
          "_id": "67a9889dc1fbde5146aba8ba",
          "name": "Yen-Yu Lin",
          "hidden": false
        },
        {
          "_id": "67a9889dc1fbde5146aba8bb",
          "name": "Yu-Lun Liu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-07T18:59:55.000Z",
      "title": "アウラフュージョン360: 참고에 기반한 360도 제한 없는 스케어 임플레시션에서 보이지 않는 영역의 어레이멘트",
      "summary": "3D 스케언 인풋팅은 가상현실부터 건축 시각화까지 다양한 응용 분야에서 중요하지만, 현재의 방법들은 360도 무제한 스케언에서의 관점 일관성과 기하 정확도에서 어려움을 겪고 있습니다. 우리는 3D 스케언에서 고품질의 객체 제거와 결함 채우기를 가능하게 하는 새로운 참조 기반의 방법, AuraFusion360를 소개합니다. 우리의 접근 방법은 다음과 같습니다: (1) 측정된 은닉 부분의 생성, 정확한 감막 인식을 위해, (2) 적응적 가이드 드피스 디퓨저, 추가적인 훈련을 필요로 하지 않는 정확한 초기점 설정을 위한 0샷 방법, (3) SDEdit에 기반한 세부 확장, 다시점 일관성을 보장하는 방법입니다. 또한, 360-USID, 360도 무제한 스케언 인풋팅의 실제 데이터를 포함하는 첫 번째 상세 데이터셋을 소개합니다. 광범위한 실험에 따라, AuraFusion360는 현재의 방법을 크게 초월하며, 관점 변화에 따른 위치 정확도를 유지하면서, 고품질의 시각적 품질을 달성합니다. 프로젝트 페이지에서, 비디오 결과와 데이터셋을 볼 수 있습니다.",
      "upvotes": 18,
      "discussionId": "67a988a4c1fbde5146abaa3b"
    },
    "publishedAt": "2025-02-10T00:05:28.205Z",
    "title": "AuraFusion360: Augmented Unseen Region Alignment for Reference-based 360° Unbounded Scene Inpainting",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/6459d5da3b6fafd9664807ab/KMKt5j_3UB0zDhxjSiyxI.mp4"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.05176.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "6459d5da3b6fafd9664807ab",
      "avatarUrl": "/avatars/57430d1bbde3a2fe5586e5fbcafb0e74.svg",
      "fullname": "Yu-Lun Liu",
      "name": "yulunliu",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 3
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.04896",
      "authors": [
        {
          "_id": "67a983ea9b72585dd12587fb",
          "user": {
            "_id": "6412a33900634c4fe9873652",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6412a33900634c4fe9873652/Nmn_yRA1gGD2VO1YbSOYF.jpeg",
            "isPro": false,
            "fullname": "Shoufa Chen",
            "user": "ShoufaChen",
            "type": "user"
          },
          "name": "Shoufa Chen",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-10T09:49:52.136Z",
          "hidden": false
        },
        {
          "_id": "67a983ea9b72585dd12587fc",
          "name": "Chongjian Ge",
          "hidden": false
        },
        {
          "_id": "67a983ea9b72585dd12587fd",
          "name": "Yuqi Zhang",
          "hidden": false
        },
        {
          "_id": "67a983ea9b72585dd12587fe",
          "name": "Yida Zhang",
          "hidden": false
        },
        {
          "_id": "67a983ea9b72585dd12587ff",
          "name": "Fengda Zhu",
          "hidden": false
        },
        {
          "_id": "67a983ea9b72585dd1258800",
          "name": "Hao Yang",
          "hidden": false
        },
        {
          "_id": "67a983ea9b72585dd1258801",
          "name": "Hongxiang Hao",
          "hidden": false
        },
        {
          "_id": "67a983ea9b72585dd1258802",
          "name": "Hui Wu",
          "hidden": false
        },
        {
          "_id": "67a983ea9b72585dd1258803",
          "name": "Zhichao Lai",
          "hidden": false
        },
        {
          "_id": "67a983ea9b72585dd1258804",
          "name": "Yifei Hu",
          "hidden": false
        },
        {
          "_id": "67a983ea9b72585dd1258805",
          "name": "Ting-Che Lin",
          "hidden": false
        },
        {
          "_id": "67a983ea9b72585dd1258806",
          "name": "Shilong Zhang",
          "hidden": false
        },
        {
          "_id": "67a983ea9b72585dd1258807",
          "name": "Fu Li",
          "hidden": false
        },
        {
          "_id": "67a983ea9b72585dd1258808",
          "name": "Chuan Li",
          "hidden": false
        },
        {
          "_id": "67a983ea9b72585dd1258809",
          "name": "Xing Wang",
          "hidden": false
        },
        {
          "_id": "67a983ea9b72585dd125880a",
          "name": "Yanghua Peng",
          "hidden": false
        },
        {
          "_id": "67a983ea9b72585dd125880b",
          "name": "Peize Sun",
          "hidden": false
        },
        {
          "_id": "67a983ea9b72585dd125880c",
          "name": "Ping Luo",
          "hidden": false
        },
        {
          "_id": "67a983ea9b72585dd125880d",
          "name": "Yi Jiang",
          "hidden": false
        },
        {
          "_id": "67a983ea9b72585dd125880e",
          "name": "Zehuan Yuan",
          "hidden": false
        },
        {
          "_id": "67a983ea9b72585dd125880f",
          "name": "Bingyue Peng",
          "hidden": false
        },
        {
          "_id": "67a983ea9b72585dd1258810",
          "name": "Xiaobing Liu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-07T13:03:55.000Z",
      "title": "悟空: Floor-based Video Generative Foundation Model",
      "summary": "이 논문에서는 최신 프레임워크인 Goku를 소개합니다. Goku는 정규화 폼 트랜스포머를 사용하여 이미지와 비디오의 생성을 동시에 수행하는 가장 선진적인 모델 시리즈로, 업계 최고 성능을 실현하고 있습니다. 고품질의 시각화 생성을 가능하게 하는 기초적인 요소를 자세히 설명합니다. 그 중 데이터 캐리팅 파이프라인, 모델 아키텍처 설계, 폼의 공식화, 그리고 대규모 훈련의 효율적이고 강력한 인프라가 포함됩니다. Goku 모델은 질적 및 양적인 평가에서 최상위 성능을 보여주며, 주요 태스크 모두에 새로운 벤치마크를 설정하고 있습니다. 특히, GenEval에서 0.76, DPG-Bench에서 83.65, VBench에서 84.85의 점수를 달성했습니다. 우리는 이 연구에서 편의점 이미지와 비디오 생성 모델의 개발에 유효한 조언과 실용적인 발전을 제공하여 믿습니다.",
      "upvotes": 14,
      "discussionId": "67a983ee9b72585dd125890f"
    },
    "publishedAt": "2025-02-09T23:43:39.239Z",
    "title": "Goku: Flow Based Video Generative Foundation Models",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.04896.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5997
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.05003",
      "authors": [
        {
          "_id": "67a9b1a69a99341e859c488d",
          "user": {
            "_id": "623753b5eddd7763adc9346a",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/623753b5eddd7763adc9346a/rcpQAKZNrkn1-tMtraQBX.jpeg",
            "isPro": false,
            "fullname": "Andrei Panferov",
            "user": "BlackSamorez",
            "type": "user"
          },
          "name": "Andrei Panferov",
          "status": "extracted_confirmed",
          "statusLastChangedAt": "2025-02-10T08:09:18.686Z",
          "hidden": false
        },
        {
          "_id": "67a9b1a69a99341e859c488e",
          "name": "Jiale Chen",
          "hidden": false
        },
        {
          "_id": "67a9b1a69a99341e859c488f",
          "user": {
            "_id": "632a2e325f2ff1958c0103be",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/632a2e325f2ff1958c0103be/Tb0ql9e4LcaFktTK1hzqe.jpeg",
            "isPro": false,
            "fullname": "Soroush Tabesh",
            "user": "soroushtabesh",
            "type": "user"
          },
          "name": "Soroush Tabesh",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-10T09:49:37.573Z",
          "hidden": false
        },
        {
          "_id": "67a9b1a69a99341e859c4890",
          "name": "Roberto L. Castro",
          "hidden": false
        },
        {
          "_id": "67a9b1a69a99341e859c4891",
          "user": {
            "_id": "6526b8ebba9a8279c139616b",
            "avatarUrl": "/avatars/09f6b677603a03be128996a0765233e6.svg",
            "isPro": false,
            "fullname": "Mahdi Nikdan",
            "user": "mnikdan97",
            "type": "user"
          },
          "name": "Mahdi Nikdan",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-10T09:50:25.944Z",
          "hidden": false
        },
        {
          "_id": "67a9b1a69a99341e859c4892",
          "user": {
            "_id": "64ef52c2718f94ae8e78a5e7",
            "avatarUrl": "/avatars/d169f4ee62786a3eb4a3fa9d1fec52e9.svg",
            "isPro": false,
            "fullname": "Alistarh",
            "user": "d-alistarh",
            "type": "user"
          },
          "name": "Dan Alistarh",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-10T09:49:35.449Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-07T15:23:34.000Z",
      "title": "クエスト: 1비트의 무게와 활성화를 이용한 LLM의 안정화 훈련",
      "summary": "1개의 대규모 언어 모델(LLMs)의 큰 비용 감소 방법 중 하나는 훈련 또는 구현 시에 사용하는 퀀텀화 또는 스패르스 표현의 사용입니다. 훈련 후의 압축 메소드는 매우 인기가 있습니다. 그러나 이러한 표현을 직접 훈련하여 더 정확한 압축 모델을 얻을 수 있는지의 문제는 아직 여백 상태입니다. 예를 들어, 최근의 연구(arXiv:2411.04330v2)는 QAT(Quantization-Aware Training)로 모델을 훈련할 수 있는 \"최적\" 비트 폭이 표준의 FP16/BF16 정확도와 정확도 비교를 통해 8비트의 가중치와 활성화를 사용하는 것을 보여줍니다.\n\n우리는 이 최선으로 발전시키기 위해 새로운 방법인 QuEST를 사용합니다. 이것은 FP16과 비교하여 더 좋은 정확도를 제공하며, 모델 크기를 줄일 수 있으며, 가중치와 활성화를 4비트 이하로 할 수 있습니다. 또한 QuEST는 1비트의 가중치와 활성화를 사용하여 안정적인 훈련을 가능하게 합니다. QuEST는 QAT 메소드의 두 가지 핵심을 개선하여 이를 실현합니다. (1) Hadamard 정규화와 MSE 최적화로 정확한 및 빠른 분포의 퀀텀화, (2) 퀀텀화 상태에서 계산되는 노이즈가 없는 경사도와 \"실제\" (하지만 모르는) 전체 정밀도 경사도의 오차를 명시적으로 최소화하는 새로운 신뢰 경사도 평가기 기반입니다. Llama 타입의 아키텍처에 대한 실험은 QuEST가 실행할 수 있는 모델을 효율적으로 실행할 수 있음을 보여주고, 이는 스패르스 표현에 확장할 수 있습니다. GPU 키보드 지원은 QuEST로 생성된 모델을 효율적으로 실행할 수 있음을 보여주며, 코드는 https://github.com/IST-DASLab/QuEST에 제공됩니다.",
      "upvotes": 11,
      "discussionId": "67a9b1a79a99341e859c48c7"
    },
    "publishedAt": "2025-02-10T03:00:12.065Z",
    "title": "QuEST: Stable Training of LLMs with 1-Bit Weights and Activations",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.05003.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64ef52c2718f94ae8e78a5e7",
      "avatarUrl": "/avatars/d169f4ee62786a3eb4a3fa9d1fec52e9.svg",
      "fullname": "Alistarh",
      "name": "d-alistarh",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 5
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.05163",
      "authors": [
        {
          "_id": "67a9604851169a582d14c113",
          "user": {
            "_id": "642f4c789b2484d7d8551a93",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/642f4c789b2484d7d8551a93/0lH4YXcbZa-Xlzj6ESo7F.jpeg",
            "isPro": true,
            "fullname": "Yihe Deng",
            "user": "ydeng9",
            "type": "user"
          },
          "name": "Yihe Deng",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-10T09:50:06.136Z",
          "hidden": false
        },
        {
          "_id": "67a9604851169a582d14c114",
          "name": "Yu Yang",
          "hidden": false
        },
        {
          "_id": "67a9604851169a582d14c115",
          "name": "Junkai Zhang",
          "hidden": false
        },
        {
          "_id": "67a9604851169a582d14c116",
          "name": "Wei Wang",
          "hidden": false
        },
        {
          "_id": "67a9604851169a582d14c117",
          "name": "Bo Li",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-07T18:45:03.000Z",
      "title": "듀오가드: 2인용 RL 드라이브 프레임워크의 다언어 LLM 보호기\n\n(注意：虽然要求保持专业性和准确性，但“RL 드라이브 프레임워크”可能需要根据具体上下文进行调整，以确保最准确的翻译。如果“RL 드라이브 프레임워크”指的是某种特定的技术或框架，请提供更多背景信息以便进行更精确的翻译。)",
      "summary": "대 언어 모델(LLMs)의 급속한 발전에 따라, 책임적인 사용에 대한 댓가리 라인 모델의 필요성이 증가하고 있습니다. 특히, 불안정하고 불법적인 콘텐츠의 감지 분야에서 이 중요성이 더욱 높아졌습니다. 영어에서 안전 데이터가 풍부하다는 것은 알려져 있습니다. 그러나 다른 언어의 오픈 소스 안전 데이터의 부족으로 인해, 다언어 댓가리 라인 모델의 연구는 아직 이루어지지 않았습니다. 이러한 공백을 메우기 위해, 우리는 새로운 2명의 플레이어의 강화 학습(RL) 프레임워크를 제안합니다. 이 프레임워크에서, 생성자와 댓가리 라인 모델이 상호 대립적으로 진화하며, 다언어 댓가리 라인 훈련을 위한 고품질의 합성 데이터를 생성하는 것을 목표로 합니다. 이 상호작용을 이론적으로 정규화하고, 나시샴 균형을 이루는 것을 증명했습니다. 실험적 평가에 따르면, 우리의 모델 \\ours는 가장 선진 모델을 초월하며, LlamaGuard3(8B)에 비해 약 10%의 개선을 달성하고, 추론 속도는 4.5배 빠르고, 모델 크기는 0.5B입니다. 다언어 안전 태스크에서, 특히 수집된 실제 데이터에서 자원 풍부한 언어의 불균형을 해결할 수 있었습니다. 소멸 조사는, 합성 데이터의 생성이 오픈 소스 데이터의 불균형을 구체적으로 하기 위한 중요성을 강조합니다. 이러한 발견은, 합성 데이터의 생성에 의한 scalable 및 효율적인 접근 방식을 권장하고, 다언어 댓가리 라인 모델의 개선에 의한 LLM의 안전성 향상에 연결하는 것을 보여줍니다. 코드, 모델, 데이터는 https://github.com/yihedeng9/DuoGuard 에서 오픈 소스화 됩니다.",
      "upvotes": 11,
      "discussionId": "67a9604951169a582d14c14d"
    },
    "publishedAt": "2025-02-10T00:43:32.191Z",
    "title": "DuoGuard: A Two-Player RL-Driven Framework for Multilingual LLM Guardrails",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.05163.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "642f4c789b2484d7d8551a93",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/642f4c789b2484d7d8551a93/0lH4YXcbZa-Xlzj6ESo7F.jpeg",
      "fullname": "Yihe Deng",
      "name": "ydeng9",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isMod": false,
      "followerCount": 8
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.05171",
      "authors": [
        {
          "_id": "67a97e27495b23306cd5ea56",
          "name": "Jonas Geiping",
          "hidden": false
        },
        {
          "_id": "67a97e27495b23306cd5ea57",
          "name": "Sean McLeish",
          "hidden": false
        },
        {
          "_id": "67a97e27495b23306cd5ea58",
          "name": "Neel Jain",
          "hidden": false
        },
        {
          "_id": "67a97e27495b23306cd5ea59",
          "name": "John Kirchenbauer",
          "hidden": false
        },
        {
          "_id": "67a97e27495b23306cd5ea5a",
          "name": "Siddharth Singh",
          "hidden": false
        },
        {
          "_id": "67a97e27495b23306cd5ea5b",
          "name": "Brian R. Bartoldson",
          "hidden": false
        },
        {
          "_id": "67a97e27495b23306cd5ea5c",
          "name": "Bhavya Kailkhura",
          "hidden": false
        },
        {
          "_id": "67a97e27495b23306cd5ea5d",
          "name": "Abhinav Bhatele",
          "hidden": false
        },
        {
          "_id": "67a97e27495b23306cd5ea5e",
          "name": "Tom Goldstein",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-07T18:55:02.000Z",
      "title": "테스트타임 컴퓨팅의 스케일링을 은닉 이유론으로 실현하는 방법: 재커렐트 데피스 접근법",
      "summary": "우리는 검사 시의 계산을 숨겨서 구현할 수 있는 새로운 언어 모델 아키텍처를 연구하고 있습니다. 우리 모델은 재귀 블록을 반복하여 작동하며, 검사 시에 임의의 깊이로 확장할 수 있습니다. 이는主流의 이유 모델과 비교하여, 토큰의 생성을 통해 계산을 확장하는 방식과 반대입니다. 우리 접근 방식은 체인 오브 스코트 기반의 접근과 다른 반면, 특수화된 훈련 데이터가 필요하지 않고, 작은 컨텍스트 윈도우와 함께 작동하며, 언어로 쉽게 표현할 수 없는 이유의 종류를 파악할 수 있습니다. 우리는 증명 모델을 35억 파라미터와 8000억 토큰으로 확장했습니다. 우리는 이러한 방식으로 얻은 모델이 이유 벤치마크의 성능을 개선할 수 있으며, 때로는 놀라울 정도로 개선되어, 계산 부하가 50억 파라미터와 같은 것을 보여주는 것을 확인했습니다.",
      "upvotes": 7,
      "discussionId": "67a97e29495b23306cd5eae5"
    },
    "publishedAt": "2025-02-09T23:19:16.714Z",
    "title": "Scaling up Test-Time Compute with Latent Reasoning: A Recurrent Depth Approach",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.05171.png",
    "numComments": 4,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5997
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.04403",
      "authors": [
        {
          "_id": "67a97c7542d4d2f92ee57d20",
          "name": "David Abel",
          "hidden": false
        },
        {
          "_id": "67a97c7542d4d2f92ee57d21",
          "name": "André Barreto",
          "hidden": false
        },
        {
          "_id": "67a97c7542d4d2f92ee57d22",
          "name": "Michael Bowling",
          "hidden": false
        },
        {
          "_id": "67a97c7542d4d2f92ee57d23",
          "name": "Will Dabney",
          "hidden": false
        },
        {
          "_id": "67a97c7542d4d2f92ee57d24",
          "name": "Shi Dong",
          "hidden": false
        },
        {
          "_id": "67a97c7542d4d2f92ee57d25",
          "name": "Steven Hansen",
          "hidden": false
        },
        {
          "_id": "67a97c7542d4d2f92ee57d26",
          "name": "Anna Harutyunyan",
          "hidden": false
        },
        {
          "_id": "67a97c7542d4d2f92ee57d27",
          "name": "Khimya Khetarpal",
          "hidden": false
        },
        {
          "_id": "67a97c7542d4d2f92ee57d28",
          "name": "Clare Lyle",
          "hidden": false
        },
        {
          "_id": "67a97c7542d4d2f92ee57d29",
          "name": "Razvan Pascanu",
          "hidden": false
        },
        {
          "_id": "67a97c7542d4d2f92ee57d2a",
          "name": "Georgios Piliouras",
          "hidden": false
        },
        {
          "_id": "67a97c7542d4d2f92ee57d2b",
          "name": "Doina Precup",
          "hidden": false
        },
        {
          "_id": "67a97c7542d4d2f92ee57d2c",
          "name": "Jonathan Richens",
          "hidden": false
        },
        {
          "_id": "67a97c7542d4d2f92ee57d2d",
          "name": "Mark Rowland",
          "hidden": false
        },
        {
          "_id": "67a97c7542d4d2f92ee57d2e",
          "name": "Tom Schaul",
          "hidden": false
        },
        {
          "_id": "67a97c7542d4d2f92ee57d2f",
          "name": "Satinder Singh",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-06T08:34:57.000Z",
      "title": "Agency Is Frame-Dependent\n\n기관은 프레임에 의존합니다.",
      "summary": "안녕하세요. 아래는 제공된 영문 텍스트를 한국어로 번역한 결과입니다.\n\n\"안녕하세요. 아제네시(Agency)는 시스템이 목적에 대한 결과를 제어하는 기능을 지닌 것으로, 생물학, 철학, 인지과학, 인공 지능의 각 분야에서 핵심적인 연구 과제 중 하나입니다. 아제네시를 가지고 있는지를 판단하는 것은 매우 어려운 문제로, 딥넷(Dennett, 1989)은 암석, 사이버그, 로보트 각각이 아제네시를 가지고 있는지를 판단하는 원리인 미지의 문제를 제기하고 있습니다. 우리는 이 미지의 문제를 해결하기 위해 강화학습(Reinforcement Learning)의 관점에서 접근합니다. 아제네시는 근본적으로 프레임 의존성을 가진다고 주장하는 것으로, 시스템의 아제네시를 측정하기 위해서는 참조 프레임에 대한 측정이 필요함을 주장합니다. 이를 지지하기 위해, 밴다라나(Banderara, 2009)와 모레노(Moreno, 2018)가 제안한 아제네시의 기본적인 특성 각각이 프레임 의존성을 가지고 있음을 논리적으로 증명하고 있습니다. 아제네시의 기본적인 과학은 프레임 의존성을 필요로 하는 것을 결론으로 하고, 이러한 주장에 대한 강화학습의 영향을 논의합니다.\"",
      "upvotes": 7,
      "discussionId": "67a97c7642d4d2f92ee57d77"
    },
    "publishedAt": "2025-02-09T23:11:57.959Z",
    "title": "Agency Is Frame-Dependent",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.04403.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5997
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.04520",
      "authors": [
        {
          "_id": "67a97eea96d822bc6e13a1bb",
          "name": "Letian Peng",
          "hidden": false
        },
        {
          "_id": "67a97eea96d822bc6e13a1bc",
          "name": "Chenyang An",
          "hidden": false
        },
        {
          "_id": "67a97eea96d822bc6e13a1bd",
          "name": "Shibo Hao",
          "hidden": false
        },
        {
          "_id": "67a97eea96d822bc6e13a1be",
          "name": "Chengyu Dong",
          "hidden": false
        },
        {
          "_id": "67a97eea96d822bc6e13a1bf",
          "user": {
            "_id": "660655119e3555d648f6c6b5",
            "avatarUrl": "/avatars/ae1e2c97a08be39b77a9f1a5c2a718ef.svg",
            "isPro": false,
            "fullname": "Jingbo Shang",
            "user": "shangjingbo",
            "type": "user"
          },
          "name": "Jingbo Shang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-10T09:49:54.200Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-06T21:44:30.000Z",
      "title": "LM의 구성의 광범성 및 환상의 직선적인 상관관계",
      "summary": "언어 모델(LM)의 일반화는 능동적인 논의에 있으며, 일반적인 지능의 가능성과 기본적인 지식 구성의 고충(예: 역전/전환의 암시록)을 비교하고 있습니다. 본 논문은 LM의 지식 구성기의 선형상관 현상을 밝혀냅니다. 특히, 특정의 연관 지식 사이에 존재하는 선형변환은 Prompt 사이에서 다음 토큰 예측 로지스틱을 매핑합니다. 예를 들어, 「X lives in the city of」→「X lives in the country of」와 같은 것입니다. 이는 인간의 지식 구성의 선형성을 모방합니다. 우리가 발견한 것은 대규모의 미세 조정에 대한 긍정적이고, 현실적인 관계와 일치하는 경우 업데이트된 지식의 일반화에 사용되며, 편차하는 경우는 혐오쇼를 불러일으키는 것입니다. 실험 결과를 통해 선형상관은 LM의 일반화에 잠재적인 식별자 역할을 하는 것을 보여줍니다. 마지막으로, 이 선형상관은 단일의 전향 네트워크와 사전 학습된 단어 표현으로 학습될 수 있으며, LM의 일반화에 크게 의존하는 것을 보여줍니다.",
      "upvotes": 6,
      "discussionId": "67a97eea96d822bc6e13a1e7"
    },
    "publishedAt": "2025-02-09T23:22:06.784Z",
    "title": "Linear Correlation in LM's Compositional Generalization and Hallucination",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.04520.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5997
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.05179",
      "authors": [
        {
          "_id": "67a9901cc0310368e2488929",
          "name": "Shilong Zhang",
          "hidden": false
        },
        {
          "_id": "67a9901cc0310368e248892a",
          "name": "Wenbo Li",
          "hidden": false
        },
        {
          "_id": "67a9901cc0310368e248892b",
          "user": {
            "_id": "6412a33900634c4fe9873652",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6412a33900634c4fe9873652/Nmn_yRA1gGD2VO1YbSOYF.jpeg",
            "isPro": false,
            "fullname": "Shoufa Chen",
            "user": "ShoufaChen",
            "type": "user"
          },
          "name": "Shoufa Chen",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-10T09:49:46.264Z",
          "hidden": false
        },
        {
          "_id": "67a9901cc0310368e248892c",
          "name": "Chongjian Ge",
          "hidden": false
        },
        {
          "_id": "67a9901cc0310368e248892d",
          "name": "Peize Sun",
          "hidden": false
        },
        {
          "_id": "67a9901cc0310368e248892e",
          "name": "Yida Zhang",
          "hidden": false
        },
        {
          "_id": "67a9901cc0310368e248892f",
          "name": "Yi Jiang",
          "hidden": false
        },
        {
          "_id": "67a9901cc0310368e2488930",
          "name": "Zehuan Yuan",
          "hidden": false
        },
        {
          "_id": "67a9901cc0310368e2488931",
          "name": "Binyue Peng",
          "hidden": false
        },
        {
          "_id": "67a9901cc0310368e2488932",
          "name": "Ping Luo",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-07T18:59:59.000Z",
      "title": "FlashVideo: 플로팅 피더리티와 세부 피더리티를 결합하여 효율적인 고해상도 비디오 생성에 적용하기",
      "summary": "DiT 拡散モデル는 텍스트로부터 애니메이션 생성에서 큰 성공을 거뒀으며, 모델 용량과 데이터 규모의 scalability를 활용하고 있습니다. 그러나 텍스트 프로ン퓰트에 맞는 고품질의 콘텐츠와 동작의 정확성을 구현하기 위해서는 큰 모델 파라미터와 많은 함수 평가(NFEs)가 필요합니다. 현실적이고 시각적으로 사랑받는 디테일은 일반적으로 고해상도 출력에 반영되어, 특히 단일 단계의 DiT 모델에서 계산 부담이 증가합니다. 이러한 문제를 해결하기 위해, 우리는 새로운 2단계 프레임워크인 FlashVideo를 제안하고 있습니다. FlashVideo는 프레임 내에서 모델 용량과 NFEs를 전략적으로 배분하여 생성의 정확성과 질을 균형을 이루는 것을 목표로 합니다. 1단계에서는 저해상도 생성 프로세스를 활용하여 큰 파라미터와 충분한 NFEs를 사용하여 계산 효율성을 향상시키고 프로ン퓰트의 정확성을 우선시합니다. 2단계에서는 저해상도와 고해상도 사이에서 흐름 매칭을 설정하여 최소한의 NFEs를 사용하여 디테일을 생성합니다. 양의 결과를 통해, FlashVideo가 가장 先端的高해상도 애니메이션 생성을 실현하고 높은 계산 효율성을 보여주는 것을 보여줍니다. 또한 2단계의 설계는 사용자가 전체 해상도 생성에 대해 확정하기 전에 초기 출력을 미리보기 할 수 있도록 하여, 계산 비용과 대기 시간을 크게 줄이고 상업적 가능성도를 높일 수 있습니다.",
      "upvotes": 5,
      "discussionId": "67a9901ec0310368e24889c2"
    },
    "publishedAt": "2025-02-10T00:35:37.019Z",
    "title": "FlashVideo:Flowing Fidelity to Detail for Efficient High-Resolution Video Generation",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.05179.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5997
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.04363",
      "authors": [
        {
          "_id": "67a98180d0dc1ed664297368",
          "name": "Bosung Kim",
          "hidden": false
        },
        {
          "_id": "67a98180d0dc1ed664297369",
          "name": "Kyuhwan Lee",
          "hidden": false
        },
        {
          "_id": "67a98180d0dc1ed66429736a",
          "name": "Isu Jeong",
          "hidden": false
        },
        {
          "_id": "67a98180d0dc1ed66429736b",
          "name": "Jungmin Cheon",
          "hidden": false
        },
        {
          "_id": "67a98180d0dc1ed66429736c",
          "name": "Yeojin Lee",
          "hidden": false
        },
        {
          "_id": "67a98180d0dc1ed66429736d",
          "name": "Seulki Lee",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-05T05:42:29.000Z",
      "title": "소라(Sora)는 모바일 장치에서 분산 기반의 텍스트를 비디오로 생성할 수 있는 기술입니다.",
      "summary": "デバイス 상의 Sora를 소개합니다. 이것은, 스마트 폰 수준의 장치에서 효율적으로 동작하는, 확산 기반의 텍스트로부터의 비디오 생성의 선두적인 해결책입니다. Open-Sora에 기반하여, 장치 상의 Sora는 계산과 메모리에 제한된 모바일 장치에서 확산 기반의 텍스트로부터의 비디오 생성의 도전을 3가지의 새로운 기술로 해결합니다. 먼저, 선형 비례적인 점프(LPL)는, 비디오 확산에 필요한 과도한 디노이즈 스텝을 줄이기 위해 효율적인 점프 기반의 접근 방식을 사용합니다. 다음으로, 시간 차원 토큰 머지닝(TDTM)은, 注意 계층에서 연속된 토큰의 처리 계산을 최소화하기 위해, 시간 차원에 따라 연속된 토큰을 머지합니다. 그리고, 병렬 추론과 동적 로딩(CI-DL)은, 큰 모델을 작은 블록으로 동적으로 분할하여 메모리에 로딩하고 병렬적인 모델 추론을 수행하여, 장치 메모리의 제한을 효과적으로 해결합니다. iPhone 15 Pro 상에서 On-device Sora를 구현하고, 실험적 평가에 따라, 이것은 고품질의 비디오를 생성할 수 있으며, 고급 GPU로 실행된 Open-Sora와 비교하여 비슷한 것을 생성할 수 있음을 보여주었습니다. 이러한 결과를 통해, On-device Sora는 자원 제한된 모바일 장치에서 효율적이고 고품질의 비디오 생성이 가능하며, 접근성을 확장하고, 사용자 프라이버시를 보장하고, 클라우드 인프라 의존성을 줄이고, 관련 비용 감소를 보여주었습니다. On-device Sora의 제안은, 가장 선두의 생성 기술의 민주화를 위한 중요한 첫 번째 단계로 간주되어 있으며, 상품화된 모바일 및 내장 장치에서 비디오 생성 기능을 가능하게 합니다. 코드 구현은, GitHub 리포지토리에서 공개되어 있습니다: https://github.com/eai-lab/On-device-Sora.",
      "upvotes": 3,
      "discussionId": "67a98185d0dc1ed664297491"
    },
    "publishedAt": "2025-02-09T23:33:13.185Z",
    "title": "On-device Sora: Enabling Diffusion-Based Text-to-Video Generation for Mobile Devices",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.04363.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5997
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.04728",
      "authors": [
        {
          "_id": "67a97d1c02da0cdf059cb0d8",
          "name": "Zhouliang Yu",
          "hidden": false
        },
        {
          "_id": "67a97d1c02da0cdf059cb0d9",
          "name": "Yuhuan Yuan",
          "hidden": false
        },
        {
          "_id": "67a97d1c02da0cdf059cb0da",
          "name": "Tim Z. Xiao",
          "hidden": false
        },
        {
          "_id": "67a97d1c02da0cdf059cb0db",
          "name": "Fuxiang Frank Xia",
          "hidden": false
        },
        {
          "_id": "67a97d1c02da0cdf059cb0dc",
          "name": "Jie Fu",
          "hidden": false
        },
        {
          "_id": "67a97d1c02da0cdf059cb0dd",
          "user": {
            "_id": "638efcf4c67af472d316d424",
            "avatarUrl": "/avatars/97a57859d7d87a3a8f1bb41d32a72bc2.svg",
            "isPro": false,
            "fullname": "Ge Zhang",
            "user": "zhangysk",
            "type": "user"
          },
          "name": "Ge Zhang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-10T09:49:56.250Z",
          "hidden": false
        },
        {
          "_id": "67a97d1c02da0cdf059cb0de",
          "name": "Ge Lin",
          "hidden": false
        },
        {
          "_id": "67a97d1c02da0cdf059cb0df",
          "name": "Weiyang Liu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-07T07:52:25.000Z",
      "title": "테스트 시간 스케줄링에 의한 대규모 언어 모델을 통해 기호적인 세계 모델의 생성",
      "summary": "복잡한 계획 문제를 해결하기 위해, 대 언어 모델(LLMs)은 상태 변환을 명확하게 모델화하고 규칙 위반을 피하고 제약에 따라야 하며 최적성을 보장하는 것이 필요합니다. 이 문제는 자연어의 고유한 불확실성에 의해 방해되어 있습니다. 이러한 불확실성을 극복하기 위해, 계획 영역 정의 언어(PDDL)는 계획 추상화를 위해 사용되고 정확한 형식적인 상태 설명을 가능하게 합니다. PDDL을 사용하면, 우리들은 기호적인 세계 모델을 생성할 수 있으며, A*와 같은 고전적인 탐색 알고리즘을 쉽게 적용하여 최적의 계획을 찾을 수 있습니다. 그러나 현재의 LLMs는 직접 PDDL 영역을 생성하는 것은 PDDL의 훈련 데이터의 부족으로 인해 개방적인 문제를 남겨留在입니다. 이 문제를 해결하기 위해, 우리는 LLMs의 테스트 시의 계산을 확장하여 PDDL의 이유 능력을 높여, 고품질의 PDDL 영역의 생성을 가능하게 합니다. 특히, 우리는 간단하고 효과적인 알고리즘을 도입하여, N의 중의 가장 좋은 것을 선택하는 접근법을 사용하여 초기 해의 질을 개선하고, 기계 학습을 통해 해를 미세하게 개선합니다. 우리 방식은 자연어 설명으로부터 PDDL 영역을 생성하는 것과 PDDL 문제로부터 PDDL 영역을 생성하는 두 가지 모두에서 o1-mini를 크게 초월하며, 50% 이상의 성공률을 달성합니다. 이것은 추가적인 훈련이 필요하지 않습니다. PDDL을 상태 추상화에서 사용하는 것입니다. 우리 방식은 거의 모든 경쟁 수준의 계획 태스크에 대해 현재의 최선 방법을 초월할 수 있습니다.",
      "upvotes": 3,
      "discussionId": "67a97d1d02da0cdf059cb11a"
    },
    "publishedAt": "2025-02-09T23:17:42.258Z",
    "title": "Generating Symbolic World Models via Test-time Scaling of Large Language Models",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.04728.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5997
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.04404",
      "authors": [
        {
          "_id": "67a97bc5500b3bcf5babc5e8",
          "user": {
            "_id": "64bb3d1eb1a618880956da76",
            "avatarUrl": "/avatars/ec393b5eee8a3ccec61107b4aa63c4d9.svg",
            "isPro": false,
            "fullname": "Xiao-Wen Yang",
            "user": "yangxw",
            "type": "user"
          },
          "name": "Xiao-Wen Yang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-10T09:49:57.842Z",
          "hidden": false
        },
        {
          "_id": "67a97bc5500b3bcf5babc5e9",
          "name": "Xuan-Yi Zhu",
          "hidden": false
        },
        {
          "_id": "67a97bc5500b3bcf5babc5ea",
          "name": "Wen-Da Wei",
          "hidden": false
        },
        {
          "_id": "67a97bc5500b3bcf5babc5eb",
          "name": "Ding-Chu Zhang",
          "hidden": false
        },
        {
          "_id": "67a97bc5500b3bcf5babc5ec",
          "name": "Jie-Jing Shao",
          "hidden": false
        },
        {
          "_id": "67a97bc5500b3bcf5babc5ed",
          "name": "Zhi Zhou",
          "hidden": false
        },
        {
          "_id": "67a97bc5500b3bcf5babc5ee",
          "name": "Lan-Zhe Guo",
          "hidden": false
        },
        {
          "_id": "67a97bc5500b3bcf5babc5ef",
          "name": "Yu-Feng Li",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-06T08:52:43.000Z",
      "title": "스텝백 포로워드: 자동 리바ックト라킹에 의한 언어 모델의 추론력 향상",
      "summary": "LLM에서 쉼스템링 구조의 통합은, 예를 들어 OpenAI의 o1처럼 보일 수 있는 시스템으로, 레벨 2 AGI Reasoners를 달성하기 위한 바람직한 길을 제공합니다. 그러나 여러 중요한 문제들이 남아 있습니다. 그 중 하나는 무용지적 오버샘플링과 보조제어 모델의 과도한 의존성이 있습니다. 우리는 이러한 제한이 LLM이 탐색 프로세스를 내부화할 수 있는 능력이 없기 때문에 원인을 잦아줍니다. 이러한 문제를 해결하기 위한 중요한 단계 중 하나는 LLM이 자동으로 백트래킹할 시간과 장소를 결정할 수 있도록 허용하는 것입니다. 이 점에서, 우리는 LLM이 학습과 추론 모두에서 백트래킹할 수 있는 능력이 있는 자동 백트래킹 구조를 제안합니다. 이 구조는 자동 개선에 의해 쉼스템링 프로세스를 고속 쉼스템링으로 변환하고, 논리 능력과 효율을 향상시킵니다. 실험적 평가에 따르면, 우리의 제안은 최적 경로의 서브젝트 조정 방법 대비 40% 이상의 성능 향상을 달성합니다. 우리는 이 연구는 발전적이고 강력한 Reasoners의 개발에 새로운 방법론을 도입하고 있다고 믿습니다.",
      "upvotes": 2,
      "discussionId": "67a97bc7500b3bcf5babc64e"
    },
    "publishedAt": "2025-02-09T23:09:01.160Z",
    "title": "Step Back to Leap Forward: Self-Backtracking for Boosting Reasoning of Language Models",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.04404.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5997
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.04350",
      "authors": [
        {
          "_id": "67a97a77d163c9e6ea2bdb85",
          "name": "Yongchao Chen",
          "hidden": false
        },
        {
          "_id": "67a97a77d163c9e6ea2bdb86",
          "name": "Yilun Hao",
          "hidden": false
        },
        {
          "_id": "67a97a77d163c9e6ea2bdb87",
          "name": "Yueying Liu",
          "hidden": false
        },
        {
          "_id": "67a97a77d163c9e6ea2bdb88",
          "name": "Yang Zhang",
          "hidden": false
        },
        {
          "_id": "67a97a77d163c9e6ea2bdb89",
          "name": "Chuchu Fan",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-04T15:53:59.000Z",
      "title": "CodeSteer: 코드/텍스트 가이드라인에 의한 기호화된 언어 모델",
      "summary": "현재의 방법들은 대규모 언어 모델(LLMs)의 문자 논리와 코드 생성 사이에 효과적으로 제어할 수 없기 때문에, 기호 계산 능력이 과소 사용되어 있습니다. 우리는 CodeSteer라는 효과적인 방법을 소개하고, LLM의 코드/문자 생성을 가이드하는 것을 목표로 합니다. 우리는 37개의 기호적인 태스크를 포함하는 세부적인 벤치마크 SymBench를 구축하고, 12k의 다단계 가이드/생성 트래지와 5.5k의 가이드 비교 파스를 합성했습니다. 새로운 다단계 서브 프로젝트 감독 학습(SFT)과 직접적인 취미 최적화(DPO)를 사용하여 Llama-3-8B 모델을 미세 조정했습니다. 결과적으로 얻은 모델인 CodeSteerLLM은 제안된 기호 및 자동 응답 체크터를 추가하여, 큰 모델의 코드/문자 생성을 효과적으로 가이드할 수 있습니다. CodeSteer를 추가한 GPT-4o는 평균 성능 점수가 53.3에서 86.4로 상승하며, 모든 37개의 태스크(28개는 확인, 9개는 확인하지 않음)에서 현재 최고의 LLM인 OpenAI o1(82.7), o1-preview(74.8), DeepSeek R1(76.8)을 초과했습니다. CodeSteer를 훈련시킨 GPT-4o는 Claude, Mistral, GPT-3.5에 대한 평균 41.8의 성능 향상을 보여주었습니다. CodeSteer를 가이드하는 LLM은 높은 복잡한 태스크에서도 강한 성능을 유지하며, 기호 계산을 완전히 활용하고 있습니다. 모델, 데이터 세트, 코드는 다음 URL에서 사용 가능합니다: https://github.com/yongchao98/CodeSteer-v1.0.",
      "upvotes": 2,
      "discussionId": "67a97a79d163c9e6ea2bdc0c"
    },
    "publishedAt": "2025-02-09T23:03:14.294Z",
    "title": "CodeSteer: Symbolic-Augmented Language Models via Code/Text Guidance",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.04350.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5997
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.04689",
      "authors": [
        {
          "_id": "67a9b911b1f5eece682d7961",
          "user": {
            "_id": "64510a21f800611f94f0d9f8",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/lOeHK9Bvt3IXcB7Urx6jZ.jpeg",
            "isPro": false,
            "fullname": "Yuwei Yin",
            "user": "yuweiyin",
            "type": "user"
          },
          "name": "Yuwei Yin",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-10T09:49:32.672Z",
          "hidden": false
        },
        {
          "_id": "67a9b911b1f5eece682d7962",
          "name": "Giuseppe Carenini",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-07T06:30:33.000Z",
      "title": "ARR: 대규모 언어 모델을 활용한 질문응답 분석, 검색, 논리론리\n\n(Note: The original text \"ARR\" is not translated as it appears to be an acronym or identifier that is not intended to be translated into Korean.)",
      "summary": "대 언어 모델（LLMs）는 구조화된 어려운 벤치마크如 다 선택 대답（QA） 태스크에서 놀라울만한 성능을 달성합니다. Zero-shot Chain-of-Thought（CoT） 프로닝은 LLMs의 논리를 강화하지만, 이는 \"한 단계씩 생각\"과 일반적인 지침에 국한됩니다. 본 논문에서는 QA 해결의 3가지 핵심 단계를 명확히한 직관적이고 효과적인 Zero-shot 프로닝 방법인 ARR을 소개합니다. 이 단계는 문제의 의도를 분석, 관련 정보를 검색, 단계별로 이유를 제시합니다. 다양한 어려운 QA 태스크의 광범위한 실험은 ARR가 Baseline（ARR 프로닝을 포함하지 않은 것）을 일관적으로 개선하고 CoT을 초월하는 것을 보여주며, 제거 실험과 사례 연구는 분석, 검색, 이유의 각 구성 요소의 긍정적 기여를 한 번 더 증명합니다. 특히, ARR에서 의도 분석은 중요한 역할을 합니다. 또한, 모델 크기, LLM 시리즈, 생성 설정의 광범위한 범위에서 확장 평가는 ARR의 효과성, 강건성, 일반화 능력을 확립합니다.",
      "upvotes": 1,
      "discussionId": "67a9b911b1f5eece682d798c"
    },
    "publishedAt": "2025-02-10T03:30:51.974Z",
    "title": "ARR: Question Answering with Large Language Models via Analyzing, Retrieving, and Reasoning",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.04689.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64510a21f800611f94f0d9f8",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/lOeHK9Bvt3IXcB7Urx6jZ.jpeg",
      "fullname": "Yuwei Yin",
      "name": "yuweiyin",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 3
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.03512",
      "authors": [
        {
          "_id": "67a9a7cb6be3ca4a7ede471e",
          "name": "Amitava Das",
          "hidden": false
        },
        {
          "_id": "67a9a7cb6be3ca4a7ede471f",
          "name": "Yaswanth Narsupalli",
          "hidden": false
        },
        {
          "_id": "67a9a7cb6be3ca4a7ede4720",
          "name": "Gurpreet Singh",
          "hidden": false
        },
        {
          "_id": "67a9a7cb6be3ca4a7ede4721",
          "name": "Vinija Jain",
          "hidden": false
        },
        {
          "_id": "67a9a7cb6be3ca4a7ede4722",
          "name": "Vasu Sharma",
          "hidden": false
        },
        {
          "_id": "67a9a7cb6be3ca4a7ede4723",
          "name": "Suranjana Trivedy",
          "hidden": false
        },
        {
          "_id": "67a9a7cb6be3ca4a7ede4724",
          "user": {
            "_id": "63a4754927f1f64ed7238dac",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63a4754927f1f64ed7238dac/aH-eJF-31g4vof9jv2gmI.jpeg",
            "isPro": false,
            "fullname": "Aman Chadha",
            "user": "amanchadha",
            "type": "user"
          },
          "name": "Aman Chadha",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-10T09:49:39.550Z",
          "hidden": false
        },
        {
          "_id": "67a9a7cb6be3ca4a7ede4725",
          "name": "Amit Sheth",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-05T18:46:20.000Z",
      "title": "인양알라인：반대하는 목표의 벤치마크와 다목적 최적화를 기반으로 한 DPO의 제안",
      "summary": "T2I 시스템에서 매우 중요한 점으로, 생성된 이미지가 사용자의 의도를 정확히 이해하고 엄격한 윤리적 및 미학적 기준에 부합하는 것이 필수적이다. 예를 들어, Goolgle Jeimin처럼, 부적절한 출력이 대중적으로 반발되어 강력한 대응 구조의 필요성을 강조되었다. 반면, 대규모 언어 모델(LLMs)은 대응에 상당한 성공을 거두었다. 이러한 발전에 기반하여, 연구자들은 Direct Preference Optimization(DPO)과 같은 대응手法를 T2I 시스템에 적용하여 이미지 생성의 정확성과 신뢰성을 향상시키기를 희망하고 있다.\n\n우리는 YinYangAlign이라는 고급 벤치마크 프레임워크를 제안하고 있습니다. 이 것은 T2I 시스템의 대응의 정확성을 체계적으로 정량화하기 위해, 6가지 기본적이고 고유한 모순을 해결하는 설계 목표를 가지고 있습니다. 각 쌍은 이미지 생성의 기본적인 펫을 나타내며, 예를 들어, 사용자의 프롬프트에 따라 행동하는 것과 창의적인 변화의 균형을 이루는 것, 그리고 다양성과 시각적 일관성을 유지하는 것 등을 의미합니다. YinYangAlign은 인간의 프롬프트, 선택된 대응(선택)의 출력, 부적절한(거부) AI 생성의 출력, 그리고 그 뒤의 모순의 설명을 포함하는 세부적인 원리 데이터 세트를 가지고 있습니다.",
      "upvotes": 1,
      "discussionId": "67a9a7cf6be3ca4a7ede47d5"
    },
    "publishedAt": "2025-02-10T02:21:52.370Z",
    "title": "YINYANG-ALIGN: Benchmarking Contradictory Objectives and Proposing Multi-Objective Optimization based DPO for Text-to-Image Alignment",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.03512.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "63a4754927f1f64ed7238dac",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63a4754927f1f64ed7238dac/aH-eJF-31g4vof9jv2gmI.jpeg",
      "fullname": "Aman Chadha",
      "name": "amanchadha",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 3
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.05178",
      "authors": [
        {
          "_id": "67a99dfe98423dca45d8f659",
          "user": {
            "_id": "638fe91639f7e2a7f9d2a8c6",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/638fe91639f7e2a7f9d2a8c6/hB7DMVODcdAEUdQnXxWA8.jpeg",
            "isPro": false,
            "fullname": "Yue Zhao",
            "user": "zhaoyue-zephyrus",
            "type": "user"
          },
          "name": "Yue Zhao",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-10T09:49:43.493Z",
          "hidden": false
        },
        {
          "_id": "67a99dfe98423dca45d8f65a",
          "name": "Fuzhao Xue",
          "hidden": false
        },
        {
          "_id": "67a99dfe98423dca45d8f65b",
          "name": "Scott Reed",
          "hidden": false
        },
        {
          "_id": "67a99dfe98423dca45d8f65c",
          "name": "Linxi Fan",
          "hidden": false
        },
        {
          "_id": "67a99dfe98423dca45d8f65d",
          "name": "Yuke Zhu",
          "hidden": false
        },
        {
          "_id": "67a99dfe98423dca45d8f65e",
          "name": "Jan Kautz",
          "hidden": false
        },
        {
          "_id": "67a99dfe98423dca45d8f65f",
          "name": "Zhiding Yu",
          "hidden": false
        },
        {
          "_id": "67a99dfe98423dca45d8f660",
          "name": "Philipp Krähenbühl",
          "hidden": false
        },
        {
          "_id": "67a99dfe98423dca45d8f661",
          "name": "De-An Huang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-07T18:59:57.000Z",
      "title": "QLIP: 텍스트 대응 시각 토큰화는 자동적인 추론적 다모달 이해와 생성을 통합합니다.",
      "summary": "QLIP（Quantized Language-Image Pretraining）를 소개합니다. QLIP는 가장 先端의 재구성 품질과 가장 先端의 0-shot 이미지 이해를 통합한 시각적 토큰화 방법입니다. QLIP는 재구성과 언어 이미지의 어레이먼트의 목적을 가진 이분 구사면 양자화에 기반한 자동 인코더를 훈련합니다. 먼저, QLIP는 이 두 가지 목적이 충돌하지 않는 것을 보여주었습니다. QLIP는 훈련 중 이 두 가지 손실항목을 동적으로 균형을 조정하여, 이미지 언어 사전 학습의 큰 배치 요구와 재구성 목적에 의한 메모리 밴드 포인트를 더 효과적으로 혼합하기 위해 두 단계 훈련 플로우를 구현했습니다. QLIP의 효율성은 다 모델 이해와 문서 조건付き 이미지 생성에서 확인되었습니다. 특히, QLIP는 LLaVA의 시각적 인코더와 LlamaGen의 이미지 토큰화기 대신 사용될 수 있으며, 상대적으로 또는 더 좋은 성능을 나타냅니다. 마지막으로, QLIP는 이해와 생성을 위한 통합적인 혼합 모델을 구현하는 것을 보여주었습니다.",
      "upvotes": 1,
      "discussionId": "67a99dfe98423dca45d8f691"
    },
    "publishedAt": "2025-02-10T01:35:35.818Z",
    "title": "QLIP: Text-Aligned Visual Tokenization Unifies Auto-Regressive Multimodal Understanding and Generation",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.05178.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "638fe91639f7e2a7f9d2a8c6",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/638fe91639f7e2a7f9d2a8c6/hB7DMVODcdAEUdQnXxWA8.jpeg",
      "fullname": "Yue Zhao",
      "name": "zhaoyue-zephyrus",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 3
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.04376",
      "authors": [
        {
          "_id": "67a998fe495b23306cdbf51d",
          "name": "Lingxiang Hu",
          "hidden": false
        },
        {
          "_id": "67a998fe495b23306cdbf51e",
          "name": "Shurun Yuan",
          "hidden": false
        },
        {
          "_id": "67a998fe495b23306cdbf51f",
          "name": "Xiaoting Qin",
          "hidden": false
        },
        {
          "_id": "67a998fe495b23306cdbf520",
          "name": "Jue Zhang",
          "hidden": false
        },
        {
          "_id": "67a998fe495b23306cdbf521",
          "name": "Qingwei Lin",
          "hidden": false
        },
        {
          "_id": "67a998fe495b23306cdbf522",
          "name": "Dongmei Zhang",
          "hidden": false
        },
        {
          "_id": "67a998fe495b23306cdbf523",
          "name": "Saravan Rajmohan",
          "hidden": false
        },
        {
          "_id": "67a998fe495b23306cdbf524",
          "name": "Qi Zhang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-05T16:25:43.000Z",
      "title": "회의 대표: 회의를 진행하는 LLM 표준화를 대표합니다.",
      "summary": "현대의 노동장대에서는 회의는 아이디어의 교환과 팀의 조정에 필수적이지만, 시간 소모, 스케줄링의 충돌, 그리고 적절하지 않은 참여로 인한 효율 저하 등 여러 문제들이 존재합니다. 최근의 대규모 언어 모델(LLMs)의 발전은 강력한 자연어 생성과 추론 능력을 보여주며, \"LLMs는 회의의 참석자를 효과적으로 위탁할 수 있을까요?\"와 같은 질문이 제기되었습니다. 이를 조사하기 위해, 우리는 LLM 프로텍팅의 회의 위탁 시스템을 개발하고 실제 회의 트랜스스크립트를 사용하여 상세한 벤치마크를 만들었습니다. 평가 결과는 GPT-4/4o가 적극적이고 신중한 참여 전략의 균형을 유지하고, 대비적으로, Gemini 1.5 Pro는 더 신중한 경향을 보여주고, Gemini 1.5 Flash와 Llama3-8B/70B는 더 적극적인 경향을示しています. 전체적으로 약 60%의 답변은 사실의 핵심 포인트에서 적어도 1개를 다루는 것입니다. 그러나, 상관없는 내용이나 중복을 줄이고, 현실적인 환경에서 복사 오류의 견고성을 높일 필요가 있습니다. 또한, 실용적인 환경에서 시스템을 구현하고, Demo에서 현실적인 피드백을 수집했습니다. 우리의 발견은 LLMs를 회의 위탁에 활용할 수 있는 가능성과 문제점을 밝혀, 회의의 부담을 해결하기 위한 실용적인 애플리케이션에 대한 유익한 콘텐츠 제공을 목표로 합니다.",
      "upvotes": 1,
      "discussionId": "67a99900495b23306cdbf57e"
    },
    "publishedAt": "2025-02-10T01:15:52.070Z",
    "title": "MEETING DELEGATE: Benchmarking LLMs on Attending Meetings on Our Behalf",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.04376.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "662b0bc9c709a61df8291c0f",
      "avatarUrl": "/avatars/16dd4d945e9fbef5ac889a8087101ded.svg",
      "fullname": "Xiaoting Qin",
      "name": "XiaotingQin",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.03738",
      "authors": [
        {
          "_id": "67a8d049406cb5a65f847eb1",
          "name": "Feng Wang",
          "hidden": false
        },
        {
          "_id": "67a8d049406cb5a65f847eb2",
          "name": "Yaodong Yu",
          "hidden": false
        },
        {
          "_id": "67a8d049406cb5a65f847eb3",
          "name": "Guoyizhe Wei",
          "hidden": false
        },
        {
          "_id": "67a8d049406cb5a65f847eb4",
          "name": "Wei Shao",
          "hidden": false
        },
        {
          "_id": "67a8d049406cb5a65f847eb5",
          "name": "Yuyin Zhou",
          "hidden": false
        },
        {
          "_id": "67a8d049406cb5a65f847eb6",
          "name": "Alan Yuille",
          "hidden": false
        },
        {
          "_id": "67a8d049406cb5a65f847eb7",
          "name": "Cihang Xie",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-06T03:01:38.000Z",
      "title": "스케일링 라즈에서 패치 팩션： 이미지는 50,176 토큰보다 더 많은 가치를 지어います。",
      "summary": "ビジョントランスフォーマー(ViT)의 도입 이후, 패치 팩토리는 단순한 시각 아키텍처의 실질적인 이미지 토큰화 접근법으로 장기적으로 인정받았습니다. 이 방법은 이미지의 공간 크기를 압축하여 ViT와 같은 단순한 아키텍처의 계산 비용 효율적으로 줄일 수 있습니다. 본 논문에서는, 패치 팩토리에 의한 압축 압축 패턴에 따른 정보 손실을 상세히 조사하고, 이는 시각 이해에 어떤 영향을 미치는지 조사하는 것을 목표로 합니다. 광범위한 패치 크기 스케일링 실험을 수행하여, 패치 팩토리에서 관심점을 불러일으키는 관심점의 스케일링 법칙을 발견했습니다. 모델은 패치 크기를 줄이면 일관된 이익을 얻으며 예측 성능이 향상됩니다만, 1x1의 최소 패치 크기까지 도달하면 픽셀 토큰화가 됩니다. 이 결론은 다양한 시각 작업, 입력 스케일, ViT 및 최근의 Mamba 모델과 같은 다양한 아키텍처에 광범위하게 적용 가능합니다. 또한, 패치가 작아질수록 특정 작업에 대한 디코더 헤드는 밀집 예측에 대한 중요도가 낮아집니다. 실험에서는 이미지 시퀀스를 예외로 50,176 토큰으로 긴 것으로 확장하여, ImageNet-1k 벤치마크에서 기본 크기의 모델은 84.6%의 경쟁력 있는 테스트 정확도를 달성했습니다. 이 연구는 향후 비압축 시각 모델의 구축에 대한 피드백과 이론적 기초를 제공하기를 희망합니다. 코드는 https://github.com/wangf3014/Patch_Scaling 에 제공됩니다.",
      "upvotes": 0,
      "discussionId": "67a8d04a406cb5a65f847ed3"
    },
    "publishedAt": "2025-02-10T02:34:31.480Z",
    "title": "Scaling Laws in Patchification: An Image Is Worth 50,176 Tokens And More",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.03738.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "5f1158120c833276f61f1a84",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1608042047613-5f1158120c833276f61f1a84.jpeg",
      "fullname": "Niels Rogge",
      "name": "nielsr",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 754
    },
    "isAuthorParticipating": false
  }
]