[
  {
    "paper": {
      "id": "2507.07104",
      "authors": [
        {
          "_id": "686f95e9706a6ea4654189ff",
          "user": {
            "_id": "66e0b013733965882099cc37",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/66e0b013733965882099cc37/CkTK2kV2v-TfdYiwsW6Tx.jpeg",
            "isPro": true,
            "fullname": "Tiezheng Zhang",
            "user": "PatZhang11",
            "type": "user"
          },
          "name": "Tiezheng Zhang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-07-11T08:03:27.231Z",
          "hidden": false
        },
        {
          "_id": "686f95e9706a6ea465418a00",
          "name": "Yitong Li",
          "hidden": false
        },
        {
          "_id": "686f95e9706a6ea465418a01",
          "name": "Yu-cheng Chou",
          "hidden": false
        },
        {
          "_id": "686f95e9706a6ea465418a02",
          "name": "Jieneng Chen",
          "hidden": false
        },
        {
          "_id": "686f95e9706a6ea465418a03",
          "name": "Alan Yuille",
          "hidden": false
        },
        {
          "_id": "686f95e9706a6ea465418a04",
          "name": "Chen Wei",
          "hidden": false
        },
        {
          "_id": "686f95e9706a6ea465418a05",
          "user": {
            "_id": "64b5ba6060274cbb296d6288",
            "avatarUrl": "/avatars/67e0343954dda6e92ed3f6e7976f9f87.svg",
            "isPro": true,
            "fullname": "Junfei Xiao",
            "user": "lambertxiao",
            "type": "user"
          },
          "name": "Junfei Xiao",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-07-11T08:03:25.003Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-07-09T17:59:04.000Z",
      "submittedOnDailyAt": "2025-07-16T04:05:40.175Z",
      "title": "비전・런・비전 자동 인코더: 확장 가능한 지식 제공\n디퓨션 모델로부터",
      "submittedOnDailyBy": {
        "_id": "64b5ba6060274cbb296d6288",
        "avatarUrl": "/avatars/67e0343954dda6e92ed3f6e7976f9f87.svg",
        "isPro": true,
        "fullname": "Junfei Xiao",
        "user": "lambertxiao",
        "type": "user"
      },
      "summary": "ビジョン-言語モデル（VLMs）의 최신 구축에는 강력한 캡처 능력이 필수적입니다が、이것은 수십억의 고품질의 이미지-텍스트 페어의 훈련을 필요로 하며, 수십만대의 GPU 시간도 필요합니다. 본 논문에서는, Vision-Language-Vision (VLV) 자동 인코더 프레임워크를 통해 이 문제를 해결합니다. 이 프레임워크는 시각 인코더, Text-to-Image (T2I) 디퓨전 모델의 디코더, 그리고 라지언 언어 모델 (LLM)을 전략적으로 활용합니다. 특히, 언어 표현 공간을 정규화하고, 훈련된 T2I 디퓨전 디코더를 고정하여 정보 밴드포인트를 설정합니다. VLV 프로리프는, 연속적인 인코딩을 사용하여 텍스트 조건된 디퓨전 모델에서의 지식을 효과적으로 흡수하고, 고품질의 재구성을 통해 세부적인 설명을 수행할 수 있습니다. 또한, 제공된 LLM을 미세 조정하여, 중간 언어 표현을 세부적인 설명으로 변환하여, GPT-4o나 Gemini 2.0 Flash와 같은 첨단 캡처 기능을 구현합니다. 이 방법은 특히 비용 효율성이 높고, 데이터 요구가 크게 감소하며, 단일 모달 이미지를 주로 사용하며, 기존 제공된 모델 (그림 인코더, T2I 디퓨전 모델, LLM)의 최대 효율을 극대화합니다. 이미지-텍스트 페어 데이터 세트의 필요성을 회피하고, 총 훈련 비용은 1,000 달러를 초과하지 않도록 합니다.",
      "upvotes": 13,
      "discussionId": "686f95e9706a6ea465418a06",
      "projectPage": "https://lambert-x.github.io/Vision-Language-Vision/",
      "githubRepo": "https://github.com/Tiezheng11/Vision-Language-Vision",
      "ai_summary": "The VLV auto-encoder framework uses pretrained vision and text models to create a cost-effective and data-efficient captioning system.",
      "ai_keywords": [
        "Vision-Language Models",
        "VLV auto-encoder",
        "vision encoder",
        "Text-to-Image diffusion model",
        "Large Language Model",
        "information bottleneck",
        "continuous embeddings",
        "semantic understanding",
        "captioning",
        "fine-tuning",
        "GPT-4o",
        "Gemini 2.0 Flash"
      ],
      "githubStars": 19
    },
    "publishedAt": "2025-07-09T13:59:04.000Z",
    "title": "Vision-Language-Vision Auto-Encoder: Scalable Knowledge Distillation\n  from Diffusion Models",
    "summary": "Building state-of-the-art Vision-Language Models (VLMs) with strong\ncaptioning capabilities typically necessitates training on billions of\nhigh-quality image-text pairs, requiring millions of GPU hours. This paper\nintroduces the Vision-Language-Vision (VLV) auto-encoder framework, which\nstrategically leverages key pretrained components: a vision encoder, the\ndecoder of a Text-to-Image (T2I) diffusion model, and subsequently, a Large\nLanguage Model (LLM). Specifically, we establish an information bottleneck by\nregularizing the language representation space, achieved through freezing the\npretrained T2I diffusion decoder. Our VLV pipeline effectively distills\nknowledge from the text-conditioned diffusion model using continuous\nembeddings, demonstrating comprehensive semantic understanding via high-quality\nreconstructions. Furthermore, by fine-tuning a pretrained LLM to decode the\nintermediate language representations into detailed descriptions, we construct\na state-of-the-art (SoTA) captioner comparable to leading models like GPT-4o\nand Gemini 2.0 Flash. Our method demonstrates exceptional cost-efficiency and\nsignificantly reduces data requirements; by primarily utilizing single-modal\nimages for training and maximizing the utility of existing pretrained models\n(image encoder, T2I diffusion model, and LLM), it circumvents the need for\nmassive paired image-text datasets, keeping the total training expenditure\nunder $1,000 USD.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2507.07104.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64b5ba6060274cbb296d6288",
      "avatarUrl": "/avatars/67e0343954dda6e92ed3f6e7976f9f87.svg",
      "fullname": "Junfei Xiao",
      "name": "lambertxiao",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 6
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2507.11407",
      "authors": [
        {
          "_id": "68774564257d4f04353707dc",
          "name": "LG AI Research",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707de",
          "name": "Kyunghoon Bae",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707df",
          "name": "Eunbi Choi",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707e0",
          "name": "Kibong Choi",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707e1",
          "name": "Stanley Jungkyu Choi",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707e2",
          "name": "Yemuk Choi",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707e3",
          "name": "Kyubeen Han",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707e4",
          "name": "Seokhee Hong",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707e5",
          "name": "Junwon Hwang",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707e6",
          "name": "Taewan Hwang",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707e7",
          "name": "Joonwon Jang",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707e8",
          "name": "Hyojin Jeon",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707e9",
          "name": "Kijeong Jeon",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707ea",
          "name": "Gerrard Jeongwon Jo",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707eb",
          "name": "Hyunjik Jo",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707ec",
          "name": "Jiyeon Jung",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707ed",
          "name": "Euisoon Kim",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707ee",
          "name": "Hyosang Kim",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707ef",
          "name": "Jihoon Kim",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707f0",
          "name": "Joonkee Kim",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707f1",
          "name": "Seonghwan Kim",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707f2",
          "name": "Soyeon Kim",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707f3",
          "name": "Sunkyoung Kim",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707f4",
          "name": "Yireun Kim",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707f5",
          "name": "Yongil Kim",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707f6",
          "name": "Youchul Kim",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707f7",
          "name": "Edward Hwayoung Lee",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707f8",
          "name": "Gwangho Lee",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707f9",
          "name": "Haeju Lee",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707fa",
          "name": "Honglak Lee",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707fb",
          "name": "Jinsik Lee",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707fc",
          "name": "Kyungmin Lee",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707fd",
          "name": "Sangha Park",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707fe",
          "name": "Young Min Paik",
          "hidden": false
        },
        {
          "_id": "68774564257d4f04353707ff",
          "name": "Yongmin Park",
          "hidden": false
        },
        {
          "_id": "68774564257d4f0435370800",
          "name": "Youngyong Park",
          "hidden": false
        },
        {
          "_id": "68774564257d4f0435370801",
          "name": "Sanghyun Seo",
          "hidden": false
        },
        {
          "_id": "68774564257d4f0435370802",
          "name": "Sihoon Yang",
          "hidden": false
        },
        {
          "_id": "68774564257d4f0435370803",
          "name": "Heuiyeen Yeen",
          "hidden": false
        },
        {
          "_id": "68774564257d4f0435370804",
          "name": "Sihyuk Yi",
          "hidden": false
        },
        {
          "_id": "68774564257d4f0435370805",
          "name": "Hyeongu Yun",
          "hidden": false
        }
      ],
      "publishedAt": "2025-07-15T15:24:51.000Z",
      "submittedOnDailyAt": "2025-07-16T07:04:54.982Z",
      "title": "EXAONE 4.0: 논리론과 비논리론을 통합한 대규모 언어 모델",
      "submittedOnDailyBy": {
        "_id": "660260cf1737e5cd4a826550",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/660260cf1737e5cd4a826550/AlSfoM2WtqPjLtYR6x7Wf.jpeg",
        "isPro": false,
        "fullname": "Yireun Kim",
        "user": "yireun",
        "type": "user"
      },
      "summary": "이 기술보고서에서는 EXAONE 4.0를 소개합니다. EXAONE 4.0는 Non-reasoning 모드와 Reasoning 모드를 통합하여 EXAONE 3.5의 뛰어난 사용 가능성과 EXAONE Deep의 첨단 논리 능력 모두를 실현합니다. 효과적인 AI 시대를 위한 EXAONE 4.0는 에이전트 툴의 사용과 다언어 능력을 확장하며, 특수 기능을 추가합니다. EXAONE 4.0 모델 시리즈는 고성능을 최적화한 중형 32B 모델과, 온디바이스 애플리케이션을 위한 소형 1.2B 모델로 구성됩니다. EXAONE 4.0는 같은 클래스의 오픈 웨이트 모델보다 높은 성능을 보여주며, 고급 클래스 모델과 비교하여 경쟁력을 가지고 있습니다. 모델은 공개적으로 사용 가능합니다. 간단히 https://huggingface.co/LGAI-EXAONE에서 다운로드 가능합니다.",
      "upvotes": 11,
      "discussionId": "68774564257d4f0435370806",
      "ai_summary": "EXAONE 4.0 integrates non-reasoning and reasoning modes, supports multilingualism, and offers models optimized for high performance and on-device use, demonstrating superior performance compared to open-weight models.",
      "ai_keywords": [
        "Non-reasoning mode",
        "Reasoning mode",
        "agentic tool use",
        "multilingual capabilities",
        "mid-size model",
        "small-size model",
        "high performance",
        "on-device applications",
        "open-weight models",
        "frontier-class models"
      ]
    },
    "publishedAt": "2025-07-15T11:24:51.000Z",
    "title": "EXAONE 4.0: Unified Large Language Models Integrating Non-reasoning and\n  Reasoning Modes",
    "summary": "This technical report introduces EXAONE 4.0, which integrates a Non-reasoning\nmode and a Reasoning mode to achieve both the excellent usability of EXAONE 3.5\nand the advanced reasoning abilities of EXAONE Deep. To pave the way for the\nagentic AI era, EXAONE 4.0 incorporates essential features such as agentic tool\nuse, and its multilingual capabilities are extended to support Spanish in\naddition to English and Korean. The EXAONE 4.0 model series consists of two\nsizes: a mid-size 32B model optimized for high performance, and a small-size\n1.2B model designed for on-device applications. The EXAONE 4.0 demonstrates\nsuperior performance compared to open-weight models in its class and remains\ncompetitive even against frontier-class models. The models are publicly\navailable for research purposes and can be easily downloaded via\nhttps://huggingface.co/LGAI-EXAONE.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2507.11407.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "660260cf1737e5cd4a826550",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/660260cf1737e5cd4a826550/AlSfoM2WtqPjLtYR6x7Wf.jpeg",
      "fullname": "Yireun Kim",
      "name": "yireun",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 4
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2507.09404",
      "authors": [
        {
          "_id": "68774155257d4f04353707d3",
          "name": "Mustafa Shukor",
          "hidden": false
        },
        {
          "_id": "68774155257d4f04353707d4",
          "name": "Louis Bethune",
          "hidden": false
        },
        {
          "_id": "68774155257d4f04353707d5",
          "name": "Dan Busbridge",
          "hidden": false
        },
        {
          "_id": "68774155257d4f04353707d6",
          "name": "David Grangier",
          "hidden": false
        },
        {
          "_id": "68774155257d4f04353707d7",
          "name": "Enrico Fini",
          "hidden": false
        },
        {
          "_id": "68774155257d4f04353707d8",
          "name": "Alaaeldin El-Nouby",
          "hidden": false
        },
        {
          "_id": "68774155257d4f04353707d9",
          "name": "Pierre Ablin",
          "hidden": false
        }
      ],
      "publishedAt": "2025-07-12T21:16:08.000Z",
      "submittedOnDailyAt": "2025-07-16T04:39:10.654Z",
      "title": "최적의 데이터의 혼합의 스케일링 법칙",
      "submittedOnDailyBy": {
        "_id": "62bdeedd01dc22b4d22a371e",
        "avatarUrl": "/avatars/3cc0643feb53bf2e895ec12c275d5483.svg",
        "isPro": false,
        "fullname": "Mustafa Shukor",
        "user": "mshukor",
        "type": "user"
      },
      "summary": "대규모의 기초 모델은 일반적으로 여러 분야에서 온 데이터로 훈련되어 있으며, 이러한 데이터의 혼합비율(각 분야를 사용하는 비율)은 모델의 성능에 중요한 역할을 합니다. 이 혼합비율의 선택에 대한 표준적인 접근 방식은 시험과 오류에 의존하며, 대규모의 사전 훈련에 있어 실용적이지 않습니다. 우리는 스케일링 라즈를 사용하여 특정 타겟 분야에 대한 최적의 데이터 혼합비율을 결정하는 방법을 제안합니다. 우리 접근 방식은 모델의 크기 N, D 토큰, 그리고 특정 분야의 가중치 벡터 h를 사용하여 모델의 손실을 정확하게 예측할 수 있습니다. 우리는 이러한 스케일링 라즈의 일반성을 증명하고, 대규모의 3가지 다른 설정에서 예측력을 보여주었습니다: 대규모 언어 모델(LLM), 원생 다모달 모델(NMM), 그리고 대규모 시각 모델(LVM)의 사전 훈련. 또한, 우리는 이러한 스케일링 라즈는 새로운 데이터 혼합비율과 스케일에도 적용할 수 있으며, 그 파라미터는 소규모의 훈련을 통해 정확하게 추정할 수 있으며, 이를 사용하여 대규모의 스케일과未见의 분야 가중치에 대한 성능을 예측할 수 있습니다. 스케일링 라즈는 주어진 훈련 배치(N, D)의 가정하에 특정 타겟 분야에 대한 최적의 영역 가중치를 구할 수 있음을 보여줍니다. 이는 고가의 시험과 오류 방식 대신 원칙적인 접근 방식을 제공합니다.",
      "upvotes": 8,
      "discussionId": "68774156257d4f04353707da",
      "ai_summary": "Scaling laws predict optimal data mixtures for large foundation models, improving performance across different domains and scales.",
      "ai_keywords": [
        "scaling laws",
        "large language model",
        "native multimodal model",
        "large vision models",
        "domain weights",
        "parameter estimation",
        "performance prediction",
        "training budget"
      ]
    },
    "publishedAt": "2025-07-12T17:16:08.000Z",
    "title": "Scaling Laws for Optimal Data Mixtures",
    "summary": "Large foundation models are typically trained on data from multiple domains,\nwith the data mixture--the proportion of each domain used--playing a critical\nrole in model performance. The standard approach to selecting this mixture\nrelies on trial and error, which becomes impractical for large-scale\npretraining. We propose a systematic method to determine the optimal data\nmixture for any target domain using scaling laws. Our approach accurately\npredicts the loss of a model of size N trained with D tokens and a specific\ndomain weight vector h. We validate the universality of these scaling laws by\ndemonstrating their predictive power in three distinct and large-scale\nsettings: large language model (LLM), native multimodal model (NMM), and large\nvision models (LVM) pretraining. We further show that these scaling laws can\nextrapolate to new data mixtures and across scales: their parameters can be\naccurately estimated using a few small-scale training runs, and used to\nestimate the performance at larger scales and unseen domain weights. The\nscaling laws allow to derive the optimal domain weights for any target domain\nunder a given training budget (N,D), providing a principled alternative to\ncostly trial-and-error methods.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2507.09404.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "62bdeedd01dc22b4d22a371e",
      "avatarUrl": "/avatars/3cc0643feb53bf2e895ec12c275d5483.svg",
      "fullname": "Mustafa Shukor",
      "name": "mshukor",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 59
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2507.10787",
      "authors": [
        {
          "_id": "68771a98257d4f04353707b2",
          "user": {
            "_id": "62f662bcc58915315c4eccea",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62f662bcc58915315c4eccea/zOAQLONfMP88zr70sxHK-.jpeg",
            "isPro": true,
            "fullname": "Yilun Zhao",
            "user": "yilunzhao",
            "type": "user"
          },
          "name": "Yilun Zhao",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-07-16T08:15:45.442Z",
          "hidden": false
        },
        {
          "_id": "68771a98257d4f04353707b3",
          "name": "Chengye Wang",
          "hidden": false
        },
        {
          "_id": "68771a98257d4f04353707b4",
          "name": "Chuhan Li",
          "hidden": false
        },
        {
          "_id": "68771a98257d4f04353707b5",
          "name": "Arman Cohan",
          "hidden": false
        }
      ],
      "publishedAt": "2025-07-14T20:35:25.000Z",
      "submittedOnDailyAt": "2025-07-16T01:51:11.312Z",
      "title": "다모달 기초 모델은 구조도를 이해할 수 있는지에 대한 증명 연구 - 정보 탐색 QA에 대한 과학 논문에서",
      "submittedOnDailyBy": {
        "_id": "62f662bcc58915315c4eccea",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62f662bcc58915315c4eccea/zOAQLONfMP88zr70sxHK-.jpeg",
        "isPro": true,
        "fullname": "Yilun Zhao",
        "user": "yilunzhao",
        "type": "user"
      },
      "summary": "이 논문에서는 과학 문헌 내 구조도를 해석할 수 있는 능력을 평가하기 위해 설계된 첫 번째 벤치마크인 \"MISS-QA\"를 소개합니다. MISS-QA는 465편의 과학 논문에 대한 1,500건의 전문가 설명 사례로 구성되어 있습니다. 이 벤치마크에서, 구조도를 설명한 연구 개요를 이해하고 논문의 더 넓은 맥락에 기반하여 적절한 정보 탐색 질문을 답하는 것을 모델에 과제로 합니다. 18개의 첨단 모델의 성능을 평가하고 있습니다. o4-mini, Gemini-2.5-Flash, Qwen2.5-VL 등을 포함합니다. MISS-QA에서 모델과 인간 전문가 사이에서 뚜렷한 성능 차이를 밝혀냅니다. 모델의 성능을 평가하고 오류 분석을 수행하여 현재 모델의 강점과 한계를 명확히 하고, 과학 문헌의 다양한 이해를 위한 모델 개선의 핵심 지침을 제공합니다.",
      "upvotes": 4,
      "discussionId": "68771a98257d4f04353707b6",
      "githubRepo": "https://github.com/yilunzhao/MISS-QA",
      "ai_summary": "A benchmark evaluates multimodal models' ability to interpret scientific schematic diagrams and answer related questions, revealing performance gaps and insights for improvement.",
      "ai_keywords": [
        "multimodal foundation models",
        "schematic diagrams",
        "scientific literature",
        "information-seeking questions",
        "error analysis"
      ],
      "githubStars": 0
    },
    "publishedAt": "2025-07-14T16:35:25.000Z",
    "title": "Can Multimodal Foundation Models Understand Schematic Diagrams? An\n  Empirical Study on Information-Seeking QA over Scientific Papers",
    "summary": "This paper introduces MISS-QA, the first benchmark specifically designed to\nevaluate the ability of models to interpret schematic diagrams within\nscientific literature. MISS-QA comprises 1,500 expert-annotated examples over\n465 scientific papers. In this benchmark, models are tasked with interpreting\nschematic diagrams that illustrate research overviews and answering\ncorresponding information-seeking questions based on the broader context of the\npaper. We assess the performance of 18 frontier multimodal foundation models,\nincluding o4-mini, Gemini-2.5-Flash, and Qwen2.5-VL. We reveal a significant\nperformance gap between these models and human experts on MISS-QA. Our analysis\nof model performance on unanswerable questions and our detailed error analysis\nfurther highlight the strengths and limitations of current models, offering key\ninsights to enhance models in comprehending multimodal scientific literature.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2507.10787.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "62f662bcc58915315c4eccea",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62f662bcc58915315c4eccea/zOAQLONfMP88zr70sxHK-.jpeg",
      "fullname": "Yilun Zhao",
      "name": "yilunzhao",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 14
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2507.09411",
      "authors": [
        {
          "_id": "68771a0b257d4f04353707a9",
          "user": {
            "_id": "6159f88235226e98eaa28b39",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1633286253722-noauth.jpeg",
            "isPro": false,
            "fullname": "Md Ajwad Akil",
            "user": "Ajwad",
            "type": "user"
          },
          "name": "Md Ajwad Akil",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-07-16T08:15:48.362Z",
          "hidden": false
        },
        {
          "_id": "68771a0b257d4f04353707aa",
          "name": "Adrian Shuai Li",
          "hidden": false
        },
        {
          "_id": "68771a0b257d4f04353707ab",
          "name": "Imtiaz Karim",
          "hidden": false
        },
        {
          "_id": "68771a0b257d4f04353707ac",
          "name": "Arun Iyengar",
          "hidden": false
        },
        {
          "_id": "68771a0b257d4f04353707ad",
          "name": "Ashish Kundu",
          "hidden": false
        },
        {
          "_id": "68771a0b257d4f04353707ae",
          "name": "Vinny Parla",
          "hidden": false
        },
        {
          "_id": "68771a0b257d4f04353707af",
          "name": "Elisa Bertino",
          "hidden": false
        }
      ],
      "publishedAt": "2025-07-12T22:11:10.000Z",
      "submittedOnDailyAt": "2025-07-16T01:54:43.633Z",
      "title": "LLMalMorph: 대언어 모델을 이용한 변이 마르웨어의 생성 가능성에 관한 연구\n\n(注意：虽然要求不添加解释或额外的文本，但为了确保翻译的准确性和专业性，我进行了适当的调整，以确保翻译符合韩国语的习惯表达方式。)",
      "submittedOnDailyBy": {
        "_id": "6159f88235226e98eaa28b39",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1633286253722-noauth.jpeg",
        "isPro": false,
        "fullname": "Md Ajwad Akil",
        "user": "Ajwad",
        "type": "user"
      },
      "summary": "대 언어 모델(LLMs)는 소프트웨어 개발을 혁신하고 코드 생성을 자동화했습니다. 이러한 발전에 기반하여 본 논문은 LLMs가 악성코드의 소스 코드를 변경하여 변종을 생성할 가능성을 조사합니다. LLMalMorph라는 반자동화 프레임워크를 통해 LLMs가 문법적 및 의미적 코드 이해를 활용하여 새로운 악성코드 변종을 생성하는 방법을 제안합니다. LLMalMorph는 악성코드의 소스 코드에서 함수 수준의 정보를 추출하고 전략적으로 정의된 코드 변환을 위한 프롬프트와 결합하여, LLM에 변종을 생성할 때 자원 비용의 얇은 최종 조정을 피하면서 가이드합니다. LLMalMorph의 평가에는 10종류의 서로 다른 Windows 악성코드 샘플을 수집하고 618개의 변종을 생성했습니다.",
      "upvotes": 2,
      "discussionId": "68771a0c257d4f04353707b0",
      "ai_summary": "A semi-automated framework uses Large Language Models to generate malware variants, demonstrating reduced detection rates and notable attack success against ML classifiers.",
      "ai_keywords": [
        "Large Language Models",
        "LLMalMorph",
        "semantical code comprehension",
        "syntactical code comprehension",
        "function-level information",
        "custom-engineered prompts",
        "code transformations",
        "antivirus engines",
        "ML-based malware detectors",
        "malware variant generation"
      ]
    },
    "publishedAt": "2025-07-12T18:11:10.000Z",
    "title": "LLMalMorph: On The Feasibility of Generating Variant Malware using\n  Large-Language-Models",
    "summary": "Large Language Models (LLMs) have transformed software development and\nautomated code generation. Motivated by these advancements, this paper explores\nthe feasibility of LLMs in modifying malware source code to generate variants.\nWe introduce LLMalMorph, a semi-automated framework that leverages semantical\nand syntactical code comprehension by LLMs to generate new malware variants.\nLLMalMorph extracts function-level information from the malware source code and\nemploys custom-engineered prompts coupled with strategically defined code\ntransformations to guide the LLM in generating variants without\nresource-intensive fine-tuning. To evaluate LLMalMorph, we collected 10 diverse\nWindows malware samples of varying types, complexity and functionality and\ngenerated 618 variants. Our thorough experiments demonstrate that it is\npossible to reduce the detection rates of antivirus engines of these malware\nvariants to some extent while preserving malware functionalities. In addition,\ndespite not optimizing against any Machine Learning (ML)-based malware\ndetectors, several variants also achieved notable attack success rates against\nan ML-based malware classifier. We also discuss the limitations of current LLM\ncapabilities in generating malware variants from source code and assess where\nthis emerging technology stands in the broader context of malware variant\ngeneration.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2507.09411.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6159f88235226e98eaa28b39",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1633286253722-noauth.jpeg",
      "fullname": "Md Ajwad Akil",
      "name": "Ajwad",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2507.09075",
      "authors": [
        {
          "_id": "687731d0257d4f04353707be",
          "name": "Wasi Uddin Ahmad",
          "hidden": false
        },
        {
          "_id": "687731d0257d4f04353707bf",
          "user": {
            "_id": "6254f8e5d21e4cc386b881ad",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1649899774659-6254f8e5d21e4cc386b881ad.jpeg",
            "isPro": false,
            "fullname": "Somshubra Majumdar",
            "user": "smajumdar94",
            "type": "user"
          },
          "name": "Somshubra Majumdar",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-07-16T08:15:41.697Z",
          "hidden": false
        },
        {
          "_id": "687731d0257d4f04353707c0",
          "name": "Aleksander Ficek",
          "hidden": false
        },
        {
          "_id": "687731d0257d4f04353707c1",
          "name": "Sean Narenthiran",
          "hidden": false
        },
        {
          "_id": "687731d0257d4f04353707c2",
          "name": "Mehrzad Samadi",
          "hidden": false
        },
        {
          "_id": "687731d0257d4f04353707c3",
          "name": "Jocelyn Huang",
          "hidden": false
        },
        {
          "_id": "687731d0257d4f04353707c4",
          "name": "Siddhartha Jain",
          "hidden": false
        },
        {
          "_id": "687731d0257d4f04353707c5",
          "name": "Vahid Noroozi",
          "hidden": false
        },
        {
          "_id": "687731d0257d4f04353707c6",
          "name": "Boris Ginsburg",
          "hidden": false
        }
      ],
      "publishedAt": "2025-07-11T23:35:54.000Z",
      "submittedOnDailyAt": "2025-07-16T03:31:02.680Z",
      "title": "OpenCodeReasoning-II: 자기 비판에 의한 간단한 테스트 시간 스케일링 접근법",
      "submittedOnDailyBy": {
        "_id": "6254f8e5d21e4cc386b881ad",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1649899774659-6254f8e5d21e4cc386b881ad.jpeg",
        "isPro": false,
        "fullname": "Somshubra Majumdar",
        "user": "smajumdar94",
        "type": "user"
      },
      "summary": "최근의 근거 기반의 대규모 언어 모델(LLMs)의 발전, 특히 테스트 시 스케일링의 잠재적인 가능성은 코드 생성과 평가의 결합에 있어 중요한 기회를 제공하고 있습니다. 그러나 이러한 분야의 발전은 대규모 고품질의 데이터 세트의 존재에 기초하고 있습니다. 본 논문에서는 OpenCodeReasoning-II라는 데이터 세트를 소개합니다. 이 데이터 세트는 약 250만 개의 질문・답변・평가 삼중집합(약 35,000건의 고유의 프로그래밍 질문)을 포함하며, 이전의 최대 공개된 코드 이유 데이터 세트의 크기와 유사하게 크기가 이전의 것과 유사합니다. 본 논문에서는 2단계의 서브 객체 조정 전략을 채택합니다. 첫 번째 단계에서는 코드 생성을 위한 조정을 중점으로 하며, 두 번째 단계에서는 코드 생성과 평가의 모델의 공통 조정을 수행합니다. 우리의 결과로, 조정된 Qwen2.5-Instruct 모델은 코드 생성의 성능이 이전의 최고의 오픈 웨이트 모델의 성능을 초과하거나 같은 성능을 달성합니다. 특히, 우리의 코드 생성과 평가 모델의 통합은 경쟁적인 코딩 성능에 있어 상당한 향상을 실현하고 있습니다. 또한 LiveCodeBench 벤치마크의 확장을 제안하며, C++ 프로그래밍 언어를 특히 지원하고, 이 벤치마크를 사용하여 더 자세한 LLM 평가를 촉진합니다.",
      "upvotes": 2,
      "discussionId": "687731d0257d4f04353707c7"
    },
    "publishedAt": "2025-07-11T19:35:54.000Z",
    "title": "OpenCodeReasoning-II: A Simple Test Time Scaling Approach via\n  Self-Critique",
    "summary": "Recent advancements in reasoning-based Large Language Models (LLMs),\nparticularly their potential through test-time scaling, have created\nsignificant opportunities for distillation in code generation and critique.\nHowever, progress in both areas fundamentally depends on large-scale,\nhigh-quality datasets. In this work, we introduce OpenCodeReasoning-II, a\ndataset consists of 2.5M question-solution-critique triples (approx. 35K unique\nprogramming questions), making it nearly twice the size of the previous largest\npublicly available code reasoning dataset. In this work, we employ a two-stage\nsupervised fine-tuning strategy. The first stage focuses on fine-tuning for\ncode generation, while the second stage involves the joint training of models\nfor both code generation and critique. Our resulting finetuned Qwen2.5-Instruct\nmodels achieve performance in code generation that either exceeds or equals the\nbest prior open-weight distilled models. Notably, the integration of our code\ngeneration and critique models leads to significant improvements in competitive\ncoding performance. Furthermore, we present an extension of the LiveCodeBench\nbenchmark to specifically support the C++ programming language, thereby\nfacilitating more comprehensive LLM evaluation using this benchmark.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2507.09075.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6254f8e5d21e4cc386b881ad",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1649899774659-6254f8e5d21e4cc386b881ad.jpeg",
      "fullname": "Somshubra Majumdar",
      "name": "smajumdar94",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 27
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2507.08616",
      "authors": [
        {
          "_id": "687764e0ff8f47a7f86442ad",
          "name": "Florian Grötschla",
          "hidden": false
        },
        {
          "_id": "687764e0ff8f47a7f86442ae",
          "name": "Luis Müller",
          "hidden": false
        },
        {
          "_id": "687764e0ff8f47a7f86442af",
          "name": "Jan Tönshoff",
          "hidden": false
        },
        {
          "_id": "687764e0ff8f47a7f86442b0",
          "name": "Mikhail Galkin",
          "hidden": false
        },
        {
          "_id": "687764e0ff8f47a7f86442b1",
          "name": "Bryan Perozzi",
          "hidden": false
        }
      ],
      "publishedAt": "2025-07-11T14:13:22.000Z",
      "submittedOnDailyAt": "2025-07-16T07:08:39.797Z",
      "title": "AgentsNet: 다Agent LLM의 협조와 협의론\n\n(Note: The translation provided is a direct translation of the given text. If there are any specific nuances or contextual details that need to be adjusted for a more accurate or professional translation, please provide additional information.)",
      "submittedOnDailyBy": {
        "_id": "63c09599dd793d5a62890e7d",
        "avatarUrl": "/avatars/fed51ddd492b98e7cd4c3d1f82998635.svg",
        "isPro": false,
        "fullname": "Michael Galkin",
        "user": "mgalkin",
        "type": "user"
      },
      "summary": "대 언어 모델(LLMs)는 특히 멀티 에이전트 시스템에서 강력한 문제 해결 능력을 보여주고 있습니다. 그러나 이러한 시스템의 도입으로 인해, 복잡한 에이전트 네트워크가 효과적으로 자기 조직화와 협력하는 능력을 가지고 있는지는 몇 가지 의문이 나옵니다. 표준의 이유 검증 벤치마크에서의 성능 평가는 멀티 에이전트 시스템이 이유 문제를 해결할 수 있는 정도를 보여주지만, 이러한 시스템이 네트워크 토픽을 효과적으로 활용하는 능력에 대해서는 알 수 없습니다. 여기서 우리는 AgentsNet, 새로운 멀티 에이전트 이유 벤치마크를 제안합니다. 분산 시스템과 그래프 이론의 고전적인 문제를 빌드하여 AgentsNet은 네트워크 토픽을 제공했을 때, 멀티 에이전트 시스템이 문제 해결, 자기 조직화, 그리고 효율적인 통신을 위해 공동으로 형성하는 전략을 측정합니다. AgentsNet에서 다양한 베이스라인 메소드를 평가하고, 처음으로 조직과 통신의 기본적인 프로토콜을 동의하는 Homogeneous 네트워크의 에이전트를 포함합니다. 우리는 작은 네트워크에서 강력한 성능을 보였지만, 네트워크의 크기가 확장하면 성능이 떨어지는 것을 확인했습니다. 현재의 멀티 에이전트 벤치마크는 최대 2-5 에이전트를 대상으로 하며, AgentsNet은 실제 크기가 제한이 없고, 새로운 LLMs의 세대에 따라 확장할 수 있습니다. 따라서 우리는 100 에이전트 이상의 시스템에서 프론티어 모델을 평가합니다.",
      "upvotes": 1,
      "discussionId": "687764e0ff8f47a7f86442b2",
      "projectPage": "https://agentsnet.graphben.ch/",
      "githubRepo": "https://github.com/floriangroetschla/AgentsNet",
      "ai_summary": "AgentsNet is a new benchmark for evaluating multi-agent systems' ability to self-organize, communicate, and solve problems collaboratively across varying network sizes.",
      "ai_keywords": [
        "multi-agent systems",
        "AgentsNet",
        "distributed systems",
        "graph theory",
        "self-organization",
        "communication",
        "network topology",
        "homogeneous networks",
        "protocols",
        "LLMs"
      ],
      "githubStars": 1
    },
    "publishedAt": "2025-07-11T10:13:22.000Z",
    "title": "AgentsNet: Coordination and Collaborative Reasoning in Multi-Agent LLMs",
    "summary": "Large-language models (LLMs) have demonstrated powerful problem-solving\ncapabilities, in particular when organized in multi-agent systems. However, the\nadvent of such systems also raises several questions on the ability of a\ncomplex network of agents to effectively self-organize and collaborate. While\nmeasuring performance on standard reasoning benchmarks indicates how well\nmulti-agent systems can solve reasoning tasks, it is unclear whether these\nsystems are able to leverage their topology effectively. Here, we propose\nAgentsNet, a new benchmark for multi-agent reasoning. By drawing inspiration\nfrom classical problems in distributed systems and graph theory, AgentsNet\nmeasures the ability of multi-agent systems to collaboratively form strategies\nfor problem-solving, self-organization, and effective communication given a\nnetwork topology. We evaluate a variety of baseline methods on AgentsNet\nincluding homogeneous networks of agents which first have to agree on basic\nprotocols for organization and communication. We find that some frontier LLMs\nare already demonstrating strong performance for small networks but begin to\nfall off once the size of the network scales. While existing multi-agent\nbenchmarks cover at most 2-5 agents, AgentsNet is practically unlimited in size\nand can scale with new generations of LLMs. As such, we also probe frontier\nmodels in a setup with up to 100 agents.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2507.08616.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "63c09599dd793d5a62890e7d",
      "avatarUrl": "/avatars/fed51ddd492b98e7cd4c3d1f82998635.svg",
      "fullname": "Michael Galkin",
      "name": "mgalkin",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 13
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2507.07186",
      "authors": [
        {
          "_id": "68708a2ac8391850d609787d",
          "user": {
            "_id": "610c1e1a423fe7d80928aefd",
            "avatarUrl": "/avatars/8591584d678cf7fddace01e223953a63.svg",
            "isPro": true,
            "fullname": "Itay Itzhak",
            "user": "itay1itzhak",
            "type": "user"
          },
          "name": "Itay Itzhak",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-07-16T08:15:57.996Z",
          "hidden": false
        },
        {
          "_id": "68708a2ac8391850d609787e",
          "name": "Yonatan Belinkov",
          "hidden": false
        },
        {
          "_id": "68708a2ac8391850d609787f",
          "name": "Gabriel Stanovsky",
          "hidden": false
        }
      ],
      "publishedAt": "2025-07-09T18:01:14.000Z",
      "submittedOnDailyAt": "2025-07-16T06:16:00.646Z",
      "title": "「학습기간에 삽입되어, 미세 조정에 흔들려: LLM에서 인지바이어스의 근원의 사례 연구」",
      "submittedOnDailyBy": {
        "_id": "610c1e1a423fe7d80928aefd",
        "avatarUrl": "/avatars/8591584d678cf7fddace01e223953a63.svg",
        "isPro": true,
        "fullname": "Itay Itzhak",
        "user": "itay1itzhak",
        "type": "user"
      },
      "summary": "대 언어 모델(LLMs)은 인간에 의해 인과적으로 부적절한 의사결정의 체계적인 경향을 보여줍니다. 기존 연구에서 이러한 편향은 모델 간에 다릅니다, 그리고 명령 학습에 의해 확장되는 것을 관찰했습니다. 그러나 이러한 편향의 원인이 사전 학습, 상세 학습, 또는 훈련의 표준성으로 인한 난수로부터 발생하는 것이 아니라는 점은 명확하지 않습니다. 우리는 이러한 원인을 분리하기 위해 두 단계의因果적인 실험적 접근을 제안합니다. 먼저, 다른 랜덤 시드를 사용하여 모델을 여러 번 상세 학습하여 훈련의 난수가 30개 이상의 인지 편향에 어떻게 영향을 미치는지 연구합니다. 다음으로, 교차 학습을 도입하여 모델 간에 명령 데이터 세트를 교환하여 편향의 근원이 분리합니다. 이 교환은 서로 다른 편향 패턴을 일으키는 데이터 세트를 사용하며, 편향이 데이터 세트에 의존하는지 직접적으로 검증합니다. 우리의 발견은 훈련의 난수는 일부 변동을 일으킨다만, 편향은 주로 사전 학습에 의해 형성되어 있음을 명확히 알 수 있습니다: 같은 사전 학습 백본을 공유하는 모델은 상세 학습 데이터 세트를 공유하는 모델보다 편향 패턴에 따라 유사합니다. 이러한 발견은 상세 학습 모델의 편향을 이해하기 위해서는 상세 학습의 영향을 초월하여 사전 학습의 근원을 고려하는 것이 필요함을 보여줍니다. 이 시각은 향후의 노력을 가이드하여 LLMs의 편향 평가와 완화의 원칙적인 전략의 개발에 도움을 줄 수 있습니다.",
      "upvotes": 1,
      "discussionId": "68708a2bc8391850d6097880",
      "ai_summary": "Research identifies pretraining as the primary source of cognitive biases in large language models, distinguishing its influence from finetuning and training randomness.",
      "ai_keywords": [
        "large language models",
        "cognitive biases",
        "instruction tuning",
        "pretraining",
        "finetuning",
        "training randomness",
        "cross-tuning",
        "dataset-dependent biases"
      ]
    },
    "publishedAt": "2025-07-09T14:01:14.000Z",
    "title": "Planted in Pretraining, Swayed by Finetuning: A Case Study on the\n  Origins of Cognitive Biases in LLMs",
    "summary": "Large language models (LLMs) exhibit cognitive biases -- systematic\ntendencies of irrational decision-making, similar to those seen in humans.\nPrior work has found that these biases vary across models and can be amplified\nby instruction tuning. However, it remains unclear if these differences in\nbiases stem from pretraining, finetuning, or even random noise due to training\nstochasticity. We propose a two-step causal experimental approach to\ndisentangle these factors. First, we finetune models multiple times using\ndifferent random seeds to study how training randomness affects over 30\ncognitive biases. Second, we introduce cross-tuning -- swapping\ninstruction datasets between models to isolate bias sources. This swap uses\ndatasets that led to different bias patterns, directly testing whether biases\nare dataset-dependent. Our findings reveal that while training randomness\nintroduces some variability, biases are mainly shaped by pretraining: models\nwith the same pretrained backbone exhibit more similar bias patterns than those\nsharing only finetuning data. These insights suggest that understanding biases\nin finetuned models requires considering their pretraining origins beyond\nfinetuning effects. This perspective can guide future efforts to develop\nprincipled strategies for evaluating and mitigating bias in LLMs.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2507.07186.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "610c1e1a423fe7d80928aefd",
      "avatarUrl": "/avatars/8591584d678cf7fddace01e223953a63.svg",
      "fullname": "Itay Itzhak",
      "name": "itay1itzhak",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  }
]