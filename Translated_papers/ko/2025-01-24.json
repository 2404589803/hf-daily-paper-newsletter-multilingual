[
  {
    "paper": {
      "id": "2501.13200",
      "authors": [
        {
          "_id": "67933d69b843fda452c689dd",
          "user": {
            "_id": "65c0db0fbda79a18292dfbb7",
            "avatarUrl": "/avatars/1201b8282664c2d8c18beaba2396c03b.svg",
            "isPro": false,
            "fullname": "Alsu Sagirova",
            "user": "alsu-sagirova",
            "type": "user"
          },
          "name": "Alsu Sagirova",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-01-24T09:07:49.036Z",
          "hidden": false
        },
        {
          "_id": "67933d69b843fda452c689de",
          "name": "Yuri Kuratov",
          "hidden": false
        },
        {
          "_id": "67933d69b843fda452c689df",
          "user": {
            "_id": "639c6e978a34ed9a404c6a7b",
            "avatarUrl": "/avatars/c98ca8c9f9ed8509c2f1bb6aa994fd57.svg",
            "isPro": false,
            "fullname": "MIKHAIL BURTSEV",
            "user": "mbur",
            "type": "user"
          },
          "name": "Mikhail Burtsev",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:07:03.954Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-22T20:08:53.000Z",
      "title": "SRMT: 공유 메모리 프로젝트 다중 에이전트 라이프랭킹 패스워드 핀딩",
      "summary": "다수효과를 보이는 다중아우ト로이드 강화 학습(MARL)은 다양한 환경에서 기업적 및 경쟁적인 다중아우ト로이드 문제를 효과적으로 해결할 수 있도록 큰 진전을 보이고 있습니다. MARL의 주요 문제 중 하나는 기업적 목표를 달성하기 위해 각 아우ト로이드의 행동을 명시적으로 예측하는 것이 필요합니다. 이 문제를 해결하기 위해, 우리는 각 아우ト로이드의 작업 메모리를 팍싱하고, 글로벌로 브로드캐스팅하는 방식으로 메모리 트랜스포머를 다중아우ト로이드 설정에 확장한 \"공유 재현 메모리 트랜스포머(SRMT)\"를 제안합니다. SRMT는 아우ト로이드 간에 정보를 숨겨서 교환하고 행동을 조절할 수 있게 되었습니다. SRMT는 포트폴리오 관찰 가능한 다수효과 MARL 패스 피딩 문제를 해결하기 위해, POTTERBOTTLE NECK NAVIGATION TASK과 POGEMA 벤치마크 TASK에서 평가되었습니다. POTTERBOTTLE NECK TASK에서 SRMT는 다양한 강화 학습 기반 라인에 일관되게 뛰어나며, 특히 희소한 보상의 경우, 학습 중 본래보다 긴 코어로도 효과적으로 일반화합니다. POGEMA MAP에서 SRMT는 MAZES, RANDOM, MovingAI를 포함하며, 최근의 MARL, 하이브리드, 계획기반 알고리즘과 경쟁적으로 평가되었습니다. 이러한 결과는 트랜스포머 기반 아키텍처에 공유 재현 메모리를 통합하는 것이 분산된 다중아우ト로이드 시스템의 조정을 향상시킬 수 있음을 보여주고 있습니다. 학습과 평가의 소스 코드는 GitHub에서 접근 가능합니다: https://github.com/Aloriosa/srmt.",
      "upvotes": 36,
      "discussionId": "67933d6ab843fda452c68a38"
    },
    "publishedAt": "2025-01-24T02:35:35.802Z",
    "title": "SRMT: Shared Memory for Multi-agent Lifelong Pathfinding",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.13200.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "65c0db0fbda79a18292dfbb7",
      "avatarUrl": "/avatars/1201b8282664c2d8c18beaba2396c03b.svg",
      "fullname": "Alsu Sagirova",
      "name": "alsu-sagirova",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2501.13918",
      "authors": [
        {
          "_id": "679319848d46289f90266168",
          "user": {
            "_id": "639be86b59473c6ae02ef9c4",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/639be86b59473c6ae02ef9c4/gw34RBCVZCOkcAA79xUr3.png",
            "isPro": false,
            "fullname": "Jie Liu",
            "user": "jieliu",
            "type": "user"
          },
          "name": "Jie Liu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-01-24T09:07:53.235Z",
          "hidden": false
        },
        {
          "_id": "679319848d46289f90266169",
          "name": "Gongye Liu",
          "hidden": false
        },
        {
          "_id": "679319848d46289f9026616a",
          "name": "Jiajun Liang",
          "hidden": false
        },
        {
          "_id": "679319848d46289f9026616b",
          "name": "Ziyang Yuan",
          "hidden": false
        },
        {
          "_id": "679319848d46289f9026616c",
          "name": "Xiaokun Liu",
          "hidden": false
        },
        {
          "_id": "679319848d46289f9026616d",
          "name": "Mingwu Zheng",
          "hidden": false
        },
        {
          "_id": "679319848d46289f9026616e",
          "name": "Xiele Wu",
          "hidden": false
        },
        {
          "_id": "679319848d46289f9026616f",
          "name": "Qiulin Wang",
          "hidden": false
        },
        {
          "_id": "679319848d46289f90266170",
          "name": "Wenyu Qin",
          "hidden": false
        },
        {
          "_id": "679319848d46289f90266171",
          "name": "Menghan Xia",
          "hidden": false
        },
        {
          "_id": "679319848d46289f90266172",
          "user": {
            "_id": "60e272ca6c78a8c122b12127",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/60e272ca6c78a8c122b12127/xldEGBzGrU-bX6IwAw0Ie.jpeg",
            "isPro": false,
            "fullname": "Xintao Wang",
            "user": "Xintao",
            "type": "user"
          },
          "name": "Xintao Wang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-01-24T09:07:51.248Z",
          "hidden": false
        },
        {
          "_id": "679319848d46289f90266173",
          "name": "Xiaohong Liu",
          "hidden": false
        },
        {
          "_id": "679319848d46289f90266174",
          "name": "Fei Yang",
          "hidden": false
        },
        {
          "_id": "679319848d46289f90266175",
          "name": "Pengfei Wan",
          "hidden": false
        },
        {
          "_id": "679319848d46289f90266176",
          "name": "Di Zhang",
          "hidden": false
        },
        {
          "_id": "679319848d46289f90266177",
          "name": "Kun Gai",
          "hidden": false
        },
        {
          "_id": "679319848d46289f90266178",
          "name": "Yujiu Yang",
          "hidden": false
        },
        {
          "_id": "679319848d46289f90266179",
          "name": "Wanli Ouyang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-23T18:55:41.000Z",
      "title": "개선된 비디오 생성에 인간적인 피드백을 활용하기\n\n(Note: The translation is provided as requested, without additional explanation or text.)",
      "summary": "비디오 생성은 정규화 흐름 기법을 통해 발전하고 있지만, 부적절한 움직임이나 비디오와 프로ンプト의 비대칭성 등 문제들이 남아 있습니다. 본 연구에서는, 이 문제를 완화하고 정확한 비디오 생성 모델을 개발하기 위해 인간 피드백을 활용하여 시스템적인 파이프라인을 개발합니다. 특히, 현대 비디오 생성 모델에 초점을 맞추고 있는 대규모 인간 취향 데이터셋을 구축하여, 다양한 차원 간의 페어웨이즈 설명을 포함하도록 시작합니다. 다음으로, VideoReward라는 다양한 차원의 비디오 보상 모델을 도입하여, 설명과 디자인 선택이 보상의 효과를 어떻게 영향을 미칠지 검토합니다. 단일의 강화 학습의 관점에서 보상을 최대화하는 것을 목표로, KL 정규화를 포함하며, 흐름 기반 모델에 대한 3가지의 어레이먼트 알고리즘을 도입합니다. 이 알고리즘들은 학습 시의 두 가지의 스탠다처: 흐름의 직접적인 취향 최적화 (Flow-DPO) 및 보상 가중치付き 회귀 (Flow-RWR)와, 추론 시의 기술인, Flow-NRG (Noisy Video Reward Guidance)입니다. Flow-NRG는 추론 시에 노이즈가 있는 비디오에 보상 가이드를 직접 적용합니다. 실험 결과로부터, VideoReward는 기존의 보상 모델을 크게 초월하고, Flow-DPO는 Flow-RWR와 표준의 정규화 학습의 최적화 방법과 비교하여 우수한 성능을 나타냅니다. 또한, Flow-NRG는 추론 시에 다수의 객체별로 사용자 정의의 가중치를 할당하여, 개별 비디오의 품질의 필요를 충족시킬 수 있습니다. 프로젝트 페이지: https://gongyeliu.github.io/videoalign.",
      "upvotes": 28,
      "discussionId": "679319858d46289f90266203"
    },
    "publishedAt": "2025-01-24T05:39:01.676Z",
    "title": "Improving Video Generation with Human Feedback",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.13918.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "639be86b59473c6ae02ef9c4",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/639be86b59473c6ae02ef9c4/gw34RBCVZCOkcAA79xUr3.png",
      "fullname": "Jie Liu",
      "name": "jieliu",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 10
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2501.13629",
      "authors": [
        {
          "_id": "6792f8ed5e3ec6035dafb06a",
          "user": {
            "_id": "63776f1806241efce1e7aae6",
            "avatarUrl": "/avatars/d67d9dcd932934c630f407ac152f2ce6.svg",
            "isPro": false,
            "fullname": "Zhenghao Lin",
            "user": "Lin0",
            "type": "user"
          },
          "name": "Zhenghao Lin",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T09:14:52.584Z",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb06b",
          "user": {
            "_id": "656c6bd8e0ff1cebe966aa35",
            "avatarUrl": "/avatars/1083cb58bdb0bee72036953276d42e13.svg",
            "isPro": false,
            "fullname": "tangzihao",
            "user": "tzh94588",
            "type": "user"
          },
          "name": "Zihao Tang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T09:15:04.802Z",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb06c",
          "user": {
            "_id": "63fb6e281b4b1bd4e7ffc5be",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1677422062937-noauth.jpeg",
            "isPro": false,
            "fullname": "Xiao Liu",
            "user": "lx865712528",
            "type": "user"
          },
          "name": "Xiao Liu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-01-24T09:08:05.797Z",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb06d",
          "user": {
            "_id": "643f615aa16cd6d1f4c581de",
            "avatarUrl": "/avatars/47753a3e82b44f81881600c52e1e8495.svg",
            "isPro": false,
            "fullname": "Yeyun Gong",
            "user": "yegong",
            "type": "user"
          },
          "name": "Yeyun Gong",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T09:58:33.228Z",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb06e",
          "name": "Yi Cheng",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb06f",
          "name": "Qi Chen",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb070",
          "user": {
            "_id": "61342a4b488458a484dee6c4",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1630808595161-noauth.png",
            "isPro": false,
            "fullname": "Hang Li",
            "user": "hanglics",
            "type": "user"
          },
          "name": "Hang Li",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:03:59.680Z",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb071",
          "name": "Ying Xin",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb072",
          "user": {
            "_id": "62f6a9add3bdacb7eec0d4f5",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1660332390183-noauth.jpeg",
            "isPro": false,
            "fullname": "Ziyue Yang",
            "user": "ziyueyang37",
            "type": "user"
          },
          "name": "Ziyue Yang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:04:09.709Z",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb073",
          "user": {
            "_id": "646fc402e9c03ba436d5e93e",
            "avatarUrl": "/avatars/870c86dc99fb1cb6a348a7a0385b1a04.svg",
            "isPro": false,
            "fullname": "Kailai Yang",
            "user": "klyang",
            "type": "user"
          },
          "name": "Kailai Yang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:04:16.033Z",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb074",
          "name": "Yu Yan",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb075",
          "name": "Xiao Liang",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb076",
          "name": "Shuai Lu",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb077",
          "name": "Yiming Huang",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb078",
          "user": {
            "_id": "6443bb593c323e0918f61a96",
            "avatarUrl": "/avatars/b9e1ba17f7798b5142bc0124fba95237.svg",
            "isPro": false,
            "fullname": "zheheng luo",
            "user": "KenLuo",
            "type": "user"
          },
          "name": "Zheheng Luo",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:04:49.140Z",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb079",
          "name": "Lei Qu",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb07a",
          "name": "Xuan Feng",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb07b",
          "name": "Yaoxiang Wang",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb07c",
          "user": {
            "_id": "6369e01864aad59d4d4501ac",
            "avatarUrl": "/avatars/bcbd3f9d0d194eeccd061c4fa6a6e283.svg",
            "isPro": false,
            "fullname": "Yuqing Xia",
            "user": "yuqxia",
            "type": "user"
          },
          "name": "Yuqing Xia",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:05:26.287Z",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb07d",
          "user": {
            "_id": "673fd856a45b6f21829a3bf5",
            "avatarUrl": "/avatars/deb8c5362fad22019cccaed6d03dea09.svg",
            "isPro": false,
            "fullname": "Feiyang Chen",
            "user": "PhilipChen",
            "type": "user"
          },
          "name": "Feiyang Chen",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:05:34.991Z",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb07e",
          "user": {
            "_id": "64e85f4e5ddcace745bc0a55",
            "avatarUrl": "/avatars/e316355b913c73104db530010ceedeb4.svg",
            "isPro": false,
            "fullname": "Yuting Jiang",
            "user": "Stautinger",
            "type": "user"
          },
          "name": "Yuting Jiang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:05:41.151Z",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb07f",
          "name": "Yasen Hu",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb080",
          "name": "Hao Ni",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb081",
          "user": {
            "_id": "6485714cfc41a0b97fe377cc",
            "avatarUrl": "/avatars/0af8a3df9ad711a5eac739bce26c4c2a.svg",
            "isPro": false,
            "fullname": "Li",
            "user": "Binyang",
            "type": "user"
          },
          "name": "Binyang Li",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:06:03.263Z",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb082",
          "user": {
            "_id": "663de80ca920d195191807da",
            "avatarUrl": "/avatars/2437ce3fa073a07b971d370c26c7ab65.svg",
            "isPro": false,
            "fullname": "Guoshuai Zhao",
            "user": "crayonshine",
            "type": "user"
          },
          "name": "Guoshuai Zhao",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:05:17.780Z",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb083",
          "name": "Jui-Hao Chiang",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb084",
          "name": "Zhongxin Guo",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb085",
          "name": "Chen Lin",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb086",
          "name": "Kun Kuang",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb087",
          "user": {
            "_id": "66a3710a4ee2a4c936315a5a",
            "avatarUrl": "/avatars/ef8da8fb1031695d77d34a5d365aa177.svg",
            "isPro": false,
            "fullname": "Li",
            "user": "WenjieLi",
            "type": "user"
          },
          "name": "Wenjie Li",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:06:22.951Z",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb088",
          "user": {
            "_id": "6454c337a13edf669cd5d8ea",
            "avatarUrl": "/avatars/a383a0dda7c2ef6a0d6c3c64651f42ff.svg",
            "isPro": false,
            "fullname": "Yelong Shen",
            "user": "uuu6",
            "type": "user"
          },
          "name": "Yelong Shen",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:06:30.109Z",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb089",
          "name": "Jian Jiao",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb08a",
          "name": "Peng Cheng",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb08b",
          "name": "Mao Yang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-23T12:58:14.000Z",
      "title": "시그마: 조정된 질문, 키, 값의 미분 조정에 의한 효율적인 언어 모델",
      "summary": "Sigma는 새로운 아키텍처에 기반하여 강화된 효율적인 시스템 영역에 특화된 대규모 언어 모델입니다. DiffQKV attention을 도입하여 모델의 추론 효율성을 크게 향상시킵니다. DiffQKV attention은 Query (Q), Key (K), Value (V)의 각 요소에 따라 다른 효과를 가짐을 고려하여 모델의 성능과 효율 지표를 최적화합니다. 특히, K와 V의 복잡한 작업에 대한 대응성을 보여주고, 차이적으로 압축된 KV를 개발하고 Q 헤드의 차원을 확장하여 모델의 표현력을 향상시킵니다. 이론적 및 실험적 분석에 따르면, DiffQKV attention은 긴 컨텍스트의 경우 GQA보다 33.36%의 추론 속도 향상을 달성합니다. Sigma는 6T 토큰의 데이터에서 학습되었으며, 그 중 19.5B의 시스템 영역 데이터와 1T 토큰의 합성된 데이터를 신중하게 수집하여 구성됩니다. 일반적인 영역에서는 다른 최선 모델과 동일한 성능을 보여주며, 시스템 영역에서는 처음으로 실증적인 벤치마크 AIMicius에서 기록한 실적입니다. 이 벤치마크에서, Sigma는 모든 태스크에서 뛰어난 성능을 보여주고, GPT-4를 크게 초과하며 절대적인 향상은 52.5%에 달합니다.",
      "upvotes": 27,
      "discussionId": "6792f8f05e3ec6035dafb140"
    },
    "publishedAt": "2025-01-23T22:48:16.405Z",
    "title": "Sigma: Differential Rescaling of Query, Key and Value for Efficient Language Models",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.13629.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "63fb6e281b4b1bd4e7ffc5be",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1677422062937-noauth.jpeg",
      "fullname": "Xiao Liu",
      "name": "lx865712528",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 7
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2501.13926",
      "authors": [
        {
          "_id": "6793040ec67af4a116a25d05",
          "user": {
            "_id": "647d9ab61a1fcad2fdbf2d3d",
            "avatarUrl": "/avatars/48c8aeae8979d2c87df8bde922437d62.svg",
            "isPro": true,
            "fullname": "Ziyu Guo",
            "user": "ZiyuG",
            "type": "user"
          },
          "name": "Ziyu Guo",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:07:58.258Z",
          "hidden": false
        },
        {
          "_id": "6793040ec67af4a116a25d06",
          "name": "Renrui Zhang",
          "hidden": false
        },
        {
          "_id": "6793040ec67af4a116a25d07",
          "name": "Chengzhuo Tong",
          "hidden": false
        },
        {
          "_id": "6793040ec67af4a116a25d08",
          "user": {
            "_id": "6713a71e7dfe714b425cccfb",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/95YYcbv_f6J8yWTunwn4z.png",
            "isPro": false,
            "fullname": "zhizhengzhao",
            "user": "zhizhengzhao",
            "type": "user"
          },
          "name": "Zhizheng Zhao",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:08:20.272Z",
          "hidden": false
        },
        {
          "_id": "6793040ec67af4a116a25d09",
          "user": {
            "_id": "6759af3eccbc8817f9169179",
            "avatarUrl": "/avatars/49e64c7ccf71b8f25c52783b6ae93620.svg",
            "isPro": false,
            "fullname": "Peng Gao",
            "user": "gaopenghigh",
            "type": "user"
          },
          "name": "Peng Gao",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:08:26.816Z",
          "hidden": false
        },
        {
          "_id": "6793040ec67af4a116a25d0a",
          "user": {
            "_id": "65c04e9c27a5fdca81abcbd9",
            "avatarUrl": "/avatars/12a155683c824fa23da4a9e2bed4f64e.svg",
            "isPro": false,
            "fullname": "Hongsheng LI",
            "user": "hsli-cuhk",
            "type": "user"
          },
          "name": "Hongsheng Li",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:08:33.312Z",
          "hidden": false
        },
        {
          "_id": "6793040ec67af4a116a25d0b",
          "name": "Pheng-Ann Heng",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-23T18:59:43.000Z",
      "title": "CoT에서 이미지가 생성될 수 있을까? 단계별로 이미지 생성을 확인하고 강화합니다.",
      "summary": "Chain-of-Thought (CoT) 추론은 대규모 모델에서 복잡한 이해 태스크를 해결하기 위해 광범위하게 검토되고 있습니다. 그러나 이러한 전략이 사진 생성 시나리오의 검증과 강화에 적용할 수 있는지는 아직 여론이 있는 문제입니다. 본 논문에서는 CoT 추론이 자동 사진 생성을 강화하는 가능성을 처음부터 상세하게 조사합니다. 초점은 3가지 기술로 이루어져 있습니다: 검증을 위한 테스트 시간 계산의 스케일링, 모델의 취향과 Direct Preference Optimization (DPO)의 일치, 그리고 이러한 기술의 보완 효과의 통합입니다. 이러한 접근法是 사진 생성의 성능을 크게 향상시킬 수 있음을 보여줍니다. 또한 보상 모델이 우리의 발견에 중요한 역할을 수행하는 것을 고려하여 Potential Assessment Reward Model (PARM)과 PARM++를 제안합니다. PARM은 기존 보상 모델의 강점을 통합하고, 각 생성 단계를 잠재적인 평가 접근법으로 적응적으로 평가합니다. PARM++는 생성된 불만족스러운 사진을 자동으로 보정하는 반성 기능을 추가합니다. 조사한 이유 접근법을 사용하며, 기본 모델 Show-o를 강화하여 GenEval 벤치마크에서 +24%의 큰 향상을 달성하고, Stable Diffusion 3을 +15% 이상 초월했습니다. 우리의 연구는 CoT 추론과 자동 사진 생성의 통합에 대해 특이한 시각을 제공하며, 새로운 길을 개척합니다. 코드와 모델은 https://github.com/ZiyuGuo99/Image-Generation-CoT에서 릴리즈되었습니다.",
      "upvotes": 9,
      "discussionId": "67930410c67af4a116a25da4"
    },
    "publishedAt": "2025-01-23T22:08:17.598Z",
    "title": "Can We Generate Images with CoT? Let's Verify and Reinforce Image Generation Step by Step",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.13926.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "63468720dd6d90d82ccf3450",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63468720dd6d90d82ccf3450/tVBFlmZNz8FRMkOrDaDID.jpeg",
      "fullname": "YSH",
      "name": "BestWishYsh",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 28
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.13920",
      "authors": [
        {
          "_id": "679316ff3698fd97252a8e6f",
          "user": {
            "_id": "64c3c72e8f31d1e6c664b052",
            "avatarUrl": "/avatars/af1ad5048eaa9dc417837ad02f927911.svg",
            "isPro": false,
            "fullname": "jiayi lei",
            "user": "jyjyjyjy",
            "type": "user"
          },
          "name": "Jiayi Lei",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:12:22.641Z",
          "hidden": false
        },
        {
          "_id": "679316ff3698fd97252a8e70",
          "name": "Renrui Zhang",
          "hidden": false
        },
        {
          "_id": "679316ff3698fd97252a8e71",
          "name": "Xiangfei Hu",
          "hidden": false
        },
        {
          "_id": "679316ff3698fd97252a8e72",
          "user": {
            "_id": "66026c9068d519ed32519e9c",
            "avatarUrl": "/avatars/8fa051312c713772e5b8ba65989ff7f5.svg",
            "isPro": false,
            "fullname": "Weifeng Lin",
            "user": "Afeng-x",
            "type": "user"
          },
          "name": "Weifeng Lin",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:13:07.303Z",
          "hidden": false
        },
        {
          "_id": "679316ff3698fd97252a8e73",
          "name": "Zhen Li",
          "hidden": false
        },
        {
          "_id": "679316ff3698fd97252a8e74",
          "name": "Wenjian Sun",
          "hidden": false
        },
        {
          "_id": "679316ff3698fd97252a8e75",
          "user": {
            "_id": "64a54586c0f13de8e7093314",
            "avatarUrl": "/avatars/389e43e9a32cf2fc95f8f3a23b8f0508.svg",
            "isPro": false,
            "fullname": "Ruoyi Du",
            "user": "RuoyiDu",
            "type": "user"
          },
          "name": "Ruoyi Du",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:13:21.861Z",
          "hidden": false
        },
        {
          "_id": "679316ff3698fd97252a8e76",
          "user": {
            "_id": "6358a167f56b03ec9147074d",
            "avatarUrl": "/avatars/e54ea7bf0c240cf76d538296efb3976c.svg",
            "isPro": false,
            "fullname": "Le Zhuo",
            "user": "JackyZhuo",
            "type": "user"
          },
          "name": "Le Zhuo",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:13:27.523Z",
          "hidden": false
        },
        {
          "_id": "679316ff3698fd97252a8e77",
          "user": {
            "_id": "6740a5730bb4a675446a80ad",
            "avatarUrl": "/avatars/27c08e33df88e4f73c136da65f2b5adb.svg",
            "isPro": false,
            "fullname": "Zhong-Yu Li",
            "user": "lzyhha",
            "type": "user"
          },
          "name": "Zhongyu Li",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:13:33.108Z",
          "hidden": false
        },
        {
          "_id": "679316ff3698fd97252a8e78",
          "name": "Xinyue Li",
          "hidden": false
        },
        {
          "_id": "679316ff3698fd97252a8e79",
          "user": {
            "_id": "62c66504031996c36c86976a",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62c66504031996c36c86976a/wIq0YJhkWnEhlzsh-TGYO.png",
            "isPro": true,
            "fullname": "steve z",
            "user": "stzhao",
            "type": "user"
          },
          "name": "Shitian Zhao",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-01-24T13:30:14.688Z",
          "hidden": false
        },
        {
          "_id": "679316ff3698fd97252a8e7a",
          "user": {
            "_id": "647d9ab61a1fcad2fdbf2d3d",
            "avatarUrl": "/avatars/48c8aeae8979d2c87df8bde922437d62.svg",
            "isPro": true,
            "fullname": "Ziyu Guo",
            "user": "ZiyuG",
            "type": "user"
          },
          "name": "Ziyu Guo",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:14:21.821Z",
          "hidden": false
        },
        {
          "_id": "679316ff3698fd97252a8e7b",
          "user": {
            "_id": "6614fb3d5aed02b298a4b469",
            "avatarUrl": "/avatars/d0ddb4f989ad1a3f24128cc843347bde.svg",
            "isPro": false,
            "fullname": "yiting lu",
            "user": "yeeeeeyy",
            "type": "user"
          },
          "name": "Yiting Lu",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:14:50.714Z",
          "hidden": false
        },
        {
          "_id": "679316ff3698fd97252a8e7c",
          "user": {
            "_id": "6759af3eccbc8817f9169179",
            "avatarUrl": "/avatars/49e64c7ccf71b8f25c52783b6ae93620.svg",
            "isPro": false,
            "fullname": "Peng Gao",
            "user": "gaopenghigh",
            "type": "user"
          },
          "name": "Peng Gao",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:15:04.489Z",
          "hidden": false
        },
        {
          "_id": "679316ff3698fd97252a8e7d",
          "user": {
            "_id": "65c04e9c27a5fdca81abcbd9",
            "avatarUrl": "/avatars/12a155683c824fa23da4a9e2bed4f64e.svg",
            "isPro": false,
            "fullname": "Hongsheng LI",
            "user": "hsli-cuhk",
            "type": "user"
          },
          "name": "Hongsheng Li",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:15:11.437Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-23T18:58:33.000Z",
      "title": "IMAGINE-E: 가장 선진한 이미지 생성 인트라지션 평가\n문에서 이미지로의 가장 선진 모델의 평가",
      "summary": "확산 모델의 급격한 발전에 따라, 텍스트에서 이미지(T2I) 모델은 눈에 띄게 발전하고 있으며, Prompt 추적과 이미지 생성에 뛰어난 능력을 보여주고 있습니다. 최근의 FLUX.1와 Ideogram2.0 등 모델은 Dall-E3와 Stable Diffusion 3을 포함한 다른 모델들과 함께 복잡한 태스크에서 뛰어난 실력을 보여주고 있으며, T2I 모델이 일반적인 용도에서 발전하고 있는지의 의문이 제기되고 있습니다. 이러한 모델들은 다양한 분야에서 제어 가능한 생성, 이미지 편집, 비디오, 음성, 3D, 동작 생성 등의 기능을 보여주며, 세ман틱 분할 및 깊이 추정 등 컴퓨터 시각화 태스크도 지원하고 있습니다. 그러나 현재의 평가 프레임워크는 이러한 모델의 확장된 분야에서의 성능을 완벽하게 평가할 수 없는 경우가 있습니다. 이를 위해 IMAGINE-E를 개발하여 FLUX.1, Ideogram2.0, Midjourney, Dall-E3, Stable Diffusion 3, Jimeng의 6개의 모델을 검증했습니다. 평가는 구조화된 출력 생성, Realism, 물리적 일관성, 특정 분야의 생성, 어려운 시나리오의 생성, 멀티 스타일의 생성 태스크의 5개의 주요 분야로 나눌 수 있습니다. 이 상세한 평가는 각 모델의 강점과 약점을 명확히 하고, 특히 FLUX.1과 Ideogram2.0가 구조화된 태스크 및 특정 분야의 태스크에서 뛰어난 실력을 보여주며, T2I 모델의 확장된 적용 가능성과 잠재적 효과를 강조하고 있습니다. 이 연구는 T2I 모델이 일반적인 용도에서 발전하고 있는 현재 상태와 미래의 계획에 대한 유익한 통찰을 제공하고 있습니다. 평가 스크립트는 https://github.com/jylei16/Imagine-e에서 공개됩니다.",
      "upvotes": 8,
      "discussionId": "679317043698fd97252a8f6f"
    },
    "publishedAt": "2025-01-23T23:31:27.973Z",
    "title": "IMAGINE-E: Image Generation Intelligence Evaluation of State-of-the-art Text-to-Image Models",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.13920.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "645dbaa6f5760d1530d7580d",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/645dbaa6f5760d1530d7580d/Bqob8arLZoHIgMwNZpL9I.jpeg",
      "fullname": "Simeon Emanuilov",
      "name": "s-emanuilov",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isMod": false,
      "followerCount": 16
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.10018",
      "authors": [
        {
          "_id": "678e125d09dc6d3a311cc04e",
          "user": {
            "_id": "6497b4464a3c31df8e4148d8",
            "avatarUrl": "/avatars/4397a380468e84bc7945fddd9a6d1066.svg",
            "isPro": false,
            "fullname": "Xiaowen Li",
            "user": "asLKHFksasak",
            "type": "user"
          },
          "name": "Xiaowen Li",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:31:02.655Z",
          "hidden": false
        },
        {
          "_id": "678e125d09dc6d3a311cc04f",
          "name": "Haolan Xue",
          "hidden": false
        },
        {
          "_id": "678e125d09dc6d3a311cc050",
          "user": {
            "_id": "64b74a45f902508f0d786505",
            "avatarUrl": "/avatars/8bc5aaa011642827e12524c4f0a56927.svg",
            "isPro": false,
            "fullname": "Peiran REN",
            "user": "lyraestar",
            "type": "user"
          },
          "name": "Peiran Ren",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:30:47.443Z",
          "hidden": false
        },
        {
          "_id": "678e125d09dc6d3a311cc051",
          "user": {
            "_id": "63d0cc736b985b0f25d0412c",
            "avatarUrl": "/avatars/3eb8c79f9a7c4c819038ea7b04e323dd.svg",
            "isPro": false,
            "fullname": "Bo",
            "user": "Liefeng",
            "type": "user"
          },
          "name": "Liefeng Bo",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:30:55.550Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-17T08:03:02.000Z",
      "title": "DiffuEraser: 이미지의 불완전 부분을 보완하는 DifuEusion 모델",
      "summary": "최근의 비디오 인플레이스 알고리즘은 플로우 기반의 픽셀 전파와 트랜스포머 기반의 생성을 통합하여, 인접한 프레임으로부터의 정보를 활용하여 텍스트와 객체의 리스트를 복원하기 위해 광학 플로우를 활용하고 있습니다. 또한, 마스크 된 영역은 시각 트랜스포머로 완벽하게 처리되고 있습니다. 그러나 이러한 접근 방식은 큰 마스크를 처리할 때 브로드와 시간적 불확실성을 나타내며, 생성 능력의 향상이 필요합니다. 최근, 확산 모델은 이미지와 비디오의 생성에 우수한 성능을 보여주며, 중요한 기술로 꼽히고 있습니다. 본 논문에서는, 확산 모델 기반의 안정적인 비디오 인플레이스 모델 \"DiffuEraser\"을 소개하고, 마스크 된 영역을 더 상세한 디테일과 일관된 구조로 채우는 것을 목표로 합니다. 이전 정보와 결합하여, 초기化和 약한 조건을 제공하여 노이즈의 아버럴과 홀로잉을 억제할 수 있습니다. 또한, 긴 시퀀스 추론 시 시간적 일관성을 개선하기 위해, 이전 모델과 DiffuEraser의 시간적 수용野를 확장하고, 시간적 스무싱의 특성을 활용하여 일관성을 더욱 향상시킬 수 있습니다. 실험 결과를 통해, 우리 제안된 방법론이 콘텐츠의 완전성과 시간적 일관성에서 가장 先端의 기술을 초과하며, 인식 가능한 효율성을 유지하는 것을 보여줍니다.",
      "upvotes": 7,
      "discussionId": "678e125f09dc6d3a311cc0af"
    },
    "publishedAt": "2025-01-24T03:08:08.583Z",
    "title": "DiffuEraser: A Diffusion Model for Video Inpainting",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.10018.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "5f1158120c833276f61f1a84",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1608042047613-5f1158120c833276f61f1a84.jpeg",
      "fullname": "Niels Rogge",
      "name": "nielsr",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 735
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.13919",
      "authors": [
        {
          "_id": "679317f9d3ef2f790a539a28",
          "user": {
            "_id": "6785fc7d17a2dfa3720ec082",
            "avatarUrl": "/avatars/73e9d715bb16f14240c733c4843dfc22.svg",
            "isPro": false,
            "fullname": "Rui Li",
            "user": "ruili0",
            "type": "user"
          },
          "name": "Rui Li",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-01-24T10:17:34.282Z",
          "hidden": false
        },
        {
          "_id": "679317f9d3ef2f790a539a29",
          "user": {
            "_id": "65703fab7f50602340d23704",
            "avatarUrl": "/avatars/324c45f5fba9cd8c38a89b30427c06b4.svg",
            "isPro": false,
            "fullname": "Xiaohan Wang",
            "user": "nicholswang",
            "type": "user"
          },
          "name": "Xiaohan Wang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:11:30.999Z",
          "hidden": false
        },
        {
          "_id": "679317f9d3ef2f790a539a2a",
          "user": {
            "_id": "62da55164398e21bf7f0e292",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62da55164398e21bf7f0e292/xjKkG8IA2IZZqCdjApSh3.jpeg",
            "isPro": false,
            "fullname": "Yuhui Zhang",
            "user": "yuhuizhang",
            "type": "user"
          },
          "name": "Yuhui Zhang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:11:46.689Z",
          "hidden": false
        },
        {
          "_id": "679317f9d3ef2f790a539a2b",
          "name": "Zeyu Wang",
          "hidden": false
        },
        {
          "_id": "679317f9d3ef2f790a539a2c",
          "user": {
            "_id": "677c8b2e92550a07fcad0f50",
            "avatarUrl": "/avatars/2be26e8f25e98cfe5b1d227ee0409cd0.svg",
            "isPro": false,
            "fullname": "Serena Yeung-Levy",
            "user": "yeunglevy",
            "type": "user"
          },
          "name": "Serena Yeung-Levy",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:09:52.788Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-23T18:58:03.000Z",
      "title": "시계열 선호도 최적화에 의한 긴 비디오 이해",
      "summary": "장편 비디오에서의 시간계의 기초화의 효과적인 실현은 현재의 모델에서 어려운 도전입니다. 이 제한을 극복하기 위해 우리는 새로운 후학습 프레임워크인 \"Temporal Preference Optimization (TPO)\"를 제안합니다. TPO는 선호 학습을 통해 비디오-LMMs의 시간계의 기초화 능력을 향상시키는 것입니다. TPO는 두 가지 크기의 선호 데이터 세트를 사용하여 모델이 확실히 기초화된 시간계의 반응과 그 정확도가 낮은 시간계의 반응을 구분할 수 있습니다. 이러한 선호 데이터 세트에 의한 최적화로 TPO는 시간계의 이해를 크게 향상시키고, 자동 주석된 데이터의 의존성을 줄입니다. 장편 비디오 이해 벤치마크에서 다양한 실험을 통해 TPO의 효과성은 LongVideoBench, MLVU, Video-MME의 3가지 벤치마크에서 확인되었습니다. 특히, LLaVA-Video-TPO는 Video-MME 벤치마크에서 가장 우수한 7B 모델로 자리잡으며, TPO가 장편 비디오 이해의 시간계의 이유에 대한 교환성과 효율적인 해결책의 가능성에 대한 가능성을 보여주었습니다. 프로젝트 페이지: https://ruili33.github.io/tpo_website.",
      "upvotes": 7,
      "discussionId": "679317fcd3ef2f790a539ad6"
    },
    "publishedAt": "2025-01-23T23:33:03.175Z",
    "title": "Temporal Preference Optimization for Long-Form Video Understanding",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.13919.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "645dbaa6f5760d1530d7580d",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/645dbaa6f5760d1530d7580d/Bqob8arLZoHIgMwNZpL9I.jpeg",
      "fullname": "Simeon Emanuilov",
      "name": "s-emanuilov",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isMod": false,
      "followerCount": 16
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.13826",
      "authors": [
        {
          "_id": "67934585e4e44e2866b644f2",
          "user": {
            "_id": "6400ba2b261cfa61f3a00555",
            "avatarUrl": "/avatars/1311e0b5e21b1c94d73fcaf455d3c7f7.svg",
            "isPro": false,
            "fullname": "Kairui",
            "user": "KairuiHu",
            "type": "user"
          },
          "name": "Kairui Hu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-01-24T09:07:46.937Z",
          "hidden": false
        },
        {
          "_id": "67934585e4e44e2866b644f3",
          "user": {
            "_id": "64101f81b27543634e377fc1",
            "avatarUrl": "/avatars/557dd9d4707e3b38e0805dfb87c08004.svg",
            "isPro": false,
            "fullname": "Penghao Wu",
            "user": "craigwu",
            "type": "user"
          },
          "name": "Penghao Wu",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:21:29.750Z",
          "hidden": false
        },
        {
          "_id": "67934585e4e44e2866b644f4",
          "user": {
            "_id": "646e1ef5075bbcc48ddf21e8",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/_vJC0zeVOIvaNV2R6toqg.jpeg",
            "isPro": false,
            "fullname": "Pu Fanyi",
            "user": "pufanyi",
            "type": "user"
          },
          "name": "Fanyi Pu",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:21:39.917Z",
          "hidden": false
        },
        {
          "_id": "67934585e4e44e2866b644f5",
          "user": {
            "_id": "647efcc945baf21ad707e10c",
            "avatarUrl": "/avatars/e2fab1c9031eb0eec9f015a8fc237f64.svg",
            "isPro": false,
            "fullname": "Wang Xiao",
            "user": "wangxiao1208",
            "type": "user"
          },
          "name": "Wang Xiao",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:21:46.540Z",
          "hidden": false
        },
        {
          "_id": "67934585e4e44e2866b644f6",
          "user": {
            "_id": "62a993d80472c0b7f94027df",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62a993d80472c0b7f94027df/j5vp-IwLA2YBexylUHiQU.png",
            "isPro": false,
            "fullname": "Zhang Yuanhan",
            "user": "ZhangYuanhan",
            "type": "user"
          },
          "name": "Yuanhan Zhang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:26:42.528Z",
          "hidden": false
        },
        {
          "_id": "67934585e4e44e2866b644f7",
          "user": {
            "_id": "6230d750d93e84e233882dbc",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6230d750d93e84e233882dbc/4MGEekLW3oWzqeFWDWvIK.jpeg",
            "isPro": false,
            "fullname": "Xiang Yue",
            "user": "yuexiang96",
            "type": "user"
          },
          "name": "Xiang Yue",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:27:14.894Z",
          "hidden": false
        },
        {
          "_id": "67934585e4e44e2866b644f8",
          "name": "Bo Li",
          "hidden": false
        },
        {
          "_id": "67934585e4e44e2866b644f9",
          "user": {
            "_id": "62ab1ac1d48b4d8b048a3473",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1656826685333-62ab1ac1d48b4d8b048a3473.png",
            "isPro": false,
            "fullname": "Ziwei Liu",
            "user": "liuziwei7",
            "type": "user"
          },
          "name": "Ziwei Liu",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:27:30.310Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-23T16:51:47.000Z",
      "title": "Video-MMMU: 복수 수학 문제에서 지식 획득 평가\n\n전문 동영상\n\n(无额外文本)",
      "summary": "인간은 지식을 얻기 위해 3단계의 인지 단계를 거칩니다: 정보의 인식, 지식의 이해, 지식의 적용으로 문제 해결에 적용되는 단계입니다. 비디오는 이 학습 과정의 효과적인 매체이며, 이러한 인지 단계를 촉진할 수 있습니다. 그러나 현재의 비디오 벤치마크는 대규모 다모달 모델(LMMs)의 지식 획득 능력을 체계적으로 평가할 수 없기 때문에, 이러한 결함이 해결되지 않습니다. 이를 해결하기 위해, 비디오-MMMU(비디오 다모달 다학부 벤치마크)를 소개합니다. 비디오-MMMU는 6개의 학부 중 300개의 전문 수준의 비디오와 900개의 인간으로 정답된 질문을 선택하여, 인식, 이해, 적용 단계에 맞는 지식 획득을 평가합니다. 제안된 지식의 이익 측정, Δ 지식은 비디오 시청 후의 성능 향상을 정량화합니다. LMMs의 평가에서 인지 요구가 증가하면 성능이 급격히 떨어지고, 인간과 모델의 지식 획득 사이에서 명확한 차이를 드러내며, LMMs의 학습과 적용 능력의 향상이 필요함을 강조합니다.",
      "upvotes": 6,
      "discussionId": "67934587e4e44e2866b64597"
    },
    "publishedAt": "2025-01-24T04:24:01.412Z",
    "title": "Video-MMMU: Evaluating Knowledge Acquisition from Multi-Discipline Professional Videos",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.13826.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6400ba2b261cfa61f3a00555",
      "avatarUrl": "/avatars/1311e0b5e21b1c94d73fcaf455d3c7f7.svg",
      "fullname": "Kairui",
      "name": "KairuiHu",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 5
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2501.13554",
      "authors": [
        {
          "_id": "6793900eddc6cc37fdc74928",
          "user": {
            "_id": "65a909fe8581aad8c97a67d3",
            "avatarUrl": "/avatars/96570e47117e957543d9f0fe5e1d9d57.svg",
            "isPro": false,
            "fullname": "liutao",
            "user": "byliutao",
            "type": "user"
          },
          "name": "Tao Liu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-01-24T13:30:20.097Z",
          "hidden": false
        },
        {
          "_id": "6793900eddc6cc37fdc74929",
          "name": "Kai Wang",
          "hidden": false
        },
        {
          "_id": "6793900eddc6cc37fdc7492a",
          "name": "Senmao Li",
          "hidden": false
        },
        {
          "_id": "6793900eddc6cc37fdc7492b",
          "name": "Joost van de Weijer",
          "hidden": false
        },
        {
          "_id": "6793900eddc6cc37fdc7492c",
          "name": "Fahad Shahbaz Khan",
          "hidden": false
        },
        {
          "_id": "6793900eddc6cc37fdc7492d",
          "name": "Shiqi Yang",
          "hidden": false
        },
        {
          "_id": "6793900eddc6cc37fdc7492e",
          "name": "Yaxing Wang",
          "hidden": false
        },
        {
          "_id": "6793900eddc6cc37fdc7492f",
          "name": "Jian Yang",
          "hidden": false
        },
        {
          "_id": "6793900eddc6cc37fdc74930",
          "name": "Ming-Ming Cheng",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-23T10:57:22.000Z",
      "title": "하나의 프롬프트에 한 가지 이야기: 일관된 텍스트를 이미지로 생성하는 Free-Lunch",
      "summary": "텍스트로부터 이미지 생성 모델은 입력 프로ン퓰트로 고품질의 이미지를 생성할 수 있습니다. 그러나 이러한 모델은 이야기 속에서 고유의 정체성을 유지하면서 일관된 생성을 지원하는 것이 어려워서, 현재의 접근 방식은 일반적으로 큰 데이터 세트를 사용하여 확장 훈련이나 원 모델 구조의 추가 변경이 필요합니다. 이는 다른 데이터 세트나 다양한 분기 모델의 구조에 대한 적용 범위를 제한합니다. 본 논문에서는 언어 모델의 고유한 능력과 맥락 일관성을 인식하고, 하나의 프로ン퓰트로 고유의 정체성을 이해할 수 있음을 관찰합니다. 이 맥락 일관성을 참고하여, \"One-Prompt-One-Story\" (1Prompt1Story)라는 새로운 훈련 없이의 방법론을 제안합니다. 1Prompt1Story는 T2I 분기 모델을 위해 모든 프로ン퓰터를 하나의 입력으로 결합하여 초기에 고유의 정체성을 유지합니다. 다음으로, Singular-Value Reweighting과 Identity-Preserving Cross-Attention의 두 가지 새로운 방법을 사용하여 생성 프로세스를 정밀화하고, 각 프레임과 입력 설명과의 값을 더욱 잘 맞춥니다. 실험에서는 현재 일관된 T2I 생성 접근 방식과 비교하여, 양적인 측정과 질적인 평가로 이 방법론의 효과성을 보여주었습니다. 코드는 https://github.com/byliutao/1Prompt1Story에 제공됩니다.",
      "upvotes": 4,
      "discussionId": "67939013ddc6cc37fdc74a9d"
    },
    "publishedAt": "2025-01-24T08:34:50.383Z",
    "title": "One-Prompt-One-Story: Free-Lunch Consistent Text-to-Image Generation Using a Single Prompt",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.13554.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "65a909fe8581aad8c97a67d3",
      "avatarUrl": "/avatars/96570e47117e957543d9f0fe5e1d9d57.svg",
      "fullname": "liutao",
      "name": "byliutao",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2501.13452",
      "authors": [
        {
          "_id": "6793480ec6fd669f7341cf41",
          "name": "Jiangchuan Wei",
          "hidden": false
        },
        {
          "_id": "6793480ec6fd669f7341cf42",
          "name": "Shiyue Yan",
          "hidden": false
        },
        {
          "_id": "6793480ec6fd669f7341cf43",
          "user": {
            "_id": "6676c4f86f2ac48ee6c2f4d4",
            "avatarUrl": "/avatars/fea4e5be4da7a7047df567a4aa86de0c.svg",
            "isPro": false,
            "fullname": "linwenfeng",
            "user": "linwf",
            "type": "user"
          },
          "name": "Wenfeng Lin",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:18:06.509Z",
          "hidden": false
        },
        {
          "_id": "6793480ec6fd669f7341cf44",
          "name": "Boyuan Liu",
          "hidden": false
        },
        {
          "_id": "6793480ec6fd669f7341cf45",
          "name": "Renjie Chen",
          "hidden": false
        },
        {
          "_id": "6793480ec6fd669f7341cf46",
          "name": "Mingyu Guo",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-23T08:06:11.000Z",
      "title": "EchoVideo: 멀티모달 특성량 융합에 의한 정체 유지형 인간 비디오 생성",
      "summary": "최근의 영상 생성의 발전은 특히 정체성 유지 영상 생성(IPT2V)과 같은 각 서브 스크립션에 큰 영향을 미쳤습니다. 그러나 현재의 방법들은 \"복사와 패스트\"의artifacts와 낮은 유사도 문제를 둘러싸고 있습니다. 이는 낮은 수준의 얼굴 이미지 정보를 의존하고 있기 때문입니다. 이 의존성은 얼굴의 과도한 刚성과, 관련없는 세부 정보를 반영하는artifacts를 생성하게 됩니다. 이러한 문제를 해결하기 위해 우리는 EchoVideo를 제안하고 있습니다. EchoVideo는 두 가지 핵심 전략을 사용합니다: (1) 정체성 이미지 텍스트 융합 모듈(IITF)으로, 텍스트로부터 높은 수준의 의미적 특징을 통합하고, 얼굴의 정체성을 명확히捉え同时, 마스크, 자세, 빛의 변화를 제거하여artifacts의 발생을 피합니다; (2) 2단계 학습 단계로, 두 번째 단계에서 랜덤으로 shallow 얼굴 정보를 사용하는 상태 메소드를 포함합니다. 목표는 shallow 특징에 의한 충실도 향상과 과도한 의존 관계를 완화합니다. 이 단계는 학습 중 높은 수준의 특징을 사용하여 모델을 권장하고, 얼굴의 정체성을 더욱 강하게 표현하게 합니다. EchoVideo는 얼굴의 정체성을 유지하고, 전체의 조화를 유지하고 있습니다. 확장된 실험은, 고품질, 제어 가능한 비디오의 생성에 우수한 결과를 달성함을 보여줍니다.",
      "upvotes": 4,
      "discussionId": "67934811c6fd669f7341cfbf"
    },
    "publishedAt": "2025-01-24T02:59:28.457Z",
    "title": "EchoVideo: Identity-Preserving Human Video Generation by Multimodal Feature Fusion",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.13452.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "63468720dd6d90d82ccf3450",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63468720dd6d90d82ccf3450/tVBFlmZNz8FRMkOrDaDID.jpeg",
      "fullname": "YSH",
      "name": "BestWishYsh",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 28
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.10799",
      "authors": [
        {
          "_id": "679208664e521de952ca0cdc",
          "user": {
            "_id": "5df9c78eda6d0311fd3d541f",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/5df9c78eda6d0311fd3d541f/8oDFuP77l5zhvamXNVmnc.jpeg",
            "isPro": false,
            "fullname": "Yen-Ting Lin",
            "user": "yentinglin",
            "type": "user"
          },
          "name": "Yen-Ting Lin",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-01-23T09:17:30.742Z",
          "hidden": false
        },
        {
          "_id": "679208664e521de952ca0cdd",
          "user": {
            "_id": "62f690dfc58915315c504af5",
            "avatarUrl": "/avatars/a6732dda8cd7e37d9c0e0b1dfb68c66b.svg",
            "isPro": false,
            "fullname": "Di Jin",
            "user": "jindi",
            "type": "user"
          },
          "name": "Di Jin",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:15:36.716Z",
          "hidden": false
        },
        {
          "_id": "679208664e521de952ca0cde",
          "name": "Tengyu Xu",
          "hidden": false
        },
        {
          "_id": "679208664e521de952ca0cdf",
          "name": "Tianhao Wu",
          "hidden": false
        },
        {
          "_id": "679208664e521de952ca0ce0",
          "user": {
            "_id": "66a8611eb51510d82ed54231",
            "avatarUrl": "/avatars/ad559e774fee4914091b82c9831ae2a2.svg",
            "isPro": false,
            "fullname": "Sainbayar Sukhbaatar",
            "user": "sainbar",
            "type": "user"
          },
          "name": "Sainbayar Sukhbaatar",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:16:23.763Z",
          "hidden": false
        },
        {
          "_id": "679208664e521de952ca0ce1",
          "name": "Chen Zhu",
          "hidden": false
        },
        {
          "_id": "679208664e521de952ca0ce2",
          "user": {
            "_id": "6437de5d51c7ebfc813ce68a",
            "avatarUrl": "/avatars/144cb1c5d5a4a645080611953494f437.svg",
            "isPro": false,
            "fullname": "he",
            "user": "yunhe",
            "type": "user"
          },
          "name": "Yun He",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:16:34.273Z",
          "hidden": false
        },
        {
          "_id": "679208664e521de952ca0ce3",
          "name": "Yun-Nung Chen",
          "hidden": false
        },
        {
          "_id": "679208664e521de952ca0ce4",
          "user": {
            "_id": "62f023a36a027498eaa2f9cc",
            "avatarUrl": "/avatars/8ac1c5c74d0957e3c6cc94b3a7795c37.svg",
            "isPro": false,
            "fullname": "Jason Weston",
            "user": "spermwhale",
            "type": "user"
          },
          "name": "Jason Weston",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:15:25.564Z",
          "hidden": false
        },
        {
          "_id": "679208664e521de952ca0ce5",
          "user": {
            "_id": "6344cf73ee1504dbcd5bdfe7",
            "avatarUrl": "/avatars/6dd2bf1f9c5679e5c8c85d62c9836aac.svg",
            "isPro": false,
            "fullname": "Yuandong Tian",
            "user": "tydsh",
            "type": "user"
          },
          "name": "Yuandong Tian",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:16:47.602Z",
          "hidden": false
        },
        {
          "_id": "679208664e521de952ca0ce6",
          "name": "Arash Rahnama",
          "hidden": false
        },
        {
          "_id": "679208664e521de952ca0ce7",
          "user": {
            "_id": "65b483c5ed110eb9f1ee62df",
            "avatarUrl": "/avatars/29100098f5aed1735675d06c516a85b7.svg",
            "isPro": false,
            "fullname": "Sinong Wang",
            "user": "TheronWong",
            "type": "user"
          },
          "name": "Sinong Wang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:17:03.211Z",
          "hidden": false
        },
        {
          "_id": "679208664e521de952ca0ce8",
          "name": "Hao Ma",
          "hidden": false
        },
        {
          "_id": "679208664e521de952ca0ce9",
          "name": "Han Fang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-18T15:38:03.000Z",
      "title": "스텝・ケーション・オプティマイザー: 스텝별로 두 값의 피드백에 의한 수학적 논리의 최적화",
      "summary": "대 언어 모델(LLMs)은 최근 수학 계산의 이유론에 있어서 놀라운 성공을 보입니다. 연관 컨티닝 프로ン퓰팅이나 자기 일관성 샘플링 등 방법의 발전은, 최종적인 정확성을 보장하기 위해서는 이유론의 기초적인 조화성과 신뢰성을 확인하는 것이 거의 필요하지 않습니다. 본 논문에서는, 진화적인 이유론의 경로를 가이드하기 위한, 단계 수준과 결과 수준의 이진 피드백을 조합한 훈련 프레임워크 \"Step-KTO\"를 소개합니다. 단계 수준과 결과 수준 모두 이진 평가를 제공함으로써, 모델은 논리적인 진행을 중시하고, 표면적인 단축을 믿지 않도록 격려합니다. 수학의 어려운 벤치마크에서의 실험에 따라, 단계 수준의 이유론의 질을 높이며, 최종적인 답의 정확성을 크게 향상시키는 것이 확인되었습니다. 예를 들어, MATH-500 데이터 세트에서 단계 수준의 이유론의 질을 높이며, 최종적인 답의 정확성을 크게 향상시키는 것이 확인되었습니다. 이러한 결과를 통해, LLM 훈련에 단계별로 진행 피드백을 포함하는 가능성을 보여주고, 해석 가능한 신뢰성 있는 이유론의 기능에 도달하는 길을 열어놓습니다.",
      "upvotes": 4,
      "discussionId": "679208674e521de952ca0d2f"
    },
    "publishedAt": "2025-01-23T22:32:09.207Z",
    "title": "Step-KTO: Optimizing Mathematical Reasoning through Stepwise Binary Feedback",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/5df9c78eda6d0311fd3d541f/VXjkUKeidLg_JO5d3RWUG.jpeg"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.10799.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "5df9c78eda6d0311fd3d541f",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/5df9c78eda6d0311fd3d541f/8oDFuP77l5zhvamXNVmnc.jpeg",
      "fullname": "Yen-Ting Lin",
      "name": "yentinglin",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 281
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2501.13124",
      "authors": [
        {
          "_id": "6793188b56f015277a9ed95c",
          "user": {
            "_id": "65a6131fee7aa779f5bf8329",
            "avatarUrl": "/avatars/aa25cc3153fd7e511b51b801e8107564.svg",
            "isPro": false,
            "fullname": "langhao",
            "user": "langnick",
            "type": "user"
          },
          "name": "Hao Lang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:09:24.142Z",
          "hidden": false
        },
        {
          "_id": "6793188b56f015277a9ed95d",
          "user": {
            "_id": "635b8b6a37c6a2c12e2cce00",
            "avatarUrl": "/avatars/229fb72180529141515d1df797b33709.svg",
            "isPro": false,
            "fullname": "Fei Huang",
            "user": "hzhwcmhf",
            "type": "user"
          },
          "name": "Fei Huang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:09:39.353Z",
          "hidden": false
        },
        {
          "_id": "6793188b56f015277a9ed95e",
          "user": {
            "_id": "66641b2fd8e1e34bc621e688",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/66641b2fd8e1e34bc621e688/csPETwnx2zCIHSWi9uAi-.png",
            "isPro": false,
            "fullname": "Yongbin Li",
            "user": "Yongbin-Li",
            "type": "user"
          },
          "name": "Yongbin Li",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:08:59.394Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-21T05:36:13.000Z",
      "title": "디바ッ트는 약한 면에서 강한 면으로의 일반화에 촉발하는 역할을 합니다.",
      "summary": "通常, 모델의 능력과 기대하는 행동을 일치시키기 위한 방법은 인간이 감독을 제공하는 능력을 기반으로 합니다. 그러나 미래의 초인간 모델은 인간의 능력을 초월할 것입니다. 따라서 인간은 초인간 모델을 약한 감독만 할 수 있습니다. 이러한 예상되는 인간 평가의 부족은 미래의 AI 시스템의 안전성을 약화시킬 것입니다. 확장 가능한 감독과 약한에서 강한 일반화에 대한 두 가지 보완적인 방법은 이 문제를 해결하는 데 사용됩니다. 본 논문에서는 이러한 두 가지 방법을 결합하여 더 나은 일치성을 개선하는 데 시도합니다. 구체적으로, 우리는 강력한 사전 훈련된 모델을 사용하여 인간 감독을 개선하는 방법을 연구하고, 그 후 강화된 약한 인간 감독을 사용하여 강력한 모델을 감독하는 방법을 연구합니다. 반복적인实证적인 진전을 위해, 우리는 다음과 같은 비유를 고려합니다: 강력한 모델을 사용하여 약한 모델의 감독을 개선할 수 있는지, 그 후 이를 사용하여 강력한 모델을 감독할 수 있는지를 생각합니다. 우리는 실제 레이블에 대해 미세 조정된 작은 약한 모델을 사용하여 실험을 진행하며, 큰 강력한 모델의 추가 도움을 받아 약한 모델이 생성한 레이블을 사용하여 강력한 모델을 미세 조정합니다. 우리는 논쟁이 약한 모델이 불신한 강력한 모델에서 신뢰할 수 있는 정보를 추출할 수 있다는 것을 발견하였으며, 이는 약한 모델의 훈련 시 샘플의 탓을 제공하여 контекст을 제공합니다. 또한, 약한 모델의 통합은 강력한 모델의 논쟁가 생성한 긴 논점을 활용하여 더 강건한 감독 추정치를 얻을 수 있음을 보여주었습니다. OpenAI의 약한에서 강한 NLP 기준 테스트를 통해 광범위한 실험을 수행한 결과, 결합된 방법이 더 나은 일치성을 나타내며, 이는 논쟁이 약한에서 강한 일반화에 도움을 줄 수 있다는 잠재력을 나타냅니다.",
      "upvotes": 3,
      "discussionId": "6793188d56f015277a9ed9aa"
    },
    "publishedAt": "2025-01-23T23:35:50.957Z",
    "title": "Debate Helps Weak-to-Strong Generalization",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.13124.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "62e0ef42edb0462c8d51818d",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62e0ef42edb0462c8d51818d/3YM7DUynIWiiRFM6_enpg.jpeg",
      "fullname": "Ting-En Lin",
      "name": "tnlin",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 9
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.13075",
      "authors": [
        {
          "_id": "6791ae54330198cc26b72479",
          "user": {
            "_id": "6444241e9c1bd83bd19ea70f",
            "avatarUrl": "/avatars/24b4e65f26f5f8dcc1465cef67fd334b.svg",
            "isPro": false,
            "fullname": "Joel Lehman",
            "user": "jal278",
            "type": "user"
          },
          "name": "Joel Lehman",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-01-23T02:49:57.110Z",
          "hidden": false
        },
        {
          "_id": "6791ae54330198cc26b7247a",
          "user": {
            "_id": "6514b7fde1273c28705142cc",
            "avatarUrl": "/avatars/072bf14abd8ef17d9393338a20157cc2.svg",
            "isPro": false,
            "fullname": "Elliot Meyerson",
            "user": "ekmeyerson",
            "type": "user"
          },
          "name": "Elliot Meyerson",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:20:51.128Z",
          "hidden": false
        },
        {
          "_id": "6791ae54330198cc26b7247b",
          "name": "Tarek El-Gaaly",
          "hidden": false
        },
        {
          "_id": "6791ae54330198cc26b7247c",
          "name": "Kenneth O. Stanley",
          "hidden": false
        },
        {
          "_id": "6791ae54330198cc26b7247d",
          "name": "Tarin Ziyaee",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-22T18:38:41.000Z",
      "title": "머신 학습의 발전과 나이트 비시전\n\n(注意：虽然要求不添加解释或额外的文本，但为了确保翻译的准确性和专业性，这里提供了一个更符合韩国语习惯的翻译版本。)",
      "summary": "이 논문은 기계 학습(ML)이 일반적인 지능의 중요한 면을 크게 빚어놓은 것을 주장하고 있습니다: 개방된 세계에서 질적으로 모르는 미래에 대한 강건성. 이 강건성은 경제학의 Knightian uncertainty(KU)와 관련이 있으며, 즉, 양수화할 수 없는 불확실성, ML의 주요 형식론에서 고려되지 않은 것입니다. 이 논문은 이러한盲점을 식별하고 중요성을 주장하고, 이를 해결하기 위한 연구를 촉진하는 것을 목표로 합니다. 우리는 이것은 개방된 세계의 AI를 진정으로 강건하게 만드는 데 필수적인 것이고, 이러한盲점을 밝혀내는 데 ML의 한 영역인 강화 학습(RL)과 생물학적인 진화의 과정을 비교하고 있습니다. 진화는 놀라운 속도로 진행되더라도, RL은 여전히 개방된 세계의 상황에서 어려움을 감안하고 있으며, 예상되지 않는 상황에서 실패하는 경우가 많습니다. 예를 들어, 미국에서만 학습한 자율주행 정책이 영국에도 도입될 수 있다는 것은 현재 매우 야심勃勃입니다. 반면, 생물학적인 진화는 일반적으로 개방된 세계에서 생존하는 에이전트를 생산하고, 그 때에도 가장 놀라운 외란적인 상황에서도 생존할 수 있습니다(예: 침입종, 또는 인간, 같은 0-shot國際運転를 수행하는 것입니다). 흥미로운 점은, 진화는 명시적인 이론, 형식론, 또는 수학적인 경사를 갖지 않고 이러한 강건성을 달성하는 것입니다. RL의 일반적인 형식론의 기초적인 가정에 대해 조사하고, 이는 변화하는 복잡한 세계의 특징적인 \"unknown unknown\"와 관계에 대해 보여줍니다. 또한, 진화의 프로세스가 새로운 큰 도전에 대한 강건성을 촉진하는 구조를 식별하고, 그 알고리즘적인 구현의 가능한 패스웨이지를 논의하고 있습니다. 결론은, ML의 남은 흥미로운 취약성은 형식론의 blind point에서 발생할 수 있으며, KU의 도전에 직접 대응하여 큰 효과를 얻을 수 있다는 것입니다.",
      "upvotes": 2,
      "discussionId": "6791ae55330198cc26b724bc"
    },
    "publishedAt": "2025-01-24T01:17:22.150Z",
    "title": "Evolution and The Knightian Blindspot of Machine Learning",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.13075.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6444241e9c1bd83bd19ea70f",
      "avatarUrl": "/avatars/24b4e65f26f5f8dcc1465cef67fd334b.svg",
      "fullname": "Joel Lehman",
      "name": "jal278",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2501.13824",
      "authors": [
        {
          "_id": "6793a52265c4dd63499ca548",
          "user": {
            "_id": "662ce44c8b8705f30371fba8",
            "avatarUrl": "/avatars/b96a25a8c124e7caa9de06b7188bdc15.svg",
            "isPro": false,
            "fullname": "Shuzhou Yuan",
            "user": "shuzyuan",
            "type": "user"
          },
          "name": "Shuzhou Yuan",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-01-24T14:52:27.570Z",
          "hidden": false
        },
        {
          "_id": "6793a52265c4dd63499ca549",
          "name": "Michael Färber",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-23T16:45:51.000Z",
      "title": "하로윈조ン즈는 약물발견을 위해 대규모 언어 모델을 개선할 수 있습니다.",
      "summary": "라르지젯언어 모델(LLMs)에서 헛문(hallucination)의 우려는 연구자들에게 문제가 되고 있지만, 헛문이 창의성이 중요한 분야에서 잠재력을 가지고 있으며, 특히 약물발견 분야에서는 탐색의 가치를 지닌다고 평가되어 있습니다. 본 논문에서는 헛문이 약물발견 분야의 LLMs를 개선할 수 있다는 가정을 제안합니다. 이 가정을 검증하기 위해, LLMs를 사용하여 분자의 SMILES 문자열을 자연어로 설명하고, 이러한 설명을 특정 약물발견의 태스크의 Prompt의 일부로 사용함으로써 7개의 LLMs와 5개의 분류 태스크를 평가했습니다. 우리의 발견은 헛문이 포함된 텍스트로 LLMs가 더 좋은 성능을 달성할 수 있다는 가정을 확인했습니다. 특히, Llama-3.1-8B는 헛문이 없는 기준과 비교하여 ROC-AUC에서 18.35%의 개선을 달성했습니다. 또한, GPT-4o가 생성한 헛문이 모델 전체에서 가장 일관된 개선을 제공했습니다. 또한 실험적 분석과 사례 연구를 수행하여, 성능에 영향을 미치는 요인과 그 배경을 조사했습니다. 이 연구는 LLMs에서 헛문의 잠재적인 활용을 밝혀, 약물발견 분야의 LLMs의 활용을 확장하는 미래 연구에 새로운 시각을 제공합니다.",
      "upvotes": 1,
      "discussionId": "6793a52465c4dd63499ca5ad"
    },
    "publishedAt": "2025-01-24T09:39:01.834Z",
    "title": "Hallucinations Can Improve Large Language Models in Drug Discovery",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.13824.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "662ce44c8b8705f30371fba8",
      "avatarUrl": "/avatars/b96a25a8c124e7caa9de06b7188bdc15.svg",
      "fullname": "Shuzhou Yuan",
      "name": "shuzyuan",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2501.10283",
      "authors": [
        {
          "_id": "67934e1511eb9c774dd1bfc3",
          "user": {
            "_id": "67936c63ddd1e487c0c6c691",
            "avatarUrl": "/avatars/6d57469b4afdc8bedffeea9ed5f59dd4.svg",
            "isPro": false,
            "fullname": "Chengwei Zheng",
            "user": "zhengcw18",
            "type": "user"
          },
          "name": "Chengwei Zheng",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-01-24T13:30:16.388Z",
          "hidden": false
        },
        {
          "_id": "67934e1511eb9c774dd1bfc4",
          "user": {
            "_id": "645b95f8438d6cfbe1ae8256",
            "avatarUrl": "/avatars/ac0ebb0a73569ab063c5b2f28c509d23.svg",
            "isPro": false,
            "fullname": "Lixin Xue",
            "user": "lxxue",
            "type": "user"
          },
          "name": "Lixin Xue",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:27:50.665Z",
          "hidden": false
        },
        {
          "_id": "67934e1511eb9c774dd1bfc5",
          "name": "Juan Zarate",
          "hidden": false
        },
        {
          "_id": "67934e1511eb9c774dd1bfc6",
          "name": "Jie Song",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-17T16:26:24.000Z",
      "title": "GSTAR: 가우시안 표면 트라ッ킹과 리콘스트럭션",
      "summary": "3D 가우스 스프레팅 기술은 정적 시네의 효율적인 사진 렌더링에 성공했습니다. 최근의 연구는 이러한 접근 방식을 표면 구성과 추적에 확장했습니다. 그러나 3D 가우스을 사용하여 동적인 표면을 추적하는 것은 표면이 나타날 때, 사라질 때, 또는 분리할 때 등 복잡한 토폴로지 변화에 의해 어려워질 수 있습니다. 이러한 도전에 대응하기 위해 우리는 GSTAR라는 새로운 방법을 제안합니다. GSTAR은 일반적인 동적인 시네의 사진 렌더링, 정확한 표면 구성, 그리고 변화하는 토폴로지를 가진 일반적인 동적인 시네의 신뢰성 있는 3D 추적을 실현합니다. 다점 촬영을 입력으로 받아, GSTAR은 가우스를 메쉬의 면에 결합하여 동적인 오브젝트를 표현합니다. 토폴로지가 일치하는 표면에 대해, GSTAR은 메쉬의 토폴로지를 유지하고 가우스를 사용하여 메쉬를 추적합니다. 토폴로지가 변하는 곳에서는, GSTAR은 가우스를 메쉬에서 적응적으로 결합하고 해제하고, 이 최적화된 가우스를 기반으로 새로운 표면을 생성하는 것을 가능하게 합니다. 또한 표면 기반의 시네 플로우 방법을 소개하고, 프레임 간 추적을 강력한 초기화로 제공합니다. 실험은 우리의 방법론이 동적인 표면을 정확하게 추적하고 구성하여 다양한 애플리케이션을 가능하게 하는 것을 보여줍니다. 코드의 릴리즈와 프로젝트 페이지는 https://eth-ait.github.io/GSTAR/에 공개되어 있습니다.",
      "upvotes": 1,
      "discussionId": "67934e1611eb9c774dd1bffe"
    },
    "publishedAt": "2025-01-24T03:24:06.601Z",
    "title": "GSTAR: Gaussian Surface Tracking and Reconstruction",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.10283.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "5f1158120c833276f61f1a84",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1608042047613-5f1158120c833276f61f1a84.jpeg",
      "fullname": "Niels Rogge",
      "name": "nielsr",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 735
    },
    "isAuthorParticipating": false
  }
]