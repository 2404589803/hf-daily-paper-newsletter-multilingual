[
  {
    "paper": {
      "id": "2502.18411",
      "authors": [
        {
          "_id": "67be834ae7b05f9e43b172b2",
          "user": {
            "_id": "6530e62f536dbca918e71c3e",
            "avatarUrl": "/avatars/efc93bc767e561c6c6d429f65c23382d.svg",
            "isPro": false,
            "fullname": "Xiangyu Z",
            "user": "PhoenixZ",
            "type": "user"
          },
          "name": "Xiangyu Zhao",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-26T08:26:02.247Z",
          "hidden": false
        },
        {
          "_id": "67be834ae7b05f9e43b172b3",
          "user": {
            "_id": "646cd947da8e99940b6e55cf",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/646cd947da8e99940b6e55cf/9c0P0WppFqNW9pdo8LgOS.jpeg",
            "isPro": false,
            "fullname": "Shengyuan Ding",
            "user": "ChrisDing1105",
            "type": "user"
          },
          "name": "Shengyuan Ding",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-26T08:25:59.887Z",
          "hidden": false
        },
        {
          "_id": "67be834ae7b05f9e43b172b4",
          "user": {
            "_id": "675aa937ab6aa7ecd09341ce",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/d_CNUsNOw92pg7MVhf9Vm.png",
            "isPro": false,
            "fullname": "Zicheng Zhang",
            "user": "UniverseCA",
            "type": "user"
          },
          "name": "Zicheng Zhang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:49:10.028Z",
          "hidden": false
        },
        {
          "_id": "67be834ae7b05f9e43b172b5",
          "name": "Haian Huang",
          "hidden": false
        },
        {
          "_id": "67be834ae7b05f9e43b172b6",
          "name": "Maosong Cao",
          "hidden": false
        },
        {
          "_id": "67be834ae7b05f9e43b172b7",
          "user": {
            "_id": "619507e7b74b6c591f794340",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/619507e7b74b6c591f794340/JbPDoy6Ko1V1-6oJJwFV8.jpeg",
            "isPro": false,
            "fullname": "Weiyun Wang",
            "user": "Weiyun1025",
            "type": "user"
          },
          "name": "Weiyun Wang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:48:45.520Z",
          "hidden": false
        },
        {
          "_id": "67be834ae7b05f9e43b172b8",
          "user": {
            "_id": "64638c4d51fa6e63060521b5",
            "avatarUrl": "/avatars/c863ace5b1dc788a341bcf4ddbdfaec1.svg",
            "isPro": false,
            "fullname": "JIaqi",
            "user": "Jiaqiwang",
            "type": "user"
          },
          "name": "Jiaqi Wang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:48:38.876Z",
          "hidden": false
        },
        {
          "_id": "67be834ae7b05f9e43b172b9",
          "user": {
            "_id": "64f5f8dd9b17cd59c453c57f",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64f5f8dd9b17cd59c453c57f/MulhwLcePFUWUQel8LQZ8.jpeg",
            "isPro": false,
            "fullname": "Xinyu Fang",
            "user": "nebulae09",
            "type": "user"
          },
          "name": "Xinyu Fang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-26T08:26:04.433Z",
          "hidden": false
        },
        {
          "_id": "67be834ae7b05f9e43b172ba",
          "user": {
            "_id": "64d1c560c0c627dfa71bdbe0",
            "avatarUrl": "/avatars/f42794fe25bffcd870a1bcee69b95298.svg",
            "isPro": false,
            "fullname": "wenhai.wang",
            "user": "wangwhcore",
            "type": "user"
          },
          "name": "Wenhai Wang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:48:28.151Z",
          "hidden": false
        },
        {
          "_id": "67be834ae7b05f9e43b172bb",
          "name": "Guangtao Zhai",
          "hidden": false
        },
        {
          "_id": "67be834ae7b05f9e43b172bc",
          "user": {
            "_id": "63ee1379190ddd6214efd73a",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1676546883247-noauth.png",
            "isPro": false,
            "fullname": "HAODONG DUAN",
            "user": "KennyUTC",
            "type": "user"
          },
          "name": "Haodong Duan",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:48:20.155Z",
          "hidden": false
        },
        {
          "_id": "67be834ae7b05f9e43b172bd",
          "name": "Hua Yang",
          "hidden": false
        },
        {
          "_id": "67be834ae7b05f9e43b172be",
          "name": "Kai Chen",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-25T18:05:14.000Z",
      "title": "OmniAlign-V: 인간의 취향과 MLLM의 대응 향상을 위한 것입니다.",
      "summary": "최근의 오픈 소스 다 모델 대 언어 모델(MLLM)의 발전은 주로 기초적인 능력을 향상시키기 위한 데 초점을 맞추고 있지만, 인간의 취향에 맞는 데는 큰 결함이 있습니다. 본 논문에서는 OmniAlign-V라는, 200K건의 고품질의 훈련 샘플을 특징으로 하는, 다양한 이미지, 복잡한 질문, 그리고 다양한 답변 형식을 제시하는 통일된 데이터 세트를 소개합니다. 이들은 MLLM의 인간의 취향에 맞는 데 개선하기 위한 목적을 가지고 있습니다. 또한, MM-AlignBench라는, 인간이 설명한 벤치마크를 소개하고, 이는 MLLM의 인간의 가치에 맞는 데 평가를 위해 특별히 설계되었습니다. 실험 결과를 따르면, OmniAlign-V를 활용한, Supervised Fine-Tuning(SFT) 또는 Direct Preference Optimization(DPO)를 활용한 MLLM의 미세 조정은 표준의 VQA 벤치마크에서 성능을 유지하거나 향상시키면서, 인간의 취향에 맞는 데 크게 향상시키고 기초적인 능력을 유지할 수 있습니다. 우리 데이터 세트, 벤치마크, 코드 및 체크포인트는 https://github.com/PhoenixZ810/OmniAlign-V에 공개되어 있습니다.",
      "upvotes": 46,
      "discussionId": "67be834ce7b05f9e43b1730a"
    },
    "publishedAt": "2025-02-25T22:01:56.532Z",
    "title": "OmniAlign-V: Towards Enhanced Alignment of MLLMs with Human Preference",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.18411.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6530e62f536dbca918e71c3e",
      "avatarUrl": "/avatars/efc93bc767e561c6c6d429f65c23382d.svg",
      "fullname": "Xiangyu Z",
      "name": "PhoenixZ",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.18137",
      "authors": [
        {
          "_id": "67be8443ed8e258c0f70063a",
          "user": {
            "_id": "66c0a08bac74db25de8427ec",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/66c0a08bac74db25de8427ec/9D-piDBZqSt6KNkHImmkv.jpeg",
            "isPro": false,
            "fullname": "Jintao Zhang",
            "user": "jt-zhang",
            "type": "user"
          },
          "name": "Jintao Zhang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-26T08:25:57.704Z",
          "hidden": false
        },
        {
          "_id": "67be8443ed8e258c0f70063b",
          "user": {
            "_id": "6329bdbbde087eac2921e6a9",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1663679904323-noauth.jpeg",
            "isPro": false,
            "fullname": "Xiangchendong",
            "user": "Xiang-cd",
            "type": "user"
          },
          "name": "Chendong Xiang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:49:29.341Z",
          "hidden": false
        },
        {
          "_id": "67be8443ed8e258c0f70063c",
          "name": "Haofeng Huang",
          "hidden": false
        },
        {
          "_id": "67be8443ed8e258c0f70063d",
          "name": "Jia Wei",
          "hidden": false
        },
        {
          "_id": "67be8443ed8e258c0f70063e",
          "user": {
            "_id": "65d5a000ec7e31555e4db57e",
            "avatarUrl": "/avatars/aab8319fbaffdd53faff59a40ca5a5ea.svg",
            "isPro": false,
            "fullname": "Haocheng Xi",
            "user": "hxi0408",
            "type": "user"
          },
          "name": "Haocheng Xi",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:49:45.446Z",
          "hidden": false
        },
        {
          "_id": "67be8443ed8e258c0f70063f",
          "name": "Jun Zhu",
          "hidden": false
        },
        {
          "_id": "67be8443ed8e258c0f700640",
          "user": {
            "_id": "65fcad0ba0d7adc40b54fac2",
            "avatarUrl": "/avatars/7564b5642378fddb46ec3b5ae57c0402.svg",
            "isPro": false,
            "fullname": "Jianfei Chen",
            "user": "surfingtomchen",
            "type": "user"
          },
          "name": "Jianfei Chen",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:49:52.550Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-25T12:02:17.000Z",
      "title": "SpargeAttn: 정확한 스패르스 어텐션입니다. 이는 모델의 추론을 가속화하는 데 사용되는 접근 방식입니다.",
      "summary": "대규모 모델에서 효율적인 액션 구현이 중요하게 여겨지는 이유는 그 시간복잡성을 따릅니다. 다행히, 액션은 일반적으로 희소성을 나타내며, 즉, 액션 맵에 있는 많은 값이 근사치로 같아서 상대적인 계산을 줄일 수 있습니다. 많은 연구들은 희소 패턴을 활용하여 액션을 고속화하는 시도를 하고 있습니다. 그러나 현재의 많은 연구들은 특정 모델 내부에서 액션의 최적화를 목표로, 액션 맵의 특정 희소 패턴을 활용하고 있습니다. 다양한 모델의 속도 향상과 끝에서 끝까지 성능을 보장하는 일반적인 희소 액션은 지금까지 발견되지 않았습니다. 본 논문에서는 SpargeAttn이라는 일반적인 희소 및 퀀텀화 액션을 제안하여 모든 모델에서 사용할 수 있는 것을 제안합니다. 우리 방법은 두 단계의 온라인 필터를 사용합니다: 첫 번째 단계에서는 액션 맵을 신속하고 정확하게 예측하고, 액션의 일부 행렬곱을 스킵할 수 있게 합니다. 두 번째 단계에서는 온라인 소프트맥스에 관련된 필터를 설계하여 추가 오버헤드를 주지 않고 더 많은 행렬곱을 스킵할 수 있습니다. 실험은 우리 방법을 통해 언어, 이미지, 비디오의 생성 등 다양한 모델을 고속화하고 끝에서 끝까지 측정 지표를 잃지 않고 수행함을 보여줍니다. 코드는 https://github.com/thu-ml/SpargeAttn에 공개되어 있습니다.",
      "upvotes": 33,
      "discussionId": "67be8447ed8e258c0f70075f"
    },
    "publishedAt": "2025-02-25T22:04:57.351Z",
    "title": "SpargeAttn: Accurate Sparse Attention Accelerating Any Model Inference",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.18137.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "66c0a08bac74db25de8427ec",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/66c0a08bac74db25de8427ec/9D-piDBZqSt6KNkHImmkv.jpeg",
      "fullname": "Jintao Zhang",
      "name": "jt-zhang",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.17363",
      "authors": [
        {
          "_id": "67bd6d2bbf6d46017e619f31",
          "user": {
            "_id": "66078994c50f8393c56ed837",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/aYYde45zaFACRllyEhJyU.jpeg",
            "isPro": true,
            "fullname": "Tianrui Zhu",
            "user": "xilluill",
            "type": "user"
          },
          "name": "Tianrui Zhu",
          "status": "extracted_confirmed",
          "statusLastChangedAt": "2025-02-25T07:24:35.845Z",
          "hidden": false
        },
        {
          "_id": "67bd6d2bbf6d46017e619f32",
          "user": {
            "_id": "6315d306a9456afe2b9bf34a",
            "avatarUrl": "/avatars/7285b4e7d84b528d1a50f8ee4eb10727.svg",
            "isPro": false,
            "fullname": "ElevenZ",
            "user": "shiyi0408",
            "type": "user"
          },
          "name": "Shiyi Zhang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-26T08:30:48.262Z",
          "hidden": false
        },
        {
          "_id": "67bd6d2bbf6d46017e619f33",
          "user": {
            "_id": "646c6985d072747f7ebf352a",
            "avatarUrl": "/avatars/8aaf92045687b21b56c257db62bf4fa5.svg",
            "isPro": false,
            "fullname": "Jiawei Shao",
            "user": "jewelshaw",
            "type": "user"
          },
          "name": "Jiawei Shao",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:50:09.030Z",
          "hidden": false
        },
        {
          "_id": "67bd6d2bbf6d46017e619f34",
          "name": "Yansong Tang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-24T17:40:09.000Z",
      "title": "KV-Edit: 훈련 없이 이미지 편집 기술로 정확한 배경 보존이 가능합니다.",
      "summary": "배경 일관성은 이미지 편집 작업에서 중요한 문제로, 현재의 기술은 이 문제를 오랜 기간 개발해 왔습니다. 현재의 연구에서는 원본 이미지와 유사성을 유지하는 것과 목표에 맞는 내용을 생성하는 것 사이의 조화는 여전히 어려워 남아 있습니다. 여기에서, KV-Edit라는 훈련 필요 없는 접근 방식을 제안합니다. KV-Edit는 DiTs의 KV 캐시를 사용하여, 배경 일관성을 유지하면서 배경 토큰을 저장하고 재생되지 않도록 하여, 복잡한 구조나 고가의 훈련이 필요하지 않도록 하고, 사용자가 제공한 영역 내에서 背景와 연속적으로 새로운 내용을 생성하는 것을 목표로 합니다. 또한, 편집 중 KV 캐시의 메모리 소비를 자세히 조사하여, 반전 없는 방법을 사용하여 공간 복잡도를 O(1)로 최적화했습니다. 우리 접근 방식은, 추가적인 훈련을 필요로 하지 않도록 DiT 기반의 생성 모델의 확장성을 유지하고 있습니다. 실험에 따르면, KV-Edit는 배경과 이미지의 품질 모두에서, 현재의 접근 방식을 크게 초월하며, 훈련 기반의 방법을 초월하는 것을 증명했습니다. 프로젝트의 웹 페이지는 https://xilluill.github.io/projectpages/KV-Edit에 공개되어 있습니다.",
      "upvotes": 22,
      "discussionId": "67bd6d2dbf6d46017e619f99"
    },
    "publishedAt": "2025-02-25T21:36:19.851Z",
    "title": "KV-Edit: Training-Free Image Editing for Precise Background Preservation",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.17363.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "66078994c50f8393c56ed837",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/aYYde45zaFACRllyEhJyU.jpeg",
      "fullname": "Tianrui Zhu",
      "name": "xilluill",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.18449",
      "authors": [
        {
          "_id": "67be845a8a5a80542314579f",
          "user": {
            "_id": "632a176259950c1d279d5ea7",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/632a176259950c1d279d5ea7/xsSGhBXalt9RaKzSKY8uk.jpeg",
            "isPro": false,
            "fullname": "Yuxiang Wei",
            "user": "yuxiang630",
            "type": "user"
          },
          "name": "Yuxiang Wei",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:50:44.837Z",
          "hidden": false
        },
        {
          "_id": "67be845a8a5a8054231457a0",
          "name": "Olivier Duchenne",
          "hidden": false
        },
        {
          "_id": "67be845a8a5a8054231457a1",
          "user": {
            "_id": "6481e0ac50b759c75d5fdad0",
            "avatarUrl": "/avatars/49f08d989ca505ae01bce5578a94f6fe.svg",
            "isPro": false,
            "fullname": "Jade Copet",
            "user": "JadeCopet",
            "type": "user"
          },
          "name": "Jade Copet",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:50:58.290Z",
          "hidden": false
        },
        {
          "_id": "67be845a8a5a8054231457a2",
          "name": "Quentin Carbonneaux",
          "hidden": false
        },
        {
          "_id": "67be845a8a5a8054231457a3",
          "user": {
            "_id": "656f473c14fa8cfccd14559e",
            "avatarUrl": "/avatars/8f4fef3d835a7a11c2ab66dbf04f3424.svg",
            "isPro": false,
            "fullname": "Lingming Zhang",
            "user": "lingming",
            "type": "user"
          },
          "name": "Lingming Zhang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:51:10.640Z",
          "hidden": false
        },
        {
          "_id": "67be845a8a5a8054231457a4",
          "name": "Daniel Fried",
          "hidden": false
        },
        {
          "_id": "67be845a8a5a8054231457a5",
          "user": {
            "_id": "630eac7931970d1cd4fbacf2",
            "avatarUrl": "/avatars/b7ccbddfa745db854dc342be1327cd53.svg",
            "isPro": false,
            "fullname": "Gabriel Synnaeve",
            "user": "gsynnaeve",
            "type": "user"
          },
          "name": "Gabriel Synnaeve",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:51:21.641Z",
          "hidden": false
        },
        {
          "_id": "67be845a8a5a8054231457a6",
          "user": {
            "_id": "6597e5a6420dcc68501a69e9",
            "avatarUrl": "/avatars/da48b13e07c367ecd5c891abfd6c3ded.svg",
            "isPro": false,
            "fullname": "Rishabh Singh",
            "user": "RishabhSingh021",
            "type": "user"
          },
          "name": "Rishabh Singh",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:51:28.321Z",
          "hidden": false
        },
        {
          "_id": "67be845a8a5a8054231457a7",
          "name": "Sida I. Wang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-25T18:45:04.000Z",
      "title": "SWE-RL: 강화학습에 의한 LLM 추론의 발전 - 오픈 소프트웨어의 발전에 관한 연구\n\n(Note: The translation is provided as requested, without additional explanation or text.)",
      "summary": "최근의 DeepSeek-R1의 릴리즈는 대규모 언어 모델(LLMs)의 일반적인 인공 지능 능력을 강화하기 위해 강화학습(RL)의 큰 잠재력을 보여주었습니다. DeepSeek-R1과 다른 연속적인 작업들은 주로 RL을 마라톤 코딩 및 수학 문제를 적용하지만, 이 논문에서는 SWE-RL, RL 기반의 LLM의 인공 지능을 실제 세계적인 소프트웨어 엔지니어링에 확장하는 첫 번째 접근을 소개합니다. 가벼운 규칙 기반의 보상(예: 실제와 LLM 생성의 해결책의 유사도 점수)을 활용하여, SWE-RL은 LLM이 오픈 소스 소프트웨어의 진화 데이터로부터 개발자의 인공 지능 프로세스와 해결책을 자동으로 복원할 수 있게 합니다 - 소프트웨어의 합성 사이클 기록, 코드 스냅샷, 코드 변경, 버그 및 리푼 요청 등 이벤트를 포함합니다. Llama 3에 훈련된 결과, 우리 인공 지능 모델, Llama3-SWE-RL-70B은 SWE-bench Verified - GitHub의 실제 세계적인 문제의 인간 인증의 집합 -에서 41.0%의 해결률을 달성했습니다. 우리 지식에 따르면, 이것은 지금까지 보고된 중형(<100B) LLMs의 최고의 성능으로, GPT-4o와 같은 선진적인 개인 LLMs와 비교적으로도 상당히 있습니다. 놀라울 정도로, 소프트웨어 진화 데이터에 제한적으로 강화학습을 수행한 Llama3-SWE-RL은 확장된 인공 지능을 발견했습니다. 예를 들어, 함수 코딩, 라이브러리 사용, 코드 인공 지능, 수학, 일반적인 언어 이해의 5가지 외부 태스크에서 개선된 결과를 보여주고, 관찰적인 훈련 기반 선형 피치팅은 평균적으로 성능 저하를招致합니다. 전체적으로, SWE-RL은 강화학습을 대규모 소프트웨어 엔지니어링 데이터에 의해 LLM의 인공 지능을 향상시키는 새로운 방향을 개척합니다.",
      "upvotes": 14,
      "discussionId": "67be845b8a5a8054231457d6"
    },
    "publishedAt": "2025-02-25T22:03:08.515Z",
    "title": "SWE-RL: Advancing LLM Reasoning via Reinforcement Learning on Open Software Evolution",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.18449.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 6218
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.17262",
      "authors": [
        {
          "_id": "67bd3870a917fc506d9f3d15",
          "user": {
            "_id": "66ab06956b8847339d449128",
            "avatarUrl": "/avatars/d71490acb91981459121005b84e556d8.svg",
            "isPro": false,
            "fullname": "Xu Chengyin",
            "user": "JerryXu98",
            "type": "user"
          },
          "name": "Chengyin Xu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-25T09:39:44.252Z",
          "hidden": false
        },
        {
          "_id": "67bd3870a917fc506d9f3d16",
          "user": {
            "_id": "636b4d796e6981ebad73f398",
            "avatarUrl": "/avatars/bcd405b98c12afaf1e32d85ad8ce7f23.svg",
            "isPro": false,
            "fullname": "Kaiyuan Chen",
            "user": "Lucky2022",
            "type": "user"
          },
          "name": "Kaiyuan Chen",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-25T09:40:01.532Z",
          "hidden": false
        },
        {
          "_id": "67bd3870a917fc506d9f3d17",
          "name": "Xiao Li",
          "hidden": false
        },
        {
          "_id": "67bd3870a917fc506d9f3d18",
          "user": {
            "_id": "645604eebabbbbd3486dc615",
            "avatarUrl": "/avatars/17a5ca8274e2bfc8f183a4af9878a930.svg",
            "isPro": false,
            "fullname": "shenke",
            "user": "shenke18",
            "type": "user"
          },
          "name": "Ke Shen",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-25T09:39:49.578Z",
          "hidden": false
        },
        {
          "_id": "67bd3870a917fc506d9f3d19",
          "name": "Chenggang Li",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-24T15:44:57.000Z",
      "title": "LLM의 하류실적의 스케일링을 밝혀주는 방법: 클러스터링 기반의 시각화 방법\n\n(Note: The translation is provided as requested, without additional explanation or text.)",
      "summary": "진보적인 빠른 계산기 발전은 대규모 언어 모델(LLM)의 훈련 규모와 비용에 크게 영향을 미칩니다. 모델 훈련 전 하류 태스크의 성능을 정확하게 예측하는 것은 효율적인 리소스 분배에 중요하지만, 두 가지 주요한 제약으로 인해 어려움이 있습니다: (1) \"현상\"으로 인해 하류의 성능 메트릭은 훈련 후 상세한 의미가 있지만, 작은 모델을 사용하여 예측할 수 있는 능력이 제한됩니다; (2) 태스크의 난이도 분포의 불균형성과 일관된 스케일링 법칙의 존재하지 않는 것, 메트릭의 큰 변동을 초래합니다. 현재의 성능 예측 방법은 정확도와 신뢰성에 한계가 있으며, LLM의 잠재적 능력을 평가하는데 방해됩니다. 이러한 문제를 대처하기 위해COD(난이도에 기반한 클러스터링) 하류 성능 예측 프레임워크를 제안합니다.COD는 난이도 특성에 기반하여 태스크를 클러스터링하여 예측 가능한 지원 서브셋을 구축하고, 비현상적이고 비스케일링적인 클러스터를 전략적으로 제외합니다. 선택된 서브셋의 점수는 전체 평가 세트의 하류 성능에 효과적인 중간 예측자 역할을 합니다. 이론적인 지지를 갖으며, 가능한 서브셋으로부터의 성능 메트릭을 전체 평가 세트에 변환하는 함수를 얻을 수 있습니다. 제안된 방법은 70B LLM의 성능 스케일링 예측에 적용되었으며, 훈련 리소스의 분배에役立つ可能な행동을 제공하며, 훈련 프로세스의 관찰에役立ちます. 특히,COD는 작은 모델의 앙상블을 사용하여 70B LLM에서 눈에 띈 예측 정확도를 달성하고, 8개의 중요한 LLM 평가 벤치마크에서 절대 평균 이상도는 1.36%였습니다.",
      "upvotes": 13,
      "discussionId": "67bd3872a917fc506d9f3d8f"
    },
    "publishedAt": "2025-02-25T22:18:24.064Z",
    "title": "Unveiling Downstream Performance Scaling of LLMs: A Clustering-Based Perspective",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.17262.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "636b4d796e6981ebad73f398",
      "avatarUrl": "/avatars/bcd405b98c12afaf1e32d85ad8ce7f23.svg",
      "fullname": "Kaiyuan Chen",
      "name": "Lucky2022",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.15499",
      "authors": [
        {
          "_id": "67be86743ea16c7e9491ff16",
          "name": "Ya Wang",
          "hidden": false
        },
        {
          "_id": "67be86743ea16c7e9491ff17",
          "user": {
            "_id": "66335b9c95c5b79ebf306f30",
            "avatarUrl": "/avatars/d57784ee65cbef014360c9bac1ad4119.svg",
            "isPro": false,
            "fullname": "Zhijian Zhuo",
            "user": "BryceZhuo",
            "type": "user"
          },
          "name": "Zhijian Zhuo",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:58:10.556Z",
          "hidden": false
        },
        {
          "_id": "67be86743ea16c7e9491ff18",
          "user": {
            "_id": "6371128eafbe42caa5a5222b",
            "avatarUrl": "/avatars/c3b2ab35949c38aa3dfb2657a1300aac.svg",
            "isPro": false,
            "fullname": "Yutao Zeng",
            "user": "Taoer",
            "type": "user"
          },
          "name": "Yutao Zeng",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-26T08:25:55.016Z",
          "hidden": false
        },
        {
          "_id": "67be86743ea16c7e9491ff19",
          "user": {
            "_id": "62533db4a06ec75172eeabe7",
            "avatarUrl": "/avatars/b1a4dad90afae5c00df97233a97777db.svg",
            "isPro": false,
            "fullname": "xunzhou",
            "user": "xunzhou",
            "type": "user"
          },
          "name": "Xun Zhou",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:52:26.974Z",
          "hidden": false
        },
        {
          "_id": "67be86743ea16c7e9491ff1a",
          "name": "Jian Yang",
          "hidden": false
        },
        {
          "_id": "67be86743ea16c7e9491ff1b",
          "user": {
            "_id": "64648638351adef1a847a7ad",
            "avatarUrl": "/avatars/7518e058fcf81ee81a06c96e996531e9.svg",
            "isPro": false,
            "fullname": "Xiaoqing Li",
            "user": "LLIXQ",
            "type": "user"
          },
          "name": "Xiaoqing Li",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:51:57.314Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-21T14:49:34.000Z",
      "title": "스케일 분포의 탈출: 대규모 언어 모델의 안정적이고 효과적인 훈련을 가능하게 합니다.",
      "summary": "훈련의 안정성은 대규모 언어 모델(LLM)의 사전 학습에서 장기적인 문제로 알려져 있으며, 특히 Post-Norm Transformer와 같은 구조는 경사의 폭발과 소실로 취약합니다. 본 연구에서는 경사의 폭발과 소실을 방지하고 훈련을 안정화하기 위해 경사의 전파를 안정화하는 새로운 접근법인 \"스케일 분포의 분리(SDD)\"를 제안합니다. SDD는 전체 결합 계층의 가중 행렬의 스케일과 분포를 명시적으로 분리하고, 정규화 구조와 학습 가능한 스케일링 벡터를 사용하여 활성화를 조절합니다. 이를 통해 경사의 폭발과 소실을 방지하고 최적화의 효율화를 실현합니다. 이 분리는 경사의 안정한 전파를 보장하고, 특히 깊은 네트워크에서도 효과적으로 작동합니다. 실험 결과를 통해 다양한 LLM 구조의 훈련의 안정성을 보장하고, 다양한 정규화 설정에서도 기존 방법보다 뛰어난 결과를 보였습니다. 또한 제안된 방법은 가벼워서, 기존 프레임워크와의 호환성이 좋으며, LLM의 훈련의 안정화에 효과적인 실용적인 해결책입니다. 코드는 https://github.com/kaihemo/SDD에서 사용 가능합니다.",
      "upvotes": 10,
      "discussionId": "67be86753ea16c7e9491ff49"
    },
    "publishedAt": "2025-02-25T22:26:11.421Z",
    "title": "Scale-Distribution Decoupling: Enabling Stable and Effective Training of Large Language Models",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/6371128eafbe42caa5a5222b/eu6jpeTjTn34I1SJ4_K1a.png",
      "https://cdn-uploads.huggingface.co/production/uploads/6371128eafbe42caa5a5222b/P6mXXagZPsH6fwQ6myMlr.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.15499.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6371128eafbe42caa5a5222b",
      "avatarUrl": "/avatars/c3b2ab35949c38aa3dfb2657a1300aac.svg",
      "fullname": "Yutao Zeng",
      "name": "Taoer",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.18364",
      "authors": [
        {
          "_id": "67be81414084d82ee69ad4a2",
          "user": {
            "_id": "647e83257f9ad5e44babe82a",
            "avatarUrl": "/avatars/2d9593775c49856fe5dfa5bd23dfcda7.svg",
            "isPro": false,
            "fullname": "yifan pu",
            "user": "yifanpu001",
            "type": "user"
          },
          "name": "Yifan Pu",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:58:24.942Z",
          "hidden": false
        },
        {
          "_id": "67be81414084d82ee69ad4a3",
          "user": {
            "_id": "65e78ebf24a38e0fc5e149e6",
            "avatarUrl": "/avatars/d05e267f29de7de226c4fc0ae37c95ff.svg",
            "isPro": false,
            "fullname": "Yiming Zhao",
            "user": "2JZ",
            "type": "user"
          },
          "name": "Yiming Zhao",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:58:30.860Z",
          "hidden": false
        },
        {
          "_id": "67be81414084d82ee69ad4a4",
          "name": "Zhicong Tang",
          "hidden": false
        },
        {
          "_id": "67be81414084d82ee69ad4a5",
          "name": "Ruihong Yin",
          "hidden": false
        },
        {
          "_id": "67be81414084d82ee69ad4a6",
          "user": {
            "_id": "65229f2f6b01183a67e86370",
            "avatarUrl": "/avatars/b218207fce28497b30e22c807d44b2d2.svg",
            "isPro": false,
            "fullname": "Haoxing Ye",
            "user": "131131yhx",
            "type": "user"
          },
          "name": "Haoxing Ye",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:58:52.821Z",
          "hidden": false
        },
        {
          "_id": "67be81414084d82ee69ad4a7",
          "name": "Yuhui Yuan",
          "hidden": false
        },
        {
          "_id": "67be81414084d82ee69ad4a8",
          "user": {
            "_id": "666470a28f5513b0cf11e850",
            "avatarUrl": "/avatars/7beea758882677ad32a12ce56d4d084a.svg",
            "isPro": false,
            "fullname": "Dong Chen",
            "user": "DongChen06",
            "type": "user"
          },
          "name": "Dong Chen",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:59:16.526Z",
          "hidden": false
        },
        {
          "_id": "67be81414084d82ee69ad4a9",
          "user": {
            "_id": "646b2f4bb1202bc77c0fb396",
            "avatarUrl": "/avatars/6b09dec5d5affe817ad6acda60f61740.svg",
            "isPro": false,
            "fullname": "Jianmin_bao",
            "user": "JianminBao",
            "type": "user"
          },
          "name": "Jianmin Bao",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:59:22.654Z",
          "hidden": false
        },
        {
          "_id": "67be81414084d82ee69ad4aa",
          "user": {
            "_id": "64f7f119a92703ef65d9a717",
            "avatarUrl": "/avatars/118524faab66cecba6d4da622034b44b.svg",
            "isPro": false,
            "fullname": "Sirui Zhang",
            "user": "zsr200901",
            "type": "user"
          },
          "name": "Sirui Zhang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:59:30.766Z",
          "hidden": false
        },
        {
          "_id": "67be81414084d82ee69ad4ab",
          "user": {
            "_id": "67965a5a9f57883759a6efc3",
            "avatarUrl": "/avatars/9138a879fbe1f60c2f4720810bfdfda6.svg",
            "isPro": false,
            "fullname": "Yanbin Wang",
            "user": "yanbinwang",
            "type": "user"
          },
          "name": "Yanbin Wang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:59:38.138Z",
          "hidden": false
        },
        {
          "_id": "67be81414084d82ee69ad4ac",
          "name": "Lin Liang",
          "hidden": false
        },
        {
          "_id": "67be81414084d82ee69ad4ad",
          "user": {
            "_id": "6672e20d1dbdf7da8310dd92",
            "avatarUrl": "/avatars/5d2fb23f92a7f9ff025a5be17a26de4d.svg",
            "isPro": false,
            "fullname": "lijuanwang",
            "user": "lijuanwang228",
            "type": "user"
          },
          "name": "Lijuan Wang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T09:00:05.520Z",
          "hidden": false
        },
        {
          "_id": "67be81414084d82ee69ad4ae",
          "name": "Ji Li",
          "hidden": false
        },
        {
          "_id": "67be81414084d82ee69ad4af",
          "name": "Xiu Li",
          "hidden": false
        },
        {
          "_id": "67be81414084d82ee69ad4b0",
          "user": {
            "_id": "64c882f7527d7636555bbb2c",
            "avatarUrl": "/avatars/578a118a945dd6fa62fd3be9d6e4e986.svg",
            "isPro": false,
            "fullname": "Zhouhui Lian",
            "user": "lianzhouhui",
            "type": "user"
          },
          "name": "Zhouhui Lian",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T08:59:57.943Z",
          "hidden": false
        },
        {
          "_id": "67be81414084d82ee69ad4b1",
          "name": "Gao Huang",
          "hidden": false
        },
        {
          "_id": "67be81414084d82ee69ad4b2",
          "name": "Baining Guo",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-25T16:57:04.000Z",
      "title": "ART: 변수 다층 투명 이미지 생성을 위한 비명칭 영역 Transformer",
      "summary": "다층 이미지 생성은 사용자가 특정 이미지 레이어를 분리하고 선택하고 편집할 수 있는 기본적인 임무로, 생성 모델과 상호작용을 혁신적으로 변화시키는 데 필수적입니다. 본 논문에서는, 글로벌 텍스트 플롯과 익명 영역 배치에 기반하여 변수의 다층 투명 이미지를 직접 생성하는 Anonymous Region Transformer(ART)를 도입합니다. 단순 이론에 의한 지식의 구조화 모델로, 기존의 주요적인 의미적인 영역 배치와 달리, ART는 생성 모델이 자동으로 텍스트 토큰과 시각 토큰의 대응을 결정할 수 있게 합니다. 또한, 각 익명 영역에 속하는 시각 토큰만 선택하는 영역 크롭 구조는 주의 계산 비용의 크게 줄이고, 다층(예: 50 이상) 이미지의 효율적인 생성을 가능하게 합니다. 전체 주의 접근 방식과 비교하여 12배 이상 빠르고 레이어의 충돌이 줄어듭니다. 또한, ART는 효율적인 레이어의 생성과 시각성의 정밀한 제어를 가능하게 하고, 새로운 인터랙티브 콘텐츠 생성 패러다임을 구축합니다.",
      "upvotes": 7,
      "discussionId": "67be81464084d82ee69ad576"
    },
    "publishedAt": "2025-02-25T21:50:19.941Z",
    "title": "ART: Anonymous Region Transformer for Variable Multi-Layer Transparent Image Generation",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.18364.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "646f69a6041e48e1c4728de3",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/646f69a6041e48e1c4728de3/U5OaW6PgsXTXnfG03xs9Q.png",
      "fullname": "GlyphByT5",
      "name": "GlyphByT5",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 34
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.18461",
      "authors": [
        {
          "_id": "67bea0cc2d6011a72335f704",
          "user": {
            "_id": "67be9daa65ae638b17e461e9",
            "avatarUrl": "/avatars/30ab04b8a6a4d3e1d211943c0344b95e.svg",
            "isPro": false,
            "fullname": "Ziheng Ouyang",
            "user": "oyzh2005",
            "type": "user"
          },
          "name": "Ziheng Ouyang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-26T08:25:46.941Z",
          "hidden": false
        },
        {
          "_id": "67bea0cc2d6011a72335f705",
          "name": "Zhen Li",
          "hidden": false
        },
        {
          "_id": "67bea0cc2d6011a72335f706",
          "name": "Qibin Hou",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-25T18:59:12.000Z",
      "title": "K-LoRA: 어떤 섹트와 스타일의 LoRA를 무료로 통합하는 방법",
      "summary": "최근의 연구는 학습된 스타일과 내용을 동시에 생성하기 위해 서로 다른 LoRA를 조합하는 방법을 검토하고 있습니다. 그러나 현재의 방법들은 두 가지의 원형 주제와 스타일을 동시에 효과적으로 보존할 수 없거나 추가적인 훈련이 필요할 경우가 많은 것으로 나타났습니다. 본 논문에서는 LoRA의 내적 특성이 확산 모델에서 학습된 주제와 스타일을 효과적으로 융합시킬 수 있음을 주장합니다. 이 전망에 기반하여, K-LoRA라는 간단하고 효과적인 훈련 불필요한 LoRA 융합 접근법을 제안합니다. 각 어텐션 레이어에서, K-LoRA는 융합할 LoRA의 Top-K 요소를 비교하고, 최적의 융합에 적합한 LoRA를 선택합니다. 이 선택 구조는 융합 과정에서 주제와 스타일의 가장 대표적인 특성을 유지하고, 이들의 기여를 효과적으로 균형을 이루는 것을 보장합니다. 실험 결과를 통해 제안된 방법이 원형 LoRA가 학습한 주제와 스타일 정보를 효과적으로 통합하고, 질적 및 양적인 측면에서 가장 선진적인 훈련 기준을 초과하는 방법을 보여주고 있습니다.",
      "upvotes": 6,
      "discussionId": "67bea0cf2d6011a72335f7aa"
    },
    "publishedAt": "2025-02-26T00:56:27.275Z",
    "title": "K-LoRA: Unlocking Training-Free Fusion of Any Subject and Style LoRAs",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.18461.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6285a9133ab6642179158944",
      "avatarUrl": "/avatars/6e10fa07c94141fcdbe0cab02bb731ca.svg",
      "fullname": "Zhen Li",
      "name": "Paper99",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 14
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.18356",
      "authors": [
        {
          "_id": "67be8866823e790d21a2bb90",
          "user": {
            "_id": "6529aa1460e706730575baa9",
            "avatarUrl": "/avatars/550fac58a6ebf937a65d19a48e71eb45.svg",
            "isPro": false,
            "fullname": "George Thomas",
            "user": "georgethomas",
            "type": "user"
          },
          "name": "George Thomas",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T09:06:53.500Z",
          "hidden": false
        },
        {
          "_id": "67be8866823e790d21a2bb91",
          "user": {
            "_id": "636c1e4415cd58e915bc45df",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/636c1e4415cd58e915bc45df/KnPgdPe0G5ngvXaCBua6R.jpeg",
            "isPro": false,
            "fullname": "Alex J. Chan",
            "user": "XanderJC",
            "type": "user"
          },
          "name": "Alex J. Chan",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-02-26T03:20:08.029Z",
          "hidden": false
        },
        {
          "_id": "67be8866823e790d21a2bb92",
          "name": "Jikun Kang",
          "hidden": false
        },
        {
          "_id": "67be8866823e790d21a2bb93",
          "user": {
            "_id": "63a2f1dfc8a2aa5d9e85f8f6",
            "avatarUrl": "/avatars/f2191e3a0ce92563f9bfe83283d8d966.svg",
            "isPro": false,
            "fullname": "Wenqi Wu",
            "user": "BiggieW",
            "type": "user"
          },
          "name": "Wenqi Wu",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T09:08:43.843Z",
          "hidden": false
        },
        {
          "_id": "67be8866823e790d21a2bb94",
          "user": {
            "_id": "64f46b681d337935d0495d4d",
            "avatarUrl": "/avatars/cce5a4910617931fb13062b832e14ef8.svg",
            "isPro": false,
            "fullname": "Filippos Christianos",
            "user": "semitable",
            "type": "user"
          },
          "name": "Filippos Christianos",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T09:08:23.534Z",
          "hidden": false
        },
        {
          "_id": "67be8866823e790d21a2bb95",
          "user": {
            "_id": "5f195784925b9863e28ad610",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1595496291585-noauth.png",
            "isPro": false,
            "fullname": "Fraser Greenlee",
            "user": "Fraser",
            "type": "user"
          },
          "name": "Fraser Greenlee",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T09:08:16.380Z",
          "hidden": false
        },
        {
          "_id": "67be8866823e790d21a2bb96",
          "name": "Andy Toulis",
          "hidden": false
        },
        {
          "_id": "67be8866823e790d21a2bb97",
          "user": {
            "_id": "6787c4a970c0f5272f456968",
            "avatarUrl": "/avatars/bdfa53add57b0f0a9e4e94e24115b354.svg",
            "isPro": false,
            "fullname": "Marvin Purtorab",
            "user": "comvergent-marvin",
            "type": "user"
          },
          "name": "Marvin Purtorab",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T09:07:42.610Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-25T16:45:08.000Z",
      "title": "웹게임: 어려운 일반적인 홈페이지 검색 AI 에이전트",
      "summary": "WebGames는 일반적인 웹 브로싱 AI 에이전트의 평가를 목적으로 50점 이상의 상호작용적인 문제를 모아 만든 엄격한 벤치마크 시트입니다. 이 문제를 특별히 설계하여 인간에게 쉽게 할 수 있는 것처럼, 현재의 AI 시스템의 기본적인 브라우저 상호작용, 높은 입력 처리, 인지적인 태스크, 워크 플로우 자동화, 상호작용적인 엔터테인먼트에 대한 제한을 체계적으로 검증하는 데 목적이 있습니다. 프레임워크는 외부 의존성을 제외하고 조화로운 테스트 환경에서 재현 가능한 평가를 보장합니다. GPT-4o, Claude Computer-Use, Gemini-1.5-Pro, Qwen2-VL 등 첨단 시각 언어 모델을 인간의 성능과 비교하여 평가합니다. 결과는 큰 능력의 차이가 있으며, 가장 좋은 AI 시스템은 인간의 성능과 비교하여 95.7%의 성공률을 달성할 43.1%입니다. 인간이 직감적으로 이해할 수 있는 일반적인 웹 상호작용 패턴의 처리 능력의 근본적인 한계가 밝혀져 있습니다. 벤치마크는 webgames.convergence.ai에서 공개할 수 있으며, 가벼운 클라이언트 측 구현을 제공하여 빠른 평가 사이클을 촉진합니다. 표준화된 문제规格와 모듈화된 아키텍처를 통해, WebGames는 더 유능한 웹 브로싱 AI 에이전트의 개발 진척을 측정하는 강력한 기반을 제공합니다.",
      "upvotes": 4,
      "discussionId": "67be8868823e790d21a2bbea"
    },
    "publishedAt": "2025-02-25T22:20:16.916Z",
    "title": "WebGames: Challenging General-Purpose Web-Browsing AI Agents",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.18356.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 6218
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.16794",
      "authors": [
        {
          "_id": "67be86a78a5a80542314f0e6",
          "user": {
            "_id": "6531a65daed617662c7f1007",
            "avatarUrl": "/avatars/ea2e504780dc40719f7501ab2c7d9c91.svg",
            "isPro": false,
            "fullname": "Xilin Jiang",
            "user": "xi-j",
            "type": "user"
          },
          "name": "Xilin Jiang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-26T08:25:52.841Z",
          "hidden": false
        },
        {
          "_id": "67be86a78a5a80542314f0e7",
          "user": {
            "_id": "661361993bb67cb4f356c3de",
            "avatarUrl": "/avatars/b707c07f9c70d2ed1e8cd8cff2551c69.svg",
            "isPro": false,
            "fullname": "Sukru Samet Dindar",
            "user": "susameddin",
            "type": "user"
          },
          "name": "Sukru Samet Dindar",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T09:11:37.706Z",
          "hidden": false
        },
        {
          "_id": "67be86a78a5a80542314f0e8",
          "user": {
            "_id": "670e8671ba29b3fca221b8c9",
            "avatarUrl": "/avatars/20f6479bd5218d6d3e304539df5003f9.svg",
            "isPro": false,
            "fullname": "Vishal Choudhari",
            "user": "vchoudhari",
            "type": "user"
          },
          "name": "Vishal Choudhari",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T09:11:45.258Z",
          "hidden": false
        },
        {
          "_id": "67be86a78a5a80542314f0e9",
          "name": "Stephan Bickel",
          "hidden": false
        },
        {
          "_id": "67be86a78a5a80542314f0ea",
          "name": "Ashesh Mehta",
          "hidden": false
        },
        {
          "_id": "67be86a78a5a80542314f0eb",
          "name": "Guy M McKhann",
          "hidden": false
        },
        {
          "_id": "67be86a78a5a80542314f0ec",
          "name": "Adeen Flinker",
          "hidden": false
        },
        {
          "_id": "67be86a78a5a80542314f0ed",
          "name": "Daniel Friedman",
          "hidden": false
        },
        {
          "_id": "67be86a78a5a80542314f0ee",
          "name": "Nima Mesgarani",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-24T03:06:45.000Z",
      "title": "AAD-LLM: 뉴럴 어텐션 구동 음향 스케어 이해",
      "summary": "음향 기반 모델, 특히 음향 대 언어 모델(LLMs)을 포함하는 것은 모든 음성 입력을 균일하게 처리하고, 듣는 사람의 인식에 의존하지 않는다. 그러나, 인간의 음향 인식은 고유의 선택성을 가지고 있다: 듣는 사람은 복잡한 음향 스케일에서 특정 스피커를 집중하고, 나머지를 무시한다. 현재의 모델은 이러한 선택성을 갖지 않기 때문에, 인식에 맞는 응답을 생성하는 능력이 제한되어 있다. 이에 대처하여, 우리는 Intention-Informed Auditory Scene Understanding(II-ASU)를 도입하고, 뇌 신호를 통합하여 듣는 사람의 주의를 추정하는 프로토 타입 시스템인 Auditory Attention-Driven LLM(AAD-LLM)을 소개한다. AAD-LLM은 뇌 내 전기 값 프로그래밍(iEEG)의 기록을 통합하여, 듣는 사람이 주목하고 있는 스피커를 해석하고, 상대적으로 개선된 응답을 생성한다. 모델은 신경 활성으로부터 주목하고 있는 스피커를 예측하고, 이 예측된 주의 상태에 따라 응답의 생성을 조건부하게 한다. AAD-LLM은 다 태일러 스케인에서 스피커 설명, 연설 번역, 추출, 질문에 대한 뉴스에 있어서, 주관적 및 객관적인 평가를 통해 듣는 사람의 의도에 맞는 리저스트를 향상시키는 것을 보여주고 있다. 이 작업은 의도에 대한 음향 AI의 첫 번째 단계를 시도하고, 듣는 사람의 인식이 기계의 듣기를 정보를 제공하는 새로운 패러다임을 탐색하는 시도이다. 데모와 코드는 다음 URL에서 사용 가능합니다: https://aad-llm.github.io.",
      "upvotes": 4,
      "discussionId": "67be86a98a5a80542314f16e"
    },
    "publishedAt": "2025-02-25T22:20:08.416Z",
    "title": "AAD-LLM: Neural Attention-Driven Auditory Scene Understanding",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.16794.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "6531a65daed617662c7f1007",
      "avatarUrl": "/avatars/ea2e504780dc40719f7501ab2c7d9c91.svg",
      "fullname": "Xilin Jiang",
      "name": "xi-j",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.17425",
      "authors": [
        {
          "_id": "67bddd63c7d8b835b82ced9a",
          "user": {
            "_id": "635364b3c41f548fe39db945",
            "avatarUrl": "/avatars/ad1916bbfabca0b6651c8eabacc5eba8.svg",
            "isPro": false,
            "fullname": "Runpeng Yu",
            "user": "rp-yu",
            "type": "user"
          },
          "name": "Runpeng Yu",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T09:14:07.580Z",
          "hidden": false
        },
        {
          "_id": "67bddd63c7d8b835b82ced9b",
          "user": {
            "_id": "64396ebc21221ac7411852b3",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64396ebc21221ac7411852b3/SR0dC8N0bdj9tZFxYPpSf.jpeg",
            "isPro": false,
            "fullname": "Xinyin Ma",
            "user": "horseee",
            "type": "user"
          },
          "name": "Xinyin Ma",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T09:14:13.670Z",
          "hidden": false
        },
        {
          "_id": "67bddd63c7d8b835b82ced9c",
          "user": {
            "_id": "63fc03a50aab060792ffef39",
            "avatarUrl": "/avatars/9d5b1bb2a41928e08176b703935133ab.svg",
            "isPro": false,
            "fullname": "Wangxinchao",
            "user": "wxcTest",
            "type": "user"
          },
          "name": "Xinchao Wang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T09:14:53.838Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-24T18:56:12.000Z",
      "title": "Visual Perception Token을 Multimodal Large Language Model에 통합하는 방법을 소개합니다.",
      "summary": "ビジュアル情報의 활용에 따라, 다모달 대언어 모델(MLLM)은 시각 엔코더의 인식 처리에 의존합니다. 시각 인식의 완전성과 정확도는 공간적 논리, 세부적인 이해, 기타 태스크의 정확도에 큰 영향을 미칩니다. 그러나 MLLM은 이미지의 특정 영역을 선택적으로 검토하거나 특정 물체 카테고리에 관련된 정보를 집중하는 등 자동 제어 능력을 갖지 않습니다. 본 연구에서는 시각 인식 토큰의 개념을 제안하고, MLLM이 시각 인식 처리를 제어하는 구조를 부여하는 것을 목표로 합니다. Region Selection Token과 Vision Re-Encoding Token의 2가지 유형의 시각 인식 토큰을 설계하고, MLLM은 이러한 토큰을 생성하여 추가적인 시각 인식 액션을 시작합니다. Region Selection Token은 이미지의 특정 영역을 명확히하고, 그 영역에 대해 진행합니다. Vision Re-Encoding Token은 그 은닉 상태를 제어 신호로 사용하며, 추가적인 시각 인식 프로세스를 가이드합니다. 확장된 실험은 이러한 토큰이 공간적 논리, 세부적인 이해, 기타 태스크에서의 우세를 보여주고 있습니다. 평균적으로, 시각 인식 토큰의 도입은 2B 모델의 성능을 23.6% 높이고, 점수를 0.572에서 0.708로 높였으며, 7B 파라미터 모델을 13.4% 초과(0.624에서)합니다. 로컬 확인을 부탁드립니다. https://github.com/yu-rp/VisualPerceptionToken",
      "upvotes": 3,
      "discussionId": "67bddd64c7d8b835b82cee5a"
    },
    "publishedAt": "2025-02-26T02:37:36.287Z",
    "title": "Introducing Visual Perception Token into Multimodal Large Language Model",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.17425.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "635364b3c41f548fe39db945",
      "avatarUrl": "/avatars/ad1916bbfabca0b6651c8eabacc5eba8.svg",
      "fullname": "Runpeng Yu",
      "name": "rp-yu",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.17535",
      "authors": [
        {
          "_id": "67beaec94a1d9d7e368a7840",
          "user": {
            "_id": "66a4a319a1711696948b045c",
            "avatarUrl": "/avatars/1d92d57a949332cb8227697b9a0c2f39.svg",
            "isPro": false,
            "fullname": "Zhenheng Tang",
            "user": "coolzhtang",
            "type": "user"
          },
          "name": "Zhenheng Tang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T09:15:34.971Z",
          "hidden": false
        },
        {
          "_id": "67beaec94a1d9d7e368a7841",
          "name": "Xiang Liu",
          "hidden": false
        },
        {
          "_id": "67beaec94a1d9d7e368a7842",
          "name": "Qian Wang",
          "hidden": false
        },
        {
          "_id": "67beaec94a1d9d7e368a7843",
          "name": "Peijie Dong",
          "hidden": false
        },
        {
          "_id": "67beaec94a1d9d7e368a7844",
          "name": "Bingsheng He",
          "hidden": false
        },
        {
          "_id": "67beaec94a1d9d7e368a7845",
          "user": {
            "_id": "6676935fcd0b89a0115174b0",
            "avatarUrl": "/avatars/4caca1b672d29e787814f9a30bf20bcc.svg",
            "isPro": false,
            "fullname": "Xiaowen Chu",
            "user": "wenxinsiju",
            "type": "user"
          },
          "name": "Xiaowen Chu",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-02-26T09:15:41.884Z",
          "hidden": false
        },
        {
          "_id": "67beaec94a1d9d7e368a7846",
          "name": "Bo Li",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-24T15:39:35.000Z",
      "title": "로ッテリー LLM 가설, LLM 압축 시 어떤 능력이 유지되어야 하는지에 대한 재검토",
      "summary": "모델의 계산 비용과 저장 비용의 감소를 동기로 LLMs의 모델 압축과 KV 캐시 압축이 연구자들에게 주목받고 있습니다. 그러나 현재의 방법들은 주로 압축된 LLMs의 성능을 측정하는 어려움이나 단순한 정확도를 유지하는 것을 우선시하고 있습니다. 이 블로그에서는 LLMs와 관련된 검색 어셈블리 생성, 다단계 논리, 외부 도구, 계산적 표현성의 최근 진보에 대해 성능을 크게 향상시킬 수 있는 간단한 리뷰를 제공합니다. 이어서 동일한 성능을 발휘할 수 있는 작은 라틴어 LLM의 존재를 다단계 논리와 외부 도구의 도움을 받아 라틴어 LLM 가설을 제안합니다. 현재 LLMs의 발전에 대한 리뷰에 기초하여 라틴어 LLM과 KV 캐시 압축이 필요로 하는 기본적인 능력을 논의하고, 현재 법에서 놓쳐져 있는 것을 설명합니다.",
      "upvotes": 3,
      "discussionId": "67beaeca4a1d9d7e368a7875"
    },
    "publishedAt": "2025-02-26T01:04:23.776Z",
    "title": "The Lottery LLM Hypothesis, Rethinking What Abilities Should LLM Compression Preserve?",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.17535.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "63024676056ec3a2a8714b24",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1661093436322-noauth.jpeg",
      "fullname": "Xiang Liu",
      "name": "Dominic789654",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 4
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.17092",
      "authors": [
        {
          "_id": "67bea8cc7e54112af6c372aa",
          "user": {
            "_id": "63d9e09f1cae35c27bf80cb2",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1675223055197-noauth.jpeg",
            "isPro": true,
            "fullname": "Syed Abdul Gaffar Shakhadri",
            "user": "SyedAbdul",
            "type": "user"
          },
          "name": "Syed Abdul Gaffar Shakhadri",
          "status": "extracted_confirmed",
          "statusLastChangedAt": "2025-02-26T05:52:19.355Z",
          "hidden": false
        },
        {
          "_id": "67bea8cc7e54112af6c372ab",
          "user": {
            "_id": "5fb7ae48e6ae537272bdeb3c",
            "avatarUrl": "/avatars/e5d01cb428f4b22161e0d17895a5c678.svg",
            "isPro": false,
            "fullname": "Kruthika",
            "user": "kruthika",
            "type": "user"
          },
          "name": "Kruthika KR",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-02-26T05:38:21.529Z",
          "hidden": false
        },
        {
          "_id": "67bea8cc7e54112af6c372ac",
          "user": {
            "_id": "677cc34fe4cf361eedccd085",
            "avatarUrl": "/avatars/e97a3f9a84ed258ab4b75c12865562d6.svg",
            "isPro": false,
            "fullname": "Kartik Basavaraj Angadi",
            "user": "KartikAngadi",
            "type": "user"
          },
          "name": "Kartik Basavaraj Angadi",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-02-26T05:38:21.529Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-24T12:15:07.000Z",
      "title": "Shakti-VLMs: 기업 AI를 위한 scalable Vision-Language Model\n\n(注意：原文中的“企業AI向けのスケーラブルなビジョン・ラングワードモデル”被翻译为“기업 AI를 위한 scalable Vision-Language Model”，其中“Vision-Language Model”是更常见的术语，而“scalable”则保留了原文的含义，以保持专业性和准确性。)",
      "summary": "Shakti VLM는 1B와 4B 파라미터의 비젼 런그레이시움 모델의 가족입니다. 이 모델들은 여러 모드 학습의 데이터 효율성 문제를 해결하기 위해 설계되었습니다. 최근의 VLM은 큰 훈련 데이터로 강력한 성능을 달성하지만, Shakti 모델은 아키텍처의 혁신을 활용하여 적은 토큰으로 경쟁적인 결과를 얻을 수 있습니다. 주요 진보점은 QK-Normalization(アテンション의 안정화), 하이브리드 정규화 방법, 위치 인코딩의 향상이 있습니다. 세 단계 훈련 전략은 학습 효율을 향상시킵니다. 평가에 따르면 Shakti-VLM-1B과 Shakti-VLM-4B는 문서 이해, 시각적 논리, OCR 추출, 일반적인 다 모드 논리 등에서 뛰어납니다. 우리의 결과는 높은 성능은 모델의 설계와 훈련 전략에 의해 실현될 수 있으며, 이는 데이터 크기만 아니라 기업 규모의 다 모드 태스크에 효율적인 해결책으로 작용하는 것을 명확히 알 수 있습니다.",
      "upvotes": 2,
      "discussionId": "67bea8cd7e54112af6c37305"
    },
    "publishedAt": "2025-02-26T00:38:42.527Z",
    "title": "Shakti-VLMs: Scalable Vision-Language Models for Enterprise AI",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.17092.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "63d9e09f1cae35c27bf80cb2",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1675223055197-noauth.jpeg",
      "fullname": "Syed Abdul Gaffar Shakhadri",
      "name": "SyedAbdul",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isMod": false,
      "followerCount": 6
    },
    "isAuthorParticipating": true
  }
]