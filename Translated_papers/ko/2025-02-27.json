[
  {
    "paper": {
      "id": "2502.18934",
      "authors": [
        {
          "_id": "67bfe1bf4426925c82fe5953",
          "name": "Kanana LLM Team",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe5954",
          "name": "Yunju Bak",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe5955",
          "name": "Hojin Lee",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe5956",
          "user": {
            "_id": "60436d159e905013ae8715d7",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1623809612769-60436d159e905013ae8715d7.jpeg",
            "isPro": false,
            "fullname": "Minho Ryu",
            "user": "bzantium",
            "type": "user"
          },
          "name": "Minho Ryu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-27T09:14:17.979Z",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe5957",
          "user": {
            "_id": "66ebb4fdc5b2c25450fd17de",
            "avatarUrl": "/avatars/e6b40dcbe2eba838ba21be9221758a3c.svg",
            "isPro": false,
            "fullname": "Jiyeon Ham",
            "user": "jiyeonham",
            "type": "user"
          },
          "name": "Jiyeon Ham",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-27T09:14:11.786Z",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe5958",
          "name": "Seungjae Jung",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe5959",
          "user": {
            "_id": "66c82a50c1b3c03c61aea140",
            "avatarUrl": "/avatars/3c508f96bdca2f2ce9746d3decd4718e.svg",
            "isPro": false,
            "fullname": "daniel nam",
            "user": "daniel-rl2",
            "type": "user"
          },
          "name": "Daniel Wontae Nam",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-27T09:14:09.613Z",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe595a",
          "name": "Taegyeong Eo",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe595b",
          "name": "Donghun Lee",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe595c",
          "user": {
            "_id": "6142e17fe9e656d4459121e4",
            "avatarUrl": "/avatars/6baebd4598a845ec7fdb735eb0d53139.svg",
            "isPro": false,
            "fullname": "Doohae Jung",
            "user": "Doohae",
            "type": "user"
          },
          "name": "Doohae Jung",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-27T09:14:06.858Z",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe595d",
          "user": {
            "_id": "60f559be68ee3ef098e407cf",
            "avatarUrl": "/avatars/e1f00ff1c1c9fa7f591535d39c7d5e44.svg",
            "isPro": false,
            "fullname": "Boseop Kim",
            "user": "seopbo",
            "type": "user"
          },
          "name": "Boseop Kim",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-27T09:14:01.989Z",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe595e",
          "user": {
            "_id": "6605028007a154c768e1c4c7",
            "avatarUrl": "/avatars/88678edb83fdb466067e38acd22d07de.svg",
            "isPro": false,
            "fullname": "Nayeon Kim",
            "user": "lana-ny",
            "type": "user"
          },
          "name": "Nayeon Kim",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-27T09:14:13.867Z",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe595f",
          "user": {
            "_id": "6136f65440e43b8f748a0833",
            "avatarUrl": "/avatars/f72a5ae3d3e94485de8aed8df94abdad.svg",
            "isPro": false,
            "fullname": "Jaesun Park",
            "user": "jaesun",
            "type": "user"
          },
          "name": "Jaesun Park",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-27T09:14:15.898Z",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe5960",
          "name": "Hyunho Kim",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe5961",
          "name": "Hyunwoong Ko",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe5962",
          "user": {
            "_id": "63d268bb57ab367124ea7b75",
            "avatarUrl": "/avatars/11312cde1e9f077aa9e5103b48be5de6.svg",
            "isPro": false,
            "fullname": "Changmin Lee",
            "user": "changminlee",
            "type": "user"
          },
          "name": "Changmin Lee",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-27T09:14:04.506Z",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe5963",
          "name": "Kyoung-Woon On",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe5964",
          "name": "Seulye Baeg",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe5965",
          "name": "Junrae Cho",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe5966",
          "name": "Sunghee Jung",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe5967",
          "name": "Jieun Kang",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe5968",
          "name": "EungGyun Kim",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe5969",
          "name": "Eunhwa Kim",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe596a",
          "name": "Byeongil Ko",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe596b",
          "name": "Daniel Lee",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe596c",
          "name": "Minchul Lee",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe596d",
          "name": "Miok Lee",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe596e",
          "name": "Shinbok Lee",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe596f",
          "name": "Gaeun Seo",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-26T08:36:20.000Z",
      "title": "카나나: 계산 효율적인 바이리언어 언어 모델",
      "summary": "카나나, 한국어와 영어에서 뛰어난 성능을 보여주는 바이리언어 언어 모델 시리즈를 소개합니다. 카나나의 계산 비용은 같은 크기의 최신 모델보다 크게 저렴합니다. 보고서에서는 효율적인 모델을 구현하기 위해 사용된 방법을 자세히 설명하고 있습니다. 그 중에는 고품질 데이터 필터링, 단계별 사전 학습, 깊이 업스케일링, 프리닝과 디자이너, 그리고 카나나 모델의 후 학습 기간에 사용된 방법을 설명하고 있습니다. 그 중에는 사용자와의 무결한 피닝과 취미 최적화를 포함하는 서브 프로모션입니다. 마지막으로, 특정 언어 모델의 스케나리오에 적용할 수 있는 가능성 있는 접근도 자세히 설명하고 있습니다. 카나나 모델 시리즈는 210억부터 325억 파라미터의 범위로 확장되어 있으며, 210억 파라미터의 모델(베이스, 인스톰트, 엔베디닝)은 공개되어 한국어 모델 연구에 기여하는 것을 목표로 합니다.",
      "upvotes": 39,
      "discussionId": "67bfe1c04426925c82fe59a1"
    },
    "publishedAt": "2025-02-26T23:05:13.440Z",
    "title": "Kanana: Compute-efficient Bilingual Language Models",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.18934.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60436d159e905013ae8715d7",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1623809612769-60436d159e905013ae8715d7.jpeg",
      "fullname": "Minho Ryu",
      "name": "bzantium",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 5
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.19400",
      "authors": [
        {
          "_id": "67bfd6f15db054ee3c5a766b",
          "user": {
            "_id": "631d760344503b7227837242",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/631d760344503b7227837242/3b6JRusFX6GKJpsN9ZdeJ.png",
            "isPro": false,
            "fullname": "Max Ku",
            "user": "vinesmsuic",
            "type": "user"
          },
          "name": "Max Ku",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-27T09:14:55.238Z",
          "hidden": false
        },
        {
          "_id": "67bfd6f15db054ee3c5a766c",
          "user": {
            "_id": "6365d5baa7a1324ccd5ecdb9",
            "avatarUrl": "/avatars/636d3f410b878e451a878a6cf171dd53.svg",
            "isPro": false,
            "fullname": "Thomas Chong",
            "user": "chongcht",
            "type": "user"
          },
          "name": "Thomas Chong",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-27T09:14:49.567Z",
          "hidden": false
        },
        {
          "_id": "67bfd6f15db054ee3c5a766d",
          "name": "Jonathan Leung",
          "hidden": false
        },
        {
          "_id": "67bfd6f15db054ee3c5a766e",
          "user": {
            "_id": "67bfdfdbf856fd8ddbb7e0f0",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/rIR0QnVM3wxMCulG2R9SJ.png",
            "isPro": false,
            "fullname": "Krish Shah",
            "user": "KrishKrosh",
            "type": "user"
          },
          "name": "Krish Shah",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-27T09:14:47.269Z",
          "hidden": false
        },
        {
          "_id": "67bfd6f15db054ee3c5a766f",
          "user": {
            "_id": "6696061aa8dbb9a9997dfff6",
            "avatarUrl": "/avatars/d8f0bbff362fd630e6e60aab141076d3.svg",
            "isPro": false,
            "fullname": "Alvin Yu",
            "user": "AlvinYuVotee",
            "type": "user"
          },
          "name": "Alvin Yu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-27T09:14:52.146Z",
          "hidden": false
        },
        {
          "_id": "67bfd6f15db054ee3c5a7670",
          "name": "Wenhu Chen",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-26T18:50:09.000Z",
      "title": "TheoremExplainAgent: LLM 定리 이해를 위한 다중모달 설명에 관한 연구\n\n(Note: The translation is provided as requested, maintaining professionalism and accuracy while adhering to the format requirements.)",
      "summary": "특정 분야의 정리에 대한 이해는 문맥 기반의 이유만으로는 충분하지 않고, 구조화된 시각화 설명을 통해 효과적인 의사소통이 깊은 이해에 필수적이다. 대규모 언어 모델(LLMs)은 문맥 기반의 정리의 이유에 강한 성능을 보여주지만, 협동적이고 교육적으로 의미 있는 시각화 설명을 생성하는 능력은 개방된 문제로 간주된다. 본 연구에서는, Manim 애니메이션을 사용하여 긴 기간의 정리 설명 비디오(5분 이상)을 생성하기 위한 TheoremExplainAgent를 도입하였다. 다형성 평가의 위해, 240개 이상의 정리를 포함하는 다양한 STEM 분야의 TheoremExplainBench를 제안하고, 5개의 자동 평가 지표를 적용하였다. 결과적으로, 효과적인 비디오의 생성에 대한 에이전트의 계획이 중요함을 명확히 확인했으며, o3-mini 에이전트는 성공률 93.8%와 종합 점수 0.77을 달성하였다. 그러나 양적 및 질적 연구에 따르면, 생성된 많은 비디오는 시각화 요소의 순서에 약간의 문제를 가지고 있었다. 또한, 다형성 설명은 문맥 기반의 설명이 숨겨놓은 깊은 이유의 결함이 명확히 드러내며, 다형성 설명의 중요성을 강조하였다.",
      "upvotes": 17,
      "discussionId": "67bfd6f25db054ee3c5a7699"
    },
    "publishedAt": "2025-02-26T22:07:49.438Z",
    "title": "TheoremExplainAgent: Towards Multimodal Explanations for LLM Theorem Understanding",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.19400.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 6232
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.19361",
      "authors": [
        {
          "_id": "67bfe435ca6e3c22b6e29442",
          "name": "Yancheng He",
          "hidden": false
        },
        {
          "_id": "67bfe435ca6e3c22b6e29443",
          "name": "Shilong Li",
          "hidden": false
        },
        {
          "_id": "67bfe435ca6e3c22b6e29444",
          "name": "Jiaheng Liu",
          "hidden": false
        },
        {
          "_id": "67bfe435ca6e3c22b6e29445",
          "name": "Weixun Wang",
          "hidden": false
        },
        {
          "_id": "67bfe435ca6e3c22b6e29446",
          "name": "Xingyuan Bu",
          "hidden": false
        },
        {
          "_id": "67bfe435ca6e3c22b6e29447",
          "user": {
            "_id": "638efcf4c67af472d316d424",
            "avatarUrl": "/avatars/97a57859d7d87a3a8f1bb41d32a72bc2.svg",
            "isPro": false,
            "fullname": "Ge Zhang",
            "user": "zhangysk",
            "type": "user"
          },
          "name": "Ge Zhang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-27T09:13:58.959Z",
          "hidden": false
        },
        {
          "_id": "67bfe435ca6e3c22b6e29448",
          "name": "Zhongyuan Peng",
          "hidden": false
        },
        {
          "_id": "67bfe435ca6e3c22b6e29449",
          "name": "Zhaoxiang Zhang",
          "hidden": false
        },
        {
          "_id": "67bfe435ca6e3c22b6e2944a",
          "name": "Wenbo Su",
          "hidden": false
        },
        {
          "_id": "67bfe435ca6e3c22b6e2944b",
          "name": "Bo Zheng",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-26T17:59:27.000Z",
      "title": "큰 언어 모델은 긴 컨텍스트의 생각연쇄에서 오류를 감지하는가?",
      "summary": "최근 o1-likeモデル가 주목을 받고 있습니다. 이 모델들은 긴 Chain-of-Thought(CoT)를 생성하여 현재의 Large Language Models(LLMs)의 추론능력을 향상시킵니다. 본 연구에서는 이러한 긴 CoT의 질을 이해하고 현재의 LLMs가 이러한 긴 CoT에 대한 평가능력을 측정하기 위해 DeltaBench를 사용합니다. DeltaBench는 QwQ, DeepSeek-R1 등 다양한 o1-likeモデル이 생성한 긴 CoT을 포함하며 수학, 코드, 일반적인 추론 등 다양한 추론업무에 사용됩니다. 이를 통해 긴 CoT의 추론에 대한 오류검출능력을 측정할 수 있습니다. DeltaBench를 기반으로 첫째, 생성된 긴 CoT에 대해 세밀한 분석을 수행하여 각 o1-likeモデル의 효과성과 효율성을 발견합니다. 둘째, 현재의 Process Reward Models(PRMs)와 평가모델에 대한 확장된 평가를 수행하여 각 추론에 대한 오류를 검출하는 것을 목표로 PRMs와 평가모델의 경계와 한계를 조사합니다. 최종적으로, DeltaBench는 개발자에게 모델의 긴 CoT의 추론능력을 더 잘 이해할 수 있도록 하고자 동시에, 그 모델의 긴 CoT의 추론능력을 더 잘 이해할 수 있도록 하고자 합니다.",
      "upvotes": 12,
      "discussionId": "67bfe438ca6e3c22b6e2948e"
    },
    "publishedAt": "2025-02-26T23:04:47.406Z",
    "title": "Can Large Language Models Detect Errors in Long Chain-of-Thought Reasoning?",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.19361.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "65377c30e48353201e6fdda0",
      "avatarUrl": "/avatars/a8f803b6f2e598eaee9c52c0d2ddfc16.svg",
      "fullname": "Jiaheng Liu",
      "name": "CheeryLJH",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 7
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.19328",
      "authors": [
        {
          "_id": "67bfcb774d22a9379b29334c",
          "name": "Hao Peng",
          "hidden": false
        },
        {
          "_id": "67bfcb774d22a9379b29334d",
          "name": "Yunjia Qi",
          "hidden": false
        },
        {
          "_id": "67bfcb774d22a9379b29334e",
          "name": "Xiaozhi Wang",
          "hidden": false
        },
        {
          "_id": "67bfcb774d22a9379b29334f",
          "name": "Zijun Yao",
          "hidden": false
        },
        {
          "_id": "67bfcb774d22a9379b293350",
          "name": "Bin Xu",
          "hidden": false
        },
        {
          "_id": "67bfcb774d22a9379b293351",
          "name": "Lei Hou",
          "hidden": false
        },
        {
          "_id": "67bfcb774d22a9379b293352",
          "name": "Juanzi Li",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-26T17:19:12.000Z",
      "title": "Agentic Reward Modeling: 인간의 취향과 증명 가능한 정확한 신호를 통합한 신뢰성 있는 보상 시스템",
      "summary": "보상모듈(RMs)은 대규모 언어 모듈(LLMs)의 훈련 및 추론 시의 스케일링에 중요한 역할을 수행합니다. 그러나 현재의 보상 모듈은 주로 인간의 취향에 초점을 맞추고, 검증 가능한 정확성 신호에 대한 주목을 미루어 있으며, LLMs의 훈련에 강력한 잠재력을 보여주고 있는 것을 지나치게 낡게 보아왔습니다. 본 논문에서는 검증 가능한 정확성 신호를 조합한 보상 모듈로서 에이전트 보상 모델링을 제안합니다. 이 보상 시스템은 검증 가능한 정확성 신호와 보상 모듈을 조합하여 신뢰성 있는 보상을 제공하는 것을 목표로 합니다. 실험적으로는 인간의 취향의 보상과 사실성과 지시에 따라 두 가지 검증 가능한 신호를 조합한 보상 에이전트인 \"RewardAgent\"를 구현하여 신뢰성 있는 보상을 제공하는 것을 목표로 합니다. 현재의 보상 모듈 벤치마크와 실제 세계적인 하류 태스크의 추론 시의 best-of-n 검색에 대해 실험을 수행하였으며, RewardAgent는 현재의 보상 모듈보다 뚜렷하게 우수합니다. 또한 RewardAgent를 사용하여 훈련 선호의 페어를 구축하고 DPO의 목표를 가진 LLM을 훈련함으로써 전통적인 보상 모듈과 비교하여 다양한 NLP 벤치마크에서 상위 성능을 달성했습니다. 우리 코드는 공개되어 있으며, 진보적인 연구를 위해 유연성을 제공합니다(https://github.com/THU-KEG/Agentic-Reward-Modeling).",
      "upvotes": 11,
      "discussionId": "67bfcb784d22a9379b29338f"
    },
    "publishedAt": "2025-02-26T22:05:16.150Z",
    "title": "Agentic Reward Modeling: Integrating Human Preferences with Verifiable Correctness Signals for Reliable Reward Systems",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.19328.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "625a5446f1063e7085d5178a",
      "avatarUrl": "/avatars/5e78186f13f74b14e01583e06ff6c4dc.svg",
      "fullname": "Hao Peng",
      "name": "Wesleythu",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.17955",
      "authors": [
        {
          "_id": "67bff526ca6e3c22b6e89d71",
          "user": {
            "_id": "65d2f1e0fe21569868393411",
            "avatarUrl": "/avatars/1401020e76d958bef3f33e7449773694.svg",
            "isPro": false,
            "fullname": "Tushar Aggarwal",
            "user": "AggarwalTushar",
            "type": "user"
          },
          "name": "Tushar Aggarwal",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-02-27T05:16:24.257Z",
          "hidden": false
        },
        {
          "_id": "67bff526ca6e3c22b6e89d72",
          "name": "Kumar Tanmay",
          "hidden": false
        },
        {
          "_id": "67bff526ca6e3c22b6e89d73",
          "user": {
            "_id": "61a7cbb0fcbbebe775bf17fd",
            "avatarUrl": "/avatars/8b54907c6a1ea90a1242f26e03e117af.svg",
            "isPro": false,
            "fullname": "Ayush Agrawal",
            "user": "ayush1801",
            "type": "user"
          },
          "name": "Ayush Agrawal",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-27T09:13:56.625Z",
          "hidden": false
        },
        {
          "_id": "67bff526ca6e3c22b6e89d74",
          "name": "Kumar Ayush",
          "hidden": false
        },
        {
          "_id": "67bff526ca6e3c22b6e89d75",
          "name": "Hamid Palangi",
          "hidden": false
        },
        {
          "_id": "67bff526ca6e3c22b6e89d76",
          "name": "Paul Pu Liang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-25T08:27:18.000Z",
      "title": "언어 모델의 사실성은 질문의 언어에 의존합니다.",
      "summary": "다언어 언어 모델(LMs)는 여러 언어에서 사실적인 지식이 일관되게 기억되는 것을 기대하지만, 이들은 각각의 언어에서 정확한 정보를 가지고 있는 경우에도, 지식의 이동이 실패할 수 있습니다. 예를 들어, 阿拉伯語의 질문에서, Rashed Al Shashai가 第三イヤを출生地とする 것을 정확히 인식할 수 있습니다が, 영어나 スワハリ語で 질문을 받을 때, 이러한 지식을 정확히 인식하는 것이 어려워집니다. 이러한 제한을 체계적으로 조사하기 위해, 13가지 언어에 걸쳐 10,000건의 국제관계의 사실에 기반한 벤치마크를 제안하고, 사실적인 기억 스코어, 지식의 이동성 스코어, 코스라인 라운딩 사실적인 지식의 이동성 스코어를 제안했습니다. 이러한 스코어는 LMs가 서로 다른 언어에서 사실적인 기억과 지식의 이동성을 정량화하기 위해 사용됩니다. 우리의 결과를 통해, 현재의 가장 先端의 LMs의 기본적인 약점을 밝혀, 특히, 서로 다른 언어에서 지식의 이동성이 낮은 것을 보여, 이로 인해 언어에 따라 강조되는 성능의 불확실성을 나타냅니다. 우리의 발견은, LMs가 언어특유의 사실의 신뢰성을 인식하고, 서로 다른 언어에서 가장 신뢰받는 정보를 활용하는 필요성을 강조합니다. 우리의 벤치마크와 평가 프레임워크를 공개하고, 향후 다언어 지식의 이동에 대한 연구를 추진하는 것을 목표로 합니다.",
      "upvotes": 9,
      "discussionId": "67bff528ca6e3c22b6e89ddd"
    },
    "publishedAt": "2025-02-27T00:17:58.262Z",
    "title": "Language Models' Factuality Depends on the Language of Inquiry",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.17955.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "65d2f1e0fe21569868393411",
      "avatarUrl": "/avatars/1401020e76d958bef3f33e7449773694.svg",
      "fullname": "Tushar Aggarwal",
      "name": "AggarwalTushar",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.18864",
      "authors": [
        {
          "_id": "67bfd957c2a9b64ab3f97aa7",
          "name": "Juraj Gottweis",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97aa8",
          "name": "Wei-Hung Weng",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97aa9",
          "name": "Alexander Daryin",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97aaa",
          "name": "Tao Tu",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97aab",
          "name": "Anil Palepu",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97aac",
          "name": "Petar Sirkovic",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97aad",
          "name": "Artiom Myaskovsky",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97aae",
          "name": "Felix Weissenberger",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97aaf",
          "name": "Keran Rong",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ab0",
          "name": "Ryutaro Tanno",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ab1",
          "name": "Khaled Saab",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ab2",
          "name": "Dan Popovici",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ab3",
          "name": "Jacob Blum",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ab4",
          "name": "Fan Zhang",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ab5",
          "name": "Katherine Chou",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ab6",
          "name": "Avinatan Hassidim",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ab7",
          "name": "Burak Gokturk",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ab8",
          "name": "Amin Vahdat",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ab9",
          "name": "Pushmeet Kohli",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97aba",
          "name": "Yossi Matias",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97abb",
          "name": "Andrew Carroll",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97abc",
          "name": "Kavita Kulkarni",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97abd",
          "name": "Nenad Tomasev",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97abe",
          "name": "Yuan Guan",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97abf",
          "name": "Vikram Dhillon",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ac0",
          "name": "Eeshit Dhaval Vaishnav",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ac1",
          "name": "Byron Lee",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ac2",
          "name": "Tiago R D Costa",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ac3",
          "name": "José R Penadés",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ac4",
          "name": "Gary Peltz",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ac5",
          "name": "Yunhan Xu",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ac6",
          "name": "Annalisa Pawlosky",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ac7",
          "name": "Alan Karthikesalingam",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ac8",
          "name": "Vivek Natarajan",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-26T06:17:13.000Z",
      "title": "AI와의 협력을 목표로 합니다.",
      "summary": "과학적 발견은 과학자가 새로운 가설을 생성하고 엄격한 실험적인 검증을 받습니다. 이 프로세스를 지원하기 위해, 우리는 젬미니 2.0에 기반한 다 에이전트 시스템에서 구축된 AI 코사인티스트를 소개합니다. AI 코사인티스트는 새로운, 기존의 지식을 발견하고 과학자가 제공한 연구 목적과 가이드에 따라 기존의 증거를 바탕으로 새로운 연구 가설을 제안하는 것을 목표로 합니다. 시스템의 설계는 과학 방법의 영감을 받아, 테스트 시의 계산량의 스케일링으로 가속화하고, 가설의 생성, 논리, 진화의 접근 방식을 채택합니다. 주요 기여점은 (1) 목표의 가설의 생성에 효과적인 계산량의 스케일링을 가능하게 하는 비동기 작업 실행 프레임워크를 구축한 다 에이전트 아키텍처, (2) 자기 개선의 가설의 생성을 위한 토너먼트 진화 프로세스입니다. 자동 평가는 테스트 시의 계산량의 기반으로 지속적인 이익을 보여주고, 가설의 질을 향상시킵니다. 일반적인 용도로 사용하지만, 약품 재활용, 새로운 타겟의 발견, 바크테리아의 진化和 항미생물 저항성 구조의 밝혀진 3가지 생물학적 의료 분야의 개발과 검증을 중점으로 합니다. 약품 재활용에서, 임상적으로 유효한 농도で 변이 발생을 보이는 후보를 제안하고, 특히 암성髓性 백혈病的 후보에 대해 세포증식 억제를 나타냅니다. 새로운 타겟의 발견에서, AI 코사인티스트가 제안한 간암의 새로운 표현 유전적 타겟을 검증하고, 항암 활성과 인간 간의 세포의 재생을 확인합니다. 마지막으로, AI 코사인티스트는 바크테리아의 진화의 새로운 유전 이동 기구의 병렬 시네마디스카바리로 발표되지 않은 실험 결과를 재현합니다. 이러한 결과를 개별적으로 동시 포스트에서 자세히 기록하지만, 이러한 결과가 생물학적 의료와 과학적 발견을 지원할 수 있으며, AI를 기반으로 한 과학자의 새로운 시대를 맞이하는 것을 보여주고 있습니다.",
      "upvotes": 9,
      "discussionId": "67bfd958c2a9b64ab3f97afa"
    },
    "publishedAt": "2025-02-26T22:18:06.494Z",
    "title": "Towards an AI co-scientist",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.18864.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 6232
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.19414",
      "authors": [
        {
          "_id": "67c01587925b73feaf61ac41",
          "name": "Shiven Sinha",
          "hidden": false
        },
        {
          "_id": "67c01587925b73feaf61ac42",
          "name": "Shashwat Goel",
          "hidden": false
        },
        {
          "_id": "67c01587925b73feaf61ac43",
          "name": "Ponnurangam Kumaraguru",
          "hidden": false
        },
        {
          "_id": "67c01587925b73feaf61ac44",
          "name": "Jonas Geiping",
          "hidden": false
        },
        {
          "_id": "67c01587925b73feaf61ac45",
          "name": "Matthias Bethge",
          "hidden": false
        },
        {
          "_id": "67c01587925b73feaf61ac46",
          "name": "Ameya Prabhu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-26T18:58:13.000Z",
      "title": "언어 모델이 가짜를 만들 수 있는가? 예시 생성에 의한 알고리즘적 추론 평가",
      "summary": "언어 모델(LMs)에 대한 과학의 발견을 가속화하는 가능성에 대한 관심이 증가하고 있습니다. 가설의 부정은 과학의 발전의 키로, 이를 통해 주장이 시간이 지나면서 반복적으로 개선될 수 있습니다. 이 과정은 연구자의 큰 노력을 필요로 하며, 논리와 독창성을 필요로 합니다. 그러나 현재의 LMs 평가 기준은 주로 해결책의 생성 능력을 평가하고, 그 반대의 능력에 대한 평가는 미흡합니다. 우리는 반대의 능력에 대한 평가 기준을 개발하는 것을 주장합니다. 구체적으로는 알고리즘 문제 해결 분야를 중심으로, 코드 실행으로 자동으로 평가가 가능한 카운터 엔지니어링을 만들 것을 목표로 합니다. 특히, REFUTE라는 동적으로 업데이트되는 평가 기준을 통해, 최근의 문제를 포함하는 프로그래밍 코ン퍼티션에서 카운터 엔지니어링을 성공적으로 인식한 전문가의 경험을 참고하여, 우리의 분석에 따르면, REFUTE의 부정적인 해결책에 대한 카운터 엔지니어링을 만들 수 있는 가장 좋은 이유인理由 에이전트, OpenAI o3-mini(고)는 코드 실행의 피드백을 받지도 하지만, <9%의 부정적인 해결책에 대한 카운터 엔지니어링을 만들 수 있습니다. 그러나 레이팅은 이러한 문제를 빠르게 해결할 수 있는 능력을 보여주고 있습니다. 우리는 LMs의 부정적인 해결책을 부정하는 능력의 평가와 향상에 발전을 촉구하고, 이 능력은 연구의 가속화와 모델의 신뢰성 있는 반사적인 이유에 의한 자기 개선에 중요하다는 것을 희망합니다.",
      "upvotes": 8,
      "discussionId": "67c01588925b73feaf61ad2c"
    },
    "publishedAt": "2025-02-27T02:36:29.037Z",
    "title": "Can Language Models Falsify? Evaluating Algorithmic Reasoning with Counterexample Creation",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.19414.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6506832221ac448013f94995",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6506832221ac448013f94995/sVUI1JV4Dxan5l-MqNze4.jpeg",
      "fullname": "Shashwat Goel",
      "name": "shash42",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.18906",
      "authors": [
        {
          "_id": "67bfd5d2381f8fcb67e5ad36",
          "name": "Jiani Zheng",
          "hidden": false
        },
        {
          "_id": "67bfd5d2381f8fcb67e5ad37",
          "name": "Lu Wang",
          "hidden": false
        },
        {
          "_id": "67bfd5d2381f8fcb67e5ad38",
          "user": {
            "_id": "669dcf6200970c3b27aafa5d",
            "avatarUrl": "/avatars/bb9ed5ff86326fdaeb184c6b0e40f74f.svg",
            "isPro": false,
            "fullname": "kaikai yang",
            "user": "keanudicap",
            "type": "user"
          },
          "name": "Fangkai Yang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-27T09:14:57.452Z",
          "hidden": false
        },
        {
          "_id": "67bfd5d2381f8fcb67e5ad39",
          "user": {
            "_id": "654dbac9938fbf1e696be8aa",
            "avatarUrl": "/avatars/b3c4035c48169c1bfb04a439fce3499f.svg",
            "isPro": false,
            "fullname": "Chaoyun Zhang",
            "user": "vyokky",
            "type": "user"
          },
          "name": "Chaoyun Zhang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-27T09:14:59.653Z",
          "hidden": false
        },
        {
          "_id": "67bfd5d2381f8fcb67e5ad3a",
          "name": "Lingrui Mei",
          "hidden": false
        },
        {
          "_id": "67bfd5d2381f8fcb67e5ad3b",
          "name": "Wenjie Yin",
          "hidden": false
        },
        {
          "_id": "67bfd5d2381f8fcb67e5ad3c",
          "name": "Qingwei Lin",
          "hidden": false
        },
        {
          "_id": "67bfd5d2381f8fcb67e5ad3d",
          "name": "Dongmei Zhang",
          "hidden": false
        },
        {
          "_id": "67bfd5d2381f8fcb67e5ad3e",
          "name": "Saravan Rajmohan",
          "hidden": false
        },
        {
          "_id": "67bfd5d2381f8fcb67e5ad3f",
          "name": "Qi Zhang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-26T07:52:02.000Z",
      "title": "VEM: 환경 없는 훈련에 의한 GUI 에이전트의 탐색 및 가치의 환경 모델",
      "summary": "GUI를 위한 시각언어 모델(VLMs)를 강화학습(RL)에 의해 훈련하는 과정에서 중요한 문제점이 있습니다. 환경에 기반한 RL은 고가적인 상호작용이 필요하며, 환경없는 방법들은 분포변환과 보상의 일반화에 어려움을 겪습니다. 우리는 예측된 값 환경 모델(VEM)을 활용하여 환경없는 RL 프레임워크를 제안합니다. VEM은 오프라인 데이터로부터 직접 상태 액션 가치를 예측하고, GUI의 상호작용 결과에 대한 인간처럼의 사전이식을 구조화합니다. 이는 다음 상태 예측 및 환경의 피드백이 필요하지 않도록 오류를 누적하는 것을 피하고, UI의 변경에 대한 강건성을 높입니다. 프레임워크는 2단계로 동작합니다: (1) VEM의 예측, 장기적인 액션의 가치를 평가하고, (2) VEM의 신호를 사용하여 정책 검색을 가이드하여 레이아웃과 상관없는 GUI 자동화를 가능하게 합니다. Android-in-the-Wild 벤치마크를 사용하여 평가한 결과, VEM은 오프라인 및 온라인 설정에서 최상위 성능을 달성하며, 환경없는 기본라인을 크게 초월하고, 환경에 기반한 접근 방식과 같은 수준의 성능을 달성합니다. 중요한 점은 VEM은 의미 인식에 기반한 가치 평가가 온라인 훈련된 방법과 비교하여 상대적으로 우수한 성능을 달성할 수 있음을 보여줍니다.",
      "upvotes": 5,
      "discussionId": "67bfd5d7381f8fcb67e5ae3d"
    },
    "publishedAt": "2025-02-26T22:02:50.690Z",
    "title": "VEM: Environment-Free Exploration for Training GUI Agent with Value Environment Model",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.18906.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "654dbac9938fbf1e696be8aa",
      "avatarUrl": "/avatars/b3c4035c48169c1bfb04a439fce3499f.svg",
      "fullname": "Chaoyun Zhang",
      "name": "vyokky",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.18772",
      "authors": [
        {
          "_id": "67bfc297ca6e3c22b6d99c78",
          "name": "Xueqing Peng",
          "hidden": false
        },
        {
          "_id": "67bfc297ca6e3c22b6d99c79",
          "name": "Triantafillos Papadopoulos",
          "hidden": false
        },
        {
          "_id": "67bfc297ca6e3c22b6d99c7a",
          "name": "Efstathia Soufleri",
          "hidden": false
        },
        {
          "_id": "67bfc297ca6e3c22b6d99c7b",
          "name": "Polydoros Giannouris",
          "hidden": false
        },
        {
          "_id": "67bfc297ca6e3c22b6d99c7c",
          "name": "Ruoyu Xiang",
          "hidden": false
        },
        {
          "_id": "67bfc297ca6e3c22b6d99c7d",
          "name": "Yan Wang",
          "hidden": false
        },
        {
          "_id": "67bfc297ca6e3c22b6d99c7e",
          "name": "Lingfei Qian",
          "hidden": false
        },
        {
          "_id": "67bfc297ca6e3c22b6d99c7f",
          "user": {
            "_id": "63b58ed5889aa6707f0bb0f4",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63b58ed5889aa6707f0bb0f4/znl74_aMswlV8VtHrfj3G.jpeg",
            "isPro": true,
            "fullname": "Jimin Huang",
            "user": "jiminHuang",
            "type": "user"
          },
          "name": "Jimin Huang",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-02-27T01:40:40.189Z",
          "hidden": false
        },
        {
          "_id": "67bfc297ca6e3c22b6d99c80",
          "name": "Qianqian Xie",
          "hidden": false
        },
        {
          "_id": "67bfc297ca6e3c22b6d99c81",
          "name": "Sophia Ananiadou",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-26T03:04:01.000Z",
      "title": "Pulls: 저자원 그리스 금융에서 대규모 언어 모델의 벤치마크\n\n(Note: The term \"Pulls\" seems to be a typo or placeholder and should be \"Pulls\" as in \"Pulls\" the benchmark, but it is kept as is per the original text.)",
      "summary": "그리스시아의 세계경제에서 중요한 역할을 하되, 그 재정적 맥락에서 큰 규모의 언어 모델(LLMs)은 그리스시아어의 언어복잡성과 영역专門적 데이터의 부족으로 조사가 진행되지 않는다. 지금까지의 다언어 재무 자연어 처리(NLP)의 노력에서 상당한 성능의 차이를 명확히 확인되었지만, 지금까지는 그리스시아 재무용의 전문 벤치마크나 그리스시아어의 고유한 LLMs는 개발되지 않았다. 이를 메꾸기 위해, 우리는 Plutus-ben이라는 첫 번째 그리스시아 재무 평가 벤치마크와 Plutus-8B이라는 선두의 그리스시아 재무용 LLM을 소개합니다. Plutus-8B는 그리스시아어의 고유한 데이터로 미세 조정되어 있습니다. Plutus-ben은 5가지의 핵심적인 금융 NLP 태스크를 처리하고, LLM의 체계적인 재현 가능한 평가에 촉발합니다. 이러한 태스크에 기반하여, 우리는 3가지의 새로운, 고품질의 그리스시아 재무 데이터 세트를 제공하며, 이들은 국적의 전문가로 엄격하게 注釈되어 2가지의 기존 리소스를 추가하고 있습니다. 22개의 LLM의 완전한 평가에 따라, 그리스시아 재무 NLP는 언어복잡성, 영역专門적 용어, 재무 계산의 결함이 어려워졌음을 명확히 합니다. 이러한 발견은 언어간 트랜스포머의 한계, 모델이 그리스시아어 학습할 때 재무 지식의 필요성, 그리고 재무 LLM을 그리스시아어에 적용하는 어려움을 강조합니다. 우리는 Plutus-ben, Plutus-8B, 그리고 모든 관련 데이터 세트를 공개하여 재현 가능한 연구를 추진하고, 그리스시아 재무 NLP의 발전을 촉진하고, 금융 분야에서 광범위한 다언어 인클루션을 촉진합니다.",
      "upvotes": 4,
      "discussionId": "67bfc298ca6e3c22b6d99caa"
    },
    "publishedAt": "2025-02-27T00:08:09.082Z",
    "title": "Plutus: Benchmarking Large Language Models in Low-Resource Greek Finance",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.18772.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "63b58ed5889aa6707f0bb0f4",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63b58ed5889aa6707f0bb0f4/znl74_aMswlV8VtHrfj3G.jpeg",
      "fullname": "Jimin Huang",
      "name": "jiminHuang",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isMod": false,
      "followerCount": 14
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.16776",
      "authors": [
        {
          "_id": "67bfd8d546083445aacb4605",
          "name": "Zhexin Zhang",
          "hidden": false
        },
        {
          "_id": "67bfd8d546083445aacb4606",
          "name": "Leqi Lei",
          "hidden": false
        },
        {
          "_id": "67bfd8d546083445aacb4607",
          "name": "Junxiao Yang",
          "hidden": false
        },
        {
          "_id": "67bfd8d546083445aacb4608",
          "name": "Xijie Huang",
          "hidden": false
        },
        {
          "_id": "67bfd8d546083445aacb4609",
          "name": "Yida Lu",
          "hidden": false
        },
        {
          "_id": "67bfd8d546083445aacb460a",
          "name": "Shiyao Cui",
          "hidden": false
        },
        {
          "_id": "67bfd8d546083445aacb460b",
          "name": "Renmiao Chen",
          "hidden": false
        },
        {
          "_id": "67bfd8d546083445aacb460c",
          "name": "Qinglin Zhang",
          "hidden": false
        },
        {
          "_id": "67bfd8d546083445aacb460d",
          "name": "Xinyuan Wang",
          "hidden": false
        },
        {
          "_id": "67bfd8d546083445aacb460e",
          "name": "Hao Wang",
          "hidden": false
        },
        {
          "_id": "67bfd8d546083445aacb460f",
          "user": {
            "_id": "653f1ef4aabbf15fc76a259c",
            "avatarUrl": "/avatars/94e569999d913e961266394ea2875965.svg",
            "isPro": false,
            "fullname": "LLLeo Li",
            "user": "LLLeo612",
            "type": "user"
          },
          "name": "Hao Li",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-27T09:14:45.366Z",
          "hidden": false
        },
        {
          "_id": "67bfd8d546083445aacb4610",
          "name": "Xianqi Lei",
          "hidden": false
        },
        {
          "_id": "67bfd8d546083445aacb4611",
          "name": "Chengwei Pan",
          "hidden": false
        },
        {
          "_id": "67bfd8d546083445aacb4612",
          "name": "Lei Sha",
          "hidden": false
        },
        {
          "_id": "67bfd8d546083445aacb4613",
          "name": "Hongning Wang",
          "hidden": false
        },
        {
          "_id": "67bfd8d546083445aacb4614",
          "name": "Minlie Huang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-24T02:11:52.000Z",
      "title": "AI안전실: AI 보안 평가 및 향상 통합 프레임워크",
      "summary": "AI 모델이 다양한 리알 웨어 스케일러로 일상적으로 확장하는 가운데, 그 안전성의 보장은 중요한 문제로 남아 있으며, 아직도 충분히 연구되지 않은 상태다. AI 보안 평가와 향상에 대한 큰 노력을 기울이고 있지만, 표준화된 프레임워크와 완전한 도구킷의 부족은 시스템 연구와 실용적인 도입에 중대한 장애를 두는 것이다. 이를 해결하기 위해, AISafetyLab라는 통합된 프레임워크와 도구킷을 소개한다. AISafetyLab는 대표적인 공격, 방어, 평가手法를 통합한 것이며, 개발자가 직관적인 인터페이스를 사용하여 다양한 기술을 쉽게 적용할 수 있도록 설계되어 있다. 또한, Vicuna에 대한 실험적 연구를 수행하고, 공격과 방어 전략을 분석하여 상대적으로 효과적인 성능을 제공하는 유익한 성능을 제공한다. AI 보안 연구와 개발의 진행을 촉진하기 위해, AISafetyLab는 공개적으로 사용 가능한 상태에 있으며 (https://github.com/thu-coai/AISafetyLab) 그 지속적인 유지와 향상에 노력을 기울이고 있다.",
      "upvotes": 4,
      "discussionId": "67bfd8d646083445aacb464f"
    },
    "publishedAt": "2025-02-26T22:16:03.582Z",
    "title": "AISafetyLab: A Comprehensive Framework for AI Safety Evaluation and Improvement",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.16776.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "61b58aa0d65058ce70beb98c",
      "avatarUrl": "/avatars/aefd9271b891abc6dd2ded1a30eebca4.svg",
      "fullname": "Zhexin Zhang",
      "name": "nonstopfor",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.19204",
      "authors": [
        {
          "_id": "67bfd735ca6e3c22b6de43c7",
          "name": "Xiankang He",
          "hidden": false
        },
        {
          "_id": "67bfd735ca6e3c22b6de43c8",
          "name": "Dongyan Guo",
          "hidden": false
        },
        {
          "_id": "67bfd735ca6e3c22b6de43c9",
          "name": "Hongji Li",
          "hidden": false
        },
        {
          "_id": "67bfd735ca6e3c22b6de43ca",
          "name": "Ruibo Li",
          "hidden": false
        },
        {
          "_id": "67bfd735ca6e3c22b6de43cb",
          "name": "Ying Cui",
          "hidden": false
        },
        {
          "_id": "67bfd735ca6e3c22b6de43cc",
          "name": "Chi Zhang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-26T15:10:05.000Z",
      "title": "어떤 깊이로도 결과가 얻을 수 있습니다: 디자이너씬은 강력한 모노럴 심도 추정기를 만들 것입니다.",
      "summary": "MDE는 RGB 이미지에서 스케인의 깊이를 예측하는 목적을 가지고 있으며, 3차원 스케인 이해에 중요한 역할을 합니다. 최근의 0-shot MDE의 발전은 정규화된 깊이 표현과 학습에 기반한 결과를 활용하여 다양한 스케인에 대한 일반화 능력을 향상시켰습니다. 그러나 현재 사용하는 깊이 정규화 방법은 글로벌 정규화를 기반으로 하고 있으므로, 노이즈를 증폭시키고 결과를 수집하는 효과를 저하시킵니다. 본 논문에서는 다양한 깊이 정규화 전략의 영향을 체계적으로 분석합니다. 그 결과를 바탕으로 Cross-Context Distillation을 제안합니다. 이는 글로벌과 지역적인 깊이 코드를 통합하여 퍼포먼스 레이블의 질을 향상시킵니다. 또한 보간적인 강점을 활용한 다태거 결과를 수집하는 프레임워크를 도입합니다. 이로써 깊이 예측이 더욱 강고 정확하게 이루어집니다. 표준 데이터 세트에 대한 확장된 실험에 따라, 우리의 접근법은 현재의 방법과 비교하여 통계적으로 및 질적으로 유의미하게 우수함을 보여주었습니다.",
      "upvotes": 4,
      "discussionId": "67bfd736ca6e3c22b6de441e"
    },
    "publishedAt": "2025-02-26T22:10:20.646Z",
    "title": "Distill Any Depth: Distillation Creates a Stronger Monocular Depth Estimator",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/64196320ed725fef64419c2a/k13rSuJPlDkMtzwdHXCXm.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.19204.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64196320ed725fef64419c2a",
      "avatarUrl": "/avatars/96feb22fb5e8931d6c9e0ea06148266f.svg",
      "fullname": "Chi Zhang",
      "name": "DrChiZhang",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 3
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.19279",
      "authors": [
        {
          "_id": "67bffaca3f838c1e33e074e7",
          "user": {
            "_id": "638ef0b0c67af472d31674a6",
            "avatarUrl": "/avatars/02df97d15a0f46b47f9162221733b121.svg",
            "isPro": false,
            "fullname": "Honglin Guo",
            "user": "KYLN24",
            "type": "user"
          },
          "name": "Honglin Guo",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-27T09:13:52.094Z",
          "hidden": false
        },
        {
          "_id": "67bffaca3f838c1e33e074e8",
          "name": "Kai Lv",
          "hidden": false
        },
        {
          "_id": "67bffaca3f838c1e33e074e9",
          "name": "Qipeng Guo",
          "hidden": false
        },
        {
          "_id": "67bffaca3f838c1e33e074ea",
          "name": "Tianyi Liang",
          "hidden": false
        },
        {
          "_id": "67bffaca3f838c1e33e074eb",
          "name": "Zhiheng Xi",
          "hidden": false
        },
        {
          "_id": "67bffaca3f838c1e33e074ec",
          "name": "Demin Song",
          "hidden": false
        },
        {
          "_id": "67bffaca3f838c1e33e074ed",
          "name": "Qiuyinzhe Zhang",
          "hidden": false
        },
        {
          "_id": "67bffaca3f838c1e33e074ee",
          "name": "Yu Sun",
          "hidden": false
        },
        {
          "_id": "67bffaca3f838c1e33e074ef",
          "name": "Kai Chen",
          "hidden": false
        },
        {
          "_id": "67bffaca3f838c1e33e074f0",
          "name": "Xipeng Qiu",
          "hidden": false
        },
        {
          "_id": "67bffaca3f838c1e33e074f1",
          "name": "Tao Gui",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-26T16:33:41.000Z",
      "title": "캐리크스：인간적인 취향으로부터 데이터의 품질 기준을 개발합니다.",
      "summary": "언어 모델은 최적의 성능을 발휘하기 위해 고품질의 데이터를 매우 중요합니다. 현재의 접근 방식은 수동으로 설계된 휴리스틱, 기존 모델의 변동, 분류기의 훈련, 또는 유도문의 조정에 의존합니다. 이러한 접근 방식은 큰 전문 지식과 인간의 기호 노력이 필요하며, 데이터에 대한 편향을 유발합니다. 우리는 새로운 데이터 선택 방법인 CritiQ를 소개합니다. CritiQ는 sim30의 인간 기호 쌍을 사용하여 데이터의 품질에 대한 인간 취향을 자동으로 규칙으로 추출하고 효율적인 데이터 선택을 수행합니다. 주요 구성 요소인 CritiQ Flow는 관리자 에이전트가 품질의 규칙을 진화시키고 작업 에이전트가 두 개의 제너럴을 판단하는 것입니다. 우리는 이전의 작업에서 품질의 규칙을 추출하고, CritiQ Flow를 강화하는 지식 기반을 구축합니다. 변동과 분류기 기반의 방법과 비교하여, 언어적 규칙은 해석 가능하며 재사용의 가치를 가지고 있습니다. 규칙을 얻은 후, CritiQ 스코어를 훈련시키고 품질 스코어를 부여하여 효율적인 데이터 선택을 수행합니다. 코드, 수학, 로직 분야에서 효과를 보여주며, 인간 기호 테스트 세트에서 높은 정확도를 달성합니다. 선택된 데이터의 품질을 확인하기 위해 Llama 3.1 모델을 지속적으로 훈련하고 하류 태스크에 대한 성능 향상을 관찰합니다. Ablation studies에서 지식 기반과 반성 프로세스의 이익을 증명합니다. 규칙의 진화과 다수결의 효과를 분석합니다.",
      "upvotes": 3,
      "discussionId": "67bffacc3f838c1e33e075a2"
    },
    "publishedAt": "2025-02-27T00:47:02.948Z",
    "title": "CritiQ: Mining Data Quality Criteria from Human Preferences",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.19279.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "638ef0b0c67af472d31674a6",
      "avatarUrl": "/avatars/02df97d15a0f46b47f9162221733b121.svg",
      "fullname": "Honglin Guo",
      "name": "KYLN24",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.19413",
      "authors": [
        {
          "_id": "67c02d6aa15ac71dcf1c754e",
          "name": "Christoph Schuhmann",
          "hidden": false
        },
        {
          "_id": "67c02d6aa15ac71dcf1c754f",
          "name": "Gollam Rabby",
          "hidden": false
        },
        {
          "_id": "67c02d6aa15ac71dcf1c7550",
          "name": "Ameya Prabhu",
          "hidden": false
        },
        {
          "_id": "67c02d6aa15ac71dcf1c7551",
          "name": "Tawsif Ahmed",
          "hidden": false
        },
        {
          "_id": "67c02d6aa15ac71dcf1c7552",
          "name": "Andreas Hochlehnert",
          "hidden": false
        },
        {
          "_id": "67c02d6aa15ac71dcf1c7553",
          "name": "Huu Nguyen",
          "hidden": false
        },
        {
          "_id": "67c02d6aa15ac71dcf1c7554",
          "name": "Nick Akinci Heidrich",
          "hidden": false
        },
        {
          "_id": "67c02d6aa15ac71dcf1c7555",
          "name": "Ludwig Schmidt",
          "hidden": false
        },
        {
          "_id": "67c02d6aa15ac71dcf1c7556",
          "name": "Robert Kaczmarczyk",
          "hidden": false
        },
        {
          "_id": "67c02d6aa15ac71dcf1c7557",
          "name": "Sören Auer",
          "hidden": false
        },
        {
          "_id": "67c02d6aa15ac71dcf1c7558",
          "name": "Jenia Jitsev",
          "hidden": false
        },
        {
          "_id": "67c02d6aa15ac71dcf1c7559",
          "name": "Matthias Bethge",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-26T18:56:52.000Z",
      "title": "알렉시데우리ア 프로젝트: LLMs를 통해 과학 지식에서 저작권의 부담을 해소하기 위한 프로젝트",
      "summary": "ペイウォール、リセントと著作権規則는 과학知識의 광범위한 확산과 재활용을 제한합니다. 우리는 학술 논문에 포함된 과학 지식을 추출할 수 있는 법칙적이고 기술적으로 가능한 입장에서 착안하고 있습니다. 현재의 방법, 예를 들어 텍스트埋め込み는 사실적인 내용을 신뢰할 수 있는 방식으로 보존할 수 없습니다. 간단한 재어화는 법칙적으로 정당할 수 있습니다. 우리는 커뮤니티에 새로운 아이디어를 받아들일 것을 촉구합니다: 학술 논문을 LLM을 사용하여 Knowledge Units로 변환하는 것입니다. 이러한 유닛은 스타일이 없는 구조화된 데이터로 구성된 구조화된 데이터를 사용하여 엔티티, 속성 및 관계에 대한 정보를捉えます. 우리는 Knowledge Units가 다음을 보여줍니다: (1) 德国的著作権法と米国の「Fair Use」理論의 法則的分析에 기반하여, 著作権의 연구文書로부터의 知識의 共有에 기반한 法則적으로 立得住腳な フレームワーク을 형성할 수 있음을 입증합니다. (2) 原稿의 거의 모든 사실적인 知識 (약 95%)를 보존할 수 있으며, 原稿의著作権的文書から의 事実을 MCQで 측정한 결과를 보여줍니다. 과학 知識은, 言語モデル가著作権的文書から重要な 事実을 재활용을 许可することで, 科学研究と 教育に 変革的な 利益を 収得することが 可能であることを予想します. 이를 지원하기 위해, 학술 논문을 Knowledge Units로 변환하기 위한 오픈소스 ツール를 공유しています. 총括的に, 우리의 작업은著作権를 존중하는 동시에 과학 知識의 민주적인 접근의 가능성에 대한 주장을 합니다.",
      "upvotes": 2,
      "discussionId": "67c02d6ba15ac71dcf1c7596"
    },
    "publishedAt": "2025-02-27T04:18:26.724Z",
    "title": "Project Alexandria: Towards Freeing Scientific Knowledge from Copyright Burdens via LLMs",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.19413.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6464a0d41683d3c81f51924a",
      "avatarUrl": "/avatars/bfa89f568302fa34a641e0d8744bf8b5.svg",
      "fullname": "Ameya Prabhu",
      "name": "AmeyaPrabhu",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 4
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.18417",
      "authors": [
        {
          "_id": "67c02b2eb14cf3cbc800c292",
          "name": "Alexander Groshev",
          "hidden": false
        },
        {
          "_id": "67c02b2eb14cf3cbc800c293",
          "user": {
            "_id": "67aafccd7517c92ba71142f2",
            "avatarUrl": "/avatars/ef4b5c6867250b8b7af2c995dd7ad740.svg",
            "isPro": false,
            "fullname": "Anastasiia Iashchenko",
            "user": "nastasia-y",
            "type": "user"
          },
          "name": "Anastasiia Iashchenko",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-27T09:13:49.896Z",
          "hidden": false
        },
        {
          "_id": "67c02b2eb14cf3cbc800c294",
          "name": "Pavel Paramonov",
          "hidden": false
        },
        {
          "_id": "67c02b2eb14cf3cbc800c295",
          "name": "Denis Dimitrov",
          "hidden": false
        },
        {
          "_id": "67c02b2eb14cf3cbc800c296",
          "name": "Andrey Kuznetsov",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-25T18:13:55.000Z",
      "title": "GHOST 2.0: 고품질 1회 회전 전송\n\n(请注意，\"高品質\"在韩语中通常翻译为\"고품질\"，但在这里为了保持原文的\"生成高品質\"的含义，我们使用了\"고품질\"。如果需要更精确的翻译，可以考虑使用\"고품질 생성\"。)",
      "summary": "최근, 얼굴 교환의 문제를 연구 커뮤니티에 주목받던 동안, 머리 교환의 문제를 크게 조사하지 않았습니다. 얼굴 색상의 이동을 제외한 머리 교환은 합성 중 전체 머리의 구조 정보를 보존하고, 교환된 머리와 배경 사이에 빈칸을 채우는 특수한 문제를 가지고 있습니다. 본 논문에서는, GHOST 2.0라는 두 가지 문제를 특화된 모듈을 사용하여 이러한 문제를 해결합니다. 먼저, 머리 재현에 적합한 Alignment 모델을 강화하고, 다 척도で 정체 정보를 보존하며, 극단적인 자세 변화에 강건하도록 합니다. 다음으로, Blender 모듈을 사용하여 얼굴 색상의 이동과 잘못된 영역을 채우며, 목표의 배경에 순전히 할 수 있습니다. 두 모듈은 대응하는 태스크에서 기준보다 높은 성능을示し, 머리 교환에서 가장 先端 的 결과를 달성할 수 있습니다. 또한, 소스와 목표의 머리형의 큰 차이 등 복잡한 경우도 해결합니다. 코드는, https://github.com/ai-forever/ghost-2.0 에 액세스할 수 있습니다.",
      "upvotes": 2,
      "discussionId": "67c02b31b14cf3cbc800c34b"
    },
    "publishedAt": "2025-02-27T04:15:43.126Z",
    "title": "GHOST 2.0: generative high-fidelity one shot transfer of heads",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.18417.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "67aafccd7517c92ba71142f2",
      "avatarUrl": "/avatars/ef4b5c6867250b8b7af2c995dd7ad740.svg",
      "fullname": "Anastasiia Iashchenko",
      "name": "nastasia-y",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.19187",
      "authors": [
        {
          "_id": "67c01747e8c7d56a8e0cbdc3",
          "name": "Mehran Kazemi",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdc4",
          "user": {
            "_id": "654e97ef5da3196a78409341",
            "avatarUrl": "/avatars/1a5ea7351ca21960891cf9721b9f4667.svg",
            "isPro": false,
            "fullname": "Bahare Fatemi",
            "user": "baharefatemi",
            "type": "user"
          },
          "name": "Bahare Fatemi",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-02-27T07:42:00.525Z",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdc5",
          "name": "Hritik Bansal",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdc6",
          "name": "John Palowitch",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdc7",
          "name": "Chrysovalantis Anastasiou",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdc8",
          "name": "Sanket Vaibhav Mehta",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdc9",
          "name": "Lalit K. Jain",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdca",
          "name": "Virginia Aglietti",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdcb",
          "name": "Disha Jindal",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdcc",
          "name": "Peter Chen",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdcd",
          "name": "Nishanth Dikkala",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdce",
          "name": "Gladys Tyen",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdcf",
          "name": "Xin Liu",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdd0",
          "name": "Uri Shalit",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdd1",
          "name": "Silvia Chiappa",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdd2",
          "name": "Kate Olszewska",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdd3",
          "name": "Yi Tay",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdd4",
          "name": "Vinh Q. Tran",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdd5",
          "name": "Quoc V. Le",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdd6",
          "name": "Orhan Firat",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-26T14:50:50.000Z",
      "title": "BIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハード\n\nBIG-Bench エクストラ ハー",
      "summary": "대 언어 모델(LLMs)는 일상적인 응용 분야에서 매일 증가하고 있으며, 강력한 일반적인 논리론 능력을 요구하고 다양한 논리론 스킬 세트를 요구하고 있습니다. 그러나 현재의 LLM의 논리론 벤치마크는 주로 수학적 및 코딩 능력에 초점을 맞추어 있어, 광범위한 논리론 능력을 평가하는 여지가 있습니다. 특히 예외로, BIG-Bench 데이터 세트가 있으며, 이는 다양한 어려운 태스크의 세트를 가지고 있으며, 한 개의 통일된 프레임워크로 광범위한 논리론을 평가할 수 있는 것을 통해 LLM의 일반적인 논리론 능력을 평가하는 중요한 벤치마크로役立ちました. 그러나 LLM의 최근 진도는 BIG-Bench에 속하여 사타르(SATAR)로, 그 어려운 버전 BIG-Bench Hard(BBH)에 있어도 그 효용이 떨어졌습니다. 가장 선진한 모델은 BBH의 많은 태스크에서 근접절대적 점수를 달성하고, 그 효용을 떨어뜨리고 있습니다. 이러한 제한을 해결하기 위해, BIG-Bench Extra Hard(BBEH)라는 새로운 벤치마크를 도입하고, LLM의 논리론 평가의 경계를 뛰어넘는 것을 목표로하고 있습니다. BBEH는 BBH의 각 태스크를 새로운 태스크로 대체하며, 유사한 논리론 능력을 조사하지만, 크게 더 어려워졌습니다. BBEH에서, 다양한 모델을 평가하고, 최고의 일반적인 모델의 평균 정확도는 9.8%, 최고의 논리론 전문 모델의 평균 정확도는 44.8%이며, 큰 향상의 여지가 있으며, LLM에서 강력한 일반적인 논리론을 달성하는 과제를 명확히 합니다. BBEH는 공개적으로 릴리즈되어 있습니다: https://github.com/google-deepmind/bbeh.",
      "upvotes": 2,
      "discussionId": "67c01748e8c7d56a8e0cbe0b"
    },
    "publishedAt": "2025-02-27T02:43:05.341Z",
    "title": "BIG-Bench Extra Hard",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.19187.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "5f1158120c833276f61f1a84",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1608042047613-5f1158120c833276f61f1a84.jpeg",
      "fullname": "Niels Rogge",
      "name": "nielsr",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 773
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.16284",
      "authors": [
        {
          "_id": "67bfdbd0302c06f220658e9d",
          "user": {
            "_id": "64e84ec6d41a68b065bf78a7",
            "avatarUrl": "/avatars/bae3c5e3210b40af6e4f113e85f3e206.svg",
            "isPro": false,
            "fullname": "Liang Wang",
            "user": "AzureLeon1",
            "type": "user"
          },
          "name": "Liang Wang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-27T09:14:42.802Z",
          "hidden": false
        },
        {
          "_id": "67bfdbd0302c06f220658e9e",
          "name": "Shaozhen Liu",
          "hidden": false
        },
        {
          "_id": "67bfdbd0302c06f220658e9f",
          "name": "Yu Rong",
          "hidden": false
        },
        {
          "_id": "67bfdbd0302c06f220658ea0",
          "name": "Deli Zhao",
          "hidden": false
        },
        {
          "_id": "67bfdbd0302c06f220658ea1",
          "name": "Qiang Liu",
          "hidden": false
        },
        {
          "_id": "67bfdbd0302c06f220658ea2",
          "name": "Shu Wu",
          "hidden": false
        },
        {
          "_id": "67bfdbd0302c06f220658ea3",
          "name": "Liang Wang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-22T16:34:32.000Z",
      "title": "MolSpectra: 3차원 분자 표현의 예비 학습을 에너지 스펙트럼의 다양성에 의해 실현합니다.",
      "summary": "3D 구조와 분자의 에너지 상태 간의 관계를 확립하는 것은 3D 분자의 표현을 학습하기 위한 유망한 방법임을 증명되었습니다. 그러나 현재의 방법들은 고전적 역학으로부터 분자의 에너지 상태의 모델링에 제한되어 있습니다. 이 제한은 분자의 에너지를 상세하게 평가하고, 에너지 스펙트럼을 통해 실험적으로 측정할 수 있는 것을 지나치게 보고, 예를 들어 양자역학의 효과, 양자화(분산)의 에너지 레벨 구조 등이 제공하는 것을 제외하고 있습니다. 이 논문에서는 에너지 스펙트럼을 사용하여 3D 분자의 표현을 사전 훈련시키는 방법(MolSpectra)을 제안하고, 분자 표현에 양자역학의 지식을 넣는 것을 목표로 합니다. 특히, 분자 스펙트럼을 SpecFormer(다 스펙트럼 엔코더)으로 인코딩하기 위해 마스크付き 패치 재구성을 통해 제안합니다. 3D 엔코더의 분자를 이해하기 위해 3D 엔코더와 스펙트럼 엔코더의 출력을 비교하는 객체를 사용하여 조정합니다. 공개 벤치마크에서 평가에 따라, 사전 훈련된 표현은 현재의 방법을 초월하여 분자의 특성의 예측과 동역학의 모델링에 있어서는 분명히 확인되었습니다.",
      "upvotes": 2,
      "discussionId": "67bfdbd1302c06f220658ece"
    },
    "publishedAt": "2025-02-26T22:29:40.056Z",
    "title": "MolSpectra: Pre-training 3D Molecular Representation with Multi-modal Energy Spectra",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.16284.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64e84ec6d41a68b065bf78a7",
      "avatarUrl": "/avatars/bae3c5e3210b40af6e4f113e85f3e206.svg",
      "fullname": "Liang Wang",
      "name": "AzureLeon1",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.17540",
      "authors": [
        {
          "_id": "67bff9608d761fc6a75e24ad",
          "user": {
            "_id": "657ccbf2869d5bb0e53b482f",
            "avatarUrl": "/avatars/2eae5a10bdc14814a04d9f255f16de6b.svg",
            "isPro": false,
            "fullname": "Rohit Saxena",
            "user": "rohitsaxena",
            "type": "user"
          },
          "name": "Rohit Saxena",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-27T09:13:54.284Z",
          "hidden": false
        },
        {
          "_id": "67bff9608d761fc6a75e24ae",
          "name": "Pasquale Minervini",
          "hidden": false
        },
        {
          "_id": "67bff9608d761fc6a75e24af",
          "name": "Frank Keller",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-24T18:35:39.000Z",
      "title": "포스터 요약 벤치마크: 과학 포스터의 다모달 벤치마크",
      "summary": "마르치모더럴 문서에서 정확한, 간결한 텍스트 요약을 생성하는 것은 어려운 일이다. 특히, 시각적으로 복잡한 콘텐츠인 과학 포스터를 처리하는 경우尤为如此。 포스터 요약을 사용하여, 과학 포스터를 연구 논문의 요약로 이해하고 요약할 수 있는 비전-언어 모델의 개발을 위해, 포스터 요약을 사용하여 새로운 벤치마크를 소개합니다. 데이터셋에는 16,305건의 회의 포스터가 포함되어 있으며, 각 포스터는 이미지 형식으로 제공되며, 복잡한 라우터, 밀집된 텍스트 영역, 테이블, 그림 등 다양한 시각적인 이해적 문제를 제시합니다. 포스터 요약에 벤치마크를 적용하여, 가장 先端의 마르치모더럴 대 언어 모델(MLLMs)을 평가하고, 과학 포스터의 정확한 해석과 요약에 어려움을 보여줍니다. Segment & Summarize라는 계층적인 방법을 제안하여, 현재의 MLLMs를 초월하여, ROUGE-L에서 3.14%의 이익을 달성합니다. 이는 향후 포스터 요약 연구의 출발점으로 사용될 수 있는 것입니다.",
      "upvotes": 1,
      "discussionId": "67bff96d8d761fc6a75e27a0"
    },
    "publishedAt": "2025-02-27T00:37:24.965Z",
    "title": "PosterSum: A Multimodal Benchmark for Scientific Poster Summarization",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.17540.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "657ccbf2869d5bb0e53b482f",
      "avatarUrl": "/avatars/2eae5a10bdc14814a04d9f255f16de6b.svg",
      "fullname": "Rohit Saxena",
      "name": "rohitsaxena",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 4
    },
    "isAuthorParticipating": true
  }
]