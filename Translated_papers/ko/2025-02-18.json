[
  {
    "paper": {
      "id": "2502.12152",
      "authors": [
        {
          "_id": "67b41ed52867282b4eb37ce4",
          "name": "Xialin He",
          "hidden": false
        },
        {
          "_id": "67b41ed52867282b4eb37ce5",
          "user": {
            "_id": "6201fc5d91d53938a6432fbf",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6201fc5d91d53938a6432fbf/VLs8ZYaZrop4KBpZn53fH.jpeg",
            "isPro": false,
            "fullname": "Runpei Dong",
            "user": "RunpeiDong",
            "type": "user"
          },
          "name": "Runpei Dong",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-18T09:31:13.178Z",
          "hidden": false
        },
        {
          "_id": "67b41ed52867282b4eb37ce6",
          "name": "Zixuan Chen",
          "hidden": false
        },
        {
          "_id": "67b41ed52867282b4eb37ce7",
          "name": "Saurabh Gupta",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-17T18:59:06.000Z",
      "title": "Learning Getting-Up Policies for Real-World Humanoid Robots\n\n이 문장은 한국어로 번역하면 다음과 같습니다:\n\n\"실세계인형 로봇을 위한 Getting-Up 정책 학습\"",
      "summary": "自動의 폴리카리는 인형 로봇이 신뢰할 수 있는 배치에서 중요한 가정 조건입니다. 인형 로봇이 폴리한 후 다양한 구조로 인해, 로봇이 어렵고 다양한 지형에서 동작하기 때문에, 손으로 컨트롤러를 설계하는 것은 어렵습니다. 본 논문에서는 인형 로봇이 다양한 구조와 다양한 지형에서 서서히 할 수 있는 컨트롤러를 생성하는 학습 프레임워크를 개발합니다. 이전에 성공한 인형 로봇의 이동 학습의 적용과 다른 점은, 서서히 할 작업에는 복잡한 접촉 패턴이 포함되어 있으며, 이에는 충돌의 기하학적 모델링과 희소한 보상의 설명이 필요합니다. 이러한 도전에 대해 2단계 접근 방식을 캄레리움에 따라 해결합니다. 첫 번째 단계는, 평활성 및 속도/토크의 제한을 최소화한 상태에서, 좋은 서서히 할 타라이트를 발견하는 것을 중점으로 합니다. 다음 단계에서는, 발견된 동작을 실제로 사용할 수 있는 (즉, 평활하고 천천히 진행되는) 동작으로 개선하고, 초기 구조 및 지형의 변화에 강건하게 만드는 것입니다. 우리들은 이러한 혁신적인 기술이, 실제 세계에서 G1 인형 로봇이 두 가지 주요 상태를 서서히 할 수 있게 만들었습니다: a) 얼굴 위에서 서서히 있는 상태와 b) 얼굴 아래에서 서서히 있는 상태, 둘 다 평탄하고 유연하며, 슬리피는 표면과 기울어진 (예: 슬리피는 초과와 눈野)에서 테스트되었습니다. 우리 지식의 한계로, 이는 인류 크기의 인형 로봇이 실제 세계에서 서서히 할 정책의 첫 번째 성공적인 실험입니다. 프로젝트 페이지: https://humanoid-getup.github.io/",
      "upvotes": 23,
      "discussionId": "67b41edb2867282b4eb37ddf"
    },
    "publishedAt": "2025-02-18T00:49:53.124Z",
    "title": "Learning Getting-Up Policies for Real-World Humanoid Robots",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/6201fc5d91d53938a6432fbf/x35BuXOhc6ubukxLfiVzt.mp4"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.12152.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6201fc5d91d53938a6432fbf",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6201fc5d91d53938a6432fbf/VLs8ZYaZrop4KBpZn53fH.jpeg",
      "fullname": "Runpei Dong",
      "name": "RunpeiDong",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 3
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.11190",
      "authors": [
        {
          "_id": "67b420dfb2528c023491f455",
          "name": "Haoming Xu",
          "hidden": false
        },
        {
          "_id": "67b420dfb2528c023491f456",
          "name": "Ningyuan Zhao",
          "hidden": false
        },
        {
          "_id": "67b420dfb2528c023491f457",
          "name": "Liming Yang",
          "hidden": false
        },
        {
          "_id": "67b420dfb2528c023491f458",
          "name": "Sendong Zhao",
          "hidden": false
        },
        {
          "_id": "67b420dfb2528c023491f459",
          "name": "Shumin Deng",
          "hidden": false
        },
        {
          "_id": "67b420dfb2528c023491f45a",
          "name": "Mengru Wang",
          "hidden": false
        },
        {
          "_id": "67b420dfb2528c023491f45b",
          "name": "Bryan Hooi",
          "hidden": false
        },
        {
          "_id": "67b420dfb2528c023491f45c",
          "name": "Nay Oo",
          "hidden": false
        },
        {
          "_id": "67b420dfb2528c023491f45d",
          "name": "Huajun Chen",
          "hidden": false
        },
        {
          "_id": "67b420dfb2528c023491f45e",
          "user": {
            "_id": "620b3bbb0668e435407c8d0a",
            "avatarUrl": "/avatars/e0fccbb2577d76088e09f054c35cffbc.svg",
            "isPro": false,
            "fullname": "Ningyu Zhang",
            "user": "Ningyu",
            "type": "user"
          },
          "name": "Ningyu Zhang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-18T09:31:11.243Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-16T16:31:00.000Z",
      "title": "ReLearn: 대 언어 모델에 의한 잊음을 학습에 의한 것을 실현하기 위한 것.",
      "summary": "현재의 대규모 언어 모델의 잊는 방법은 목표 토큰의 확률을 줄이기 위해 역복원 최적화를 통해 수행되고 있습니다. 그러나 이 패러다임은 후속 토큰의 예측을 파괴하고 모델의 성능과 문법 일관성을 저하시킵니다. 또한 현재의 평가 지표는 컨텍스트 잊는 것을 과도하게 중시하고 응답의 흐름과 관련성을 부족하게 평가하고 있습니다. 이러한 문제를 해결하기 위해 우리는 ReLearn를 제안합니다. ReLearn는 효과적인 잊음을 실현하기 위한 데이터 확장과 미세 조정 파이프라인을 포함하며, 또한 상세한 평가 프레임워크를 사용합니다. 이 프레임워크는 지식 보존을 평가하기 위한 지식 잊는율(KFR)과 지식 보존율(KRR), 그리고 생성 품질을 평가하기 위한 언어 점수(LS)를 도입합니다. 우리의 실험은 ReLearn가 목표 잊음을 실현하면서 고품질의 출력을 유지하는 것을 성공적으로 보여주고 있습니다. 구조적 분석을 통해 역복원 최적화가 컨텍스트 일관성을 파괴한다는 것을 ReLearn가 이러한 기본적인 능력을 유지한다는 것을 더욱 강조합니다. 코드는 https://github.com/zjunlp/unlearn에 공개되어 있습니다.",
      "upvotes": 11,
      "discussionId": "67b420e2b2528c023491f506"
    },
    "publishedAt": "2025-02-18T00:58:24.094Z",
    "title": "ReLearn: Unlearning via Learning for Large Language Models",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/620b3bbb0668e435407c8d0a/A4YB7t6hDVty6QrvLN0a7.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.11190.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "620b3bbb0668e435407c8d0a",
      "avatarUrl": "/avatars/e0fccbb2577d76088e09f054c35cffbc.svg",
      "fullname": "Ningyu Zhang",
      "name": "Ningyu",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 17
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.12115",
      "authors": [
        {
          "_id": "67b41a72a38d04cc6148d80e",
          "name": "Samuel Miserendino",
          "hidden": false
        },
        {
          "_id": "67b41a72a38d04cc6148d80f",
          "name": "Michele Wang",
          "hidden": false
        },
        {
          "_id": "67b41a72a38d04cc6148d810",
          "name": "Tejal Patwardhan",
          "hidden": false
        },
        {
          "_id": "67b41a72a38d04cc6148d811",
          "name": "Johannes Heidecke",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-17T18:41:16.000Z",
      "title": "SWE-Lancer: 프론티ア LLMs는 본격적인 프리랜서 소프트웨어 엔지니어링에서 100만 달러를 벌 수 있을지 말지?",
      "summary": "우리는 SWE-Lancer를 소개합니다. 이 기준은 Upwork에서 제공하는 1,400여 개의 무료 일자로 구성된 소프트웨어 엔지니어링 작업집합입니다. 이 작업집합의 총 실제 보상은 1,000만 달러입니다. SWE-Lancer는 독립적인 엔지니어링 작업과 관리 작업으로 구성되어 있습니다. 독립적인 작업은 50개의 버그 수정부터 32,000 달러의 기능 구현까지 다양한 작업이 포함됩니다. 관리 작업에서는 모델은 기술적인 구현 제안 사이에서 선택합니다. 독립적인 작업은 경험 있는 소프트웨어 엔지니어가 세 번 검증된 엔드-to-엔드 테스트로 평가됩니다. 관리 결정은 원래 고용된 엔지니어링 관리자의 선택과 비교하여 평가됩니다. 모델 성능을 평가하고, 프론티어 모델이 대부분의 작업을 해결하지 못하는 것을 발견했습니다. 향후 연구를 위해, 우리는 SWE-Lancer 다이아몬드(https://github.com/openai/SWELancer-Benchmark)의 통합 Docker 이미지와 공개 평가 분할을 오픈소스로 공개합니다. 모델 성능을 경제적 가치에 매핑하여, 우리는 SWE-Lancer가 AI 모델 개발의 경제적 영향에 대한 연구를 더욱 확대할 수 있도록 지원하고자 합니다.",
      "upvotes": 9,
      "discussionId": "67b41a74a38d04cc6148d84b"
    },
    "publishedAt": "2025-02-18T00:28:31.293Z",
    "title": "SWE-Lancer: Can Frontier LLMs Earn $1 Million from Real-World Freelance Software Engineering?",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.12115.png",
    "numComments": 3,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 6128
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.12148",
      "authors": [
        {
          "_id": "67b40c8cdb88dfd19ab917f3",
          "name": "Ling Yang",
          "hidden": false
        },
        {
          "_id": "67b40c8cdb88dfd19ab917f4",
          "user": {
            "_id": "653e5d31ffd60206c8b64bb5",
            "avatarUrl": "/avatars/5076795722ec1f9e031654f301d30e8f.svg",
            "isPro": false,
            "fullname": "Xinchen Zhang",
            "user": "comin",
            "type": "user"
          },
          "name": "Xinchen Zhang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-18T09:31:31.841Z",
          "hidden": false
        },
        {
          "_id": "67b40c8cdb88dfd19ab917f5",
          "name": "Ye Tian",
          "hidden": false
        },
        {
          "_id": "67b40c8cdb88dfd19ab917f6",
          "name": "Chenming Shang",
          "hidden": false
        },
        {
          "_id": "67b40c8cdb88dfd19ab917f7",
          "name": "Minghao Xu",
          "hidden": false
        },
        {
          "_id": "67b40c8cdb88dfd19ab917f8",
          "name": "Wentao Zhang",
          "hidden": false
        },
        {
          "_id": "67b40c8cdb88dfd19ab917f9",
          "name": "Bin Cui",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-17T18:57:51.000Z",
      "title": "헤리마스 플로우：다모둠 이해와 생성의 간격을 무한히 닫는 방법",
      "summary": "順語法 모델의 거대한 성공은 다모달 대언어 모델(MLLMs)에서 뚜렷한 발전을 달성했습니다. Show-o, Transfusion, Emu3 등 강력한 모델들이 놀라운 발전을 이루고, 통일된 이미지 이해와 생성에 주목을 받았다. 우선, MLLMs의 이해 능력이 일반적으로 더 강한 생성 능력보다 훨씬 강하다는 것을 발견했습니다. 이 관점에서 HermesFlow라는 간단하고 일반적인 프레임워크를 제안했습니다. 이 프레임워크는 이해와 생성 사이의 간극을 쉽게 연결하는 것을 목표로 합니다. 특히, 같은 데이터를 입력으로 삼아 이해와 생성 모두 동일한 취향 데이터를 추출하고, Pair-DPO와 자기 자신의 플레이를 통해 동일한 취향 데이터를 사용하여 다모달 이해와 생성을 적절하게 조정합니다. 확장된 실험은 기존 방법보다 우리의 접근 방식의 뚜렷한 우위를 보여주며, 특히 다모달 이해와 생성 사이의 간극을 좁히는 데 적합합니다. 이러한 발견은 HermesFlow가 다음 세대의 다모달fundamental 모델의 일반적인 조정 프레임워크로서의 가능성을 밝혀줍니다. 코드: https://github.com/Gen-Verse/HermesFlow",
      "upvotes": 9,
      "discussionId": "67b40c8edb88dfd19ab9183f"
    },
    "publishedAt": "2025-02-17T23:29:29.396Z",
    "title": "HermesFlow: Seamlessly Closing the Gap in Multimodal Understanding and Generation",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.12148.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "653e5d31ffd60206c8b64bb5",
      "avatarUrl": "/avatars/5076795722ec1f9e031654f301d30e8f.svg",
      "fullname": "Xinchen Zhang",
      "name": "comin",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 13
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.11167",
      "authors": [
        {
          "_id": "67b4221bbc387d2eda6f8637",
          "user": {
            "_id": "650267e7e751d03da933a24a",
            "avatarUrl": "/avatars/f047a047d1de304cd97027463541bdf3.svg",
            "isPro": false,
            "fullname": "Bohan22",
            "user": "Bohan22",
            "type": "user"
          },
          "name": "Bohan Lyu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-18T09:31:06.388Z",
          "hidden": false
        },
        {
          "_id": "67b4221bbc387d2eda6f8638",
          "name": "Siqiao Huang",
          "hidden": false
        },
        {
          "_id": "67b4221bbc387d2eda6f8639",
          "user": {
            "_id": "67286718746a95c09d04cb1d",
            "avatarUrl": "/avatars/317efa8459cca08c2ff56c3ab116e15c.svg",
            "isPro": false,
            "fullname": "Zichen Liang",
            "user": "zcliang22",
            "type": "user"
          },
          "name": "Zichen Liang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-18T09:31:08.469Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-16T15:38:19.000Z",
      "title": "SURGE: 대규모 언어 모델의 일반적인 코드 실행 기능을 가능하게 하는 가능성",
      "summary": "대규모 언어 모델(LLMs)은 코드 관련 태스크에서 뛰어난 능력을 보여주고 있습니다. 예를 들어, 코드 이해와 코드 생성 등. 그러나 같은 중요도를 지닌 문제로, LLMs가 일반적인 코드 실행자로서 도움을 받을 수 있는지 여부에 대한 조사가 부족합니다. 이러한 능력의 체계적인 조사를 위해, SURGE라는 세부적인 벤치마크를 도입합니다. SURGE는 8개의 키 포인트로 구성됩니다: 다언어 프로그래밍 태스크, 컴피테션 수준의 프로그래밍 문제, 리포지토리 수준의 코드 분석, 고비용 과학 계산, 시간 복잡도가 높은 알고리즘, 버그 코드 분석, 특정 컴파일러 또는 실행 환경에 의존하는 프로그램, 그리고 형식적인 수학 증명 검증. SURGE에서 다수의 오픈 소스 및 소유권 있는 LLMs를 평가하고, 모델 크기와 학습 데이터 크기의 영향을 분석하는 스케일링 연구를 수행합니다. 또한, 모델 예측 오류를 분류하고 개선 가능한 영역을 탐색합니다. 우리의 발견은, LLMs는 특정 상황에서 코드 실행 결과를 예측할 수 있음을 보여줍니다. 그러나 일반적인 코드 실행자로서의 기능성에는 결점을 발견했습니다. 이 연구는 LLMs를 대신하는 코드 실행자로 사용하는 가능성에 대한 실증적인 전망을 제공합니다. 코드와 데이터셋은 https://github.com/Imbernoulli/SURGE에서 릴리스되어 있습니다.",
      "upvotes": 7,
      "discussionId": "67b4221ebc387d2eda6f8717"
    },
    "publishedAt": "2025-02-18T01:01:24.331Z",
    "title": "SURGE: On the Potential of Large Language Models as General-Purpose Surrogate Code Executors",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.11167.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "650267e7e751d03da933a24a",
      "avatarUrl": "/avatars/f047a047d1de304cd97027463541bdf3.svg",
      "fullname": "Bohan22",
      "name": "Bohan22",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.12146",
      "authors": [
        {
          "_id": "67b40ce4d3c5f50aa9b71df5",
          "name": "Ye Tian",
          "hidden": false
        },
        {
          "_id": "67b40ce4d3c5f50aa9b71df6",
          "name": "Ling Yang",
          "hidden": false
        },
        {
          "_id": "67b40ce4d3c5f50aa9b71df7",
          "user": {
            "_id": "653e5d31ffd60206c8b64bb5",
            "avatarUrl": "/avatars/5076795722ec1f9e031654f301d30e8f.svg",
            "isPro": false,
            "fullname": "Xinchen Zhang",
            "user": "comin",
            "type": "user"
          },
          "name": "Xinchen Zhang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-18T09:31:29.697Z",
          "hidden": false
        },
        {
          "_id": "67b40ce4d3c5f50aa9b71df8",
          "name": "Yunhai Tong",
          "hidden": false
        },
        {
          "_id": "67b40ce4d3c5f50aa9b71df9",
          "name": "Mengdi Wang",
          "hidden": false
        },
        {
          "_id": "67b40ce4d3c5f50aa9b71dfa",
          "name": "Bin Cui",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-17T18:57:26.000Z",
      "title": "디퓨션 셰아핑: 디퓨션 모델의 미세 조정에서 노이즈 트래픽의 셰아핑\n\n(请注意，虽然翻译力求准确，但在某些技术术语的表达上可能存在细微差异，具体取决于上下文和领域内的常用术语。)",
      "summary": "Diffusion-Sharpening을 제안합니다. 이는 샘플링 프로세스의 프로젝트를 최적화하고 하류의 어레이먼트를 향상시키기 위한 미세 조정 접근 방식입니다. 현재의 RL 기반의 미세 조정 방법은 단일의 훈련 스텝을 중점으로, 프로젝트 수준의 어레이먼트를 뛰어넘고 있지만, 최근의 샘플링 프로젝트 최적화 방법은 과도한 추론 NFE 비용에 부담을 받습니다. Diffusion-Sharpening은 학습 중 최적의 프로젝트를 선택하기 위한 패스 적분 프레임워크를 사용하며, 보상 피드백을 활용하여 추론 비용을 극복합니다. 우리 방식은 추가적인 NFE가 필요하지 않고도 최고의 추론 효율성을 보여주며, 효율적인 학습 효율성과 빠른 수렴을 보여줍니다. 확장된 실험은 텍스트 어레이먼트, 구성 능력, 인간의 취향 등 다양한 메트릭을 통해 RL 기반의 미세 조정 방법(예: Diffusion-DPO)과 샘플링 프로젝트 최적화 방법(예: 추론 스케일링)을 초과하는 결과를 보여줍니다. 코드: https://github.com/Gen-Verse/Diffusion-Sharpening",
      "upvotes": 6,
      "discussionId": "67b40ce8d3c5f50aa9b71f9a"
    },
    "publishedAt": "2025-02-17T23:30:53.097Z",
    "title": "Diffusion-Sharpening: Fine-tuning Diffusion Models with Denoising Trajectory Sharpening",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.12146.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "653e5d31ffd60206c8b64bb5",
      "avatarUrl": "/avatars/5076795722ec1f9e031654f301d30e8f.svg",
      "fullname": "Xinchen Zhang",
      "name": "comin",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 13
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.10458",
      "authors": [
        {
          "_id": "67b3ea0f4dd7ea0538ce589d",
          "user": {
            "_id": "6354bda206d707b33249c4c2",
            "avatarUrl": "/avatars/bbd9f76274ac52214df92084d50bc7b5.svg",
            "isPro": false,
            "fullname": "Zhenxing Mi",
            "user": "Mifucius",
            "type": "user"
          },
          "name": "Zhenxing Mi",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-18T09:31:52.837Z",
          "hidden": false
        },
        {
          "_id": "67b3ea0f4dd7ea0538ce589e",
          "name": "Kuan-Chieh Wang",
          "hidden": false
        },
        {
          "_id": "67b3ea0f4dd7ea0538ce589f",
          "name": "Guocheng Qian",
          "hidden": false
        },
        {
          "_id": "67b3ea0f4dd7ea0538ce58a0",
          "name": "Hanrong Ye",
          "hidden": false
        },
        {
          "_id": "67b3ea0f4dd7ea0538ce58a1",
          "name": "Runtao Liu",
          "hidden": false
        },
        {
          "_id": "67b3ea0f4dd7ea0538ce58a2",
          "name": "Sergey Tulyakov",
          "hidden": false
        },
        {
          "_id": "67b3ea0f4dd7ea0538ce58a3",
          "name": "Kfir Aberman",
          "hidden": false
        },
        {
          "_id": "67b3ea0f4dd7ea0538ce58a4",
          "name": "Dan Xu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-12T05:30:08.000Z",
      "title": "「기억하고, 그 것을 확산시키자: 확산 모델에서 다모달 사례별 이유론」",
      "summary": "이 논문에서는 새로운 아라インメン트 패러다임인 ThinkDiff를 소개합니다. 이 패러다임은 시각 언어 모델(VLMs)의 강점을 통합하여, 텍스트로부터 이미지의 디퓨전 모델에 다양한 종류의 컨텍스트 이해와 추론 능력을 제공합니다. 현재의 다양한 종류의 디퓨전의 미세 조정 방법들은 픽셀 수준의 재구성에 초점을 맞추지만, 컨텍스트 추론에는 거의 집중되지 않고, 추론 데이터 세트의 복잡성과 제한성에 의해 제한되어 있습니다. ThinkDiff는 시각 언어 훈련을 가짜 태스크로 삼고, VLMs와 대규모 언어 모델(LLM)의 디코더를 어레이링하여 이러한挑戦를 해결합니다. 이 가짜 태스크는 LLM의 디코더가, 디퓨전 디코더가 사용하는 대응하는 LLM 엔코더에서 프로ン퓰트 인코딩을 사용하여 입력 특징 공간과 동일한 공간과 공유함을 관찰합니다. 따라서, VLMs와 디퓨전 디코더의 어레이링을 간단히 수행할 수 있습니다. 복잡한 훈련이나 데이터 세트가 필요하지 않고, ThinkDiff는 이해, 추론, 그리고 구성의 능력을 효과적으로 발휘합니다. 실험은 CoBSAT의 도전적인 벤치마크에서 정확도를 19.2%에서 46.3%로 크게 향상시켰으며, 4개의 A100 GPU를 5시간 동안 훈련해도 가능했습니다. 또한, ThinkDiff는 여러 이미지와 텍스트를 논리적으로 일관된 이미지로 구성하기 위해 뛰어난 성능을 나타냅니다. 프로젝트 페이지: https://mizhenxing.github.io/ThinkDiff.",
      "upvotes": 5,
      "discussionId": "67b3ea124dd7ea0538ce592d"
    },
    "publishedAt": "2025-02-18T04:33:41.120Z",
    "title": "I Think, Therefore I Diffuse: Enabling Multimodal In-Context Reasoning in Diffusion Models",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.10458.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6354bda206d707b33249c4c2",
      "avatarUrl": "/avatars/bbd9f76274ac52214df92084d50bc7b5.svg",
      "fullname": "Zhenxing Mi",
      "name": "Mifucius",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.11196",
      "authors": [
        {
          "_id": "67b42223c2fe54b8d43efed6",
          "name": "Yixin Ou",
          "hidden": false
        },
        {
          "_id": "67b42223c2fe54b8d43efed7",
          "name": "Yunzhi Yao",
          "hidden": false
        },
        {
          "_id": "67b42223c2fe54b8d43efed8",
          "user": {
            "_id": "620b3bbb0668e435407c8d0a",
            "avatarUrl": "/avatars/e0fccbb2577d76088e09f054c35cffbc.svg",
            "isPro": false,
            "fullname": "Ningyu Zhang",
            "user": "Ningyu",
            "type": "user"
          },
          "name": "Ningyu Zhang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-18T09:31:04.227Z",
          "hidden": false
        },
        {
          "_id": "67b42223c2fe54b8d43efed9",
          "name": "Hui Jin",
          "hidden": false
        },
        {
          "_id": "67b42223c2fe54b8d43efeda",
          "name": "Jiacheng Sun",
          "hidden": false
        },
        {
          "_id": "67b42223c2fe54b8d43efedb",
          "name": "Shumin Deng",
          "hidden": false
        },
        {
          "_id": "67b42223c2fe54b8d43efedc",
          "name": "Zhenguo Li",
          "hidden": false
        },
        {
          "_id": "67b42223c2fe54b8d43efedd",
          "name": "Huajun Chen",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-16T16:55:43.000Z",
      "title": "LLM는 어떻게 새로운 지식을 얻습니다? 연속적인 예측 학습의 지식 사이클을 고려한 관점에서",
      "summary": "큰 규모 언어 모델(LLMs)은 확장된 지식 밀도형 작업에서 특별한 능력을 갖추기 위해, 새로운 지식을 내부화하는 방법의 중요한 결함이 드러났습니다. 특히, 학습된 지식이 신경 컴퓨팅에 구조적으로 내장되는 방법에 대한 이해가 어렵습니다. 우리는 지식 회로의 진화에서 이 문제를 해결하고 지식의 저장 및 처리를 촉진하는 계산적인 서브 그래프를 특정합니다. 연속적인 예측 훈련의 전 과정에서 회로 진화의 체계적인 분석으로부터 다음과 같은 중요한 발견이 얻어졌습니다: 1) 새로운 지식의 획득은 기존 지식과의 연관성에 영향을 받습니다; 2) 지식 회로의 진화는 형성에서 최적화로의 다른 단계를 나타냅니다; 3) 지식 회로의 진화는 깊은 패턴에 따라 진행됩니다. 이러한 관점은 LLMs에서 새로운 지식의 획득 구조의 이론적인 이해를 촉진하고, 연속적인 예측 훈련의 전략을 개선하여 모델의 성능을 향상시키는 잠재적인 의미를 제공합니다. 코드와 데이터는 https://github.com/zjunlp/DynamicKnowledgeCircuits에서 이용할 수 있습니다.",
      "upvotes": 5,
      "discussionId": "67b42225c2fe54b8d43eff9b"
    },
    "publishedAt": "2025-02-18T01:02:25.236Z",
    "title": "How Do LLMs Acquire New Knowledge? A Knowledge Circuits Perspective on Continual Pre-Training",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/620b3bbb0668e435407c8d0a/_LGnwvwslWc3YDIirfOKS.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.11196.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "620b3bbb0668e435407c8d0a",
      "avatarUrl": "/avatars/e0fccbb2577d76088e09f054c35cffbc.svg",
      "fullname": "Ningyu Zhang",
      "name": "Ningyu",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 17
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.11438",
      "authors": [
        {
          "_id": "67b406993d0f54ab381594f5",
          "name": "Jimin Lee",
          "hidden": false
        },
        {
          "_id": "67b406993d0f54ab381594f6",
          "name": "Ingeol Baek",
          "hidden": false
        },
        {
          "_id": "67b406993d0f54ab381594f7",
          "name": "Byeongjeong Kim",
          "hidden": false
        },
        {
          "_id": "67b406993d0f54ab381594f8",
          "name": "Hwanhee Lee",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-17T04:52:24.000Z",
      "title": "SAFE-SQL: 텍스트에서 SQL로 자동화한 핑그레이드 샘플링에 의한 텍스트 포맷 내부의 피드백 학습",
      "summary": "Text-to-SQL는 자연어의 질문을 실행 가능한 SQL 쿼리로 변환하는 것을 목표로 합니다. 이전의 접근 방식에서, 구조 마스킹 선택 등 기법을 사용하여 유사한 학습 예를 검색하여 큰 언어 모델(LLM)을 지도하고 강력한 성능을 보여주었습니다. 그러나 실제 세계적인 시나리오에서 이러한 예가 없는 경우 어려움을 겪습니다. 이러한 한계를 극복하기 위해, 우리는 Text-to-SQL의 SQL 생성을 개선하기 위한 새로운 프레임워크 \"Self-Augmentation in-context learning with Fine-grained Example selection for Text-to-SQL (SAFE-SQL)\"를 제안합니다. SAFE-SQL은 자동으로 생성된 예를 생성하고 필터링하여 고품질의 in-context learning 예를 구축합니다. SAFE-SQL은 자동으로 생성된 예를 사용하여 이전의 0-shot, few-shot의 Text-to-SQL 프레임워크를 초과하고 실행 정확도를 높입니다. 특히, 우리의 접근 방식은 단순한 방법이 실패할 확률이 매우 높은, 거의 발견되지 않는 시나리오에서도 추가적인 성능 향상을 제공합니다.",
      "upvotes": 5,
      "discussionId": "67b4069a3d0f54ab38159520"
    },
    "publishedAt": "2025-02-17T23:06:03.562Z",
    "title": "SAFE-SQL: Self-Augmented In-Context Learning with Fine-grained Example Selection for Text-to-SQL",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.11438.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "63f6f245e94ed998c46316df",
      "avatarUrl": "/avatars/9c0ec8682d4a85b96d2180602b1bbe6c.svg",
      "fullname": "ingeolbaek",
      "name": "ingeol",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 3
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.09061",
      "authors": [
        {
          "_id": "67b401de3995f28d45c212d6",
          "name": "Debangshu Banerjee",
          "hidden": false
        },
        {
          "_id": "67b401de3995f28d45c212d7",
          "name": "Tarun Suresh",
          "hidden": false
        },
        {
          "_id": "67b401de3995f28d45c212d8",
          "name": "Shubham Ugare",
          "hidden": false
        },
        {
          "_id": "67b401de3995f28d45c212d9",
          "name": "Sasa Misailovic",
          "hidden": false
        },
        {
          "_id": "67b401de3995f28d45c212da",
          "name": "Gagandeep Singh",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-13T08:23:42.000Z",
      "title": "CRANE: 제약付き LLM 생성에 기반한 추론",
      "summary": "LLM은 코드 생성, 기호적 수학논리, 기타 작업에서 합성적 언어와 의미적 정확성을 유지하는 출력을 생성해야 합니다. LLM의 생성을 공식적인 언어에 따라하도록 강제하는 것은 실험적으로 보임에 따라 논리적 사고능력을 저하시키는 경우가 많습니다. 본 연구에서는 우선 LLM의 출력을 매우 제한된 언어에 따라하도록 하는 것이 논리적 사고능력을 저하시키는 이유를 이론적으로 설명합니다. 다음으로, 합성적 언어와 의미적 정확성을 보장하면서 논리적 사고능력을 유지할 수 있는 방법론을 제시합니다. 이러한 이론적인 원리에 기반하여 논리적 사고를 강화한 제약된 디코딩 알고리즘인 CRANE를 제안합니다. CRANE는 제약된 생성의 정확성과 비제한된 생성의 유연성을 균형을 이루며, 여러 오픈소스 LLM과 벤치마크에서 GSM-symbolic과 FOLIO의 어려운 기호적 논리 벤치마크에서 10% 정도의 정확도 향상을 나타냅니다.",
      "upvotes": 4,
      "discussionId": "67b401e03995f28d45c21354"
    },
    "publishedAt": "2025-02-17T22:43:51.555Z",
    "title": "CRANE: Reasoning with constrained LLM generation",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.09061.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "65e7bb35e5e78134ab049942",
      "avatarUrl": "/avatars/3c0972f0d59e51ebb5c218ee736d4458.svg",
      "fullname": "Tarun Suresh",
      "name": "tarsur909",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.11275",
      "authors": [
        {
          "_id": "67b3fa2862838a378b21860d",
          "name": "Letian Peng",
          "hidden": false
        },
        {
          "_id": "67b3fa2862838a378b21860e",
          "name": "Zilong Wang",
          "hidden": false
        },
        {
          "_id": "67b3fa2862838a378b21860f",
          "name": "Feng Yao",
          "hidden": false
        },
        {
          "_id": "67b3fa2862838a378b218610",
          "name": "Jingbo Shang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-16T21:32:20.000Z",
      "title": "쿠커오：대규모의 네트워크 구축으로 IE 무료 라이너가 탄생한 LLM의 낡은집",
      "summary": "큰 질의 높은 품질의 데이터, 즉 사전학습용의 탬플릿 텍스트와 사전학습 후의 어노테이션, 신중하게 준비되어 있으며, 높은 규모의 언어 모델(LLMs)의 개발을 촉진하고 있습니다. 비교적으로, 정보 추출(IE)에서 사전학습 데이터와 같은 BIO 태그가 붙은 시퀀스는 확장하기 어렵습니다. 우리는 IE 모델이 LLM 데이터의 리소스를 자유로워서 작용하는 것을 보여주고 있습니다. 구체적으로, 다음 텍스트 예측을 추출하기 위해 재구성합니다. 특히, 우리가 제안한 다음 텍스트 추출(NTE) 패러다임은 LLM의 사전학습 데이터와 사전학습 후의 데이터로부터 102.6M의 추출 데이터를 변환하여 다양한 IE 모델인 Cuckoo를 학습합니다. 적은샷 설정에서 Cuckoo는 기존의 복잡한 명령어 기반 IE에 비해 기존의 사전학습된 IE 모델보다 더 좋은 성능으로 효과적으로 적용됩니다. 자유로워서 Cuckoo는 LLM 데이터의 준비의 진보에 자연스럽게 진화하며, LLM의 훈련 파이프라인 개선에 혜택을 받습니다. 추가적인 수동적인 노력을 필요로 하지 않습니다.",
      "upvotes": 4,
      "discussionId": "67b3fa2962838a378b21867b"
    },
    "publishedAt": "2025-02-17T22:10:49.900Z",
    "title": "Cuckoo: An IE Free Rider Hatched by Massive Nutrition in LLM's Nest",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.11275.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64323dd503d81fa4d26deaf9",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64323dd503d81fa4d26deaf9/x3ES8VXEZJljxDWvFWaAf.png",
      "fullname": "Letian Peng",
      "name": "KomeijiForce",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 7
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.11901",
      "authors": [
        {
          "_id": "67b3f8cc1bfe04e82830b752",
          "name": "Dylan Zhang",
          "hidden": false
        },
        {
          "_id": "67b3f8cc1bfe04e82830b753",
          "name": "Justin Wang",
          "hidden": false
        },
        {
          "_id": "67b3f8cc1bfe04e82830b754",
          "name": "Tianran Sun",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-17T15:24:11.000Z",
      "title": "데이터 부족에 대응한 64%의 우위를 가진 증명방향付き 프로그래머의 개발",
      "summary": "현재의 LM은 증명 중심의 프로그래밍에서 데이터 부족이 문제로 되고, 이는 두 가지 주요 점에 이르는 문제로 간주된다.",
      "upvotes": 3,
      "discussionId": "67b3f8cd1bfe04e82830b77f"
    },
    "publishedAt": "2025-02-17T22:05:54.047Z",
    "title": "Building A Proof-Oriented Programmer That Is 64% Better Than GPT-4o Under Data Scarsity",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.11901.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "642b8add48f67b6f21d4eb20",
      "avatarUrl": "/avatars/f15025b39248daa19a18e6ccb2eaaa0c.svg",
      "fullname": "Dylan",
      "name": "shizhuo2",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.12054",
      "authors": [
        {
          "_id": "67b44a6888813676da9f8239",
          "name": "Xinyu Zhang",
          "hidden": false
        },
        {
          "_id": "67b44a6888813676da9f823a",
          "name": "Yuxuan Dong",
          "hidden": false
        },
        {
          "_id": "67b44a6888813676da9f823b",
          "name": "Yanrui Wu",
          "hidden": false
        },
        {
          "_id": "67b44a6888813676da9f823c",
          "name": "Jiaxing Huang",
          "hidden": false
        },
        {
          "_id": "67b44a6888813676da9f823d",
          "user": {
            "_id": "6602548a68d519ed324b47c5",
            "avatarUrl": "/avatars/5ab411f87440cc2a98c7a1c6a3ed5548.svg",
            "isPro": false,
            "fullname": "ChengyouJia",
            "user": "ChengyouJia",
            "type": "user"
          },
          "name": "Chengyou Jia",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-18T09:30:47.313Z",
          "hidden": false
        },
        {
          "_id": "67b44a6888813676da9f823e",
          "name": "Basura Fernando",
          "hidden": false
        },
        {
          "_id": "67b44a6888813676da9f823f",
          "name": "Mike Zheng Shou",
          "hidden": false
        },
        {
          "_id": "67b44a6888813676da9f8240",
          "name": "Lingling Zhang",
          "hidden": false
        },
        {
          "_id": "67b44a6888813676da9f8241",
          "name": "Jun Liu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-17T17:24:14.000Z",
      "title": "물리적 이유：물리 기반의 추론의 전면적인 기준",
      "summary": "대 언어 모델은 수학이나 논리 추론에 특화된 능력을 보여주지만, 현재의 평가는 물리적인 논리를 뛰어넘고 있습니다. 물리적인 논리는 물리학의 定理 및 제약을 요구하는 복잡한 작업입니다. 우리는 지식 기반(25%)와 논리 기반(75%)의 문제를 포함하는 1,200 문제의 벤치마크 \"PhysReason\"를 제안합니다. 논리 기반의 문제는 쉬운, 중간난, 어려운 3가지 난이도 레벨로 나눌 수 있습니다. 특히, 문제는 평균 8.1 단계의 해결 방법이 필요하며, 어려운 문제는 15.6 단계를 필요로 하며, 물리적인 논리의 복잡성을 반영하고 있습니다. 우리는 물리적인 답의 자동 평가 프레임워크를 제안합니다. 이는 효율적인 답안 수준과 구성 수준의 세부적인 평가를 포함하는 것입니다. Deepseek-R1, Gemini-2.0-Flash-Thinking, o3-mini-high 등 우수한 모델은 답안 수준의 평가에서 60% 미만을 달성하고, 지식 문제(75.11%)부터 어려운 문제(31.95%)까지 성능이 떨어집니다. 단계 수준의 평가를 통해, 우리는 4가지 키워드를 지정했습니다: 물리학의 定理의 적용, 물리적 과정의 이해, 계산, 물리적 조건의 분석. 이러한 발견은 물리적인 논리 능력의 평가를 위해 새로운 및 종합적인 벤치마크인 \"PhysReason\"의 역할을 확립하고 있습니다. 우리 코드 및 데이터는 https://dxzxy12138.github.io/PhysReason에 공개됩니다.",
      "upvotes": 2,
      "discussionId": "67b44a6988813676da9f82d0"
    },
    "publishedAt": "2025-02-18T03:53:47.570Z",
    "title": "PhysReason: A Comprehensive Benchmark towards Physics-Based Reasoning",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.12054.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6602548a68d519ed324b47c5",
      "avatarUrl": "/avatars/5ab411f87440cc2a98c7a1c6a3ed5548.svg",
      "fullname": "ChengyouJia",
      "name": "ChengyouJia",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 3
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.11330",
      "authors": [
        {
          "_id": "67b42c5632929e97a92dee90",
          "name": "Minbyul Jeong",
          "hidden": false
        },
        {
          "_id": "67b42c5632929e97a92dee91",
          "name": "Jungho Cho",
          "hidden": false
        },
        {
          "_id": "67b42c5632929e97a92dee92",
          "name": "Minsoo Khang",
          "hidden": false
        },
        {
          "_id": "67b42c5632929e97a92dee93",
          "name": "Dawoon Jung",
          "hidden": false
        },
        {
          "_id": "67b42c5632929e97a92dee94",
          "name": "Teakgyu Hong",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-17T01:05:31.000Z",
      "title": "사용자의 취향을 활용한 시스템 메세지 생성에 대한 오픈 소스 모델의 활용",
      "summary": "시스템 메세지는 대규모 언어 모델(LLM)과의 상호작용에서 중요한 역할을 수행합니다. 이러한 메세지는 대화를 시작하기 위해 사용되며, 사용자가 특정 역할을 할 수 있도록 할 수 있으며, 행동을 결정하고 배경 정보를 포함할 수 있습니다. 또한 출력 형식과 커뮤니케이션 스타일을 지정할 수 있습니다. 이러한 다양성을 더한 것이 공개된 데이터는 시스템 메세지를 포함하는 데이터가 거의 없으며, 업계에서는 엄격한 라이센스 제약으로 제한되어 있습니다. 공개된 데이터에 시스템 메세지를 자동으로 라벨링하여 사용자가 원하는 대로 생성하는 것은 사용자 지시에 맞는 시스템 메세지를 만들 때 상당한 자원이 필요합니다. 이러한 문제를 해결하기 위해, 우리의 연구에서는 시스템 메세지를 생성하는 파이프라인인 \"SysGen\"를 도입했습니다. 이 파이프라인은 시스템 메세지를 포함하지 않는 데이터셋으로부터, 서브젝트 피쳐링 데이터셋으로부터 생성된 시스템 메세지를 사용하여, 더 적합한 보조자의 응답을 얻을 수 있습니다. SysGen 데이터에 의한 훈련은 Multifacet 벤치마크에서 모델의 응답과 시스템 메세지, 사용자 지시의 일치성을 크게 향상시키고, 다른未见된 벤치마크(예: Open LLM Leaderboard 2)에 최소한의 영향을 미칩니다. 우리의 질적 분석은 다양한 맥락에서 더 좋은 적응성을 보장하기 위해 다양한 시스템 메세지의 중요성을 강조합니다.",
      "upvotes": 2,
      "discussionId": "67b42c5732929e97a92deed7"
    },
    "publishedAt": "2025-02-18T01:45:36.359Z",
    "title": "System Message Generation for User Preferences using Open-Source Models",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.11330.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64587be872b60ae7a3817858",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64587be872b60ae7a3817858/BbdOOxOCEzWTvEpkWp8MM.png",
      "fullname": "Minbyul Jeong",
      "name": "Minbyul",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 3
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.09083",
      "authors": [
        {
          "_id": "67b30726d4665a0448e6436d",
          "user": {
            "_id": "6698cffdb2ebada9f4a7e7d7",
            "avatarUrl": "/avatars/e66d946c14595d3b008185f2be8d2f57.svg",
            "isPro": false,
            "fullname": "Greta Warren",
            "user": "gretawarren",
            "type": "user"
          },
          "name": "Greta Warren",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-18T09:32:34.585Z",
          "hidden": false
        },
        {
          "_id": "67b30726d4665a0448e6436e",
          "name": "Irina Shklovski",
          "hidden": false
        },
        {
          "_id": "67b30726d4665a0448e6436f",
          "name": "Isabelle Augenstein",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-13T08:56:25.000Z",
      "title": "「일하는 것을 보여 주세요: 설명 가능한 자동화 사실검증의 문제」",
      "summary": "대 언어 모델과 생성 AI가 온라인 미디어에 광범위하게 확산되어 있으며, 이러한 기술의 확산에 따라 불신 의도와 복잡성이 증가하고, 효과적인 자동 사실검증의 필요성이 높아지고 있습니다. 사실검증의 복잡한 특성에 따라, 자동 사실검증 시스템은 사실검증자에게 출력을 검토하도록 촉발하기 위해 어떤 설명을 제공해야 하는지 중요합니다. 그러나 이러한 설명은 사실검증자의 결정 기능과 논리 과정에 어떻게 잘 합쳐질지 명확하지 않습니다. 사실검증 전문가와의 반구조적인 인터뷰를 통해, 우리는 다음과 같은 점을 보완할 수 있습니다: (i) 사실검증자가 증거를 평가하고 결정을 하고 그 과정을 설명하는 방법; (ii) 사실검증자가 실제로 자동 도구를 어떻게 사용하는지 조사; (iii) 자동 사실검증 도구의 사실검증자의 설명 요구를 특정하는 것. 이 조사 결과를 통해, 부족한 설명의 필요성을 보여주고, 반복 가능한 사실검증의 설명의 중요한 기준을 정하고, 모델의 이유를 변경하고 특정 증거를 참조하고, 불확실성과 정보의 결함이 특징적으로 나타내는 것을 보여줍니다.",
      "upvotes": 1,
      "discussionId": "67b30727d4665a0448e6438d"
    },
    "publishedAt": "2025-02-18T04:37:21.573Z",
    "title": "Show Me the Work: Fact-Checkers' Requirements for Explainable Automated Fact-Checking",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/6698cffdb2ebada9f4a7e7d7/55xAEeg9Xsk87DXHTH9gM.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.09083.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6698cffdb2ebada9f4a7e7d7",
      "avatarUrl": "/avatars/e66d946c14595d3b008185f2be8d2f57.svg",
      "fullname": "Greta Warren",
      "name": "gretawarren",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.12135",
      "authors": [
        {
          "_id": "67b4028237db78705fb256e1",
          "user": {
            "_id": "64fb31a34c8924c4fe7498bc",
            "avatarUrl": "/avatars/6c8e4a66e1b8b3c786a4000210089392.svg",
            "isPro": false,
            "fullname": "Chaoyue Song",
            "user": "chaoyue7",
            "type": "user"
          },
          "name": "Chaoyue Song",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-18T09:31:40.771Z",
          "hidden": false
        },
        {
          "_id": "67b4028237db78705fb256e2",
          "name": "Jianfeng Zhang",
          "hidden": false
        },
        {
          "_id": "67b4028237db78705fb256e3",
          "name": "Xiu Li",
          "hidden": false
        },
        {
          "_id": "67b4028237db78705fb256e4",
          "name": "Fan Yang",
          "hidden": false
        },
        {
          "_id": "67b4028237db78705fb256e5",
          "name": "Yiwen Chen",
          "hidden": false
        },
        {
          "_id": "67b4028237db78705fb256e6",
          "name": "Zhongcong Xu",
          "hidden": false
        },
        {
          "_id": "67b4028237db78705fb256e7",
          "name": "Jun Hao Liew",
          "hidden": false
        },
        {
          "_id": "67b4028237db78705fb256e8",
          "name": "Xiaoyang Guo",
          "hidden": false
        },
        {
          "_id": "67b4028237db78705fb256e9",
          "name": "Fayao Liu",
          "hidden": false
        },
        {
          "_id": "67b4028237db78705fb256ea",
          "name": "Jiashi Feng",
          "hidden": false
        },
        {
          "_id": "67b4028237db78705fb256eb",
          "name": "Guosheng Lin",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-17T18:53:27.000Z",
      "title": "MagicArticulate: 3D 모델의 아키텍처 준비를 하는 것입니다.",
      "summary": "3D 콘텐츠 제작의 폭발적인 성장에 따라,静的な3D 모델을动的なアーチュレーション 준비한 버전을 자동으로 변환하는 요구가 증가하고 있습니다. 전통적인 접근 방식은, 자동 注釈를 통해 더 많은 시간과 노동이 필요하며, 또한, 규모적인 벤치마크의 부족이 학습 기반의 해결책 개발에 문제로 작용합니다. 본 논문에서는, MagicArticulate라는 효과적인 프레임워크를 제안하여,静的な3D 모델을动的なアーチュレーション 준비한 자산을 자동으로 변환하는 것을 실현합니다. 우리의 주요 기여는 세 가지입니다. 먼저, Articulation-XL라는 규모적인 벤치마크를 제안하여, 33,000점 이상의 고품질의アーチュレーション 注釈를 포함하는 3D 모델에서 선정된 것입니다. 다음으로, 새로운 스ケルタル 생성 방법을 제안하여, 이 작업은 순서 모델링 문제로 구성되며, 자동 협조 변환 드라이버를 사용하여 스ケルタル 내의 骨または関節의 수의 변동 및 3D 모델 간의 고유의 의존관계를 자연스럽게 처리하는 것을 목표로 합니다. 마지막으로, 関節と頂点의 체적 계산 기하 거리를 포함한 기능적인 분산 프로세스를 사용하여 スキンニング 가중치를 예측합니다. 확산된 실험에 따라, MagicArticulate는 현재의 방법보다 크게 뛰어넘으며, 고품질의アーチュレーション을 실현하고 실제적인 애니메이션을 가능하게 합니다. 프로젝트 페이지: https://chaoyuesong.github.io/MagicArticulate.",
      "upvotes": 1,
      "discussionId": "67b4028437db78705fb25726"
    },
    "publishedAt": "2025-02-18T04:34:15.786Z",
    "title": "MagicArticulate: Make Your 3D Models Articulation-Ready",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.12135.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64fb31a34c8924c4fe7498bc",
      "avatarUrl": "/avatars/6c8e4a66e1b8b3c786a4000210089392.svg",
      "fullname": "Chaoyue Song",
      "name": "chaoyue7",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.11831",
      "authors": [
        {
          "_id": "67b450cf315f7b69956df3d6",
          "name": "Quentin Garrido",
          "hidden": false
        },
        {
          "_id": "67b450cf315f7b69956df3d7",
          "name": "Nicolas Ballas",
          "hidden": false
        },
        {
          "_id": "67b450cf315f7b69956df3d8",
          "name": "Mahmoud Assran",
          "hidden": false
        },
        {
          "_id": "67b450cf315f7b69956df3d9",
          "name": "Adrien Bardes",
          "hidden": false
        },
        {
          "_id": "67b450cf315f7b69956df3da",
          "name": "Laurent Najman",
          "hidden": false
        },
        {
          "_id": "67b450cf315f7b69956df3db",
          "name": "Michael Rabbat",
          "hidden": false
        },
        {
          "_id": "67b450cf315f7b69956df3dc",
          "name": "Emmanuel Dupoux",
          "hidden": false
        },
        {
          "_id": "67b450cf315f7b69956df3dd",
          "name": "Yann LeCun",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-17T14:27:14.000Z",
      "title": "直觉적인 물리학 이해는 자연 비디오에서 자기규범의 사전 학습을 통해 발생합니다.",
      "summary": "우리는 자연스러운 영화에서 숨겨진 영역을 예측하기 위한 일반적인 심층 신경망 모델로 직감적인 물리적 인식의 발생을 조사하고 있습니다. 기대 파괴 프레임워크를 활용하여 학습된 표현 공간에서 결과를 예측하는 모델은 물체의 영구성과 모양의 일관성 등 직감적인 물리적 특성을 이해하는 것을 발견했습니다. 반면, 픽셀 공간에서 이미지 예측과 텍스트를 통해 이유를 찾아낸 다양한 규모의 언어 모델은 가까운 성능을 달성합니다. 이러한 아키텍처를 비교하면, 감각 입력의 부족 부분을 예측하는 동시에 추상적인 표현 공간을 학습하는 것(예측 코딩과 같은 것)으로 직감적인 물리적 인식을 얻을 수 있다는 것을 명확히 합니다. 한 주 동안 개인적인 영화로 훈련된 모델도 운명보다 높은 성능을 달성하는 것을 발견합니다. 이는 핵심 지식(세계를 이해하기 위해 종속적인 유전적 시스템)이 직감적인 물리적 인식의 이해에 필요하고 있다고 생각하는 아이디어를 질의합니다.",
      "upvotes": 1,
      "discussionId": "67b450d0315f7b69956df3f9"
    },
    "publishedAt": "2025-02-18T04:20:25.916Z",
    "title": "Intuitive physics understanding emerges from self-supervised pretraining on natural videos",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.11831.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "5f1158120c833276f61f1a84",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1608042047613-5f1158120c833276f61f1a84.jpeg",
      "fullname": "Niels Rogge",
      "name": "nielsr",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 763
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.11085",
      "authors": [
        {
          "_id": "67b44f44620ae0bad17d6699",
          "name": "Yasir Ghunaim",
          "hidden": false
        },
        {
          "_id": "67b44f44620ae0bad17d669a",
          "user": {
            "_id": "642b51385bf2355d02a23d15",
            "avatarUrl": "/avatars/87985347643b2647555f2453fa4d94fb.svg",
            "isPro": true,
            "fullname": "Hasan Abed Al Kader Hammoud",
            "user": "hammh0a",
            "type": "user"
          },
          "name": "Hasan Abed Al Kader Hammoud",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-18T09:30:43.057Z",
          "hidden": false
        },
        {
          "_id": "67b44f44620ae0bad17d669b",
          "name": "Bernard Ghanem",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-16T11:46:23.000Z",
      "title": "예전 학습을 통한 원자의 특성 예측을 통한 데이터 효율화",
      "summary": "이 논문은 원자 물질의 성질 예측에 최근의 패러다임에 도전하고 있습니다. 이 패러다임은 발전과 데이터 세트의 크기 및 계산 자원의 증가가 관련되어 있음을 보여줍니다. 우리는 적절한 데이터 세트를 선택하여 사전 학습이 수행된 경우, 규모가 큰 사전 학습을 뛰어넘을 수 있음을 보여주고, 그 계산 비용을 1/24로 줄일 수 있음을 보여줍니다. 우리는 컴퓨터 비전의 Fr\\'echet Inception Distance를 기반으로 한 새로운 지표인 CSI(Chemical Similarity Index)를 분자 그래프에 적용하여, 상류의 사전 학습 데이터 세트와 하류의 작업 사이에서의 일치성을 정량화합니다. CSI의 거리가 최소가 되는 가장 관련성이 높은 데이터 세트를 선택함으로써, 작은 데이터 세트에서 수행된 사전 학습 모델은 규모가 큰 혼합 데이터 세트(예: JMP)에서 수행된 사전 학습 모델을 경험적으로 초과할 수 있음을 보여줍니다. 반대로, 관련성이 없는 데이터를 무용하게 추가하는 것은 모델의 성능을 저하시키는 것을 보여줍니다. 우리의 발견은 원자 물질의 성질 예측의 사전 학습에서 질의가 양보다 더 우수함을 보여줍니다.",
      "upvotes": 1,
      "discussionId": "67b44f45620ae0bad17d66b0"
    },
    "publishedAt": "2025-02-18T04:16:28.219Z",
    "title": "Towards Data-Efficient Pretraining for Atomic Property Prediction",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/642b51385bf2355d02a23d15/bLvTbh56AkUmcmRst8mT3.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.11085.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "642b51385bf2355d02a23d15",
      "avatarUrl": "/avatars/87985347643b2647555f2453fa4d94fb.svg",
      "fullname": "Hasan Abed Al Kader Hammoud",
      "name": "hammh0a",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isMod": false,
      "followerCount": 4
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.11775",
      "authors": [
        {
          "_id": "67b4147f7721b4fe4d2bd466",
          "name": "Guangzhi Sun",
          "hidden": false
        },
        {
          "_id": "67b4147f7721b4fe4d2bd467",
          "name": "Yudong Yang",
          "hidden": false
        },
        {
          "_id": "67b4147f7721b4fe4d2bd468",
          "name": "Jimin Zhuang",
          "hidden": false
        },
        {
          "_id": "67b4147f7721b4fe4d2bd469",
          "name": "Changli Tang",
          "hidden": false
        },
        {
          "_id": "67b4147f7721b4fe4d2bd46a",
          "name": "Yixuan Li",
          "hidden": false
        },
        {
          "_id": "67b4147f7721b4fe4d2bd46b",
          "name": "Wei Li",
          "hidden": false
        },
        {
          "_id": "67b4147f7721b4fe4d2bd46c",
          "name": "Zejun MA",
          "hidden": false
        },
        {
          "_id": "67b4147f7721b4fe4d2bd46d",
          "name": "Chao Zhang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-17T13:07:40.000Z",
      "title": "video-SALMONN-o1: 강력한 이유를 강화한 비디오 오디오 대 언어 모델",
      "summary": "최근의 이유 계산 최적화의 진보는 대규모 언어 모델(LLMs)의 능력을 크게 향상시켰지만, 현재의 노력을 수학 문제 해결과 시각적인 그래픽 입력에 초점을 맞추며, 일반적인 비디오 이해의 광범위한 응용 분야에 주목하지 않습니다. 본 논문에서는 일반적인 비디오 이해 태스크에 대한 이유 계산을 강화한 첫 번째 오픈 소스 언어 모델을 제안합니다. 이를 video-SALMONN-o1으로 합니다. 이유 계산의 능력을 향상시키기 위해, 복잡한 음성 비디오 질문을 포함하는 단계별 해결 방법의 특징을 가진 이유 계산을 강화한 데이터 세트를 개발했습니다. 또한, 비교적 단계 선택을 활용한 과정 직접 선호 최적화(pDPO)를 제안하고, 다양한 입력에 적응 가능한 단계 수준 보상 모델링을 효율적으로 구현했습니다. 또한, 이유 계산을 강화한 비디오 이해 벤치마크인 RivaBench를 도입했습니다. 이는 스튜디오 코미디, 학술 연설, 합성 비디오 감지 등 비디오 이해의 스케너로 4,000개 이상의 고품질, 전문가가 편집된 질문 대답 쌍을 특징으로 합니다. video-SALMONN-o1은 다양한 비디오 이유 계산 벤치마크에서 LLaVA-OneVision의 기준에 대해 3-8%의 정확도 향상을 실현했습니다. 또한, pDPO는 RivaBench의 서브 객체 조정 모델에 대해 6-8%의 향상을 실현했습니다. 이유 계산의 향상으로 video-SALMONN-o1은 합성 비디오 감지의 0 shot 능력을 실현했습니다.",
      "upvotes": 1,
      "discussionId": "67b414827721b4fe4d2bd534"
    },
    "publishedAt": "2025-02-18T00:06:55.671Z",
    "title": "video-SALMONN-o1: Reasoning-enhanced Audio-visual Large Language Model",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.11775.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 6128
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.11098",
      "authors": [
        {
          "_id": "67b411e45e634139c0d86a1e",
          "name": "Zhao Wang",
          "hidden": false
        },
        {
          "_id": "67b411e45e634139c0d86a1f",
          "name": "Sota Moriyama",
          "hidden": false
        },
        {
          "_id": "67b411e45e634139c0d86a20",
          "name": "Wei-Yao Wang",
          "hidden": false
        },
        {
          "_id": "67b411e45e634139c0d86a21",
          "name": "Briti Gangopadhyay",
          "hidden": false
        },
        {
          "_id": "67b411e45e634139c0d86a22",
          "name": "Shingo Takamatsu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-16T12:26:58.000Z",
      "title": "구조적으로 이야기하고, 계층적으로 행동하는: LLM의 Collaboration Framework의 Multi-Agent System",
      "summary": "최근 LLM 기반의 효과자 시스템(LLM-MA)에서 기대할 수 있는 발전이 있을 수 있지만, 복잡한 작업에서 효과자 간의 통신과 개선에 대한 중대한 문제들이 남아 있습니다. 본 논문에서는, 복잡한 작업에서 효과적으로 의사소통을 위한 구조화된 통신 프로토콜과 부정적인 출력, 얼굴, 편견 등 문제 해결을 위한 계층적인 개선 시스템인 \"Talk Structurally, Act Hierarchically (TalkHier)\"라는 새로운 프레임워크를 제안합니다. TalkHier는 현재의 LLM 및 단일 효과자 기반 라인 워크(예: ReAct, GPT4o)에 대한 추론 스케일링 모델(OpenAI-o1), 오픈 소스 효과자 모델(예: AgentVerse)을 포함하여, 다양한 작업에서 효과적이고 적응적이고 협업적인 성능을 보여주는 최신 기술(SoTA)을 초과하여, LLM-MA 시스템의 새로운 기준을 설정할 수 있습니다. 이러한 결과를 통해, 더 효과적이고 적응적이고 협업적인 효과자 프레임워크의 개발에 길을 열어줍니다. 코드는, https://github.com/sony/talkhier에서 사용 가능합니다.",
      "upvotes": 1,
      "discussionId": "67b411e55e634139c0d86a4c"
    },
    "publishedAt": "2025-02-17T23:51:50.821Z",
    "title": "Talk Structurally, Act Hierarchically: A Collaborative Framework for LLM Multi-Agent Systems",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.11098.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 6128
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.10454",
      "authors": [
        {
          "_id": "67b40e56bffd44cc85976ecd",
          "name": "Yinghui Li",
          "hidden": false
        },
        {
          "_id": "67b40e56bffd44cc85976ece",
          "name": "Jiayi Kuang",
          "hidden": false
        },
        {
          "_id": "67b40e56bffd44cc85976ecf",
          "name": "Haojing Huang",
          "hidden": false
        },
        {
          "_id": "67b40e56bffd44cc85976ed0",
          "name": "Zhikun Xu",
          "hidden": false
        },
        {
          "_id": "67b40e56bffd44cc85976ed1",
          "name": "Xinnian Liang",
          "hidden": false
        },
        {
          "_id": "67b40e56bffd44cc85976ed2",
          "name": "Yi Yu",
          "hidden": false
        },
        {
          "_id": "67b40e56bffd44cc85976ed3",
          "name": "Wenlian Lu",
          "hidden": false
        },
        {
          "_id": "67b40e56bffd44cc85976ed4",
          "name": "Yangning Li",
          "hidden": false
        },
        {
          "_id": "67b40e56bffd44cc85976ed5",
          "name": "Xiaoyu Tan",
          "hidden": false
        },
        {
          "_id": "67b40e56bffd44cc85976ed6",
          "name": "Chao Qu",
          "hidden": false
        },
        {
          "_id": "67b40e56bffd44cc85976ed7",
          "name": "Ying Shen",
          "hidden": false
        },
        {
          "_id": "67b40e56bffd44cc85976ed8",
          "name": "Hai-Tao Zheng",
          "hidden": false
        },
        {
          "_id": "67b40e56bffd44cc85976ed9",
          "name": "Philip S. Yu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-12T02:01:10.000Z",
      "title": "하나의 예를 보여주면 많은 개념이 알려짐! 수학의 LLM에서 반례를 제시하는 개념적인 논리론",
      "summary": "수학의 대 언어 모델(LLMs)을 활용한 증명 생성은 LLMs 연구의 기본적인 토픽 중 하나입니다. 현재의 LLMs가 증명을 수행할 수 있는 능력은 훈련 과정에서 관련 증명 과정을 경험했는지에 크게 의존하고 있습니다. 이 의존성은 수학 정리와 관련된 개념에 대한 깊은 이해를 제한적으로 합니다. 인간이 일반적으로 사용하는 수학 교육에서 「예외를 이용한 증명」의 교육 방법이 있을 때, 우리 연구는 LLMs의 수학적 논리와 증명 능력을 예외를 사용하여 향상시키기 위한 것입니다. 구체적으로는, 우리는 직접 고품질의 대학 수준의 수학 벤치마크인 CounterMATH를 제작하여, LLMs가 수학적 논리를 수행하기 위해 예외를 제공하여 증명을 수행하고 이해도를 평가하는 것을 요구하고 있습니다. 또한, 우리는 데이터 과학 프레임워크를 개발하고, 모델의 진화에 대한 훈련 데이터를 자동으로 취득하기 위해 목표를 세고 있습니다. 확장된 실험과 상세한 분석은 CounterMATH가 어려운 것을 보여주고, OpenAI o1 등 LLMs가 예외를 사용한 증명 능력이 충분하지 않다는 것을 밝혀줍니다. 또한, 모델의 훈련 과정에서의 검토는 LLMs의 예외를 사용한 개념적 논리 능력의 강화가 그 수학적 기억력 전체의 향상에 중요하다는 것을 보여주고 있습니다. 우리 연구는 수학의 LLMs 커뮤니티에 새로운 시각을 제공하여 믿습니다.",
      "upvotes": 1,
      "discussionId": "67b40e57bffd44cc85976f0e"
    },
    "publishedAt": "2025-02-17T23:37:16.770Z",
    "title": "One Example Shown, Many Concepts Known! Counterexample-Driven Conceptual Reasoning in Mathematical LLMs",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.10454.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 6128
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.11574",
      "authors": [
        {
          "_id": "67b435c29e5685b308a8edac",
          "user": {
            "_id": "65bcbc01d6d0ffbceb8b2e6e",
            "avatarUrl": "/avatars/73edb2d6b7b11208439ac88b365079e8.svg",
            "isPro": false,
            "fullname": "Johan Boye",
            "user": "jboye",
            "type": "user"
          },
          "name": "Johan Boye",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-02-18T07:24:50.956Z",
          "hidden": false
        },
        {
          "_id": "67b435c29e5685b308a8edad",
          "user": {
            "_id": "6033e34a9aa44495c80dd043",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1614079701740-6033e34a9aa44495c80dd043.jpeg",
            "isPro": false,
            "fullname": "Birger Moell",
            "user": "birgermoell",
            "type": "user"
          },
          "name": "Birger Moell",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-18T09:30:49.328Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-17T09:07:32.000Z",
      "title": "대형 언어 모델과 수학적인 이유의 실패",
      "summary": "이 논문은 50개의 신규 건축된 중학교 수준의 문제를 사용하여, 대규모 언어 모델(LLMs)의 수학적 추론 능력을 조사하고 있습니다. 이전 연구에서는 답의 정확도를 중심으로 있었지만, 우리는 최종적인 답과 해답 단계를 엄격하게 분석하고 추론의 실패를 식별합니다. 최신 모델 8개(Mixtral, Llama, Gemini, GPT-4o, OpenAI의 o1 버전 및 기타 모델)을 평가하고, 새로운 모델(예를 들어 o3-mini, deepseek-r1)이 높은 정확도를 달성하는 것을 발견하지만, 모든 모델은 공간적 추론, 전략적 계획, 산술에서 오류를 나타내고, 때로는 잘못된 논리로 정확한 답을 생성합니다. 일반적인 실패 모드는 무용의 가정, 숫자 패턴의 과도한 의존성, 물리적 직관과 수학적 단계를 번역하는 어려움 등이 있습니다. 손으로의 분석은, 다단계 추론 및 현실 세계의 지식이 필요한 문제에 모델이 어려움을 보여주고, 광범위한 수학적 지식을 가지고 있는 것의 경우 이러한 문제를 대응하는 것이 어려운 것을 보여주고 있습니다. 우리의 결과를 통해, 이유 평가의 중요성을 강조하고, LLMs의 문제 해결 능력을 과도히 높게 평가하는 것을 경고하고 있습니다. 이 연구는 LLMs의 일반화 능력의 남아있는 부족점을 밝혀, 구조적인 이유 개선과 제한 처리에 대한 특정적인 향상의 필요성을 강조하고 있습니다.",
      "upvotes": 0,
      "discussionId": "67b435c29e5685b308a8edf1"
    },
    "publishedAt": "2025-02-18T02:26:18.856Z",
    "title": "Large Language Models and Mathematical Reasoning Failures",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.11574.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6033e34a9aa44495c80dd043",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1614079701740-6033e34a9aa44495c80dd043.jpeg",
      "fullname": "Birger Moell",
      "name": "birgermoell",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 36
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.11578",
      "authors": [
        {
          "_id": "67b435475bff5f34c1ebee1b",
          "user": {
            "_id": "6033e34a9aa44495c80dd043",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1614079701740-6033e34a9aa44495c80dd043.jpeg",
            "isPro": false,
            "fullname": "Birger Moell",
            "user": "birgermoell",
            "type": "user"
          },
          "name": "Birger Moell",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-18T09:30:52.639Z",
          "hidden": false
        },
        {
          "_id": "67b435475bff5f34c1ebee1c",
          "user": {
            "_id": "65bcbc01d6d0ffbceb8b2e6e",
            "avatarUrl": "/avatars/73edb2d6b7b11208439ac88b365079e8.svg",
            "isPro": false,
            "fullname": "Johan Boye",
            "user": "jboye",
            "type": "user"
          },
          "name": "Johan Boye",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-02-18T07:22:48.554Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-17T09:09:58.000Z",
      "title": "언어 복잡도 측정을 LLM의 성능 평가의 노이즈 신호 제로 프로кси로 사용합니다.",
      "summary": "대 언어 모델(LLMs)은 자연어 생성 분야에서 중요한 발전을 이루고 있지만, 높은 정확도를 요구하는 계산이나 구조적 분석을 수행하는 작업에서 많은 경우 문제가 있습니다. 본 논문에서는, LIX 읽기 난이도 지표와 평균 의존 거리(ADD)의 계산을 통해, 가장 최신의 LLMs의 언어 복잡도 측정 작업의 성능을 조사합니다. 스웨덴의 고등학교 및 대학 수준의 논문을 사용하여, 모델의 LIX 점수의 계산 및 의존 분석 능력을 평가하고, 기존의 기준과 비교합니다. 우리의 발견은, 모든 모델이 이러한 작업에서 어떤 능력을 보여주는지 보여주고, ChatGPT-o1-mini가 가장 일관된 높은 정확도를 달성하고, LIX 계산 및 의존 분석 모두에서 가장 높은 정확도를 달성합니다. 또한, 모델의 LIX 계산 정확도와, Massive Multitask Language Understanding(MMLU) 벤치마크의 전체적인 성능 사이에서 강한 유의적인 상관관계(-0.875, p 0.026, N=6)이 발견됩니다. 이러한 결과를 통해, 언어 복잡도 측정 능력이 LLMs의 일반적인 능력을 평가하는 데 있어 노이즈도 포함하는 0 shot의 대리인으로서의 역할을 수행함을 보여줍니다. 그리고, 광범위한 벤치마크 데이터 세트가 필요할 경우, 유용한 모델 평가 방법을 제공합니다.",
      "upvotes": 0,
      "discussionId": "67b435485bff5f34c1ebee52"
    },
    "publishedAt": "2025-02-18T02:23:29.869Z",
    "title": "Language Complexity Measurement as a Noisy Zero-Shot Proxy for Evaluating LLM Performance",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.11578.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6033e34a9aa44495c80dd043",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1614079701740-6033e34a9aa44495c80dd043.jpeg",
      "fullname": "Birger Moell",
      "name": "birgermoell",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 36
    },
    "isAuthorParticipating": true
  }
]