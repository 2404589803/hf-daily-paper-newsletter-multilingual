[
  {
    "paper": {
      "id": "2502.01506",
      "authors": [
        {
          "_id": "67a4214f12b90b15dc5a648e",
          "name": "Yuzhe Yang",
          "hidden": false
        },
        {
          "_id": "67a4214f12b90b15dc5a648f",
          "name": "Yifei Zhang",
          "hidden": false
        },
        {
          "_id": "67a4214f12b90b15dc5a6490",
          "name": "Minghao Wu",
          "hidden": false
        },
        {
          "_id": "67a4214f12b90b15dc5a6491",
          "name": "Kaidi Zhang",
          "hidden": false
        },
        {
          "_id": "67a4214f12b90b15dc5a6492",
          "name": "Yunmiao Zhang",
          "hidden": false
        },
        {
          "_id": "67a4214f12b90b15dc5a6493",
          "name": "Honghai Yu",
          "hidden": false
        },
        {
          "_id": "67a4214f12b90b15dc5a6494",
          "name": "Yan Hu",
          "hidden": false
        },
        {
          "_id": "67a4214f12b90b15dc5a6495",
          "name": "Benyou Wang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-03T16:39:48.000Z",
      "title": "트윈마크: 금융시장의 교환성 행동과 사회증명",
      "summary": "사회현상 연구는 오랜 기간 사회학의 중심적인 초점이었다. 규칙 기반의 Agent-Based Models(ABMs) 등 전통적인 모델링 접근법은 특히 행동경제학에서 강조되는 무리적인 요소를 포함하는 인간 행동의 다양성과 복잡성을 파악할 수 없었다. 최근, 대규모 언어 모델(LLM) 에이전트는 사회학에서 인간 행동의 모델링 및 역할을 위한 시뮬레이션 도구로 도입되어 사용되고 있다. 연구는 LLM가 인지 편향, 감정의 변화 및 기타 비리적인 영향을 고려할 수 있다는 점을 보여주고, 더 현실적인 사회경제 동력학의 시뮬레이션을 가능하게 하는 데 기여하고 있다. 본 논문에서는, TwinMarket라는 새로운 다 에이전트 프레임워크를 통해 LLM을 사용하여 사회경제 시스템의 시뮬레이션을 수행하는 방법을 소개한다. 특히, 개인 행동이 상호작용 및 피드백 구조를 통해 집단적인 동력학 및 현상을 발생시키는 것을 관찰한다. 시뮬레이션된 주식시장 환경에서 수행된 실험을 통해, 개인 행동이 집단 행동을 불러일으키고, 금융 파산, 불균형 등 현상을 발생시키는 것을 보여주고, 개인 결정과 집단적인 사회경제 패턴의 복잡한 상호작용에 대한 유익한 통찰을 제공한다.",
      "upvotes": 21,
      "discussionId": "67a4215212b90b15dc5a650a"
    },
    "publishedAt": "2025-02-05T21:44:36.248Z",
    "title": "TwinMarket: A Scalable Behavioral and Social Simulation for Financial Markets",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01506.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "643c047326f177a3e41627b6",
      "avatarUrl": "/avatars/ade75cebd049daf080ba80a80d516240.svg",
      "fullname": "Yifei Zhang",
      "name": "amstrongzyf",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.03373",
      "authors": [
        {
          "_id": "67a42c079a4fb11b11cc4f6f",
          "name": "Edward Yeo",
          "hidden": false
        },
        {
          "_id": "67a42c079a4fb11b11cc4f70",
          "name": "Yuxuan Tong",
          "hidden": false
        },
        {
          "_id": "67a42c079a4fb11b11cc4f71",
          "name": "Morry Niu",
          "hidden": false
        },
        {
          "_id": "67a42c079a4fb11b11cc4f72",
          "name": "Graham Neubig",
          "hidden": false
        },
        {
          "_id": "67a42c079a4fb11b11cc4f73",
          "name": "Xiang Yue",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-05T17:13:32.000Z",
      "title": "장인한 체인의 기억을 이해하는 LLM의 미지의 해독\n\n(注意：虽然要求不添加额外的文本，但为了确保翻译的准确性和专业性，我在这里提供了一个更自然的韩语表达。如果需要完全按照原文的格式，可以使用“장인한 체인의 기억을 이해하는 LLM의 미지의 해독”这一翻译。)",
      "summary": "スケーリングインフェリンス計算은 대규모 언어 모델(LLMs)의 추론에서 논리적 근거를 강화합니다. 긴 체인 오브 컨슈(CoTs)를 활용하여, 백트래킹이나 오류 수정 등 전략을 수행할 수 있습니다. 강화 학습(RL)은 이러한 능력의 개발에 중요한 방법 중 하나로 등장했지만, 긴 CoTs가 나타날 조건이 명확하지 않습니다. 또한, RL의 훈련은 신중한 설계 선택을 필요로 합니다. 본 연구에서는, 긴 CoTs의 논리적 근거의 구조를 체계적으로 조사하고, 모델이 긴 CoTs의 트래지렉트를 생성하는 원인을 특정합니다. 여러 가지 감독 학습(SFT)과 RL 실험을 통해, 다음 4가지 주요한 발견을 나타냅니다: 1. SFT는 엄밀하게 필요하지 않습니다が, 훈련을 단순화하고 효율을 높일 수 있습니다. 2. 논리적 근거의 능력은 훈련 계산량을 증가시키면서 발견되는데, 그러나 그 개발은 확실하지 않습니다. 따라서, 보상의 조정은 CoTs의 길이의 성장에 안정을 줄 때 중요합니다. 3. 보상의 스케일링은 RL에서 중요한 전망입니다. 보상 신호를 노이즈를 포함하는 웹 요약된 해결책을 활용하고, 필터링 구조를 사용함으로써 강력한 가능성이 나타납니다. 특히, 분포 외(OOD) 태스크의 경우 효과적입니다. 4. 오류 수정 등 기본적인 능력은 기본 모델에 고유하지만, 이러한 스킬을 효과적으로 장려하기 위해 복잡한 태스크에서 계산량이 크게 증가하고, 그 발견은 복잡한 접근이 필요합니다. 이러한 통찰은 LLMs의 긴 CoTs의 논리적 근거를 강화하는 데 필요한 훈련 전략의 최적화에 실질적인 가이드를 제공합니다. 코드는 다음 URL에서 공개됩니다: https://github.com/eddycmu/demystify-long-cot.",
      "upvotes": 15,
      "discussionId": "67a42c089a4fb11b11cc4fae"
    },
    "publishedAt": "2025-02-05T22:27:48.348Z",
    "title": "Demystifying Long Chain-of-Thought Reasoning in LLMs",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.03373.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "6230d750d93e84e233882dbc",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6230d750d93e84e233882dbc/4MGEekLW3oWzqeFWDWvIK.jpeg",
      "fullname": "Xiang Yue",
      "name": "yuexiang96",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 26
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.03387",
      "authors": [
        {
          "_id": "67a445ccbdd74b63b4e52a7d",
          "name": "Yixin Ye",
          "hidden": false
        },
        {
          "_id": "67a445ccbdd74b63b4e52a7e",
          "name": "Zhen Huang",
          "hidden": false
        },
        {
          "_id": "67a445ccbdd74b63b4e52a7f",
          "name": "Yang Xiao",
          "hidden": false
        },
        {
          "_id": "67a445ccbdd74b63b4e52a80",
          "name": "Ethan Chern",
          "hidden": false
        },
        {
          "_id": "67a445ccbdd74b63b4e52a81",
          "name": "Shijie Xia",
          "hidden": false
        },
        {
          "_id": "67a445ccbdd74b63b4e52a82",
          "name": "Pengfei Liu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-05T17:23:45.000Z",
      "title": "理由의 이유로 적은 편이 좋습니다.",
      "summary": "여기서 우리는 복잡한 이유론이 대규모 언어 모델에서 어떻게 나타나는지 이해하는 문제를 다루고 있습니다. 일반적인 인식은 복잡한 이유론 태스크는 복잡한 훈련 데이터(100,000개 이상)가 필요하지만, 우리는 주제적인 소수인 817개의 예시만으로 복잡한 수학적인 이유론 능력을 효과적으로 발휘할 수 있음을 보여줍니다. 구체적인 실험을 통해 제안한 모델 LIMO는 전례없는 수학적 이유론 성능을 나타냅니다. 817개의 훈련 데이터로, LIMO는 AIME에서 57.1%의 정확도, MATH에서 94.8%의 정확도를 달성했습니다. 이전의 SFT 기반 모델의 6.5%와 59.2%보다 성능이 향상되었으며, 이전 접근에서 필요했던 훈련 데이터의 1%만 사용했습니다. LIMO는 10가지 다양한 벤치마크에서 40.5%의 절대적인 향상을 달성했으며, 100배 이상 더 많은 데이터를 훈련한 모델을 초과하며, SFT는 기억화보다 일반화에 의존함을 의심합니다. 이러한 결과를 기반으로, 우리는 복잡한 이유론의 발견 임계치를 결정하는 두 가지 요인을 제시합니다: 1) 훈련 전 완전히 인코딩 된 모델의 지식의 기초의 완전성, 2) 훈련 후의 예의 유효성인 \"인식 템플릿\"이 모델이 어떻게 지식 기반을 사용하여 복잡한 이유론 태스크를 해결하는지 보여줍니다.",
      "upvotes": 9,
      "discussionId": "67a445cdbdd74b63b4e52af7"
    },
    "publishedAt": "2025-02-06T00:26:02.483Z",
    "title": "LIMO: Less is More for Reasoning",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.03387.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5956
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.02737",
      "authors": [
        {
          "_id": "67a446a9430e358f5d5ac4c3",
          "name": "Loubna Ben Allal",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4c4",
          "name": "Anton Lozhkov",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4c5",
          "name": "Elie Bakouch",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4c6",
          "name": "Gabriel Martín Blázquez",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4c7",
          "name": "Guilherme Penedo",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4c8",
          "name": "Lewis Tunstall",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4c9",
          "name": "Andrés Marafioti",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4ca",
          "name": "Hynek Kydlíček",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4cb",
          "name": "Agustín Piqueres Lajarín",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4cc",
          "name": "Vaibhav Srivastav",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4cd",
          "name": "Joshua Lochner",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4ce",
          "name": "Caleb Fahlgren",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4cf",
          "name": "Xuan-Son Nguyen",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4d0",
          "name": "Clémentine Fourrier",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4d1",
          "name": "Ben Burtenshaw",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4d2",
          "name": "Hugo Larcher",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4d3",
          "name": "Haojun Zhao",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4d4",
          "name": "Cyril Zakka",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4d5",
          "name": "Mathieu Morlon",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4d6",
          "name": "Colin Raffel",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4d7",
          "user": {
            "_id": "6284b359eac6d6ca13879514",
            "avatarUrl": "/avatars/2dcca0f0d21cbe1a54eedac759adc61c.svg",
            "isPro": false,
            "fullname": "evaluate-bot",
            "user": "evaluate-bot",
            "type": "user"
          },
          "name": "Leandro von Werra",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-02-06T05:20:41.925Z",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4d8",
          "name": "Thomas Wolf",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-04T21:43:16.000Z",
      "title": "スモルLM2: 스モル가 커지면 데이터센터의 훈련으로 작은 언어 모델을 학습합니다.",
      "summary": "이 논문에서는 \"SmolLM2\"라는 가장 선진적인 \"작은\" (170억 파라미터) 언어 모델의 개발을 기록하고 있습니다. SmolLM2는 네트워크 텍스트와 수학, 코드, 명령 데이터의 혼합된 다단계 학습 프로세스를 사용하여 약 11조 토큰의 데이터로 과적합을 수행하고 있습니다. 또한, 기존 데이터셋이 문제적으로 작거나 저품질일 경우, 새로운 특화된 데이터셋 (FineMath, Stack-Edu, SmolTalk)을 추가하고 있습니다. 데이터셋의 혼합률을 업데이트하기 위해 각 단계의 성능에 기반한 소규모 제거 시험 및 손동으로의 개선 프로세스를 수행하고 있습니다. 최종적으로, SmolLM2는 최근 다른 작은 LM (Qwen2.5-1.5B, Llama3.2-1B)을 초과하는 성능을 보여주고 있습니다. 향후 LM 개발 연구 및 작은 LM의 응용에 대한 연구를 촉진하기 위해, SmolLM2 및 이 프로젝트에서 준비한 모든 데이터셋을 공개합니다.",
      "upvotes": 9,
      "discussionId": "67a446a9430e358f5d5ac4f8"
    },
    "publishedAt": "2025-02-06T00:20:51.704Z",
    "title": "SmolLM2: When Smol Goes Big -- Data-Centric Training of a Small Language Model",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.02737.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5956
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.02339",
      "authors": [
        {
          "_id": "67a3262873bdaf626f1e9eab",
          "name": "Jinyang Wu",
          "hidden": false
        },
        {
          "_id": "67a3262873bdaf626f1e9eac",
          "name": "Mingkuan Feng",
          "hidden": false
        },
        {
          "_id": "67a3262873bdaf626f1e9ead",
          "name": "Shuai Zhang",
          "hidden": false
        },
        {
          "_id": "67a3262873bdaf626f1e9eae",
          "name": "Ruihan Jin",
          "hidden": false
        },
        {
          "_id": "67a3262873bdaf626f1e9eaf",
          "name": "Feihu Che",
          "hidden": false
        },
        {
          "_id": "67a3262873bdaf626f1e9eb0",
          "name": "Zengqi Wen",
          "hidden": false
        },
        {
          "_id": "67a3262873bdaf626f1e9eb1",
          "name": "Jianhua Tao",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-04T14:18:29.000Z",
      "title": "MCTS를 활용한 구조화된 사고를 이용한 다모델 논리 향상",
      "summary": "다형 대 언어 모델(MLLMs)은 놀라운 능력을 보여주고 있지만, 복잡한 시각적 추론에서 여전히 문제점이 있습니다. 최근의 노력은, OpenAI o1-like의 구조화된 사고를 명시적인 검색 구조나 교사가 지도한 련화에 의해 MLLMs의 추론을 향상시키려 있지만, 이러한 접근은 성능과 효율의 균형을 유지하는 것이 어려워, 다양한 데이터와 검색 공간에 중점을 두어 낮은 효율의 인풋 인젝트 추출과 데이터 사용에 한계가 있습니다. 이러한 문제를 해결하기 위해, 우리는 Monte Carlo Tree Search(MCTS)를 활용한 자동화된 구조화된 사고 패러다임인 AStar를 제안합니다. AStar는 제한된 데이터에서 MCTS를 통해 계층적 구조를 사용하여 고レ벨의 인지적 사고 패턴을 자동으로 도출합니다. 이러한 명시적인 패턴에 기반하여, 우리는 모델의 내부의 사고能力和 외부의 사고 가이드라인을 무간적으로 통합하는 유닛레이팅 추론 프레임워크를 설계합니다. 이 프레임워크는 최소한의 트리의 반복으로 효율적인 추론을 가능하게 합니다. 이 새로운 패러다임은 성능과 효율의 균형을 강하게 다루며, MathVerse 벤치마크에서 AStar의 효과를 보여주며, 54.0%의 상위 정확도를 달성하고, GPT-4o(50.2%)를 초과하는 동시에, 대규모 데이터와 계산 효율성을 유지했습니다.",
      "upvotes": 7,
      "discussionId": "67a3262973bdaf626f1e9edb"
    },
    "publishedAt": "2025-02-05T21:45:32.304Z",
    "title": "Boosting Multimodal Reasoning with MCTS-Automated Structured Thinking",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.02339.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6747de57f8cab58c22ec94a2",
      "avatarUrl": "/avatars/5bae0341862fac24564781c0fa32aac5.svg",
      "fullname": "Jinyang Wu",
      "name": "Jinyang23",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 4
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.01154",
      "authors": [
        {
          "_id": "67a4609af2e553c1d0da914d",
          "name": "Yu-Ling Hsu",
          "hidden": false
        },
        {
          "_id": "67a4609af2e553c1d0da914e",
          "name": "Hsuan Su",
          "hidden": false
        },
        {
          "_id": "67a4609af2e553c1d0da914f",
          "name": "Shang-Tse Chen",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-03T08:44:24.000Z",
      "title": "유일한 プロンプト를 이용한 제일 브레이크",
      "summary": "대 언어 모형(LLMs)은 최근에 급격한 발전을 거두고 다양한 응용 분야에 혁신적인 영향을 미치고 있으며, 편리성과 생산성을 크게 향상시켰습니다. 그러나 이러한 평가적 능력에 따라 윤리적 우려와 새로운 공격 유형, 예를 들어 젓가락 브레이킹(jailbreaking) 등이 나타났습니다. 프로ン퓰트 기술은 주로 개인적인 상황에서 적대적인 입력을 최적화하는 데 초점을 두고, 대규모 데이터 세트에 대응할 때 계산 비용이 증가합니다. 반면, 더 일반적인 설정에서 일반적인 공격자를 훈련하고未见의 태스크에도 대응할 수 있는 연구는 부족하며, 이를 조사하지 않습니다. 본 논문에서는, 일반적인 프로ン퓰트를 사용하여 LLMs를 젓가락 브레이킹하는 데 필요한 프로ン퓰트 기반의 방법을 소개합니다. 이를 방어를 위해 적용한 방법을 DUMP이라고 합니다. 실험 결과를 통해, 우리의 일반적인 프로ン퓰트를 최적화하는 방법은 기존 기술보다 뛰어난 것을 보여줍니다.",
      "upvotes": 3,
      "discussionId": "67a4609bf2e553c1d0da9181"
    },
    "publishedAt": "2025-02-06T02:11:41.374Z",
    "title": "Jailbreaking with Universal Multi-Prompts",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01154.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "608abf1272b50b02c4b02865",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1619708309549-608abf1272b50b02c4b02865.jpeg",
      "fullname": "Hsuan Su",
      "name": "jacksukk",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.01105",
      "authors": [
        {
          "_id": "67a45c85e73ad243c0b9529e",
          "name": "Yiren Song",
          "hidden": false
        },
        {
          "_id": "67a45c85e73ad243c0b9529f",
          "name": "Danze Chen",
          "hidden": false
        },
        {
          "_id": "67a45c85e73ad243c0b952a0",
          "user": {
            "_id": "63a55320ce5763e06f78519c",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1671779060549-noauth.jpeg",
            "isPro": false,
            "fullname": "Mike Shou",
            "user": "mikeshou",
            "type": "user"
          },
          "name": "Mike Zheng Shou",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-02-06T06:54:02.195Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-03T06:49:58.000Z",
      "title": "LayerTracer: 인지 대응 레이어 구조의 SVG 합성을 분기와 Transformer를 통해 구현합니다.",
      "summary": "컴퓨터에 의한 계층적 SVG의 생성은 현재의 방법들이 너무 단순화되어 단일 계층의 출력이나 최적화에 의한 모양의 불필요성으로 인해 어려워 여겨지고 있습니다. 우리는 새로운 순차적인 디자인 연산 데이터셋으로부터 디자이너의 계층적 SVG의 제작 과정을 학습하여 이 공백을 채우기 위해 LayerTracer를 제안합니다. 이 프레임워크는 분산 트랜스포머를 기반으로 합니다. 우리의 접근 방식은 두 단계로 구성되어 있습니다: 첫째, 텍스트 조건付き의 DiT는 인간의 디자인 작업 흐름을 모방하기 위해 다단계의 리스터저지화된 구조 계획서를 생성합니다. 둘째, 계층별로 벡터화와 패스 축소를 수행하여 깨끗한 편집 가능한 SVG를 생성합니다. 이미지의 벡터화 과정에서, 우리는 참조 이미지를 잠재 토큰으로 인코딩하여 구조적 정비성을 유지하면서 계층적인 재구성을 가이드하는 조건付き 분산 구조를 도입합니다. 분산 실험은 최적화 기반과 신경 기반 선형으로 생성 품질과 편집성 향상을 보여주고, AI가 생성한 벡터를 전문 디자이너의 디자인 인식과 일치시킬 수 있음을 증명했습니다.",
      "upvotes": 3,
      "discussionId": "67a45c8ae73ad243c0b953ea"
    },
    "publishedAt": "2025-02-06T01:55:37.207Z",
    "title": "LayerTracer: Cognitive-Aligned Layered SVG Synthesis via Diffusion Transformer",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01105.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64311a95034ecbefddd141ef",
      "avatarUrl": "/avatars/b6dc5ca373bedbaa368208517954c375.svg",
      "fullname": "Yiren Song",
      "name": "yiren98",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.01618",
      "authors": [
        {
          "_id": "67a438d26bb8caaab06f5a5e",
          "user": {
            "_id": "64c2abe8c43875b438efef25",
            "avatarUrl": "/avatars/6efda081f52cf56db2d29a5ec05cb557.svg",
            "isPro": false,
            "fullname": "isha",
            "user": "ishapuri-mit",
            "type": "user"
          },
          "name": "Isha Puri",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-02-06T04:21:39.202Z",
          "hidden": false
        },
        {
          "_id": "67a438d26bb8caaab06f5a5f",
          "name": "Shivchander Sudalairaj",
          "hidden": false
        },
        {
          "_id": "67a438d26bb8caaab06f5a60",
          "name": "Guangxuan Xu",
          "hidden": false
        },
        {
          "_id": "67a438d26bb8caaab06f5a61",
          "name": "Kai Xu",
          "hidden": false
        },
        {
          "_id": "67a438d26bb8caaab06f5a62",
          "name": "Akash Srivastava",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-03T18:50:50.000Z",
      "title": "粒子기반몬테카를로법을 이용한 LLM의 추론 시 스케일링에 대한 확률론적 추론 방법",
      "summary": "대 언어 모델(LLMs)는 모델 크기와 데이터의 확장으로 상당한 성능 향상을 달성했습니다. 그러나 최근의 증거에서 이러한 접근 방식의 효과가 감소하고, 추론 시간 계산량을 확대하는 것을 촉구하고 있습니다. 현재의 추론 시간 확대 방식은 일반적으로 보상 모델을 사용하여 태스크를 탐색 문제로 취급하고, 보상 모델의 근사 오류로 인한 보상 해킹에 취약한 경우가 있습니다. 본 논문에서는 추론 시간 확대를 확률론적 추론 태스크로 보고, 근사 가능성을 사용하는 상태 공간 모델의 상태 분포의 일반적인 집합을 탐색하는 샘플 기반 방식에 활용합니다. 이를 통해 모델의 모드를 직접 최적화하지 않습니다. 본 논문에서는 이 태스크에 입체 기반의 모ンテカル로法是 적용하고, 새로운 추론 시간 확대 접근 방식을 제안합니다. 실험 평가에 따라 결정론적 탐색과 비교하여 다양한 어려운 수학적 논리 태스크에서 4-16배의 확장율을 나타냅니다. 이 접근 방식에 의해 Qwen2.5-Math-1.5B-Instruct는 4회 로드아웃으로 GPT-4o의 정확도를 초과하고, Qwen2.5-Math-7B-Instruct는 32회 로드아웃으로 o1 수준의 정확도를 달성했습니다. 본 논문은 추론 시간 확대의 효과적인 방법을 제공하고, 확률론적 추론의 풍부한 문헌과 LLMs의 추론 시간 확대와의 연계를 통해 향후 연구에서 더욱 강건한 알고리즘의 개발에 기여합니다. 코드와 추가 정보는 https://probabilistic-inference-scaling.github.io에 제공됩니다.",
      "upvotes": 3,
      "discussionId": "67a438d36bb8caaab06f5a87"
    },
    "publishedAt": "2025-02-05T23:23:08.428Z",
    "title": "A Probabilistic Inference Approach to Inference-Time Scaling of LLMs using Particle-Based Monte Carlo Methods",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/648b3f3208c4a9d807a90a99/gwgJD14Bd0fdz7xpcHdHe.mp4",
      "https://cdn-uploads.huggingface.co/production/uploads/648b3f3208c4a9d807a90a99/KHcaqxZL3wiloAm7x-7nA.mp4"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01618.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "648b3f3208c4a9d807a90a99",
      "avatarUrl": "/avatars/03634b4e7f8afe9b589a2d7370e29960.svg",
      "fullname": "Akash Srivastava",
      "name": "akashsri",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 8
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.03275",
      "authors": [
        {
          "_id": "67a448b69ca42c642a723a7d",
          "name": "DiJia Su",
          "hidden": false
        },
        {
          "_id": "67a448b69ca42c642a723a7e",
          "name": "Hanlin Zhu",
          "hidden": false
        },
        {
          "_id": "67a448b69ca42c642a723a7f",
          "name": "Yingchen Xu",
          "hidden": false
        },
        {
          "_id": "67a448b69ca42c642a723a80",
          "name": "Jiantao Jiao",
          "hidden": false
        },
        {
          "_id": "67a448b69ca42c642a723a81",
          "name": "Yuandong Tian",
          "hidden": false
        },
        {
          "_id": "67a448b69ca42c642a723a82",
          "name": "Qinqing Zheng",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-05T15:33:00.000Z",
      "title": "토큰 조합: 잠재 토큰과 텍스트 토큰의 혼합으로 언어 모델의 논리적 논리 개선의 이유",
      "summary": "대 언어 모델（LLMs）는 chain-of-thought（CoT） 데이터에 훈련되어 있을 때, 단계별 생각 과정을 명확히 나타내어 논리적 논리와 계획에 특화된다. 그러나, 이는 많은 단어들이 문장의 연속성에 대한 핵심적인 논리적 정보로 기여하고, 이러한 입력의 처리는 복잡한 계산 리소스를 필요로 한다. 본 논문에서는 논리적 논리 처리의 하이브리드 표현을 제안하고, VQ-VAE로 생성된 잠재적인 이산 토큰을 사용하여 초기 논리적 논리 단계를 일부 추상화하고, 논리적 논리 처리의 길이를 크게 줄이는 것을 목표로 한다. 잠재적인 트래스 추상화의 사용은 두 가지 시나리오로 검토된다: 1) Keys-Finding Maze 문제의 모델의 시작부터의 훈련, 2) 이 하이브리드 데이터에 대한 LLMs의 미세 조정, 둘 다 논리적 및 수학적 논리 문제에 포함될 수 있다. 효과적인 학습을 촉진하기 위해, 잠재적인 토큰과 문맥 토큰을 랜덤으로 섞는 간단한 훈련 절차를 도입하고, 새로운 잠재적인 토큰에 빠르게 적응할 수 있도록 한다. 우리의 접근法是 다양한 벤치마크에서 일관된 베이스라인 방법과 일치하지 않고, 뛰어넘는다.",
      "upvotes": 2,
      "discussionId": "67a448b89ca42c642a723ac6"
    },
    "publishedAt": "2025-02-06T00:29:44.686Z",
    "title": "Token Assorted: Mixing Latent and Text Tokens for Improved Language Model Reasoning",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.03275.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5956
    },
    "isAuthorParticipating": false
  }
]