[
  {
    "paper": {
      "id": "2502.08910",
      "authors": [
        {
          "_id": "67aebd48225614bbe7f6f271",
          "user": {
            "_id": "62e622d08e0b2dc6707f8794",
            "avatarUrl": "/avatars/8c47b5c862f82d4258ba707c932f7f87.svg",
            "isPro": false,
            "fullname": "Heejun Lee",
            "user": "gmlwns5176",
            "type": "user"
          },
          "name": "Heejun Lee",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-14T08:01:15.423Z",
          "hidden": false
        },
        {
          "_id": "67aebd48225614bbe7f6f272",
          "user": {
            "_id": "646cae3093badbc8c2e891c7",
            "avatarUrl": "/avatars/4aae2aca70ea9dc58dd6f9f9b2be15e1.svg",
            "isPro": false,
            "fullname": "Geon Park",
            "user": "geonp",
            "type": "user"
          },
          "name": "Geon Park",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-14T08:01:12.988Z",
          "hidden": false
        },
        {
          "_id": "67aebd48225614bbe7f6f273",
          "name": "Jaduk Suh",
          "hidden": false
        },
        {
          "_id": "67aebd48225614bbe7f6f274",
          "name": "Sung Ju Hwang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-13T02:52:01.000Z",
      "title": "InfiniteHiP: 1 그래픽 포트럴에서 300만 토큰의 언어 모델 컨텍스트를 확장합니다.",
      "summary": "현대의 대규모 언어 모델(LLMs)에서, 매우 긴 컨텍스트 길이를 처리하는 데에는 추론 속도의 느려짐과 메모리 비용의 증가가 큰 문제로 알려져 있습니다. 또한, 기존의 많은 사전 학습된 LLMs는 원의 학습 시퀀스 길이를 초과한 경우 일반화가 되지 않는 경우가 있습니다. 긴 컨텍스트의 효율적인 실천적인 활용을 가능하게 하기 위해, InfiniteHiP 프레임워크를 소개합니다. InfiniteHiP는 새로운 모듈화 휴리스틱 토큰 프리닝 알고리즘을 통해, 관련없는 컨텍스트 토큰을 동적으로 제거함으로써 처리 속도를 가속화합니다. 우리 방법은 LLM의 내부의 注意 패턴에 따라, 다양한 RoPE 조정 방법을 선택적으로 적용하여 긴 시퀀스로의 일반화에 성공합니다. 또한, 추론 시 키 밸류 캐쉬를 호스트 메모리에 오프라인으로 하여, GPU 메모리 압박을 크게 줄입니다. 이렇게, InfiniteHiP는 1개의 L40s 48GB GPU로 300만 토큰의 처리를 가능하게 하고, 컨텍스트 정보의 영구적인 손실을 제거합니다. 우리 프레임워크는 100만 토큰의 컨텍스트에서의 注意의 디코딩 속도에 18.95배의 속도업을 달성하며, 추가 학습이 필요하지 않습니다. 우리 방법은 SGLang 프레임워크에 구현되어, 다양한 평가에 의해 효과성과 실천성을 입증합니다.",
      "upvotes": 43,
      "discussionId": "67aebd4a225614bbe7f6f2d6"
    },
    "publishedAt": "2025-02-13T22:57:03.709Z",
    "title": "InfiniteHiP: Extending Language Model Context Up to 3 Million Tokens on a Single GPU",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/646cae3093badbc8c2e891c7/upRSt7mdOUX5vJZTWKG8D.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.08910.png",
    "numComments": 3,
    "submittedBy": {
      "_id": "646cae3093badbc8c2e891c7",
      "avatarUrl": "/avatars/4aae2aca70ea9dc58dd6f9f9b2be15e1.svg",
      "fullname": "Geon Park",
      "name": "geonp",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.08690",
      "authors": [
        {
          "_id": "67aec0a203bf3301ec29ac39",
          "user": {
            "_id": "633e6f07309a99325095dd42",
            "avatarUrl": "/avatars/57b91a488ac1745b3c0509c04eb6ad93.svg",
            "isPro": false,
            "fullname": "Hoigi Seo",
            "user": "Agorium",
            "type": "user"
          },
          "name": "Hoigi Seo",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-14T08:01:10.420Z",
          "hidden": false
        },
        {
          "_id": "67aec0a203bf3301ec29ac3a",
          "name": "Wongi Jeong",
          "hidden": false
        },
        {
          "_id": "67aec0a203bf3301ec29ac3b",
          "name": "Jae-sun Seo",
          "hidden": false
        },
        {
          "_id": "67aec0a203bf3301ec29ac3c",
          "name": "Se Young Chun",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-12T15:03:26.000Z",
      "title": "スクリー：메모리 효과적인 텍스트 인코더 레이어 사용하지 않고 텍스트로부터 이미지 생성\n\n(Note: The translation is provided as requested, but it is important to note that the original text \"スクリー：メモリエフェクティブなテキストエンコーダーレイヤーをスキップして再利用するテキストから画像生成\" can be interpreted in two ways: 1) Skipping the memory-efficient text encoder layer and reusing the text for image generation, or 2) Reusing the text without using the memory-efficient text encoder layer for image generation. The translation provided here reflects the second interpretation.)",
      "summary": "대규모 맥락 인코더는 맥락 프로ン퓰트를 통해 고품질의 이미지를 생성하기 위해 텍스트를 이미지로 변환하는 (T2I) 확산 모델에서 특이한 성능을 보입니다. 노이즈 모듈은 여러 반복 단계를 필요로 하지만 맥락 인코더는 하나의 전파 과정을 통해 텍스트를 인코딩해야 합니다. 그러나 총 추론 시간과 부동 소수점 계산(FLOPs)에 대해 맥락 인코더는 노이즈 모듈보다 크게 메모리 사용량을 요구합니다. 이러한 불적절함을 해결하기 위해 우리는 T2I 확산 모델의 맥락 인코더에 특화된 간단하고 효과적인 축소 전략인 스키ッ프와 재사용 레이어(Skrr)를 제안합니다. Skrr은 트랜스포머 블록의 내부적 과도성을 활용하여 T2I 태스크에 맞는 특정 레이어를 선택적으로 스키ッ프하거나 재사용함으로써 메모리 소비량을 줄이고 성능을 희생하지 않도록 설계되었습니다. 확장된 실험에 따르면 Skrr은 높은 스패르스 레벨에서도 원래 모델과 비교하여 상대적으로 좋은 이미지 품질을 유지하며, 현재의 블록별로 축소 방법에 비해 뛰어납니다. 또한 Skrr은 FID, CLIP, DreamSim, GenEval 스코어 등 다양한 평가 지표에서 성능을 유지하면서 최선의 메모리 효율을 달성하고 있습니다.",
      "upvotes": 24,
      "discussionId": "67aec0a903bf3301ec29adf3"
    },
    "publishedAt": "2025-02-13T23:10:44.295Z",
    "title": "Skrr: Skip and Re-use Text Encoder Layers for Memory Efficient Text-to-Image Generation",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.08690.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "633e6f07309a99325095dd42",
      "avatarUrl": "/avatars/57b91a488ac1745b3c0509c04eb6ad93.svg",
      "fullname": "Hoigi Seo",
      "name": "Agorium",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.09604",
      "authors": [
        {
          "_id": "67aeac4f2d48d9bf7728334e",
          "user": {
            "_id": "5df84571da6d0311fd3d5407",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1650651305661-5df84571da6d0311fd3d5407.png",
            "isPro": false,
            "fullname": "Yung-Sung Chuang",
            "user": "voidism",
            "type": "user"
          },
          "name": "Yung-Sung Chuang",
          "status": "extracted_confirmed",
          "statusLastChangedAt": "2025-02-14T02:37:32.909Z",
          "hidden": false
        },
        {
          "_id": "67aeac4f2d48d9bf7728334f",
          "user": {
            "_id": "639aaf82a4c528850bba2bfe",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/639aaf82a4c528850bba2bfe/nn23r8bsNiOJzVUxAPfo7.png",
            "isPro": false,
            "fullname": "Benjamin Cohen-Wang",
            "user": "bencw",
            "type": "user"
          },
          "name": "Benjamin Cohen-Wang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-14T08:01:17.696Z",
          "hidden": false
        },
        {
          "_id": "67aeac4f2d48d9bf77283350",
          "name": "Shannon Zejiang Shen",
          "hidden": false
        },
        {
          "_id": "67aeac4f2d48d9bf77283351",
          "user": {
            "_id": "6351712b40dffad651f128c7",
            "avatarUrl": "/avatars/87708c86c1baef548ef556f5d32dca71.svg",
            "isPro": false,
            "fullname": "Zhaofeng Wu",
            "user": "ZhaofengWu",
            "type": "user"
          },
          "name": "Zhaofeng Wu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-14T08:01:19.691Z",
          "hidden": false
        },
        {
          "_id": "67aeac4f2d48d9bf77283352",
          "name": "Hu Xu",
          "hidden": false
        },
        {
          "_id": "67aeac4f2d48d9bf77283353",
          "name": "Xi Victoria Lin",
          "hidden": false
        },
        {
          "_id": "67aeac4f2d48d9bf77283354",
          "name": "James Glass",
          "hidden": false
        },
        {
          "_id": "67aeac4f2d48d9bf77283355",
          "name": "Shang-Wen Li",
          "hidden": false
        },
        {
          "_id": "67aeac4f2d48d9bf77283356",
          "name": "Wen-tau Yih",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-13T18:55:13.000Z",
      "title": "SelfCite: 자기의 서브젝트 조정에 의한 대규모 언어 모델에서의 맥락 책임 부여",
      "summary": "SelfCite는 생성된 응답의 맥락에 대한 고품질의 세밀한 문서 리뷰를 생성하기 위해 새로운 자동 훈련 방법론을 소개합니다. SelfCite는 고가의 노동비로 인한 비용에 대한 문제를 해결하기 위해 사용됩니다.",
      "upvotes": 19,
      "discussionId": "67aeac502d48d9bf77283380"
    },
    "publishedAt": "2025-02-13T21:42:37.926Z",
    "title": "SelfCite: Self-Supervised Alignment for Context Attribution in Large Language Models",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/5df84571da6d0311fd3d5407/YmJO6H2Wa0ZVw31qeHZi0.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.09604.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "5df84571da6d0311fd3d5407",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1650651305661-5df84571da6d0311fd3d5407.png",
      "fullname": "Yung-Sung Chuang",
      "name": "voidism",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 3
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.09620",
      "authors": [
        {
          "_id": "67aeec91b1bbfb68824df5d1",
          "user": {
            "_id": "6552f1ad5d55ccb20e9142a0",
            "avatarUrl": "/avatars/0e3e80cba64b5ae0bc5638694ac33dbf.svg",
            "isPro": false,
            "fullname": "Ivan Tang",
            "user": "IvanTang",
            "type": "user"
          },
          "name": "Yiwen Tang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-14T08:00:57.216Z",
          "hidden": false
        },
        {
          "_id": "67aeec91b1bbfb68824df5d2",
          "name": "Zoey Guo",
          "hidden": false
        },
        {
          "_id": "67aeec91b1bbfb68824df5d3",
          "name": "Zhuhao Wang",
          "hidden": false
        },
        {
          "_id": "67aeec91b1bbfb68824df5d4",
          "name": "Ray Zhang",
          "hidden": false
        },
        {
          "_id": "67aeec91b1bbfb68824df5d5",
          "name": "Qizhi Chen",
          "hidden": false
        },
        {
          "_id": "67aeec91b1bbfb68824df5d6",
          "name": "Junli Liu",
          "hidden": false
        },
        {
          "_id": "67aeec91b1bbfb68824df5d7",
          "user": {
            "_id": "64daecec888b7e9c400f59b5",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64daecec888b7e9c400f59b5/f4pfOfWk6jYJX-Nf2-qHn.png",
            "isPro": false,
            "fullname": "Delin Qu",
            "user": "delinqu",
            "type": "user"
          },
          "name": "Delin Qu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-14T08:00:55.263Z",
          "hidden": false
        },
        {
          "_id": "67aeec91b1bbfb68824df5d8",
          "name": "Zhigang Wang",
          "hidden": false
        },
        {
          "_id": "67aeec91b1bbfb68824df5d9",
          "name": "Dong Wang",
          "hidden": false
        },
        {
          "_id": "67aeec91b1bbfb68824df5da",
          "name": "Xuelong Li",
          "hidden": false
        },
        {
          "_id": "67aeec91b1bbfb68824df5db",
          "name": "Bin Zhao",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-13T18:59:45.000Z",
      "title": "3D LMMs의 Encoder-free 아키텍처에 대해 조사하여 딥러닝 모델의 잠재력을 발굴하기 위한 조사입니다.",
      "summary": "エンコーダー無しアーキテクチャ는 2차원 시각 영역에서 初期的に 봅니다が 3차원 이해 시나리오에서 어떻게 효과적으로 적용할 수 있는지는 여론이 있는 문제입니다. 본 논문에서는 3차원 대형 다형 모델(LMMs)에서 エンコーダー 무시 아키텍처의 가능성에 대해 처음으로 상세하게 조사합니다. 이러한 도전은 점 云의 변동적인 해상도에 적응할 수 없으며, エンコーダー로부터의 점 특징이 대규모 언어 모델(LLMs)의 문학적 요구에 부합하지 않습니다. 3차원 LMMs에서 エンコーダー를 제거하고 LLM이 3차원 エンコーダー의 역할을 수행하도록 할 수 있는 중요한 측면에서 1) 사전 훈련 단계에서 LLM을 내장한 문학적 エンコーディング 전략을 제안하고, 점 云의 자동 인식 손실의 효과를 조사합니다. 또한, 고レ벨의 문법을 추출하기 위해 통합 문법 손실을 소개합니다. 2) 명령 훈련 단계에서는 휴리스틱な 기오메트리 어그레시브 규칙 전략을 도입하고, LLM의 초기층에 적용하여 점 云의 지역적인 세부 사항을 강조합니다. 최종적으로, エンコーダー 무시 3차원 LMM의 첫 번째 예를 소개합니다. 우리 7B 모델은 현재의 최선 모델인 ShapeLLM-13B와 경쟁하며, 분류, 캡처, VQA 태스크에서 각각 55.0%, 50.92%, 42.7%를 달성했습니다. 우리의 결과를 통해 3차원 이해 영역에서 エンコーダー 무시 아키텍처가 エンコーダー 기준 아키텍처를 대체할 수 있는지 여부를 밝혀줍니다. 코드는 https://github.com/Ivan-Tang-3D/ENEL에서 릴리즈되었습니다.",
      "upvotes": 17,
      "discussionId": "67aeec92b1bbfb68824df61f"
    },
    "publishedAt": "2025-02-14T02:27:45.749Z",
    "title": "Exploring the Potential of Encoder-free Architectures in 3D LMMs",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.09620.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "647d9ab61a1fcad2fdbf2d3d",
      "avatarUrl": "/avatars/48c8aeae8979d2c87df8bde922437d62.svg",
      "fullname": "Ziyu Guo",
      "name": "ZiyuG",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isMod": false,
      "followerCount": 8
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.09082",
      "authors": [
        {
          "_id": "67aee90c208d299238758622",
          "name": "Xintao Wang",
          "hidden": false
        },
        {
          "_id": "67aee90c208d299238758623",
          "name": "Heng Wang",
          "hidden": false
        },
        {
          "_id": "67aee90c208d299238758624",
          "name": "Yifei Zhang",
          "hidden": false
        },
        {
          "_id": "67aee90c208d299238758625",
          "name": "Xinfeng Yuan",
          "hidden": false
        },
        {
          "_id": "67aee90c208d299238758626",
          "name": "Rui Xu",
          "hidden": false
        },
        {
          "_id": "67aee90c208d299238758627",
          "name": "Jen-tse Huang",
          "hidden": false
        },
        {
          "_id": "67aee90c208d299238758628",
          "name": "Siyu Yuan",
          "hidden": false
        },
        {
          "_id": "67aee90c208d299238758629",
          "name": "Haoran Guo",
          "hidden": false
        },
        {
          "_id": "67aee90c208d29923875862a",
          "name": "Jiangjie Chen",
          "hidden": false
        },
        {
          "_id": "67aee90c208d29923875862b",
          "name": "Wei Wang",
          "hidden": false
        },
        {
          "_id": "67aee90c208d29923875862c",
          "name": "Yanghua Xiao",
          "hidden": false
        },
        {
          "_id": "67aee90c208d29923875862d",
          "name": "Shuchang Zhou",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-13T08:55:24.000Z",
      "title": "CoSER: 기존의 역할을 기반으로 하는 LLM 기반의 Personalization의 협조",
      "summary": "RPLAs（Role-Playing Language Outputs）는 대규모 언어 모델（LLMs）의 잠재적인 응용 분야 중 하나로 등장했습니다. 그러나 RPLAs가 기존 캐릭터를 시뮬레이션하는 것은 사실적인 캐릭터 데이터 세트의 부족과 그 데이터를 활용하는 微妙한 평가 방법의 부족으로 인해 어려워졌습니다. 본 논문에서는 기존 캐릭터에 효과적인 RPLAs를 목표로 하는 고품질 데이터 세트, 오픈 모델, 평가 프로토콜을 제공합니다. CoSER 데이터 세트는 771권 유명 소설에서 17,966명의 캐릭터를 기록하고 있습니다. 이 데이터 세트는 현실적인 복잡성을 가진 실제적인 대화, 대화의 설정, 캐릭터의 경험 및 내부적인 기억 등 다양한 데이터 타입을 제공하고 있습니다. 연기 방법 기반으로, RPLA의 훈련과 평가에 이르는 연기 상태에 대한 보상을 도입했습니다. 이 데이터 세트를 기반으로 LLaMA-3.1 모델을 사용하여 발전된 오픈 RPLA LLMs인 CoSER 8B와 CoSER 70B를 개발했습니다. 확장된 실험은 CoSER 데이터 세트의 RPLA 훈련, 평가, 검색의 가치를 보여주었습니다. 또한 CoSER 70B는 우리 평가와 3개의 기존 벤치마크에서 가장 先端의 성능을 나타내었고, InCharacter 벤치마크에서 75.80%, LifeChoice 벤치마크에서 93.47%의 정확도를 달성했습니다.",
      "upvotes": 15,
      "discussionId": "67aee90f208d2992387586d1"
    },
    "publishedAt": "2025-02-14T02:50:35.108Z",
    "title": "CoSER: Coordinating LLM-Based Persona Simulation of Established Roles",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.09082.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64c7bf2c4524c2aea7eac0b3",
      "avatarUrl": "/avatars/03e432e05c0f711cfe32fc07f195e11e.svg",
      "fullname": "Xintao Wang",
      "name": "Neph0s",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.09056",
      "authors": [
        {
          "_id": "67aea8d7926b659c7e959bbc",
          "name": "Kunat Pipatanakul",
          "hidden": false
        },
        {
          "_id": "67aea8d7926b659c7e959bbd",
          "user": {
            "_id": "615313b0793ef66b3324da1f",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/615313b0793ef66b3324da1f/VyJniD3dxbV5a2CMgVVQ2.jpeg",
            "isPro": false,
            "fullname": "Pittawat Taveekitworachai",
            "user": "pittawat",
            "type": "user"
          },
          "name": "Pittawat Taveekitworachai",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-14T08:01:21.838Z",
          "hidden": false
        },
        {
          "_id": "67aea8d7926b659c7e959bbe",
          "name": "Potsawee Manakul",
          "hidden": false
        },
        {
          "_id": "67aea8d7926b659c7e959bbf",
          "name": "Kasima Tharnpipitchai",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-13T08:10:45.000Z",
      "title": "1일 동안 언어특화 모델을 논리 모델에 적용하기 위한 오픈 레시피: 모델 통합에 의한 적응",
      "summary": "이 논문은 DeepSeek R1와 같은 고급 논리력 기능을 언어 고유의 대 언어 모델(LLMs)에 통합하기 위한 데이터 선택 및 모델 통합 방법론에 대한 연구를 수행하며, 특히 태국의 LLM에 집중하고 있습니다. 우리의 목표는 언어 고유의 LLMs의 논리력 능력을 향상시키면서 그 목표 언어 능력을 유지하는 것입니다. DeepSeek R1은 논리력에 뛰어나지만, 주로 영어와 중국어와 같은 풍부한 리소스 언어에 이점을 얻습니다. 그러나 영어 중심의 훈련 데이터와 모델 최적화의 우위를 통해, 낮은 리소스 언어는 이러한 언어의 성능을 제한하고 있습니다. 이러한 제한은 언어 간의 코드 스위칭의 불신과 낮은 리소스 언어의 태스크에 대한 효과성 저하와 연결되어 있습니다. 반면, 지역적인 LLM 이니셔티브는 언어 고유의 LLM 개발을 통해 이러한 오류를 메꾸는 시도를 하고 있습니다. 우리는 공개된 데이터 세트와 $120의 계산 마나즈를 통해 언어 고유의 LLMs의 논리력 능력을 DeepSeek R1 수준으로 향상시킬 수 있음을 보여줍니다, 그 목표 언어 태스크의 성능을 유지하는 한입니다.",
      "upvotes": 15,
      "discussionId": "67aea8d8926b659c7e959bee"
    },
    "publishedAt": "2025-02-13T22:01:48.364Z",
    "title": "An Open Recipe: Adapting Language-Specific LLMs to a Reasoning Model in One Day via Model Merging",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.09056.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 6082
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.06608",
      "authors": [
        {
          "_id": "67aebe57f47426f753bc3b07",
          "name": "Yangguang Li",
          "hidden": false
        },
        {
          "_id": "67aebe57f47426f753bc3b08",
          "name": "Zi-Xin Zou",
          "hidden": false
        },
        {
          "_id": "67aebe57f47426f753bc3b09",
          "name": "Zexiang Liu",
          "hidden": false
        },
        {
          "_id": "67aebe57f47426f753bc3b0a",
          "name": "Dehu Wang",
          "hidden": false
        },
        {
          "_id": "67aebe57f47426f753bc3b0b",
          "name": "Yuan Liang",
          "hidden": false
        },
        {
          "_id": "67aebe57f47426f753bc3b0c",
          "name": "Zhipeng Yu",
          "hidden": false
        },
        {
          "_id": "67aebe57f47426f753bc3b0d",
          "name": "Xingchao Liu",
          "hidden": false
        },
        {
          "_id": "67aebe57f47426f753bc3b0e",
          "name": "Yuan-Chen Guo",
          "hidden": false
        },
        {
          "_id": "67aebe57f47426f753bc3b0f",
          "name": "Ding Liang",
          "hidden": false
        },
        {
          "_id": "67aebe57f47426f753bc3b10",
          "name": "Wanli Ouyang",
          "hidden": false
        },
        {
          "_id": "67aebe57f47426f753bc3b11",
          "name": "Yan-Pei Cao",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-10T16:07:54.000Z",
      "title": "TripoSG: 고품질의 3D 형상 합성을 수행하기 위해 큰 규모의 정규화 폼 모델을 사용합니다.",
      "summary": "최근의 확산手法의 발전은 이미지와 비디오의 생성에 있어 전례가ない 질을 달성하고, 생성 AI의 도입과 응용을 크게 가속화시켰습니다. 그러나 3D 형상 생성 기술은 아직 미달한 상태입니다. 3D 데이터의 규모, 3D 데이터 처리의 복잡성, 3D 분야의 첨단 기술의 부족이 제약을 가하고 있습니다. 현재의 3D 형상 생성 접근 방식은 출력 품질, 일반화 능력, 입력 조건과의 일치성에서 큰 도전을 받고 있습니다. 우리는 TripoSG, 새로운 스트리밍 라인화된 형상 확산 패러다임에 대해 제안합니다. 이는 입력 이미지에 대한 정확한 대응을 지닌 고품질의 3D 메쉬를 생성할 수 있습니다. 구체적인 내용은 다음과 같습니다: 1) 큰 규모의 정규화 플로트 라ン스 폼가저를 사용하여 3D 형상 생성, 다양한 고품질 데이터에 의한 훈련으로 가장 선진한 품질을 달성합니다. 2) SDF, 노르말, 에코나럴 손실을 조합한 통계적 모니터링 훈련 전략을 사용하여 3D VAE의 고품질 3D 재구성 성능을 실현합니다. 3) 200만건의 고품질 3D 샘플을 생성하는 데이터 처리 프로이플링을 제안하고, 3D 생성 모델의 훈련 시 데이터의 질과 양의 중요한 규칙을 명확히 합니다. 세부적인 실험을 통해 새로운 프레임워크의 각 구성 요소의 효과성을 검증했습니다. 이러한 부분의 연속적인 통합으로 TripoSG는 3D 형상 생성에 가장 선진적인 성능을 달성했습니다. 결과적으로, 고해상도 능력에 의한 디테일의 향상이 확인되고, 입력 이미지에 대한 특별한 품질을 보여주며, 다양한 이미지 스타일과 콘텐츠에서 3D 모델의 생성에 강력한 일반화 능력을 보여주며 다양성을 향상시킵니다. 3D 생성 분야의 발전과 혁신을 촉진하기 위해, 우리는 모델을 공개적으로 제공합니다.",
      "upvotes": 11,
      "discussionId": "67aebe5ef47426f753bc3d31"
    },
    "publishedAt": "2025-02-13T22:56:23.567Z",
    "title": "TripoSG: High-Fidelity 3D Shape Synthesis using Large-Scale Rectified Flow Models",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.06608.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64d71083a787c9bc7b9f1238",
      "avatarUrl": "/avatars/d0b0546dec7fc5792921154bec41385a.svg",
      "fullname": "YG",
      "name": "Lp256",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.09100",
      "authors": [
        {
          "_id": "67aeb0a3d58f4990b384d83e",
          "name": "Hanmeng Liu",
          "hidden": false
        },
        {
          "_id": "67aeb0a3d58f4990b384d83f",
          "name": "Zhizhang Fu",
          "hidden": false
        },
        {
          "_id": "67aeb0a3d58f4990b384d840",
          "name": "Mengru Ding",
          "hidden": false
        },
        {
          "_id": "67aeb0a3d58f4990b384d841",
          "user": {
            "_id": "62e47d1b6a82e063860c587e",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62e47d1b6a82e063860c587e/jvFt1caSZNWDQTYKZQ9K-.jpeg",
            "isPro": false,
            "fullname": "ruoxining",
            "user": "ruoxining",
            "type": "user"
          },
          "name": "Ruoxi Ning",
          "status": "extracted_confirmed",
          "statusLastChangedAt": "2025-02-14T06:28:50.414Z",
          "hidden": false
        },
        {
          "_id": "67aeb0a3d58f4990b384d842",
          "name": "Chaoli Zhang",
          "hidden": false
        },
        {
          "_id": "67aeb0a3d58f4990b384d843",
          "name": "Xiaozhang Liu",
          "hidden": false
        },
        {
          "_id": "67aeb0a3d58f4990b384d844",
          "name": "Yue Zhang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-13T09:19:14.000Z",
      "title": "대 언어 모형의 로지스틱 추론: 개요",
      "summary": "최근의 첨단 추론 모델（예：OpenAI o3, DeepSeek-R1）의 등장으로 인해, 대규모 언어 모델（LLMs）은 놀라운 추론 능력을 보여주고 있다. 그러나 이들이 엄격한 로지컬 추론을 수행하는 능력은 아직 해결되지 않은 문제로 남아있다. 이 조사에서는 LLMs의 로지컬 추론 분야의 최근 발전을 종합적으로 분석하고, AI 연구의 중요한 분야 중 하나인 이 분야의 논리 추론의 범위, 이론적 기초, 로지컬 추론의 실용성을 평가하기 위한 벤치마크를 설명하고 있다. 이러한 모델의 현재 능력은 추론적인, 추론적인, 추론적인, 어나로지컬의 추론 패러다임의 각 분야에 대해 분석되어 있으며, 추론 성능을 향상시키기 위한 전략（데이터 중심의 훈련, 강화학습, 디코딩 전략, 뉴로사이버드 접근법）을 평가하고 있다. 이 리뷰는 AI 시스템의 로지컬 추론을 강화하기 위한 발전 방향을 명확히 하고, 더 많은 탐색이 필요함을 강조하며 끝을 내고 있다.",
      "upvotes": 11,
      "discussionId": "67aeb0a4d58f4990b384d871"
    },
    "publishedAt": "2025-02-13T21:55:58.708Z",
    "title": "Logical Reasoning in Large Language Models: A Survey",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.09100.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 6082
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.09621",
      "authors": [
        {
          "_id": "67aee0229e69670f49533146",
          "user": {
            "_id": "6349214f8146350b3a4c5cdf",
            "avatarUrl": "/avatars/cfd24caac9a87efb528d0f4c375932bc.svg",
            "isPro": false,
            "fullname": "Dongzhi Jiang",
            "user": "CaraJ",
            "type": "user"
          },
          "name": "Dongzhi Jiang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-14T08:01:05.736Z",
          "hidden": false
        },
        {
          "_id": "67aee0229e69670f49533147",
          "name": "Renrui Zhang",
          "hidden": false
        },
        {
          "_id": "67aee0229e69670f49533148",
          "name": "Ziyu Guo",
          "hidden": false
        },
        {
          "_id": "67aee0229e69670f49533149",
          "name": "Yanwei Li",
          "hidden": false
        },
        {
          "_id": "67aee0229e69670f4953314a",
          "name": "Yu Qi",
          "hidden": false
        },
        {
          "_id": "67aee0229e69670f4953314b",
          "name": "Xinyan Chen",
          "hidden": false
        },
        {
          "_id": "67aee0229e69670f4953314c",
          "name": "Liuhui Wang",
          "hidden": false
        },
        {
          "_id": "67aee0229e69670f4953314d",
          "name": "Jianhan Jin",
          "hidden": false
        },
        {
          "_id": "67aee0229e69670f4953314e",
          "name": "Claire Guo",
          "hidden": false
        },
        {
          "_id": "67aee0229e69670f4953314f",
          "name": "Shen Yan",
          "hidden": false
        },
        {
          "_id": "67aee0229e69670f49533150",
          "name": "Bo Zhang",
          "hidden": false
        },
        {
          "_id": "67aee0229e69670f49533151",
          "name": "Chaoyou Fu",
          "hidden": false
        },
        {
          "_id": "67aee0229e69670f49533152",
          "name": "Peng Gao",
          "hidden": false
        },
        {
          "_id": "67aee0229e69670f49533153",
          "name": "Hongsheng Li",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-13T18:59:46.000Z",
      "title": "MME-CoT: 대규모 다모뎀 모델에서 Chain-of-Thought 평가에 있어서의 이유성, 강건성, 그리고 효율성",
      "summary": "Chain-of-Thought (CoT)를 사용하여 질문에 답하는 데 있어서 Large Language Models (LLMs)의 논리성능이 크게 향상되었지만, 이는 Large Multimodal Models (LMMs)에 미치는 영향에 대한 체계적인 평가와 세부적인 조사가 부족한 것으로 나타났다. 본 논문에서는 LMMs의 CoT 논리성능을 평가하기 위한 특수화된 벤치마크인 MME-CoT을 소개합니다. 이 벤치마크는 수학, 과학, OCR, 로직, 시간-공간, 일반적인 상황 등 6가지 분야를 포함하고 있으며, 이 분야에서 처음으로 전범위적인 연구이며, 논리성능의 질, 강건성, 효과성 등을 상세하게 평가하기 위해 3가지 새로운 메트릭을 도입한 상세한 평가 시트를 제안합니다. 고품질의 데이터와 특별한 평가 전략을 활용하여 최신의 LMMs에 대한 상세한 분석을 수행하고, 다음과 같은 중요한 지침을 제시했습니다: 1) 반성 기능을 가진 모델은 Kimi k1.5가 GPT-4o를 초과하여, 가장 높은 질의 결과를 보여주었습니다; 2) CoT 프로닝은 관찰력 중시된 작업에서 LMM의 성능을 저하시키고, 잠재적으로 유해한 과도한 생각의 행동을 보여줍니다; 3) 다른 한편, 고품질의 CoT에 비해 반성을 보이는 LMMs는 일반적인 응답 및 자기보정 단계에서 상당한 불적절성을 보여줍니다. MME-CoT은 LMMs의 다모달 논리성능의 발전을 촉진하는 기초로 활용될 수 있는 것입니다. 프로젝트 페이지: https://mmecot.github.io/",
      "upvotes": 10,
      "discussionId": "67aee0249e69670f495331d8"
    },
    "publishedAt": "2025-02-14T01:34:58.800Z",
    "title": "MME-CoT: Benchmarking Chain-of-Thought in Large Multimodal Models for Reasoning Quality, Robustness, and Efficiency",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.09621.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6349214f8146350b3a4c5cdf",
      "avatarUrl": "/avatars/cfd24caac9a87efb528d0f4c375932bc.svg",
      "fullname": "Dongzhi Jiang",
      "name": "CaraJ",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 6
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.09042",
      "authors": [
        {
          "_id": "67aea8c94d4cb38be4a40c55",
          "user": {
            "_id": "615313b0793ef66b3324da1f",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/615313b0793ef66b3324da1f/VyJniD3dxbV5a2CMgVVQ2.jpeg",
            "isPro": false,
            "fullname": "Pittawat Taveekitworachai",
            "user": "pittawat",
            "type": "user"
          },
          "name": "Pittawat Taveekitworachai",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-14T08:01:24.073Z",
          "hidden": false
        },
        {
          "_id": "67aea8c94d4cb38be4a40c56",
          "name": "Potsawee Manakul",
          "hidden": false
        },
        {
          "_id": "67aea8c94d4cb38be4a40c57",
          "name": "Kasima Tharnpipitchai",
          "hidden": false
        },
        {
          "_id": "67aea8c94d4cb38be4a40c58",
          "name": "Kunat Pipatanakul",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-13T07:55:54.000Z",
      "title": "태풍 T1: 개방형 타이 로직 모형",
      "summary": "이 논문에서는 Typhoon T1를 소개합니다. Typhoon T1는 개방된 태국어의 이유 모델 개발을 목표로 하는 개방된 시도입니다. 이유 모델은 대규모 언어 모델(LLMs) 위에 구축된 새로운 생성 모델 유형입니다. 이유 모델은 최종적인 답에 도달하기까지 긴 생각의 체인을 생성합니다. 이 접근 방식은 복잡한 태스크에 대한 성능 향상에 유용하다는 것이 조사되었습니다. 그러나 이러한 모델 개발에 대한 세부 사항은 제한되어 있으며, 특히 저 리소스 언어에서 이유 트레이스를 생성할 수 있는 이유 모델에 대한 세부 사항은 제한되어 있습니다. Typhoon T1은 규칙적인 미세 조정을 통해 오픈 데이터 세트를 활용하여 비용 효율적인 방법으로 이유 모델 개발을 자세히 조사하는 개방된 시도입니다. 이 논문에서는 합성 데이터의 생성과 훈련, 데이터 세트와 모델의 가중치에 대한 세부 사항을 공유합니다. 또한, 이유 트레이스를 생성할 수 있는 이유 모델 개발에 대한 얻은 피드백을 제공합니다. 우리는 이 개방된 시도가 이 분야의 발전에 연결될 수 있는 기반으로 간주하고 있습니다.",
      "upvotes": 10,
      "discussionId": "67aea8ca4d4cb38be4a40cab"
    },
    "publishedAt": "2025-02-14T01:29:44.233Z",
    "title": "Typhoon T1: An Open Thai Reasoning Model",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.09042.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "615313b0793ef66b3324da1f",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/615313b0793ef66b3324da1f/VyJniD3dxbV5a2CMgVVQ2.jpeg",
      "fullname": "Pittawat Taveekitworachai",
      "name": "pittawat",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.09560",
      "authors": [
        {
          "_id": "67aec4285b9801b819449b84",
          "name": "Rui Yang",
          "hidden": false
        },
        {
          "_id": "67aec4285b9801b819449b85",
          "user": {
            "_id": "6700b1f93381f2db06857fb5",
            "avatarUrl": "/avatars/c8b9ec7c00773c5a4055ba50de0c6b2f.svg",
            "isPro": false,
            "fullname": "Hanyang Chen",
            "user": "Hanyang81",
            "type": "user"
          },
          "name": "Hanyang Chen",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-14T08:01:08.365Z",
          "hidden": false
        },
        {
          "_id": "67aec4285b9801b819449b86",
          "name": "Junyu Zhang",
          "hidden": false
        },
        {
          "_id": "67aec4285b9801b819449b87",
          "name": "Mark Zhao",
          "hidden": false
        },
        {
          "_id": "67aec4285b9801b819449b88",
          "name": "Cheng Qian",
          "hidden": false
        },
        {
          "_id": "67aec4285b9801b819449b89",
          "name": "Kangrui Wang",
          "hidden": false
        },
        {
          "_id": "67aec4285b9801b819449b8a",
          "name": "Qineng Wang",
          "hidden": false
        },
        {
          "_id": "67aec4285b9801b819449b8b",
          "name": "Teja Venkat Koripella",
          "hidden": false
        },
        {
          "_id": "67aec4285b9801b819449b8c",
          "name": "Marziyeh Movahedi",
          "hidden": false
        },
        {
          "_id": "67aec4285b9801b819449b8d",
          "name": "Manling Li",
          "hidden": false
        },
        {
          "_id": "67aec4285b9801b819449b8e",
          "name": "Heng Ji",
          "hidden": false
        },
        {
          "_id": "67aec4285b9801b819449b8f",
          "name": "Huan Zhang",
          "hidden": false
        },
        {
          "_id": "67aec4285b9801b819449b90",
          "name": "Tong Zhang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-13T18:11:34.000Z",
      "title": "EmbodiedBench: 시각을 주도하는 Embodied 에이전트에 대한 다양한 언어 모델의 종합적인 벤치마크",
      "summary": "다모둠 대언어 모델(MLLMs)를 활용하여 구체화 에이전트를 생성하는 것은 현실적인 태스크를 해결하기 위한 잠재적인 방법입니다. 언어 중심의 구체화 에이전트는 상당한 주목을 받았지만, MLLM 기반의 구체화 에이전트는 평가 프레임워크의 결함이로 조사가 부족합니다. 이를 보완하기 위해, 여기는 EmbodiedBench를 소개합니다. EmbodiedBench는 시각을 주도한 구체화 에이전트의 평가를 위한 광범위한 벤치마크입니다. EmbodiedBench의 특징은 다음과 같습니다: 1) 4가지 환경에서 1,128개의 다양한 태스크; 고수준의 의미적 태스크(예: 가정)부터 저수준의 행동을 포함하는 태스크까지; 2) 常識적 추론, 복잡한 명령어 이해, 공간 인식, 시각 인식, 장기 계획 등 에이전트의 기본적인 능력을 평가하는 6가지의 세부집합입니다. 광범위한 실험을 통해, EmbodiedBench에서 13가지의 先進的な 프로프라이차와 오픈소스의 MLLMs를 평가했습니다. 이러한 결과는 MLLMs는 고수준의 태스크에서 뛰어난 성능을 보였지만, 저수준의 동작에 대해 어려움을 겪고 있습니다. 가장 좋은 모델인 GPT-4o는 평균적으로 그 지점에 28.9%입니다. EmbodiedBench는 현재의 문제를 명확히 해주는 동시에, MLLM 기반의 구체화 에이전트의 발전에 도움을 주는 유익한 보조 역할을 합니다. 코드는 https://embodiedbench.github.io에 액세스할 수 있습니다.",
      "upvotes": 9,
      "discussionId": "67aec42b5b9801b819449bf5"
    },
    "publishedAt": "2025-02-13T23:23:42.492Z",
    "title": "EmbodiedBench: Comprehensive Benchmarking Multi-modal Large Language Models for Vision-Driven Embodied Agents",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.09560.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64d45451c34a346181b130dd",
      "avatarUrl": "/avatars/9bb8205b889337df5d321539c9b5d69d.svg",
      "fullname": "Rui Yang",
      "name": "Ray2333",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 5
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.09601",
      "authors": [
        {
          "_id": "67aed173e6952709b47c0c5c",
          "name": "Xinyin Ma",
          "hidden": false
        },
        {
          "_id": "67aed173e6952709b47c0c5d",
          "name": "Guangnian Wan",
          "hidden": false
        },
        {
          "_id": "67aed173e6952709b47c0c5e",
          "name": "Runpeng Yu",
          "hidden": false
        },
        {
          "_id": "67aed173e6952709b47c0c5f",
          "name": "Gongfan Fang",
          "hidden": false
        },
        {
          "_id": "67aed173e6952709b47c0c60",
          "name": "Xinchao Wang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-13T18:52:36.000Z",
      "title": "CoT-Valve: 길이 가변성의 사고연쇄 조정",
      "summary": "Chain-of-Thought는 모델의 논리 능력이 크게 향상되지만, 긴 체인으로 인해 추론 비용도 크게 증가합니다. 간단한 일련의 작업에서 논리 경로가 쉽게 압축될 수 있는 것을 관찰하고, 어려운 일련의 작업에서는 어려움을 겪는 것을 발견했습니다. 한 모델에서 논리 경로의 길이를 유연하게 제어할 수 있는지 조사하고, 일련의 난이도에 따라 논리 모델의 추론 오버헤드를 줄일 가능성도 조사했습니다. 새로운 조정과 추론 전략을 CoT-Valve로 소개하고, 논리 체인의 길이를 변화시킬 수 있는 것을 목표로 합니다. 이를 실현하기 위해, 파라미터 공간의 방향을 특정하고, 그 조작으로 생성된 CoT의 길이를 효과적으로 제어할 수 있음을 보여주었습니다. 또한, 이 특성은 논리 체인의 압축에도 가치가 있는 것을 보여주었습니다. 같은 질문에서 긴 체인과 짧은 체인을 가진 데이터 세트를 구축하고, CoT-Valve의 두 확장 전략을 탐색했습니다: (1) 정확한 길이 압축 가능한 CoT 조정 방법, (2) 발전적인 체인 길이 압축 접근법. 실험에 따르면, CoT-Valve는 체인의 제어 가능度和 압축 가능도를 성공적으로 보여주고, Prompt 기반의 제어보다 더 좋은 성능을 나타냅니다. QwQ-32B-Preview에 이 방법을 적용하여, GSM8K에서 741 토큰을 225 토큰으로 줄였고, 성능의 하락은 약간이지만 (95.07%에서 94.92%) AIME에서 6827 토큰을 4629 토큰으로 줄였고, 한 개의 오답이 추가되었습니다.",
      "upvotes": 8,
      "discussionId": "67aed174e6952709b47c0ca1"
    },
    "publishedAt": "2025-02-14T00:16:30.034Z",
    "title": "CoT-Valve: Length-Compressible Chain-of-Thought Tuning",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.09601.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64396ebc21221ac7411852b3",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64396ebc21221ac7411852b3/SR0dC8N0bdj9tZFxYPpSf.jpeg",
      "fullname": "Xinyin Ma",
      "name": "horseee",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.09390",
      "authors": [
        {
          "_id": "67aef17da9f929ce0ca3e36b",
          "user": {
            "_id": "62d93cd728f9c86a4031562e",
            "avatarUrl": "/avatars/4619930d15512ec9b80b01c62e986217.svg",
            "isPro": false,
            "fullname": "Daniel Fleischer",
            "user": "danf",
            "type": "user"
          },
          "name": "Daniel Fleischer",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-02-14T07:32:14.019Z",
          "hidden": false
        },
        {
          "_id": "67aef17da9f929ce0ca3e36c",
          "name": "Moshe Berchansky",
          "hidden": false
        },
        {
          "_id": "67aef17da9f929ce0ca3e36d",
          "name": "Gad Markovits",
          "hidden": false
        },
        {
          "_id": "67aef17da9f929ce0ca3e36e",
          "name": "Moshe Wasserblat",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-13T15:07:20.000Z",
      "title": "SQuARE: 긴 문양 문장과 대 언어 모델의 Chain-of-Thought를 강화하는 논리 추론 엔진",
      "summary": "자연어 처리의 급속한 발전으로 인해, 대규모 언어 모델(LLMs)은 복잡한 논리론의 도전을 맡게 되었습니다. 연속적인 사고 방식의 Prompting 등 전통적인 방법들은 뛰어난 성과를 보였지만, 모델의 논리론 능력을 극대화하는 것은 어려웠고, 이러한 방법들은 지금까지의 한계였습니다. 본 연구에서는, 새로운 Prompting 방법인 SQuARE(Sequential Question Answering Reasoning Engine)을 소개합니다. 이 방법은 자신의 질문을 기반으로 논리론을 개선하는 것을 목표로 합니다. CoT 프레임워크를 기반으로, SQuARE는 모델을 여러 개의 보조언어 생성과 해결에 촉발시키는 것으로, 주요 질문에 대한 처리를 촉진하고 다양한 논리적인 주제에서 세부적인 검토를 추진합니다. 본 연구에서는 Llama 3과 GPT-4o 모델을 사용하여 다양한 질문응답 데이터셋에서 광범위한 평가를 수행하였으며, SQuARE가 전통적인 CoT Prompting과 기존의 수정과 응답의 방법과 비교하여 상당한 성능을 보였음을 보여주었습니다. 질문을 체계적으로 분해함으로써, SQuARE는 LLM의 논리론 태스크의 능력을 향상시킵니다. 코드는 https://github.com/IntelLabs/RAG-FiT/tree/square에 공개되어 있습니다.",
      "upvotes": 6,
      "discussionId": "67aef17ea9f929ce0ca3e3bf"
    },
    "publishedAt": "2025-02-14T02:35:53.718Z",
    "title": "SQuARE: Sequential Question Answering Reasoning Engine for Enhanced Chain-of-Thought in Large Language Models",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.09390.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "62d93cd728f9c86a4031562e",
      "avatarUrl": "/avatars/4619930d15512ec9b80b01c62e986217.svg",
      "fullname": "Daniel Fleischer",
      "name": "danf",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.09619",
      "authors": [
        {
          "_id": "67aef6212c36e4d8bd23740e",
          "name": "Jonathan Kahana",
          "hidden": false
        },
        {
          "_id": "67aef6212c36e4d8bd23740f",
          "name": "Or Nathan",
          "hidden": false
        },
        {
          "_id": "67aef6212c36e4d8bd237410",
          "name": "Eliahu Horwitz",
          "hidden": false
        },
        {
          "_id": "67aef6212c36e4d8bd237411",
          "name": "Yedid Hoshen",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-13T18:59:44.000Z",
      "title": "이 모델은 강아지를 가장 잘 인식할 수 있나요? 가중치에서 0샷 모델 검색",
      "summary": "プロテインモデル의 공개 수가 증가하는 가운데, 사용자가 필요로 하는 다양한 태스크에 대해, 사전 학습된 온라인 모델이 존재할 수 있는 것으로 추정할 수 있습니다. 그러나 현재의 모델 검색 방법은 기본적이고, 문서에 기반한 텍스트 기반의 검색으로, 사용자가 관련된 모델을 찾기가 어렵습니다. 본 논문에서는, 특정 개념(예: 「犬」)을 인식할 수 있는 분류 모델을 검색하기 위해, 모델 메타 데이터나 훈련 데이터를 참조하지 않는 한, ProbeLog라는 방법을 소개합니다. 이전의 프로브 메소드와 달리, ProbeLog는 각 모델의 출력 차원(logit)에 대해 고정된 입력(프로브)에 대한 응답을 관찰하여, 디스크라이버를 계산합니다. 이 방법은 logit 기반의 검색(\"이렇게의 로지ッ트를 찾아라\")와 0 shot, 텍스트 기반의 검색(\"犬에 대한 모든 로지ッ트를 찾아라\")를 지원합니다. 프로브 기반의 표현에는 모델을 통과시키는 비용이 높기 때문에, colaboration 필터링에 기반한 방법을 개발하여, 디스크라이버의 비용을 3배 줄였습니다. ProbeLog는 실세계적인, 분화된 검색 태스크에서 높은 검색 정확도를 달성하고, FULL SIZE의 디스크라이버에서도 scalable하다는 것을 보여주었습니다.",
      "upvotes": 4,
      "discussionId": "67aef6222c36e4d8bd237472"
    },
    "publishedAt": "2025-02-14T02:58:25.756Z",
    "title": "Can this Model Also Recognize Dogs? Zero-Shot Model Search from Weights",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.09619.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6465fd33dac127ac80f0b334",
      "avatarUrl": "/avatars/113f02c1b1f8d33d3487daa867afcd3f.svg",
      "fullname": "Jonathan Kahana",
      "name": "jonkahana",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.08946",
      "authors": [
        {
          "_id": "67aeb180cb3be2cefd46ed07",
          "name": "Mo Yu",
          "hidden": false
        },
        {
          "_id": "67aeb180cb3be2cefd46ed08",
          "name": "Lemao Liu",
          "hidden": false
        },
        {
          "_id": "67aeb180cb3be2cefd46ed09",
          "name": "Junjie Wu",
          "hidden": false
        },
        {
          "_id": "67aeb180cb3be2cefd46ed0a",
          "name": "Tsz Ting Chung",
          "hidden": false
        },
        {
          "_id": "67aeb180cb3be2cefd46ed0b",
          "name": "Shunchi Zhang",
          "hidden": false
        },
        {
          "_id": "67aeb180cb3be2cefd46ed0c",
          "name": "Jiangnan Li",
          "hidden": false
        },
        {
          "_id": "67aeb180cb3be2cefd46ed0d",
          "name": "Dit-Yan Yeung",
          "hidden": false
        },
        {
          "_id": "67aeb180cb3be2cefd46ed0e",
          "name": "Jie Zhou",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-13T04:00:03.000Z",
      "title": "LLM의 어깨에 스로딩 파워터：물리 개념 이해의 종합 평가",
      "summary": "시스템적으로, 광범위하게 묻힌 질의에 조사를 수행합니다: LLMs가 실제로 무엇을 말하는지에 대한 이해가 있는지? 이는 \"Stochastic Parrot\"라는 인식에 관련됩니다. 이에 대한 제안된 평가는, 거의 설계된 물리적인 개념 이해 작업에 대한 요약적인 평가입니다. 이 작업은, 추상적인 물리현상을 설명하는 그리드 포맷의 입력을 사용하여 기억 문제를 해결합니다. 그리드는, 그리드 월드에서 다른 추상적인 패턴과의 유사성, 핵심 현상, 적용 사례 등 이해 수준을 나타냅니다. 우리 작업에 대한 자세한 연구는 다음과 같습니다: (1) 가장 최신의 LLMs, GPT-4o, o1 및 Gemini 2.0 flash thinking은 인간보다 약 40% 떨어졌습니다; (2) Stochastic Parrot 현상은 LLMs에서 나타날 수 있는 것을 알 수 있으며, 그리드 포맷에서의 실패로, 자연어로 같은 개념을 설명하고 인식할 수 있습니다; (3) 우리 작업은 LLMs에 대한 고유한 어려움을 보여주고, 같은 포맷의 데이터에 대한 포맷 내 학습 및 미세 조정은 그 성능에 약간의 효과를 주지 않습니다.",
      "upvotes": 4,
      "discussionId": "67aeb181cb3be2cefd46ed4c"
    },
    "publishedAt": "2025-02-13T21:59:28.400Z",
    "title": "The Stochastic Parrot on LLM's Shoulder: A Summative Assessment of Physical Concept Understanding",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.08946.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 6082
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.08468",
      "authors": [
        {
          "_id": "67ad5f3fcad644864b4366ca",
          "user": {
            "_id": "66add675c7a575aa0e03d5f3",
            "avatarUrl": "/avatars/b72b18130664c1de197c1f8df371aa70.svg",
            "isPro": false,
            "fullname": "Haonan Chen",
            "user": "Haon-Chen",
            "type": "user"
          },
          "name": "Haonan Chen",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-13T08:21:55.329Z",
          "hidden": false
        },
        {
          "_id": "67ad5f3fcad644864b4366cb",
          "name": "Liang Wang",
          "hidden": false
        },
        {
          "_id": "67ad5f3fcad644864b4366cc",
          "name": "Nan Yang",
          "hidden": false
        },
        {
          "_id": "67ad5f3fcad644864b4366cd",
          "name": "Yutao Zhu",
          "hidden": false
        },
        {
          "_id": "67ad5f3fcad644864b4366ce",
          "name": "Ziliang Zhao",
          "hidden": false
        },
        {
          "_id": "67ad5f3fcad644864b4366cf",
          "name": "Furu Wei",
          "hidden": false
        },
        {
          "_id": "67ad5f3fcad644864b4366d0",
          "name": "Zhicheng Dou",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-12T15:03:33.000Z",
      "title": "고품질의 합성 데이터를 활용한 다 모델 다 언어 매핑 성능 향상",
      "summary": "다모달 엔베딩 모댈은 텍스트나 이미지 등 다양한 모델의 데이터를 일관된 표현 공간에 매핑하는 능력을 가지고 있으며, 중요한 관심을 모으고 있습니다. 그러나 제한된 라벨링된 다모달 데이터는 엔베딩의 성능을 저해하고 있습니다. 최근의 접근법은 이 문제를 해결하기 위해 데이터 합성을 사용하지만, 합성 데이터의 품질은 중요한 한계로 작용하고 있습니다. 본 논문에서는 고품질의 합성 모노모달 데이터를 위해 3가지 기준을 식별합니다. 첫째, 광범위한 범위는 생성된 데이터가 다양한 태스크와 모델의 조합을 덮고, 다운스트림 시나리오에 적용할 수 있도록 합니다. 둘째, 강한 크로스 모우드 aligment는 서로 다른 모델이 의미적으로 일관되게 유지되도록 보장합니다. 셋째, 고품질는 합성 데이터가 현실적인 세부 사항을 유지하고 신뢰도를 향상시키는 것을 보장합니다. 이러한 원칙에 따라 데이터셋은 다음과 같이 합성됩니다: 1) 광범위한 태스크, 모델의 조합, 언어를 커버하고, 2) 단일 패스의 다모달 대 언어 모댈의 깊은 사고 과정에 의해 생성되고, 3) 사진을 포함하여 정확한, 관련성 있는 텍스트를 선택하고, 자기 평가와 개선을 통해 신뢰도를 보장합니다. 이러한 고품질의 합성 데이터셋을 사용하여, 다모달 다언어 E5 모댈 mmE5를 훈련합니다. 확장된 실험에 따라, mmE5는 MMEB 벤치마크에서 가장 先端의 성능을 달성하고, XTD 벤치마크에서는 상위의 다언어 성능을 나타냅니다. 우리 코드, 데이터셋, 모댈은 https://github.com/haon-chen/mmE5에서 공개됩니다.",
      "upvotes": 3,
      "discussionId": "67ad5f3fcad644864b4366f5"
    },
    "publishedAt": "2025-02-13T23:32:15.420Z",
    "title": "mmE5: Improving Multimodal Multilingual Embeddings via High-quality Synthetic Data",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.08468.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "66add675c7a575aa0e03d5f3",
      "avatarUrl": "/avatars/b72b18130664c1de197c1f8df371aa70.svg",
      "fullname": "Haonan Chen",
      "name": "Haon-Chen",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 4
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.09614",
      "authors": [
        {
          "_id": "67af107d6bd28b8bd4e13c38",
          "name": "Xueyi Liu",
          "hidden": false
        },
        {
          "_id": "67af107d6bd28b8bd4e13c39",
          "name": "Jianibieke Adalibieke",
          "hidden": false
        },
        {
          "_id": "67af107d6bd28b8bd4e13c3a",
          "name": "Qianwei Han",
          "hidden": false
        },
        {
          "_id": "67af107d6bd28b8bd4e13c3b",
          "name": "Yuzhe Qin",
          "hidden": false
        },
        {
          "_id": "67af107d6bd28b8bd4e13c3c",
          "name": "Li Yi",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-13T18:59:13.000Z",
      "title": "DexTrack: Dexterous Neural Tracking Control for Generalizable Synthetic Operations",
      "summary": "우리는 인간 데이터에 기반한 적응적인 신경 트랙킹 제어러의 개발을 시도하고 있습니다. 이 제어러는 다양한 목적을 달성하기 위해 다양한 물체를 조작하는 적응적인 디텍션적인 로봇 손을 관리하는 것을 목표로 합니다. 이러한 제어러의 개발은 적응성, 일반화성 및 강건성의 필요로 인해 복잡합니다. 현재의 강화 학습과 경로 최적화 방법들은 특정 태스크의 보상이나 정밀한 시스템 모델에 의존하여 이러한 문제를 대응하지 않습니다. 우리는 큰 성공한 로봇 트랙킹을 보여주는 데 활용하여, 신경 제어러를 훈련하기 위해 인간 데이터와 로봇의 동작의 쌍을 구성하는 접근 방식을 소개합니다. 데이터 플로우를 사용하여 제어러의 성능을 향상시키고, 성공한 트랙킹 디스플레이의 수와 질을 반복적으로 향상시킵니다. 장치의 트랙킹 디스플레이를 사용하여 강화 학습과 학습된 디텍션적인 트랙킹 제어러를 동적 환경에서 제어러의 성능을 향상시킵니다. 또한, 고품질의 트랙킹 디스플레이를 얻기 위해 각 트라이마다 트랙킹을 개별적으로 최적화합니다. 호모피아 최적화는 체인 오브 시ン크스를 미모링하여 어려운 트라이 트랙킹 문제를 해결하고 디스플레이의 다양성을 증가시킵니다. 우리의 성공을 보여주기 위해, 일반화 가능한 신경 제어러를 훈련하고 시뮬레이션과 실세계에서 평가합니다. 우리의 방법은 최신 기준과 비교하여 10% 이상의 성공율을 향상시킵니다. 프로젝트의 웹 사이트는 https://meowuu7.github.io/DexTrack/ 로, 애니메이션의 결과를 표시합니다.",
      "upvotes": 1,
      "discussionId": "67af10806bd28b8bd4e13ce5"
    },
    "publishedAt": "2025-02-14T04:50:27.474Z",
    "title": "DexTrack: Towards Generalizable Neural Tracking Control for Dexterous Manipulation from Human References",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/65b8070ad49f4330ab0ca5f7/Ir-_GtsnqYII8yhrpJRD5.mp4"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.09614.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "65b8070ad49f4330ab0ca5f7",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/t4fI-3djMfgXCchU_xpjL.png",
      "fullname": "Xueyi Liu",
      "name": "xymeow7",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.05761",
      "authors": [
        {
          "_id": "67aee1cd7af05a21a72e793d",
          "user": {
            "_id": "648bf9afded4c3eb970eca85",
            "avatarUrl": "/avatars/a4b7b7fd6c1fca0eac85da7383f58361.svg",
            "isPro": false,
            "fullname": "enquan yang",
            "user": "enquan2022",
            "type": "user"
          },
          "name": "Enquan Yang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-14T08:01:03.483Z",
          "hidden": false
        },
        {
          "_id": "67aee1cd7af05a21a72e793e",
          "name": "Peng Xing",
          "hidden": false
        },
        {
          "_id": "67aee1cd7af05a21a72e793f",
          "name": "Hanyang Sun",
          "hidden": false
        },
        {
          "_id": "67aee1cd7af05a21a72e7940",
          "name": "Wenbo Guo",
          "hidden": false
        },
        {
          "_id": "67aee1cd7af05a21a72e7941",
          "name": "Yuanwei Ma",
          "hidden": false
        },
        {
          "_id": "67aee1cd7af05a21a72e7942",
          "name": "Zechao Li",
          "hidden": false
        },
        {
          "_id": "67aee1cd7af05a21a72e7943",
          "name": "Dan Zeng",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-09T03:37:54.000Z",
      "title": "3CAD: 3C 제품의 로컬 세계에서의 무제한 비라벨 데이터셋에서의 이상 검출",
      "summary": "工業의 이상검출은 MVTec-AD나 VisA와 같은 데이터셋을 활용하여 발전하고 있지만, 디피크 샘플의 수, 디피크의 종류, 현실적인 시나리오의 활용성에 제한이 존재합니다. 이러한 제약은 연구자들에게 더 높은 정확도를 달성하여 산업적 이상검출 성능을 향상시킬 것을 어렵게 합니다. 이러한 관점에서, 우리는 실제적인 3C 생산라인에서 얻을 수 있는 새로운 규모의 이상검출 데이터셋을 제안합니다. 특히 제안된 3CAD는 8종의 다른 제품부품을 포함하고 있으며, 27,039 장의 고해상도 이미지를 포함하고 있으며, 픽셀 수준의 이상들을 레이블付け하고 있습니다. 3CAD의 주요 특징은 이상 영역의 종류와 크기, 다수의 이상 종류, 또는 한 장의 이상 이미지에서 다수의 이상 영역과 이상 종류가 될 수 있다는 것입니다. 이는 3C 제품의 품질 관리에专用한 가장 큰 이상검출 데이터셋이며, 커뮤니티의 논의와 개발에 유용합니다. 또한 우리는 간단하고 효과적인 무레이블 검출 프레임워크를 소개합니다: Recovery Guidance를 활용한 Coarse-to-Fine 검출 패러다임 (CFRG). 작은 결함이 있는 이상 검출에 대해 제안된 CFRG는 heterogeneous distillation 모델을 사용하여 coarse localization을 수행하고, 그 후 segmentation 모델을 사용하여 fine localization을 수행합니다. 또한 정상 패턴을 더 잘捉えるために, recovery features를 검출 가이드에 적용します. 마지막으로, 3CAD 데이터셋에서 CFRG 프레임워크와 일반적인 이상 검출 방법의 결과를 보고하고, 강력한 경쟁력을 나타내며 이상 검출 분야의 개발을 촉진하는 높은 벤치마크를 제공합니다. 데이터와 코드는 아래 URL에서 사용 가능합니다: https://github.com/EnquanYang2022/3CAD.",
      "upvotes": 1,
      "discussionId": "67aee1cf7af05a21a72e799b"
    },
    "publishedAt": "2025-02-14T04:00:29.585Z",
    "title": "3CAD: A Large-Scale Real-World 3C Product Dataset for Unsupervised Anomaly",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/648bf9afded4c3eb970eca85/n-ufwo6Smo9TdMiTqKG8_.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.05761.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "648bf9afded4c3eb970eca85",
      "avatarUrl": "/avatars/a4b7b7fd6c1fca0eac85da7383f58361.svg",
      "fullname": "enquan yang",
      "name": "enquan2022",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  }
]