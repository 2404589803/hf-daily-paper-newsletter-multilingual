[
  {
    "paper": {
      "id": "2501.12380",
      "authors": [
        {
          "_id": "67906f432565fc5140d72dc3",
          "name": "Yilun Zhao",
          "hidden": false
        },
        {
          "_id": "67906f432565fc5140d72dc4",
          "name": "Lujing Xie",
          "hidden": false
        },
        {
          "_id": "67906f432565fc5140d72dc5",
          "name": "Haowei Zhang",
          "hidden": false
        },
        {
          "_id": "67906f432565fc5140d72dc6",
          "name": "Guo Gan",
          "hidden": false
        },
        {
          "_id": "67906f432565fc5140d72dc7",
          "name": "Yitao Long",
          "hidden": false
        },
        {
          "_id": "67906f432565fc5140d72dc8",
          "name": "Zhiyuan Hu",
          "hidden": false
        },
        {
          "_id": "67906f432565fc5140d72dc9",
          "name": "Tongyan Hu",
          "hidden": false
        },
        {
          "_id": "67906f432565fc5140d72dca",
          "name": "Weiyuan Chen",
          "hidden": false
        },
        {
          "_id": "67906f432565fc5140d72dcb",
          "name": "Chuhan Li",
          "hidden": false
        },
        {
          "_id": "67906f432565fc5140d72dcc",
          "name": "Junyang Song",
          "hidden": false
        },
        {
          "_id": "67906f432565fc5140d72dcd",
          "name": "Zhijian Xu",
          "hidden": false
        },
        {
          "_id": "67906f432565fc5140d72dce",
          "name": "Chengye Wang",
          "hidden": false
        },
        {
          "_id": "67906f432565fc5140d72dcf",
          "name": "Weifeng Pan",
          "hidden": false
        },
        {
          "_id": "67906f432565fc5140d72dd0",
          "name": "Ziyao Shangguan",
          "hidden": false
        },
        {
          "_id": "67906f432565fc5140d72dd1",
          "name": "Xiangru Tang",
          "hidden": false
        },
        {
          "_id": "67906f432565fc5140d72dd2",
          "name": "Zhenwen Liang",
          "hidden": false
        },
        {
          "_id": "67906f432565fc5140d72dd3",
          "name": "Yixin Liu",
          "hidden": false
        },
        {
          "_id": "67906f432565fc5140d72dd4",
          "name": "Chen Zhao",
          "hidden": false
        },
        {
          "_id": "67906f432565fc5140d72dd5",
          "name": "Arman Cohan",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-21T18:56:18.000Z",
      "title": "MMVU: 전문 수준의 다양한 학문 분야의 비디오 이해 평가",
      "summary": "MMVU는 비디오 이해를 평가하기 위한 전문 수준의 전문 분야별 벤치마크입니다. MMVU는 과학, 의료, 인문·사회과학, 공학의 4개 핵심 분야에 27개 주제를 포함하여 3,000개의 전문가 注記를 담은 질문을 제공합니다. 기존 벤치마크와 비교하여, MMVU는 3가지 주요의 발전을 특징으로 합니다. 첫 번째는 모델이 전문 분야의 지식을 적용하여 전문가 수준의 이유를 가진 전문 분야의 비디오를 분석하는 것을 목표로 하고, 현재 비디오 벤치마크에서 일반적인 시각 인식을 초과하고 있습니다. 두 번째는 각 예는 전문가로부터 시작하여 注記가 되어 있습니다. 데이터 품질 관리를 엄격히 수행하여 데이터 세트의 높은 품질을 보장하고 있습니다. 마지막으로, 각 예는 전문가가 작성한 이유와 관련된 분야의 지식을 추가하여 상세한 분석을 촉진합니다. MMVU에서 32개의 선도 모델을 평가했습니다. 최신 시스템 2 능력 모델인 o1과 Gemini 2.0 Flash Thinking은 평가된 모델 중 가장 높은 성능을 보입니다. 그러나 이들은 여전히 전문의의 지식을 완전히 대립하지 않습니다. 구체적인 오류 분석과 사례 연구를 통해, 향후 전문 수준의 지식밀집형 전문 분야의 비디오 이해의 발전에 대한 실질적인 이리언을 제공합니다.",
      "upvotes": 23,
      "discussionId": "67906f442565fc5140d72e4a"
    },
    "publishedAt": "2025-01-21T23:19:52.256Z",
    "title": "MMVU: Measuring Expert-Level Multi-Discipline Video Understanding",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.12380.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "62f662bcc58915315c4eccea",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62f662bcc58915315c4eccea/zOAQLONfMP88zr70sxHK-.jpeg",
      "fullname": "Yilun",
      "name": "yilunzhao",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isMod": false,
      "followerCount": 5
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.11425",
      "authors": [
        {
          "_id": "679080298ad1d8203a994f7f",
          "name": "Siyu Yuan",
          "hidden": false
        },
        {
          "_id": "679080298ad1d8203a994f80",
          "name": "Zehui Chen",
          "hidden": false
        },
        {
          "_id": "679080298ad1d8203a994f81",
          "name": "Zhiheng Xi",
          "hidden": false
        },
        {
          "_id": "679080298ad1d8203a994f82",
          "name": "Junjie Ye",
          "hidden": false
        },
        {
          "_id": "679080298ad1d8203a994f83",
          "name": "Zhengyin Du",
          "hidden": false
        },
        {
          "_id": "679080298ad1d8203a994f84",
          "name": "Jiecao Chen",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-20T11:46:04.000Z",
      "title": "Agent-R: 반복적인 자기 학습을 통해 표현하는 언어 모델 에이전트의 훈련",
      "summary": "대 언어 모델(LLMs)의 에이전트는 상호작용 환경에서 복잡한 태스크를 해결하기 위해 중요한 역할을 수행하고 있습니다. 현재의 연구는 주로 강력한 익스퍼트로부터의 행동 크로니킹을 통해 성능을 향상시키는 데 중점을 두고 있으며, 그러나 이러한 접근법은 실제 세계적인 애플리케이션에서 오류를 회복할 수 없기 때문에 실패합니다. 그러나 단계별 평가 데이터의 수집은 어려워 비용이 높습니다. 따라서, 자동적으로 동적으로 평가 데이터 세트를 구축하는 것이 에이전트의 지능적인 능력을 갖추게 하는 데 중요합니다. 본 연구에서는, 언어 에이전트가 즉시 반성할 수 있는 반복적 학습 프레임워크인 Agent-R을 제안합니다. 기존의 방법과 달리, Agent-R은 MCTS를 사용하여 오류의 경로를 통해 올바른 경로를 구축하는 훈련 데이터를 구축합니다. 에이전트의 반성 과정에서 주요한 문제점은 경로의 끝까지 기다리지 않고, 시간에 따라 수정하는 필요성입니다. 이에 대응하여, 모델을 가이드한 평가 구성 구조를 도입합니다: 카운터 모델은 실패한 경로의 첫 번째 오류 단계(현재 능력의 범위 내에서)를 식별합니다. 그로부터, 그 주변에 있는 정확한 경로를 분산하고, 부모 노드가 동일한 것입니다. 이 전략은 모델이 현재 정책에 기반하여 반성을 학습할 수 있게 하고, 더 효율적인 학습을 실현할 수 있습니다. 또한, 이러한 자동 개선 패러다임의 scalability를 탐구하기 위해, 오류 수정 능력과 평가 데이터 세트 구축의 반복적 최적화를 조사합니다. 우리의 조사 결과는, Agent-R이 모델의 오류 회복 능력을 지속적으로 향상시키고, 시간에 따른 오류 수정을 가능하게 합니다. 3개의 상호작용 환경에서의 실험은, Agent-R이 에이전트를 갖게 되면 오류를 수정하는 데 효과적으로 작동하며, 기준 방법보다 높은 성능을 달성했습니다(+5.59%)",
      "upvotes": 13,
      "discussionId": "6790802b8ad1d8203a994fc7"
    },
    "publishedAt": "2025-01-22T00:20:57.292Z",
    "title": "Agent-R: Training Language Model Agents to Reflect via Iterative Self-Training",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.11425.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5732
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.12273",
      "authors": [
        {
          "_id": "67906c674932687e24e0cc08",
          "name": "Maosong Cao",
          "hidden": false
        },
        {
          "_id": "67906c674932687e24e0cc09",
          "name": "Taolin Zhang",
          "hidden": false
        },
        {
          "_id": "67906c674932687e24e0cc0a",
          "name": "Mo Li",
          "hidden": false
        },
        {
          "_id": "67906c674932687e24e0cc0b",
          "name": "Chuyu Zhang",
          "hidden": false
        },
        {
          "_id": "67906c674932687e24e0cc0c",
          "name": "Yunxin Liu",
          "hidden": false
        },
        {
          "_id": "67906c674932687e24e0cc0d",
          "name": "Haodong Duan",
          "hidden": false
        },
        {
          "_id": "67906c674932687e24e0cc0e",
          "name": "Songyang Zhang",
          "hidden": false
        },
        {
          "_id": "67906c674932687e24e0cc0f",
          "name": "Kai Chen",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-21T16:44:12.000Z",
      "title": "코ンドール: 지식을 활용한 데이터 합성 및 편집에 의한 LLM의 성능 향상",
      "summary": "Supervised Fine-Tuning (SFT) 데이터의 품질은 Large Language Models (LLMs)의 대화 능력 향상에 중요한 역할을 합니다. 그러나 LLMs가 발전하면서, 고품질의 인간 Annotation을 받은 SFT 데이터의 활용성이 중요한 한계로 되어, 합성 데이터의 활용에 더욱 강한 의존성을 갖게 되었습니다. 본 논문에서는, World Knowledge Tree와 Self-Reflection Refinement을 결합한 새로운 2단계 합성 데이터 생성 프레임워크 Condor을 소개합니다. 이 프레임워크는 Scalable하게 고품질의 SFT 데이터를 생성하는 것을 목표로 합니다. 실험 결과를 통해, Condor에서 생성된 20K 샘플을 기반 모델에 적용한 경우, 극히 우수한 성능을 나타내며, 같은 모델과 비교하여 상위에 서는 것을 확인합니다. Condor의 추가적인 개선 단계는 LLMs의 다양한 규모(최대 72B)에서 반복적인 자기 개선을 가능하게 하며, 우리의 접근 방식의 효과에 입증합니다. 또한 합성 데이터의 Scalability에 대한 조사에 따르면, 학습 후 성능 향상에 있어 큰 개발 가능성이 있으며, 향후 연구에 희망스러운 길을 열어줍니다.",
      "upvotes": 7,
      "discussionId": "67906c684932687e24e0cc61"
    },
    "publishedAt": "2025-01-21T22:56:36.701Z",
    "title": "Condor: Enhance LLM Alignment with Knowledge-Driven Data Synthesis and Refinement",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.12273.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "630716d11801ecc7d2595021",
      "avatarUrl": "/avatars/2d36a880ce4a3cf7efc5ff3987dbeaf3.svg",
      "fullname": "Songyang Zhang",
      "name": "zsytony",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 14
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.11733",
      "authors": [
        {
          "_id": "6790791b203b95acf96ebf45",
          "user": {
            "_id": "628d7265db4cd1d1717c884f",
            "avatarUrl": "/avatars/dff2a3dd10d84b4a73fa486402de7219.svg",
            "isPro": false,
            "fullname": "Zhenhailong Wang",
            "user": "mikewang",
            "type": "user"
          },
          "name": "Zhenhailong Wang",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-01-22T04:50:40.468Z",
          "hidden": false
        },
        {
          "_id": "6790791b203b95acf96ebf46",
          "name": "Haiyang Xu",
          "hidden": false
        },
        {
          "_id": "6790791b203b95acf96ebf47",
          "name": "Junyang Wang",
          "hidden": false
        },
        {
          "_id": "6790791b203b95acf96ebf48",
          "name": "Xi Zhang",
          "hidden": false
        },
        {
          "_id": "6790791b203b95acf96ebf49",
          "name": "Ming Yan",
          "hidden": false
        },
        {
          "_id": "6790791b203b95acf96ebf4a",
          "name": "Ji Zhang",
          "hidden": false
        },
        {
          "_id": "6790791b203b95acf96ebf4b",
          "name": "Fei Huang",
          "hidden": false
        },
        {
          "_id": "6790791b203b95acf96ebf4c",
          "name": "Heng Ji",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-20T20:35:46.000Z",
      "title": "모바일-에이전트-E: 복잡한 태스크를 위한 자동화 모바일 보조자",
      "summary": "스마트폰은 현대 생활의 필수 요소로 자리잡았지만, 복잡한 작업을 수행할 때 때로는 불만을 느끼기도 합니다. 최근, 대규모 다모달 모둔 모델(LMM) 기반의 모바일 에이전트의 발전은 모바일 환경에서 인식과 행동을 가능하게 한 것으로 나타났습니다. 그러나 현재의 접근 방식은 다음과 같은 한계를 가지고 있습니다: 현실적인 사람들의 필요를 충족하지 못하며, 논리적인 장기적인 작업을 처리하기 어렵고, 이전 경험을 통해 학습하여 개선하는 구조가 없기 때문입니다. 이러한 문제를 해결하기 위해, Mobile-Agent-E라는 과거의 경험을 통해 자기 진화 가능한 휴리스틱な 다 에이전트 프레임워크를 소개합니다. 휴리스틱이란, 고 수준의 계획과 저 수준의 행동 실행을 명시적으로 구분하는 것입니다. 이 프레임워크는 복잡한 작업을 차례대로 분해하고 전체적인 계획을 결정하는 Manager와 Perceptor, Operator, Action Reflector, Notetaker 등 4가지 부하 에이전트로 구성되어 있습니다. Perceptor는 세부적인 시각 인식, Operator는 즉시의 행동 실행, Action Reflector는 오류 확인, Notetaker는 정보의 수집을 담당합니다. Mobile-Agent-E는 새로운 자기 진화 모듈을 도입하여, 이 모듈은 이전 작업에서 얻은 일반적인 지침과 교훈, 특정 서브루틴에 적합한 재사용 가능한 원자 연산의 목록으로 구성됩니다. Tips와 Shortcuts의 도입으로, 성능과 효율의 지속적인 개선이 가능합니다. 또한, Mobile-Eval-E라는 새로운 벤치마크도 소개되며, 복잡한 모바일 작업 처리 시 필요한 장기적인 작업과 여러 앱 간의 상호작용을 포함합니다. 실험 결과는, Mobile-Agent-E는 3가지의 기본 모델 백본을 통해, 이전의 최선 접근 방식보다 22%의 절대적인 향상을 달성한 것으로 나타납니다. 프로젝트 페이지는 https://x-plug.github.io/MobileAgent에 있습니다.",
      "upvotes": 5,
      "discussionId": "67907920203b95acf96ec126"
    },
    "publishedAt": "2025-01-22T00:17:48.799Z",
    "title": "Mobile-Agent-E: Self-Evolving Mobile Assistant for Complex Tasks",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.11733.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "645b10e80c73ea27d13f7aca",
      "avatarUrl": "/avatars/95e565306472a15067440b5b43e07a6f.svg",
      "fullname": "xuhaiyang",
      "name": "xhyandwyy",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.10687",
      "authors": [
        {
          "_id": "6790856e3b0a6384a4117d0e",
          "name": "Linrui Tian",
          "hidden": false
        },
        {
          "_id": "6790856e3b0a6384a4117d0f",
          "name": "Siqi Hu",
          "hidden": false
        },
        {
          "_id": "6790856e3b0a6384a4117d10",
          "name": "Qi Wang",
          "hidden": false
        },
        {
          "_id": "6790856e3b0a6384a4117d11",
          "name": "Bang Zhang",
          "hidden": false
        },
        {
          "_id": "6790856e3b0a6384a4117d12",
          "name": "Liefeng Bo",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-18T07:51:29.000Z",
      "title": "EMO2: 엔드エフェク터러더뷰드리브오디オ가동아바타비디오생성",
      "summary": "이 논문에서는 새로운 음성 주도 테이블 헤드 기법을 제안합니다. 이 기법은 고품질의 표정과 손의 손짓을 동시에 생성할 수 있습니다. 기존 기법은 전체 또는 절반의 자세를 생성하는 데 초점을 두고 있었지만, 우리는 음성 특징과 전체의 손짓과의 약한 대응 관계를 주요한 한계로 보고, 이를 해결하기 위해 작업을 2단계적인 프로세스로 재 정의했습니다. 첫 번째 단계에서는 음성 입력으로부터 직접 손의 자세를 생성하고, 음성 신호와 손의 움직임 사이의 강한 연관성을 활용합니다. 두 번째 단계에서는 생성된 손의 자세를 포함하여 분산 모델을 사용하여 동영상 프레임을 합성하고, 현실적인 표정과 신체의 움직임을 생성합니다. 실험 결과를 통해 제안된 기법이 가장 선진적인 기법(CyberHost, Vlogger)과 비교하여 시각적 품질과 동기 정확도에서도 우수합니다. 이 연구는 음성 주도 조작 생성에 새로운 시각을 제공하고, 표현적이고 자연스러운 테이블 헤드 애니메이션의 제작에 강력한 프레임워크를 제공합니다.",
      "upvotes": 3,
      "discussionId": "679085813b0a6384a41183f1"
    },
    "publishedAt": "2025-01-22T00:49:10.316Z",
    "title": "EMO2: End-Effector Guided Audio-Driven Avatar Video Generation",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.10687.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "65df1f1ee98700500d4c289c",
      "avatarUrl": "/avatars/be11bf61465df29ac997cc0fedad1cb9.svg",
      "fullname": "qi wang",
      "name": "lucaskingjade",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.12326",
      "authors": [
        {
          "_id": "679078f902b4d94b0f2347c1",
          "name": "Yujia Qin",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347c2",
          "name": "Yining Ye",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347c3",
          "name": "Junjie Fang",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347c4",
          "name": "Haoming Wang",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347c5",
          "name": "Shihao Liang",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347c6",
          "name": "Shizuo Tian",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347c7",
          "name": "Junda Zhang",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347c8",
          "name": "Jiahao Li",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347c9",
          "name": "Yunxin Li",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347ca",
          "name": "Shijue Huang",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347cb",
          "name": "Wanjun Zhong",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347cc",
          "name": "Kuanye Li",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347cd",
          "name": "Jiale Yang",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347ce",
          "name": "Yu Miao",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347cf",
          "name": "Woyu Lin",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347d0",
          "name": "Longxiang Liu",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347d1",
          "name": "Xu Jiang",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347d2",
          "name": "Qianli Ma",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347d3",
          "name": "Jingyu Li",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347d4",
          "name": "Xiaojun Xiao",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347d5",
          "name": "Kai Cai",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347d6",
          "name": "Chuang Li",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347d7",
          "name": "Yaowei Zheng",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347d8",
          "name": "Chaolin Jin",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347d9",
          "name": "Chen Li",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347da",
          "name": "Xiao Zhou",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347db",
          "name": "Minchao Wang",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347dc",
          "name": "Haoli Chen",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347dd",
          "name": "Zhaojian Li",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347de",
          "name": "Haihua Yang",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347df",
          "name": "Haifeng Liu",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347e0",
          "name": "Feng Lin",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347e1",
          "name": "Tao Peng",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347e2",
          "name": "Xin Liu",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347e3",
          "name": "Guang Shi",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-21T17:48:10.000Z",
      "title": "UI-TARS: 프로덕션화 가이드 유이리어 인터랙션의 선두자",
      "summary": "이 논문에서는, 화면샷을 그대로 입력으로 처리하는 것보다 인간처럼 상호작용을 수행하기 위해原创적인 GUI 에이전트 모델인 \"UI-TARS\"를 소개합니다. 이는, 반복되는 비즈니스 모델(예: GPT-4o)에 의존하는 전문적인 프론트엔드 모델(예: GPT-4o)과 비교하여, 이 모델들을 뛰어넘는 우수한 성능을 보여주는 엔드-toend 모델입니다. 실험은 시각적, 깊이 탐색, GUI 태스크 수행 평가를 수행하는 10개 이상의 GUI 에이전트 벤치마크에서 가장 선진적인 성능을 달성함을 보여줍니다. 특히, OSWorld 벤치마크에서 50단계에서 24.6, 15단계에서 22.7의 점수를 달성하여, Claude(22.0과 14.9)을 초과합니다. AndroidWorld에서 46.6의 점수를 달성하여, GPT-4o(34.5)를 초과합니다. UI-TARS는 다음과 같은 신규성을 도입합니다: (1) 확장된 시각화: GUI 화면샷의 큰 데이터 세트를 활용하여, UI 요소의 컨텍스트에 기반한 이해와 정확한 캡처를 수행합니다. (2) 통합된 행동 모델링: 플랫폼 간에 행동을 통일시키고, 큰 규모의 행동 트래스를 통해 정확한 깊이 탐색과 상호작용을 실현합니다. (3) 시스템 2의 이유: 여러 단계 결정론에서 잘못된 이유를 포함하는 인식을 포함하고, 태스크 분해, 반성 사고, 마일스톤 인식 등 다양한 이유 패턴을 포함하여, 여러 이유를 포함하는 인식을 실현합니다. (4) 반성적 온라인 트래스에 의한 반복 학습: 데이터 보크너를 해결하기 위해, 수백대의 기본 머신에 자동으로 수집, 필터링, 반성적으로 개선된 새로운 상호작용 트래스를 수행합니다. 반복 학습과 반성 조정을 통해, UI-TARS는 자신의 오류를 반복적으로 학습하고, 최소한의 인간의 간섭을 통해 예상되지 않은 상황으로 적응합니다. 또한, GUI 에이전트의 진화 경로를 분석하고, 이 분야의 발전을 가이드하는 시도를 합니다.",
      "upvotes": 3,
      "discussionId": "679078ff02b4d94b0f2348e0"
    },
    "publishedAt": "2025-01-21T23:51:53.248Z",
    "title": "UI-TARS: Pioneering Automated GUI Interaction with Native Agents",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.12326.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5732
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.11223",
      "authors": [
        {
          "_id": "6790772b8d7df822f1fb4405",
          "name": "Maciej Besta",
          "hidden": false
        },
        {
          "_id": "6790772b8d7df822f1fb4406",
          "name": "Julia Barth",
          "hidden": false
        },
        {
          "_id": "6790772b8d7df822f1fb4407",
          "name": "Eric Schreiber",
          "hidden": false
        },
        {
          "_id": "6790772b8d7df822f1fb4408",
          "name": "Ales Kubicek",
          "hidden": false
        },
        {
          "_id": "6790772b8d7df822f1fb4409",
          "name": "Afonso Catarino",
          "hidden": false
        },
        {
          "_id": "6790772b8d7df822f1fb440a",
          "name": "Robert Gerstenberger",
          "hidden": false
        },
        {
          "_id": "6790772b8d7df822f1fb440b",
          "name": "Piotr Nyczyk",
          "hidden": false
        },
        {
          "_id": "6790772b8d7df822f1fb440c",
          "name": "Patrick Iff",
          "hidden": false
        },
        {
          "_id": "6790772b8d7df822f1fb440d",
          "name": "Yueling Li",
          "hidden": false
        },
        {
          "_id": "6790772b8d7df822f1fb440e",
          "name": "Sam Houliston",
          "hidden": false
        },
        {
          "_id": "6790772b8d7df822f1fb440f",
          "name": "Tomasz Sternal",
          "hidden": false
        },
        {
          "_id": "6790772b8d7df822f1fb4410",
          "name": "Marcin Copik",
          "hidden": false
        },
        {
          "_id": "6790772b8d7df822f1fb4411",
          "name": "Grzegorz Kwaśniewski",
          "hidden": false
        },
        {
          "_id": "6790772b8d7df822f1fb4412",
          "name": "Jürgen Müller",
          "hidden": false
        },
        {
          "_id": "6790772b8d7df822f1fb4413",
          "name": "Łukasz Flis",
          "hidden": false
        },
        {
          "_id": "6790772b8d7df822f1fb4414",
          "name": "Hannes Eberhard",
          "hidden": false
        },
        {
          "_id": "6790772b8d7df822f1fb4415",
          "name": "Hubert Niewiadomski",
          "hidden": false
        },
        {
          "_id": "6790772b8d7df822f1fb4416",
          "name": "Torsten Hoefler",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-20T02:16:19.000Z",
      "title": "리언싱 언어 모델: 플랜 포맷",
      "summary": "理由언어 모델（RLMs）、또는 대규모理由 모델（LRMs）라고 불리는 모델들은, 진화적인 논리 구조를 추가하여 대규모 언어 모델（LLMs）의 문제 해결 능력을 재 정의했습니다. 그러나 높은 비용, 소유권, 복잡한 아키텍처, 특히 강화학습（RL）, 탐색 휴리스틱, LLMs의 조합으로 인해 발생하는 고유한 구조는 접근성과 확장성 문제를 초래하고 있습니다. 이러한 문제를 해결하기 위해, RLM의 구성 요소를 모듈화된 프레임워크로 통합하기 위한 통일된 계획을 제안합니다. 이 계획은 모든 RLM의 조사와 분석에 기반합니다. 이 계획은 다양한 논리 구조（연쇄, 트리, 그래프, 낱말형식）와 논리 전략（예: 모ンテカルロ 트리 탐색, 빔 탐색）을 포함하며, RL의 개념（정책, 가치 모델 등）과 관찰 계획（출력 기반, 프로세스 기반의 관찰）을 포함합니다. 또한 RLM의 구현을 단순화하기 위해 상세한 수학적 공식과 알고리즘의规格를 제공합니다. LLaMA-Berry, QwQ, Journey Learning, Graph of Thoughts 등 간단한 사례에서 어떻게 적용되는지 보여줍니다. 또한, 정책 모델과 가치 모델의 단계별 훈련, 관찰 분포의 중요성 등 주요 포인트를 x1과 문헌 조사를 통해 제공합니다. 마지막으로, RLM은 광범위한 LLM 생태계와 통합하는 방법을 설명합니다. 우리의 연구는 RLM의 구축을 설명하고, 진화적인 논리 능력을 민주화하고, 혁신을 촉진하며, 「부유한 AI」와 「부족한 AI」 사이의 간격을 좁히기 위해 RLM의 개발과 실험의 벽을 낮추는 것을 목표로 합니다.",
      "upvotes": 3,
      "discussionId": "6790772d8d7df822f1fb4493"
    },
    "publishedAt": "2025-01-21T23:42:44.747Z",
    "title": "Reasoning Language Models: A Blueprint",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.11223.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5732
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.12390",
      "authors": [
        {
          "_id": "67906d622ae55818ddfd0d93",
          "name": "Chao Feng",
          "hidden": false
        },
        {
          "_id": "67906d622ae55818ddfd0d94",
          "name": "Ziyang Chen",
          "hidden": false
        },
        {
          "_id": "67906d622ae55818ddfd0d95",
          "name": "Aleksander Holynski",
          "hidden": false
        },
        {
          "_id": "67906d622ae55818ddfd0d96",
          "name": "Alexei A. Efros",
          "hidden": false
        },
        {
          "_id": "67906d622ae55818ddfd0d97",
          "name": "Andrew Owens",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-21T18:59:46.000Z",
      "title": "GPS를 이미지 생성의 제어 신호로 활용하기",
      "summary": "GPS 태그를 포함하는 사진 데이터는 이미지 생성에 유용한 제어 신호로 제시된다. GPS를 통해 이미지에 대한 모델을 훈련시키고, 도시 내 이미지의 微妙한 변화에 대한 이해를 위한 복잡한 작업에 사용된다. 특히, GPS와 문장을 모두 조건으로 하는 분화 모델을 훈련한다. 학습된 모델은 서로 다른 Neighborhood, 공원, 그리고 지표의 특징적인 외모를 감지하는 이미지를 생성한다. 또한, 2D GPS를 통해 3D 모델을 스코어 디스탠시온 샘플링을 사용하여 추출한다. GPS 조건을 사용하여 각 시각점에서 재구성된 외모를 제어한다. 평가에 따르면, GPS 조건付き 모델은 위치에 기반한 이미지의 변화를 생성할 수 있으며, GPS 조건은 추측되는 3D 구조를 개선하는 것을 알 수 있다.",
      "upvotes": 3,
      "discussionId": "67906d682ae55818ddfd0f53"
    },
    "publishedAt": "2025-01-21T23:41:48.239Z",
    "title": "GPS as a Control Signal for Image Generation",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.12390.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "645ab0b7c266796265baefa4",
      "avatarUrl": "/avatars/bdac661996b63c4b2a56881707afa01f.svg",
      "fullname": "Chao Feng",
      "name": "chfeng",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.12202",
      "authors": [
        {
          "_id": "67908409416b83605450716a",
          "name": "Zibo Zhao",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450716b",
          "name": "Zeqiang Lai",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450716c",
          "name": "Qingxiang Lin",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450716d",
          "name": "Yunfei Zhao",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450716e",
          "name": "Haolin Liu",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450716f",
          "name": "Shuhui Yang",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507170",
          "name": "Yifei Feng",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507171",
          "name": "Mingxin Yang",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507172",
          "name": "Sheng Zhang",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507173",
          "name": "Xianghui Yang",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507174",
          "name": "Huiwen Shi",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507175",
          "name": "Sicong Liu",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507176",
          "name": "Junta Wu",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507177",
          "name": "Yihang Lian",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507178",
          "name": "Fan Yang",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507179",
          "name": "Ruining Tang",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450717a",
          "name": "Zebin He",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450717b",
          "name": "Xinzhou Wang",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450717c",
          "name": "Jian Liu",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450717d",
          "name": "Xuhui Zuo",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450717e",
          "name": "Zhuo Chen",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450717f",
          "name": "Biwen Lei",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507180",
          "name": "Haohan Weng",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507181",
          "name": "Jing Xu",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507182",
          "name": "Yiling Zhu",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507183",
          "name": "Xinhai Liu",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507184",
          "name": "Lixin Xu",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507185",
          "name": "Changrong Hu",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507186",
          "name": "Tianyu Huang",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507187",
          "name": "Lifu Wang",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507188",
          "name": "Jihong Zhang",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507189",
          "name": "Meng Chen",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450718a",
          "name": "Liang Dong",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450718b",
          "name": "Yiwen Jia",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450718c",
          "name": "Yulin Cai",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450718d",
          "name": "Jiaao Yu",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450718e",
          "name": "Yixuan Tang",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450718f",
          "name": "Hao Zhang",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507190",
          "name": "Zheng Ye",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507191",
          "name": "Peng He",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507192",
          "name": "Runzhou Wu",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507193",
          "name": "Chao Zhang",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507194",
          "name": "Yonghao Tan",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507195",
          "name": "Jie Xiao",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507196",
          "name": "Yangyu Tao",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507197",
          "name": "Jianchen Zhu",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507198",
          "name": "Jinbao Xue",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507199",
          "name": "Kai Liu",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450719a",
          "name": "Chongqing Zhao",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450719b",
          "name": "Xinming Wu",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450719c",
          "name": "Zhichao Hu",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450719d",
          "name": "Lei Qin",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450719e",
          "name": "Jianbing Peng",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450719f",
          "name": "Zhan Li",
          "hidden": false
        },
        {
          "_id": "67908409416b8360545071a0",
          "name": "Minghui Chen",
          "hidden": false
        },
        {
          "_id": "67908409416b8360545071a1",
          "name": "Xipeng Zhang",
          "hidden": false
        },
        {
          "_id": "67908409416b8360545071a2",
          "name": "Lin Niu",
          "hidden": false
        },
        {
          "_id": "67908409416b8360545071a3",
          "name": "Paige Wang",
          "hidden": false
        },
        {
          "_id": "67908409416b8360545071a4",
          "name": "Yingkai Wang",
          "hidden": false
        },
        {
          "_id": "67908409416b8360545071a5",
          "name": "Haozhao Kuang",
          "hidden": false
        },
        {
          "_id": "67908409416b8360545071a6",
          "name": "Zhongyi Fan",
          "hidden": false
        },
        {
          "_id": "67908409416b8360545071a7",
          "name": "Xu Zheng",
          "hidden": false
        },
        {
          "_id": "67908409416b8360545071a8",
          "name": "Weihao Zhuang",
          "hidden": false
        },
        {
          "_id": "67908409416b8360545071a9",
          "name": "YingPing He",
          "hidden": false
        },
        {
          "_id": "67908409416b8360545071aa",
          "name": "Tian Liu",
          "hidden": false
        },
        {
          "_id": "67908409416b8360545071ab",
          "name": "Yong Yang",
          "hidden": false
        },
        {
          "_id": "67908409416b8360545071ac",
          "name": "Di Wang",
          "hidden": false
        },
        {
          "_id": "67908409416b8360545071ad",
          "name": "Yuhong Liu",
          "hidden": false
        },
        {
          "_id": "67908409416b8360545071ae",
          "name": "Jie Jiang",
          "hidden": false
        },
        {
          "_id": "67908409416b8360545071af",
          "name": "Jingwei Huang",
          "hidden": false
        },
        {
          "_id": "67908409416b8360545071b0",
          "name": "Chunchao Guo",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-21T15:16:54.000Z",
      "title": "폼유ン 3D 2.0: 고해상도 테크스쳐 피드 드라이브 라이브러리 생성을 위한 확장 디퓨저 모델",
      "summary": "ハニュアン3D 2.0는 고도화된 대규모 3D 합성 시스템으로 소개됩니다. 이 시스템은 고해상도 3D 자산을 생성하기 위한 것입니다. 이 시스템에는 두 가지 핵심 구성 요소가 포함되어 있습니다: 대규모 형태 생성 모델「ハニュアン3D-DiT」와 대규모 테크스처 합성 모델「ハニュアン3D-Paint」입니다. 형태 생성 모델은 scalable flow-based diffusion transformer로 구축되어 있으며, 주어진 조건 이미지에 맞는 기하학을 생성하는 것을 목표로 합니다. 이는 하류 애플리케이션에 강력한 기초를 제공합니다. 테크스처 합성 모델은 강력한 기하학 및 diffusion priors에 기반하여, 생성된 또는手工 만든 메쉬에 대해 고해상도와 풍부한 테크스처 맵을 생성합니다. 또한 ハニュアン3D-Studio를 구축했습니다. 이는 다양한, 사용자 친화적인 생산 플랫폼으로 3D 자산의 재구성 프로세스를 단순화하는 것을 목표로 합니다. 이는 프로페셔널 및 팬들이 메쉬를 조작하거나 애니메이션을 수행할 수 있게 되었습니다. 모델을 체계적으로 평가하여, ハニュアン3D 2.0은 기하학의 세부, 조건의 일치, 테크스처의 품질 등 이전의 최상위 모델을 초월하는 것을 보여주고 있습니다. ハニュアン3D 2.0은 대규모 기반 생성 모델의 오픈 소스 3D 커뮤니티의 부족점을 보완하기 위해 공개되었습니다. 모델의 코드와 사전 학습 튜닝은 아래 URL에서 사용 가능합니다.\nhttps://github.com/Tencent/Hunyuan3D-2",
      "upvotes": 1,
      "discussionId": "6790840d416b8360545072a7"
    },
    "publishedAt": "2025-01-22T00:37:32.486Z",
    "title": "Hunyuan3D 2.0: Scaling Diffusion Models for High Resolution Textured 3D Assets Generation",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.12202.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5732
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.10893",
      "authors": [
        {
          "_id": "67907dd5e1d8fc832b3e7b0f",
          "name": "Hongjin Su",
          "hidden": false
        },
        {
          "_id": "67907dd5e1d8fc832b3e7b10",
          "name": "Ruoxi Sun",
          "hidden": false
        },
        {
          "_id": "67907dd5e1d8fc832b3e7b11",
          "name": "Jinsung Yoon",
          "hidden": false
        },
        {
          "_id": "67907dd5e1d8fc832b3e7b12",
          "name": "Pengcheng Yin",
          "hidden": false
        },
        {
          "_id": "67907dd5e1d8fc832b3e7b13",
          "name": "Tao Yu",
          "hidden": false
        },
        {
          "_id": "67907dd5e1d8fc832b3e7b14",
          "name": "Sercan Ö. Arık",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-18T22:34:41.000Z",
      "title": "학습된 실제 실습: 실제 환경에서 자동 조정 아웃풋 프로그램의 데이터 중심 프레임워크",
      "summary": "自動 언어 모델（LLMs）를 기반으로 한 자율주의 에이전트는 인간의 능력을 높일 수 있으며, 메일 전송부터 데이터 분석까지 디지털 작업에 도움을 줄 수 있습니다. 현재의 LLMs는 이러한 작업에서의 능력은 에이전트가 상호작용하는 환경에서 고품질의 데이터를 얻는 데 제한되어 있습니다. 우리는 인간이 지시를 필요로 하지 않도록 환경에 적응하는 LLM 에이전트를 구축하기 위해 「학습을 통해 적응하는」 데이터 중심 프레임워크를 제안합니다. 「학습을 통해 적응하는」는 문서에 기반한 에이전트와 환경의 상호작용의 트래지렉트를 합성하고 상호작용의 역사를 요약하거나 추상화하여 명령을 구축합니다. 이를 「후진 구축」이라고 합니다. 우리는 합성 데이터의 품질을 평가하기 위해 학습 기반 시나리오와 학습 필요없는 in-context learning（ICL）을 사용합니다. 여기서는 외부 검색 접근 방식을 개발하고 에이전트를 최적화합니다. SWE-bench, WebArena, OSWorld, Spider2-V의 실제 코딩, 웹, 데스크톱 환경에 대한 실험에서 「학습을 통해 적응하는」는 다양한 하류 에이전트 작업에 대한 효과를 보여주었습니다. ICL의 기준 결과를 보면 Claude-3.5에서 12.2％, Codestral-22B에서 19.5％의 향상을 나타냅니다. 또한 후진 구축의 중요성을 보여주며 학습에서 14.0％의 향상을 나타냅니다. 우리의 제거 연구는 ICL에서 합성 데이터의 효율성과 우리의 검색 파이프라인의 우월성을 보여주었습니다. LLMs가 실제 세계적인 환경에서 실제로 도입될 것을 기대합니다.",
      "upvotes": 1,
      "discussionId": "67907dd9e1d8fc832b3e7c36"
    },
    "publishedAt": "2025-01-22T00:11:18.322Z",
    "title": "Learn-by-interact: A Data-Centric Framework for Self-Adaptive Agents in Realistic Environments",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.10893.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5732
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.11873",
      "authors": [
        {
          "_id": "679071da11a3f67d8f498649",
          "name": "Zihan Qiu",
          "hidden": false
        },
        {
          "_id": "679071da11a3f67d8f49864a",
          "name": "Zeyu Huang",
          "hidden": false
        },
        {
          "_id": "679071da11a3f67d8f49864b",
          "name": "Bo Zheng",
          "hidden": false
        },
        {
          "_id": "679071da11a3f67d8f49864c",
          "name": "Kaiyue Wen",
          "hidden": false
        },
        {
          "_id": "679071da11a3f67d8f49864d",
          "name": "Zekun Wang",
          "hidden": false
        },
        {
          "_id": "679071da11a3f67d8f49864e",
          "name": "Rui Men",
          "hidden": false
        },
        {
          "_id": "679071da11a3f67d8f49864f",
          "name": "Ivan Titov",
          "hidden": false
        },
        {
          "_id": "679071da11a3f67d8f498650",
          "name": "Dayiheng Liu",
          "hidden": false
        },
        {
          "_id": "679071da11a3f67d8f498651",
          "name": "Jingren Zhou",
          "hidden": false
        },
        {
          "_id": "679071da11a3f67d8f498652",
          "name": "Junyang Lin",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-21T04:04:39.000Z",
      "title": "데모نز 인티뷰얼: 훈련 시 구현할 하부 밸런스 손실에 대해 전문적인 익스퍼트 모델의 구현\n\n(注意：虽然要求不添加解释或额外的文本，但为了确保翻译的准确性和专业性，这里提供了一个更加自然和流畅的翻译版本，同时保持了原文的专业性。)",
      "summary": "이 논문은 Mixture-of-Experts (MoEs) 모델의 훈련 시 Load-balancing Loss (LBL)의 구현을 재검토합니다. 특히, MoEs의 LBL는 N_E\nsum_{i=1}^{N_E} f_i p_i로 정의되어 있으며, N_E는 전문가의 총 수, f_i는 i번째 전문가의 선택 빈도, p_i는 i번째 전문가의 평균 게이팅 점수를 나타냅니다. 현재의 MoE 훈련 프레임워크는 일반적으로 병렬 훈련 전략을 사용하며, f_i와 LBL은 마이크로 배치 내에서 계산되어, 대응하는 병렬 그룹에 평균이 됩니다. 본질적으로, 마이크로 배치는 훈련 비리온 스케일의 LLMs의 훈련 시 매우 적은 시퀀스를 포함합니다. 따라서, 마이크로 배치의 LBL은 거의 시퀀스 수준으로, 로터는 각 시퀀스 내 토큰을 균등하게 분배하도록 압력을 가합니다. 이러한 엄격한 제약 아래, 영역 Specialization의 전문가 시퀀스 (예: 코드)에서의 토큰은 모두 전문가에 균등하게 분배되어 전문가의 Specialization을 억제합니다. 이 연구에서는 마이크로 배치의 제약을 해제하고, 글로벌 배치를 사용하여 LBL을 계산하는 방법을 제안합니다. 글로벌 배치는 마이크로 배치에 비해 매우 다양한 시퀀스를 포함하며, 이는 코퍼스 수준의 부하 균형을 촉진합니다. 특히, f_i를 마이크로 배치 간에 동기화하기 위해 추가적인 통신 단계를 추가하고 이를 사용하여 LBL을 계산합니다. MoEs 기반의 LLMs의 훈련 (총 파라미터 수 42.8B까지, 토큰 수 400B까지)의 실험에서, 글로벌 배치의 LBL 전략은 예측 외의 뛰어난 성능 향상을 나타냅니다. 분석에 따르면, 글로벌 배치의 LBL은 MoE의 전문가의 영역 Specialization을 크게 향상시킵니다.",
      "upvotes": 1,
      "discussionId": "679071db11a3f67d8f498680"
    },
    "publishedAt": "2025-01-21T23:27:52.660Z",
    "title": "Demons in the Detail: On Implementing Load Balancing Loss for Training Specialized Mixture-of-Expert Models",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/647ccbd6e07cf9bb2d485244/ddUbQV_yVPwD6P0TSR5lu.png",
      "https://cdn-uploads.huggingface.co/production/uploads/647ccbd6e07cf9bb2d485244/f7Q4QULppOygZlsYBUvY9.png",
      "https://cdn-uploads.huggingface.co/production/uploads/647ccbd6e07cf9bb2d485244/9Jwx37bQkCjaWcccWbJ7b.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.11873.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "647ccbd6e07cf9bb2d485244",
      "avatarUrl": "/avatars/e8915abaff04f6762247e196b7cf84df.svg",
      "fullname": "Zihan Qiu",
      "name": "QwQZh",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 3
    },
    "isAuthorParticipating": false
  }
]