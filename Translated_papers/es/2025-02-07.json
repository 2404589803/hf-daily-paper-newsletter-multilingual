[
  {
    "paper": {
      "id": "2502.03032",
      "authors": [
        {
          "_id": "67a59c4e7ffacd843a56404a",
          "user": {
            "_id": "634c5f8cfb80cc6bcaf42c03",
            "avatarUrl": "/avatars/1f37db0e70cbaf9707f4c8cbcee37ca0.svg",
            "isPro": false,
            "fullname": "Daniil Laptev",
            "user": "dlaptev",
            "type": "user"
          },
          "name": "Daniil Laptev",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-07T09:58:04.546Z",
          "hidden": false
        },
        {
          "_id": "67a59c4e7ffacd843a56404b",
          "user": {
            "_id": "60b364e7f88532cd79eaff7b",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1654185363389-60b364e7f88532cd79eaff7b.jpeg",
            "isPro": false,
            "fullname": "Nikita Balagansky",
            "user": "elephantmipt",
            "type": "user"
          },
          "name": "Nikita Balagansky",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-07T09:58:02.693Z",
          "hidden": false
        },
        {
          "_id": "67a59c4e7ffacd843a56404c",
          "name": "Yaroslav Aksenov",
          "hidden": false
        },
        {
          "_id": "67a59c4e7ffacd843a56404d",
          "user": {
            "_id": "62a9c8edc19f92ae443ab37f",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1669110208492-62a9c8edc19f92ae443ab37f.png",
            "isPro": false,
            "fullname": "Daniil Gavrilov",
            "user": "kefirski",
            "type": "user"
          },
          "name": "Daniil Gavrilov",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-07T09:58:06.718Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-05T09:39:34.000Z",
      "title": "Características de análisis de flujo para mejorar la interpretación del modelo de lenguaje y la guía para el usuario.",
      "summary": "Un nuevo enfoque permite mapear sistemáticamente las características encontradas por un codificador automático esparso en las capas continuas de modelos de lenguaje grandes. En estudios previos, se examinaron las conexiones de características entre capas, y se seguió cómo una característica específica se mantiene, se deforma o aparece por primera vez utilizando métodos de semejanza de coseno sin datos. Este método genera graficas que describen detalladamente la evolución de las características y proporciona una comprensión estructural en el cálculo del modelo. Es importante destacar que esta mapeo de características entre capas permite controlar directamente el comportamiento del modelo al fortalecer o inhibir características seleccionadas, lo que permite controlar el tema en la generación de textos. Estos hallazgos clarifican la utilidad de estructuras explicativas causales y intermedias entre capas, y ayudan a entender cómo las características se desarrollan durante el proceso de propagación, proporcionando nuevas formas de comprender el comportamiento transparente de modelos de lenguaje grandes.",
      "upvotes": 34,
      "discussionId": "67a59c4f7ffacd843a56408f"
    },
    "publishedAt": "2025-02-07T01:29:53.798Z",
    "title": "Analyze Feature Flow to Enhance Interpretation and Steering in Language Models",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.03032.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "62a9c8edc19f92ae443ab37f",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1669110208492-62a9c8edc19f92ae443ab37f.png",
      "fullname": "Daniil Gavrilov",
      "name": "kefirski",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 10
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.04153",
      "authors": [
        {
          "_id": "67a57b1fdea89ffe80d9fe56",
          "user": {
            "_id": "66c89152d33e34fbc29497d7",
            "avatarUrl": "/avatars/bbddabf6532393951c4759e5915a065b.svg",
            "isPro": false,
            "fullname": "KaikaiAn",
            "user": "kkk-an",
            "type": "user"
          },
          "name": "Kaikai An",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-07T09:58:18.320Z",
          "hidden": false
        },
        {
          "_id": "67a57b1fdea89ffe80d9fe57",
          "name": "Li Sheng",
          "hidden": false
        },
        {
          "_id": "67a57b1fdea89ffe80d9fe58",
          "name": "Ganqu Cui",
          "hidden": false
        },
        {
          "_id": "67a57b1fdea89ffe80d9fe59",
          "user": {
            "_id": "637c99bbfe115289cfedfb44",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/637c99bbfe115289cfedfb44/344NN9KKF_XXTlVYaGaMW.png",
            "isPro": false,
            "fullname": "ssz",
            "user": "ssz1111",
            "type": "user"
          },
          "name": "Shuzheng Si",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-07T09:58:16.229Z",
          "hidden": false
        },
        {
          "_id": "67a57b1fdea89ffe80d9fe5a",
          "name": "Ning Ding",
          "hidden": false
        },
        {
          "_id": "67a57b1fdea89ffe80d9fe5b",
          "name": "Yu Cheng",
          "hidden": false
        },
        {
          "_id": "67a57b1fdea89ffe80d9fe5c",
          "name": "Baobao Chang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-06T15:39:16.000Z",
      "title": "UltraIF: Se está promoviendo la traza de comandos de la naturaleza.",
      "summary": "Las instrucciones siguientes desempeñan un papel de asistente para utilizar modelos de lenguaje grande y moderno (LLMs). Sin embargo, el control de LLMs a través de comandos complejos requiere un secreto crucial, y existe un gran desvío entre los modelos entrenados por comunidades abiertas y empresas líderes. Para cerrar este desvío, proponemos una aproximación sencilla y expandible basada en datos abiertos para construir LLMs que sigan comandos complejos, llamada \"UltraIF\". UltraIF se inicia decompando las instrucciones de usuarios reales en simples términos de búsqueda, condiciones de restricción y preguntas de evaluación correspondientes a estas condiciones. Luego, se entrena UltraComposer para configurar instrucciones y preguntas de evaluación relacionadas con las condiciones de restricción. Esta configuración de instrucciones permite la síntesis de comandos complejos y la filtración de respuestas mediante preguntas de evaluación. En nuestros experimentos, primero demostramos que se puede seguir 5 comandos con el modelo LLaMA-3.1-8B-Base, convertiéndolo en una versión de instrucciones. Esto logró generar respuestas sin necesidad de usar información del benchmark, utilizando el modelo como generador de respuestas y evaluador. El modelo asociado logró puntuaciones competitivas en otros benchmarks. Además, UltraIF muestra que puede mejorar el modelo LLaMA-3.1-8B-Instruct mediante autoconexión, promoviendo ampliamente el uso de este método. Nuestro código está disponible en https://github.com/kkk-an/UltraIF.",
      "upvotes": 13,
      "discussionId": "67a57b1fdea89ffe80d9fe93"
    },
    "publishedAt": "2025-02-06T22:27:51.425Z",
    "title": "UltraIF: Advancing Instruction Following from the Wild",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.04153.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "66c89152d33e34fbc29497d7",
      "avatarUrl": "/avatars/bbddabf6532393951c4759e5915a065b.svg",
      "fullname": "KaikaiAn",
      "name": "kkk-an",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.04328",
      "authors": [
        {
          "_id": "67a586fad177de2eeba7de7b",
          "user": {
            "_id": "64f001bfabd9fb1914398bd5",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64f001bfabd9fb1914398bd5/9teH82hkBI4csIz_WQh5q.jpeg",
            "isPro": false,
            "fullname": "liuzuyan",
            "user": "Zuyan",
            "type": "user"
          },
          "name": "Zuyan Liu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-07T09:58:10.679Z",
          "hidden": false
        },
        {
          "_id": "67a586fad177de2eeba7de7c",
          "name": "Yuhao Dong",
          "hidden": false
        },
        {
          "_id": "67a586fad177de2eeba7de7d",
          "name": "Jiahui Wang",
          "hidden": false
        },
        {
          "_id": "67a586fad177de2eeba7de7e",
          "name": "Ziwei Liu",
          "hidden": false
        },
        {
          "_id": "67a586fad177de2eeba7de7f",
          "name": "Winston Hu",
          "hidden": false
        },
        {
          "_id": "67a586fad177de2eeba7de80",
          "name": "Jiwen Lu",
          "hidden": false
        },
        {
          "_id": "67a586fad177de2eeba7de81",
          "name": "Yongming Rao",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-06T18:59:55.000Z",
      "title": "Ora: Supera las fronteras de un modelo de lenguaje 360 grados utilizando una mente de modelo de diversidad avanzada.",
      "summary": "Recientemente, el interés en el desarrollo de grandes modelos de lenguaje, especialmente después de GPT-4o, ha aumentado debido a su capacidad para entender y procesar diferentes tipos de información. Sin embargo, el progreso en términos de rendimiento ha sido más lento en comparación con modelos específicos. En este artículo, se presenta el modelo de lenguaje Omni-modal llamado Ola. Ola logra alcanzar un rendimiento comparable a modelos especializados en imágenes, videos y sonidos. El diseño central de Ola es una estrategia avanzada para la configuración de modelos. En esta estrategia, se comienza con modelos más diferentes y se expande progresivamente el conjunto de habilidades del modelo a través de datos de diálogo que conectan lenguaje y sonido, o datos de video que conectan todo el modelo. Este sistema de aprendizaje en línea permite mantener el tamaño de los datos de entrenamiento cruzado entre modelos y facilita el desarrollo de modelos Omni-modal de manera eficiente y costo-eficiente, comparado con los modelos visuales lingüísticos actuales. Además, para lograr experiencias interactivas de alta dimensión como GPT-4o, Ola desarrolla una estrategia de resolución de lenguaje de flujo a nivel de oración. Las experimentaciones distribuidas superan los modelos abiertos actuales en todos los modelos y alcanzan altos rendimientos comparables a los modelos más avanzados de rendimiento especializado de la misma dimensión. Ola se propone convertirse en una solución completamente abierta de comprensión Omni-modal para impulsar la investigación futura en esta área emergente. Los pesos del modelo, el código y los datos están abiertos en GitHub en la dirección https://github.com/Ola-Omni/Ola.",
      "upvotes": 8,
      "discussionId": "67a586fbd177de2eeba7deae"
    },
    "publishedAt": "2025-02-07T00:54:43.254Z",
    "title": "Ola: Pushing the Frontiers of Omni-Modal Language Model with Progressive Modality Alignment",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.04328.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64f001bfabd9fb1914398bd5",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64f001bfabd9fb1914398bd5/9teH82hkBI4csIz_WQh5q.jpeg",
      "fullname": "liuzuyan",
      "name": "Zuyan",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.03621",
      "authors": [
        {
          "_id": "67a59e5298f41a0460ee5282",
          "name": "Danah Yatim",
          "hidden": false
        },
        {
          "_id": "67a59e5298f41a0460ee5283",
          "name": "Rafail Fridman",
          "hidden": false
        },
        {
          "_id": "67a59e5298f41a0460ee5284",
          "name": "Omer Bar-Tal",
          "hidden": false
        },
        {
          "_id": "67a59e5298f41a0460ee5285",
          "name": "Tali Dekel",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-05T21:14:55.000Z",
      "title": "DynVFX: Contenido dinámico agregado en vídeos reales",
      "summary": "Proponemos un método para agregar contenido dinámico nuevo a videos reales cuando se crea. Dado un video de entrada y una indicación textual breve del contenido deseado por el usuario, nuestro método synthetiza objetos dinámicos que interactúan con el espacio existente o complejos espacios a medida que el tiempo pasa. La posición, apariencia y movimiento del nuevo contenido se integran sin distorsión con la imagen original, considerando el movimiento de la cámara, el ocultamiento y la interacción con otros objetos dinámicos en el espacio. De esta manera, se obtiene una salida videorealista coherente. Este método se implementa utilizando transformadores de expansión de vídeo desde texto pre-entrenados y modelos de lenguaje visuo-lingüístico pre-entrenados, permitiendo un enfoque de 0-shot y sin entrenamiento. Para facilitar la asignación precisa de la posición y la integración sin distorsión del nuevo contenido, introducimos un método de inferencia basado en características manipuladas dentro de estructuras de atención. Este método es completamente automatizado pero requiere solo instrucciones simples del usuario. Mostramos los resultados de aplicar este método a videos reales, que incluyen diversos escenarios con objetos y escenarios variados según el movimiento de la cámara y los objetos.",
      "upvotes": 8,
      "discussionId": "67a59e5798f41a0460ee5389"
    },
    "publishedAt": "2025-02-07T00:48:49.217Z",
    "title": "DynVFX: Augmenting Real Videos with Dynamic Content",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.03621.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6181c72cdcc1df2c9de8a4d8",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1655248010394-6181c72cdcc1df2c9de8a4d8.jpeg",
      "fullname": "Hila Chefer",
      "name": "Hila",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 9
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.02358",
      "authors": [
        {
          "_id": "67a43546f6caedc30f9d8c71",
          "user": {
            "_id": "659faf1d874e583fed79d09b",
            "avatarUrl": "/avatars/178a18686426908b9496ce71f6550655.svg",
            "isPro": false,
            "fullname": "Ziyan Guo",
            "user": "ZiyanGuo",
            "type": "user"
          },
          "name": "Ziyan Guo",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-06T14:15:01.599Z",
          "hidden": false
        },
        {
          "_id": "67a43546f6caedc30f9d8c72",
          "name": "Zeyu Hu",
          "hidden": false
        },
        {
          "_id": "67a43546f6caedc30f9d8c73",
          "name": "Na Zhao",
          "hidden": false
        },
        {
          "_id": "67a43546f6caedc30f9d8c74",
          "name": "De Wen Soh",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-04T14:43:26.000Z",
      "title": "MotionLab: Generación y edición de movimientos humanos mediante un paradigma dinámico dinámico de condiciones unificado",
      "summary": "El generación y edición de movimientos humanos son componentes esenciales de la gráfica computacional y la visión. Sin embargo, la forma en que se aborda actualmente esta área ofrece soluciones separadas para tareas específicas, que no se adaptan bien a aplicaciones reales. Por otro lado, algunos esfuerzos buscan integrar tareas relacionadas con el movimiento, pero estas metodologías se centran únicamente en guiar el movimiento mediante modelos diferentes, sinofían, faltan funciones de edición y control detallado, y no fomentan la compartir conocimiento entre tareas. Para superar estas limitaciones y proporcionar un marco funcional y uniforme que aborde tanto la generación como la edición de movimientos humanos, se propone un nuevo paradigma: 'Movement Condition Motion'. Con este paradigma, se propone 'Movement Lab'. Movement Lab aprende a mapear movimientos fuentes a movimientos objetivos utilizando flujos de flujo normalizado guiados por condiciones específicas. En Movement Lab, 1) se introduce el Motion Flow Channel Setter para fortalecer la generación y edición sin necesidad de módulos de tarea específica, 2) se utiliza Alignment Position Encoding para garantizar la sincronización temporal entre los movimientos fuente y objetivo, 3) se modela la instrucción de tarea específica, y 4) se aprende el movimiento kernel para promover un aprendizaje efectivo de múltiples tareas y la compartida de conocimiento entre ellas. En particular, nuestro Movement Lab muestra un buen rendimiento de generalización y eficiencia de inferencia en varios benchmarks de movimientos humanos. Nuestro código y resultados adicionales en vídeo están disponibles en la siguiente URL: https://diouo.github.io/motionlab.github.io/.",
      "upvotes": 8,
      "discussionId": "67a43547f6caedc30f9d8c9b"
    },
    "publishedAt": "2025-02-06T23:38:19.926Z",
    "title": "MotionLab: Unified Human Motion Generation and Editing via the Motion-Condition-Motion Paradigm",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.02358.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "659faf1d874e583fed79d09b",
      "avatarUrl": "/avatars/178a18686426908b9496ce71f6550655.svg",
      "fullname": "Ziyan Guo",
      "name": "ZiyanGuo",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.04313",
      "authors": [
        {
          "_id": "67a5b9107897c8f5406155e0",
          "name": "Shashwat Goel",
          "hidden": false
        },
        {
          "_id": "67a5b9107897c8f5406155e1",
          "name": "Joschka Struber",
          "hidden": false
        },
        {
          "_id": "67a5b9107897c8f5406155e2",
          "name": "Ilze Amanda Auzina",
          "hidden": false
        },
        {
          "_id": "67a5b9107897c8f5406155e3",
          "name": "Karuna K Chandra",
          "hidden": false
        },
        {
          "_id": "67a5b9107897c8f5406155e4",
          "name": "Ponnurangam Kumaraguru",
          "hidden": false
        },
        {
          "_id": "67a5b9107897c8f5406155e5",
          "name": "Douwe Kiela",
          "hidden": false
        },
        {
          "_id": "67a5b9107897c8f5406155e6",
          "name": "Ameya Prabhu",
          "hidden": false
        },
        {
          "_id": "67a5b9107897c8f5406155e7",
          "name": "Matthias Bethge",
          "hidden": false
        },
        {
          "_id": "67a5b9107897c8f5406155e8",
          "name": "Jonas Geiping",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-06T18:56:01.000Z",
      "title": "El modelo también piensa de la misma manera, esto reduce la visión y el Audición de la IA.",
      "summary": "Con el desarrollo de las capacidades de un LM, se ha encontrado que la evaluación y el supervisión escalares son tareas que resultan difíciles para la humanidad. Otros LM se han visto como capaces de automatizar estas tareas, lo cual se ha considerado deseable, y se ha denominado \"AI Vigilancia\". Para investigar cómo la similitud entre LM afecta ambos aspectos de la AI Vigilancia, se propone una medida de probabilidad de similitud basada en el repetir errores de modelo. Usando esta medida, se muestra primero que los puntajes de un jurado de un LLM actúan de manera más amigable con modelos similares a los jurados, y se generalizan los resultados automáticos de preferencia recientes. A continuación, se investiga el entrenamiento de LM con notas de modelos, y se observa que el punto medio entre un supervisor débil y un modelo estudiante fuerte tiene un efecto de \"la razón débil es importante para una fuerte generalización\". Con el aumento de la capacidad del modelo, se espera que la búsqueda de errores en el modelo se vuelva más difícil, y que las solicitudes por parte de la AI Vigilancia aumenten. Sin embargo, se observa un tendencia de preocupación. Los errores del modelo se vuelven más similares a medida que aumenta su capacidad, y existe un riesgo de fracaso en la correlación. En este artículo, se reporta la similitud entre modelos en el nuevo paradigma de la AI Vigilancia y se enfatiza la importancia de la corrección.",
      "upvotes": 7,
      "discussionId": "67a5b9137897c8f540615673"
    },
    "publishedAt": "2025-02-07T02:46:29.675Z",
    "title": "Great Models Think Alike and this Undermines AI Oversight",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/6506832221ac448013f94995/pXBCc2dpWXCw6JinTbiFP.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.04313.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6506832221ac448013f94995",
      "avatarUrl": "/avatars/0a86f64cb502a04ab1487d78f63bf3fd.svg",
      "fullname": "Shashwat Goel",
      "name": "shash42",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.03544",
      "authors": [
        {
          "_id": "67a589ebb16fabcdd2dea1eb",
          "name": "Yuri Chervonyi",
          "hidden": false
        },
        {
          "_id": "67a589ebb16fabcdd2dea1ec",
          "name": "Trieu H. Trinh",
          "hidden": false
        },
        {
          "_id": "67a589ebb16fabcdd2dea1ed",
          "name": "Miroslav Olšák",
          "hidden": false
        },
        {
          "_id": "67a589ebb16fabcdd2dea1ee",
          "name": "Xiaomeng Yang",
          "hidden": false
        },
        {
          "_id": "67a589ebb16fabcdd2dea1ef",
          "name": "Hoang Nguyen",
          "hidden": false
        },
        {
          "_id": "67a589ebb16fabcdd2dea1f0",
          "name": "Marcelo Menegali",
          "hidden": false
        },
        {
          "_id": "67a589ebb16fabcdd2dea1f1",
          "name": "Junehyuk Jung",
          "hidden": false
        },
        {
          "_id": "67a589ebb16fabcdd2dea1f2",
          "name": "Vikas Verma",
          "hidden": false
        },
        {
          "_id": "67a589ebb16fabcdd2dea1f3",
          "name": "Quoc V. Le",
          "hidden": false
        },
        {
          "_id": "67a589ebb16fabcdd2dea1f4",
          "name": "Thang Luong",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-05T19:02:03.000Z",
      "title": "El problema de la geometría de los Olimpiadas resuelto por AlphaGeometry2: las logros del listado de platas de oro",
      "summary": "AlphaGeometry2 es una versión significativamente mejorada de AlphaGeometry, introducida por Trinh et al. (2024). Este sistema ha logrado resultados superiores a los de los ganadores medios del torneo olímpico de geometría. Inicialmente, se expandió el lenguaje de AlphaGeometry con el objetivo de abordar problemas más complejos. Esto permitió resolver problemas que incluían ecuaciones lineales, razones y distancias. Con estas expansiones y otras funciones adicionales, la cobertura del lenguaje de AlphaGeometry en los problemas de la Olimpiada Internacional de Matemáticas (IMO) de 2000 a 2024 se incrementó del 66% al 88%. Además, la mejora del modelado del lenguaje utilizando la arquitectura Gemini y la introducción de un nuevo mecanismo de compartir conocimientos (combinando múltiples árboles de búsqueda) mejoró significativamente el proceso de exploración de AlphaGeometry2. Además, la mejora del motor de operaciones con símbolos y la generación de datos sintéticos aumentaron la tasa de respuestas completas de AlphaGeometry2, que ahora resuelve 84% de todos los problemas desarrollados en los 25 años (anteriormente, 54%). AlphaGeometry2 fue parte de un sistema que alcanzó el estándar para la medalla de plata en la IMO 2024 (ver más información en https://dpmd.ai/imo-silver). Finalmente, se presenta un informe sobre el desarrollo de un sistema completamente automático para resolver problemas de geometría ingresados en naturaleza.",
      "upvotes": 7,
      "discussionId": "67a589ecb16fabcdd2dea259"
    },
    "publishedAt": "2025-02-06T23:20:09.641Z",
    "title": "Gold-medalist Performance in Solving Olympiad Geometry with AlphaGeometry2",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.03544.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5968
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.04306",
      "authors": [
        {
          "_id": "67a57f334e50b2956b13f4e0",
          "user": {
            "_id": "6730dc8df84c8aac97451e57",
            "avatarUrl": "/avatars/4f2cf5363b17744daca41d2a18ddfeb8.svg",
            "isPro": false,
            "fullname": "Yinjie Wang",
            "user": "yinjiewang",
            "type": "user"
          },
          "name": "Yinjie Wang",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-02-07T03:34:13.176Z",
          "hidden": false
        },
        {
          "_id": "67a57f334e50b2956b13f4e1",
          "name": "Ling Yang",
          "hidden": false
        },
        {
          "_id": "67a57f334e50b2956b13f4e2",
          "name": "Guohao Li",
          "hidden": false
        },
        {
          "_id": "67a57f334e50b2956b13f4e3",
          "name": "Mengdi Wang",
          "hidden": false
        },
        {
          "_id": "67a57f334e50b2956b13f4e4",
          "name": "Bryon Aragam",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-06T18:47:49.000Z",
      "title": "Score Flow: Comprender el flujo de puntuación para optimizar el flujo de preferencias basado en puntuación en el flujo de trabajo de la inteligencia artificial de lenguaje (LLM) agente.",
      "summary": "Recientes estudios han enfatizado la utilización de sistemas de modelos de lenguaje grandes con múltiples agentes para reducir el esfuerzo necesario para la construcción automática de modelos en problemas complejos. Esto ha llevado a la desarrollo de métodos de optimización de flujos de trabajo de agentes automáticos. Sin embargo, los métodos actuales presentan problemas como limitaciones de representación, falta de adaptabilidad y escalabilidad reducida debido a métodos de optimización discretos, lo que limita su flexibilidad. ScoreFlow, un marco de trabajo sencillo y altamente eficiente, aborda estos desafíos. ScoreFlow utiliza optimización basada en gradientes eficientes. Además, introduce una variante de la nueva metodología de optimización de preferencias directas, Score-DPO, considerando retroalimentación cuantitativa. Mediante seis pruebas de benchmark, ScoreFlow ha logrado mejoras del 8.2% sobre los base lines existentes. Además, estos pequeños modelos pueden superar los grandes modelos con un costo de inferencia bajo. Proyecto: https://github.com/Gen-Verse/ScoreFlow",
      "upvotes": 7,
      "discussionId": "67a57f354e50b2956b13f53d"
    },
    "publishedAt": "2025-02-06T22:34:42.483Z",
    "title": "ScoreFlow: Mastering LLM Agent Workflows via Score-based Preference Optimization",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.04306.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64fde4e252e82dd432b74ce9",
      "avatarUrl": "/avatars/061a69d858b86d1600be916122cae7fc.svg",
      "fullname": "Ling Yang",
      "name": "Lingaaaaaaa",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 6
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.04128",
      "authors": [
        {
          "_id": "67a5894db16fabcdd2de5459",
          "user": {
            "_id": "645f172d7c6bff8577353d1a",
            "avatarUrl": "/avatars/a83682e1343809257b082b78d58c582a.svg",
            "isPro": false,
            "fullname": "ZhenYE",
            "user": "ZhenYe234",
            "type": "user"
          },
          "name": "Zhen Ye",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-07T09:58:08.787Z",
          "hidden": false
        },
        {
          "_id": "67a5894db16fabcdd2de545a",
          "name": "Xinfa Zhu",
          "hidden": false
        },
        {
          "_id": "67a5894db16fabcdd2de545b",
          "name": "Chi-Min Chan",
          "hidden": false
        },
        {
          "_id": "67a5894db16fabcdd2de545c",
          "name": "Xinsheng Wang",
          "hidden": false
        },
        {
          "_id": "67a5894db16fabcdd2de545d",
          "name": "Xu Tan",
          "hidden": false
        },
        {
          "_id": "67a5894db16fabcdd2de545e",
          "name": "Jiahe Lei",
          "hidden": false
        },
        {
          "_id": "67a5894db16fabcdd2de545f",
          "name": "Yi Peng",
          "hidden": false
        },
        {
          "_id": "67a5894db16fabcdd2de5460",
          "name": "Haohe Liu",
          "hidden": false
        },
        {
          "_id": "67a5894db16fabcdd2de5461",
          "name": "Yizhu Jin",
          "hidden": false
        },
        {
          "_id": "67a5894db16fabcdd2de5462",
          "name": "Zheqi DAI",
          "hidden": false
        },
        {
          "_id": "67a5894db16fabcdd2de5463",
          "name": "Hongzhan Lin",
          "hidden": false
        },
        {
          "_id": "67a5894db16fabcdd2de5464",
          "name": "Jianyi Chen",
          "hidden": false
        },
        {
          "_id": "67a5894db16fabcdd2de5465",
          "name": "Xingjian Du",
          "hidden": false
        },
        {
          "_id": "67a5894db16fabcdd2de5466",
          "name": "Liumeng Xue",
          "hidden": false
        },
        {
          "_id": "67a5894db16fabcdd2de5467",
          "name": "Yunlin Chen",
          "hidden": false
        },
        {
          "_id": "67a5894db16fabcdd2de5468",
          "name": "Zhifei Li",
          "hidden": false
        },
        {
          "_id": "67a5894db16fabcdd2de5469",
          "name": "Lei Xie",
          "hidden": false
        },
        {
          "_id": "67a5894db16fabcdd2de546a",
          "name": "Qiuqiang Kong",
          "hidden": false
        },
        {
          "_id": "67a5894db16fabcdd2de546b",
          "name": "Yike Guo",
          "hidden": false
        },
        {
          "_id": "67a5894db16fabcdd2de546c",
          "user": {
            "_id": "6628adb14277eae0da5eee28",
            "avatarUrl": "/avatars/6cb41b80cc5e014e455dfc2a22682e64.svg",
            "isPro": true,
            "fullname": "HKUST Audio",
            "user": "HKUST-Audio",
            "type": "user"
          },
          "name": "Wei Xue",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-02-07T04:17:17.888Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-06T15:04:00.000Z",
      "title": "Razna: Expansión de la computación para el entrenamiento y la inferencia en la síntesis de voz basada en Ramar",
      "summary": "Recientemente, el desarrollo de grandes modelos de lenguaje basados en documentos (LLMs) ha recibido mucha atención, especialmente el de las series GPT y el modelo o1, debido a su capacidad para escalar el cálculo en el entrenamiento y en la inferencia. Sin embargo, los sistemas de TTS que utilizan los más avanzados LLMs actuales están compuestos por varios pasos, lo que complica la decisión sobre la escalabilidad de modelos específicos durante el entrenamiento y el test. En este estudio, se presentan las siguientes contribuciones: primero, se aplica el escalado del cálculo en el entrenamiento y en la inferencia a la síntesis de voz. Segundo, se propone un marco sencillo llamado Llasa, que utiliza una capa de cuantificación vectorial (VQ) y una arquitectura Transformer, y se ajusta a los modelos de LLMs estándares (por ejemplo, Llama). Los experimentos muestran que el escalado del cálculo en el entrenamiento de Llasa mejora consistentemente la naturaleza de la voz sintetizada y permite la generación de patrones de voz complejos y precisos. Además, desde la perspectiva del escalado del cálculo en la inferencia, se utiliza un modelo de comprensión de voz como evaluador para realizar búsquedas, y se confirma que el escalado del cálculo en la inferencia puede cambiar a modo de muestreo según la preferencia de un evaluador específico, mejorando la expresión emocional, la consistencia de la tonalidad y la precisión del contenido. Además, se publican los modelos de TTS (1B, 3B, 8B) y los checkpoints y códigos de entrenamiento de los modelos de código.",
      "upvotes": 5,
      "discussionId": "67a5894db16fabcdd2de54d3"
    },
    "publishedAt": "2025-02-06T23:17:40.725Z",
    "title": "Llasa: Scaling Train-Time and Inference-Time Compute for Llama-based Speech Synthesis",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.04128.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5968
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.04299",
      "authors": [
        {
          "_id": "67a591234020a3bfdb8cb2e5",
          "name": "Jinbo Xing",
          "hidden": false
        },
        {
          "_id": "67a591234020a3bfdb8cb2e6",
          "name": "Long Mai",
          "hidden": false
        },
        {
          "_id": "67a591234020a3bfdb8cb2e7",
          "name": "Cusuh Ham",
          "hidden": false
        },
        {
          "_id": "67a591234020a3bfdb8cb2e8",
          "name": "Jiahui Huang",
          "hidden": false
        },
        {
          "_id": "67a591234020a3bfdb8cb2e9",
          "name": "Aniruddha Mahapatra",
          "hidden": false
        },
        {
          "_id": "67a591234020a3bfdb8cb2ea",
          "name": "Chi-Wing Fu",
          "hidden": false
        },
        {
          "_id": "67a591234020a3bfdb8cb2eb",
          "name": "Tien-Tsin Wong",
          "hidden": false
        },
        {
          "_id": "67a591234020a3bfdb8cb2ec",
          "name": "Feng Liu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-06T18:41:04.000Z",
      "title": "MotionCanvas: Diseño de resúmenes de películas y generación de animación a partir de imágenes controlables",
      "summary": "En este artículo se propone un método para diseñar fotos de video en el contexto de un sistema que genera vídeos a partir de imágenes. El diseño de fotos es un aspecto importante en la producción de películas, ya que implica planificar cuidadosamente el movimiento de la cámara y los movimientos de los objetos en la pantalla. Sin embargo, existen dos principales problemas que impiden que el diseño de fotos sea intuitivo en sistemas actuales que generan vídeos a partir de imágenes: 1. Es necesario especificar junto al movimiento de la cámara el movimiento de los objetos en el espacio de la pantalla para comprender adecuadamente los intereses del usuario. 2. Es necesario que el modelo de difusión de vídeo pueda representar información de movimiento que sea útil para la animación de las imágenes sintéticas. Para resolver estos problemas, se propone la técnica llamada \"MotionCanvas\". Esta técnica integra el control de usuario en modelos que generan vídeo a partir de imágenes, permitiendo controlar el movimiento de los objetos y la cámara en función del contexto de la pantalla. Al integrar la visión clásica de graficas computacionales con las tecnologías modernas de generación de vídeo, MotionCanvas muestra cómo se puede implementar el control de movimiento relacionado con el 3D sin necesidad de datos de entrenamiento costosos, reduciendo así los costos asociados con el control de movimiento 3D en la composición de vídeos. En MotionCanvas, los usuarios pueden expresar de manera intuitiva el movimiento en el espacio de la pantalla, lo cual se puede traducir en señales de condiciones de movimiento espacio-temporales que el modelo de difusión de vídeo puede utilizar. En contenidos reales y en diferentes escenarios de diseño de fotos, demostramos la efectividad de nuestro método, mejorando el flujo de trabajo creativo en la producción de contenido digital y mostrando su aplicabilidad en aplicaciones de edición de imágenes y vídeos.",
      "upvotes": 3,
      "discussionId": "67a5912b4020a3bfdb8cb4d5"
    },
    "publishedAt": "2025-02-06T23:50:54.836Z",
    "title": "MotionCanvas: Cinematic Shot Design with Controllable Image-to-Video Generation",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.04299.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5968
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.03860",
      "authors": [
        {
          "_id": "67a5880c886a1e223b1d57ec",
          "name": "Bo Pang",
          "hidden": false
        },
        {
          "_id": "67a5880c886a1e223b1d57ed",
          "name": "Hanze Dong",
          "hidden": false
        },
        {
          "_id": "67a5880c886a1e223b1d57ee",
          "name": "Jiacheng Xu",
          "hidden": false
        },
        {
          "_id": "67a5880c886a1e223b1d57ef",
          "name": "Silvio Savarese",
          "hidden": false
        },
        {
          "_id": "67a5880c886a1e223b1d57f0",
          "name": "Yingbo Zhou",
          "hidden": false
        },
        {
          "_id": "67a5880c886a1e223b1d57f1",
          "name": "Caiming Xiong",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-06T08:19:59.000Z",
      "title": "BOLT: Diseño de un modelo de lenguaje que no reduce el estop de desaceleración en cadenas de pensamiento largas",
      "summary": "Los modelos de lenguaje grande (LLMs) son conocidos por su capacidad extraordinariamente potente, como demostrada por OpenAI's o1. El modelo o1 genera una larga cadena de pensamiento (LongCoT) antes de presentar una respuesta. La LongCoT permite a los LLMs analizar problemas, planificar, reflexionar y retroceder, mejorando así su capacidad para resolver problemas complejos. Después de la publicación de o1, muchos equipos han intentado reproducir su lógica y LongCoT. Para ello, se ha dependido principalmente de la experiencia de modelos que ya poseen esta capacidad (como OpenAI-o1, Qwen-QwQ, DeepSeek-R1-Preview), pero sigue existiendo incertidumbre sobre el desarrollo sistemático de esta lógica. En términos de datos, se centra principalmente en matemáticas, a veces incluyendo código, limitando la capacidad de generalización. En este artículo, se presenta un nuevo enfoque para desarrollar la capacidad de LongCoT en LLMs, independientemente de experiencias del modelo o anotaciones humanas costosas, como en el caso de o1. Este enfoque comienza con el modelo instumental estándar. BOLT se configura en tres etapas: 1) inicio de datos de LongCoT en el modelo instumental estándar; 2) ajuste de subconjuntos de LongCoT; 3) mejora gradual de la capacidad de LongCoT mediante aprendizaje en línea. En el primer paso, solo es necesario construir unos pocos ejemplos de entrada y salida, pero nuestros experimentos demostraron la posibilidad de crear 10 ejemplos, mostrando la viabilidad de este enfoque. Utilizando Llama-3.1-70B-Instruct, iniciamos el LongCoT y aplicamos este método a diferentes escalas de modelos (7B, 8B, 70B). Evaluamos la capacidad de resolución de tareas y lógica en diferentes marcos de referencia como Arena-Hard, MT-Bench, WildBench, ZebraLogic, y MATH500, alcanzando resultados notables.",
      "upvotes": 3,
      "discussionId": "67a5880e886a1e223b1d58ca"
    },
    "publishedAt": "2025-02-06T23:12:15.874Z",
    "title": "BOLT: Bootstrap Long Chain-of-Thought in Language Models without Distillation",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.03860.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5968
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.04295",
      "authors": [
        {
          "_id": "67a57d32bc587f5b57a3f24f",
          "name": "Yuanye Liu",
          "hidden": false
        },
        {
          "_id": "67a57d32bc587f5b57a3f250",
          "user": {
            "_id": "62abdf657b037eafffc48808",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1655430982462-noauth.jpeg",
            "isPro": false,
            "fullname": "Jiahang Xu",
            "user": "Jiahang",
            "type": "user"
          },
          "name": "Jiahang Xu",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-02-07T03:25:39.760Z",
          "hidden": false
        },
        {
          "_id": "67a57d32bc587f5b57a3f251",
          "name": "Li Lyna Zhang",
          "hidden": false
        },
        {
          "_id": "67a57d32bc587f5b57a3f252",
          "name": "Qi Chen",
          "hidden": false
        },
        {
          "_id": "67a57d32bc587f5b57a3f253",
          "name": "Xuan Feng",
          "hidden": false
        },
        {
          "_id": "67a57d32bc587f5b57a3f254",
          "name": "Yang Chen",
          "hidden": false
        },
        {
          "_id": "67a57d32bc587f5b57a3f255",
          "name": "Zhongxin Guo",
          "hidden": false
        },
        {
          "_id": "67a57d32bc587f5b57a3f256",
          "name": "Yuqing Yang",
          "hidden": false
        },
        {
          "_id": "67a57d32bc587f5b57a3f257",
          "name": "Cheng Peng",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-06T18:36:44.000Z",
      "title": "Optimización del Prompt Integrado para Mejora del Rendimiento de la LLM mediante el Uso de Formatos de Contenido",
      "summary": "Los modelos de lenguaje de gran escala (LLMs) muestran capacidades significativas en diversas tareas, y su efectividad real en el mundo se maneja generalmente a través de la diseño de los prompts. Los recientes estudios se centran en la optimización del contenido de los prompts, pero la formación de los prompts, esencial pero poco destacada, necesita más atención. La formación de los prompts es crucial para el rendimiento de los modelos, aunque a menudo es olvidada. La formación de los prompts es una aspecto fundamental pero a menudo es olvidado. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es una cuestión crucial pero a menudo es olvidada. La formación de los prompts es",
      "upvotes": 3,
      "discussionId": "67a57d33bc587f5b57a3f29d"
    },
    "publishedAt": "2025-02-06T22:27:24.284Z",
    "title": "Beyond Prompt Content: Enhancing LLM Performance via Content-Format Integrated Prompt Optimization",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.04295.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "62abdf657b037eafffc48808",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1655430982462-noauth.jpeg",
      "fullname": "Jiahang Xu",
      "name": "Jiahang",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 8
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.00989",
      "authors": [
        {
          "_id": "67a5c7601e6db426653ebc3d",
          "name": "Kanika Goswami",
          "hidden": false
        },
        {
          "_id": "67a5c7601e6db426653ebc3e",
          "name": "Puneet Mathur",
          "hidden": false
        },
        {
          "_id": "67a5c7601e6db426653ebc3f",
          "name": "Ryan Rossi",
          "hidden": false
        },
        {
          "_id": "67a5c7601e6db426653ebc40",
          "name": "Franck Dernoncourt",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-03T02:00:51.000Z",
      "title": "ChartCitor: Responsabilidad de la visualización de gráficos de céntricos en un marco de agentes de detalle",
      "summary": "Los modelos de lenguaje grande (LLMs) pueden responder a preguntas en un chatbot, pero a menudo generan palabras sin fundamento. Los métodos actuales de evaluación de respuestas no pueden adaptarse a los contextos visuales y semánticos limitados del chatbot, lo que dificulta la respuesta a frases visuales complejas y la predicción de cajas en layouts complejos. Presentamos un marco de trabajo multi-agente llamado \"ChartCitor\" que identifica evidencias dentro de imágenes de chatbots y proporciona referencias a cajas detalladas. Este sistema colabora los agentes de LLM para extraer tablas, reorganizar respuestas, expandir tablas, predecir y rescalar, buscando evidencias y mapeando las respuestas a las tablas. \"ChartCitor\" es factible en diferentes tipos de chatbots y puede superar los límites actuales. En un entorno de usuario, \"ChartCitor\" mejora la comprensión de las respuestas de chatbots basadas en LLMs, aumentando la confianza en la IA y la productividad de los expertos.",
      "upvotes": 2,
      "discussionId": "67a5c7621e6db426653ebc8a"
    },
    "publishedAt": "2025-02-07T03:42:17.799Z",
    "title": "ChartCitor: Multi-Agent Framework for Fine-Grained Chart Visual Attribution",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.00989.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "62c5947524171688a9feb992",
      "avatarUrl": "/avatars/5a151713b9eae8dc566f5957acee3475.svg",
      "fullname": "Franck Dernoncourt",
      "name": "Franck-Dernoncourt",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 7
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.04322",
      "authors": [
        {
          "_id": "67a5a9357415f9155e9b4b58",
          "name": "Yik Siu Chan",
          "hidden": false
        },
        {
          "_id": "67a5a9357415f9155e9b4b59",
          "user": {
            "_id": "64698ed0dcbb937d56b9dd02",
            "avatarUrl": "/avatars/835ce9bf6e2cd1d4b7a709cf41a884e2.svg",
            "isPro": false,
            "fullname": "Edward Ri",
            "user": "narutatsuri",
            "type": "user"
          },
          "name": "Narutatsu Ri",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-07T09:57:58.519Z",
          "hidden": false
        },
        {
          "_id": "67a5a9357415f9155e9b4b5a",
          "user": {
            "_id": "64bf072bae436c8813494ba3",
            "avatarUrl": "/avatars/afb96d2bbf90411f4b1a030ebebff300.svg",
            "isPro": false,
            "fullname": "Yuxin Xiao",
            "user": "YuxinXiao",
            "type": "user"
          },
          "name": "Yuxin Xiao",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-07T09:58:00.910Z",
          "hidden": false
        },
        {
          "_id": "67a5a9357415f9155e9b4b5b",
          "name": "Marzyeh Ghassemi",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-06T18:59:02.000Z",
      "title": "\"Speech Ieee: Extracción de Brakes de Utensilios Pésimos a Partir de Interacciones Simples en LLM\"",
      "summary": "Un amplio ajuste de seguridad ha hecho que los modelos de lenguaje de grandes escala (LLMs) estén fácilmente expuestos a comportamientos perjudiciales y ataques maliciosos. La mayoría de los estudios actuales se centran en métodos de ataque que requieren conocimientos técnicos, pero dos problemas importantes no han sido suficientemente investigados: 1) ¿Se pueden realizar comportamientos perjudiciales mediante ataques maliciosos para usuarios normales? 2) ¿Existen vulnerabilidades de seguridad comunes y sencillas en la interacción humano-LLM? En este artículo, se muestran las dos propiedades clave que deben tener las respuestas de un LLM para promover comportamientos perjudiciales. Basándose en esta perspectiva, se propone un índice de ataque malicioso \"HarmScore\" para evaluar cómo promueven comportamientos perjudiciales y un marco de ataque multi-paso y multilingüe sencillo llamado \"Speak Easy\". En particular, cuando \"Speak Easy\" se utiliza directamente como solicitud y se agrega un benchmark de ataque malicioso, los modelos abiertos y los modelos de venta experimentan un aumento promedio del 0.319 en la tasa de éxito del ataque y un aumento del 0.426 en el \"HarmScore\" en cuatro pruebas de seguridad. Nuestro estudio revela importantes vulnerabilidades de seguridad: los usuarios maliciosos pueden facilmente explotar patrones comunes de interacción para alcanzar objetivos perjudiciales.",
      "upvotes": 2,
      "discussionId": "67a5a9367415f9155e9b4bbb"
    },
    "publishedAt": "2025-02-07T01:37:25.953Z",
    "title": "Speak Easy: Eliciting Harmful Jailbreaks from LLMs with Simple Interactions",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.04322.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64bf072bae436c8813494ba3",
      "avatarUrl": "/avatars/afb96d2bbf90411f4b1a030ebebff300.svg",
      "fullname": "Yuxin Xiao",
      "name": "YuxinXiao",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.04235",
      "authors": [
        {
          "_id": "67a56af6d7c26c7497a86308",
          "user": {
            "_id": "64b764bffdb702b3d8640610",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64b764bffdb702b3d8640610/lpHg0AX_NOmzw-ZxeOa1s.png",
            "isPro": false,
            "fullname": "haoxintong",
            "user": "haoxintong",
            "type": "user"
          },
          "name": "Xintong Hao",
          "status": "extracted_confirmed",
          "statusLastChangedAt": "2025-02-07T04:41:11.249Z",
          "hidden": false
        },
        {
          "_id": "67a56af6d7c26c7497a86309",
          "name": "Ke Shen",
          "hidden": false
        },
        {
          "_id": "67a56af6d7c26c7497a8630a",
          "name": "Chenggang Li",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-06T17:19:55.000Z",
      "title": "MAGA: MA Granjeador Administrador Formador Técnico de la Formación Previa y Extensión del Conjunto de Datos Previos",
      "summary": "El modelo de lenguaje general muestra una excelente capacidad en diversas tareas, pero su escalabilidad continua está limitada por la escasez de datos de entrenamiento de alta calidad. Aunque la arquitectura del modelo sigue evolucionando, la escalabilidad de los datos de lenguaje natural se retrasa. Para resolver estos problemas, proponemos un método de redesign denominado MAassive Genre-Audience (MAGA). Este método permite la síntesis sistemática de datos de entrenamiento previo ricos en contexto y variados a partir de los corpus actuales. Este estudio resume tres contribuciones principales: (1) la propuesta del método de redesign MAGA, la construcción de una aproximación ligera y escalable para la expansión de los corpus de entrenamiento previo, y la creación de un corpus MAGA de 770B tokens. (2) La evaluación del corpus MAGA utilizando diferentes estrategias de escalabilidad de bases de datos, mostrando mejoras consistentes en diferentes tamaños de modelo (134M-13B) y demostrando la necesidad de modelos de lenguaje de entrenamiento previo de gran escala en futuras generaciones. (3) Un análisis detallado que investiga la influencia de la ingeniería de procesamiento sobre el desgaste de entrenamiento y revela las limitaciones de los métricas tradicionales de detección de desgaste basadas en pérdidas de evaluación. Nuestro estudio muestra que MAGA puede ampliar significativamente la cantidad de datos de entrenamiento mientras mantiene la calidad. Ofrece una clave segura para la escalabilidad de modelos, superando las limitaciones de los datos.",
      "upvotes": 1,
      "discussionId": "67a56af8d7c26c7497a86359"
    },
    "publishedAt": "2025-02-07T00:56:20.873Z",
    "title": "MAGA: MAssive Genre-Audience Reformulation to Pretraining Corpus Expansion",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.04235.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64b764bffdb702b3d8640610",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64b764bffdb702b3d8640610/lpHg0AX_NOmzw-ZxeOa1s.png",
      "fullname": "haoxintong",
      "name": "haoxintong",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.04270",
      "authors": [
        {
          "_id": "67a5882fa8e877ef10b8d1fd",
          "name": "Yunzhen Feng",
          "hidden": false
        },
        {
          "_id": "67a5882fa8e877ef10b8d1fe",
          "name": "Ariel Kwiatkowski",
          "hidden": false
        },
        {
          "_id": "67a5882fa8e877ef10b8d1ff",
          "name": "Kunhao Zheng",
          "hidden": false
        },
        {
          "_id": "67a5882fa8e877ef10b8d200",
          "name": "Julia Kempe",
          "hidden": false
        },
        {
          "_id": "67a5882fa8e877ef10b8d201",
          "name": "Yaqi Duan",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-06T18:09:00.000Z",
      "title": "PILAF: Modelo de recompensa por muestreo de intereses humanos adecuados",
      "summary": "El lenguaje de lenguaje general se ha convertido en una tarea importante para que las aplicaciones realistas se ejecuten de manera consistente con las valores humanos. La aprendizaje por refuerzo con retroalimentación humana (RLHF) ha surgido como una tecnología crucial, y es necesario traducir datos de preferencia a modelos de recompensa cuando no es posible acceder a los valores humanos. De manera práctica, el RLHF se basa principalmente en modelos de recompensa aproximados, pero estos modelos no pueden guiar políticas que maximicen los valores del usuario de manera coherente. Proponemos PILAF (Aprendizaje de Políticas Interpoladas para Retroalimentación Alineada). PILAF utiliza muestras de respuestas de etiquetas de preferencia para proporcionar un nuevo enfoque claro que maximiza explicitamente los valores humanos, alineando claramente el aprendizaje de preferencias. PILAF está construido teóricamente, y se demuestra su óptimalidad desde los puntos de vista de la óptimidad y estadística. Este método es sencillo de implementar y muestra un rendimiento fuerte en entornos RLHF online y iterativos donde la edición de retroalimentación es crucial.",
      "upvotes": 1,
      "discussionId": "67a58830a8e877ef10b8d226"
    },
    "publishedAt": "2025-02-06T23:13:23.158Z",
    "title": "PILAF: Optimal Human Preference Sampling for Reward Modeling",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.04270.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "65cbfa6c968742be942e6cba",
      "avatarUrl": "/avatars/1a6cc0983edc28fa92178d3abc283ba1.svg",
      "fullname": "Feng",
      "name": "Yunzhen",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.03639",
      "authors": [
        {
          "_id": "67a59193f86e1b9d7ae7cd55",
          "name": "Yunuo Chen",
          "hidden": false
        },
        {
          "_id": "67a59193f86e1b9d7ae7cd56",
          "name": "Junli Cao",
          "hidden": false
        },
        {
          "_id": "67a59193f86e1b9d7ae7cd57",
          "name": "Anil Kag",
          "hidden": false
        },
        {
          "_id": "67a59193f86e1b9d7ae7cd58",
          "name": "Vidit Goel",
          "hidden": false
        },
        {
          "_id": "67a59193f86e1b9d7ae7cd59",
          "name": "Sergei Korolev",
          "hidden": false
        },
        {
          "_id": "67a59193f86e1b9d7ae7cd5a",
          "name": "Chenfanfu Jiang",
          "hidden": false
        },
        {
          "_id": "67a59193f86e1b9d7ae7cd5b",
          "name": "Sergey Tulyakov",
          "hidden": false
        },
        {
          "_id": "67a59193f86e1b9d7ae7cd5c",
          "name": "Jian Ren",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-05T21:49:06.000Z",
      "title": "El método de normalización de puntos 3D con objetivo de comprensión física",
      "summary": "Aquí se presenta un nuevo marco de trabajo para la generación de vídeos. Este marco integra el árbol tridimensional y la reconocción dinámica. Para ello, se agrega a la vídeo bidimensional una trayectoria de puntos en tres dimensiones y se ajusta este en el espacio de píxeles de acuerdo con el objetivo. De esta manera, se obtiene un conjunto de vídeos con reconocimiento tridimensional, llamado PointVid, que se utiliza para finejar modelos de diferenciación potencial y para seguir objetos bidimensionales en coordenadas cartesianas tridimensionales. Basándose en esto, se normalizan la forma y el comportamiento de los objetos en el vídeo y se eliminan áreas inadecuadas, como por ejemplo, transformaciones físicas. De esta manera, se mejora la calidad del vídeo RGB RGB y se resuelven problemas comunes como la deformación de la forma de los objetos debido a la falta de reconocimiento de forma en modelos de vídeo actuales. Gracias a la adición tridimensional y la normalización, el modelo puede manejar escenarios ricos en contacto. Estos vídeos incluyen interacciones complejas necesarias para la comprensión de la forma y el reconocimiento de contacto. Además, el modelo promueve la coherencia dinámica, reduce rápidas transformaciones de forma y acción, y mejora la calidad general de la generación de vídeo.",
      "upvotes": 0,
      "discussionId": "67a59195f86e1b9d7ae7cd97"
    },
    "publishedAt": "2025-02-06T23:52:49.331Z",
    "title": "Towards Physical Understanding in Video Generation: A 3D Point Regularization Approach",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.03639.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5968
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.04296",
      "authors": [
        {
          "_id": "67a57a4637e2abc28667ec1b",
          "name": "Lirui Wang",
          "hidden": false
        },
        {
          "_id": "67a57a4637e2abc28667ec1c",
          "name": "Kevin Zhao",
          "hidden": false
        },
        {
          "_id": "67a57a4637e2abc28667ec1d",
          "name": "Chaoqi Liu",
          "hidden": false
        },
        {
          "_id": "67a57a4637e2abc28667ec1e",
          "name": "Xinlei Chen",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-06T18:38:26.000Z",
      "title": "Aprende la dinámica de videos de acciones con mascarillas híbridos",
      "summary": "Se propone HMA (Homojonion Masked Autoencoder). HMA modela la dinámica de videos de acciones para lograr la generación y evaluación de datos de alta calidad en el aprendizaje de robots. La construcción de modelos de video mundo interactivos y políticas para robots es difícil debido a que deben mantenerse eficientes en términos de cálculo temporal mientras trabajan en diferentes configuraciones. HMA utiliza pretrenamiento heterogeno a partir de secuencias de observaciones y acciones de observaciones y acciones de diferentes robots, dominios y tareas. HMA utiliza el auto-regresso con mascara para caracterizar o generar tokenes suaves. Comparado con modelos anteriores de generación de videos de robots, HMA logra la mayor precisión visual y posibilidad de control, y funciona 15 veces más rápido en el mundo real. Después del entrenamiento posterior, este modelo puede ser utilizado como simulador de video a partir de entradas de acciones de bajo nivel, ayudando en la evaluación de políticas y la generación de datos sintéticos. Para más información, consulte: https://liruiw.github.io/hma",
      "upvotes": 0,
      "discussionId": "67a57a4737e2abc28667ec58"
    },
    "publishedAt": "2025-02-06T22:17:36.193Z",
    "title": "Learning Real-World Action-Video Dynamics with Heterogeneous Masked Autoregression",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.04296.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "63151385b031f7b1c7c0871c",
      "avatarUrl": "/avatars/0088eb929866face5f95218943e3f478.svg",
      "fullname": "Lirui Wang",
      "name": "liruiw",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 4
    },
    "isAuthorParticipating": false
  }
]