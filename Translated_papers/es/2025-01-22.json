[
  {
    "paper": {
      "id": "2501.12380",
      "authors": [
        {
          "_id": "67906f432565fc5140d72dc3",
          "name": "Yilun Zhao",
          "hidden": false
        },
        {
          "_id": "67906f432565fc5140d72dc4",
          "name": "Lujing Xie",
          "hidden": false
        },
        {
          "_id": "67906f432565fc5140d72dc5",
          "name": "Haowei Zhang",
          "hidden": false
        },
        {
          "_id": "67906f432565fc5140d72dc6",
          "name": "Guo Gan",
          "hidden": false
        },
        {
          "_id": "67906f432565fc5140d72dc7",
          "name": "Yitao Long",
          "hidden": false
        },
        {
          "_id": "67906f432565fc5140d72dc8",
          "name": "Zhiyuan Hu",
          "hidden": false
        },
        {
          "_id": "67906f432565fc5140d72dc9",
          "name": "Tongyan Hu",
          "hidden": false
        },
        {
          "_id": "67906f432565fc5140d72dca",
          "name": "Weiyuan Chen",
          "hidden": false
        },
        {
          "_id": "67906f432565fc5140d72dcb",
          "name": "Chuhan Li",
          "hidden": false
        },
        {
          "_id": "67906f432565fc5140d72dcc",
          "name": "Junyang Song",
          "hidden": false
        },
        {
          "_id": "67906f432565fc5140d72dcd",
          "name": "Zhijian Xu",
          "hidden": false
        },
        {
          "_id": "67906f432565fc5140d72dce",
          "name": "Chengye Wang",
          "hidden": false
        },
        {
          "_id": "67906f432565fc5140d72dcf",
          "name": "Weifeng Pan",
          "hidden": false
        },
        {
          "_id": "67906f432565fc5140d72dd0",
          "name": "Ziyao Shangguan",
          "hidden": false
        },
        {
          "_id": "67906f432565fc5140d72dd1",
          "name": "Xiangru Tang",
          "hidden": false
        },
        {
          "_id": "67906f432565fc5140d72dd2",
          "name": "Zhenwen Liang",
          "hidden": false
        },
        {
          "_id": "67906f432565fc5140d72dd3",
          "name": "Yixin Liu",
          "hidden": false
        },
        {
          "_id": "67906f432565fc5140d72dd4",
          "name": "Chen Zhao",
          "hidden": false
        },
        {
          "_id": "67906f432565fc5140d72dd5",
          "name": "Arman Cohan",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-21T18:56:18.000Z",
      "title": "MMVU: Evaluación de comprensión de videos en diversos campos académicos a nivel profesional",
      "summary": "MMVU es un marco de referencia profesional especializado para evaluar la comprensión de videos. MMVU proporciona 3,000 preguntas con notaciones de expertos en 27 temas distribuidos en 4 áreas clave: ciencia, medicina, humanidades y ciencias sociales, y ingeniería. Comparado con otros marcos de referencia, MMVU destaca por tres desarrollos principales. Primero, se enfoca en que los modelos apliquen conocimientos específicos de un campo para analizar videos profesionales con razones basadas en conocimientos profesionales, superando la reconocimiento visual general en los marcos de referencia de video. Segundo, cada ejemplo comienza con una notación de un experto, garantizando un alto nivel de calidad de los datos a través de un rigoroso manejo de la calidad de datos. Tercero, cada ejemplo promueve una análisis detallado al agregar conocimientos relacionados con las razones y conocimientos del campo escritos por expertos. Se evaluaron 32 modelos líderes en MMVU, donde el modelo o1 de la capacidad 2 de la nueva sistema y Gemini 2.0 Flash Thinking mostraron los mejores resultados. Sin embargo, aún no completan la competencia de los expertos. El análisis de errores específicos y estudios de caso proporcionan una riqueza práctica para el desarrollo futuro de la comprensión de videos en campos especializados con conocimientos densos.",
      "upvotes": 23,
      "discussionId": "67906f442565fc5140d72e4a"
    },
    "publishedAt": "2025-01-21T23:19:52.256Z",
    "title": "MMVU: Measuring Expert-Level Multi-Discipline Video Understanding",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.12380.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "62f662bcc58915315c4eccea",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62f662bcc58915315c4eccea/zOAQLONfMP88zr70sxHK-.jpeg",
      "fullname": "Yilun",
      "name": "yilunzhao",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isMod": false,
      "followerCount": 5
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.11425",
      "authors": [
        {
          "_id": "679080298ad1d8203a994f7f",
          "name": "Siyu Yuan",
          "hidden": false
        },
        {
          "_id": "679080298ad1d8203a994f80",
          "name": "Zehui Chen",
          "hidden": false
        },
        {
          "_id": "679080298ad1d8203a994f81",
          "name": "Zhiheng Xi",
          "hidden": false
        },
        {
          "_id": "679080298ad1d8203a994f82",
          "name": "Junjie Ye",
          "hidden": false
        },
        {
          "_id": "679080298ad1d8203a994f83",
          "name": "Zhengyin Du",
          "hidden": false
        },
        {
          "_id": "679080298ad1d8203a994f84",
          "name": "Jiecao Chen",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-20T11:46:04.000Z",
      "title": "Agent-R: Entrenamiento de modelos de lenguaje de agentes a través del aprendizaje auto-recurrente repetitivo",
      "summary": "Los agentes de modelos de lenguaje grande (LLMs) desempeñan un papel importante en la resolución de tareas complejas en entornos de interacción. La investigación actual se centra principalmente en mejorar el rendimiento a través del cronocrímineto de acciones de fuertes expertos, pero este enfoque falla en la recuperación de errores en aplicaciones reales. Sin embargo, la recopilación de datos de evaluación de pasos es difícil y costosa. Por lo tanto, es crucial construir automáticamente conjuntos de datos de evaluación dinámicos para mejorar la capacidad inteligente de los agentes. En este estudio, proponemos un marco de entrenamiento iterativo que permita que los agentes de lenguaje reflejen inmediatamente, llamado Agent-R. A diferencia de los métodos existentes, Agent-R construye datos de entrenamiento mediante MCTS, utilizando rutas que llevan a errores para construir rutas correctas. Una de las principales cuestiones durante el proceso de reflexión del agente es la necesidad de modificar las rutas en tiempo real, sin esperar hasta el final. Para abordar esto, introducimos una estructura de evaluación guiada por modelos: el modelo contador identifica el primer error en la ruta fallida (dentro del rango de capacidades actuales) y, a partir de ahí, distribuye rutas precisas cercanas, de manera que los nodos padres sean iguales. Esta estrategia permite que el modelo aprenda a reflejar sobre su política actual y realice un aprendizaje más eficiente. Además, exploramos la escalabilidad de este paradigma de mejora automática investigando la optimización iterativa de la capacidad de corrección de errores y la construcción de conjuntos de datos de evaluación. Nuestros resultados muestran que Agent-R continuamente mejora la capacidad de recuperación de errores del modelo y permite la modificación de errores en tiempo real. Experimentos en tres entornos de interacción demuestran que Agent-R funciona efectivamente para corregir errores y alcanza un rendimiento superior al método de referencia (+5.59%).",
      "upvotes": 13,
      "discussionId": "6790802b8ad1d8203a994fc7"
    },
    "publishedAt": "2025-01-22T00:20:57.292Z",
    "title": "Agent-R: Training Language Model Agents to Reflect via Iterative Self-Training",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.11425.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5732
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.12273",
      "authors": [
        {
          "_id": "67906c674932687e24e0cc08",
          "name": "Maosong Cao",
          "hidden": false
        },
        {
          "_id": "67906c674932687e24e0cc09",
          "name": "Taolin Zhang",
          "hidden": false
        },
        {
          "_id": "67906c674932687e24e0cc0a",
          "name": "Mo Li",
          "hidden": false
        },
        {
          "_id": "67906c674932687e24e0cc0b",
          "name": "Chuyu Zhang",
          "hidden": false
        },
        {
          "_id": "67906c674932687e24e0cc0c",
          "name": "Yunxin Liu",
          "hidden": false
        },
        {
          "_id": "67906c674932687e24e0cc0d",
          "name": "Haodong Duan",
          "hidden": false
        },
        {
          "_id": "67906c674932687e24e0cc0e",
          "name": "Songyang Zhang",
          "hidden": false
        },
        {
          "_id": "67906c674932687e24e0cc0f",
          "name": "Kai Chen",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-21T16:44:12.000Z",
      "title": "Cóndor: Mejora del rendimiento de los modelos de lenguaje de inteligencia artificial mediante la síntesis y edición de datos basada en el conocimiento",
      "summary": "La calidad de los datos de Fine-Tuning Supervisado (SFT) juega un papel crucial en la mejora de las habilidades de conversación de los Modelos de Lenguaje Grandes (LLMs). Sin embargo, al evolucionar los LLMs, la capacidad de utilizar datos de SFT con alta calidad y annotados por humanos se ha convertido en una limitante importante, lo que ha aumentado la dependencia de los datos sintéticos. En este artículo, se presenta un nuevo marco de trabajo de generación de datos sintéticos en dos etapas, llamado Condor, que combina el Árbol de Conocimientos Mundiales y la Reflexión Auto-Refinamiento. Este marco de trabajo tiene como objetivo la generación de datos de SFT de alta calidad y escalable. Los resultados de los experimentos muestran que aplicando 20K muestras generadas por Condor al modelo base, se obtiene un desempeño excepcional y se confirma que supera a otros modelos comparativos. Los pasos adicionales de mejora de Condor permiten una mejora automática iterativa en diferentes escalas de LLMs (hasta 72B), demostrando la efectividad de nuestro enfoque. Además, la investigación sobre la escalabilidad de los datos sintéticos muestra una gran posibilidad de mejora en el rendimiento después del entrenamiento, abriéndose caminos prometedores para futuras investigaciones.",
      "upvotes": 7,
      "discussionId": "67906c684932687e24e0cc61"
    },
    "publishedAt": "2025-01-21T22:56:36.701Z",
    "title": "Condor: Enhance LLM Alignment with Knowledge-Driven Data Synthesis and Refinement",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.12273.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "630716d11801ecc7d2595021",
      "avatarUrl": "/avatars/2d36a880ce4a3cf7efc5ff3987dbeaf3.svg",
      "fullname": "Songyang Zhang",
      "name": "zsytony",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 14
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.11733",
      "authors": [
        {
          "_id": "6790791b203b95acf96ebf45",
          "user": {
            "_id": "628d7265db4cd1d1717c884f",
            "avatarUrl": "/avatars/dff2a3dd10d84b4a73fa486402de7219.svg",
            "isPro": false,
            "fullname": "Zhenhailong Wang",
            "user": "mikewang",
            "type": "user"
          },
          "name": "Zhenhailong Wang",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-01-22T04:50:40.468Z",
          "hidden": false
        },
        {
          "_id": "6790791b203b95acf96ebf46",
          "name": "Haiyang Xu",
          "hidden": false
        },
        {
          "_id": "6790791b203b95acf96ebf47",
          "name": "Junyang Wang",
          "hidden": false
        },
        {
          "_id": "6790791b203b95acf96ebf48",
          "name": "Xi Zhang",
          "hidden": false
        },
        {
          "_id": "6790791b203b95acf96ebf49",
          "name": "Ming Yan",
          "hidden": false
        },
        {
          "_id": "6790791b203b95acf96ebf4a",
          "name": "Ji Zhang",
          "hidden": false
        },
        {
          "_id": "6790791b203b95acf96ebf4b",
          "name": "Fei Huang",
          "hidden": false
        },
        {
          "_id": "6790791b203b95acf96ebf4c",
          "name": "Heng Ji",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-20T20:35:46.000Z",
      "title": "Móvil-agente-E: Automático para tareas complejas de asistente móvil",
      "summary": "El smartphone ha adquirido la posición de elemento esencial en la vida moderna, pero a veces se siente insatisfecho cuando se trata de realizar tareas complejas. Recientemente, el desarrollo de agentes móviles basados en modelos de grandes multimodales (LMM) ha demostrado la posibilidad de reconocimiento y acción en entornos móviles. Sin embargo, el enfoque actual presenta limitaciones: no satisface las necesidades reales de las personas, es difícil procesar tareas lógicas y de largo plazo, y no tiene una estructura que permita aprender y mejorar a partir de experiencias anteriores. Para resolver estos problemas, se presenta el framework de agentes móviles evolutivos, Mobile-Agent-E, que se inspira en experiencias pasadas y que puede autoevolucionar. El término \"heurístico\" se refiere a la clara diferenciación entre la planificación de alto nivel y la ejecución de acciones de bajo nivel. Este framework se compone de cuatro agentes subordinados: Manager, Perceptor, Operator, Action Reflector y Notetaker. El Perceptor se encarga de la reconocimiento visual detallado, el Operator de la ejecución inmediata de acciones, el Action Reflector de la verificación de errores y el Notetaker de la recopilación de información. Mobile-Agent-E introduce un nuevo módulo de autoevolución que se constituye en consejos generales y enseñanzas obtenidas de trabajos anteriores, así como en una lista de operaciones primitivas reutilizables para subrutinas específicas. La introducción de consejos y cortocircuitos permite la mejora continua de rendimiento y eficiencia. Además, se presenta Mobile-Eval-E, un nuevo marco de referencia que incluye tareas de largo plazo y la interacción entre varias aplicaciones. Los resultados de los experimentos muestran que Mobile-Agent-E, a través de tres modelos básicos, logra un aumento absoluto del 22% en comparación con los métodos óptimos anteriores. El sitio web del proyecto está disponible en https://x-plug.github.io/MobileAgent.",
      "upvotes": 5,
      "discussionId": "67907920203b95acf96ec126"
    },
    "publishedAt": "2025-01-22T00:17:48.799Z",
    "title": "Mobile-Agent-E: Self-Evolving Mobile Assistant for Complex Tasks",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.11733.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "645b10e80c73ea27d13f7aca",
      "avatarUrl": "/avatars/95e565306472a15067440b5b43e07a6f.svg",
      "fullname": "xuhaiyang",
      "name": "xhyandwyy",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.10687",
      "authors": [
        {
          "_id": "6790856e3b0a6384a4117d0e",
          "name": "Linrui Tian",
          "hidden": false
        },
        {
          "_id": "6790856e3b0a6384a4117d0f",
          "name": "Siqi Hu",
          "hidden": false
        },
        {
          "_id": "6790856e3b0a6384a4117d10",
          "name": "Qi Wang",
          "hidden": false
        },
        {
          "_id": "6790856e3b0a6384a4117d11",
          "name": "Bang Zhang",
          "hidden": false
        },
        {
          "_id": "6790856e3b0a6384a4117d12",
          "name": "Liefeng Bo",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-18T07:51:29.000Z",
      "title": "EMO2: End-Effector Laser Drive Live Body Audio Generation",
      "summary": "En este artículo se propone una nueva técnica de cabeza de tabla de voz. Esta técnica puede generar altas calidades de expresiones faciales y movimientos de manos al mismo tiempo. Los métodos existentes se centraban en la generación de toda o la mitad de la posición, pero nosotros consideramos que la relación débil entre las características del habla y los movimientos de las manos es un límite principal, lo cual resolvimos redefiniendo el proceso en dos etapas. En la primera etapa, se genera la posición de las manos directamente a partir del habla, utilizando la fuerte asociación entre el habla y los movimientos de las manos. En la segunda etapa, se utiliza un modelo de dispersión para sintetizar los frame de video incluyendo la posición de las manos generada, creando expresiones realistas y movimientos corporales. Los resultados de los experimentos muestran que la propuesta es superior en calidad visual y precisión de sincronización a los métodos más avanzados (CyberHost, Vlogger). Esta investigación ofrece una nueva perspectiva en la generación de manipulación de voz y proporciona un sólido marco para la creación de animaciones de cabeza de tabla expresivas y naturales.",
      "upvotes": 3,
      "discussionId": "679085813b0a6384a41183f1"
    },
    "publishedAt": "2025-01-22T00:49:10.316Z",
    "title": "EMO2: End-Effector Guided Audio-Driven Avatar Video Generation",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.10687.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "65df1f1ee98700500d4c289c",
      "avatarUrl": "/avatars/be11bf61465df29ac997cc0fedad1cb9.svg",
      "fullname": "qi wang",
      "name": "lucaskingjade",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.12326",
      "authors": [
        {
          "_id": "679078f902b4d94b0f2347c1",
          "name": "Yujia Qin",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347c2",
          "name": "Yining Ye",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347c3",
          "name": "Junjie Fang",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347c4",
          "name": "Haoming Wang",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347c5",
          "name": "Shihao Liang",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347c6",
          "name": "Shizuo Tian",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347c7",
          "name": "Junda Zhang",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347c8",
          "name": "Jiahao Li",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347c9",
          "name": "Yunxin Li",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347ca",
          "name": "Shijue Huang",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347cb",
          "name": "Wanjun Zhong",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347cc",
          "name": "Kuanye Li",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347cd",
          "name": "Jiale Yang",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347ce",
          "name": "Yu Miao",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347cf",
          "name": "Woyu Lin",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347d0",
          "name": "Longxiang Liu",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347d1",
          "name": "Xu Jiang",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347d2",
          "name": "Qianli Ma",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347d3",
          "name": "Jingyu Li",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347d4",
          "name": "Xiaojun Xiao",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347d5",
          "name": "Kai Cai",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347d6",
          "name": "Chuang Li",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347d7",
          "name": "Yaowei Zheng",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347d8",
          "name": "Chaolin Jin",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347d9",
          "name": "Chen Li",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347da",
          "name": "Xiao Zhou",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347db",
          "name": "Minchao Wang",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347dc",
          "name": "Haoli Chen",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347dd",
          "name": "Zhaojian Li",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347de",
          "name": "Haihua Yang",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347df",
          "name": "Haifeng Liu",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347e0",
          "name": "Feng Lin",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347e1",
          "name": "Tao Peng",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347e2",
          "name": "Xin Liu",
          "hidden": false
        },
        {
          "_id": "679078f902b4d94b0f2347e3",
          "name": "Guang Shi",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-21T17:48:10.000Z",
      "title": "UI-TARS: Guía de producción líder en la interacción de UI-TARS",
      "summary": "En este artículo, se presenta un modelo de inteligencia artificial (IA) llamado \"UI-TARS\", que se utiliza para procesar capturas de pantalla como entrada directa, pero que también puede interactuar de manera humana. Este modelo, \"UI-TARS\", supera a modelos profesionales como GPT-4o que dependen de modelos de negocios repetitivos, demostrando una excelente performance en tareas de frontend. Los experimentos realizados en más de 10 marcos de referencia de agentes de GUI para evaluar exploración visual, tareas de GUI y evaluación de profundidad, demostraron que \"UI-TARS\" es el mejor en su clase. En particular, en el OSWorld benchmark, alcanzó un puntaje de 24.6 en 50 etapas y 22.7 en 15 etapas, superando a Claude (22.0 y 14.9). En AndroidWorld, alcanzó un puntaje de 46.6, superando a GPT-4o (34.5). \"UI-TARS\" introduce las siguientes novedades: (1) visualización expandida: utiliza grandes conjuntos de datos de capturas de pantalla para comprender y capturar precisamente los elementos de la interfaz de usuario (UI) en su contexto. (2) modelado integrado de acciones: uniforma las acciones entre plataformas y realiza exploración profunda e interacción precisas a través de gran cantidad de trazas de acciones. (3) razonamiento de sistema 2: incluye la percepción de razones incorrectas en decisiones multi-etapa, y incorpora patrones de razonamiento como decomposición de tareas, pensamiento reflexivo y reconocimiento de milestones, logrando una percepción que incluye múltiples razones. (4) aprendizaje iterativo mediante trazas online reflexivas: recoge, filtra y mejora automáticamente nuevas interacciones en base a miles de máquinas básicas, resuelviendo problemas de datos y adaptándose a situaciones inesperadas con minimo intervención humana. A través del análisis del camino de evolución de los agentes de GUI y su guia para el desarrollo de la tecnología, \"UI-TARS\" contribuye a la evolución de este campo.",
      "upvotes": 3,
      "discussionId": "679078ff02b4d94b0f2348e0"
    },
    "publishedAt": "2025-01-21T23:51:53.248Z",
    "title": "UI-TARS: Pioneering Automated GUI Interaction with Native Agents",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.12326.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5732
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.11223",
      "authors": [
        {
          "_id": "6790772b8d7df822f1fb4405",
          "name": "Maciej Besta",
          "hidden": false
        },
        {
          "_id": "6790772b8d7df822f1fb4406",
          "name": "Julia Barth",
          "hidden": false
        },
        {
          "_id": "6790772b8d7df822f1fb4407",
          "name": "Eric Schreiber",
          "hidden": false
        },
        {
          "_id": "6790772b8d7df822f1fb4408",
          "name": "Ales Kubicek",
          "hidden": false
        },
        {
          "_id": "6790772b8d7df822f1fb4409",
          "name": "Afonso Catarino",
          "hidden": false
        },
        {
          "_id": "6790772b8d7df822f1fb440a",
          "name": "Robert Gerstenberger",
          "hidden": false
        },
        {
          "_id": "6790772b8d7df822f1fb440b",
          "name": "Piotr Nyczyk",
          "hidden": false
        },
        {
          "_id": "6790772b8d7df822f1fb440c",
          "name": "Patrick Iff",
          "hidden": false
        },
        {
          "_id": "6790772b8d7df822f1fb440d",
          "name": "Yueling Li",
          "hidden": false
        },
        {
          "_id": "6790772b8d7df822f1fb440e",
          "name": "Sam Houliston",
          "hidden": false
        },
        {
          "_id": "6790772b8d7df822f1fb440f",
          "name": "Tomasz Sternal",
          "hidden": false
        },
        {
          "_id": "6790772b8d7df822f1fb4410",
          "name": "Marcin Copik",
          "hidden": false
        },
        {
          "_id": "6790772b8d7df822f1fb4411",
          "name": "Grzegorz Kwaśniewski",
          "hidden": false
        },
        {
          "_id": "6790772b8d7df822f1fb4412",
          "name": "Jürgen Müller",
          "hidden": false
        },
        {
          "_id": "6790772b8d7df822f1fb4413",
          "name": "Łukasz Flis",
          "hidden": false
        },
        {
          "_id": "6790772b8d7df822f1fb4414",
          "name": "Hannes Eberhard",
          "hidden": false
        },
        {
          "_id": "6790772b8d7df822f1fb4415",
          "name": "Hubert Niewiadomski",
          "hidden": false
        },
        {
          "_id": "6790772b8d7df822f1fb4416",
          "name": "Torsten Hoefler",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-20T02:16:19.000Z",
      "title": "Modelo de lenguaje de Riensing: Plan format",
      "summary": "Los modelos denominados de Razonamiento de Lenguaje (RLMs) o Grandes Modelos de Razonamiento (LRMs) han redefinido la capacidad de resolución de problemas de los Grandes Modelos de Lenguaje (LLMs) agregando estructuras lógicas evolutivas. Sin embargo, la alta costo, propiedad, complejidad de la arquitectura, especialmente el aprendizaje por refuerzo (RL), heurísticas de exploración y la combinación con LLMs, generan problemas de accesibilidad y expansión. Para resolver estos problemas, se propone un plan unificado para integrar los componentes de RLMs en un marco modularizado. Este plan se basa en la investigación y análisis de todos los RLMs. Incluye estructuras lógicas diversas (secuencial, árbol, grafo, palabra individual) y estrategias de razonamiento (por ejemplo, exploración de árbols de Monte Carlo, búsqueda de rayos), así como conceptos de RL (políticas, modelos de valor) y planes de observación (basados en salida, basados en proceso). Además, proporciona detalladas fórmulas matemáticas y especificaciones de algoritmos para simplificar la implementación de RLMs. Muestra cómo se aplican en casos sencillos como LLaMA-Berry, QwQ, Journey Learning, y Graph of Thoughts. También presenta puntos clave como el entrenamiento paso a paso de modelos de política y modelos de valor, la importancia de la distribución de observación, etc., a través de x1 y investigación bibliográfica. Finalmente, explica cómo RLMs se integran en una amplia ecosistema de LLMs. Nuestro estudio tiene como objetivo explicar la construcción de RLMs, democratizar capacidades evolutivas de razonamiento, fomentar innovación, y reducir la brecha entre \"AI llena\" y \"AI vacía\" al bajar las barreras de desarrollo y experimentación de RLMs.",
      "upvotes": 3,
      "discussionId": "6790772d8d7df822f1fb4493"
    },
    "publishedAt": "2025-01-21T23:42:44.747Z",
    "title": "Reasoning Language Models: A Blueprint",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.11223.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5732
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.12390",
      "authors": [
        {
          "_id": "67906d622ae55818ddfd0d93",
          "name": "Chao Feng",
          "hidden": false
        },
        {
          "_id": "67906d622ae55818ddfd0d94",
          "name": "Ziyang Chen",
          "hidden": false
        },
        {
          "_id": "67906d622ae55818ddfd0d95",
          "name": "Aleksander Holynski",
          "hidden": false
        },
        {
          "_id": "67906d622ae55818ddfd0d96",
          "name": "Alexei A. Efros",
          "hidden": false
        },
        {
          "_id": "67906d622ae55818ddfd0d97",
          "name": "Andrew Owens",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-21T18:59:46.000Z",
      "title": "Utilizar GPS como señal de control para la generación de imágenes",
      "summary": "Las imágenes de datos que incluyen etiquetas GPS son presentadas como señales de control útiles para la generación de imágenes. Se utilizan GPS para entrenar modelos de imágenes y para realizar trabajos complejos para entender pequeños cambios en imágenes urbanas. En particular, se entrena un modelo de generación condicional que considera tanto GPS como frases. El modelo entrenado genera imágenes que detectan características peculiares de vecindarios, parques y marcas geográficas. Además, se extrae modelo 3D a través de la sampling de puntos de escore utilizando GPS 2D. Se controlan las características reconstruidas desde cada punto de vista utilizando condiciones de GPS. En evaluación, se observa que modelos condicionales con GPS pueden generar cambios en imágenes basados en la ubicación, y que las condiciones de GPS mejoran la estructura 3D inferida.",
      "upvotes": 3,
      "discussionId": "67906d682ae55818ddfd0f53"
    },
    "publishedAt": "2025-01-21T23:41:48.239Z",
    "title": "GPS as a Control Signal for Image Generation",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.12390.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "645ab0b7c266796265baefa4",
      "avatarUrl": "/avatars/bdac661996b63c4b2a56881707afa01f.svg",
      "fullname": "Chao Feng",
      "name": "chfeng",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.12202",
      "authors": [
        {
          "_id": "67908409416b83605450716a",
          "name": "Zibo Zhao",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450716b",
          "name": "Zeqiang Lai",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450716c",
          "name": "Qingxiang Lin",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450716d",
          "name": "Yunfei Zhao",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450716e",
          "name": "Haolin Liu",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450716f",
          "name": "Shuhui Yang",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507170",
          "name": "Yifei Feng",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507171",
          "name": "Mingxin Yang",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507172",
          "name": "Sheng Zhang",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507173",
          "name": "Xianghui Yang",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507174",
          "name": "Huiwen Shi",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507175",
          "name": "Sicong Liu",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507176",
          "name": "Junta Wu",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507177",
          "name": "Yihang Lian",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507178",
          "name": "Fan Yang",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507179",
          "name": "Ruining Tang",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450717a",
          "name": "Zebin He",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450717b",
          "name": "Xinzhou Wang",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450717c",
          "name": "Jian Liu",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450717d",
          "name": "Xuhui Zuo",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450717e",
          "name": "Zhuo Chen",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450717f",
          "name": "Biwen Lei",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507180",
          "name": "Haohan Weng",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507181",
          "name": "Jing Xu",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507182",
          "name": "Yiling Zhu",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507183",
          "name": "Xinhai Liu",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507184",
          "name": "Lixin Xu",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507185",
          "name": "Changrong Hu",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507186",
          "name": "Tianyu Huang",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507187",
          "name": "Lifu Wang",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507188",
          "name": "Jihong Zhang",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507189",
          "name": "Meng Chen",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450718a",
          "name": "Liang Dong",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450718b",
          "name": "Yiwen Jia",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450718c",
          "name": "Yulin Cai",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450718d",
          "name": "Jiaao Yu",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450718e",
          "name": "Yixuan Tang",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450718f",
          "name": "Hao Zhang",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507190",
          "name": "Zheng Ye",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507191",
          "name": "Peng He",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507192",
          "name": "Runzhou Wu",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507193",
          "name": "Chao Zhang",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507194",
          "name": "Yonghao Tan",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507195",
          "name": "Jie Xiao",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507196",
          "name": "Yangyu Tao",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507197",
          "name": "Jianchen Zhu",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507198",
          "name": "Jinbao Xue",
          "hidden": false
        },
        {
          "_id": "67908409416b836054507199",
          "name": "Kai Liu",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450719a",
          "name": "Chongqing Zhao",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450719b",
          "name": "Xinming Wu",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450719c",
          "name": "Zhichao Hu",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450719d",
          "name": "Lei Qin",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450719e",
          "name": "Jianbing Peng",
          "hidden": false
        },
        {
          "_id": "67908409416b83605450719f",
          "name": "Zhan Li",
          "hidden": false
        },
        {
          "_id": "67908409416b8360545071a0",
          "name": "Minghui Chen",
          "hidden": false
        },
        {
          "_id": "67908409416b8360545071a1",
          "name": "Xipeng Zhang",
          "hidden": false
        },
        {
          "_id": "67908409416b8360545071a2",
          "name": "Lin Niu",
          "hidden": false
        },
        {
          "_id": "67908409416b8360545071a3",
          "name": "Paige Wang",
          "hidden": false
        },
        {
          "_id": "67908409416b8360545071a4",
          "name": "Yingkai Wang",
          "hidden": false
        },
        {
          "_id": "67908409416b8360545071a5",
          "name": "Haozhao Kuang",
          "hidden": false
        },
        {
          "_id": "67908409416b8360545071a6",
          "name": "Zhongyi Fan",
          "hidden": false
        },
        {
          "_id": "67908409416b8360545071a7",
          "name": "Xu Zheng",
          "hidden": false
        },
        {
          "_id": "67908409416b8360545071a8",
          "name": "Weihao Zhuang",
          "hidden": false
        },
        {
          "_id": "67908409416b8360545071a9",
          "name": "YingPing He",
          "hidden": false
        },
        {
          "_id": "67908409416b8360545071aa",
          "name": "Tian Liu",
          "hidden": false
        },
        {
          "_id": "67908409416b8360545071ab",
          "name": "Yong Yang",
          "hidden": false
        },
        {
          "_id": "67908409416b8360545071ac",
          "name": "Di Wang",
          "hidden": false
        },
        {
          "_id": "67908409416b8360545071ad",
          "name": "Yuhong Liu",
          "hidden": false
        },
        {
          "_id": "67908409416b8360545071ae",
          "name": "Jie Jiang",
          "hidden": false
        },
        {
          "_id": "67908409416b8360545071af",
          "name": "Jingwei Huang",
          "hidden": false
        },
        {
          "_id": "67908409416b8360545071b0",
          "name": "Chunchao Guo",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-21T15:16:54.000Z",
      "title": "Formyn 3D 2.0: Modelo de difusor extendido para la generación de bibliotecas de driveres de textura de alta resolución",
      "summary": "El Hunyuan 3D 2.0 introduce un sistema de síntesis 3D a gran escala de alta calidad. Este sistema se utiliza para crear recursos 3D de alta resolución. Este sistema incluye dos componentes clave: el modelo de generación de formas a gran escala \"Hunyuan3D-DiT\" y el modelo de síntesis de texturas a gran escala \"Hunyuan3D-Paint\". El modelo de formas se construye con un transformador basado en flujo difusión escalable, con el objetivo de generar geometrías que se ajusten a las imágenes de condición dadas. Esto proporciona una base sólida para aplicaciones posteriores. El modelo de texturas se basa en una fuerte geometría y prioridades de difusión, creando mapas de textura de alta resolución y riqueza para cualquier malla generada o manualmente creada. Además, se desarrolló Hunyuan3D-Studio, un entorno de producción amigable para el usuario que simplifica el proceso de reconfiguración de recursos 3D. Esto permitió a profesionales y fanáticos manipular mallas y realizar animaciones. La evaluación sistemática del modelo muestra que Hunyuan3D 2.0 supera a los modelos anteriores en detalles de geometría, coincidencia de condiciones y calidad de texturas. Hunyuan3D 2.0 se ha publicado para complementar las deficiencias del comité abierto de generación de modelos 3D a gran escala. El código del modelo y la entrenamiento previo están disponibles en la siguiente URL:\nhttps://github.com/Tencent/Hunyuan3D-2",
      "upvotes": 1,
      "discussionId": "6790840d416b8360545072a7"
    },
    "publishedAt": "2025-01-22T00:37:32.486Z",
    "title": "Hunyuan3D 2.0: Scaling Diffusion Models for High Resolution Textured 3D Assets Generation",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.12202.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5732
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.10893",
      "authors": [
        {
          "_id": "67907dd5e1d8fc832b3e7b0f",
          "name": "Hongjin Su",
          "hidden": false
        },
        {
          "_id": "67907dd5e1d8fc832b3e7b10",
          "name": "Ruoxi Sun",
          "hidden": false
        },
        {
          "_id": "67907dd5e1d8fc832b3e7b11",
          "name": "Jinsung Yoon",
          "hidden": false
        },
        {
          "_id": "67907dd5e1d8fc832b3e7b12",
          "name": "Pengcheng Yin",
          "hidden": false
        },
        {
          "_id": "67907dd5e1d8fc832b3e7b13",
          "name": "Tao Yu",
          "hidden": false
        },
        {
          "_id": "67907dd5e1d8fc832b3e7b14",
          "name": "Sercan Ö. Arık",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-18T22:34:41.000Z",
      "title": "Aprendizaje en entorno real: marco de datos centrado para programas de ajuste automático de salida en entornos reales",
      "summary": "Automáticos modelos de lenguaje (LLMs) basados en autonomías pueden elevar las capacidades humanas y ayudar en tareas digitales desde la transmisión de correos hasta el análisis de datos. Los actuales LLMs están limitados en su capacidad en estas tareas debido a que las interacciones entre agentes y entornos requieren datos de alta calidad. Proponemos un marco centrado en datos para adaptar los LLMs a los entornos sin necesidad de instrucciones, llamado \"aprendiendo para adaptarse\". \"Aprendiendo para adaptarse\" sintetiza la trayectoria de interacción entre el agente basado en documentos y el entorno, resume o abstracta la historia de interacción para construir comandos, lo que se denomina \"construcción retroalimentada\". Evaluamos la calidad de los datos sin aprendizaje mediante escenarios basados en aprendizaje y aprendizaje in-context (ICL) sin necesidad de aprendizaje. Desarrollamos un acceso de búsqueda externo y optimizamos al agente. En experimentos reales en entornos de codificación, web y desktop como SWE-bench, WebArena, OSWorld y Spider2-V, \"aprendiendo para adaptarse\" demostró efectos en diversas tareas de agentes. Los resultados de ICL muestran un aumento del 12.2% en Claude-3.5 y del 19.5% en Codestral-22B. Además, demostró la importancia de la construcción retroalimentada con un aumento del 14.0%. Nuestro estudio de validación demostró la eficiencia de los datos sin aprendizaje en ICL y la superioridad de nuestro pipeline de búsqueda. Se espera la introducción de LLMs en entornos reales y globales.",
      "upvotes": 1,
      "discussionId": "67907dd9e1d8fc832b3e7c36"
    },
    "publishedAt": "2025-01-22T00:11:18.322Z",
    "title": "Learn-by-interact: A Data-Centric Framework for Self-Adaptive Agents in Realistic Environments",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.10893.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5732
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.11873",
      "authors": [
        {
          "_id": "679071da11a3f67d8f498649",
          "name": "Zihan Qiu",
          "hidden": false
        },
        {
          "_id": "679071da11a3f67d8f49864a",
          "name": "Zeyu Huang",
          "hidden": false
        },
        {
          "_id": "679071da11a3f67d8f49864b",
          "name": "Bo Zheng",
          "hidden": false
        },
        {
          "_id": "679071da11a3f67d8f49864c",
          "name": "Kaiyue Wen",
          "hidden": false
        },
        {
          "_id": "679071da11a3f67d8f49864d",
          "name": "Zekun Wang",
          "hidden": false
        },
        {
          "_id": "679071da11a3f67d8f49864e",
          "name": "Rui Men",
          "hidden": false
        },
        {
          "_id": "679071da11a3f67d8f49864f",
          "name": "Ivan Titov",
          "hidden": false
        },
        {
          "_id": "679071da11a3f67d8f498650",
          "name": "Dayiheng Liu",
          "hidden": false
        },
        {
          "_id": "679071da11a3f67d8f498651",
          "name": "Jingren Zhou",
          "hidden": false
        },
        {
          "_id": "679071da11a3f67d8f498652",
          "name": "Junyang Lin",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-21T04:04:39.000Z",
      "title": "Democratización de la entrevista: Implementación de pérdida de balance en la parte inferior durante el entrenamiento con un modelo de experto en el campo.",
      "summary": "Este artículo revisa la implementación del Loss de Balanza de Carga (LBL) durante el entrenamiento de modelos Mixture-of-Experts (MoEs). Específicamente, el LBL de MoEs se define como N_E sum_{i=1}^{N_E} f_i p_i, donde N_E es el número total de expertos, f_i es la frecuencia de selección del i-ésimo experto y p_i es el puntaje medio de gating del i-ésimo experto. El actual marco de entrenamiento de MoEs generalmente utiliza estrategias de entrenamiento paralelo, donde f_i y el LBL se calculan dentro de micro-batches y se promedian en grupos paralelos correspondientes. Fundamentalmente, los micro-batches incluyen muy pocos secuencias durante el entrenamiento de LLMs en escalas de entrenamiento. Por lo tanto, el LBL de micro-batches es casi a nivel de secuencia, lo que aplica presión para distribuir equitativamente los tokens dentro de cada secuencia. Bajo estas estrictas restricciones, los tokens en secuencias de especialización de expertos (por ejemplo, código) son equitativamente distribuidos entre todos los expertos, lo que inhibe la especialización de los expertos. En este estudio, se propone liberar las restricciones de los micro-batches y calcular el LBL utilizando un batch global. El batch global incluye secuencias muy diversas en comparación con los micro-batches, lo que fomenta un equilibrio de carga a nivel de corpus. Específicamente, se agrega un paso adicional de comunicación para sincronizar f_i entre micro-batches y utilizar esto para calcular el LBL. Las experimentaciones de entrenamiento de LLMs basados en MoEs (con un total de parámetros de hasta 42.8B y hasta 400B de tokens) muestran un excelente mejora en rendimiento además de la predicción con la estrategia de LBL de batch global. Según el análisis, el LBL de batch global mejora significativamente la especialización de los expertos en MoEs.",
      "upvotes": 1,
      "discussionId": "679071db11a3f67d8f498680"
    },
    "publishedAt": "2025-01-21T23:27:52.660Z",
    "title": "Demons in the Detail: On Implementing Load Balancing Loss for Training Specialized Mixture-of-Expert Models",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/647ccbd6e07cf9bb2d485244/ddUbQV_yVPwD6P0TSR5lu.png",
      "https://cdn-uploads.huggingface.co/production/uploads/647ccbd6e07cf9bb2d485244/f7Q4QULppOygZlsYBUvY9.png",
      "https://cdn-uploads.huggingface.co/production/uploads/647ccbd6e07cf9bb2d485244/9Jwx37bQkCjaWcccWbJ7b.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.11873.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "647ccbd6e07cf9bb2d485244",
      "avatarUrl": "/avatars/e8915abaff04f6762247e196b7cf84df.svg",
      "fullname": "Zihan Qiu",
      "name": "QwQZh",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 3
    },
    "isAuthorParticipating": false
  }
]