[
  {
    "paper": {
      "id": "2501.13200",
      "authors": [
        {
          "_id": "67933d69b843fda452c689dd",
          "user": {
            "_id": "65c0db0fbda79a18292dfbb7",
            "avatarUrl": "/avatars/1201b8282664c2d8c18beaba2396c03b.svg",
            "isPro": false,
            "fullname": "Alsu Sagirova",
            "user": "alsu-sagirova",
            "type": "user"
          },
          "name": "Alsu Sagirova",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-01-24T09:07:49.036Z",
          "hidden": false
        },
        {
          "_id": "67933d69b843fda452c689de",
          "name": "Yuri Kuratov",
          "hidden": false
        },
        {
          "_id": "67933d69b843fda452c689df",
          "user": {
            "_id": "639c6e978a34ed9a404c6a7b",
            "avatarUrl": "/avatars/c98ca8c9f9ed8509c2f1bb6aa994fd57.svg",
            "isPro": false,
            "fullname": "MIKHAIL BURTSEV",
            "user": "mbur",
            "type": "user"
          },
          "name": "Mikhail Burtsev",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:07:03.954Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-22T20:08:53.000Z",
      "title": "SRMT: Proyecto de memoria compartida para ranking de vidas múltiples agentes y búsqueda de contraseñas",
      "summary": "La visión de efectos múltiples en la aprendizaje de refuerzo multi-agente (MARL) está demostrando una gran avancada en la resolución efectiva de problemas empresariales y competitivos multi-agente en diferentes entornos. Una de las principales desafíos de MARL es la necesidad de predecir explícitamente las acciones de cada agente para alcanzar los objetivos empresariales. Para abordar este problema, proponemos la expansión de la transformer de memoria hacia un entorno multi-agente denominada \"Memoria de Reproducción Compartida Transformer (SRMT)\". SRMT permite a los agentes intercambiar información oculta y regular sus acciones mutuamente. SRMT fue evaluado en problemas de aprendizaje de refuerzo multi-agente observables por portafolios, como el TASK de Navegación en el Collar de Potter y el TASK de POGEMA. En el TASK de Navegación en el Collar de Potter, SRMT demostró excelencia en líneas de aprendizaje basadas en refuerzos diversos, especialmente generalizando eficazmente en entrenamientos más largos con recompensas escasas. En el TASK de POGEMA MAP, SRMT competía con algoritmos de MARL, híbridos y basados en planificación, incluyendo mazos como MAZES, RANDOM y MovingAI. Estos resultados muestran que la integración de una memoria de reproducción compartida en arquitecturas basadas en transformers puede mejorar la coordinación en sistemas multi-agente distribuidos. Los códigos de fuente para el aprendizaje y la evaluación están disponibles en GitHub: https://github.com/Aloriosa/srmt.",
      "upvotes": 36,
      "discussionId": "67933d6ab843fda452c68a38"
    },
    "publishedAt": "2025-01-24T02:35:35.802Z",
    "title": "SRMT: Shared Memory for Multi-agent Lifelong Pathfinding",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.13200.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "65c0db0fbda79a18292dfbb7",
      "avatarUrl": "/avatars/1201b8282664c2d8c18beaba2396c03b.svg",
      "fullname": "Alsu Sagirova",
      "name": "alsu-sagirova",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2501.13918",
      "authors": [
        {
          "_id": "679319848d46289f90266168",
          "user": {
            "_id": "639be86b59473c6ae02ef9c4",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/639be86b59473c6ae02ef9c4/gw34RBCVZCOkcAA79xUr3.png",
            "isPro": false,
            "fullname": "Jie Liu",
            "user": "jieliu",
            "type": "user"
          },
          "name": "Jie Liu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-01-24T09:07:53.235Z",
          "hidden": false
        },
        {
          "_id": "679319848d46289f90266169",
          "name": "Gongye Liu",
          "hidden": false
        },
        {
          "_id": "679319848d46289f9026616a",
          "name": "Jiajun Liang",
          "hidden": false
        },
        {
          "_id": "679319848d46289f9026616b",
          "name": "Ziyang Yuan",
          "hidden": false
        },
        {
          "_id": "679319848d46289f9026616c",
          "name": "Xiaokun Liu",
          "hidden": false
        },
        {
          "_id": "679319848d46289f9026616d",
          "name": "Mingwu Zheng",
          "hidden": false
        },
        {
          "_id": "679319848d46289f9026616e",
          "name": "Xiele Wu",
          "hidden": false
        },
        {
          "_id": "679319848d46289f9026616f",
          "name": "Qiulin Wang",
          "hidden": false
        },
        {
          "_id": "679319848d46289f90266170",
          "name": "Wenyu Qin",
          "hidden": false
        },
        {
          "_id": "679319848d46289f90266171",
          "name": "Menghan Xia",
          "hidden": false
        },
        {
          "_id": "679319848d46289f90266172",
          "user": {
            "_id": "60e272ca6c78a8c122b12127",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/60e272ca6c78a8c122b12127/xldEGBzGrU-bX6IwAw0Ie.jpeg",
            "isPro": false,
            "fullname": "Xintao Wang",
            "user": "Xintao",
            "type": "user"
          },
          "name": "Xintao Wang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-01-24T09:07:51.248Z",
          "hidden": false
        },
        {
          "_id": "679319848d46289f90266173",
          "name": "Xiaohong Liu",
          "hidden": false
        },
        {
          "_id": "679319848d46289f90266174",
          "name": "Fei Yang",
          "hidden": false
        },
        {
          "_id": "679319848d46289f90266175",
          "name": "Pengfei Wan",
          "hidden": false
        },
        {
          "_id": "679319848d46289f90266176",
          "name": "Di Zhang",
          "hidden": false
        },
        {
          "_id": "679319848d46289f90266177",
          "name": "Kun Gai",
          "hidden": false
        },
        {
          "_id": "679319848d46289f90266178",
          "name": "Yujiu Yang",
          "hidden": false
        },
        {
          "_id": "679319848d46289f90266179",
          "name": "Wanli Ouyang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-23T18:55:41.000Z",
      "title": "Mejorar la generación de vídeos utilizando retroalimentación humana",
      "summary": "La generación de videos ha evolucionado a través de la tecnología de flujos de normalización, aunque siguen existiendo problemas como movimientos inadecuados o la asimetría entre videos y prompts. En este estudio, se desarrolla un sistema icónico de pipeline utilizando retroalimentación humana para mitigar estos problemas y crear un modelo de generación de videos más preciso. En particular, se centra en modelos modernos de generación de videos y se construye un grande conjunto de datos de preferencias humanas para incluir explicaciones de parejas de dimensiones. Luego, se introduce el modelo de recompensa de videos (VideoReward) para evaluar cómo las elecciones de diseño y explicaciones afectan el efecto de la recompensa. Se maximiza la recompensa desde una perspectiva única de aprendizaje por refuerzo, incluyendo la normalización de Kullback-Leibler y tres algoritmos de arranque para modelos basados en flujos. Estos algoritmos ofrecen dos estrategias durante el entrenamiento: la optimización directa del gusto del flujo (Flow-DPO) y la regresión con pesos de recompensa (Flow-RWR), y durante la inferencia, la guía de recompensa con ruido (Flow-NRG). Flow-NRG aplica directamente una guía de recompensa a videos con ruido durante la inferencia. Los resultados de los experimentos muestran que VideoReward supera significativamente a los modelos de recompensa existentes, y Flow-DPO presenta un desempeño excelente comparado con Flow-RWR y el método óptimo de entrenamiento de normalización estándar. Además, Flow-NRG permite asignar pesos personalizados a múltiples objetos durante la inferencia, lo que satisface la calidad individual de los videos. Página del proyecto: https://gongyeliu.github.io/videoalign.",
      "upvotes": 28,
      "discussionId": "679319858d46289f90266203"
    },
    "publishedAt": "2025-01-24T05:39:01.676Z",
    "title": "Improving Video Generation with Human Feedback",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.13918.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "639be86b59473c6ae02ef9c4",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/639be86b59473c6ae02ef9c4/gw34RBCVZCOkcAA79xUr3.png",
      "fullname": "Jie Liu",
      "name": "jieliu",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 10
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2501.13629",
      "authors": [
        {
          "_id": "6792f8ed5e3ec6035dafb06a",
          "user": {
            "_id": "63776f1806241efce1e7aae6",
            "avatarUrl": "/avatars/d67d9dcd932934c630f407ac152f2ce6.svg",
            "isPro": false,
            "fullname": "Zhenghao Lin",
            "user": "Lin0",
            "type": "user"
          },
          "name": "Zhenghao Lin",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T09:14:52.584Z",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb06b",
          "user": {
            "_id": "656c6bd8e0ff1cebe966aa35",
            "avatarUrl": "/avatars/1083cb58bdb0bee72036953276d42e13.svg",
            "isPro": false,
            "fullname": "tangzihao",
            "user": "tzh94588",
            "type": "user"
          },
          "name": "Zihao Tang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T09:15:04.802Z",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb06c",
          "user": {
            "_id": "63fb6e281b4b1bd4e7ffc5be",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1677422062937-noauth.jpeg",
            "isPro": false,
            "fullname": "Xiao Liu",
            "user": "lx865712528",
            "type": "user"
          },
          "name": "Xiao Liu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-01-24T09:08:05.797Z",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb06d",
          "user": {
            "_id": "643f615aa16cd6d1f4c581de",
            "avatarUrl": "/avatars/47753a3e82b44f81881600c52e1e8495.svg",
            "isPro": false,
            "fullname": "Yeyun Gong",
            "user": "yegong",
            "type": "user"
          },
          "name": "Yeyun Gong",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T09:58:33.228Z",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb06e",
          "name": "Yi Cheng",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb06f",
          "name": "Qi Chen",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb070",
          "user": {
            "_id": "61342a4b488458a484dee6c4",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1630808595161-noauth.png",
            "isPro": false,
            "fullname": "Hang Li",
            "user": "hanglics",
            "type": "user"
          },
          "name": "Hang Li",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:03:59.680Z",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb071",
          "name": "Ying Xin",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb072",
          "user": {
            "_id": "62f6a9add3bdacb7eec0d4f5",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1660332390183-noauth.jpeg",
            "isPro": false,
            "fullname": "Ziyue Yang",
            "user": "ziyueyang37",
            "type": "user"
          },
          "name": "Ziyue Yang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:04:09.709Z",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb073",
          "user": {
            "_id": "646fc402e9c03ba436d5e93e",
            "avatarUrl": "/avatars/870c86dc99fb1cb6a348a7a0385b1a04.svg",
            "isPro": false,
            "fullname": "Kailai Yang",
            "user": "klyang",
            "type": "user"
          },
          "name": "Kailai Yang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:04:16.033Z",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb074",
          "name": "Yu Yan",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb075",
          "name": "Xiao Liang",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb076",
          "name": "Shuai Lu",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb077",
          "name": "Yiming Huang",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb078",
          "user": {
            "_id": "6443bb593c323e0918f61a96",
            "avatarUrl": "/avatars/b9e1ba17f7798b5142bc0124fba95237.svg",
            "isPro": false,
            "fullname": "zheheng luo",
            "user": "KenLuo",
            "type": "user"
          },
          "name": "Zheheng Luo",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:04:49.140Z",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb079",
          "name": "Lei Qu",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb07a",
          "name": "Xuan Feng",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb07b",
          "name": "Yaoxiang Wang",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb07c",
          "user": {
            "_id": "6369e01864aad59d4d4501ac",
            "avatarUrl": "/avatars/bcbd3f9d0d194eeccd061c4fa6a6e283.svg",
            "isPro": false,
            "fullname": "Yuqing Xia",
            "user": "yuqxia",
            "type": "user"
          },
          "name": "Yuqing Xia",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:05:26.287Z",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb07d",
          "user": {
            "_id": "673fd856a45b6f21829a3bf5",
            "avatarUrl": "/avatars/deb8c5362fad22019cccaed6d03dea09.svg",
            "isPro": false,
            "fullname": "Feiyang Chen",
            "user": "PhilipChen",
            "type": "user"
          },
          "name": "Feiyang Chen",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:05:34.991Z",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb07e",
          "user": {
            "_id": "64e85f4e5ddcace745bc0a55",
            "avatarUrl": "/avatars/e316355b913c73104db530010ceedeb4.svg",
            "isPro": false,
            "fullname": "Yuting Jiang",
            "user": "Stautinger",
            "type": "user"
          },
          "name": "Yuting Jiang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:05:41.151Z",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb07f",
          "name": "Yasen Hu",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb080",
          "name": "Hao Ni",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb081",
          "user": {
            "_id": "6485714cfc41a0b97fe377cc",
            "avatarUrl": "/avatars/0af8a3df9ad711a5eac739bce26c4c2a.svg",
            "isPro": false,
            "fullname": "Li",
            "user": "Binyang",
            "type": "user"
          },
          "name": "Binyang Li",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:06:03.263Z",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb082",
          "user": {
            "_id": "663de80ca920d195191807da",
            "avatarUrl": "/avatars/2437ce3fa073a07b971d370c26c7ab65.svg",
            "isPro": false,
            "fullname": "Guoshuai Zhao",
            "user": "crayonshine",
            "type": "user"
          },
          "name": "Guoshuai Zhao",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:05:17.780Z",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb083",
          "name": "Jui-Hao Chiang",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb084",
          "name": "Zhongxin Guo",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb085",
          "name": "Chen Lin",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb086",
          "name": "Kun Kuang",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb087",
          "user": {
            "_id": "66a3710a4ee2a4c936315a5a",
            "avatarUrl": "/avatars/ef8da8fb1031695d77d34a5d365aa177.svg",
            "isPro": false,
            "fullname": "Li",
            "user": "WenjieLi",
            "type": "user"
          },
          "name": "Wenjie Li",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:06:22.951Z",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb088",
          "user": {
            "_id": "6454c337a13edf669cd5d8ea",
            "avatarUrl": "/avatars/a383a0dda7c2ef6a0d6c3c64651f42ff.svg",
            "isPro": false,
            "fullname": "Yelong Shen",
            "user": "uuu6",
            "type": "user"
          },
          "name": "Yelong Shen",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:06:30.109Z",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb089",
          "name": "Jian Jiao",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb08a",
          "name": "Peng Cheng",
          "hidden": false
        },
        {
          "_id": "6792f8ed5e3ec6035dafb08b",
          "name": "Mao Yang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-23T12:58:14.000Z",
      "title": "Sigma: Modelo de lenguaje eficiente mediante ajustes de diferencias de preguntas, claves y valores",
      "summary": "Sigma es un grande modelo de lenguaje que se adapta a áreas específicas de sistemas, basándose en una nueva arquitectura. Introduce la técnica de la atención DiffQKV, lo que significa un gran aumento en la eficiencia de la inferencia del modelo. La atención DiffQKV optimiza los parámetros de rendimiento y eficiencia del modelo considerando que los componentes Query (Q), Key (K) y Value (V) tienen efectos diferentes. En particular, demostra su capacidad para manejar tareas complejas en K y V, desarrollando un KV más comprimido y expandiendo el dimensión de los cabezas Q para mejorar la representación del modelo. Según análisis teórico y experimental, la atención DiffQKV logra un aumento de 33.36% en la velocidad de inferencia frente a GQA en contextos largos. Sigma se entrenó con 6T tokens de datos, de los cuales 19.5B son de datos de áreas de sistema y 1T son datos sintéticos recopilados con cuidado. En áreas generales, Sigma muestra el mismo rendimiento que otros modelos de alto rendimiento, mientras que en áreas de sistemas, es el primer modelo que ha registrado resultados comprobados en el benchmark AIMicius. En este benchmark, Sigma muestra excelentes resultados en todas las tareas, superando significativamente a GPT-4 con un aumento absoluto de 52.5%.",
      "upvotes": 27,
      "discussionId": "6792f8f05e3ec6035dafb140"
    },
    "publishedAt": "2025-01-23T22:48:16.405Z",
    "title": "Sigma: Differential Rescaling of Query, Key and Value for Efficient Language Models",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.13629.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "63fb6e281b4b1bd4e7ffc5be",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1677422062937-noauth.jpeg",
      "fullname": "Xiao Liu",
      "name": "lx865712528",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 7
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2501.13926",
      "authors": [
        {
          "_id": "6793040ec67af4a116a25d05",
          "user": {
            "_id": "647d9ab61a1fcad2fdbf2d3d",
            "avatarUrl": "/avatars/48c8aeae8979d2c87df8bde922437d62.svg",
            "isPro": true,
            "fullname": "Ziyu Guo",
            "user": "ZiyuG",
            "type": "user"
          },
          "name": "Ziyu Guo",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:07:58.258Z",
          "hidden": false
        },
        {
          "_id": "6793040ec67af4a116a25d06",
          "name": "Renrui Zhang",
          "hidden": false
        },
        {
          "_id": "6793040ec67af4a116a25d07",
          "name": "Chengzhuo Tong",
          "hidden": false
        },
        {
          "_id": "6793040ec67af4a116a25d08",
          "user": {
            "_id": "6713a71e7dfe714b425cccfb",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/95YYcbv_f6J8yWTunwn4z.png",
            "isPro": false,
            "fullname": "zhizhengzhao",
            "user": "zhizhengzhao",
            "type": "user"
          },
          "name": "Zhizheng Zhao",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:08:20.272Z",
          "hidden": false
        },
        {
          "_id": "6793040ec67af4a116a25d09",
          "user": {
            "_id": "6759af3eccbc8817f9169179",
            "avatarUrl": "/avatars/49e64c7ccf71b8f25c52783b6ae93620.svg",
            "isPro": false,
            "fullname": "Peng Gao",
            "user": "gaopenghigh",
            "type": "user"
          },
          "name": "Peng Gao",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:08:26.816Z",
          "hidden": false
        },
        {
          "_id": "6793040ec67af4a116a25d0a",
          "user": {
            "_id": "65c04e9c27a5fdca81abcbd9",
            "avatarUrl": "/avatars/12a155683c824fa23da4a9e2bed4f64e.svg",
            "isPro": false,
            "fullname": "Hongsheng LI",
            "user": "hsli-cuhk",
            "type": "user"
          },
          "name": "Hongsheng Li",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:08:33.312Z",
          "hidden": false
        },
        {
          "_id": "6793040ec67af4a116a25d0b",
          "name": "Pheng-Ann Heng",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-23T18:59:43.000Z",
      "title": "¿Se pueden generar imágenes en el CoT? Verificar y mejorar la generación de imágenes paso a paso.",
      "summary": "La inferencia por cadena de pensamiento (CoT) es ampliamente revisada para resolver tareas complejas en modelos grandes. Sin embargo, la aplicabilidad de estas estrategias en la validación y fortalecimiento de escenarios de generación de imágenes sigue siendo un tema de debate. En este artículo, se investiga de manera detallada la posibilidad de que la inferencia por cadena de pensamiento fortalezca la generación automática de imágenes. El enfoque se compone de tres tecnologías: la escalado de cálculo de tiempo de prueba para la validación, la coincidencia entre el estilo del modelo y la Optimización de Preferencias Directas (DPO), y la integración de los efectos complementarios de estas tecnologías. Esta aproximación muestra que se puede significativamente mejorar el rendimiento de la generación de imágenes. Además, considerando el papel crucial de los modelos de recompensa en nuestros hallazgos, se propone el Modelo de Recompensa de Evaluación Potencial (PARM) y PARM++ (PARM++). El PARM integra las fortalezas de los modelos de recompensa existentes y evalúa cada etapa de generación adaptativamente utilizando un enfoque de evaluación potencial. El PARM++ añade una función de autocorrección automática para corregir imágenes generadas con insatisfacción. Utilizando la técnica de acceso a la causa, se fortalece el modelo base Show-o para lograr un aumento significativo de +24% en el benchmark GenEval, y supera a la Stable Diffusion 3 en más de +15%. Nuestro estudio ofrece una visión específica sobre la integración de la inferencia por cadena de pensamiento y la generación automática de imágenes, abriendo nuevas rutas. Los códigos y modelos están disponibles en https://github.com/ZiyuGuo99/Image-Generation-CoT.",
      "upvotes": 9,
      "discussionId": "67930410c67af4a116a25da4"
    },
    "publishedAt": "2025-01-23T22:08:17.598Z",
    "title": "Can We Generate Images with CoT? Let's Verify and Reinforce Image Generation Step by Step",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.13926.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "63468720dd6d90d82ccf3450",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63468720dd6d90d82ccf3450/tVBFlmZNz8FRMkOrDaDID.jpeg",
      "fullname": "YSH",
      "name": "BestWishYsh",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 28
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.13920",
      "authors": [
        {
          "_id": "679316ff3698fd97252a8e6f",
          "user": {
            "_id": "64c3c72e8f31d1e6c664b052",
            "avatarUrl": "/avatars/af1ad5048eaa9dc417837ad02f927911.svg",
            "isPro": false,
            "fullname": "jiayi lei",
            "user": "jyjyjyjy",
            "type": "user"
          },
          "name": "Jiayi Lei",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:12:22.641Z",
          "hidden": false
        },
        {
          "_id": "679316ff3698fd97252a8e70",
          "name": "Renrui Zhang",
          "hidden": false
        },
        {
          "_id": "679316ff3698fd97252a8e71",
          "name": "Xiangfei Hu",
          "hidden": false
        },
        {
          "_id": "679316ff3698fd97252a8e72",
          "user": {
            "_id": "66026c9068d519ed32519e9c",
            "avatarUrl": "/avatars/8fa051312c713772e5b8ba65989ff7f5.svg",
            "isPro": false,
            "fullname": "Weifeng Lin",
            "user": "Afeng-x",
            "type": "user"
          },
          "name": "Weifeng Lin",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:13:07.303Z",
          "hidden": false
        },
        {
          "_id": "679316ff3698fd97252a8e73",
          "name": "Zhen Li",
          "hidden": false
        },
        {
          "_id": "679316ff3698fd97252a8e74",
          "name": "Wenjian Sun",
          "hidden": false
        },
        {
          "_id": "679316ff3698fd97252a8e75",
          "user": {
            "_id": "64a54586c0f13de8e7093314",
            "avatarUrl": "/avatars/389e43e9a32cf2fc95f8f3a23b8f0508.svg",
            "isPro": false,
            "fullname": "Ruoyi Du",
            "user": "RuoyiDu",
            "type": "user"
          },
          "name": "Ruoyi Du",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:13:21.861Z",
          "hidden": false
        },
        {
          "_id": "679316ff3698fd97252a8e76",
          "user": {
            "_id": "6358a167f56b03ec9147074d",
            "avatarUrl": "/avatars/e54ea7bf0c240cf76d538296efb3976c.svg",
            "isPro": false,
            "fullname": "Le Zhuo",
            "user": "JackyZhuo",
            "type": "user"
          },
          "name": "Le Zhuo",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:13:27.523Z",
          "hidden": false
        },
        {
          "_id": "679316ff3698fd97252a8e77",
          "user": {
            "_id": "6740a5730bb4a675446a80ad",
            "avatarUrl": "/avatars/27c08e33df88e4f73c136da65f2b5adb.svg",
            "isPro": false,
            "fullname": "Zhong-Yu Li",
            "user": "lzyhha",
            "type": "user"
          },
          "name": "Zhongyu Li",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:13:33.108Z",
          "hidden": false
        },
        {
          "_id": "679316ff3698fd97252a8e78",
          "name": "Xinyue Li",
          "hidden": false
        },
        {
          "_id": "679316ff3698fd97252a8e79",
          "user": {
            "_id": "62c66504031996c36c86976a",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62c66504031996c36c86976a/wIq0YJhkWnEhlzsh-TGYO.png",
            "isPro": true,
            "fullname": "steve z",
            "user": "stzhao",
            "type": "user"
          },
          "name": "Shitian Zhao",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-01-24T13:30:14.688Z",
          "hidden": false
        },
        {
          "_id": "679316ff3698fd97252a8e7a",
          "user": {
            "_id": "647d9ab61a1fcad2fdbf2d3d",
            "avatarUrl": "/avatars/48c8aeae8979d2c87df8bde922437d62.svg",
            "isPro": true,
            "fullname": "Ziyu Guo",
            "user": "ZiyuG",
            "type": "user"
          },
          "name": "Ziyu Guo",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:14:21.821Z",
          "hidden": false
        },
        {
          "_id": "679316ff3698fd97252a8e7b",
          "user": {
            "_id": "6614fb3d5aed02b298a4b469",
            "avatarUrl": "/avatars/d0ddb4f989ad1a3f24128cc843347bde.svg",
            "isPro": false,
            "fullname": "yiting lu",
            "user": "yeeeeeyy",
            "type": "user"
          },
          "name": "Yiting Lu",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:14:50.714Z",
          "hidden": false
        },
        {
          "_id": "679316ff3698fd97252a8e7c",
          "user": {
            "_id": "6759af3eccbc8817f9169179",
            "avatarUrl": "/avatars/49e64c7ccf71b8f25c52783b6ae93620.svg",
            "isPro": false,
            "fullname": "Peng Gao",
            "user": "gaopenghigh",
            "type": "user"
          },
          "name": "Peng Gao",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:15:04.489Z",
          "hidden": false
        },
        {
          "_id": "679316ff3698fd97252a8e7d",
          "user": {
            "_id": "65c04e9c27a5fdca81abcbd9",
            "avatarUrl": "/avatars/12a155683c824fa23da4a9e2bed4f64e.svg",
            "isPro": false,
            "fullname": "Hongsheng LI",
            "user": "hsli-cuhk",
            "type": "user"
          },
          "name": "Hongsheng Li",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:15:11.437Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-23T18:58:33.000Z",
      "title": "IMAGINE-E: Evaluación más avanzada de la generación de imágenes en intra-situación",
      "summary": "El desarrollo rápido de los modelos de difusión ha llevado a que los modelos de texto a imagen (T2I) se han visto notablemente mejorar y han demostrado habilidades excepcionales en la captura de prompts y la generación de imágenes. Modelos recientes como FLUX.1 y Ideogram2.0, junto con otros como Dall-E3 y Stable Diffusion 3, han mostrado una excelente capacidad en tareas complejas, y se ha planteado la pregunta de si los modelos T2I están evolucionando en sus usos generales. Estos modelos ofrecen funciones en diversas áreas, como la generación de contenido controlable, edición de imágenes, videos, sonidos, 3D y movimientos, y también soportan tareas de visualización computacional como la segmentación semántica y la estimación de profundidad. Sin embargo, actualmente, los marcos de evaluación no pueden evaluar de manera perfecta el desempeño de estos modelos en sus nuevas áreas de aplicación. Para abordar este problema, se desarrolló IMAGINE-E para validar los modelos FLUX.1, Ideogram2.0, Midjourney, Dall-E3, Stable Diffusion 3 y Jimeng. La evaluación se ha dividido en cinco áreas principales: generación de salidas estructuradas, Realismo, coherencia física, generación en áreas específicas, generación de escenarios difíciles y tareas de múltiple estilos. Esta evaluación detallada permite claramente identificar las fortalezas y debilidades de cada modelo, particularmente destacando la excelente capacidad de FLUX.1 y Ideogram2.0 en tareas estructuradas y en áreas específicas, y subrayando la posibilidad de aplicación y el potencial de los modelos T2I. Este estudio ofrece valiosas perspectivas sobre el estado actual y las futuras perspectivas de los modelos T2I. Los scripts de evaluación están disponibles en https://github.com/jylei16/Imagine-e.",
      "upvotes": 8,
      "discussionId": "679317043698fd97252a8f6f"
    },
    "publishedAt": "2025-01-23T23:31:27.973Z",
    "title": "IMAGINE-E: Image Generation Intelligence Evaluation of State-of-the-art Text-to-Image Models",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.13920.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "645dbaa6f5760d1530d7580d",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/645dbaa6f5760d1530d7580d/Bqob8arLZoHIgMwNZpL9I.jpeg",
      "fullname": "Simeon Emanuilov",
      "name": "s-emanuilov",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isMod": false,
      "followerCount": 16
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.10018",
      "authors": [
        {
          "_id": "678e125d09dc6d3a311cc04e",
          "user": {
            "_id": "6497b4464a3c31df8e4148d8",
            "avatarUrl": "/avatars/4397a380468e84bc7945fddd9a6d1066.svg",
            "isPro": false,
            "fullname": "Xiaowen Li",
            "user": "asLKHFksasak",
            "type": "user"
          },
          "name": "Xiaowen Li",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:31:02.655Z",
          "hidden": false
        },
        {
          "_id": "678e125d09dc6d3a311cc04f",
          "name": "Haolan Xue",
          "hidden": false
        },
        {
          "_id": "678e125d09dc6d3a311cc050",
          "user": {
            "_id": "64b74a45f902508f0d786505",
            "avatarUrl": "/avatars/8bc5aaa011642827e12524c4f0a56927.svg",
            "isPro": false,
            "fullname": "Peiran REN",
            "user": "lyraestar",
            "type": "user"
          },
          "name": "Peiran Ren",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:30:47.443Z",
          "hidden": false
        },
        {
          "_id": "678e125d09dc6d3a311cc051",
          "user": {
            "_id": "63d0cc736b985b0f25d0412c",
            "avatarUrl": "/avatars/3eb8c79f9a7c4c819038ea7b04e323dd.svg",
            "isPro": false,
            "fullname": "Bo",
            "user": "Liefeng",
            "type": "user"
          },
          "name": "Liefeng Bo",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:30:55.550Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-17T08:03:02.000Z",
      "title": "DiffuEraser: Modelo de DifuEusion que completa las partes incompletas de una imagen",
      "summary": "Recientemente, los algoritmos de video inpainting han integrado la propagación de píxeles basada en flujo y la generación basada en transformers, utilizando la información de los frames adyacentes para recuperar textos y listas de objetos, y aplicando flujos ópticos. Además, las regiones mascaradas son tratadas perfectamente por un visual transformer. Sin embargo, estas aproximaciones presentan incertidumbres espacio-temporales y temporales cuando se trabajan con grandes mascaras, lo que requiere un aumento en la capacidad de generación. Recientemente, los modelos de difusión han demostrado excelentes resultados en la generación de imágenes y videos y han sido considerados una tecnología importante. En este artículo, se presenta un modelo de video inpainting estable basado en modelos de difusión llamado \"DiffuEraser\", con el objetivo de llenar las regiones mascaradas con detalles más detallados y estructuras coherentes. Se combinan anteriores informaciones para proporcionar inicialización y condiciones débiles, lo que permite inhibir la aberración y el holograma del ruido. Además, para mejorar la consistencia temporal en la inferencia de secuencias largas, se expanden las ventanas de recepción temporales de los modelos previos y de \"DiffuEraser\", y se utilizan las características de la temporal smoothing para mejorar la consistencia. Los resultados de los experimentos muestran que nuestro método propone tecnologías más avanzadas en la completitud de los contenidos y la consistencia temporal, manteniendo una eficiencia reconocible.",
      "upvotes": 7,
      "discussionId": "678e125f09dc6d3a311cc0af"
    },
    "publishedAt": "2025-01-24T03:08:08.583Z",
    "title": "DiffuEraser: A Diffusion Model for Video Inpainting",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.10018.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "5f1158120c833276f61f1a84",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1608042047613-5f1158120c833276f61f1a84.jpeg",
      "fullname": "Niels Rogge",
      "name": "nielsr",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 735
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.13919",
      "authors": [
        {
          "_id": "679317f9d3ef2f790a539a28",
          "user": {
            "_id": "6785fc7d17a2dfa3720ec082",
            "avatarUrl": "/avatars/73e9d715bb16f14240c733c4843dfc22.svg",
            "isPro": false,
            "fullname": "Rui Li",
            "user": "ruili0",
            "type": "user"
          },
          "name": "Rui Li",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-01-24T10:17:34.282Z",
          "hidden": false
        },
        {
          "_id": "679317f9d3ef2f790a539a29",
          "user": {
            "_id": "65703fab7f50602340d23704",
            "avatarUrl": "/avatars/324c45f5fba9cd8c38a89b30427c06b4.svg",
            "isPro": false,
            "fullname": "Xiaohan Wang",
            "user": "nicholswang",
            "type": "user"
          },
          "name": "Xiaohan Wang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:11:30.999Z",
          "hidden": false
        },
        {
          "_id": "679317f9d3ef2f790a539a2a",
          "user": {
            "_id": "62da55164398e21bf7f0e292",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62da55164398e21bf7f0e292/xjKkG8IA2IZZqCdjApSh3.jpeg",
            "isPro": false,
            "fullname": "Yuhui Zhang",
            "user": "yuhuizhang",
            "type": "user"
          },
          "name": "Yuhui Zhang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:11:46.689Z",
          "hidden": false
        },
        {
          "_id": "679317f9d3ef2f790a539a2b",
          "name": "Zeyu Wang",
          "hidden": false
        },
        {
          "_id": "679317f9d3ef2f790a539a2c",
          "user": {
            "_id": "677c8b2e92550a07fcad0f50",
            "avatarUrl": "/avatars/2be26e8f25e98cfe5b1d227ee0409cd0.svg",
            "isPro": false,
            "fullname": "Serena Yeung-Levy",
            "user": "yeunglevy",
            "type": "user"
          },
          "name": "Serena Yeung-Levy",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:09:52.788Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-23T18:58:03.000Z",
      "title": "\"Optimización de la preferencia de secuencias temporales para la comprensión de videos largos\"",
      "summary": "La implementación efectiva de la base temporal en videos largos es un desafío complejo en los modelos actuales. Para superar esto, proponemos un nuevo marco de aprendizaje posterior llamado \"Temporal Preference Optimization (TPO)\". TPO mejora la capacidad de la base temporal en videos largos mediante aprendizaje de preferencias. Utilizando dos conjuntos de datos de preferencias, TPO permite que el modelo distingua claramente entre reacciones a una base temporal establecida y reacciones a una base temporal con menor precisión. Este proceso de optimización mejora significativamente la comprensión del tiempo y reduce la dependencia de datos anotados automáticamente. Los resultados de TPO se han validado en diferentes experimentos en el marco de LongVideoBench, MLVU y Video-MME. En particular, LLaVA-Video-TPO ha sido reconocido como el mejor modelo de 7B en Video-MME, demostrando la posibilidad de TPO para mejorar la comprensión de videos largos y proporcionar soluciones eficientes al tema de la base temporal. Página del proyecto: https://ruili33.github.io/tpo_website.",
      "upvotes": 7,
      "discussionId": "679317fcd3ef2f790a539ad6"
    },
    "publishedAt": "2025-01-23T23:33:03.175Z",
    "title": "Temporal Preference Optimization for Long-Form Video Understanding",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.13919.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "645dbaa6f5760d1530d7580d",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/645dbaa6f5760d1530d7580d/Bqob8arLZoHIgMwNZpL9I.jpeg",
      "fullname": "Simeon Emanuilov",
      "name": "s-emanuilov",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isMod": false,
      "followerCount": 16
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.13826",
      "authors": [
        {
          "_id": "67934585e4e44e2866b644f2",
          "user": {
            "_id": "6400ba2b261cfa61f3a00555",
            "avatarUrl": "/avatars/1311e0b5e21b1c94d73fcaf455d3c7f7.svg",
            "isPro": false,
            "fullname": "Kairui",
            "user": "KairuiHu",
            "type": "user"
          },
          "name": "Kairui Hu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-01-24T09:07:46.937Z",
          "hidden": false
        },
        {
          "_id": "67934585e4e44e2866b644f3",
          "user": {
            "_id": "64101f81b27543634e377fc1",
            "avatarUrl": "/avatars/557dd9d4707e3b38e0805dfb87c08004.svg",
            "isPro": false,
            "fullname": "Penghao Wu",
            "user": "craigwu",
            "type": "user"
          },
          "name": "Penghao Wu",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:21:29.750Z",
          "hidden": false
        },
        {
          "_id": "67934585e4e44e2866b644f4",
          "user": {
            "_id": "646e1ef5075bbcc48ddf21e8",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/_vJC0zeVOIvaNV2R6toqg.jpeg",
            "isPro": false,
            "fullname": "Pu Fanyi",
            "user": "pufanyi",
            "type": "user"
          },
          "name": "Fanyi Pu",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:21:39.917Z",
          "hidden": false
        },
        {
          "_id": "67934585e4e44e2866b644f5",
          "user": {
            "_id": "647efcc945baf21ad707e10c",
            "avatarUrl": "/avatars/e2fab1c9031eb0eec9f015a8fc237f64.svg",
            "isPro": false,
            "fullname": "Wang Xiao",
            "user": "wangxiao1208",
            "type": "user"
          },
          "name": "Wang Xiao",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:21:46.540Z",
          "hidden": false
        },
        {
          "_id": "67934585e4e44e2866b644f6",
          "user": {
            "_id": "62a993d80472c0b7f94027df",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62a993d80472c0b7f94027df/j5vp-IwLA2YBexylUHiQU.png",
            "isPro": false,
            "fullname": "Zhang Yuanhan",
            "user": "ZhangYuanhan",
            "type": "user"
          },
          "name": "Yuanhan Zhang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:26:42.528Z",
          "hidden": false
        },
        {
          "_id": "67934585e4e44e2866b644f7",
          "user": {
            "_id": "6230d750d93e84e233882dbc",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6230d750d93e84e233882dbc/4MGEekLW3oWzqeFWDWvIK.jpeg",
            "isPro": false,
            "fullname": "Xiang Yue",
            "user": "yuexiang96",
            "type": "user"
          },
          "name": "Xiang Yue",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:27:14.894Z",
          "hidden": false
        },
        {
          "_id": "67934585e4e44e2866b644f8",
          "name": "Bo Li",
          "hidden": false
        },
        {
          "_id": "67934585e4e44e2866b644f9",
          "user": {
            "_id": "62ab1ac1d48b4d8b048a3473",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1656826685333-62ab1ac1d48b4d8b048a3473.png",
            "isPro": false,
            "fullname": "Ziwei Liu",
            "user": "liuziwei7",
            "type": "user"
          },
          "name": "Ziwei Liu",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:27:30.310Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-23T16:51:47.000Z",
      "title": "Video-MMMU: Evaluación de conocimiento en múltiples problemas de matemáticas",
      "summary": "El ser humano pasa por 3 etapas cognitivas para obtener conocimiento: la reconocimiento de la información, la comprensión del conocimiento y la aplicación del conocimiento en la resolución de problemas. Los videos son una media efectiva para este proceso de aprendizaje y pueden fomentar estas etapas cognitivas. Sin embargo, actualmente los marcadores de video no pueden evaluar de manera sistemática la capacidad de los modelos de grandes multimodales (LMMs) para obtener conocimiento. Esta limitación no se soluciona. Para resolver esto, se presenta el video-MMMU (marcador multimodal multidisciplinario de video). El video-MMMU selecciona 300 videos de nivel profesional en 6 disciplinas y 900 preguntas respuestadas por humanos para evaluar la obtención de conocimiento en las etapas de reconocimiento, comprensión y aplicación. La medida de beneficio del conocimiento propuesto, Δ conocimiento, cuantifica la mejora en el rendimiento después de ver el video. En la evaluación de los modelos, cuando aumenta la demanda cognitiva, el rendimiento disminuye rápidamente, y se destacan claramente las diferencias entre el conocimiento de los humanos y los modelos, lo que subraya la necesidad de mejorar la capacidad de aprendizaje y aplicación de los modelos.",
      "upvotes": 6,
      "discussionId": "67934587e4e44e2866b64597"
    },
    "publishedAt": "2025-01-24T04:24:01.412Z",
    "title": "Video-MMMU: Evaluating Knowledge Acquisition from Multi-Discipline Professional Videos",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.13826.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6400ba2b261cfa61f3a00555",
      "avatarUrl": "/avatars/1311e0b5e21b1c94d73fcaf455d3c7f7.svg",
      "fullname": "Kairui",
      "name": "KairuiHu",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 5
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2501.13554",
      "authors": [
        {
          "_id": "6793900eddc6cc37fdc74928",
          "user": {
            "_id": "65a909fe8581aad8c97a67d3",
            "avatarUrl": "/avatars/96570e47117e957543d9f0fe5e1d9d57.svg",
            "isPro": false,
            "fullname": "liutao",
            "user": "byliutao",
            "type": "user"
          },
          "name": "Tao Liu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-01-24T13:30:20.097Z",
          "hidden": false
        },
        {
          "_id": "6793900eddc6cc37fdc74929",
          "name": "Kai Wang",
          "hidden": false
        },
        {
          "_id": "6793900eddc6cc37fdc7492a",
          "name": "Senmao Li",
          "hidden": false
        },
        {
          "_id": "6793900eddc6cc37fdc7492b",
          "name": "Joost van de Weijer",
          "hidden": false
        },
        {
          "_id": "6793900eddc6cc37fdc7492c",
          "name": "Fahad Shahbaz Khan",
          "hidden": false
        },
        {
          "_id": "6793900eddc6cc37fdc7492d",
          "name": "Shiqi Yang",
          "hidden": false
        },
        {
          "_id": "6793900eddc6cc37fdc7492e",
          "name": "Yaxing Wang",
          "hidden": false
        },
        {
          "_id": "6793900eddc6cc37fdc7492f",
          "name": "Jian Yang",
          "hidden": false
        },
        {
          "_id": "6793900eddc6cc37fdc74930",
          "name": "Ming-Ming Cheng",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-23T10:57:22.000Z",
      "title": "Una frase con una historia: el Free-Lunch de la generación de imágenes a partir de texto coherente",
      "summary": "El modelo de generación de imágenes a partir de texto puede crear imágenes de alta calidad a partir de un prompt de entrada. Sin embargo, estos modelos tienen el desafío de mantener una identidad propia mientras generan imágenes coherentes, lo que hace que los métodos actuales generalmente requieran expandir el entrenamiento con grandes conjuntos de datos o modificaciones adicionales en la estructura del modelo original. Esto limita su aplicabilidad a otros conjuntos de datos o diferentes estructuras de modelos de entrenamiento. En este artículo, se reconocen las habilidades únicas y la coherencia contextual de los modelos de lenguaje, y se observa que un único prompt puede comprender una identidad propia. Basándose en esta coherencia, se propone un nuevo enfoque llamado \"One-Prompt-One-Story\" (1Prompt1Story), que no requiere entrenamiento adicional. 1Prompt1Story combina todos los prompts en un solo input para mantener la identidad propia desde el principio. A continuación, se utilizan dos nuevas técnicas: Singular-Value Reweighting y Identity-Preserving Cross-Attention para refinar el proceso de generación y mejorar la correspondencia entre cada frame y la explicación de entrada. Se demostró la efectividad de este enfoque comparando con los métodos actuales de generación coherente de T2I, utilizando medidas cualitativas y cuantitativas. El código está disponible en https://github.com/byliutao/1Prompt1Story.",
      "upvotes": 4,
      "discussionId": "67939013ddc6cc37fdc74a9d"
    },
    "publishedAt": "2025-01-24T08:34:50.383Z",
    "title": "One-Prompt-One-Story: Free-Lunch Consistent Text-to-Image Generation Using a Single Prompt",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.13554.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "65a909fe8581aad8c97a67d3",
      "avatarUrl": "/avatars/96570e47117e957543d9f0fe5e1d9d57.svg",
      "fullname": "liutao",
      "name": "byliutao",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2501.13452",
      "authors": [
        {
          "_id": "6793480ec6fd669f7341cf41",
          "name": "Jiangchuan Wei",
          "hidden": false
        },
        {
          "_id": "6793480ec6fd669f7341cf42",
          "name": "Shiyue Yan",
          "hidden": false
        },
        {
          "_id": "6793480ec6fd669f7341cf43",
          "user": {
            "_id": "6676c4f86f2ac48ee6c2f4d4",
            "avatarUrl": "/avatars/fea4e5be4da7a7047df567a4aa86de0c.svg",
            "isPro": false,
            "fullname": "linwenfeng",
            "user": "linwf",
            "type": "user"
          },
          "name": "Wenfeng Lin",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:18:06.509Z",
          "hidden": false
        },
        {
          "_id": "6793480ec6fd669f7341cf44",
          "name": "Boyuan Liu",
          "hidden": false
        },
        {
          "_id": "6793480ec6fd669f7341cf45",
          "name": "Renjie Chen",
          "hidden": false
        },
        {
          "_id": "6793480ec6fd669f7341cf46",
          "name": "Mingyu Guo",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-23T08:06:11.000Z",
      "title": "EchoVideo: Generación de vídeos humanos de mantenimiento de identidad mediante la integración de características multimodales",
      "summary": "El reciente avance en la generación de vídeos ha tenido un impacto especial en subescritos como la generación de vídeos de identidad (IPT2V). Sin embargo, los métodos actuales se enfrentan a problemas como artefactos de \"restauración rápida\" y una baja similitud debido a su dependencia de bajo nivel de información de imágenes faciales. Esta dependencia conduce a artefactos que reflejan excesiva rigidez facial y detalles irrelevantes. Para resolver estos problemas, proponemos EchoVideo, que utiliza dos estrategias clave: (1) el módulo de fusión de texto y características de imagen de identidad (IITF), que integra altos niveles de características significativas a partir del texto, claramente captura la identidad facial, elimina cambios en máscaras, posturas y luz para evitar el aparición de artefactos; (2) un proceso de aprendizaje en dos etapas, donde en la segunda etapa se incluye un método que utiliza información facial poco profunda de manera aleatoria. El objetivo es mejorar la fidelidad mediante características poco profundas y mitigar la dependencia excesiva. Este paso recomienda el uso de altos niveles de características durante el entrenamiento y fortalece la representación de la identidad facial. EchoVideo mantiene la identidad facial y la armonía en su totalidad. Las experimentaciones extendidas muestran resultados excelentes en la generación de alta calidad y controlable vídeos.",
      "upvotes": 4,
      "discussionId": "67934811c6fd669f7341cfbf"
    },
    "publishedAt": "2025-01-24T02:59:28.457Z",
    "title": "EchoVideo: Identity-Preserving Human Video Generation by Multimodal Feature Fusion",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.13452.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "63468720dd6d90d82ccf3450",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63468720dd6d90d82ccf3450/tVBFlmZNz8FRMkOrDaDID.jpeg",
      "fullname": "YSH",
      "name": "BestWishYsh",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 28
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.10799",
      "authors": [
        {
          "_id": "679208664e521de952ca0cdc",
          "user": {
            "_id": "5df9c78eda6d0311fd3d541f",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/5df9c78eda6d0311fd3d541f/8oDFuP77l5zhvamXNVmnc.jpeg",
            "isPro": false,
            "fullname": "Yen-Ting Lin",
            "user": "yentinglin",
            "type": "user"
          },
          "name": "Yen-Ting Lin",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-01-23T09:17:30.742Z",
          "hidden": false
        },
        {
          "_id": "679208664e521de952ca0cdd",
          "user": {
            "_id": "62f690dfc58915315c504af5",
            "avatarUrl": "/avatars/a6732dda8cd7e37d9c0e0b1dfb68c66b.svg",
            "isPro": false,
            "fullname": "Di Jin",
            "user": "jindi",
            "type": "user"
          },
          "name": "Di Jin",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:15:36.716Z",
          "hidden": false
        },
        {
          "_id": "679208664e521de952ca0cde",
          "name": "Tengyu Xu",
          "hidden": false
        },
        {
          "_id": "679208664e521de952ca0cdf",
          "name": "Tianhao Wu",
          "hidden": false
        },
        {
          "_id": "679208664e521de952ca0ce0",
          "user": {
            "_id": "66a8611eb51510d82ed54231",
            "avatarUrl": "/avatars/ad559e774fee4914091b82c9831ae2a2.svg",
            "isPro": false,
            "fullname": "Sainbayar Sukhbaatar",
            "user": "sainbar",
            "type": "user"
          },
          "name": "Sainbayar Sukhbaatar",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:16:23.763Z",
          "hidden": false
        },
        {
          "_id": "679208664e521de952ca0ce1",
          "name": "Chen Zhu",
          "hidden": false
        },
        {
          "_id": "679208664e521de952ca0ce2",
          "user": {
            "_id": "6437de5d51c7ebfc813ce68a",
            "avatarUrl": "/avatars/144cb1c5d5a4a645080611953494f437.svg",
            "isPro": false,
            "fullname": "he",
            "user": "yunhe",
            "type": "user"
          },
          "name": "Yun He",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:16:34.273Z",
          "hidden": false
        },
        {
          "_id": "679208664e521de952ca0ce3",
          "name": "Yun-Nung Chen",
          "hidden": false
        },
        {
          "_id": "679208664e521de952ca0ce4",
          "user": {
            "_id": "62f023a36a027498eaa2f9cc",
            "avatarUrl": "/avatars/8ac1c5c74d0957e3c6cc94b3a7795c37.svg",
            "isPro": false,
            "fullname": "Jason Weston",
            "user": "spermwhale",
            "type": "user"
          },
          "name": "Jason Weston",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:15:25.564Z",
          "hidden": false
        },
        {
          "_id": "679208664e521de952ca0ce5",
          "user": {
            "_id": "6344cf73ee1504dbcd5bdfe7",
            "avatarUrl": "/avatars/6dd2bf1f9c5679e5c8c85d62c9836aac.svg",
            "isPro": false,
            "fullname": "Yuandong Tian",
            "user": "tydsh",
            "type": "user"
          },
          "name": "Yuandong Tian",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:16:47.602Z",
          "hidden": false
        },
        {
          "_id": "679208664e521de952ca0ce6",
          "name": "Arash Rahnama",
          "hidden": false
        },
        {
          "_id": "679208664e521de952ca0ce7",
          "user": {
            "_id": "65b483c5ed110eb9f1ee62df",
            "avatarUrl": "/avatars/29100098f5aed1735675d06c516a85b7.svg",
            "isPro": false,
            "fullname": "Sinong Wang",
            "user": "TheronWong",
            "type": "user"
          },
          "name": "Sinong Wang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:17:03.211Z",
          "hidden": false
        },
        {
          "_id": "679208664e521de952ca0ce8",
          "name": "Hao Ma",
          "hidden": false
        },
        {
          "_id": "679208664e521de952ca0ce9",
          "name": "Han Fang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-18T15:38:03.000Z",
      "title": "Step・Casion・Optimizer: Optimización de la lógica matemática basada en retroalimentación de valores por pasos",
      "summary": "Los grandes modelos de lenguaje (LLMs) han tenido un éxito sorprendente en la teoría de cálculo matemático recientemente. El desarrollo de métodos como la asociación contínente o el sampling de auto-consistencia ha demostrado que, para garantizar la precisión final, la armonía y la confiabilidad básicas de la teoría no son necesariamente necesarios. En este artículo, se presenta un marco de entrenamiento llamado \"Step-KTO\", que combina retroalimentación binaria en niveles de etapa y resultado para guiar el camino de la teoría evolutiva. Al proporcionar evaluaciones binarias tanto en nivel de etapa como en nivel de resultado, el modelo se incentiva a priorizar el proceso lógico y a no creer en cortos caminos superficiales. Las experimentaciones en difíciles marcos de prueba matemáticos han confirmado que aumentando la calidad de la teoría en nivel de etapa mejora significativamente la precisión final del resultado. Por ejemplo, en el conjunto de datos MATH-500, se ha confirmado que aumentar la calidad de la teoría en nivel de etapa mejora significativamente la precisión final del resultado. Estos resultados muestran la posibilidad de incluir retroalimentación de progreso en el entrenamiento de LLMs de manera estadística y abren el camino hacia la funcionalidad de teorías interpretables y confiables.",
      "upvotes": 4,
      "discussionId": "679208674e521de952ca0d2f"
    },
    "publishedAt": "2025-01-23T22:32:09.207Z",
    "title": "Step-KTO: Optimizing Mathematical Reasoning through Stepwise Binary Feedback",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/5df9c78eda6d0311fd3d541f/VXjkUKeidLg_JO5d3RWUG.jpeg"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.10799.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "5df9c78eda6d0311fd3d541f",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/5df9c78eda6d0311fd3d541f/8oDFuP77l5zhvamXNVmnc.jpeg",
      "fullname": "Yen-Ting Lin",
      "name": "yentinglin",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 281
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2501.13124",
      "authors": [
        {
          "_id": "6793188b56f015277a9ed95c",
          "user": {
            "_id": "65a6131fee7aa779f5bf8329",
            "avatarUrl": "/avatars/aa25cc3153fd7e511b51b801e8107564.svg",
            "isPro": false,
            "fullname": "langhao",
            "user": "langnick",
            "type": "user"
          },
          "name": "Hao Lang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:09:24.142Z",
          "hidden": false
        },
        {
          "_id": "6793188b56f015277a9ed95d",
          "user": {
            "_id": "635b8b6a37c6a2c12e2cce00",
            "avatarUrl": "/avatars/229fb72180529141515d1df797b33709.svg",
            "isPro": false,
            "fullname": "Fei Huang",
            "user": "hzhwcmhf",
            "type": "user"
          },
          "name": "Fei Huang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:09:39.353Z",
          "hidden": false
        },
        {
          "_id": "6793188b56f015277a9ed95e",
          "user": {
            "_id": "66641b2fd8e1e34bc621e688",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/66641b2fd8e1e34bc621e688/csPETwnx2zCIHSWi9uAi-.png",
            "isPro": false,
            "fullname": "Yongbin Li",
            "user": "Yongbin-Li",
            "type": "user"
          },
          "name": "Yongbin Li",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:08:59.394Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-21T05:36:13.000Z",
      "title": "Debe actuar como un catalizador de la generalización de las características débiles hacia las características fuertes.",
      "summary": "Usualmente, los métodos para alinear la capacidad del modelo con el comportamiento esperado se basan en la capacidad de supervisión proporcionada por los humanos. Sin embargo, los modelos futuros de humanoides superiores superarán las capacidades humanas. Por lo tanto, los humanos podrán solo supervisar estos modelos de humanoides superiores de manera débil. Esta insuficiencia de evaluación humana prevista debilitará la seguridad de los sistemas de IA futuros. Dos métodos complementarios para abordar este problema son la supervisión expandible y la generalización de la supervisión desde débil a fuerte. En este artículo, intentamos mejorar la coincidencia a través de la combinación de estos dos métodos. Específicamente, investigamos cómo mejorar la supervisión humana utilizando modelos preentrenados fuertes y, posteriormente, cómo utilizar la supervisión débil fortalecida para supervisar modelos fuertes. Para la progresión empírica iterativa, consideramos la siguiente analogía: determinar si se puede mejorar la supervisión de un modelo débil utilizando un modelo fuerte, y luego si se puede utilizar este modelo débil para mejorar un modelo fuerte. Realizamos experimentos utilizando un pequeño modelo débil ajustado a etiquetas reales, y un modelo fuerte grande para ajustar el modelo fuerte con las etiquetas generadas por el modelo débil. Encontramos que el debate de un modelo débil puede extraer información confiable de un modelo fuerte, lo que proporciona contexto durante el entrenamiento. Además, mostramos que la integración de un modelo débil permite obtener estimaciones de supervisión más robustas utilizando el largo debate generado por el modelo fuerte. A través de una amplia gama de experimentos en las pruebas de NLP desde débil a fuerte de OpenAI, demostramos que el método combinado muestra una mejor coincidencia, lo que indica la potencial de que el debate puede ayudar a la generalización desde débil a fuerte.",
      "upvotes": 3,
      "discussionId": "6793188d56f015277a9ed9aa"
    },
    "publishedAt": "2025-01-23T23:35:50.957Z",
    "title": "Debate Helps Weak-to-Strong Generalization",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.13124.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "62e0ef42edb0462c8d51818d",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62e0ef42edb0462c8d51818d/3YM7DUynIWiiRFM6_enpg.jpeg",
      "fullname": "Ting-En Lin",
      "name": "tnlin",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 9
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.13075",
      "authors": [
        {
          "_id": "6791ae54330198cc26b72479",
          "user": {
            "_id": "6444241e9c1bd83bd19ea70f",
            "avatarUrl": "/avatars/24b4e65f26f5f8dcc1465cef67fd334b.svg",
            "isPro": false,
            "fullname": "Joel Lehman",
            "user": "jal278",
            "type": "user"
          },
          "name": "Joel Lehman",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-01-23T02:49:57.110Z",
          "hidden": false
        },
        {
          "_id": "6791ae54330198cc26b7247a",
          "user": {
            "_id": "6514b7fde1273c28705142cc",
            "avatarUrl": "/avatars/072bf14abd8ef17d9393338a20157cc2.svg",
            "isPro": false,
            "fullname": "Elliot Meyerson",
            "user": "ekmeyerson",
            "type": "user"
          },
          "name": "Elliot Meyerson",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:20:51.128Z",
          "hidden": false
        },
        {
          "_id": "6791ae54330198cc26b7247b",
          "name": "Tarek El-Gaaly",
          "hidden": false
        },
        {
          "_id": "6791ae54330198cc26b7247c",
          "name": "Kenneth O. Stanley",
          "hidden": false
        },
        {
          "_id": "6791ae54330198cc26b7247d",
          "name": "Tarin Ziyaee",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-22T18:38:41.000Z",
      "title": "El desarrollo de la inteligencia artificial y el enigma de la visión artificial",
      "summary": "Este artículo argumenta que la inteligencia artificial (IA) ha abierto una brecha importante en un aspecto crucial de la inteligencia general: la robustez frente a un futuro desconocido de manera cualitativa en un mundo abierto. Esta robustez se relaciona con la incertidumbre de Knightian (IK), es decir, la incertidumbre que no puede ser cuantificada, y que no se considera en los principios teóricos principales de la IA. El artículo identifica estas lacunas y sostiene su importancia, lo que busca incentivar investigaciones para resolverlas. Consideramos que esto es esencial para hacer que la IA en un mundo abierto sea realmente robusta y comparamos el aprendizaje por refuerzo (RL) -un subcampo de la IA- con el proceso biológico de la evolución. Aunque la evolución avanza a una velocidad sorprendente, el RL aún enfrenta desafíos en un mundo abierto y frecuentemente falla en situaciones inesperadas. Por ejemplo, es muy ambicioso introducir políticas de conducción autónoma entrenado únicamente en Estados Unidos en Reino Unido. En contraste, la evolución biológica generalmente produce agentes que pueden sobrevivir en un mundo abierto, incluso en situaciones extremas y desconocidas (por ejemplo, invasión de especies o el ejercicio de un 0-shot de conducción internacional). Interesantemente, la evolución logra esta robustez sin necesidad de teorías explícitas, formalismos o matemáticas. Investigamos las bases de los principios generales de RL y mostramos cómo reflejan las características específicas de un mundo complejo y cambiante con \"unknown unknowns\". Además, identificamos las estructuras que la evolución utiliza para fomentar la robustez frente a nuevos desafíos y discutimos posibles pasos hacia una implementación algorítmica. En conclusión, las vulnerabilidades interesantes que resta a la IA pueden surgir en puntos de blind spots de la teoría y se pueden mejorar significativamente al enfrentar directamente el desafío de la IK.",
      "upvotes": 2,
      "discussionId": "6791ae55330198cc26b724bc"
    },
    "publishedAt": "2025-01-24T01:17:22.150Z",
    "title": "Evolution and The Knightian Blindspot of Machine Learning",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.13075.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6444241e9c1bd83bd19ea70f",
      "avatarUrl": "/avatars/24b4e65f26f5f8dcc1465cef67fd334b.svg",
      "fullname": "Joel Lehman",
      "name": "jal278",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2501.13824",
      "authors": [
        {
          "_id": "6793a52265c4dd63499ca548",
          "user": {
            "_id": "662ce44c8b8705f30371fba8",
            "avatarUrl": "/avatars/b96a25a8c124e7caa9de06b7188bdc15.svg",
            "isPro": false,
            "fullname": "Shuzhou Yuan",
            "user": "shuzyuan",
            "type": "user"
          },
          "name": "Shuzhou Yuan",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-01-24T14:52:27.570Z",
          "hidden": false
        },
        {
          "_id": "6793a52265c4dd63499ca549",
          "name": "Michael Färber",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-23T16:45:51.000Z",
      "title": "Horowitzson puede mejorar grandes modelos de lenguaje para la detección de sustancias.",
      "summary": "La preocupación por el \"hallucination\" en modelos de lenguaje de la Tierra (LLMs) es un problema que atrae la atención de los investigadores, pero el \"hallucination\" tiene potencial en campos creativos, y en particular, se valora en el campo de la descubrimiento de fármacos por su valor para la exploración. En este artículo, se propone que el \"hallucination\" puede mejorar los LLMs en el campo de la descubrimiento de fármacos. Para verificar esta hipótesis, se evaluaron 7 modelos de LLMs y 5 tareas de clasificación utilizando la explicación en lenguaje natural de las secuencias de SMILES de moléculas, generadas por los modelos de LLMs, como parte de los prompts para tareas específicas de descubrimiento de fármacos. Nuestros hallazgos confirmaron que los modelos de LLMs pueden lograr mejores resultados con textos que incluyen \"hallucination\". En particular, Llama-3.1-8B logró una mejora del 18.35% en la ROC-AUC en comparación con un modelo de referencia sin \"hallucination\". Además, la mejor mejora consistente en el modelo completo fue proporcionada por la generación de GPT-4o. Además, se realizaron análisis experimentales y estudios de caso para investigar los factores que afectan el rendimiento y sus fundamentos. Este estudio revela el potencial de la \"hallucination\" en los LLMs y ofrece nuevas perspectivas para las investigaciones futuras que buscan expandir la aplicación de los LLMs en el campo de la descubrimiento de fármacos.",
      "upvotes": 1,
      "discussionId": "6793a52465c4dd63499ca5ad"
    },
    "publishedAt": "2025-01-24T09:39:01.834Z",
    "title": "Hallucinations Can Improve Large Language Models in Drug Discovery",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.13824.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "662ce44c8b8705f30371fba8",
      "avatarUrl": "/avatars/b96a25a8c124e7caa9de06b7188bdc15.svg",
      "fullname": "Shuzhou Yuan",
      "name": "shuzyuan",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2501.10283",
      "authors": [
        {
          "_id": "67934e1511eb9c774dd1bfc3",
          "user": {
            "_id": "67936c63ddd1e487c0c6c691",
            "avatarUrl": "/avatars/6d57469b4afdc8bedffeea9ed5f59dd4.svg",
            "isPro": false,
            "fullname": "Chengwei Zheng",
            "user": "zhengcw18",
            "type": "user"
          },
          "name": "Chengwei Zheng",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-01-24T13:30:16.388Z",
          "hidden": false
        },
        {
          "_id": "67934e1511eb9c774dd1bfc4",
          "user": {
            "_id": "645b95f8438d6cfbe1ae8256",
            "avatarUrl": "/avatars/ac0ebb0a73569ab063c5b2f28c509d23.svg",
            "isPro": false,
            "fullname": "Lixin Xue",
            "user": "lxxue",
            "type": "user"
          },
          "name": "Lixin Xue",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-24T10:27:50.665Z",
          "hidden": false
        },
        {
          "_id": "67934e1511eb9c774dd1bfc5",
          "name": "Juan Zarate",
          "hidden": false
        },
        {
          "_id": "67934e1511eb9c774dd1bfc6",
          "name": "Jie Song",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-17T16:26:24.000Z",
      "title": "GSTAR: Tracking y Reconstrucción de Superficies Gaussianas",
      "summary": "La tecnología de Gauss 3D ha tenido éxito en la renderización eficiente de imágenes estáticas. Recientes estudios han expandido esta metodología para la configuración y seguimiento de superficies. Sin embargo, la seguimiento de superficies dinámicas utilizando Gauss 3D puede enfrentarse a desafíos debido a cambios topologías complejos, como cuando las superficies aparecen, desaparecen o se separan. Para responder a estos desafíos, proponemos la metodología GSTAR. GSTAR realiza la renderización de imágenes de cine dinámico general, configuración de superficies precisa y seguimiento 3D confiable de superficies dinámicas con cambios topologías. GSTAR toma como entrada múltiples fotografías y combina Gauss en las superficies de un malla para representar objetos dinámicos. Para superficies con topologías consistentes, GSTAR mantiene la topología del malla y seguimiento utilizando Gauss. En lugares donde la topología cambia, GSTAR adapta la combinación y separación de Gauss en el malla, permitiendo la creación de nuevas superficies basadas en estas adaptaciones óptimas. Además, presentamos un método de flujo cinematográfico basado en superficies y una inicialización fuerte para el seguimiento entre frames. Las experimentaciones demuestran que nuestro enfoque permite seguir y configurar superficies dinámicas con precisión, facilitando diversas aplicaciones. El código de la implementación y la página del proyecto están disponibles en https://eth-ait.github.io/GSTAR/.",
      "upvotes": 1,
      "discussionId": "67934e1611eb9c774dd1bffe"
    },
    "publishedAt": "2025-01-24T03:24:06.601Z",
    "title": "GSTAR: Gaussian Surface Tracking and Reconstruction",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.10283.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "5f1158120c833276f61f1a84",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1608042047613-5f1158120c833276f61f1a84.jpeg",
      "fullname": "Niels Rogge",
      "name": "nielsr",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 735
    },
    "isAuthorParticipating": false
  }
]