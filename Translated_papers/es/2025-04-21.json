[
  {
    "paper": {
      "id": "2504.13835",
      "authors": [
        {
          "_id": "6805b38355d3c792e1a9d0dd",
          "name": "Yicheng Chen",
          "hidden": false
        },
        {
          "_id": "6805b38355d3c792e1a9d0de",
          "name": "Yining Li",
          "hidden": false
        },
        {
          "_id": "6805b38355d3c792e1a9d0df",
          "name": "Kai Hu",
          "hidden": false
        },
        {
          "_id": "6805b38355d3c792e1a9d0e0",
          "name": "Zerun Ma",
          "hidden": false
        },
        {
          "_id": "6805b38355d3c792e1a9d0e1",
          "name": "Haochen Ye",
          "hidden": false
        },
        {
          "_id": "6805b38355d3c792e1a9d0e2",
          "name": "Kai Chen",
          "hidden": false
        }
      ],
      "publishedAt": "2025-04-18T17:59:46.000Z",
      "submittedOnDailyAt": "2025-04-21T01:39:08.191Z",
      "title": "MIG: Maximización de beneficios de información mediante ajuste genético semántico en espacios de datos seleccionados automáticamente",
      "submittedOnDailyBy": {
        "_id": "649988726677f66c2b486392",
        "avatarUrl": "/avatars/b649a77370660e129726e29504daba34.svg",
        "isPro": false,
        "fullname": "Yining Li",
        "user": "ly015",
        "type": "user"
      },
      "summary": "La calidad y diversidad de los datos son elementos importantes para la construcción de un conjunto de datos de entrenamiento de instrucciones válidas. Con el aumento de la utilización de conjuntos de datos de entrenamiento de instrucciones abiertos, es beneficioso seleccionar automáticamente un subconjunto de alta calidad y diversidad en muchos de los datos. Los métodos actuales priorizan generalmente la calidad de las instancias y mantienen la diversidad utilizando reglas heurísticas, pero estos métodos no ofrecen una visión coherente a nivel de todo el conjunto de datos, lo que puede limitar los resultados óptimos. Además, las reglas heurísticas generalmente se centran en la distancia dentro del espacio de datos o en el clustering, lo que impide detectar exactamente el significado de instrucciones complejas. Para cerrar esta brecha, se propone un método unificado para cuantificar la información del conjunto de datos. Este método construye grafos de etiquetas para modelar el espacio simbólico y cuantifica la diversidad basándose en la distribución de la información dentro del grafo. Con esta evaluación, se introduce eficientemente un método de muestreo de datos y se seleccionan repetidamente muestras de datos para minimizar la pérdida de información y maximizar el ganancia de información en el espacio simbólico. Experimentos con diferentes conjuntos de datos y modelos de base muestran que este método supera los métodos más avanzados. En particular, el uso de 5% de los datos de Tulu3 muestreados con MIG para fines de ajuste ha mostrado que los modelos ajustados son comparables a los modelos SFT entrenados con el conjunto completo de datos, con mejoras relativas de +5.73% en AlpacaEval y +6.89% en Wildbench.",
      "upvotes": 26,
      "discussionId": "6805b38555d3c792e1a9d155",
      "projectPage": "https://yichengchen24.github.io/projects/mig",
      "githubRepo": "https://github.com/yichengchen24/MIG",
      "ai_keywords": [
        "label graph",
        "semantic space",
        "information content",
        "Maximize the Information Gain (MIG)"
      ]
    },
    "publishedAt": "2025-04-18T13:59:46.000Z",
    "title": "MIG: Automatic Data Selection for Instruction Tuning by Maximizing\n  Information Gain in Semantic Space",
    "summary": "Data quality and diversity are key to the construction of effective\ninstruction-tuning datasets. % With the increasing availability of open-source\ninstruction-tuning datasets, it is advantageous to automatically select\nhigh-quality and diverse subsets from a vast amount of data. % Existing methods\ntypically prioritize instance quality and use heuristic rules to maintain\ndiversity. % However, this absence of a comprehensive view of the entire\ncollection often leads to suboptimal results. % Moreover, heuristic rules\ngenerally focus on distance or clustering within the embedding space, which\nfails to accurately capture the intent of complex instructions in the semantic\nspace. % To bridge this gap, we propose a unified method for quantifying the\ninformation content of datasets. This method models the semantic space by\nconstructing a label graph and quantifies diversity based on the distribution\nof information within the graph. % Based on such a measurement, we further\nintroduce an efficient sampling method that selects data samples iteratively to\nMaximize the Information Gain (MIG) in semantic\nspace. % Experiments on various datasets and base models demonstrate that MIG\nconsistently outperforms state-of-the-art methods. % Notably, the model\nfine-tuned with 5\\% Tulu3 data sampled by MIG achieves comparable performance\nto the official SFT model trained on the full dataset, with improvements of\n+5.73\\% on AlpacaEval and +6.89\\% on Wildbench.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.13835.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "649988726677f66c2b486392",
      "avatarUrl": "/avatars/b649a77370660e129726e29504daba34.svg",
      "fullname": "Yining Li",
      "name": "ly015",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 3
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2504.13837",
      "authors": [
        {
          "_id": "6805b9ec7c5fa8020f595642",
          "name": "Yang Yue",
          "hidden": false
        },
        {
          "_id": "6805b9ec7c5fa8020f595643",
          "name": "Zhiqi Chen",
          "hidden": false
        },
        {
          "_id": "6805b9ec7c5fa8020f595644",
          "name": "Rui Lu",
          "hidden": false
        },
        {
          "_id": "6805b9ec7c5fa8020f595645",
          "name": "Andrew Zhao",
          "hidden": false
        },
        {
          "_id": "6805b9ec7c5fa8020f595646",
          "name": "Zhaokai Wang",
          "hidden": false
        },
        {
          "_id": "6805b9ec7c5fa8020f595647",
          "name": "Yang Yue",
          "hidden": false
        },
        {
          "_id": "6805b9ec7c5fa8020f595648",
          "name": "Shiji Song",
          "hidden": false
        },
        {
          "_id": "6805b9ec7c5fa8020f595649",
          "name": "Gao Huang",
          "hidden": false
        }
      ],
      "mediaUrls": [
        "https://cdn-uploads.huggingface.co/production/uploads/649d475111592b1a765ac1a3/2KWQqFdVDUCAu-kSu87fa.jpeg",
        "https://cdn-uploads.huggingface.co/production/uploads/649d475111592b1a765ac1a3/rF4cAa6DAI3EaejDV_dgG.mp4"
      ],
      "publishedAt": "2025-04-18T17:59:56.000Z",
      "submittedOnDailyAt": "2025-04-21T01:54:36.096Z",
      "title": "¿La aprendizaje por refuerzo es capaz de superar los modelos básicos y desencadenar una teoría sobre el capacidad lógica de los LLM?",
      "submittedOnDailyBy": {
        "_id": "649d475111592b1a765ac1a3",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/649d475111592b1a765ac1a3/rjORJjErJq-mthghan08U.jpeg",
        "isPro": false,
        "fullname": "Yang Yue",
        "user": "Yang130",
        "type": "user"
      },
      "summary": "RLVR (Rewards Verifiable) ha demostrado un significativo éxito recientemente en la mejora de las capacidades de inferencia de los LLM, especialmente en tareas de matemáticas y programación, mostrando un rendimiento excepcional. Generalmente, se piensa que RLVR permite que los modelos LLM se auto-mejoren continuamente, adquiriendo nuevas habilidades de inferencia que superen a los modelos básicos. Sin embargo, en este estudio, se revisa críticamente estas asunciones, evaluando el rendimiento con métricas de pass@k utilizando grandes valores de k y investigando la capacidad de inferencia de diferentes familias de modelos y marcos de prueba. Sorprendentemente, se descubrió que RL no extrae de manera fundamental nuevos patrones de inferencia. Los modelos entrenados con RL muestran mejores rendimientos para pequeños valores de k (por ejemplo, k=1) en comparación con los modelos básicos, pero observa-se que los modelos básicos alcanzan puntuaciones más altas de pass@k para grandes valores de k. Las rutas de inferencia generadas por modelos entrenados con RL ya están incluidas en la distribución de muestreo de los modelos básicos, lo que demuestra que las habilidades de inferencia obtenidas por estos modelos ya existían en los modelos básicos. Además, el entrenamiento con RL ajusta la distribución de salida del modelo hacia las rutas que otorgan recompensas fácilmente, mejorando la eficiencia en la muestra de respuestas precisas. Sin embargo, este método observa una estrecha frontera de capacidad de inferencia en comparación con los modelos básicos. Similares resultados se obtuvieron en tareas de inferencia visualizada utilizando RLVR. Además, se confirmó la capacidad de introducir nuevos conocimientos en los modelos a través de RLVR. Estos hallazgos demuestran limitaciones importantes de RLVR para mejorar la capacidad de inferencia de los LLM y exigen una revisión fundamental del impacto del entrenamiento con RL y la necesidad de mejores paradigmas. Página del proyecto: https://limit-of-RLVR.github.io",
      "upvotes": 24,
      "discussionId": "6805b9ed7c5fa8020f59568c",
      "projectPage": "https://limit-of-rlvr.github.io/",
      "githubRepo": "https://github.com/LeapLabTHU/limit-of-RLVR",
      "ai_keywords": [
        "Reinforcement Learning",
        "Verifiable Rewards",
        "RLVR",
        "LLMs (Large Language Models)",
        "reasoning capabilities",
        "mathematics",
        "programming tasks",
        "pass@\\textit{k}",
        "benchmark",
        "RL-trained models",
        "base models",
        "reasoning paths",
        "sampling distribution",
        "performance",
        "biasing",
        "output distribution",
        "visual reasoning tasks",
        "distillation"
      ]
    },
    "publishedAt": "2025-04-18T13:59:56.000Z",
    "title": "Does Reinforcement Learning Really Incentivize Reasoning Capacity in\n  LLMs Beyond the Base Model?",
    "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has recently\ndemonstrated notable success in enhancing the reasoning capabilities of LLMs,\nparticularly in mathematics and programming tasks. It is widely believed that\nRLVR enables LLMs to continuously self-improve, thus acquiring novel reasoning\nabilities that exceed corresponding base models' capacity. In this study,\nhowever, we critically re-examines this assumption by measuring the\npass@k metric with large values of k to explore the reasoning\ncapability boundary of the models across a wide range of model families and\nbenchmarks. Surprisingly, the RL does not, in fact, elicit fundamentally\nnew reasoning patterns. While RL-trained models outperform their base models at\nsmaller values of k (\\eg, k=1), base models can achieve a comparable or\neven higher pass@k score compared to their RL counterparts at large k\nvalues. The reasoning paths generated by RL-trained models are already included\nin the base models' sampling distribution, suggesting that most reasoning\nabilities manifested in RL-trained models are already obtained by base models.\nFurther analysis shows that RL training boosts the performance by biasing the\nmodel's output distribution toward paths that are more likely to yield rewards,\ntherefore sampling correct responses more efficiently. But this also results in\na narrower reasoning capability boundary compared to base models. Similar\nresults are observed in visual reasoning tasks trained with RLVR. Moreover, we\nfind that distillation can genuinely introduce new knowledge into the model,\ndifferent from RLVR. These findings underscore a critical limitation of RLVR in\nadvancing LLM reasoning abilities which requires us to fundamentally rethink\nthe impact of RL training in reasoning LLMs and the need of a better paradigm.\nProject Page: https://limit-of-RLVR.github.io",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/649d475111592b1a765ac1a3/2KWQqFdVDUCAu-kSu87fa.jpeg",
      "https://cdn-uploads.huggingface.co/production/uploads/649d475111592b1a765ac1a3/rF4cAa6DAI3EaejDV_dgG.mp4"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.13837.png",
    "numComments": 6,
    "submittedBy": {
      "_id": "649d475111592b1a765ac1a3",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/649d475111592b1a765ac1a3/rjORJjErJq-mthghan08U.jpeg",
      "fullname": "Yang Yue",
      "name": "Yang130",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2504.11833",
      "authors": [
        {
          "_id": "6805bb01747a412bca737b53",
          "name": "Changjiang Gao",
          "hidden": false
        },
        {
          "_id": "6805bb01747a412bca737b54",
          "name": "Xu Huang",
          "hidden": false
        },
        {
          "_id": "6805bb01747a412bca737b55",
          "name": "Wenhao Zhu",
          "hidden": false
        },
        {
          "_id": "6805bb01747a412bca737b56",
          "name": "Shujian Huang",
          "hidden": false
        },
        {
          "_id": "6805bb01747a412bca737b57",
          "name": "Lei Li",
          "hidden": false
        },
        {
          "_id": "6805bb01747a412bca737b58",
          "name": "Fei Yuan",
          "hidden": false
        }
      ],
      "publishedAt": "2025-04-16T07:45:10.000Z",
      "submittedOnDailyAt": "2025-04-21T01:57:09.327Z",
      "title": "El diversidad de lenguajes puede fortalecer la capacidad de inferencia de modelos de lenguaje de gran escala.",
      "submittedOnDailyBy": {
        "_id": "65fed45b08d35929362dd651",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65fed45b08d35929362dd651/KLMxsyRN6_HhCZP1iDw6K.png",
        "isPro": false,
        "fullname": "FeiYuan",
        "user": "FeYuan",
        "type": "user"
      },
      "summary": "Según los estudios previos, los modelos de lenguaje de gran escala muestran un significativo \"fenómeno de sesgo hacia el inglés\" y muestran un rendimiento mucho mejor cuando las tareas son proporcionadas en inglés. Interesantemente, hemos observado que se puede obtener un mejor rendimiento en tareas lógicas utilizando un lenguaje específico. Sin embargo, estas observaciones aún no han sido suficientemente investigadas. En este artículo, evaluamos las limitaciones del uso multilingüe en tareas lógicas y mostramos que, comparados con lógicas en inglés, las lógicas multilingües pueden mejorar su rendimiento en aproximadamente 10 puntos de Acc@k y presentan limitaciones de robustez (resistencia a la calidad de traducción y a la elección del lenguaje). Además, analizamos las causas de estas limitaciones y los problemas que surgen en el proceso de alcanzar estas mejoras, revelando que los métodos generales de selección de respuestas no logran alcanzar estas mejoras. Estos hallazgos esperamos ser útiles para futuras investigaciones que busquen aprovechar plenamente la potencial de las lógicas multilingües en modelos de lenguaje grandes.",
      "upvotes": 14,
      "discussionId": "6805bb02747a412bca737b7e",
      "githubRepo": "https://github.com/CONE-MT/multilingual_reasoning"
    },
    "publishedAt": "2025-04-16T03:45:10.000Z",
    "title": "Could Thinking Multilingually Empower LLM Reasoning?",
    "summary": "Previous work indicates that large language models exhibit a significant\n\"English bias\", i.e. they often perform better when tasks are presented in\nEnglish. Interestingly, we have observed that using certain other languages in\nreasoning tasks can yield better performance than English. However, this\nphenomenon remains under-explored. In this paper, we explore the upper bound of\nharnessing multilingualism in reasoning tasks, suggesting that multilingual\nreasoning promises significantly (by nearly 10 Acc@k points) and robustly\n(tolerance for variations in translation quality and language choice) higher\nupper bounds than English-only reasoning. Besides analyzing the reason behind\nthe upper bound and challenges in reaching it, we also find that common answer\nselection methods cannot achieve this upper bound, due to their limitations and\nbiases. These insights could pave the way for future research aimed at fully\nharnessing the potential of multilingual reasoning in LLMs.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.11833.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "65fed45b08d35929362dd651",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65fed45b08d35929362dd651/KLMxsyRN6_HhCZP1iDw6K.png",
      "fullname": "FeiYuan",
      "name": "FeYuan",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 21
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2504.13072",
      "authors": [
        {
          "_id": "6805bfc5e332a61dd90160b0",
          "name": "Wenqi Dong",
          "hidden": false
        },
        {
          "_id": "6805bfc5e332a61dd90160b1",
          "name": "Bangbang Yang",
          "hidden": false
        },
        {
          "_id": "6805bfc5e332a61dd90160b2",
          "name": "Zesong Yang",
          "hidden": false
        },
        {
          "_id": "6805bfc5e332a61dd90160b3",
          "name": "Yuan Li",
          "hidden": false
        },
        {
          "_id": "6805bfc5e332a61dd90160b4",
          "name": "Tao Hu",
          "hidden": false
        },
        {
          "_id": "6805bfc5e332a61dd90160b5",
          "name": "Hujun Bao",
          "hidden": false
        },
        {
          "_id": "6805bfc5e332a61dd90160b6",
          "name": "Yuewen Ma",
          "hidden": false
        },
        {
          "_id": "6805bfc5e332a61dd90160b7",
          "name": "Zhaopeng Cui",
          "hidden": false
        }
      ],
      "mediaUrls": [
        "https://cdn-uploads.huggingface.co/production/uploads/63d748ff6f49aa82306b7e48/DNTOfy5oOkjTJwLBeGOUH.qt"
      ],
      "publishedAt": "2025-04-17T16:33:39.000Z",
      "submittedOnDailyAt": "2025-04-21T03:26:56.809Z",
      "title": "Scene: 3D Escurridización en proceso de generación de vistas de ángulo recto para la fabricación escalonada de escurridización",
      "submittedOnDailyBy": {
        "_id": "63d748ff6f49aa82306b7e48",
        "avatarUrl": "/avatars/9f0b8b8a09b14d76e52ed1bd312e6b63.svg",
        "isPro": false,
        "fullname": "BB Yang",
        "user": "ybbbbt",
        "type": "user"
      },
      "summary": "La generación 3D es una frontera importante en multimedia y graficas computacionales, pero los métodos actuales tienen limitaciones en la clasificación de objetos y la flexibilidad de edición en aplicaciones de interacción. En este artículo, se presenta un nuevo marco etapa por etapa llamado \"HiScene\" para reducir la brecha entre la generación de imágenes 2D y la generación de objetos 3D. Este marco permite la generación de vistas con alta precisión y con un contenido cinematográfico artístico. Nuestra idea principal es tratar las vistas como \"objetos\" en etapas en las transformaciones equidistantes. De esta manera, las ventanas pueden ser más complejas y pueden ser más divididas, y cada ítem puede ser más dividido. Este enfoque etapa por etapa permite que el contenido 3D coincida con la representación 2D mientras se mantiene la estructura constructiva. Para garantizar la completitud y la alineación espacial de cada instancia dividida, se utilizan técnicas de modelado basadas en difusión de video que efectivamente realizan procesamiento de bandas y procesamiento de imágenes, así como la introducción de inyección de prioridades de forma para garantizar la coherencia espacial. Los resultados de los experimentos muestran que nuestro método genera disposiciones naturales de objetos y instancias completas, manteniendo la razonabilidad física y la coincidencia con la entrada del usuario.",
      "upvotes": 5,
      "discussionId": "6805bfc9e332a61dd901618b",
      "ai_keywords": [
        "hierarchical framework",
        "2D image generation",
        "3D object generation",
        "video-diffusion-based amodal completion",
        "occlusions",
        "shadows",
        "shape prior injection",
        "spatial coherence",
        "natural object arrangements",
        "complete object instances",
        "interactive applications",
        "physical plausibility",
        "user inputs"
      ]
    },
    "publishedAt": "2025-04-17T12:33:39.000Z",
    "title": "HiScene: Creating Hierarchical 3D Scenes with Isometric View Generation",
    "summary": "Scene-level 3D generation represents a critical frontier in multimedia and\ncomputer graphics, yet existing approaches either suffer from limited object\ncategories or lack editing flexibility for interactive applications. In this\npaper, we present HiScene, a novel hierarchical framework that bridges the gap\nbetween 2D image generation and 3D object generation and delivers high-fidelity\nscenes with compositional identities and aesthetic scene content. Our key\ninsight is treating scenes as hierarchical \"objects\" under isometric views,\nwhere a room functions as a complex object that can be further decomposed into\nmanipulatable items. This hierarchical approach enables us to generate 3D\ncontent that aligns with 2D representations while maintaining compositional\nstructure. To ensure completeness and spatial alignment of each decomposed\ninstance, we develop a video-diffusion-based amodal completion technique that\neffectively handles occlusions and shadows between objects, and introduce shape\nprior injection to ensure spatial coherence within the scene. Experimental\nresults demonstrate that our method produces more natural object arrangements\nand complete object instances suitable for interactive applications, while\nmaintaining physical plausibility and alignment with user inputs.",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/63d748ff6f49aa82306b7e48/DNTOfy5oOkjTJwLBeGOUH.qt"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.13072.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "63d748ff6f49aa82306b7e48",
      "avatarUrl": "/avatars/9f0b8b8a09b14d76e52ed1bd312e6b63.svg",
      "fullname": "BB Yang",
      "name": "ybbbbt",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2504.13157",
      "authors": [
        {
          "_id": "6804392129303a3402c4f38e",
          "user": {
            "_id": "631bfb21f6bc4be4a6592afc",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/631bfb21f6bc4be4a6592afc/FRgc7nwHylQZ9QURrr88y.jpeg",
            "isPro": false,
            "fullname": "Khiem Vuong",
            "user": "kvuong2711",
            "type": "user"
          },
          "name": "Khiem Vuong",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-04-20T15:01:35.224Z",
          "hidden": false
        },
        {
          "_id": "6804392129303a3402c4f38f",
          "name": "Anurag Ghosh",
          "hidden": false
        },
        {
          "_id": "6804392129303a3402c4f390",
          "name": "Deva Ramanan",
          "hidden": false
        },
        {
          "_id": "6804392129303a3402c4f391",
          "name": "Srinivasa Narasimhan",
          "hidden": false
        },
        {
          "_id": "6804392129303a3402c4f392",
          "name": "Shubham Tulsiani",
          "hidden": false
        }
      ],
      "mediaUrls": [
        "https://cdn-uploads.huggingface.co/production/uploads/631bfb21f6bc4be4a6592afc/x2dR6H7Gl0l8qbXY9YxGP.jpeg",
        "https://cdn-uploads.huggingface.co/production/uploads/631bfb21f6bc4be4a6592afc/Kf60HymR1YXGVqoSmQNYb.mp4",
        "https://cdn-uploads.huggingface.co/production/uploads/631bfb21f6bc4be4a6592afc/O0wHR9zr6E56IE7sjs0UI.jpeg"
      ],
      "publishedAt": "2025-04-17T17:57:05.000Z",
      "submittedOnDailyAt": "2025-04-21T01:28:10.375Z",
      "title": "AerialMegaDepth: Reconstrucción de Superficies Aéreas y Síntesis de Puntos de Vista",
      "submittedOnDailyBy": {
        "_id": "631bfb21f6bc4be4a6592afc",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/631bfb21f6bc4be4a6592afc/FRgc7nwHylQZ9QURrr88y.jpeg",
        "isPro": false,
        "fullname": "Khiem Vuong",
        "user": "kvuong2711",
        "type": "user"
      },
      "summary": "Estamos investigando el problema de la reconstrucción geométrica. El actual enfoque de aprendizaje basado en el más avanzado no puede procesar los cambios visuales extremos entre imágenes de fotografías de cavidades y imágenes de grillas. Nuestra hipótesis es que un conjunto de datos de grillas de cavidades altamente calificadas es el principal causante de este fracaso. Estos datos es difícil de construir de manera expandible. Para superar este desafío, proponemos un marco expandible que combina datos de formato byte en el espacio de trabajo 3D de ciudades (por ejemplo, Google Earth) y datos de muestreo compuesto a nivel de grilla (por ejemplo, MegaDepth). Los datos de formato byte simulan una amplia visión de cavidades, mientras que los datos de muestreo compuesto mejoran la precisión visual a nivel de grilla cuando el formato byte no proporciona suficientes detalles. Este conjunto de datos híbrido nos permite mejorar significativamente el rendimiento de varios algoritmos líder en el campo, alcanzando un aumento claro en tareas de grillas de cavidades en el mundo real, sin necesidad de entrenamiento. Por ejemplo, el DUSt3R básico localiza pares de grillas de cavidades con errores de rotación de cámara de menos de 5 grados, mientras que nuestro ajuste con los datos nos permite alcanzar una precisión cercana a 56%, resuelviendo principalmente los puntos de fracaso. Además de la medición de cámara y la reconstrucción de escenas, nuestros datos mejoran la eficiencia en tareas de síntesis de escenas de difíciles cavidades y demuestran la valor práctico de nuestro enfoque en aplicaciones reales.",
      "upvotes": 4,
      "discussionId": "6804392329303a3402c4f3e8",
      "projectPage": "https://aerial-megadepth.github.io/",
      "githubRepo": "https://github.com/kvuong2711/aerial-megadepth",
      "ai_keywords": [
        "geometric reconstruction",
        "learning-based approaches",
        "extreme viewpoint variation",
        "co-registered",
        "aerial-ground datasets",
        "pseudo-synthetic renderings",
        "3D city-wide meshes",
        "crowd-sourced images",
        "visual fidelity",
        "domain gap",
        "mesh-based renderings",
        "fine-tuning",
        "DUSt3R",
        "camera rotation error",
        "scene reconstruction",
        "novel-view synthesis",
        "downstream tasks"
      ]
    },
    "publishedAt": "2025-04-17T13:57:05.000Z",
    "title": "AerialMegaDepth: Learning Aerial-Ground Reconstruction and View\n  Synthesis",
    "summary": "We explore the task of geometric reconstruction of images captured from a\nmixture of ground and aerial views. Current state-of-the-art learning-based\napproaches fail to handle the extreme viewpoint variation between aerial-ground\nimage pairs. Our hypothesis is that the lack of high-quality, co-registered\naerial-ground datasets for training is a key reason for this failure. Such data\nis difficult to assemble precisely because it is difficult to reconstruct in a\nscalable way. To overcome this challenge, we propose a scalable framework\ncombining pseudo-synthetic renderings from 3D city-wide meshes (e.g., Google\nEarth) with real, ground-level crowd-sourced images (e.g., MegaDepth). The\npseudo-synthetic data simulates a wide range of aerial viewpoints, while the\nreal, crowd-sourced images help improve visual fidelity for ground-level images\nwhere mesh-based renderings lack sufficient detail, effectively bridging the\ndomain gap between real images and pseudo-synthetic renderings. Using this\nhybrid dataset, we fine-tune several state-of-the-art algorithms and achieve\nsignificant improvements on real-world, zero-shot aerial-ground tasks. For\nexample, we observe that baseline DUSt3R localizes fewer than 5% of\naerial-ground pairs within 5 degrees of camera rotation error, while\nfine-tuning with our data raises accuracy to nearly 56%, addressing a major\nfailure point in handling large viewpoint changes. Beyond camera estimation and\nscene reconstruction, our dataset also improves performance on downstream tasks\nlike novel-view synthesis in challenging aerial-ground scenarios, demonstrating\nthe practical value of our approach in real-world applications.",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/631bfb21f6bc4be4a6592afc/x2dR6H7Gl0l8qbXY9YxGP.jpeg",
      "https://cdn-uploads.huggingface.co/production/uploads/631bfb21f6bc4be4a6592afc/Kf60HymR1YXGVqoSmQNYb.mp4",
      "https://cdn-uploads.huggingface.co/production/uploads/631bfb21f6bc4be4a6592afc/O0wHR9zr6E56IE7sjs0UI.jpeg"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.13157.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "631bfb21f6bc4be4a6592afc",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/631bfb21f6bc4be4a6592afc/FRgc7nwHylQZ9QURrr88y.jpeg",
      "fullname": "Khiem Vuong",
      "name": "kvuong2711",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2504.11544",
      "authors": [
        {
          "_id": "6804ca9fd8538baa1c39ca93",
          "name": "Tianyang Xu",
          "hidden": false
        },
        {
          "_id": "6804ca9fd8538baa1c39ca94",
          "name": "Haojie Zheng",
          "hidden": false
        },
        {
          "_id": "6804ca9fd8538baa1c39ca95",
          "name": "Chengze Li",
          "hidden": false
        },
        {
          "_id": "6804ca9fd8538baa1c39ca96",
          "name": "Haoxiang Chen",
          "hidden": false
        },
        {
          "_id": "6804ca9fd8538baa1c39ca97",
          "name": "Yixin Liu",
          "hidden": false
        },
        {
          "_id": "6804ca9fd8538baa1c39ca98",
          "name": "Ruoxi Chen",
          "hidden": false
        },
        {
          "_id": "6804ca9fd8538baa1c39ca99",
          "name": "Lichao Sun",
          "hidden": false
        }
      ],
      "publishedAt": "2025-04-15T18:24:00.000Z",
      "submittedOnDailyAt": "2025-04-21T01:38:46.380Z",
      "title": "NodeRAG: Estructura de RAG basada en grafos con nodos homogéneos",
      "submittedOnDailyBy": {
        "_id": "6610fb736504d9bed5890d58",
        "avatarUrl": "/avatars/832b186fc51c639f1709025d442b3f4b.svg",
        "isPro": false,
        "fullname": "Tianyang Xu",
        "user": "TerryXu666",
        "type": "user"
      },
      "summary": "El Retién-Based Retrieval and Generation (RAG) es un método que permite a grandes modelos de lenguaje acceder a corpora externos y personales, proporcionando respuestas que coincidan de hecho en ciertos campos. Los métodos basados en grafos de RAG utilizan la estructura interna del corpus para construir índices de grafos y explotar las características estructurales del grafo. Sin embargo, actualmente, los enfoques basados en grafos de RAG no priorizan el diseño de la estructura del grafo. Un grafo mal diseñado puede impidir la integración fácil de algoritmos de grafos diversos y provocar discontinuidades en el flujo de trabajo y pérdida de eficiencia. Para explotar plenamente el potencial de los grafos, se propone el framework Node RAG, un enfoque centrado en grafos. Este framework introduce diferentes estructuras de grafos y facilita la integración de aprendizaje automático basado en grafos en el flujo de trabajo de RAG. Si se ajustan a la capacidad de los modelos de lenguaje grandes, este framework garantiza un proceso coherente y eficiente. A través de experimentos específicos, Node RAG muestra un excelente rendimiento en respuestas a consultas en comparación con otros métodos, demostrando excelencias en tiempos de índice, consulta, eficiencia de almacenamiento, y evaluaciones de marcos de prueba abiertos y evaluaciones finales. Nuestro repositorio en GitHub está disponible en https://github.com/Terry-Xu-666/NodeRAG.",
      "upvotes": 4,
      "discussionId": "6804caa0d8538baa1c39cac2",
      "projectPage": "https://terry-xu-666.github.io/NodeRAG_web/",
      "githubRepo": "https://github.com/Terry-Xu-666/NodeRAG",
      "ai_keywords": [
        "Retrieval-augmented generation (RAG)",
        "external and private corpus",
        "factually consistent responses",
        "knowledge graph index",
        "graph-based RAG methods",
        "heterogeneous graph structures",
        "seamless and holistic integration",
        "end-to-end process",
        "question-answering performance",
        "multi-hop benchmarks",
        "open-ended head-to-head evaluations",
        "retrieval tokens"
      ]
    },
    "publishedAt": "2025-04-15T14:24:00.000Z",
    "title": "NodeRAG: Structuring Graph-based RAG with Heterogeneous Nodes",
    "summary": "Retrieval-augmented generation (RAG) empowers large language models to access\nexternal and private corpus, enabling factually consistent responses in\nspecific domains. By exploiting the inherent structure of the corpus,\ngraph-based RAG methods further enrich this process by building a knowledge\ngraph index and leveraging the structural nature of graphs. However, current\ngraph-based RAG approaches seldom prioritize the design of graph structures.\nInadequately designed graph not only impede the seamless integration of diverse\ngraph algorithms but also result in workflow inconsistencies and degraded\nperformance. To further unleash the potential of graph for RAG, we propose\nNodeRAG, a graph-centric framework introducing heterogeneous graph structures\nthat enable the seamless and holistic integration of graph-based methodologies\ninto the RAG workflow. By aligning closely with the capabilities of LLMs, this\nframework ensures a fully cohesive and efficient end-to-end process. Through\nextensive experiments, we demonstrate that NodeRAG exhibits performance\nadvantages over previous methods, including GraphRAG and LightRAG, not only in\nindexing time, query time, and storage efficiency but also in delivering\nsuperior question-answering performance on multi-hop benchmarks and open-ended\nhead-to-head evaluations with minimal retrieval tokens. Our GitHub repository\ncould be seen at https://github.com/Terry-Xu-666/NodeRAG.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.11544.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6610fb736504d9bed5890d58",
      "avatarUrl": "/avatars/832b186fc51c639f1709025d442b3f4b.svg",
      "fullname": "Tianyang Xu",
      "name": "TerryXu666",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2504.09621",
      "authors": [
        {
          "_id": "6800ef5509eaa9d1d87a6eaf",
          "name": "Jiuchen Chen",
          "hidden": false
        },
        {
          "_id": "6800ef5509eaa9d1d87a6eb0",
          "user": {
            "_id": "6672c01fa6eb488f049ecb80",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6672c01fa6eb488f049ecb80/f6SetkETOWgyXy1KmBPhK.jpeg",
            "isPro": false,
            "fullname": "Xinyu Yan",
            "user": "fengyanzi",
            "type": "user"
          },
          "name": "Xinyu Yan",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-04-19T15:17:09.181Z",
          "hidden": false
        },
        {
          "_id": "6800ef5509eaa9d1d87a6eb1",
          "name": "Qizhi Xu",
          "hidden": false
        },
        {
          "_id": "6800ef5509eaa9d1d87a6eb2",
          "name": "Kaiqi Li",
          "hidden": false
        }
      ],
      "publishedAt": "2025-04-13T15:41:25.000Z",
      "submittedOnDailyAt": "2025-04-21T05:45:47.747Z",
      "title": "Tokneize Image Patches: Fusion of Global Context for Effective Noise Reduction in Dialogue",
      "submittedOnDailyBy": {
        "_id": "6672c01fa6eb488f049ecb80",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6672c01fa6eb488f049ecb80/f6SetkETOWgyXy1KmBPhK.jpeg",
        "isPro": false,
        "fullname": "Xinyu Yan",
        "user": "fengyanzi",
        "type": "user"
      },
      "summary": "En el contexto global y las características detalladas locales son esenciales en la tarea de eliminar el neblina. Los modelos de redes neuronales profundas son familiares con imágenes pequeñas y de baja resolución, pero en imágenes grandes y de alta resolución suelen enfrentar limitaciones de memoria de GPU. Por lo tanto, se opta por técnicas como el deslizamiento de imágenes o submuestreo. Sin embargo, estas técnicas tienen la desventaja de perder información global y detallada de alta frecuencia. Para resolver estos problemas, proponemos el método de eliminación de neblina llamado DehazeXL. Este método mejora la armonía entre el contexto global y las características locales, permitiendo modelar imágenes grandes desde el principio hasta el final en dispositivos de hardware de GPU predominantes. Además, diseñamos una metodología para asignar propiedades visuales adecuadas para la tarea de eliminar neblina y evaluamos la eficiencia del uso del contexto global. Finalmente, reconociendo la escasez de conjuntos de datos de benchmark para la eliminación de neblina en imágenes grandes, desarrollamos el conjunto de datos de alta resolución 8KDehaze. Este conjunto incluye 10.000 pares de imágenes de observación remota limpias y con neblina, con cada imagen de 8192×8192 píxeles. Los experimentos extendidos muestran que DehazeXL puede inferir imágenes de 10240×10240 píxeles con 21GB de memoria, logrando los resultados más avanzados entre todos los métodos evaluados. El código fuente y los conjuntos de datos de experimentos están disponibles en https://github.com/CastleChen339/DehazeXL.",
      "upvotes": 4,
      "discussionId": "6800ef5709eaa9d1d87a6f76",
      "projectPage": "https://castlechen339.github.io/DehazeXL.github.io/",
      "githubRepo": "https://github.com/CastleChen339/DehazeXL",
      "ai_keywords": [
        "haze removal",
        "image slicing",
        "downsampling",
        "DehazeXL",
        "global context",
        "local feature extraction",
        "end-to-end modeling",
        "visual attribution",
        "8KDehaze",
        "ultra-high-resolution haze removal dataset",
        "remote sensing images"
      ]
    },
    "publishedAt": "2025-04-13T11:41:25.000Z",
    "title": "Tokenize Image Patches: Global Context Fusion for Effective Haze Removal\n  in Large Images",
    "summary": "Global contextual information and local detail features are essential for\nhaze removal tasks. Deep learning models perform well on small, low-resolution\nimages, but they encounter difficulties with large, high-resolution ones due to\nGPU memory limitations. As a compromise, they often resort to image slicing or\ndownsampling. The former diminishes global information, while the latter\ndiscards high-frequency details. To address these challenges, we propose\nDehazeXL, a haze removal method that effectively balances global context and\nlocal feature extraction, enabling end-to-end modeling of large images on\nmainstream GPU hardware. Additionally, to evaluate the efficiency of global\ncontext utilization in haze removal performance, we design a visual attribution\nmethod tailored to the characteristics of haze removal tasks. Finally,\nrecognizing the lack of benchmark datasets for haze removal in large images, we\nhave developed an ultra-high-resolution haze removal dataset (8KDehaze) to\nsupport model training and testing. It includes 10000 pairs of clear and hazy\nremote sensing images, each sized at 8192 times 8192 pixels. Extensive\nexperiments demonstrate that DehazeXL can infer images up to 10240 times\n10240 pixels with only 21 GB of memory, achieving state-of-the-art results\namong all evaluated methods. The source code and experimental dataset are\navailable at https://github.com/CastleChen339/DehazeXL.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.09621.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6672c01fa6eb488f049ecb80",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6672c01fa6eb488f049ecb80/f6SetkETOWgyXy1KmBPhK.jpeg",
      "fullname": "Xinyu Yan",
      "name": "fengyanzi",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2504.13626",
      "authors": [
        {
          "_id": "6805fa66fddd500b98039425",
          "name": "Yule Liu",
          "hidden": false
        },
        {
          "_id": "6805fa66fddd500b98039426",
          "name": "Jingyi Zheng",
          "hidden": false
        },
        {
          "_id": "6805fa66fddd500b98039427",
          "name": "Zhen Sun",
          "hidden": false
        },
        {
          "_id": "6805fa66fddd500b98039428",
          "name": "Zifan Peng",
          "hidden": false
        },
        {
          "_id": "6805fa66fddd500b98039429",
          "name": "Wenhan Dong",
          "hidden": false
        },
        {
          "_id": "6805fa66fddd500b9803942a",
          "name": "Zeyang Sha",
          "hidden": false
        },
        {
          "_id": "6805fa66fddd500b9803942b",
          "name": "Shiwen Cui",
          "hidden": false
        },
        {
          "_id": "6805fa66fddd500b9803942c",
          "name": "Weiqiang Wang",
          "hidden": false
        },
        {
          "_id": "6805fa66fddd500b9803942d",
          "name": "Xinlei He",
          "hidden": false
        }
      ],
      "publishedAt": "2025-04-18T11:07:19.000Z",
      "submittedOnDailyAt": "2025-04-21T06:29:28.134Z",
      "title": "Ingrese para recibir una respuesta detallada.",
      "submittedOnDailyBy": {
        "_id": "63da3d7ae697e5898cb86854",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1675246771355-noauth.jpeg",
        "isPro": false,
        "fullname": "Talha Rüzgar Akkuş",
        "user": "Q-bert",
        "type": "user"
      },
      "summary": "El reciente desarrollo de los grandes modelos cognitivos (LRMs) ha demostrado su efectividad al escalar la cantidad de cálculos en las pruebas para mejorar la capacidad cognitiva en diversas tareas. Sin embargo, los LRMs suelen enfrentarse a problemas de \"exceso cognitivo\", donde el modelo genera una gran cantidad de etapas cognitivas para lograr un rendimiento limitado. La investigación actual depende de fine-tuning para mitigar este exceso cognitivo, pero esto implica riesgos adicionales de datos, configuraciones de entrenamiento no estándar, ajustes de seguridad y una pérdida de capacidad de generalización.\n\nUn análisis experimental ha revelado importantes características del comportamiento de los LRMs, demostrando que insertando tokens de memoria (<think> entre ellos, el modelo puede restringirse en la generación de múltiples memorias. Basándose en esta idea, se propone una simple y eficiente pipeline llamada ThoughtMani, que permite a los LRMs saltar pasos intermedios innecesarios y reducir significativamente los costos de cálculo. Se han realizado amplias pruebas para probar la utilidad y eficiencia de ThoughtMani. Por ejemplo, aplicado en el dataset LiveBench/Code a QwQ-32B, ThoughtMani redució aproximadamente el 30% de los tokens de salida mientras mantuvo el rendimiento original, reduciendo también el overhead de la generación de CoT. Además, aumentó en un promedio del 10% el ajuste de seguridad. La posición de negocio de los modelos generalmente consiste en ofrecer modelos de diferentes tamaños, lo que significa que ThoughtMani proporciona una eficiente y accesible forma de construir LRMs para aplicaciones reales.",
      "upvotes": 3,
      "discussionId": "6805fa67fddd500b98039461",
      "ai_keywords": [
        "large reasoning models (LRMs)",
        "overthinking problems",
        "fine-tuning",
        "thinking token",
        "external CoTs (Chain of Thought)",
        "ThoughtMani",
        "unnecessary intermediate steps",
        "computational costs",
        "LiveBench/Code dataset",
        "output token counts",
        "safety alignment"
      ]
    },
    "publishedAt": "2025-04-18T07:07:19.000Z",
    "title": "Thought Manipulation: External Thought Can Be Efficient for Large\n  Reasoning Models",
    "summary": "Recent advancements in large reasoning models (LRMs) have demonstrated the\neffectiveness of scaling test-time computation to enhance reasoning\ncapabilities in multiple tasks. However, LRMs typically suffer from\n\"overthinking\" problems, where models generate significantly redundant\nreasoning steps while bringing limited performance gains. Existing work relies\non fine-tuning to mitigate overthinking, which requires additional data,\nunconventional training setups, risky safety misalignment, and poor\ngeneralization.\n  Through empirical analysis, we reveal an important characteristic of LRM\nbehaviors that placing external CoTs generated by smaller models between the\nthinking token (<think> and </think>) can effectively\nmanipulate the model to generate fewer thoughts. Building on these insights, we\npropose a simple yet efficient pipeline, ThoughtMani, to enable LRMs to bypass\nunnecessary intermediate steps and reduce computational costs significantly. We\nconduct extensive experiments to validate the utility and efficiency of\nThoughtMani. For instance, when applied to QwQ-32B on the LiveBench/Code\ndataset, ThoughtMani keeps the original performance and reduces output token\ncounts by approximately 30%, with little overhead from the CoT generator.\nFurthermore, we find that ThoughtMani enhances safety alignment by an average\nof 10%. Since model vendors typically serve models of different sizes\nsimultaneously, ThoughtMani provides an effective way to construct more\nefficient and accessible LRMs for real-world applications.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.13626.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "63da3d7ae697e5898cb86854",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1675246771355-noauth.jpeg",
      "fullname": "Talha Rüzgar Akkuş",
      "name": "Q-bert",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 89
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2504.13173",
      "authors": [
        {
          "_id": "6805c4dab15a57fcb59b6f08",
          "name": "Ali Behrouz",
          "hidden": false
        },
        {
          "_id": "6805c4dab15a57fcb59b6f09",
          "name": "Meisam Razaviyayn",
          "hidden": false
        },
        {
          "_id": "6805c4dab15a57fcb59b6f0a",
          "name": "Peilin Zhong",
          "hidden": false
        },
        {
          "_id": "6805c4dab15a57fcb59b6f0b",
          "name": "Vahab Mirrokni",
          "hidden": false
        }
      ],
      "publishedAt": "2025-04-17T17:59:33.000Z",
      "submittedOnDailyAt": "2025-04-21T02:39:28.607Z",
      "title": "Todo está conectado: Test Time Memory, Session Bias, Storage, y el Deseo de Optimización en Línea",
      "submittedOnDailyBy": {
        "_id": "65cccd5134a5d74cbaa9446c",
        "avatarUrl": "/avatars/5255b734628992106598eae4f2c5848f.svg",
        "isPro": false,
        "fullname": "Ali Behrouz",
        "user": "AliBehrouz",
        "type": "user"
      },
      "summary": "Alta eficiencia de diseño y una arquitectura técnica efectiva de base fueron esenciales para mejorar el rendimiento del modelo básico. Reflejando la atención sesgada hacia objetos internos y conocimientos, a través de la reenvision de Transformers, Titans y redes neuronales lineales recursivas modernas, se construyeron módulos de memoria asociativa que utilizan sesgos de conocimiento. Sorprendentemente, muchos modelos de secuencias actuales (1) utilizan similitudes por producto punto, o (2) objetos de regresión L2 como sesgos de conocimiento. Estos objetos, más allá de lo anterior, proporcionan opciones de sesgos de conocimiento y aproximaciones efectivas, así como estabilizaron el proceso de entrenamiento. Además, se reinterpretó la estructura de olvido en arquitecturas de aprendizaje profundo como normalización de retención y se proporcionó un nuevo gate de olvido para modelos de secuencias. Desde esta perspectiva, se propone un marco general llamado Miras, diseñando arquitecturas de aprendizaje profundo basadas en cuatro opciones: (i) arquitectura de memoria asociativa, (ii) objeto de sesgo de conocimiento, (iii) gate de retención, (iv) algoritmo de aprendizaje de memoria. Se proponen tres nuevos modelos de secuencias: Moneta, Yaad y Memora, que superan las capacidades de los RNN lineales actuales, manteniendo un proceso de entrenamiento rápido y paralelizable. Los experimentos muestran que, según diferentes elecciones de diseño de Miras, se pueden obtener modelos con diferentes niveles de rendimiento, demostrando, por ejemplo, un rendimiento especial en tareas como modelado de lenguaje, inferencia general y enfoque de memoria, que superan a los modelos de Transformers y redes neuronales lineales recursivas modernas.",
      "upvotes": 3,
      "discussionId": "6805c4dbb15a57fcb59b6f3d",
      "ai_keywords": [
        "Transformers",
        "Titans",
        "linear recurrent neural networks",
        "associative memory modules",
        "attentional bias",
        "dot-product similarity",
        "L2 regression",
        "retention regularization",
        "forget gates",
        "Miras",
        "Moneta",
        "Yaad",
        "Memora",
        "parallelizable training process",
        "language modeling",
        "commonsense reasoning",
        "recall intensive tasks"
      ]
    },
    "publishedAt": "2025-04-17T13:59:33.000Z",
    "title": "It's All Connected: A Journey Through Test-Time Memorization,\n  Attentional Bias, Retention, and Online Optimization",
    "summary": "Designing efficient and effective architectural backbones has been in the\ncore of research efforts to enhance the capability of foundation models.\nInspired by the human cognitive phenomenon of attentional bias-the natural\ntendency to prioritize certain events or stimuli-we reconceptualize neural\narchitectures, including Transformers, Titans, and modern linear recurrent\nneural networks as associative memory modules that learn a mapping of keys and\nvalues using an internal objective, referred to as attentional bias.\nSurprisingly, we observed that most existing sequence models leverage either\n(1) dot-product similarity, or (2) L2 regression objectives as their\nattentional bias. Going beyond these objectives, we present a set of\nalternative attentional bias configurations along with their effective\napproximations to stabilize their training procedure. We then reinterpret\nforgetting mechanisms in modern deep learning architectures as a form of\nretention regularization, providing a novel set of forget gates for sequence\nmodels. Building upon these insights, we present Miras, a general framework to\ndesign deep learning architectures based on four choices of: (i) associative\nmemory architecture, (ii) attentional bias objective, (iii) retention gate, and\n(iv) memory learning algorithm. We present three novel sequence models-Moneta,\nYaad, and Memora-that go beyond the power of existing linear RNNs while\nmaintaining a fast parallelizable training process. Our experiments show\ndifferent design choices in Miras yield models with varying strengths. For\nexample, certain instances of Miras achieve exceptional performance in special\ntasks such as language modeling, commonsense reasoning, and recall intensive\ntasks, even outperforming Transformers and other modern linear recurrent\nmodels.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.13173.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "65cccd5134a5d74cbaa9446c",
      "avatarUrl": "/avatars/5255b734628992106598eae4f2c5848f.svg",
      "fullname": "Ali Behrouz",
      "name": "AliBehrouz",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": false
  }
]