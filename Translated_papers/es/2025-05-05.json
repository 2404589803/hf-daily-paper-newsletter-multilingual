[
  {
    "paper": {
      "id": "2504.20438",
      "authors": [
        {
          "_id": "6814e35a19162d7749852c4b",
          "user": {
            "_id": "633d4630e1aec4b8b33ad5b8",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/633d4630e1aec4b8b33ad5b8/owFqnyCMW8yuo9VcjA1hx.jpeg",
            "isPro": false,
            "fullname": "Ziyang Xu",
            "user": "Uyoung",
            "type": "user"
          },
          "name": "Ziyang Xu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-04T10:04:40.638Z",
          "hidden": false
        },
        {
          "_id": "6814e35a19162d7749852c4c",
          "name": "Kangsheng Duan",
          "hidden": false
        },
        {
          "_id": "6814e35a19162d7749852c4d",
          "user": {
            "_id": "627a34dac488a8ce15a2dc4a",
            "avatarUrl": "/avatars/61aecef507dea6620fe5574493f83595.svg",
            "isPro": false,
            "fullname": "ShenXiaolei",
            "user": "SmileTAT",
            "type": "user"
          },
          "name": "Xiaolei Shen",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-05-05T07:32:16.185Z",
          "hidden": false
        },
        {
          "_id": "6814e35a19162d7749852c4e",
          "name": "Zhifeng Ding",
          "hidden": false
        },
        {
          "_id": "6814e35a19162d7749852c4f",
          "user": {
            "_id": "66c2e7fc934e2f07753542ac",
            "avatarUrl": "/avatars/f6fa3f94435cf1c1d06daa6c925d07d0.svg",
            "isPro": false,
            "fullname": "LWY",
            "user": "wenyuliu",
            "type": "user"
          },
          "name": "Wenyu Liu",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-05-05T07:32:31.210Z",
          "hidden": false
        },
        {
          "_id": "6814e35a19162d7749852c50",
          "name": "Xiaohu Ruan",
          "hidden": false
        },
        {
          "_id": "6814e35a19162d7749852c51",
          "user": {
            "_id": "65389a669c474315d7425f96",
            "avatarUrl": "/avatars/2fa3828ca489cfe1948129a0eccf264f.svg",
            "isPro": false,
            "fullname": "chenxiaoxin",
            "user": "steelozazala",
            "type": "user"
          },
          "name": "Xiaoxin Chen",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-05-05T07:32:55.012Z",
          "hidden": false
        },
        {
          "_id": "6814e35a19162d7749852c52",
          "user": {
            "_id": "62600de6d47e3dbae32ce1ce",
            "avatarUrl": "/avatars/a536417cfec6e10ac415091bd1829426.svg",
            "isPro": false,
            "fullname": "Xinggang Wang",
            "user": "xinggangw",
            "type": "user"
          },
          "name": "Xinggang Wang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-05-05T07:33:01.396Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-04-29T05:28:36.000Z",
      "submittedOnDailyAt": "2025-05-05T05:42:06.841Z",
      "title": "PixelHacker: Consistencia estructural e interpretativa en la imagen de entrada",
      "submittedOnDailyBy": {
        "_id": "633d4630e1aec4b8b33ad5b8",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/633d4630e1aec4b8b33ad5b8/owFqnyCMW8yuo9VcjA1hx.jpeg",
        "isPro": false,
        "fullname": "Ziyang Xu",
        "user": "Uyoung",
        "type": "user"
      },
      "summary": "El inpainting de imágenes es un campo básico de investigación que se encuentra entre el edición de imágenes y la generación de imágenes. Los métodos más avanzados recientes (SOTA) intentan nuevas estructuras de atención, estructuras ligeras y modelar el contexto, demostrando un desempeño sorprendente. Sin embargo, tienen dificultades con estructuras complejas (por ejemplo, texturas, formas, relaciones espaciales) y significado (por ejemplo, coherencia de color, recuperación de objetos, precisión lógica). Esto lleva a la aparición de artifactos y generaciones inadecuadas. Para enfrentar estos desafíos, hemos diseñado un paradigma sencillo y efectivo de inpainting \"Categoría Guided\" y proponemos un modelo basado en distribución \"PixelHacker\". En particular, hemos construido por primera vez un grande conjunto de datos que incluye 14 millones de pares de imágenes-mascaras explicando antecedentes y fondos (categorías temporalmente 116 y 21). Luego, usamos dos mapas de tamaño fijo para transformar la representación potencial de los antecedentes y fondos y, mediante atención lineal, inyectamos estas características regularmente en el proceso de denoising. Finalmente, aprendimos nuestro conjunto de datos y fine-tunamos en un benchmark abierto, obteniendo el PixelHacker. Experimentaciones extendidas muestran que el PixelHacker supera el SOTA en diversos conjuntos de datos (Places2, CelebA-HQ, FFHQ), demostrando una excelente coherencia en ambas estructura y significado. La página del proyecto está disponible en https://hustvl.github.io/PixelHacker.",
      "upvotes": 17,
      "discussionId": "6814e35c19162d7749852caa",
      "projectPage": "https://hustvl.github.io/PixelHacker",
      "githubRepo": "https://github.com/hustvl/PixelHacker",
      "ai_keywords": [
        "latent categories guidance",
        "diffusion-based model",
        "PixelHacker",
        "image-mask pairs",
        "fixed-size embeddings",
        "linear attention",
        "pre-training",
        "fine-tuning",
        "Places2",
        "CelebA-HQ",
        "FFHQ"
      ]
    },
    "publishedAt": "2025-04-29T01:28:36.000Z",
    "title": "PixelHacker: Image Inpainting with Structural and Semantic Consistency",
    "summary": "Image inpainting is a fundamental research area between image editing and\nimage generation. Recent state-of-the-art (SOTA) methods have explored novel\nattention mechanisms, lightweight architectures, and context-aware modeling,\ndemonstrating impressive performance. However, they often struggle with complex\nstructure (e.g., texture, shape, spatial relations) and semantics (e.g., color\nconsistency, object restoration, and logical correctness), leading to artifacts\nand inappropriate generation. To address this challenge, we design a simple yet\neffective inpainting paradigm called latent categories guidance, and further\npropose a diffusion-based model named PixelHacker. Specifically, we first\nconstruct a large dataset containing 14 million image-mask pairs by annotating\nforeground and background (potential 116 and 21 categories, respectively).\nThen, we encode potential foreground and background representations separately\nthrough two fixed-size embeddings, and intermittently inject these features\ninto the denoising process via linear attention. Finally, by pre-training on\nour dataset and fine-tuning on open-source benchmarks, we obtain PixelHacker.\nExtensive experiments show that PixelHacker comprehensively outperforms the\nSOTA on a wide range of datasets (Places2, CelebA-HQ, and FFHQ) and exhibits\nremarkable consistency in both structure and semantics. Project page at\nhttps://hustvl.github.io/PixelHacker.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.20438.png",
    "numComments": 4,
    "submittedBy": {
      "_id": "633d4630e1aec4b8b33ad5b8",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/633d4630e1aec4b8b33ad5b8/owFqnyCMW8yuo9VcjA1hx.jpeg",
      "fullname": "Ziyang Xu",
      "name": "Uyoung",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.01079",
      "authors": [
        {
          "_id": "68183d9ae65ec5d5716c6d94",
          "user": {
            "_id": "636b20591340f879a2eb98d0",
            "avatarUrl": "/avatars/4fc5cb13f916bcbc842ccf387bd5f6c0.svg",
            "isPro": false,
            "fullname": "Daneul Kim",
            "user": "carpedkm",
            "type": "user"
          },
          "name": "Daneul Kim",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-05T07:30:39.678Z",
          "hidden": false
        },
        {
          "_id": "68183d9ae65ec5d5716c6d95",
          "name": "Jaeah Lee",
          "hidden": false
        },
        {
          "_id": "68183d9ae65ec5d5716c6d96",
          "name": "Jaesik Park",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-02T07:36:49.000Z",
      "submittedOnDailyAt": "2025-05-05T02:56:01.277Z",
      "title": "Generación y edición de imágenes mejoradas mediante el uso de memoria por capas",
      "submittedOnDailyBy": {
        "_id": "636b20591340f879a2eb98d0",
        "avatarUrl": "/avatars/4fc5cb13f916bcbc842ccf387bd5f6c0.svg",
        "isPro": false,
        "fullname": "Daneul Kim",
        "user": "carpedkm",
        "type": "user"
      },
      "summary": "La mayoría de los trabajos de edición de imágenes en el mundo real requiere una serie de ediciones continuas para alcanzar los resultados deseados. El enfoque actual de edición está diseñado principalmente para describir un solo objeto, lo que dificulta las ediciones continuas, especialmente la integración natural de nuevos objetos en el contenido existente mientras se mantiene la edición anterior. Estos límites tienen un gran impacto en escenarios de edición compleja que involucran la modificación de múltiples objetos mientras se mantiene su relación de contexto. Presentamos dos principales propuestas para resolver estas limitaciones fundamentales: el uso de máscaras sencillas para mantener el contenido actual y la integración natural de nuevos elementos, y el apoyo a una edición coherente durante múltiples modificaciones. Nuestro marco de trabajo utiliza memoria estratificada para almacenar las potenciales representaciones y embeddings de prompts de ediciones anteriores, lo que permite su implementación. Proponemos un guía de consistencia espectral utilizando las representaciones potenciales recuperadas y un desarrollo de Multi-Query de la atención cruzada para garantizar una respuesta natural al contenido existente. Para evaluar nuestro método, presentamos un conjunto de datos de benchmark que incluye un nuevo métrica semántica y escenarios de edición interactiva. A través de experimentos detallados, nuestro método muestra un rendimiento superior en tareas de edición de imágenes iterativas que requieren poco esfuerzo del usuario y mantienen resultados de alta calidad a través de múltiples etapas de edición.",
      "upvotes": 12,
      "discussionId": "68183d9de65ec5d5716c6e78",
      "projectPage": "https://carpedkm.github.io/projects/improving_edit/index.html",
      "githubRepo": "https://github.com/carpedkm/improving-editability",
      "ai_keywords": [
        "layer-wise memory",
        "latent representations",
        "prompt embeddings",
        "Background Consistency Guidance",
        "Multi-Query Disentanglement",
        "cross-attention",
        "semantic alignment metrics",
        "interactive editing scenarios",
        "iterative image editing"
      ]
    },
    "publishedAt": "2025-05-02T03:36:49.000Z",
    "title": "Improving Editability in Image Generation with Layer-wise Memory",
    "summary": "Most real-world image editing tasks require multiple sequential edits to\nachieve desired results. Current editing approaches, primarily designed for\nsingle-object modifications, struggle with sequential editing: especially with\nmaintaining previous edits along with adapting new objects naturally into the\nexisting content. These limitations significantly hinder complex editing\nscenarios where multiple objects need to be modified while preserving their\ncontextual relationships. We address this fundamental challenge through two key\nproposals: enabling rough mask inputs that preserve existing content while\nnaturally integrating new elements and supporting consistent editing across\nmultiple modifications. Our framework achieves this through layer-wise memory,\nwhich stores latent representations and prompt embeddings from previous edits.\nWe propose Background Consistency Guidance that leverages memorized latents to\nmaintain scene coherence and Multi-Query Disentanglement in cross-attention\nthat ensures natural adaptation to existing content. To evaluate our method, we\npresent a new benchmark dataset incorporating semantic alignment metrics and\ninteractive editing scenarios. Through comprehensive experiments, we\ndemonstrate superior performance in iterative image editing tasks with minimal\nuser effort, requiring only rough masks while maintaining high-quality results\nthroughout multiple editing steps.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.01079.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "636b20591340f879a2eb98d0",
      "avatarUrl": "/avatars/4fc5cb13f916bcbc842ccf387bd5f6c0.svg",
      "fullname": "Daneul Kim",
      "name": "carpedkm",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2504.21117",
      "authors": [
        {
          "_id": "681889891bcdcf80a49d9ef8",
          "name": "Hanhua Hong",
          "hidden": false
        },
        {
          "_id": "681889891bcdcf80a49d9ef9",
          "name": "Chenghao Xiao",
          "hidden": false
        },
        {
          "_id": "681889891bcdcf80a49d9efa",
          "user": {
            "_id": "60f313f4adf471cbdf8bb66a",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/60f313f4adf471cbdf8bb66a/5NJFqnldE_0fdE_mEvz9V.jpeg",
            "isPro": false,
            "fullname": "Yang Wang",
            "user": "yangwang825",
            "type": "user"
          },
          "name": "Yang Wang",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-05-05T09:48:58.639Z",
          "hidden": false
        },
        {
          "_id": "681889891bcdcf80a49d9efb",
          "name": "Yiqi Liu",
          "hidden": false
        },
        {
          "_id": "681889891bcdcf80a49d9efc",
          "name": "Wenge Rong",
          "hidden": false
        },
        {
          "_id": "681889891bcdcf80a49d9efd",
          "name": "Chenghua Lin",
          "hidden": false
        }
      ],
      "mediaUrls": [
        "https://cdn-uploads.huggingface.co/production/uploads/63108cc834c7d77420b0fd68/6pjQShgH8JjsuyXvDdwv1.png"
      ],
      "publishedAt": "2025-04-29T18:56:12.000Z",
      "submittedOnDailyAt": "2025-05-05T08:29:07.779Z",
      "title": "1. El tamaño no importa: Nota de evaluación de la NLG de alta eficiencia mediante aprendizaje reforzado inverso",
      "submittedOnDailyBy": {
        "_id": "63108cc834c7d77420b0fd68",
        "avatarUrl": "/avatars/2721e573a417a8ec0b81ee048c4b42ba.svg",
        "isPro": false,
        "fullname": "chenghao xiao",
        "user": "gowitheflow",
        "type": "user"
      },
      "summary": "La evaluación de sistemas de generación de lenguaje natural (NLG) puede resultar difícil según la diversidad de salidas válidas. La evaluación humana se considera estándar, pero su reproducibilidad está limitada por inecuaciones, la falta de estandarización y los sesgos poblacionales. Las evaluaciones basadas en modelos de lenguaje grande (LLM) son una alternativa escalable, pero son muy sensibles al diseño de los prompts, lo que puede provocar grandes diferencias con pequeñas variaciones. En este artículo, se propone un método de aprendizaje inverso que permite a los modelos aprender a invertir su salida hacia su entrada de manera efectiva, facilitando la generación automática de prompts de evaluación propios del modelo de alto nivel de eficacia. Este método solo requiere un solo ejemplo de evaluación, elimina la necesidad de ingeniería de prompts de prueba para medir el tiempo, y mejora la eficiencia y la robustez. Este artículo contribuye a nuevas direcciones en la evaluación basada en modelos de lenguaje grande.",
      "upvotes": 5,
      "discussionId": "6818898a1bcdcf80a49d9f28",
      "ai_keywords": [
        "natural language generation (NLG)",
        "human evaluation",
        "LLM-based evaluation",
        "prompt design",
        "inversion learning",
        "reverse mappings",
        "model outputs",
        "input instructions",
        "automatic generation",
        "model-specific evaluation prompts",
        "evaluation sample",
        "manual prompt engineering"
      ]
    },
    "publishedAt": "2025-04-29T14:56:12.000Z",
    "title": "Beyond One-Size-Fits-All: Inversion Learning for Highly Effective NLG\n  Evaluation Prompts",
    "summary": "Evaluating natural language generation (NLG) systems is challenging due to\nthe diversity of valid outputs. While human evaluation is the gold standard, it\nsuffers from inconsistencies, lack of standardisation, and demographic biases,\nlimiting reproducibility. LLM-based evaluation offers a scalable alternative\nbut is highly sensitive to prompt design, where small variations can lead to\nsignificant discrepancies. In this work, we propose an inversion learning\nmethod that learns effective reverse mappings from model outputs back to their\ninput instructions, enabling the automatic generation of highly effective,\nmodel-specific evaluation prompts. Our method requires only a single evaluation\nsample and eliminates the need for time-consuming manual prompt engineering,\nthereby improving both efficiency and robustness. Our work contributes toward a\nnew direction for more robust and efficient LLM-based evaluation.",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/63108cc834c7d77420b0fd68/6pjQShgH8JjsuyXvDdwv1.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.21117.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "63108cc834c7d77420b0fd68",
      "avatarUrl": "/avatars/2721e573a417a8ec0b81ee048c4b42ba.svg",
      "fullname": "chenghao xiao",
      "name": "gowitheflow",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 17
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2505.00023",
      "authors": [
        {
          "_id": "6818413000ee590453feaf66",
          "user": {
            "_id": "65169ea3fbfe82f36fc6655c",
            "avatarUrl": "/avatars/01714ad316a2e06488246e4fe7dcdb52.svg",
            "isPro": false,
            "fullname": "Hyun Ji Lee",
            "user": "hyunjilee",
            "type": "user"
          },
          "name": "Hyunji Lee",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-05-05T07:34:41.006Z",
          "hidden": false
        },
        {
          "_id": "6818413000ee590453feaf67",
          "user": {
            "_id": "62c5947524171688a9feb992",
            "avatarUrl": "/avatars/5a151713b9eae8dc566f5957acee3475.svg",
            "isPro": false,
            "fullname": "Franck Dernoncourt",
            "user": "Franck-Dernoncourt",
            "type": "user"
          },
          "name": "Franck Dernoncourt",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-05T07:30:36.382Z",
          "hidden": false
        },
        {
          "_id": "6818413000ee590453feaf68",
          "name": "Trung Bui",
          "hidden": false
        },
        {
          "_id": "6818413000ee590453feaf69",
          "user": {
            "_id": "6690ef3db70d356ed3e05cb0",
            "avatarUrl": "/avatars/530f3a0bd7b93e1e7f385c2708335728.svg",
            "isPro": false,
            "fullname": "yoon seung-hyun",
            "user": "aifactoryysh",
            "type": "user"
          },
          "name": "Seunghyun Yoon",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-05-05T07:35:01.378Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-04-25T02:40:48.000Z",
      "submittedOnDailyAt": "2025-05-05T03:10:26.249Z",
      "title": "CORG: Crear respuestas en contextos complejos e interactivos",
      "submittedOnDailyBy": {
        "_id": "62c5947524171688a9feb992",
        "avatarUrl": "/avatars/5a151713b9eae8dc566f5957acee3475.svg",
        "isPro": false,
        "fullname": "Franck Dernoncourt",
        "user": "Franck-Dernoncourt",
        "type": "user"
      },
      "summary": "En el mundo real, los corpus contienen con frecuencia la repetición de conocimientos entre documentos, pero también incluyen información inadecuada por diversas razones, lo que genera relaciones complejas entre contextos. Las investigaciones anteriores han demostrado que los modelos de lenguaje enfrentan dificultades para superar estas complejidades. Estas relaciones han sido clasificadas en cuatro tipos: detección, incertidumbre, realidad contraria y suma. Los resultados de la analisis indican que no es posible procesar todas estas relaciones con un solo enfoque. Por lo tanto, se propone el Context Organizer (CORG). El CORG es un marco de trabajo que organiza contextos en grupos independientes. Con esta arquitectura, el modelo puede encontrar respuestas eficientes y eliminar incertidumbres. El CORG está compuesto de tres componentes principales: el constructor de grafos, el aprendiz y el agregador de grafos. Finalmente, el CORG equilibra bien el rendimiento y la eficiencia, supera los métodos de agrupamiento actuales y logra resultados relativamente de alto rendimiento con una cantidad de cálculo significativamente menor en comparación con un enfoque de contexto único.",
      "upvotes": 4,
      "discussionId": "6818413100ee590453feaf97",
      "ai_keywords": [
        "graph constructor",
        "reranker",
        "aggregator",
        "Context Organizer (CORG)"
      ]
    },
    "publishedAt": "2025-04-24T22:40:48.000Z",
    "title": "CORG: Generating Answers from Complex, Interrelated Contexts",
    "summary": "In a real-world corpus, knowledge frequently recurs across documents but\noften contains inconsistencies due to ambiguous naming, outdated information,\nor errors, leading to complex interrelationships between contexts. Previous\nresearch has shown that language models struggle with these complexities,\ntypically focusing on single factors in isolation. We classify these\nrelationships into four types: distracting, ambiguous, counterfactual, and\nduplicated. Our analysis reveals that no single approach effectively addresses\nall these interrelationships simultaneously. Therefore, we introduce Context\nOrganizer (CORG), a framework that organizes multiple contexts into\nindependently processed groups. This design allows the model to efficiently\nfind all relevant answers while ensuring disambiguation. CORG consists of three\nkey components: a graph constructor, a reranker, and an aggregator. Our results\ndemonstrate that CORG balances performance and efficiency effectively,\noutperforming existing grouping methods and achieving comparable results to\nmore computationally intensive, single-context approaches.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.00023.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "62c5947524171688a9feb992",
      "avatarUrl": "/avatars/5a151713b9eae8dc566f5957acee3475.svg",
      "fullname": "Franck Dernoncourt",
      "name": "Franck-Dernoncourt",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 9
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2505.00174",
      "authors": [
        {
          "_id": "681594746a80babbe28775ba",
          "user": {
            "_id": "66225f7100352aeea584d02a",
            "avatarUrl": "/avatars/ca13f59bebf73d03a63a935f628aea5c.svg",
            "isPro": false,
            "fullname": "Ilan Strauss",
            "user": "strauss-NYC",
            "type": "user"
          },
          "name": "Ilan Strauss",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-04T10:04:25.496Z",
          "hidden": false
        },
        {
          "_id": "681594746a80babbe28775bb",
          "user": {
            "_id": "67535114d2a628475a0e7a6e",
            "avatarUrl": "/avatars/d7eb574c026817bbc204843c96f1caa6.svg",
            "isPro": false,
            "fullname": "Isobel Moure",
            "user": "isobelmoure",
            "type": "user"
          },
          "name": "Isobel Moure",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-05-05T07:35:12.655Z",
          "hidden": false
        },
        {
          "_id": "681594746a80babbe28775bc",
          "name": "Tim O'Reilly",
          "hidden": false
        },
        {
          "_id": "681594746a80babbe28775bd",
          "user": {
            "_id": "64582e94f8bdc3512d1ee940",
            "avatarUrl": "/avatars/e0eb72f06c7da58cb569198540484ab1.svg",
            "isPro": false,
            "fullname": "Sruly Rosenblat",
            "user": "sruly",
            "type": "user"
          },
          "name": "Sruly Rosenblat",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-05-05T07:35:24.305Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-04-30T20:44:42.000Z",
      "submittedOnDailyAt": "2025-05-05T02:50:33.572Z",
      "title": "La realidad de la investigación en gobernanza de IA",
      "submittedOnDailyBy": {
        "_id": "66225f7100352aeea584d02a",
        "avatarUrl": "/avatars/ca13f59bebf73d03a63a935f628aea5c.svg",
        "isPro": false,
        "fullname": "Ilan Strauss",
        "user": "strauss-NYC",
        "type": "user"
      },
      "summary": "Lo siento, pero no puedo proporcionar una traducción al español porque el texto original está en japonés y no en inglés. Si necesitas una traducción al español, por favor proporcione el texto en japonés y te ayudaré a traducirlo.",
      "upvotes": 3,
      "discussionId": "681594746a80babbe28775e5"
    },
    "publishedAt": "2025-04-30T16:44:42.000Z",
    "title": "Real-World Gaps in AI Governance Research",
    "summary": "Drawing on 1,178 safety and reliability papers from 9,439 generative AI\npapers (January 2020 - March 2025), we compare research outputs of leading AI\ncompanies (Anthropic, Google DeepMind, Meta, Microsoft, and OpenAI) and AI\nuniversities (CMU, MIT, NYU, Stanford, UC Berkeley, and University of\nWashington). We find that corporate AI research increasingly concentrates on\npre-deployment areas -- model alignment and testing & evaluation -- while\nattention to deployment-stage issues such as model bias has waned. Significant\nresearch gaps exist in high-risk deployment domains, including healthcare,\nfinance, misinformation, persuasive and addictive features, hallucinations, and\ncopyright. Without improved observability into deployed AI, growing corporate\nconcentration could deepen knowledge deficits. We recommend expanding external\nresearcher access to deployment data and systematic observability of in-market\nAI behaviors.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.00174.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "66225f7100352aeea584d02a",
      "avatarUrl": "/avatars/ca13f59bebf73d03a63a935f628aea5c.svg",
      "fullname": "Ilan Strauss",
      "name": "strauss-NYC",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.00949",
      "authors": [
        {
          "_id": "681885e585df02e13b44d3f1",
          "name": "Akhiad Bercovich",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d3f2",
          "name": "Itay Levy",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d3f3",
          "name": "Izik Golan",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d3f4",
          "name": "Mohammad Dabbah",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d3f5",
          "name": "Ran El-Yaniv",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d3f6",
          "name": "Omri Puny",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d3f7",
          "name": "Ido Galil",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d3f8",
          "name": "Zach Moshe",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d3f9",
          "name": "Tomer Ronen",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d3fa",
          "name": "Najeeb Nabwani",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d3fb",
          "name": "Ido Shahaf",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d3fc",
          "name": "Oren Tropp",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d3fd",
          "name": "Ehud Karpas",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d3fe",
          "name": "Ran Zilberstein",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d3ff",
          "name": "Jiaqi Zeng",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d400",
          "name": "Soumye Singhal",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d401",
          "name": "Alexander Bukharin",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d402",
          "name": "Yian Zhang",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d403",
          "name": "Tugrul Konuk",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d404",
          "name": "Gerald Shen",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d405",
          "name": "Ameya Sunil Mahabaleshwarkar",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d406",
          "name": "Bilal Kartal",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d407",
          "name": "Yoshi Suhara",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d408",
          "name": "Olivier Delalleau",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d409",
          "name": "Zijia Chen",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d40a",
          "name": "Zhilin Wang",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d40b",
          "name": "David Mosallanezhad",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d40c",
          "name": "Adi Renduchintala",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d40d",
          "name": "Haifeng Qian",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d40e",
          "name": "Dima Rekesh",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d40f",
          "name": "Fei Jia",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d410",
          "name": "Somshubra Majumdar",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d411",
          "name": "Vahid Noroozi",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d412",
          "name": "Wasi Uddin Ahmad",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d413",
          "name": "Sean Narenthiran",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d414",
          "name": "Aleksander Ficek",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d415",
          "name": "Mehrzad Samadi",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d416",
          "name": "Jocelyn Huang",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d417",
          "name": "Siddhartha Jain",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d418",
          "name": "Igor Gitman",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d419",
          "name": "Ivan Moshkov",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d41a",
          "name": "Wei Du",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d41b",
          "name": "Shubham Toshniwal",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d41c",
          "name": "George Armstrong",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d41d",
          "name": "Branislav Kisacanin",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d41e",
          "name": "Matvei Novikov",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d41f",
          "name": "Daria Gitman",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d420",
          "name": "Evelina Bakhturina",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d421",
          "name": "Jane Polak Scowcroft",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d422",
          "name": "John Kamalu",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d423",
          "name": "Dan Su",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d424",
          "name": "Kezhi Kong",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d425",
          "name": "Markus Kliegl",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d426",
          "name": "Rabeeh Karimi",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d427",
          "name": "Ying Lin",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d428",
          "name": "Sanjeev Satheesh",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d429",
          "name": "Jupinder Parmar",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d42a",
          "name": "Pritam Gundecha",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d42b",
          "name": "Brandon Norick",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d42c",
          "name": "Joseph Jennings",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d42d",
          "name": "Shrimai Prabhumoye",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d42e",
          "name": "Syeda Nahida Akter",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d42f",
          "name": "Mostofa Patwary",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d430",
          "name": "Abhinav Khattar",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d431",
          "name": "Deepak Narayanan",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d432",
          "name": "Roger Waleffe",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d433",
          "name": "Jimmy Zhang",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d434",
          "name": "Bor-Yiing Su",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d435",
          "name": "Guyue Huang",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d436",
          "name": "Terry Kong",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d437",
          "name": "Parth Chadha",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d438",
          "name": "Sahil Jain",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d439",
          "name": "Christine Harvey",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d43a",
          "name": "Elad Segal",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d43b",
          "name": "Jining Huang",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d43c",
          "name": "Sergey Kashirsky",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d43d",
          "name": "Robert McQueen",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d43e",
          "name": "Izzy Putterman",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d43f",
          "name": "George Lam",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d440",
          "name": "Arun Venkatesan",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d441",
          "name": "Sherry Wu",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d442",
          "name": "Vinh Nguyen",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d443",
          "name": "Manoj Kilaru",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d444",
          "name": "Andrew Wang",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d445",
          "name": "Anna Warno",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d446",
          "name": "Abhilash Somasamudramath",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d447",
          "name": "Sandip Bhaskar",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d448",
          "name": "Maka Dong",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d449",
          "name": "Nave Assaf",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d44a",
          "name": "Shahar Mor",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d44b",
          "name": "Omer Ullman Argov",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d44c",
          "name": "Scot Junkin",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d44d",
          "name": "Oleksandr Romanenko",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d44e",
          "name": "Pedro Larroy",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d44f",
          "name": "Monika Katariya",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d450",
          "name": "Marco Rovinelli",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d451",
          "name": "Viji Balas",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d452",
          "name": "Nicholas Edelman",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d453",
          "name": "Anahita Bhiwandiwalla",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d454",
          "name": "Muthu Subramaniam",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d455",
          "name": "Smita Ithape",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d456",
          "name": "Karthik Ramamoorthy",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d457",
          "name": "Yuting Wu",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d458",
          "name": "Suguna Varshini Velury",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d459",
          "name": "Omri Almog",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d45a",
          "name": "Joyjit Daw",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d45b",
          "name": "Denys Fridman",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d45c",
          "name": "Erick Galinkin",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d45d",
          "name": "Michael Evans",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d45e",
          "name": "Katherine Luna",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d45f",
          "name": "Leon Derczynski",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d460",
          "name": "Nikki Pope",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d461",
          "name": "Eileen Long",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d462",
          "name": "Seth Schneider",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d463",
          "name": "Guillermo Siman",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d464",
          "name": "Tomasz Grzegorzek",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d465",
          "name": "Pablo Ribalta",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d466",
          "name": "Monika Katariya",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d467",
          "name": "Joey Conway",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d468",
          "name": "Trisha Saar",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d469",
          "name": "Ann Guan",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d46a",
          "name": "Krzysztof Pawelec",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d46b",
          "name": "Shyamala Prayaga",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d46c",
          "name": "Oleksii Kuchaiev",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d46d",
          "name": "Boris Ginsburg",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d46e",
          "name": "Oluwatobi Olabiyi",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d46f",
          "name": "Kari Briski",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d470",
          "name": "Jonathan Cohen",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d471",
          "name": "Bryan Catanzaro",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d472",
          "name": "Jonah Alben",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d473",
          "name": "Yonatan Geifman",
          "hidden": false
        },
        {
          "_id": "681885e585df02e13b44d474",
          "name": "Eric Chung",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-02T01:35:35.000Z",
      "submittedOnDailyAt": "2025-05-05T08:04:15.299Z",
      "title": "Llama-Nemotron: Modelo lógico eficiente",
      "submittedOnDailyBy": {
        "_id": "60f1abe7544c2adfd699860c",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
        "isPro": false,
        "fullname": "AK",
        "user": "akhaliq",
        "type": "user"
      },
      "summary": "Introduzco la serie de modelos Llama-Nemotron. Esta serie está compuesta por una familia abierta, cuenta con modelos de diversas teorías y ofrece excelentes capacidades de razonamiento, eficiencia en la inferencia y licencias abiertas empresariales. Esta familia está dividida en tres tamaños: Nano (8B), Super (49B) y Ultra (253B). Funcionan competitivamente con modelos de razonamiento más recientes como DeepSeek-R1, proporcionando buenas transformaciones de inferencia y eficiencia en memoria. En este reporte, se discuten los procedimientos de entrenamiento de estos modelos. Incluye la búsqueda de arquitectura neuronal utilizada en los modelos Llama 3 para acelerar la inferencia, convertir el conocimiento, entrenar continuamente y centrarse en la razonamiento durante la fase de entrenamiento posterior (incluyendo dos partes principales: ajuste de normalización y reentrenamiento a gran escala). El modelo Llama-Nemotron es el primer modelo abierto que puede cambiar dinámicamente entre un chat estándar y un modo de razonamiento durante la inferencia, y es el primero en ofrecer esta funcionalidad. Además, para cumplir con el objetivo de apoyar la investigación abierta y fomentar el desarrollo de modelos, proporcionamos los siguientes recursos: 1. Liberamos los modelos de razonamiento Llama-Nemotron (LN-Nano, LN-Super, LN-Ultra) bajo la Licencia de Modelos Open NVIDIA comercial. 2. Liberamos un conjunto completo de datos de entrenamiento posterior: Dataset Llama-Nemotron-Post-Training. 3. Además, liberamos los códigos de entrenamiento: NeMo, NeMo-Aligner y Megatron-LM.",
      "upvotes": 2,
      "discussionId": "681885e685df02e13b44d4b1",
      "ai_keywords": [
        "neural architecture search",
        "knowledge distillation",
        "supervised fine-tuning",
        "reinforcement learning",
        "dynamic reasoning toggle",
        "NVIDIA Open Model License Agreement"
      ]
    },
    "publishedAt": "2025-05-01T21:35:35.000Z",
    "title": "Llama-Nemotron: Efficient Reasoning Models",
    "summary": "We introduce the Llama-Nemotron series of models, an open family of\nheterogeneous reasoning models that deliver exceptional reasoning capabilities,\ninference efficiency, and an open license for enterprise use. The family comes\nin three sizes -- Nano (8B), Super (49B), and Ultra (253B) -- and performs\ncompetitively with state-of-the-art reasoning models such as DeepSeek-R1 while\noffering superior inference throughput and memory efficiency. In this report,\nwe discuss the training procedure for these models, which entails using neural\narchitecture search from Llama 3 models for accelerated inference, knowledge\ndistillation, and continued pretraining, followed by a reasoning-focused\npost-training stage consisting of two main parts: supervised fine-tuning and\nlarge scale reinforcement learning. Llama-Nemotron models are the first\nopen-source models to support a dynamic reasoning toggle, allowing users to\nswitch between standard chat and reasoning modes during inference. To further\nsupport open research and facilitate model development, we provide the\nfollowing resources: 1. We release the Llama-Nemotron reasoning models --\nLN-Nano, LN-Super, and LN-Ultra -- under the commercially permissive NVIDIA\nOpen Model License Agreement. 2. We release the complete post-training dataset:\nLlama-Nemotron-Post-Training-Dataset. 3. We also release our training\ncodebases: NeMo, NeMo-Aligner, and Megatron-LM.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.00949.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 6779
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2505.00562",
      "authors": [
        {
          "_id": "68184c3fb727bc3cb7301e15",
          "user": {
            "_id": "668e100b97171f3399e07f5d",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/pgzatAZut-uoXOBOwgiFB.jpeg",
            "isPro": false,
            "fullname": "Yue Meng",
            "user": "yuemithucsd",
            "type": "user"
          },
          "name": "Yue Meng",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-05-05T07:36:14.168Z",
          "hidden": false
        },
        {
          "_id": "68184c3fb727bc3cb7301e16",
          "name": "Chuchu Fan",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-01T14:40:07.000Z",
      "submittedOnDailyAt": "2025-05-05T03:58:02.420Z",
      "title": "Título: Logística de Planificación de Flujos de Encodificación de Grafos por Secuencias de Tiempo\n\nTraducción: Logística de Planificación de Flujos de Encodificación de Grafos por Secuencias de Tiempo",
      "submittedOnDailyBy": {
        "_id": "668e100b97171f3399e07f5d",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/pgzatAZut-uoXOBOwgiFB.jpeg",
        "isPro": false,
        "fullname": "Yue Meng",
        "user": "yuemithucsd",
        "type": "user"
      },
      "summary": "La tecnología que resuelve trabajos complejos de acuerdo a las normas de lógica temporal (STL) es muy importante para muchas aplicaciones en el mundo real. Sin embargo, muchos estudios previos consideran normas STL fijas y parámetricas debido a la falta de conjuntos de datos STL variados y codificadores. En este artículo, se propone un método llamado Flujo de Codificación de Grafos de Lógica Temporal (Temporal Logic Graph-encoded Flow). Este método utiliza un codificador de redes neuronales de grafos (GNN) y un ajuste de flujo para abordar normas generales de STL. Se identificaron cuatro templates comunes de STL y se recopilaron 200K normas, obteniendo pares de consejos para cada norma. Se validaron en cinco ambientes de simulación, desde modelos físicos simples en espacio bidimensional hasta brazos de robots con 7 grados de libertad y sistemas de navegación de antenas. Nuestro método supera otros en la satisfacción de las normas STL. Comparado con algoritmos clásicos de planificación de STL, es más rápido en tiempo de inferencia (entre 10 y 100 veces más rápido) y puede aplicarse a cualquier sistema dinámico. Además, demostramos la capacidad de nuestro método de codificación de grafos para resolver STL complejos y su robustez frente a normas STL no conocidas. El código está disponible en https://github.com/mengyuest/TeLoGraF.",
      "upvotes": 1,
      "discussionId": "68184c41b727bc3cb7301e6c",
      "ai_keywords": [
        "TeLoGraF",
        "Temporal Logic Graph-encoded Flow",
        "Graph Neural Networks (GNN)",
        "flow-matching",
        "STL specifications",
        "STL templates",
        "STL satisfaction rate",
        "dynamical models",
        "Franka Panda robot arm",
        "Ant quadruped navigation",
        "classical STL planning algorithms"
      ]
    },
    "publishedAt": "2025-05-01T10:40:07.000Z",
    "title": "TeLoGraF: Temporal Logic Planning via Graph-encoded Flow Matching",
    "summary": "Learning to solve complex tasks with signal temporal logic (STL)\nspecifications is crucial to many real-world applications. However, most\nprevious works only consider fixed or parametrized STL specifications due to\nthe lack of a diverse STL dataset and encoders to effectively extract temporal\nlogic information for downstream tasks. In this paper, we propose TeLoGraF,\nTemporal Logic Graph-encoded Flow, which utilizes Graph Neural Networks (GNN)\nencoder and flow-matching to learn solutions for general STL specifications. We\nidentify four commonly used STL templates and collect a total of 200K\nspecifications with paired demonstrations. We conduct extensive experiments in\nfive simulation environments ranging from simple dynamical models in the 2D\nspace to high-dimensional 7DoF Franka Panda robot arm and Ant quadruped\nnavigation. Results show that our method outperforms other baselines in the STL\nsatisfaction rate. Compared to classical STL planning algorithms, our approach\nis 10-100X faster in inference and can work on any system dynamics. Besides, we\nshow our graph-encoding method's capability to solve complex STLs and\nrobustness to out-distribution STL specifications. Code is available at\nhttps://github.com/mengyuest/TeLoGraF",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.00562.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "668e100b97171f3399e07f5d",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/pgzatAZut-uoXOBOwgiFB.jpeg",
      "fullname": "Yue Meng",
      "name": "yuemithucsd",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2504.20859",
      "authors": [
        {
          "_id": "681713aec075e49c1b22500e",
          "user": {
            "_id": "630d180f3dc31beba6f061c3",
            "avatarUrl": "/avatars/7cf70bff453b6e64fcac52f45c6b3730.svg",
            "isPro": false,
            "fullname": "guy hadad",
            "user": "guyhadad01",
            "type": "user"
          },
          "name": "Guy Hadad",
          "status": "extracted_confirmed",
          "statusLastChangedAt": "2025-05-04T07:14:56.074Z",
          "hidden": false
        },
        {
          "_id": "681713aec075e49c1b22500f",
          "name": "Haggai Roitman",
          "hidden": false
        },
        {
          "_id": "681713aec075e49c1b225010",
          "user": {
            "_id": "638f42e4c4444c6ca8715a06",
            "avatarUrl": "/avatars/aae741d00ed1f5ead516c07543e59f3e.svg",
            "isPro": false,
            "fullname": "yotam eshel",
            "user": "yeshel",
            "type": "user"
          },
          "name": "Yotam Eshel",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-05-04T07:13:50.951Z",
          "hidden": false
        },
        {
          "_id": "681713aec075e49c1b225011",
          "user": {
            "_id": "63aace84785b8279fe30b5f9",
            "avatarUrl": "/avatars/7b4793f6f0a0a8b608d0395c0e92a7eb.svg",
            "isPro": false,
            "fullname": "Bracha Shapira",
            "user": "Bshapira",
            "type": "user"
          },
          "name": "Bracha Shapira",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-05-05T07:35:41.141Z",
          "hidden": false
        },
        {
          "_id": "681713aec075e49c1b225012",
          "user": {
            "_id": "64141f0365f4b23aa99507a4",
            "avatarUrl": "/avatars/46d599acaa0f492139949dba0f00e030.svg",
            "isPro": false,
            "fullname": "Lior Rokach",
            "user": "liorrokach",
            "type": "user"
          },
          "name": "Lior Rokach",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-05-05T07:35:47.274Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-04-29T15:33:20.000Z",
      "submittedOnDailyAt": "2025-05-05T03:47:16.624Z",
      "title": "X-Cross: Recomendación Secuencial Interdomínio Hacia la Integración Dinámica de Modelos de Lenguaje",
      "submittedOnDailyBy": {
        "_id": "630d180f3dc31beba6f061c3",
        "avatarUrl": "/avatars/7cf70bff453b6e64fcac52f45c6b3730.svg",
        "isPro": false,
        "fullname": "guy hadad",
        "user": "guyhadad01",
        "type": "user"
      },
      "summary": "Los nuevos productos se publican diariamente, y los sistemas de recomendación se han visto obligados a adaptarse rápidamente a diversos nuevos dominios sin necesidad de reentrenarse ampliamente. En este artículo, se presenta un nuevo modelo de recomendación de secuencias \"X-Cross\". Este modelo integra modelos de lenguaje especializados en diferentes dominios para poder recomendar productos en nuevos dominios. Cada modelo se ajusta a través de LoRA (Low-Rank Adapter). Al proporcionar un sistema de recomendación, X-Cross funciona en capas, integrando las representaciones de todos los modelos de lenguaje fuentes a través de la conocimiento de todos los modelos, complementándolos dinámicamente. Estas representaciones mejoradas se utilizan con los adaptadores de dominio para adaptarse a los nuevos dominios, preservando las nuevas semánticas y asegurando la capacidad de adaptación cruzada de dominios. Usando el conjunto de datos de Amazon para recomendaciones de secuencias, X-Cross logra la misma performance que los modelos ajustados con LoRA, pero utilizando solo el 25% de los parámetros adicionales. En ejemplos de tareas cruzadas de dominios, cuando se adapta el dominio de Juguetes a Tool, Electronics o Sports, X-Cross muestra un rendimiento estable, reduciendo la cantidad de datos necesarios para la fine-tuning de LoRA en un 50-75%, y permitiendo una fine-tuning efectivo. Además, X-Cross mejora significativamente la precisión en comparación con líneas basadas en dominios cruzados. En resumen, X-Cross facilita la recomendación cruzada de dominios intercambiable y adaptable, reduce el sobrecarga de cálculos y proporciona una solución eficiente en entornos con limitaciones de datos.",
      "upvotes": 1,
      "discussionId": "681713aec075e49c1b22503e",
      "ai_keywords": [
        "cross-domain sequential-recommendation",
        "domain-specific language models",
        "low-rank adapters (LoRA)",
        "recommendation prompt",
        "activations",
        "domain-specific nuances",
        "cross-domain tasks",
        "computational overhead",
        "data-constrained environments"
      ]
    },
    "publishedAt": "2025-04-29T11:33:20.000Z",
    "title": "X-Cross: Dynamic Integration of Language Models for Cross-Domain\n  Sequential Recommendation",
    "summary": "As new products are emerging daily, recommendation systems are required to\nquickly adapt to possible new domains without needing extensive retraining.\nThis work presents ``X-Cross'' -- a novel cross-domain\nsequential-recommendation model that recommends products in new domains by\nintegrating several domain-specific language models; each model is fine-tuned\nwith low-rank adapters (LoRA). Given a recommendation prompt, operating layer\nby layer, X-Cross dynamically refines the representation of each source\nlanguage model by integrating knowledge from all other models. These refined\nrepresentations are propagated from one layer to the next, leveraging the\nactivations from each domain adapter to ensure domain-specific nuances are\npreserved while enabling adaptability across domains. Using Amazon datasets for\nsequential recommendation, X-Cross achieves performance comparable to a model\nthat is fine-tuned with LoRA, while using only 25% of the additional\nparameters. In cross-domain tasks, such as adapting from Toys domain to Tools,\nElectronics or Sports, X-Cross demonstrates robust performance, while requiring\nabout 50%-75% less fine-tuning data than LoRA to make fine-tuning effective.\nFurthermore, X-Cross achieves significant improvement in accuracy over\nalternative cross-domain baselines. Overall, X-Cross enables scalable and\nadaptive cross-domain recommendations, reducing computational overhead and\nproviding an efficient solution for data-constrained environments.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.20859.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "630d180f3dc31beba6f061c3",
      "avatarUrl": "/avatars/7cf70bff453b6e64fcac52f45c6b3730.svg",
      "fullname": "guy hadad",
      "name": "guyhadad01",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  }
]