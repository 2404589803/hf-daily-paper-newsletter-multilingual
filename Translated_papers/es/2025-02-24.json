[
  {
    "paper": {
      "id": "2502.14776",
      "authors": [
        {
          "_id": "67bbdb46d94d32bcfba70db7",
          "name": "Xun Liang",
          "hidden": false
        },
        {
          "_id": "67bbdb46d94d32bcfba70db8",
          "name": "Jiawei Yang",
          "hidden": false
        },
        {
          "_id": "67bbdb46d94d32bcfba70db9",
          "user": {
            "_id": "662dd19f9e6d371ab71b91ce",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/662dd19f9e6d371ab71b91ce/mZBPw_Zs8ZlEFGlbekAoH.jpeg",
            "isPro": false,
            "fullname": "Yezhaohui Wang",
            "user": "HaruTeru",
            "type": "user"
          },
          "name": "Yezhaohui Wang",
          "status": "extracted_confirmed",
          "statusLastChangedAt": "2025-02-24T04:12:46.485Z",
          "hidden": false
        },
        {
          "_id": "67bbdb46d94d32bcfba70dba",
          "name": "Chen Tang",
          "hidden": false
        },
        {
          "_id": "67bbdb46d94d32bcfba70dbb",
          "user": {
            "_id": "656f47ba2f058b368c0b1611",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/656f47ba2f058b368c0b1611/mrmcmA8bxaDNUhuJQQ7T1.png",
            "isPro": false,
            "fullname": "Zifan Zheng",
            "user": "fan2goa1",
            "type": "user"
          },
          "name": "Zifan Zheng",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-24T09:07:22.303Z",
          "hidden": false
        },
        {
          "_id": "67bbdb46d94d32bcfba70dbc",
          "name": "Simin Niu",
          "hidden": false
        },
        {
          "_id": "67bbdb46d94d32bcfba70dbd",
          "name": "Shichao Song",
          "hidden": false
        },
        {
          "_id": "67bbdb46d94d32bcfba70dbe",
          "user": {
            "_id": "669e0b93c7cb0568dac6e92e",
            "avatarUrl": "/avatars/a39ea77d7391f164af8a80f94f85f2ca.svg",
            "isPro": false,
            "fullname": "hanyu Wang",
            "user": "UglyToilet",
            "type": "user"
          },
          "name": "Hanyu Wang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-24T09:07:20.146Z",
          "hidden": false
        },
        {
          "_id": "67bbdb46d94d32bcfba70dbf",
          "name": "Bo Tang",
          "hidden": false
        },
        {
          "_id": "67bbdb46d94d32bcfba70dc0",
          "name": "Feiyu Xiong",
          "hidden": false
        },
        {
          "_id": "67bbdb46d94d32bcfba70dc1",
          "name": "Keming Mao",
          "hidden": false
        },
        {
          "_id": "67bbdb46d94d32bcfba70dc2",
          "name": "Zhiyu li",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-20T17:59:45.000Z",
      "title": "SurveyX: Modelo de Razionalización de Opiniones por Automatización de Investigación Académica",
      "summary": "Los modelos de lenguaje grande (LLMs) muestran capacidades de comprensión inusuales y una amplia base de conocimientos, lo que les permite ser utilizados como herramientas eficientes para la generación automática de encuestas. Sin embargo, los recientes estudios sobre la generación automática de encuestas están limitados por importantes restricciones, como el tamaño del ventana de contexto limitado y la falta de discusión de contenidos profundos. Inspirados en el proceso de escritura de humanos, dividimos la creación de encuestas en dos etapas: 'Preparación' y 'Generación', proponiendo un sistema eficiente y organizado llamado 'SurveyX'. A través de la introducción creativa de la búsqueda de recursos en línea, el método de preprocesamiento 'AttributeTree' y el proceso de reposición, SurveyX mejora significativamente la eficiencia en la creación de encuestas. Los resultados de evaluación experimental muestran que SurveyX supera a los sistemas actuales de generación automática de encuestas en cuanto a calidad de contenido (mejora del 0.259) y calidad de citas (mejora del 1.76), y se acerca a la performance de expertos en varios criterios de evaluación. Ejemplos de encuestas generadas en SurveyX están disponibles en www.surveyx.cn.",
      "upvotes": 61,
      "discussionId": "67bbdb47d94d32bcfba70df3"
    },
    "publishedAt": "2025-02-23T21:39:54.375Z",
    "title": "SurveyX: Academic Survey Automation via Large Language Models",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.14776.png",
    "numComments": 4,
    "submittedBy": {
      "_id": "669e60ee8580d17cb60f8347",
      "avatarUrl": "/avatars/37963b833228afe39cc24854c9326670.svg",
      "fullname": "yang jiawei",
      "name": "Dany-0",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 5
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.11663",
      "authors": [
        {
          "_id": "67b705d2ebee4662205c47f7",
          "name": "Jingcheng Ni",
          "hidden": false
        },
        {
          "_id": "67b705d2ebee4662205c47f8",
          "name": "Yuxin Guo",
          "hidden": false
        },
        {
          "_id": "67b705d2ebee4662205c47f9",
          "user": {
            "_id": "6572dcc6bbd6664053b1fa6b",
            "avatarUrl": "/avatars/aba29efd00bc41f14ce422f7807cd2c3.svg",
            "isPro": false,
            "fullname": "Liu Yichen",
            "user": "lyclyc52",
            "type": "user"
          },
          "name": "Yichen Liu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-24T09:23:40.466Z",
          "hidden": false
        },
        {
          "_id": "67b705d2ebee4662205c47fa",
          "name": "Rui Chen",
          "hidden": false
        },
        {
          "_id": "67b705d2ebee4662205c47fb",
          "name": "Lewei Lu",
          "hidden": false
        },
        {
          "_id": "67b705d2ebee4662205c47fc",
          "user": {
            "_id": "65717368be66cd9b65a8201c",
            "avatarUrl": "/avatars/fe945828eec9ded4cfa3b89d48a64d90.svg",
            "isPro": false,
            "fullname": "Wu Zehuan",
            "user": "wzhgba",
            "type": "user"
          },
          "name": "Zehuan Wu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-21T09:59:38.956Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-17T10:53:56.000Z",
      "title": "MaskGWM: Modelo Mundial de Motorización Generalizable con Máscaras de Vídeo",
      "summary": "El modelo mundial es capaz de predecir cambios ambientales a partir de acciones, lo cual es crucial para modelos autónomos de conducción que tienen una fuerte capacidad de generalización. Los principales modelos de conducción se construyen basándose en modelos de predicción de videos. A través de generadores basados en división, se pueden crear secuencias de video de alta calidad, pero esto está limitado por el tiempo de predicción y la capacidad de generalización global. En este artículo, se revisa un método para resolver estos problemas, combinando el entrenamiento de pérdida de generación y el aprendizaje de contexto basado en características de estilo MAE. Específicamente, se introducen tres diseños clave para lograr este objetivo: 1) se extiende la estructura de Transformer de división (DiT) para que pueda ser entrenado con tareas adicionales de configuración de máscaras. 2) se diseñan tokenes de máscara relacionados para procesar las tareas de reconstrucción de máscara y generación. 3) se extiende la tarea de configuración de máscaras a las regiones espacial-temporales, utilizando máscaras individuales para reemplazar la auto-atención oculta de MAE. Después de esto, se introduce un módulo de visión cruzada individual según este diseño de máscaras. Basándose en estas mejoras, se propone un modelo de conducción de videos de alta generalización, llamado MaskGWM, que aborda la reconstrucción de máscaras de video. El modelo incluye dos variantes: MaskGWM-long, que se centra en la predicción a largo plazo, y MaskGWM-mview, que se especializa en la generación de múltiples perspectivas. Los experimentos detallados en los marcos de referencia estándar incluyen la validación generalizada en el conjunto de datos Nuscene, la predicción a largo plazo en el conjunto de datos OpenDV-2K, y la validación de zero-shot en el conjunto de datos Waymo, demostrando los efectos de los métodos propuestos. Las medidas numéricas en estos conjuntos de datos muestran que nuestro método mejora significativamente los modelos de conducción más avanzados.",
      "upvotes": 33,
      "discussionId": "67b705d4ebee4662205c489c"
    },
    "publishedAt": "2025-02-24T01:16:03.517Z",
    "title": "MaskGWM: A Generalizable Driving World Model with Video Mask Reconstruction",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.11663.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "65717368be66cd9b65a8201c",
      "avatarUrl": "/avatars/fe945828eec9ded4cfa3b89d48a64d90.svg",
      "fullname": "Wu Zehuan",
      "name": "wzhgba",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.13449",
      "authors": [
        {
          "_id": "67b7ceae3e8a45f770b2606e",
          "user": {
            "_id": "65633c5e84a9fbe322f87d81",
            "avatarUrl": "/avatars/7233a555b43c669847a950ce5697c92c.svg",
            "isPro": false,
            "fullname": "DongkiKim",
            "user": "DongkiKim",
            "type": "user"
          },
          "name": "Dongki Kim",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-21T09:59:11.214Z",
          "hidden": false
        },
        {
          "_id": "67b7ceae3e8a45f770b2606f",
          "name": "Wonbin Lee",
          "hidden": false
        },
        {
          "_id": "67b7ceae3e8a45f770b26070",
          "name": "Sung Ju Hwang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-19T05:49:10.000Z",
      "title": "Mol-LLaMA: Modelo de Lenguaje de Modularidad de Moléculas para la Comprensión General de los Molecules",
      "summary": "La comprensión de los moléculas desempeña un papel esencial en la comprensión de los organismos y en el desarrollo de la descubrimiento de fármacos, lo que requiere un conocimiento especializado en química y biología. Modelos de lenguaje molecular grandes han tenido gran éxito en la interpretación de la estructura de moléculas, pero su conjunto de datos de entrenamiento está limitado a conjuntos de datos centrados en tareas específicas de conocimientos particulares, lo que ha impidido que cubran completamente las características básicas de las moléculas, limitando así su capacidad como herramientas de apoyo generales. Para resolver estos problemas, proponemos Mol-LLaMA, un modelo de lenguaje molecular grande que aplica diferentes indicaciones para comprender el conocimiento general de las moléculas. En este modelo, se diseñan los principales tipos de datos que incluyen las características básicas de las moléculas y se integran conocimientos importantes de la estructura molecular. Además, se introduce un módulo que integra información complementaria de otros encoders de moléculas para mejorar sus características, y se utilizan diferentes representaciones de las moléculas para mejorar sus propiedades. A través de los resultados experimentales, Mol-LLaMA muestra su capacidad para comprender las características generales de las moléculas, generar respuestas relacionadas a las preguntas de los usuarios y mostrar la posibilidad de ser una herramienta de apoyo general en el análisis de moléculas.",
      "upvotes": 28,
      "discussionId": "67b7ceae3e8a45f770b2609f"
    },
    "publishedAt": "2025-02-23T21:52:51.059Z",
    "title": "Mol-LLaMA: Towards General Understanding of Molecules in Large Molecular Language Model",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13449.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "65633c5e84a9fbe322f87d81",
      "avatarUrl": "/avatars/7233a555b43c669847a950ce5697c92c.svg",
      "fullname": "DongkiKim",
      "name": "DongkiKim",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 5
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.15007",
      "authors": [
        {
          "_id": "67bc1a4a72499ce2ba28cc70",
          "name": "Anton Razzhigaev",
          "hidden": false
        },
        {
          "_id": "67bc1a4a72499ce2ba28cc71",
          "name": "Matvey Mikhalchuk",
          "hidden": false
        },
        {
          "_id": "67bc1a4a72499ce2ba28cc72",
          "name": "Temurbek Rahmatullaev",
          "hidden": false
        },
        {
          "_id": "67bc1a4a72499ce2ba28cc73",
          "name": "Elizaveta Goncharova",
          "hidden": false
        },
        {
          "_id": "67bc1a4a72499ce2ba28cc74",
          "name": "Polina Druzhinina",
          "hidden": false
        },
        {
          "_id": "67bc1a4a72499ce2ba28cc75",
          "name": "Ivan Oseledets",
          "hidden": false
        },
        {
          "_id": "67bc1a4a72499ce2ba28cc76",
          "name": "Andrey Kuznetsov",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-20T19:59:35.000Z",
      "title": "LLM-Microscope: Herramienta para descubrir el papel de los errores ocultos en el contexto\nMemoria de Transformer",
      "summary": "La metodología de codificación de información contextual en los modelos de lagragian jungle (LLM) se cuantifica, confirmando que pequeños elementos (por ejemplo, dimenitores, símbolos) tienen una alta relevancia contextual. En particular, la eliminación de estas agrupaciones de etiquetas disminuye significativamente el rendimiento en evaluaciones como MMLU y BABILong-4k, especialmente al eliminar stopwords, palabras y comas. Sin embargo, eliminar solo etiquetas irrelevantes también produce los mismos resultados. Nuestro análisis muestra una fuerte correlación entre contextualización y linearidad. La linearidad mide la precisión de transformaciones que pueden ser aproximadas con una sola transformación lineal. Estos hallazgos subrayan la importancia de las etiquetas de filtro para mantener el contexto. Para ello, proporcionamos un paquete de herramientas abierto-source llamado LLM-Microscope. Este paquete de herramientas evalúa la no linealidad a nivel de agrupaciones de etiquetas, evalua la memoria contextual, visualiza la contribución de capas indirectas (utilizando una mejora de Logit Lens), y mide la dimensión de características únicas de las representaciones. Este paquete de herramientas demuestra que las agrupaciones de etiquetas son esenciales para la comprensión a larga distancia.",
      "upvotes": 25,
      "discussionId": "67bc1a4c72499ce2ba28cd49"
    },
    "publishedAt": "2025-02-24T02:07:41.624Z",
    "title": "LLM-Microscope: Uncovering the Hidden Role of Punctuation in Context Memory of Transformers",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/6172aaeec8e66e2aa84c06b9/ZPSmOQ-7Yd7B7YIYiwcTw.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.15007.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "6172aaeec8e66e2aa84c06b9",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6172aaeec8e66e2aa84c06b9/ZdRZSp3P1SU6CIDbvQwkv.jpeg",
      "fullname": "Anton Razzhigaev",
      "name": "razzant",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 8
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.14397",
      "authors": [
        {
          "_id": "67bbed806f2833ecccf914dd",
          "name": "Shijie Huang",
          "hidden": false
        },
        {
          "_id": "67bbed806f2833ecccf914de",
          "name": "Yiren Song",
          "hidden": false
        },
        {
          "_id": "67bbed806f2833ecccf914df",
          "name": "Yuxuan Zhang",
          "hidden": false
        },
        {
          "_id": "67bbed806f2833ecccf914e0",
          "name": "Hailong Guo",
          "hidden": false
        },
        {
          "_id": "67bbed806f2833ecccf914e1",
          "name": "Xueyin Wang",
          "hidden": false
        },
        {
          "_id": "67bbed806f2833ecccf914e2",
          "name": "Mike Zheng Shou",
          "hidden": false
        },
        {
          "_id": "67bbed806f2833ecccf914e3",
          "name": "Jiaming Liu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-20T09:35:38.000Z",
      "title": "PhotoDoodle: Datos de pares de pocos frames para aprender edición de imágenes artísticas",
      "summary": "PhotoDoodle es un nuevo marco de trabajo para editar imágenes, utilizado al superponer elementos de decoración sobre las fotos. El dibujo sobre fotos requiere que los elementos insertados se integren naturalmente con el fondo, lo que implica necesidades de branding realista, ajustes de lápiz y coherencia del contexto. Además, el fondo no se deforma y se preserva, y el estilo propio del artista debe ser comprendido adecuadamente a partir de datos de entrenamiento limitados. Estas exigencias no han sido satisfactoriamente abordadas por métodos anteriores, que principalmente se centraban en la transferencia de estilo global o en la influencia local. En la propuesta, PhotoDoodle utiliza una estrategia de entrenamiento en dos etapas. Primero, se entrena un modelo general de edición de imágenes, OmniEditor, con una gran cantidad de datos. Luego, se fine-tunea el modelo utilizando EditLoRA con un pequeño conjunto de imágenes editadas por un artista, para que el modelo pueda comprender diferentes estilos y técnicas de edición. Para mejorar la coherencia de los resultados generados, se introduce una estructura de reutilización de datos de posición. Además, se publica un conjunto de datos de PhotoDoodle con seis estilos de alta calidad. Los experimentos extendidos muestran un alto rendimiento y robustez en la edición de imágenes personalizadas, abriendo nuevas posibilidades para la creación artística.",
      "upvotes": 22,
      "discussionId": "67bbed856f2833ecccf915c5"
    },
    "publishedAt": "2025-02-23T22:55:04.409Z",
    "title": "PhotoDoodle: Learning Artistic Image Editing from Few-Shot Pairwise Data",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.14397.png",
    "numComments": 4,
    "submittedBy": {
      "_id": "64311a95034ecbefddd141ef",
      "avatarUrl": "/avatars/b6dc5ca373bedbaa368208517954c375.svg",
      "fullname": "Yiren Song",
      "name": "yiren98",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isMod": false,
      "followerCount": 4
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.14922",
      "authors": [
        {
          "_id": "67bbe4ba79e0a705cf573985",
          "name": "Zihao Zeng",
          "hidden": false
        },
        {
          "_id": "67bbe4ba79e0a705cf573986",
          "name": "Xuyao Huang",
          "hidden": false
        },
        {
          "_id": "67bbe4ba79e0a705cf573987",
          "name": "Boxiu Li",
          "hidden": false
        },
        {
          "_id": "67bbe4ba79e0a705cf573988",
          "name": "Zhijie Deng",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-19T17:38:46.000Z",
      "title": "SIFT: Base de la inferencia de LLM basada en contexto (utilizando tarjetas de sticky)",
      "summary": "En este artículo, se reconoce como una importante problema la falta de comprensión del texto en los procesos de lógica de modelos de lenguaje grandes. Este problema se ha ampliado desde modelos pequeños hasta modelos avanzados como Llama3.2-3B-Instruct y DeepSeek-R1. Por ejemplo, los modelos de lenguaje grande (LLMs) a menudo no reconocen que \"per\" en \"10 dólares/kilogramo\" significa \"por cada\" y producen errores en las cálculos. Para resolver estos problemas, se presenta un nuevo enfoque de aprendizaje posterior llamado **Stick to the Facts (SIFT)**. SIFT fortalece la lógica de los modelos basados en texto mediante un aumento en la cantidad de cálculos durante la inferencia. El corazón de SIFT es el **stack text**, que es la forma en que el modelo registra y destaca claramente las informaciones importantes del texto. Cuando se proporciona el stack text, SIFT genera predicciones tanto de la solicitud original como de la solicitud con el stack text agregado. Si estos predicciones son diferentes, el stack text mejora gradualmente el resultado mediante la optimización *forward* (ajustando la extracción de hechos a la solicitud) y *inverse* (adaptando a las tendencias propias del modelo). De esta manera, se obtienen resultados lógicos con alta confianza. Los resultados de la investigación muestran un mejoramiento consistente en diferentes modelos (desde 3B hasta más de 100B) y en benchmarks como GSM8K y MATH-500. En particular, SIFT ha subido la precisión de DeepSeek-R1 en el AIME2024 de 78.33% a **85.67%**, lo que ha conferido a la comunidad abierta una nueva vanguardia. El código está disponible en https://github.com/zhijie-group/SIFT.",
      "upvotes": 13,
      "discussionId": "67bbe4bb79e0a705cf5739c3"
    },
    "publishedAt": "2025-02-23T22:17:18.309Z",
    "title": "SIFT: Grounding LLM Reasoning in Contexts via Stickers",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.14922.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 6193
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.12084",
      "authors": [
        {
          "_id": "67b8922ef6632327952ec1e1",
          "user": {
            "_id": "65d8b0f0661492b25c6623de",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65d8b0f0661492b25c6623de/c6LPDse8NIV_3BHIu8dYe.png",
            "isPro": false,
            "fullname": "Jianshu Zhang",
            "user": "Sterzhang",
            "type": "user"
          },
          "name": "Jianshu Zhang",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-02-21T14:48:16.643Z",
          "hidden": false
        },
        {
          "_id": "67b8922ef6632327952ec1e2",
          "user": {
            "_id": "64b0377121a001042bc0d274",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64b0377121a001042bc0d274/Hk8yI5_s7ey5o9SVZzXrB.png",
            "isPro": false,
            "fullname": "Dongyu Yao",
            "user": "RainJamesY",
            "type": "user"
          },
          "name": "Dongyu Yao",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-24T09:20:43.528Z",
          "hidden": false
        },
        {
          "_id": "67b8922ef6632327952ec1e3",
          "name": "Renjie Pi",
          "hidden": false
        },
        {
          "_id": "67b8922ef6632327952ec1e4",
          "name": "Paul Pu Liang",
          "hidden": false
        },
        {
          "_id": "67b8922ef6632327952ec1e5",
          "name": "Yi R.",
          "hidden": false
        },
        {
          "_id": "67b8922ef6632327952ec1e6",
          "name": "Fung",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-17T17:57:50.000Z",
      "title": "VLM^2-Bench: Exploración más detallada de la relación entre la visión oculta de los modelos visuales y la correspondencia explícita.",
      "summary": "La capacidad de enlazar categorías visualmente es fundamental en la vida diaria. Por ejemplo, se puede identificar la misma persona en varias fotografías utilizando categorías como base. Aunque se conocen las habilidades de los modelos de lenguaje visual (VLMs) para realizar estas tareas básicas, su efectividad en este campo era poco clara. Para abordar este tema, se presenta VLM^2-Bench, un marco de evaluación diseñado para analizar la capacidad de los VLMs en enlazar categorías visualmente. Este marco contiene 9 sub-tareas y más de 3,000 casos de prueba.\n\nSe realizaron evaluaciones detalladas en 8 modelos, incluyendo 8 VLMs abiertos y GPT-4o, y se analizaron los métodos de front-end tanto en el aspecto lingüístico como visual, resultando en 8 hallazgos importantes. Se detectaron importantes limitaciones en la capacidad de los modelos para enlazar categorías visualmente, y se reveló que GPT-4o era 34.80% menos efectivo que una persona humana. Con base en estos hallazgos, se proponen las siguientes recomendaciones: mejorar la capacidad visual esencial de los modelos, reducir la dependencia de conocimientos previos, unificar la justificación basada en lenguaje en tareas visuales, evitar la sesgos necesarios, construir relaciones de categorías visuales de manera independiente, y mejorar el rendimiento de modelos de inferencia modificando el patrón de entrenamiento con contextos visuales.",
      "upvotes": 12,
      "discussionId": "67b89230f6632327952ec27a"
    },
    "publishedAt": "2025-02-24T00:36:34.341Z",
    "title": "VLM$^2$-Bench: A Closer Look at How Well VLMs Implicitly Link Explicit Matching Visual Cues",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.12084.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "65d8b0f0661492b25c6623de",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65d8b0f0661492b25c6623de/c6LPDse8NIV_3BHIu8dYe.png",
      "fullname": "Jianshu Zhang",
      "name": "Sterzhang",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 8
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.15589",
      "authors": [
        {
          "_id": "67bbfe2d670ece8d9184f339",
          "name": "Jintian Zhang",
          "hidden": false
        },
        {
          "_id": "67bbfe2d670ece8d9184f33a",
          "name": "Yuqi Zhu",
          "hidden": false
        },
        {
          "_id": "67bbfe2d670ece8d9184f33b",
          "name": "Mengshu Sun",
          "hidden": false
        },
        {
          "_id": "67bbfe2d670ece8d9184f33c",
          "name": "Yujie Luo",
          "hidden": false
        },
        {
          "_id": "67bbfe2d670ece8d9184f33d",
          "user": {
            "_id": "6447800f30fa4ecb85ddad80",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6447800f30fa4ecb85ddad80/NsmXIaMsWctmTNA7tFVkX.jpeg",
            "isPro": false,
            "fullname": "Shuofei Qiao",
            "user": "GoooDte",
            "type": "user"
          },
          "name": "Shuofei Qiao",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-24T09:07:02.722Z",
          "hidden": false
        },
        {
          "_id": "67bbfe2d670ece8d9184f33e",
          "name": "Lun Du",
          "hidden": false
        },
        {
          "_id": "67bbfe2d670ece8d9184f33f",
          "name": "Da Zheng",
          "hidden": false
        },
        {
          "_id": "67bbfe2d670ece8d9184f340",
          "name": "Huajun Chen",
          "hidden": false
        },
        {
          "_id": "67bbfe2d670ece8d9184f341",
          "user": {
            "_id": "620b3bbb0668e435407c8d0a",
            "avatarUrl": "/avatars/e0fccbb2577d76088e09f054c35cffbc.svg",
            "isPro": false,
            "fullname": "Ningyu Zhang",
            "user": "Ningyu",
            "type": "user"
          },
          "name": "Ningyu Zhang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-24T09:07:04.794Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-21T16:57:22.000Z",
      "title": "LightThinker: Compresión basada en pensamientos en etapas",
      "summary": "Los modelos de lenguaje grande (LLMs) muestran un desempeño excepcional en tareas teóricas complejas, pero su eficiencia se disminuye debido a los altos costos de memoria y cálculo asociados con la generación de largos tokens. En este artículo, proponemos una nueva metodología que permita a los LLMs compresionar las pensamientos intermedios durante la resolución de problemas teóricos de manera dinámica. Inspirado en el proceso cognitivo humano, LightThinker transforma pasos de pensamiento extensos en expresiones más breves, dejando de lado la cadena original de razonamiento y reduciendo significativamente el número de tokens dentro del ventana de contexto. Esto se logra a través de la construcción de datos, la mapeo de tokens compresionados y la aplicación de una máscara de acción especializada para entrenar el modelo. Además, introducimos la métrica Dependency (Dep) para medir las relaciones de dependencia entre los tokens generados en el proceso. Los experimentos expandidos, basados en 4 conjuntos de datos y 2 modelos, demuestran que LightThinker puede mantener la precisión mientras reduce la cantidad de memoria utilizada y el tiempo de inferencia. Nuestro estudio abre nuevas perspectivas para mejorar la eficiencia de los LLMs en tareas teóricas complejas. El código está disponible en: https://github.com/zjunlp/LightThinker.",
      "upvotes": 12,
      "discussionId": "67bbfe2f670ece8d9184f3a4"
    },
    "publishedAt": "2025-02-24T00:07:05.804Z",
    "title": "LightThinker: Thinking Step-by-Step Compression",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/620b3bbb0668e435407c8d0a/dhGMWf_tcPkvQlRm5DbD6.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.15589.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "620b3bbb0668e435407c8d0a",
      "avatarUrl": "/avatars/e0fccbb2577d76088e09f054c35cffbc.svg",
      "fullname": "Ningyu Zhang",
      "name": "Ningyu",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 19
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.14494",
      "authors": [
        {
          "_id": "67b9dda03593f69f41cdb5d3",
          "name": "Jinnan Li",
          "hidden": false
        },
        {
          "_id": "67b9dda03593f69f41cdb5d4",
          "name": "Jinzhe Li",
          "hidden": false
        },
        {
          "_id": "67b9dda03593f69f41cdb5d5",
          "name": "Yue Wang",
          "hidden": false
        },
        {
          "_id": "67b9dda03593f69f41cdb5d6",
          "name": "Yi Chang",
          "hidden": false
        },
        {
          "_id": "67b9dda03593f69f41cdb5d7",
          "name": "Yuan Wu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-20T12:22:18.000Z",
      "title": "StructFlowBench: Benchmark de Flujos Estructurados de Multiple Turns",
      "summary": "La capacidad de seguimiento de comandos de transformación multi-a-multi es un aspecto esencial en aplicaciones reales de modelos de lenguaje grandes (LLMs). Los actuales marcos de evaluación se centran en la satisfacción de restricciones delicadas y en la evaluación de habilidades específicas de dominio, ignorando la relación estructural importante entre transformaciones multi-a-multi y uni-a-uni. Esta relación estructural refleja los intentos de los usuarios y proporciona un segundo nivel de evaluación más allá de la satisfacción de restricciones. Para abordar este problema, proponemos StructureFlowBench. StructureFlowBench es un marco de referencia de evaluación para seguimiento de comandos de transformación multi-a-multi que incluye modelado de flujo estructural. Este marco innovador define la relación entre seis transformaciones básicas y introduce nuevas restricciones estructurales en la evaluación de modelos, generando parámetros de flujo de diálogo personalizados que se ajustan a diferentes escaneros. Hemos aplicado métodos de evaluación basados en LLMs para realizar una evaluación sistemática de 13 modelos de LLM, tanto de código abierto como de código cerrado. Los resultados de los experimentos muestran claramente que los modelos actuales tienen deficiencias en la comprensión de la estructura de diálogos de transformación multi-a-multi. El código está disponible en: https://github.com/MLGroupJLU/StructFlowBench.",
      "upvotes": 10,
      "discussionId": "67b9dda13593f69f41cdb635"
    },
    "publishedAt": "2025-02-23T23:43:43.529Z",
    "title": "StructFlowBench: A Structured Flow Benchmark for Multi-turn Instruction Following",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.14494.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "670e57b3391f1a7021182bff",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/N0tuHZVz8KFPCv8G1qUX2.png",
      "fullname": "Yuan Wu",
      "name": "WhiteCatY",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.15027",
      "authors": [
        {
          "_id": "67bbdcec79fcd85f09ddd869",
          "name": "Henry Hengyuan Zhao",
          "hidden": false
        },
        {
          "_id": "67bbdcec79fcd85f09ddd86a",
          "name": "Wenqi Pei",
          "hidden": false
        },
        {
          "_id": "67bbdcec79fcd85f09ddd86b",
          "name": "Yifei Tao",
          "hidden": false
        },
        {
          "_id": "67bbdcec79fcd85f09ddd86c",
          "name": "Haiyang Mei",
          "hidden": false
        },
        {
          "_id": "67bbdcec79fcd85f09ddd86d",
          "name": "Mike Zheng Shou",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-20T20:27:06.000Z",
      "title": "InterFeedback: Método para clarificar la interacción inteligente de grandes modelos multimodales humanos a partir de retroalimentación",
      "summary": "Los actuales benchmarks no miden la inteligencia de interacción de grandes modelos multimodal (LMM) con usuarios humanos. Esto es un elemento necesario para el desarrollo de programas de asistencia general de IA. Hemos diseñado un marco interactivo \"InterFeedback\" aplicable tanto a los LMM como a los conjuntos de datos. De esta manera, se puede evaluar automáticamente esta inteligencia. Además, hemos introducido \"InterFeedback-Bench\" para evaluar la inteligencia interactiva utilizando conjuntos de datos representativos como MMU-Pro y MathVerse. Este benchmark mide a 10 modelos multimodal abiertos de código. Además, hemos proporcionado un nuevo conjunto de datos de 120 casos \"InterFeedback-Human\" para medir de manera manual la ejecución interactiva de modelos avanzados como OpenAI-o1 y Claude-3.5-Sonnet. Nuestros resultados de evaluación muestran que el LMM más avanzado actual (por ejemplo, OpenAI-o1) solo puede modificar sus resultados con menos del 50% de los feedbacks humanos. Nuestros hallazgos demuestran la necesidad de entender la inteligencia de los LMM y de aprovechar los beneficios de los feedbacks.",
      "upvotes": 4,
      "discussionId": "67bbdced79fcd85f09ddd8da"
    },
    "publishedAt": "2025-02-23T21:44:33.443Z",
    "title": "InterFeedback: Unveiling Interactive Intelligence of Large Multimodal Models via Human Feedback",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.15027.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 6193
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.15657",
      "authors": [
        {
          "_id": "67bbfd6c3593f69f41512d54",
          "name": "Yoshua Bengio",
          "hidden": false
        },
        {
          "_id": "67bbfd6c3593f69f41512d55",
          "name": "Michael Cohen",
          "hidden": false
        },
        {
          "_id": "67bbfd6c3593f69f41512d56",
          "name": "Damiano Fornasiere",
          "hidden": false
        },
        {
          "_id": "67bbfd6c3593f69f41512d57",
          "name": "Joumana Ghosn",
          "hidden": false
        },
        {
          "_id": "67bbfd6c3593f69f41512d58",
          "name": "Pietro Greiner",
          "hidden": false
        },
        {
          "_id": "67bbfd6c3593f69f41512d59",
          "name": "Matt MacDermott",
          "hidden": false
        },
        {
          "_id": "67bbfd6c3593f69f41512d5a",
          "name": "Sören Mindermann",
          "hidden": false
        },
        {
          "_id": "67bbfd6c3593f69f41512d5b",
          "name": "Adam Oberman",
          "hidden": false
        },
        {
          "_id": "67bbfd6c3593f69f41512d5c",
          "name": "Jesse Richardson",
          "hidden": false
        },
        {
          "_id": "67bbfd6c3593f69f41512d5d",
          "name": "Oliver Richardson",
          "hidden": false
        },
        {
          "_id": "67bbfd6c3593f69f41512d5e",
          "name": "Marc-Antoine Rondeau",
          "hidden": false
        },
        {
          "_id": "67bbfd6c3593f69f41512d5f",
          "name": "Pierre-Luc St-Charles",
          "hidden": false
        },
        {
          "_id": "67bbfd6c3593f69f41512d60",
          "name": "David Williams-King",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-21T18:28:36.000Z",
      "title": "El superinteligencia tiene un riesgo extremadamente peligroso: ¿la ciencia del IA puede proporcionar un camino seguro?",
      "summary": "Los empresas de IA avanzadas se centran en la construcción de agentes IA comunes. Este sistemas son capaces de planificar, actuar y perseguir objetivos automáticamente en casi todas las tareas que realizan los humanos. Estos sistemas detectan diversas amenazas, pero estas amenazas representan un gran riesgo para la seguridad pública y privada, ya que pueden ser causadas por la malaplicación de agentes IA maliciosos o por la pérdida de control inestable de los humanos. Actualmente se están discutiendo los métodos de entrenamiento de la IA que pueden ser los origenes de estos riesgos. De hecho, diversas escenas y experimentos presentan evidencias de que los agentes IA pueden desviarse de los objetivos establecidos por los operadores humanos y pueden buscar objetivos que contradigan los intereses humanos. Según el principio de precaución, es necesario reemplazar el camino actual de los agentes IA y elegir aquellos que sean seguros y útiles. Para ello, proponemos desarrollar sistemas de IA más seguros y confiables como bloques fundamentales. Estos sistemas se llamarán \"Scientist AI\" y tienen como objetivo que los humanos entiendan mejor su mundo, actuando solo para observar y interpretar el mundo. Este sistema está compuesto por un modelo de mundo para generar teorías de explicar los datos y un inferencia para responder a preguntas. Ambos componentes tienen la noción de incertidumbre específica para reducir el riesgo de excesivos predicciones. De acuerdo con estos consideraciones, el Scientist AI puede ayudar a acelerar la investigación científica y, en particular, incluir la seguridad de la IA. En particular, nuestro sistema puede utilizarse como guía para reducir los riesgos de los agentes IA. Finalmente, centrar nuestro enfoque en el desarrollo de IA sin agentes puede demostrar que se pueden obtener los beneficios de la innovación en la IA mientras evitamos los riesgos asociados al camino actual. Esperamos que esta discusión motive a los investigadores, desarrolladores y tomadores de decisiones a elegir caminos seguros.",
      "upvotes": 3,
      "discussionId": "67bbfd6c3593f69f41512d96"
    },
    "publishedAt": "2025-02-24T00:02:52.495Z",
    "title": "Superintelligent Agents Pose Catastrophic Risks: Can Scientist AI Offer a Safer Path?",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.15657.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6039478ab3ecf716b1a5fd4d",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg",
      "fullname": "taesiri",
      "name": "taesiri",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isMod": false,
      "followerCount": 63
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.15631",
      "authors": [
        {
          "_id": "67bbdbe8ea3003f47f15d036",
          "name": "Marthe Ballon",
          "hidden": false
        },
        {
          "_id": "67bbdbe8ea3003f47f15d037",
          "name": "Andres Algaba",
          "hidden": false
        },
        {
          "_id": "67bbdbe8ea3003f47f15d038",
          "name": "Vincent Ginis",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-21T17:59:13.000Z",
      "title": "La relación entre razones y rendimiento en grandes modelos de lenguaje -- o3 (mini) -- pueden pensar fuertemente sin necesidad de mucho tiempo.",
      "summary": "Los modelos de lenguaje de alto nivel muestran significativos avances matemáticos utilizando contextos asociativos y escalado de cálculo durante la prueba. Sin embargo, existen muchos problemas en la interacción entre el uso de tokens lógicos y el aumento de precisión. En particular, cuando se compara la generación de modelos entre generaciones, no se puede determinar si los mejores resultados vienen de una mejor asociación lógica o de una eficiencia en la lógica. Por lo tanto, se analizó sistemáticamente la longitud de la asociación lógica de o1-mini y o3-mini en el benchmark Omni-MATH, confirmando que o3-mini (m) puede alcanzar una precisión superior a o1-mini sin necesidad de asociaciones lógicas largas. Además, se muestra que la precisión generalmente disminuye cuando la asociación lógica es más larga, y este efecto es independiente de la dificultad del problema, incluso cuando se ajusta la dificultad. Esta reducción de precisión es menor en modelos más especializados, y un uso más eficiente de la capacidad de cálculo es una característica de las nuevas generaciones de modelos lógicos. Finalmente, o3-mini (h) logra un aumento de precisión más mínimo sobre o3-mini (m), lo cual se logra asignando muchos tokens lógicos a todos los problemas, incluyendo aquellos que ya pueden ser resueltos por o3-mini (m). Estos hallazgos proporcionan una nueva perspectiva sobre la relación entre la capacidad del modelo y la longitud de la asociación lógica, afectando la eficiencia, la escalabilidad y los métodos de evaluación.",
      "upvotes": 3,
      "discussionId": "67bbdbefea3003f47f15d226"
    },
    "publishedAt": "2025-02-23T21:40:17.216Z",
    "title": "The Relationship Between Reasoning and Performance in Large Language Models -- o3 (mini) Thinks Harder, Not Longer",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.15631.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 6193
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.14905",
      "authors": [
        {
          "_id": "67bbe0520aabd5d571a723e7",
          "name": "Bhavik Agarwal",
          "hidden": false
        },
        {
          "_id": "67bbe0520aabd5d571a723e8",
          "name": "Ishan Joshi",
          "hidden": false
        },
        {
          "_id": "67bbe0520aabd5d571a723e9",
          "name": "Viktoria Rojkova",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-18T16:44:55.000Z",
      "title": "JSON pensando en el: Pensando en JSON con rigor en la estrategia de fortalecimiento simple de obediencia de un LLM",
      "summary": "En este artículo, se aborda el desafío de generar un modelo de lenguaje grande (LLM) que respete la estricta sintaxis de inflexión, utilizando la capacidad de razonamiento del LLM para su implementación. Basándonos en el marco de aprendizaje por refuerzo de DeepSeek R1, nuestro enfoque combina la construcción de un conjunto de datos de razonamiento sintético con la optimización de políticas relativas (GRPO) y una función de recompensa personalizada, para desarrollar un nuevo flujo de trabajo para entrenar habilidades estructuradas de razonamiento en un modelo con 15 billones de parámetros. En particular, por primera vez, se realiza el aprendizaje por refuerzo en un conjunto de datos estructurado a partir de 20,000 muestras no estructuradas, y se reflejan los métodos de DeepSeek R1 para establecer capacidades de razonamiento esenciales. A continuación, se entrena con un conjunto de 10,000 muestras de datos de razonamiento para mejorar la respeto de la sintaxis en tareas de flujo descendente. En un rango de entrenamiento relativamente ligero, el entrenamiento de GRPO requiere aproximadamente 20 horas en un cluster de GPU 8xH100, mientras que el entrenamiento de SFT requiere 3 horas en un GPU A100. Nuestro modelo demostró una excelente capacidad para respetar la sintaxis de inflexión, y nuestro enfoque ThinkJSON demostró su eficacia en aplicaciones reales comparado con DeepSeek R1 (671B), la versión de DeepSeek R1 (Qwen-1.5B y Qwen-7B) y Gemini 2.0 Flash (70B). Nuestros resultados subrayan la utilidad práctica de un marco de trabajo eficiente en recursos.",
      "upvotes": 2,
      "discussionId": "67bbe0530aabd5d571a72437"
    },
    "publishedAt": "2025-02-23T22:11:17.789Z",
    "title": "Think Inside the JSON: Reinforcement Strategy for Strict LLM Schema Adherence",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.14905.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 6193
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.15681",
      "authors": [
        {
          "_id": "67bbe67c7727595ca5979d2a",
          "name": "Yilun Xu",
          "hidden": false
        },
        {
          "_id": "67bbe67c7727595ca5979d2b",
          "name": "Weili Nie",
          "hidden": false
        },
        {
          "_id": "67bbe67c7727595ca5979d2c",
          "name": "Arash Vahdat",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-21T18:59:20.000Z",
      "title": "1. Modelo de difusión en 1 paso: Coincidencia de distribuciones de f-Divergencia",
      "summary": "En los modelos de difusión, la muestración es una función útil que se realiza a través de un proceso largo y repetitivo, especialmente en aplicaciones interactivas donde su implementación es difícil. Para aumentar la velocidad de generación, los métodos recientes extraen a los modelos de difusión multi-paso como generadores de paso único bajo un escore no-neural, y ajustan la distribución de los muestras generadas por los estudiantes para que coincida con la distribución guía, lo que acelera la velocidad de generación. Sin embargo, estos métodos se conocen por su uso de la divergencia de KL inversa para ajustar las distribuciones, pero esto es conocido como \"mode シーキング\". En este artículo, se propone un nuevo marco de trabajo de minimización de la divergencia f para generalizar el ajuste de las distribuciones y abordar diferentes tipos de divergencias, incluyendo la versión de \"mode カバー バージョン\" y la variabilidad de entrenamiento. Se calcula la pendiente de la divergencia f entre la distribución guía y el estudiante, lo cual se expresa como la multiplicación de una función de peso determinada por la diferencia de puntajes y la razón de densidad, mostrando cómo se prioriza naturalmente los muestras con una densidad alta en la distribución guía. El enfoque generalizado de la divergencia no-neural utilizando el escore no-neural es considerado un caso especial dentro de nuestro marco de trabajo. Experimentalmente, las divergencias f alternativas como la divergencia de KL hacia adelante y la divergencia de GENESIS-シャーニング superan actualmente el mejor método de escore no-neural, y en particular, el uso de la divergencia de GENESIS-シャーニング permite a f-distill alcanzar el mejor rendimiento de generación en un paso en ImageNet64 y mostrar excelentes resultados en la generación de imágenes a partir de texto sin supervisión en MS-COCO. Página del proyecto: https://research.nvidia.com/labs/genair/f-distill",
      "upvotes": 1,
      "discussionId": "67bbe6837727595ca5979e8c"
    },
    "publishedAt": "2025-02-23T22:24:55.500Z",
    "title": "One-step Diffusion Models with $f$-Divergence Distribution Matching",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.15681.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 6193
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.13189",
      "authors": [
        {
          "_id": "67b7152f299e4d30f9eb41c2",
          "name": "Enzhe Lu",
          "hidden": false
        },
        {
          "_id": "67b7152f299e4d30f9eb41c3",
          "name": "Zhejun Jiang",
          "hidden": false
        },
        {
          "_id": "67b7152f299e4d30f9eb41c4",
          "name": "Jingyuan Liu",
          "hidden": false
        },
        {
          "_id": "67b7152f299e4d30f9eb41c5",
          "name": "Yulun Du",
          "hidden": false
        },
        {
          "_id": "67b7152f299e4d30f9eb41c6",
          "name": "Tao Jiang",
          "hidden": false
        },
        {
          "_id": "67b7152f299e4d30f9eb41c7",
          "name": "Chao Hong",
          "hidden": false
        },
        {
          "_id": "67b7152f299e4d30f9eb41c8",
          "name": "Shaowei Liu",
          "hidden": false
        },
        {
          "_id": "67b7152f299e4d30f9eb41c9",
          "name": "Weiran He",
          "hidden": false
        },
        {
          "_id": "67b7152f299e4d30f9eb41ca",
          "name": "Enming Yuan",
          "hidden": false
        },
        {
          "_id": "67b7152f299e4d30f9eb41cb",
          "name": "Yuzhi Wang",
          "hidden": false
        },
        {
          "_id": "67b7152f299e4d30f9eb41cc",
          "name": "Zhiqi Huang",
          "hidden": false
        },
        {
          "_id": "67b7152f299e4d30f9eb41cd",
          "name": "Huan Yuan",
          "hidden": false
        },
        {
          "_id": "67b7152f299e4d30f9eb41ce",
          "name": "Suting Xu",
          "hidden": false
        },
        {
          "_id": "67b7152f299e4d30f9eb41cf",
          "name": "Xinran Xu",
          "hidden": false
        },
        {
          "_id": "67b7152f299e4d30f9eb41d0",
          "name": "Guokun Lai",
          "hidden": false
        },
        {
          "_id": "67b7152f299e4d30f9eb41d1",
          "name": "Yanru Chen",
          "hidden": false
        },
        {
          "_id": "67b7152f299e4d30f9eb41d2",
          "name": "Huabin Zheng",
          "hidden": false
        },
        {
          "_id": "67b7152f299e4d30f9eb41d3",
          "name": "Junjie Yan",
          "hidden": false
        },
        {
          "_id": "67b7152f299e4d30f9eb41d4",
          "name": "Jianlin Su",
          "hidden": false
        },
        {
          "_id": "67b7152f299e4d30f9eb41d5",
          "name": "Yuxin Wu",
          "hidden": false
        },
        {
          "_id": "67b7152f299e4d30f9eb41d6",
          "name": "Neo Y. Zhang",
          "hidden": false
        },
        {
          "_id": "67b7152f299e4d30f9eb41d7",
          "name": "Zhilin Yang",
          "hidden": false
        },
        {
          "_id": "67b7152f299e4d30f9eb41d8",
          "name": "Xinyu Zhou",
          "hidden": false
        },
        {
          "_id": "67b7152f299e4d30f9eb41d9",
          "name": "Mingxing Zhang",
          "hidden": false
        },
        {
          "_id": "67b7152f299e4d30f9eb41da",
          "name": "Jiezhong Qiu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-18T14:06:05.000Z",
      "title": "MoBA: Mixtura de Atracción de Bloque en LLMs de Contexto Largo",
      "summary": "El efectivo tamaño de contexto en escalas de modelos de lenguaje grandes (LLMs) es crucial para promover su desarrollo hacia un inteligencia artificial general (AGI). Sin embargo, el aumento cuadrático de la complejidad computacional en estructuras de acción simples impone una carga significativa. Los métodos actuales aplican estructuras específicas a tareas particulares (por ejemplo, attention de ventana o sink) o deforman la estructura de acción para una aproximación lineal, pero no se han investigado su efectos suficientemente en tareas de inferencia compleja.\n\nEn este artículo, se propone una solución basada en el principio de \"minimizar la estructura\", centrandose en que el modelo determine automáticamente la posición de las acciones y evitando la introducción de sesgos predefinidos. Se introduce el Block Attention Mixture (MoBA), proponiendo una nueva aproximación que aplica los principios de Expertos Mixture (MoE) a la estructura de acción. Esta nueva arquitectura muestra un alto rendimiento en tareas de contexto largo, permite una transición adecuada entre atención total y atención esparsa, y mejora la eficiencia sin aumentar el riesgo de degradar el rendimiento. MoBA ya soporta solicitudes de contexto largo en Kimi y ha demostrado significativos avances en la cálculo eficiente de acciones en LLMs. El código está disponible en https://github.com/MoonshotAI/MoBA.",
      "upvotes": 0,
      "discussionId": "67b71530299e4d30f9eb4213"
    },
    "publishedAt": "2025-02-24T04:52:30.963Z",
    "title": "MoBA: Mixture of Block Attention for Long-Context LLMs",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13189.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "63a369d98c0c89dcae3b8329",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63a369d98c0c89dcae3b8329/6OUJ7Hc9T1jXynYH3FGaf.png",
      "fullname": "Adina Yakefu",
      "name": "AdinaY",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 420
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.13407",
      "authors": [
        {
          "_id": "67bb33f3829dedfc99ae1288",
          "user": {
            "_id": "67bb32b6a0cb6e48cfd27d80",
            "avatarUrl": "/avatars/3cafe3a3fb60405252962d00105667c5.svg",
            "isPro": false,
            "fullname": "Ziyuan Liu",
            "user": "circleLZY",
            "type": "user"
          },
          "name": "Ziyuan Liu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-24T09:07:29.223Z",
          "hidden": false
        },
        {
          "_id": "67bb33f3829dedfc99ae1289",
          "name": "Ruifei Zhu",
          "hidden": false
        },
        {
          "_id": "67bb33f3829dedfc99ae128a",
          "name": "Long Gao",
          "hidden": false
        },
        {
          "_id": "67bb33f3829dedfc99ae128b",
          "name": "Yuanxiu Zhou",
          "hidden": false
        },
        {
          "_id": "67bb33f3829dedfc99ae128c",
          "name": "Jingyu Ma",
          "hidden": false
        },
        {
          "_id": "67bb33f3829dedfc99ae128d",
          "name": "Yuantao Gu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-19T03:33:54.000Z",
      "title": "JL1-CD: Nuevo Benchmark para la Detección de Cambios en Observaciones Remotas y un Fortalecido Framework de Filtrado de Conocimiento de Datos de Diferencias",
      "summary": "Deep learning ha sido exitosamente aplicado en el campo de detección de cambios (CD) en imágenes de observación remota, pero aún existen dos grandes problemas: la escasez de conjuntos de datos completos y abiertos de CD a pequeña escala, y la dificultad de lograr resultados satisfactorios de detección consistentes entre imágenes con áreas de cambio diferentes. Para abordar estos problemas, presentamos el conjunto de datos JL1-CD. Este conjunto incluye 5,000 pares de imágenes de 512×512 píxeles a una resolución de 0.5 a 0.75 metros. Además, proponemos un marco de trabajo de conocimiento de soporte multi-turner (MTKD) para CD. A través de los resultados de experimentos con el conjunto de datos JL1-CD y SYSU-CD, demostramos que el marco MTKD mejoró significativamente el rendimiento de modelos de CD con diferentes estructuras de red y tamaños de parámetros, obteniendo resultados líderes. El código está disponible en https://github.com/circleLZY/MTKD-CD.",
      "upvotes": 0,
      "discussionId": "67bb33f6829dedfc99ae135e"
    },
    "publishedAt": "2025-02-24T04:29:42.452Z",
    "title": "JL1-CD: A New Benchmark for Remote Sensing Change Detection and a Robust Multi-Teacher Knowledge Distillation Framework",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13407.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "67bb32b6a0cb6e48cfd27d80",
      "avatarUrl": "/avatars/3cafe3a3fb60405252962d00105667c5.svg",
      "fullname": "Ziyuan Liu",
      "name": "circleLZY",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.15011",
      "authors": [
        {
          "_id": "67bc0d12ffc2c387329c8cfd",
          "user": {
            "_id": "650ec19e6620b0c57e2a551b",
            "avatarUrl": "/avatars/c26c03fa920d857120f03c9ccb9f1d7a.svg",
            "isPro": false,
            "fullname": "Sayan Deb Sarkar",
            "user": "sayandsarkar",
            "type": "user"
          },
          "name": "Sayan Deb Sarkar",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-24T09:06:56.555Z",
          "hidden": false
        },
        {
          "_id": "67bc0d12ffc2c387329c8cfe",
          "name": "Ondrej Miksik",
          "hidden": false
        },
        {
          "_id": "67bc0d12ffc2c387329c8cff",
          "name": "Marc Pollefeys",
          "hidden": false
        },
        {
          "_id": "67bc0d12ffc2c387329c8d00",
          "name": "Daniel Barath",
          "hidden": false
        },
        {
          "_id": "67bc0d12ffc2c387329c8d01",
          "name": "Iro Armeni",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-20T20:05:30.000Z",
      "title": "CrossOver: Simulación 3D Cruzada de Alineamiento",
      "summary": "Damodal 3D objeto comprensión recibe una atención importante pero, los métodos actuales asumen la utilización completa de los datos y la ajuste rígido de todas las modalidades. Presento un nuevo marco de trabajo llamado CrossOver. Este marco de trabajo realiza la comprensión de escenas 3D cruzadas mediante ajustes de modalidades flexibles a nivel de escena. A diferencia de los métodos existentes, CrossOver aprende espacios de dispersión modalmente indiferentes en escenas continuas de modalidades mediante una aprendizaje continuo de modalidades, sin necesidad de ajustar datos modales ajustados para todas las instancias de objetos. Se entrena aprendiendo con imágenes RGB, conjuntos de puntos, modelos CAD, planos de piso y descripciones textuales, y conociendo restricciones estrictas y evitando la inclusión explícita de significado de objetos. Utilizando codificadores específicos por dimensiones, un flujo de trabajo de entrenamiento multietapa y acciones cruzadas de modalidades, CrossOver proporciona búsquedas de escenas fuertes y especificación de ubicación de objetos incluso cuando la información modal es insuficiente. En evaluaciones con los conjuntos de datos ScanNet y 3RScan, muestra un desempeño superior en diferentes métricas, destacando la adaptabilidad de la comprensión de escenas 3D en aplicaciones reales.",
      "upvotes": 0,
      "discussionId": "67bc0d18ffc2c387329c8e56"
    },
    "publishedAt": "2025-02-24T01:13:24.911Z",
    "title": "CrossOver: 3D Scene Cross-Modal Alignment",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/650ec19e6620b0c57e2a551b/S_xFBPoV3YbtHmtLtRrSV.gif"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.15011.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "650ec19e6620b0c57e2a551b",
      "avatarUrl": "/avatars/c26c03fa920d857120f03c9ccb9f1d7a.svg",
      "fullname": "Sayan Deb Sarkar",
      "name": "sayandsarkar",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.15082",
      "authors": [
        {
          "_id": "67bbe93f267aa2b537b318be",
          "user": {
            "_id": "64f64da90efa33bfe0a3d9ba",
            "avatarUrl": "/avatars/c45fb015433e46a2eeb9518910f75d35.svg",
            "isPro": false,
            "fullname": "Vaidehi Patil",
            "user": "vaidehi99",
            "type": "user"
          },
          "name": "Vaidehi Patil",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-24T09:07:15.794Z",
          "hidden": false
        },
        {
          "_id": "67bbe93f267aa2b537b318bf",
          "name": "Elias Stengel-Eskin",
          "hidden": false
        },
        {
          "_id": "67bbe93f267aa2b537b318c0",
          "name": "Mohit Bansal",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-20T22:51:10.000Z",
      "title": "UPCORE: Equilibrado sin aprendizaje mediante el selección de un conjunto de núcleos de conservación de utilidad",
      "summary": "Ustedes pueden eliminar información de un modelo de recuperación de datos según las exigencias específicas de los usuarios o las estructuras legales. En este caso, es necesario eliminar puntos de datos específicos de un modelo ya entrenado o \"olvidarlos\". Esta operación puede afectar el rendimiento del modelo en otros puntos de datos, por lo que es importante encontrar un equilibrio entre la eliminación de información y la preservación de otras capacidades del modelo. Si este equilibrio no se logra, puede llevar a la pérdida del modelo o a su inutilidad. Desde esta perspectiva, proponemos UPCORE (Selección de Conjuntos de Núcleo para Preservar la Utilidad), un marco de selección de datos que minimiza los pérdidos que ocurren al \"olvidar\" datos. La daño al modelo está relacionado con la varianza de la representación del modelo en el conjunto de datos a \"olvidar\", y el objetivo es proponer conjuntos de datos de manera selectiva para minimizar el daño al modelo después de \"olvidar\" datos. UPCORE supera el objetivo de equilibrio entre la eficacia de la eliminación y la preservación del modelo mediante tres métodos estándar de \"olvidar\" datos. Para mejorar la evaluación de estas transacciones, introducimos nuevas métricas y midimos el área bajo la curva (AUC) de las métricas estándar. UPCORE mejora tanto las métricas estándar como el AUC, obtiene una transición positiva entre los puntos del conjunto de datos y los puntos propuestos, y reduce la transición negativa hacia los puntos no propuestos en el conjunto de datos a \"olvidar\".",
      "upvotes": 0,
      "discussionId": "67bbe940267aa2b537b318f4"
    },
    "publishedAt": "2025-02-23T23:17:33.152Z",
    "title": "UPCORE: Utility-Preserving Coreset Selection for Balanced Unlearning",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.15082.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64f64da90efa33bfe0a3d9ba",
      "avatarUrl": "/avatars/c45fb015433e46a2eeb9518910f75d35.svg",
      "fullname": "Vaidehi Patil",
      "name": "vaidehi99",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  }
]