[
  {
    "paper": {
      "id": "2502.18934",
      "authors": [
        {
          "_id": "67bfe1bf4426925c82fe5953",
          "name": "Kanana LLM Team",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe5954",
          "name": "Yunju Bak",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe5955",
          "name": "Hojin Lee",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe5956",
          "user": {
            "_id": "60436d159e905013ae8715d7",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1623809612769-60436d159e905013ae8715d7.jpeg",
            "isPro": false,
            "fullname": "Minho Ryu",
            "user": "bzantium",
            "type": "user"
          },
          "name": "Minho Ryu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-27T09:14:17.979Z",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe5957",
          "user": {
            "_id": "66ebb4fdc5b2c25450fd17de",
            "avatarUrl": "/avatars/e6b40dcbe2eba838ba21be9221758a3c.svg",
            "isPro": false,
            "fullname": "Jiyeon Ham",
            "user": "jiyeonham",
            "type": "user"
          },
          "name": "Jiyeon Ham",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-27T09:14:11.786Z",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe5958",
          "name": "Seungjae Jung",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe5959",
          "user": {
            "_id": "66c82a50c1b3c03c61aea140",
            "avatarUrl": "/avatars/3c508f96bdca2f2ce9746d3decd4718e.svg",
            "isPro": false,
            "fullname": "daniel nam",
            "user": "daniel-rl2",
            "type": "user"
          },
          "name": "Daniel Wontae Nam",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-27T09:14:09.613Z",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe595a",
          "name": "Taegyeong Eo",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe595b",
          "name": "Donghun Lee",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe595c",
          "user": {
            "_id": "6142e17fe9e656d4459121e4",
            "avatarUrl": "/avatars/6baebd4598a845ec7fdb735eb0d53139.svg",
            "isPro": false,
            "fullname": "Doohae Jung",
            "user": "Doohae",
            "type": "user"
          },
          "name": "Doohae Jung",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-27T09:14:06.858Z",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe595d",
          "user": {
            "_id": "60f559be68ee3ef098e407cf",
            "avatarUrl": "/avatars/e1f00ff1c1c9fa7f591535d39c7d5e44.svg",
            "isPro": false,
            "fullname": "Boseop Kim",
            "user": "seopbo",
            "type": "user"
          },
          "name": "Boseop Kim",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-27T09:14:01.989Z",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe595e",
          "user": {
            "_id": "6605028007a154c768e1c4c7",
            "avatarUrl": "/avatars/88678edb83fdb466067e38acd22d07de.svg",
            "isPro": false,
            "fullname": "Nayeon Kim",
            "user": "lana-ny",
            "type": "user"
          },
          "name": "Nayeon Kim",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-27T09:14:13.867Z",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe595f",
          "user": {
            "_id": "6136f65440e43b8f748a0833",
            "avatarUrl": "/avatars/f72a5ae3d3e94485de8aed8df94abdad.svg",
            "isPro": false,
            "fullname": "Jaesun Park",
            "user": "jaesun",
            "type": "user"
          },
          "name": "Jaesun Park",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-27T09:14:15.898Z",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe5960",
          "name": "Hyunho Kim",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe5961",
          "name": "Hyunwoong Ko",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe5962",
          "user": {
            "_id": "63d268bb57ab367124ea7b75",
            "avatarUrl": "/avatars/11312cde1e9f077aa9e5103b48be5de6.svg",
            "isPro": false,
            "fullname": "Changmin Lee",
            "user": "changminlee",
            "type": "user"
          },
          "name": "Changmin Lee",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-27T09:14:04.506Z",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe5963",
          "name": "Kyoung-Woon On",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe5964",
          "name": "Seulye Baeg",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe5965",
          "name": "Junrae Cho",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe5966",
          "name": "Sunghee Jung",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe5967",
          "name": "Jieun Kang",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe5968",
          "name": "EungGyun Kim",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe5969",
          "name": "Eunhwa Kim",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe596a",
          "name": "Byeongil Ko",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe596b",
          "name": "Daniel Lee",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe596c",
          "name": "Minchul Lee",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe596d",
          "name": "Miok Lee",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe596e",
          "name": "Shinbok Lee",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe596f",
          "name": "Gaeun Seo",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-26T08:36:20.000Z",
      "title": "Kanana: Modelo de lenguaje de programación bilingüe eficiente en cálculos",
      "summary": "Kanana, una serie de modelos de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lenguaje de lengua",
      "upvotes": 39,
      "discussionId": "67bfe1c04426925c82fe59a1"
    },
    "publishedAt": "2025-02-26T23:05:13.440Z",
    "title": "Kanana: Compute-efficient Bilingual Language Models",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.18934.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60436d159e905013ae8715d7",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1623809612769-60436d159e905013ae8715d7.jpeg",
      "fullname": "Minho Ryu",
      "name": "bzantium",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 5
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.19400",
      "authors": [
        {
          "_id": "67bfd6f15db054ee3c5a766b",
          "user": {
            "_id": "631d760344503b7227837242",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/631d760344503b7227837242/3b6JRusFX6GKJpsN9ZdeJ.png",
            "isPro": false,
            "fullname": "Max Ku",
            "user": "vinesmsuic",
            "type": "user"
          },
          "name": "Max Ku",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-27T09:14:55.238Z",
          "hidden": false
        },
        {
          "_id": "67bfd6f15db054ee3c5a766c",
          "user": {
            "_id": "6365d5baa7a1324ccd5ecdb9",
            "avatarUrl": "/avatars/636d3f410b878e451a878a6cf171dd53.svg",
            "isPro": false,
            "fullname": "Thomas Chong",
            "user": "chongcht",
            "type": "user"
          },
          "name": "Thomas Chong",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-27T09:14:49.567Z",
          "hidden": false
        },
        {
          "_id": "67bfd6f15db054ee3c5a766d",
          "name": "Jonathan Leung",
          "hidden": false
        },
        {
          "_id": "67bfd6f15db054ee3c5a766e",
          "user": {
            "_id": "67bfdfdbf856fd8ddbb7e0f0",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/rIR0QnVM3wxMCulG2R9SJ.png",
            "isPro": false,
            "fullname": "Krish Shah",
            "user": "KrishKrosh",
            "type": "user"
          },
          "name": "Krish Shah",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-27T09:14:47.269Z",
          "hidden": false
        },
        {
          "_id": "67bfd6f15db054ee3c5a766f",
          "user": {
            "_id": "6696061aa8dbb9a9997dfff6",
            "avatarUrl": "/avatars/d8f0bbff362fd630e6e60aab141076d3.svg",
            "isPro": false,
            "fullname": "Alvin Yu",
            "user": "AlvinYuVotee",
            "type": "user"
          },
          "name": "Alvin Yu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-27T09:14:52.146Z",
          "hidden": false
        },
        {
          "_id": "67bfd6f15db054ee3c5a7670",
          "name": "Wenhu Chen",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-26T18:50:09.000Z",
      "title": "TheoremExplainAgent: Investigación sobre explicaciones multimodales para la comprensión de teoremas de LLM",
      "summary": "La comprensión de la organización en áreas específicas no es suficiente solo basándose en razones contextuales, sino que una visión estructurada y visualizada es esencial para una comunicación efectiva que requiere una profundidad de entendimiento. Los modelos de lenguaje grande escala (LLMs) muestran un excelente rendimiento en la justificación de la organización basada en contexto, pero su capacidad para generar explicaciones visualizadas colaborativas y educativamente significativas es un desafío abierto. En este estudio, se presenta el TheoremExplainAgent, un agente utilizando Manim para crear videos de explicación de teoremas de larga duración (más de 5 minutos). Para evaluar la multifuncionalidad, se propone el TheoremExplainBench, un conjunto de 240 teoremas de diversas áreas STEM, y se aplican 5 criterios de evaluación automática. Los resultados confirman claramente la importancia de la planificación de los agentes para la creación de videos efectivos, y el agente o3-mini alcanzó un rendimiento del 93.8% y una puntuación general de 0.77. Sin embargo, estudios cualitativos y cuantitativos revelan que muchos de los videos generados presentan ligeras inconsistencias en la secuencia de elementos visualizados. Además, las explicaciones multifuncionales revelan claramente las falencias ocultas en las explicaciones basadas en contexto, resaltando la importancia de las explicaciones multifuncionales.",
      "upvotes": 17,
      "discussionId": "67bfd6f25db054ee3c5a7699"
    },
    "publishedAt": "2025-02-26T22:07:49.438Z",
    "title": "TheoremExplainAgent: Towards Multimodal Explanations for LLM Theorem Understanding",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.19400.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 6232
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.19361",
      "authors": [
        {
          "_id": "67bfe435ca6e3c22b6e29442",
          "name": "Yancheng He",
          "hidden": false
        },
        {
          "_id": "67bfe435ca6e3c22b6e29443",
          "name": "Shilong Li",
          "hidden": false
        },
        {
          "_id": "67bfe435ca6e3c22b6e29444",
          "name": "Jiaheng Liu",
          "hidden": false
        },
        {
          "_id": "67bfe435ca6e3c22b6e29445",
          "name": "Weixun Wang",
          "hidden": false
        },
        {
          "_id": "67bfe435ca6e3c22b6e29446",
          "name": "Xingyuan Bu",
          "hidden": false
        },
        {
          "_id": "67bfe435ca6e3c22b6e29447",
          "user": {
            "_id": "638efcf4c67af472d316d424",
            "avatarUrl": "/avatars/97a57859d7d87a3a8f1bb41d32a72bc2.svg",
            "isPro": false,
            "fullname": "Ge Zhang",
            "user": "zhangysk",
            "type": "user"
          },
          "name": "Ge Zhang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-27T09:13:58.959Z",
          "hidden": false
        },
        {
          "_id": "67bfe435ca6e3c22b6e29448",
          "name": "Zhongyuan Peng",
          "hidden": false
        },
        {
          "_id": "67bfe435ca6e3c22b6e29449",
          "name": "Zhaoxiang Zhang",
          "hidden": false
        },
        {
          "_id": "67bfe435ca6e3c22b6e2944a",
          "name": "Wenbo Su",
          "hidden": false
        },
        {
          "_id": "67bfe435ca6e3c22b6e2944b",
          "name": "Bo Zheng",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-26T17:59:27.000Z",
      "title": "¿Los grandes modelos de lenguaje detectan errores en la cadena de pensamiento de largo contexto?",
      "summary": "Recientemente, modelos similares a o1 están recibiendo atención. Estos modelos generan largos Chain-of-Thought (CoT) para mejorar la capacidad de inferencia de los actuales Large Language Models (LLMs). En este estudio, se utiliza DeltaBench para comprender la calidad de estos largos CoT y para evaluar la capacidad de los actuales LLMs para medir estos largos CoT. DeltaBench incluye CoT generados por diferentes modelos similares a o1, como QwQ y DeepSeek-R1, y se utiliza en tareas de inferencia variadas, como matemáticas, código y generales. Esto permite medir la capacidad de detección de errores en la inferencia larga CoT. Basándose en DeltaBench, primero, se realiza un análisis detallado de los largos CoT generados para descubrir la eficacia y eficiencia de cada modelo similar a o1. Segundo, se realiza una evaluación extendida de los actuales Process Reward Models (PRMs) y modelos de evaluación para investigar los límites y limitaciones de cada PRM y modelo de evaluación en la detección de errores en cada inferencia. Finalmente, DeltaBench ayuda a los desarrolladores a comprender mejor la capacidad de inferencia larga de los modelos, tanto para entenderlas mejor como para mejorar sus capacidades de inferencia larga.",
      "upvotes": 12,
      "discussionId": "67bfe438ca6e3c22b6e2948e"
    },
    "publishedAt": "2025-02-26T23:04:47.406Z",
    "title": "Can Large Language Models Detect Errors in Long Chain-of-Thought Reasoning?",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.19361.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "65377c30e48353201e6fdda0",
      "avatarUrl": "/avatars/a8f803b6f2e598eaee9c52c0d2ddfc16.svg",
      "fullname": "Jiaheng Liu",
      "name": "CheeryLJH",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 7
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.19328",
      "authors": [
        {
          "_id": "67bfcb774d22a9379b29334c",
          "name": "Hao Peng",
          "hidden": false
        },
        {
          "_id": "67bfcb774d22a9379b29334d",
          "name": "Yunjia Qi",
          "hidden": false
        },
        {
          "_id": "67bfcb774d22a9379b29334e",
          "name": "Xiaozhi Wang",
          "hidden": false
        },
        {
          "_id": "67bfcb774d22a9379b29334f",
          "name": "Zijun Yao",
          "hidden": false
        },
        {
          "_id": "67bfcb774d22a9379b293350",
          "name": "Bin Xu",
          "hidden": false
        },
        {
          "_id": "67bfcb774d22a9379b293351",
          "name": "Lei Hou",
          "hidden": false
        },
        {
          "_id": "67bfcb774d22a9379b293352",
          "name": "Juanzi Li",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-26T17:19:12.000Z",
      "title": "Agentic Reward Modeling: Modelo de Recompensas Confiables que Integra Preferencias Humanas y Señales de Verificación Precisas",
      "summary": "Los módulos de recompensa (RMs) desempeñan un papel crucial en la escalabilidad de la entrenamiento y la inferencia de módulos de lenguaje de gran escala (LLMs). Sin embargo, los módulos de recompensa actuales se centran principalmente en las preferencias humanas, ignorando las señales de precisión verificable y considerando que el potencial de los LLMs en su entrenamiento es demasiado antiguo. En este artículo, proponemos un modelo de recompensa basado en señales de precisión verificable. Este sistema de recompensa combina señales de precisión verificable y módulos de recompensa para proporcionar una recompensa confiable. Experimentalmente, implementamos un agente de recompensa (\"RewardAgent\") que combina dos señales de recompensa verificables: una basada en las preferencias humanas y otra basada en la realidad y las instrucciones. \"RewardAgent\" se centra en proporcionar una recompensa confiable. Se realizaron experimentos con el benchmark actual de módulos de recompensa y en la mejor de n en tareas de inferencia reales. \"RewardAgent\" demostró ser significativamente superior a los módulos de recompensa actuales. Además, utilizando \"RewardAgent\" para construir parejas de preferencias de entrenamiento y entrenar un LLM con el objetivo de DPO, se logró mejorar significativamente en diferentes marcos de referencia de NLP en comparación con los módulos de recompensa tradicionales. Nuestro código está disponible y ofrece flexibilidad para investigaciones avanzadas (https://github.com/THU-KEG/Agentic-Reward-Modeling).",
      "upvotes": 11,
      "discussionId": "67bfcb784d22a9379b29338f"
    },
    "publishedAt": "2025-02-26T22:05:16.150Z",
    "title": "Agentic Reward Modeling: Integrating Human Preferences with Verifiable Correctness Signals for Reliable Reward Systems",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.19328.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "625a5446f1063e7085d5178a",
      "avatarUrl": "/avatars/5e78186f13f74b14e01583e06ff6c4dc.svg",
      "fullname": "Hao Peng",
      "name": "Wesleythu",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.17955",
      "authors": [
        {
          "_id": "67bff526ca6e3c22b6e89d71",
          "user": {
            "_id": "65d2f1e0fe21569868393411",
            "avatarUrl": "/avatars/1401020e76d958bef3f33e7449773694.svg",
            "isPro": false,
            "fullname": "Tushar Aggarwal",
            "user": "AggarwalTushar",
            "type": "user"
          },
          "name": "Tushar Aggarwal",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-02-27T05:16:24.257Z",
          "hidden": false
        },
        {
          "_id": "67bff526ca6e3c22b6e89d72",
          "name": "Kumar Tanmay",
          "hidden": false
        },
        {
          "_id": "67bff526ca6e3c22b6e89d73",
          "user": {
            "_id": "61a7cbb0fcbbebe775bf17fd",
            "avatarUrl": "/avatars/8b54907c6a1ea90a1242f26e03e117af.svg",
            "isPro": false,
            "fullname": "Ayush Agrawal",
            "user": "ayush1801",
            "type": "user"
          },
          "name": "Ayush Agrawal",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-27T09:13:56.625Z",
          "hidden": false
        },
        {
          "_id": "67bff526ca6e3c22b6e89d74",
          "name": "Kumar Ayush",
          "hidden": false
        },
        {
          "_id": "67bff526ca6e3c22b6e89d75",
          "name": "Hamid Palangi",
          "hidden": false
        },
        {
          "_id": "67bff526ca6e3c22b6e89d76",
          "name": "Paul Pu Liang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-25T08:27:18.000Z",
      "title": "La verdad de un modelo de lenguaje depende del idioma de la pregunta.",
      "summary": "Los modelos de lenguaje multilingües (LMs) esperan que se recuerden con coherencia conocimientos factuales en varios idiomas, pero pueden fallar en la transferencia de estos conocimientos si se trata de información precisa en cada idioma. Por ejemplo, un LM puede reconocer con precisión que Rashed Al Shashai es el lugar de nacimiento del Tercero de Mayo en una pregunta en árabe, pero es más difícil que el mismo conozca esta información con exactitud cuando se le pregunta en inglés o en swahili. Para investigar estos límites sistemáticamente, se propone un marco de referencia basado en 10,000 hechos de relaciones internacionales en 13 idiomas, así como escores de memoria factual, movilidad de conocimiento y movilidad de conocimiento de conocimiento contextualizado. Estos escores se utilizan para cuantificar la memoria factual y la movilidad de conocimiento entre diferentes idiomas en los LMs. Nuestros resultados revelan las principales limitaciones básicas de los LMs más avanzados actuales, en particular, la baja movilidad de conocimiento entre diferentes idiomas, lo que indica una incertidumbre en el rendimiento dependiente del idioma. Nuestros hallazgos subrayan la necesidad de que los LMs reconozcan la confianza en los hechos idiomáticos y utilicen la información más confiable en diferentes idiomas. Publicamos nuestro marco de referencia y framework de evaluación, con el objetivo de promover futuras investigaciones sobre la movilidad de conocimiento multilingüe.",
      "upvotes": 9,
      "discussionId": "67bff528ca6e3c22b6e89ddd"
    },
    "publishedAt": "2025-02-27T00:17:58.262Z",
    "title": "Language Models' Factuality Depends on the Language of Inquiry",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.17955.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "65d2f1e0fe21569868393411",
      "avatarUrl": "/avatars/1401020e76d958bef3f33e7449773694.svg",
      "fullname": "Tushar Aggarwal",
      "name": "AggarwalTushar",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.18864",
      "authors": [
        {
          "_id": "67bfd957c2a9b64ab3f97aa7",
          "name": "Juraj Gottweis",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97aa8",
          "name": "Wei-Hung Weng",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97aa9",
          "name": "Alexander Daryin",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97aaa",
          "name": "Tao Tu",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97aab",
          "name": "Anil Palepu",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97aac",
          "name": "Petar Sirkovic",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97aad",
          "name": "Artiom Myaskovsky",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97aae",
          "name": "Felix Weissenberger",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97aaf",
          "name": "Keran Rong",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ab0",
          "name": "Ryutaro Tanno",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ab1",
          "name": "Khaled Saab",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ab2",
          "name": "Dan Popovici",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ab3",
          "name": "Jacob Blum",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ab4",
          "name": "Fan Zhang",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ab5",
          "name": "Katherine Chou",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ab6",
          "name": "Avinatan Hassidim",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ab7",
          "name": "Burak Gokturk",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ab8",
          "name": "Amin Vahdat",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ab9",
          "name": "Pushmeet Kohli",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97aba",
          "name": "Yossi Matias",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97abb",
          "name": "Andrew Carroll",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97abc",
          "name": "Kavita Kulkarni",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97abd",
          "name": "Nenad Tomasev",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97abe",
          "name": "Yuan Guan",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97abf",
          "name": "Vikram Dhillon",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ac0",
          "name": "Eeshit Dhaval Vaishnav",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ac1",
          "name": "Byron Lee",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ac2",
          "name": "Tiago R D Costa",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ac3",
          "name": "José R Penadés",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ac4",
          "name": "Gary Peltz",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ac5",
          "name": "Yunhan Xu",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ac6",
          "name": "Annalisa Pawlosky",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ac7",
          "name": "Alan Karthikesalingam",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ac8",
          "name": "Vivek Natarajan",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-26T06:17:13.000Z",
      "title": "Nos enfocamos en la colaboración con la IA como objetivo.",
      "summary": "La descubrimiento científico se realiza a través de la generación de nuevas hipótesis por científicos y su rigurosa validación experimental. Para apoyar este proceso, presentamos el AI Cosine Intelligence, un sistema de inteligencia artificial basado en un multi-agente sistema construido en el Orca Mini 2.0. El AI Cosine Intelligence tiene como objetivo descubrir nuevos y existentes conocimientos y proponer nuevas hipótesis de investigación basadas en evidencias existentes y guiadas por los objetivos y guías proporcionados por los científicos. El diseño del sistema se inspira en los métodos científicos, adoptando una aproximación que acelera la escala de cálculos y una metodología para la generación, lógica y evolución de las hipótesis. Los principales contribuidores son: \n\n1. Una arquitectura multi-agente que permite la ejecución de tareas no sincrónicas, facilitando la escalabilidad efectiva de los cálculos necesarios para la generación de hipótesis.\n2. Un proceso de evolución de torneo para la generación de hipótesis que se auto-mejora.\n\nLa evaluación automática muestra un beneficio continuo en términos de cálculos, mejorando la calidad de las hipótesis. Se utiliza en diversos campos, pero se centra en tres áreas biomédicas: la reciclaje de fármacos, la detección de nuevos objetivos, y la evolución y resistencia antimicrobiana de bacterias. En el reciclaje de fármacos, propone candidatos que muestran mutación en concentraciones clínicamente efectivas, especialmente en cáncer de médula ósea, demostrando una inhibición de la proliferación celular. En la detección de nuevos objetivos, se valida la nueva genética de un nuevo objetivo de cáncer de hígado propuesto por el AI Cosine Intelligence, confirmando su actividad antitumoral y la regeneración de células humanas. Finalmente, el AI Cosine Intelligence recreate resultados experimentales no publicados en paralelo con la evolución genética de bacterias mediante una técnica de cinemadiscabari. Estos resultados se registran en postes simultáneos detallados, pero demuestran su apoyo a la biomedicina y la descubrimiento científico, mostrando el comienzo de una nueva era de científicos basados en la inteligencia artificial.",
      "upvotes": 9,
      "discussionId": "67bfd958c2a9b64ab3f97afa"
    },
    "publishedAt": "2025-02-26T22:18:06.494Z",
    "title": "Towards an AI co-scientist",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.18864.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 6232
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.19414",
      "authors": [
        {
          "_id": "67c01587925b73feaf61ac41",
          "name": "Shiven Sinha",
          "hidden": false
        },
        {
          "_id": "67c01587925b73feaf61ac42",
          "name": "Shashwat Goel",
          "hidden": false
        },
        {
          "_id": "67c01587925b73feaf61ac43",
          "name": "Ponnurangam Kumaraguru",
          "hidden": false
        },
        {
          "_id": "67c01587925b73feaf61ac44",
          "name": "Jonas Geiping",
          "hidden": false
        },
        {
          "_id": "67c01587925b73feaf61ac45",
          "name": "Matthias Bethge",
          "hidden": false
        },
        {
          "_id": "67c01587925b73feaf61ac46",
          "name": "Ameya Prabhu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-26T18:58:13.000Z",
      "title": "¿El modelo de lenguaje puede crear falsos? Evaluación de inferencia algorítmica por ejemplo generación",
      "summary": "El interés en el descubrimiento científico de los modelos de lenguaje (LMs) está aumentando. La negación de hipótesis es un clave para el desarrollo científico, permitiendo que las afirmaciones se mejoren repetidamente con el paso del tiempo. Este proceso requiere gran esfuerzo de los investigadores y necesita lógica y creatividad. Sin embargo, los criterios actuales de evaluación de LMs se centran principalmente en la capacidad de generación de soluciones, y la evaluación de la capacidad contrario es insuficiente. Argumentamos la necesidad de desarrollar criterios de evaluación para la capacidad contrario. Específicamente, buscamos crear un algoritmo que resolva problemas, con un entorno de ejecución automático para evaluar el desempeño, conocido como \"counter engineering\". En particular, utilizamos REFUTE, un estándar de evaluación actualmente dinámico, que se ha desarrollado a partir de la experiencia de expertos que han logrado identificar exitosamente el counter engineering en competencias de programación que incluyen problemas recientes. Según nuestras análisis, el agente REFUTE, como OpenAI o3-mini (alto), es capaz de realizar el counter engineering en más de <9% de las soluciones negativas, aunque no recibe retroalimentación de ejecución de código. Sin embargo, su evaluación muestra su capacidad para resolver rápidamente estos problemas. Pedimos que se desarrolle la evaluación y el mejoramiento de la capacidad de los LMs para negar soluciones negativas, lo cual es crucial para la aceleración de la investigación y la mejora autocorrectiva de los modelos basada en razones reflexivas y confiables.",
      "upvotes": 8,
      "discussionId": "67c01588925b73feaf61ad2c"
    },
    "publishedAt": "2025-02-27T02:36:29.037Z",
    "title": "Can Language Models Falsify? Evaluating Algorithmic Reasoning with Counterexample Creation",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.19414.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6506832221ac448013f94995",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6506832221ac448013f94995/sVUI1JV4Dxan5l-MqNze4.jpeg",
      "fullname": "Shashwat Goel",
      "name": "shash42",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.18906",
      "authors": [
        {
          "_id": "67bfd5d2381f8fcb67e5ad36",
          "name": "Jiani Zheng",
          "hidden": false
        },
        {
          "_id": "67bfd5d2381f8fcb67e5ad37",
          "name": "Lu Wang",
          "hidden": false
        },
        {
          "_id": "67bfd5d2381f8fcb67e5ad38",
          "user": {
            "_id": "669dcf6200970c3b27aafa5d",
            "avatarUrl": "/avatars/bb9ed5ff86326fdaeb184c6b0e40f74f.svg",
            "isPro": false,
            "fullname": "kaikai yang",
            "user": "keanudicap",
            "type": "user"
          },
          "name": "Fangkai Yang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-27T09:14:57.452Z",
          "hidden": false
        },
        {
          "_id": "67bfd5d2381f8fcb67e5ad39",
          "user": {
            "_id": "654dbac9938fbf1e696be8aa",
            "avatarUrl": "/avatars/b3c4035c48169c1bfb04a439fce3499f.svg",
            "isPro": false,
            "fullname": "Chaoyun Zhang",
            "user": "vyokky",
            "type": "user"
          },
          "name": "Chaoyun Zhang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-27T09:14:59.653Z",
          "hidden": false
        },
        {
          "_id": "67bfd5d2381f8fcb67e5ad3a",
          "name": "Lingrui Mei",
          "hidden": false
        },
        {
          "_id": "67bfd5d2381f8fcb67e5ad3b",
          "name": "Wenjie Yin",
          "hidden": false
        },
        {
          "_id": "67bfd5d2381f8fcb67e5ad3c",
          "name": "Qingwei Lin",
          "hidden": false
        },
        {
          "_id": "67bfd5d2381f8fcb67e5ad3d",
          "name": "Dongmei Zhang",
          "hidden": false
        },
        {
          "_id": "67bfd5d2381f8fcb67e5ad3e",
          "name": "Saravan Rajmohan",
          "hidden": false
        },
        {
          "_id": "67bfd5d2381f8fcb67e5ad3f",
          "name": "Qi Zhang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-26T07:52:02.000Z",
      "title": "VEM: Exploración y modelado de entornos de valor para agentes de interfaz gráfica mediante entrenamiento sin entorno",
      "summary": "Los problemas importantes en el proceso de entrenamiento de modelos de lenguaje visual (VLMs) para interfaces gráficas (GUI) con aprendizaje reforzado (RL) se manifiestan claramente. El aprendizaje reforzado basado en el entorno requiere interacciones altamente costosas, mientras que los métodos sin entorno enfrentan desafíos en la transformación de distribución y la generalización de la recompensa. Proponemos un marco de trabajo de aprendizaje reforzado sin entorno utilizando modelos de entorno predecido (VEM). El VEM predecie directamente el valor de estado-acción a partir de datos off-line, estructurando una previsualización humanoide a través de las interacciones con la GUI. Esto evita la acumulación de errores y la necesidad de predicciones de estado futuro y retroalimentación del entorno, lo que mejora la robustez frente a cambios en la interfaz. El marco de trabajo opera en dos etapas: (1) predicción del VEM y evaluación del valor de acciones a largo plazo, y (2) utilización de los mensajes del VEM para guiar la búsqueda de políticas, facilitando la automatización de la GUI sin relación a la diseño. Mediante evaluaciones en el marco de referencia Android-in-the-Wild, el VEM logró el mejor rendimiento en entornos off-line y on-line, superando significativamente el límite de aprendizaje reforzado basado en el entorno y alcanzando un rendimiento comparable a los métodos basados en el entorno. Un punto clave es que el VEM puede alcanzar un rendimiento relativamente excelente en la evaluación de valor basada en la comprensión del significado, comparado con métodos entrenados en línea.",
      "upvotes": 5,
      "discussionId": "67bfd5d7381f8fcb67e5ae3d"
    },
    "publishedAt": "2025-02-26T22:02:50.690Z",
    "title": "VEM: Environment-Free Exploration for Training GUI Agent with Value Environment Model",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.18906.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "654dbac9938fbf1e696be8aa",
      "avatarUrl": "/avatars/b3c4035c48169c1bfb04a439fce3499f.svg",
      "fullname": "Chaoyun Zhang",
      "name": "vyokky",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.18772",
      "authors": [
        {
          "_id": "67bfc297ca6e3c22b6d99c78",
          "name": "Xueqing Peng",
          "hidden": false
        },
        {
          "_id": "67bfc297ca6e3c22b6d99c79",
          "name": "Triantafillos Papadopoulos",
          "hidden": false
        },
        {
          "_id": "67bfc297ca6e3c22b6d99c7a",
          "name": "Efstathia Soufleri",
          "hidden": false
        },
        {
          "_id": "67bfc297ca6e3c22b6d99c7b",
          "name": "Polydoros Giannouris",
          "hidden": false
        },
        {
          "_id": "67bfc297ca6e3c22b6d99c7c",
          "name": "Ruoyu Xiang",
          "hidden": false
        },
        {
          "_id": "67bfc297ca6e3c22b6d99c7d",
          "name": "Yan Wang",
          "hidden": false
        },
        {
          "_id": "67bfc297ca6e3c22b6d99c7e",
          "name": "Lingfei Qian",
          "hidden": false
        },
        {
          "_id": "67bfc297ca6e3c22b6d99c7f",
          "user": {
            "_id": "63b58ed5889aa6707f0bb0f4",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63b58ed5889aa6707f0bb0f4/znl74_aMswlV8VtHrfj3G.jpeg",
            "isPro": true,
            "fullname": "Jimin Huang",
            "user": "jiminHuang",
            "type": "user"
          },
          "name": "Jimin Huang",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-02-27T01:40:40.189Z",
          "hidden": false
        },
        {
          "_id": "67bfc297ca6e3c22b6d99c80",
          "name": "Qianqian Xie",
          "hidden": false
        },
        {
          "_id": "67bfc297ca6e3c22b6d99c81",
          "name": "Sophia Ananiadou",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-26T03:04:01.000Z",
      "title": "Pulls: Benchmark de Modelos de Lenguaje en Finanzas Griegas de la Autora Original",
      "summary": "Grecia desempeña un papel importante en la economía mundial, pero en el contexto financiero, modelos de lenguaje grandes de gran escala (LLMs) no se han investigado debido a la complejidad del griego y la escasez de datos específicos de su dominio. Se han identificado significativas diferencias en el rendimiento de los esfuerzos de procesamiento de lenguaje natural financiero (NLP) multilingüe, pero hasta ahora, no se ha desarrollado ningún benchmark profesional de finanzas griegas ni ningún LLM específico para este idioma. Para remediar esto, presentamos el primer benchmark de evaluación de finanzas griegas, Plutus-ben, y el primer LLM de financas griegas, Plutus-8B. Plutus-8B ha sido fine-tunado con datos únicos del griego. Plutus-ben procesa 5 tareas financieras fundamentales y promueve una evaluación sistemática y reproducible de los LLMs. Basándonos en estas tareas, proporcionamos tres nuevos conjuntos de datos de alta calidad de finanzas griegas, anotados con rigor por expertos nacionales, adicionando a dos recursos existentes. Según una evaluación completa de 22 LLMs, la NLP de finanzas griegas se enfrenta a desafíos debido a la complejidad lingüística, el uso de terminología específica y los errores en cálculos financieros. Estos hallazgos destacan las limitaciones de los transformers entre idiomas, la necesidad de conocimientos financieros para el aprendizaje del griego y los desafíos de aplicar un LLM de finanzas al griego. Publicamos Plutus-ben, Plutus-8B y todos los conjuntos de datos relacionados para promover investigación reproducible y el desarrollo de la NLP de finanzas griegas, así como fomentar la inclusión multilingüe en el sector financiero.",
      "upvotes": 4,
      "discussionId": "67bfc298ca6e3c22b6d99caa"
    },
    "publishedAt": "2025-02-27T00:08:09.082Z",
    "title": "Plutus: Benchmarking Large Language Models in Low-Resource Greek Finance",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.18772.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "63b58ed5889aa6707f0bb0f4",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63b58ed5889aa6707f0bb0f4/znl74_aMswlV8VtHrfj3G.jpeg",
      "fullname": "Jimin Huang",
      "name": "jiminHuang",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isMod": false,
      "followerCount": 14
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.16776",
      "authors": [
        {
          "_id": "67bfd8d546083445aacb4605",
          "name": "Zhexin Zhang",
          "hidden": false
        },
        {
          "_id": "67bfd8d546083445aacb4606",
          "name": "Leqi Lei",
          "hidden": false
        },
        {
          "_id": "67bfd8d546083445aacb4607",
          "name": "Junxiao Yang",
          "hidden": false
        },
        {
          "_id": "67bfd8d546083445aacb4608",
          "name": "Xijie Huang",
          "hidden": false
        },
        {
          "_id": "67bfd8d546083445aacb4609",
          "name": "Yida Lu",
          "hidden": false
        },
        {
          "_id": "67bfd8d546083445aacb460a",
          "name": "Shiyao Cui",
          "hidden": false
        },
        {
          "_id": "67bfd8d546083445aacb460b",
          "name": "Renmiao Chen",
          "hidden": false
        },
        {
          "_id": "67bfd8d546083445aacb460c",
          "name": "Qinglin Zhang",
          "hidden": false
        },
        {
          "_id": "67bfd8d546083445aacb460d",
          "name": "Xinyuan Wang",
          "hidden": false
        },
        {
          "_id": "67bfd8d546083445aacb460e",
          "name": "Hao Wang",
          "hidden": false
        },
        {
          "_id": "67bfd8d546083445aacb460f",
          "user": {
            "_id": "653f1ef4aabbf15fc76a259c",
            "avatarUrl": "/avatars/94e569999d913e961266394ea2875965.svg",
            "isPro": false,
            "fullname": "LLLeo Li",
            "user": "LLLeo612",
            "type": "user"
          },
          "name": "Hao Li",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-27T09:14:45.366Z",
          "hidden": false
        },
        {
          "_id": "67bfd8d546083445aacb4610",
          "name": "Xianqi Lei",
          "hidden": false
        },
        {
          "_id": "67bfd8d546083445aacb4611",
          "name": "Chengwei Pan",
          "hidden": false
        },
        {
          "_id": "67bfd8d546083445aacb4612",
          "name": "Lei Sha",
          "hidden": false
        },
        {
          "_id": "67bfd8d546083445aacb4613",
          "name": "Hongning Wang",
          "hidden": false
        },
        {
          "_id": "67bfd8d546083445aacb4614",
          "name": "Minlie Huang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-24T02:11:52.000Z",
      "title": "AI Seguridad: Marco Integrador de Evaluación y Mejora de la Seguridad de la IA",
      "summary": "El modelo de IA se está expandiendo diariamente a través de diferentes escaladores de realidad virtual, pero la garantía de su seguridad sigue siendo un problema importante que permanece sin resolver y que aún no ha sido suficientemente investigado. Se están haciendo grandes esfuerzos para mejorar la evaluación y seguridad de la IA, pero la falta de marcos de referencia estandarizados y un conjunto completo de herramientas está impidiendo significativamente el progreso en la investigación y la introducción práctica de los sistemas. Para resolver esto, se presenta el marco integrado y conjunto de herramientas llamado AISafetyLab. AISafetyLab integra los métodos de ataque, defensa y evaluación y está diseñado para que los desarrolladores puedan aplicar diferentes técnicas de manera intuitiva a través de una interfaz sencilla. Además, se está realizando un estudio experimental sobre Vicuna, analizando estrategias de ataque y defensa para proporcionar un rendimiento relativamente efectivo. AISafetyLab está disponible para uso público y se está dedicando a su mantenimiento y mejora continuo (https://github.com/thu-coai/AISafetyLab), lo que contribuye a fomentar el desarrollo y la investigación de la seguridad de la IA.",
      "upvotes": 4,
      "discussionId": "67bfd8d646083445aacb464f"
    },
    "publishedAt": "2025-02-26T22:16:03.582Z",
    "title": "AISafetyLab: A Comprehensive Framework for AI Safety Evaluation and Improvement",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.16776.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "61b58aa0d65058ce70beb98c",
      "avatarUrl": "/avatars/aefd9271b891abc6dd2ded1a30eebca4.svg",
      "fullname": "Zhexin Zhang",
      "name": "nonstopfor",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.19204",
      "authors": [
        {
          "_id": "67bfd735ca6e3c22b6de43c7",
          "name": "Xiankang He",
          "hidden": false
        },
        {
          "_id": "67bfd735ca6e3c22b6de43c8",
          "name": "Dongyan Guo",
          "hidden": false
        },
        {
          "_id": "67bfd735ca6e3c22b6de43c9",
          "name": "Hongji Li",
          "hidden": false
        },
        {
          "_id": "67bfd735ca6e3c22b6de43ca",
          "name": "Ruibo Li",
          "hidden": false
        },
        {
          "_id": "67bfd735ca6e3c22b6de43cb",
          "name": "Ying Cui",
          "hidden": false
        },
        {
          "_id": "67bfd735ca6e3c22b6de43cc",
          "name": "Chi Zhang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-26T15:10:05.000Z",
      "title": "¿Cualquier profundidad de resultados puede obtenerse: los diseñadores también pueden crear potentes estimadores de profundidad monorales.",
      "summary": "MDE tiene como objetivo predecir la profundidad del escencio en imágenes RGB y juega un papel importante en la comprensión tridimensional del escencio. El desarrollo reciente de MDE 0-shot ha mejorado la capacidad de generalización para diferentes escencios utilizando representaciones de profundidad normalizadas y resultados basados en aprendizaje. Sin embargo, el método actual de normalización de profundidad utiliza una normalización global, lo que amplifica el ruido y limita la efectividad de la colección de resultados. En este artículo, se analiza de manera sistemática el impacto de diferentes estrategias de normalización de profundidad. Basándose en estos resultados, se propone la Cross-Context Distillation, que integra códigos de profundidad globales e locales para mejorar la calidad de los etiquetadores de rendimiento. Además, se introduce un marco para recopilar resultados de detección múltiple de objetos utilizando las ventajas de interpolación. De esta manera, la predicción de profundidad se hace más fuerte y precisa. A través de experimentos ampliados en conjuntos de datos estándar, se muestra que nuestro enfoque es significativamente superior en términos estadísticos y de calidad a los métodos actuales.",
      "upvotes": 4,
      "discussionId": "67bfd736ca6e3c22b6de441e"
    },
    "publishedAt": "2025-02-26T22:10:20.646Z",
    "title": "Distill Any Depth: Distillation Creates a Stronger Monocular Depth Estimator",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/64196320ed725fef64419c2a/k13rSuJPlDkMtzwdHXCXm.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.19204.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64196320ed725fef64419c2a",
      "avatarUrl": "/avatars/96feb22fb5e8931d6c9e0ea06148266f.svg",
      "fullname": "Chi Zhang",
      "name": "DrChiZhang",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 3
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.19279",
      "authors": [
        {
          "_id": "67bffaca3f838c1e33e074e7",
          "user": {
            "_id": "638ef0b0c67af472d31674a6",
            "avatarUrl": "/avatars/02df97d15a0f46b47f9162221733b121.svg",
            "isPro": false,
            "fullname": "Honglin Guo",
            "user": "KYLN24",
            "type": "user"
          },
          "name": "Honglin Guo",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-27T09:13:52.094Z",
          "hidden": false
        },
        {
          "_id": "67bffaca3f838c1e33e074e8",
          "name": "Kai Lv",
          "hidden": false
        },
        {
          "_id": "67bffaca3f838c1e33e074e9",
          "name": "Qipeng Guo",
          "hidden": false
        },
        {
          "_id": "67bffaca3f838c1e33e074ea",
          "name": "Tianyi Liang",
          "hidden": false
        },
        {
          "_id": "67bffaca3f838c1e33e074eb",
          "name": "Zhiheng Xi",
          "hidden": false
        },
        {
          "_id": "67bffaca3f838c1e33e074ec",
          "name": "Demin Song",
          "hidden": false
        },
        {
          "_id": "67bffaca3f838c1e33e074ed",
          "name": "Qiuyinzhe Zhang",
          "hidden": false
        },
        {
          "_id": "67bffaca3f838c1e33e074ee",
          "name": "Yu Sun",
          "hidden": false
        },
        {
          "_id": "67bffaca3f838c1e33e074ef",
          "name": "Kai Chen",
          "hidden": false
        },
        {
          "_id": "67bffaca3f838c1e33e074f0",
          "name": "Xipeng Qiu",
          "hidden": false
        },
        {
          "_id": "67bffaca3f838c1e33e074f1",
          "name": "Tao Gui",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-26T16:33:41.000Z",
      "title": "Carískus: Desarrollamos estándares de calidad de datos a partir de las preferencias humanas.",
      "summary": "El modelo de lenguaje es fundamental para desarrollar su mejor rendimiento, lo que exige datos de alta calidad. Actualmente, el enfoque es basado en heurísticas manuales diseñadas, variaciones de modelos existentes, el entrenamiento de clasificadores o ajustes de reglas. Esta abordaje requiere gran conocimiento profesional y esfuerzo humano, y puede inducir sesgos en los datos. Presentamos CritiQ, un nuevo método de selección de datos. CritiQ utiliza pares de signos humanos de sim30 para extraer automáticamente las preferencias humanas sobre la calidad del datos y selecciona datos de manera eficiente. Uno de sus componentes principales, CritiQ Flow, permite a un agente administrativo evolucionar las reglas de calidad y a un agente de trabajo evaluar dos generalizaciones. En nuestros estudios previos, extrajimos reglas de calidad y construimos un conocimiento basado para fortalecer CritiQ Flow. Comparado con métodos basados en variabilidad y clasificadores, las reglas lingüísticas son interpretables y tienen valor de reutilización. Después de obtener las reglas, entrenamos un CritiQ score y asignamos un puntaje de calidad para seleccionar datos de manera eficiente. Demostramos efectos en áreas como código, matemáticas y lógica, y alcanzamos altas precisión en conjuntos de prueba de signos humanos. Para verificar la calidad de los datos seleccionados, continuamos entrenando el modelo Llama 3.1 y observamos mejoras en tareas de flujo posterior. Los estudios de ablación demuestran los beneficios del conocimiento basado y el proceso de reflexión. Analizamos la evolución de las reglas y el efecto de la mayoría.",
      "upvotes": 3,
      "discussionId": "67bffacc3f838c1e33e075a2"
    },
    "publishedAt": "2025-02-27T00:47:02.948Z",
    "title": "CritiQ: Mining Data Quality Criteria from Human Preferences",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.19279.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "638ef0b0c67af472d31674a6",
      "avatarUrl": "/avatars/02df97d15a0f46b47f9162221733b121.svg",
      "fullname": "Honglin Guo",
      "name": "KYLN24",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.19413",
      "authors": [
        {
          "_id": "67c02d6aa15ac71dcf1c754e",
          "name": "Christoph Schuhmann",
          "hidden": false
        },
        {
          "_id": "67c02d6aa15ac71dcf1c754f",
          "name": "Gollam Rabby",
          "hidden": false
        },
        {
          "_id": "67c02d6aa15ac71dcf1c7550",
          "name": "Ameya Prabhu",
          "hidden": false
        },
        {
          "_id": "67c02d6aa15ac71dcf1c7551",
          "name": "Tawsif Ahmed",
          "hidden": false
        },
        {
          "_id": "67c02d6aa15ac71dcf1c7552",
          "name": "Andreas Hochlehnert",
          "hidden": false
        },
        {
          "_id": "67c02d6aa15ac71dcf1c7553",
          "name": "Huu Nguyen",
          "hidden": false
        },
        {
          "_id": "67c02d6aa15ac71dcf1c7554",
          "name": "Nick Akinci Heidrich",
          "hidden": false
        },
        {
          "_id": "67c02d6aa15ac71dcf1c7555",
          "name": "Ludwig Schmidt",
          "hidden": false
        },
        {
          "_id": "67c02d6aa15ac71dcf1c7556",
          "name": "Robert Kaczmarczyk",
          "hidden": false
        },
        {
          "_id": "67c02d6aa15ac71dcf1c7557",
          "name": "Sören Auer",
          "hidden": false
        },
        {
          "_id": "67c02d6aa15ac71dcf1c7558",
          "name": "Jenia Jitsev",
          "hidden": false
        },
        {
          "_id": "67c02d6aa15ac71dcf1c7559",
          "name": "Matthias Bethge",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-26T18:56:52.000Z",
      "title": "Aleksei Our Project: Proyecto que utiliza LLMs para mitigar el impacto de la propiedad intelectual en la ciencia",
      "summary": "Paywall, Resent and copyright rules limit the widespread dissemination and reuse of scientific knowledge. We base our approach on the principles and technical feasibility of extracting scientific knowledge from academic papers. Current methods, such as text embedding, cannot preserve factual content in a trustworthy manner. Simple rephrasing is legally justifiable. We encourage the community to accept new ideas: transforming academic papers into Knowledge Units using LLMs. These units are structured data without style, using structured data to capture information about entities, attributes, and relationships. We demonstrate with Knowledge Units that: (1) a framework based on the analysis of German copyright law and the U.S. \"Fair Use\" theory can support the legal sharing of knowledge from research papers. (2) nearly all factual knowledge (about 95%) from the original paper can be preserved, and the results of measuring facts from the copyrighted document using MCQs are shown. We predict that scientific knowledge can derive significant benefits for scientific research and education by reusing important facts from copyrighted documents. To support this, we share open-source tools for converting academic papers into Knowledge Units. In summary, our work asserts the possibility of a democratic access to scientific knowledge while respecting copyright.",
      "upvotes": 2,
      "discussionId": "67c02d6ba15ac71dcf1c7596"
    },
    "publishedAt": "2025-02-27T04:18:26.724Z",
    "title": "Project Alexandria: Towards Freeing Scientific Knowledge from Copyright Burdens via LLMs",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.19413.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6464a0d41683d3c81f51924a",
      "avatarUrl": "/avatars/bfa89f568302fa34a641e0d8744bf8b5.svg",
      "fullname": "Ameya Prabhu",
      "name": "AmeyaPrabhu",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 4
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.18417",
      "authors": [
        {
          "_id": "67c02b2eb14cf3cbc800c292",
          "name": "Alexander Groshev",
          "hidden": false
        },
        {
          "_id": "67c02b2eb14cf3cbc800c293",
          "user": {
            "_id": "67aafccd7517c92ba71142f2",
            "avatarUrl": "/avatars/ef4b5c6867250b8b7af2c995dd7ad740.svg",
            "isPro": false,
            "fullname": "Anastasiia Iashchenko",
            "user": "nastasia-y",
            "type": "user"
          },
          "name": "Anastasiia Iashchenko",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-27T09:13:49.896Z",
          "hidden": false
        },
        {
          "_id": "67c02b2eb14cf3cbc800c294",
          "name": "Pavel Paramonov",
          "hidden": false
        },
        {
          "_id": "67c02b2eb14cf3cbc800c295",
          "name": "Denis Dimitrov",
          "hidden": false
        },
        {
          "_id": "67c02b2eb14cf3cbc800c296",
          "name": "Andrey Kuznetsov",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-25T18:13:55.000Z",
      "title": "GHOST 2.0: Transmisión de alta calidad en una rotación de un solo turno",
      "summary": "Recientemente, mientras el problema de intercambio de rostros recibió atención en la comunidad de investigación, el problema de intercambio de cabezas no fue ampliamente investigado. El intercambio de cabezas, excluyendo el movimiento de color de rostro, presenta un problema especial en la síntesis, ya que debe conservar toda la información estructural de la cabeza y llenar los espacios vacíos entre la cabeza intercambiada y el fondo. En este artículo, se utilizan dos módulos especializados para abordar estos problemas: GHOST 2.0. Primero, se fortalece el modelo de Alignment adecuado para la representación de la cabeza, conservando la identidad a diferentes escalas y haciéndola resistente a cambios de postura extremos. Luego, se utiliza el módulo de Blender para mover el color de rostro y llenar áreas incorrectas, permitiendo que la cabeza se adapte completamente al fondo objetivo. Ambos módulos muestran un rendimiento superior a los estándares en sus respectivas tareas y permiten alcanzar resultados líderes en el intercambio de cabezas. Además, resuelven casos complejos como grandes diferencias entre las formas de cabeza del fuente y el objetivo. El código está disponible en: https://github.com/ai-forever/ghost-2.0.",
      "upvotes": 2,
      "discussionId": "67c02b31b14cf3cbc800c34b"
    },
    "publishedAt": "2025-02-27T04:15:43.126Z",
    "title": "GHOST 2.0: generative high-fidelity one shot transfer of heads",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.18417.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "67aafccd7517c92ba71142f2",
      "avatarUrl": "/avatars/ef4b5c6867250b8b7af2c995dd7ad740.svg",
      "fullname": "Anastasiia Iashchenko",
      "name": "nastasia-y",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.19187",
      "authors": [
        {
          "_id": "67c01747e8c7d56a8e0cbdc3",
          "name": "Mehran Kazemi",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdc4",
          "user": {
            "_id": "654e97ef5da3196a78409341",
            "avatarUrl": "/avatars/1a5ea7351ca21960891cf9721b9f4667.svg",
            "isPro": false,
            "fullname": "Bahare Fatemi",
            "user": "baharefatemi",
            "type": "user"
          },
          "name": "Bahare Fatemi",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-02-27T07:42:00.525Z",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdc5",
          "name": "Hritik Bansal",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdc6",
          "name": "John Palowitch",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdc7",
          "name": "Chrysovalantis Anastasiou",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdc8",
          "name": "Sanket Vaibhav Mehta",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdc9",
          "name": "Lalit K. Jain",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdca",
          "name": "Virginia Aglietti",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdcb",
          "name": "Disha Jindal",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdcc",
          "name": "Peter Chen",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdcd",
          "name": "Nishanth Dikkala",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdce",
          "name": "Gladys Tyen",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdcf",
          "name": "Xin Liu",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdd0",
          "name": "Uri Shalit",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdd1",
          "name": "Silvia Chiappa",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdd2",
          "name": "Kate Olszewska",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdd3",
          "name": "Yi Tay",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdd4",
          "name": "Vinh Q. Tran",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdd5",
          "name": "Quoc V. Le",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdd6",
          "name": "Orhan Firat",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-26T14:50:50.000Z",
      "title": "BIG-Bench EXTRA HARD",
      "summary": "Los modelos de lenguaje general (LLMs) están creciendo diariamente en aplicaciones cotidianas y exigen fuertes capacidades de lógica general, así como una amplia gama de habilidades de lógica. Sin embargo, los marcos de evaluación actuales de lógica para los LLMs se centran principalmente en capacidades matemáticas y de programación, lo que limita su evaluación de una amplia gama de habilidades de lógica. En particular, el conjunto de datos BIG-Bench es un excepcional caso, ya que cuenta con una serie de tareas difíciles y ofrece una evaluación de la capacidad lógica general de los LLMs a través de un solo marco unificado. Sin embargo, el último avance en los LLMs, denominado SATAR, que es una versión más difícil de BIG-Bench (BBH), ha demostrado una reducción de su utilidad. Los modelos más avanzados alcanzan puntuaciones cercanas a la máxima en muchas tareas del BBH, pero su utilidad se ve afectada. Para superar estas limitaciones, se ha introducido el nuevo marco de evaluación BIG-Bench Extra Hard (BBEH), cuyo objetivo es superar los límites de la evaluación de lógica en los LLMs. BBEH reemplaza cada tarea del BBH con una nueva tarea que investiga una misma capacidad lógica pero con un gran aumento de dificultad. En BBEH, se evaluan diferentes modelos, y el promedio de precisión del mejor modelo general es del 9.8%, mientras que el mejor modelo de lógica es del 44.8%, mostrando un gran potencial para mejoras y claramente identificando el desafío de lograr una fuerte capacidad lógica general en los LLMs. BBEH está disponible públicamente: https://github.com/google-deepmind/bbeh.",
      "upvotes": 2,
      "discussionId": "67c01748e8c7d56a8e0cbe0b"
    },
    "publishedAt": "2025-02-27T02:43:05.341Z",
    "title": "BIG-Bench Extra Hard",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.19187.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "5f1158120c833276f61f1a84",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1608042047613-5f1158120c833276f61f1a84.jpeg",
      "fullname": "Niels Rogge",
      "name": "nielsr",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 773
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.16284",
      "authors": [
        {
          "_id": "67bfdbd0302c06f220658e9d",
          "user": {
            "_id": "64e84ec6d41a68b065bf78a7",
            "avatarUrl": "/avatars/bae3c5e3210b40af6e4f113e85f3e206.svg",
            "isPro": false,
            "fullname": "Liang Wang",
            "user": "AzureLeon1",
            "type": "user"
          },
          "name": "Liang Wang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-27T09:14:42.802Z",
          "hidden": false
        },
        {
          "_id": "67bfdbd0302c06f220658e9e",
          "name": "Shaozhen Liu",
          "hidden": false
        },
        {
          "_id": "67bfdbd0302c06f220658e9f",
          "name": "Yu Rong",
          "hidden": false
        },
        {
          "_id": "67bfdbd0302c06f220658ea0",
          "name": "Deli Zhao",
          "hidden": false
        },
        {
          "_id": "67bfdbd0302c06f220658ea1",
          "name": "Qiang Liu",
          "hidden": false
        },
        {
          "_id": "67bfdbd0302c06f220658ea2",
          "name": "Shu Wu",
          "hidden": false
        },
        {
          "_id": "67bfdbd0302c06f220658ea3",
          "name": "Liang Wang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-22T16:34:32.000Z",
      "title": "MolSpectra: El aprendizaje previo de representaciones tridimensionales de moléculas se realiza a través de la diversidad de espectros de energía.",
      "summary": "Establecer la relación entre la estructura 3D y el estado de energía de los moléculas ha demostrado ser un método prometedor para aprender la representación de moléculas 3D. Sin embargo, los métodos actuales están limitados por la modelación de los estados de energía de los moléculos basados en la mecánica clásica. Esta limitación excluye detalladas evaluaciones de la energía de los moléculos y la medición experimental de su espectro de energía, excepto por efectos cuantico-mecánicos y la estructura de niveles de energía debido a la cuantización. En este artículo, se propone un método para entrenar la representación de moléculas 3D utilizando espectros de energía (MolSpectra), con el objetivo de incorporar conocimientos de la mecánica cuántica en la representación de moléculas. Específicamente, se propone codificar espectros de moléculas usando un encoder de espectros (SpecFormer) a través de reconstrucción de patches mascarados. Para entender mejor la representación de moléculas 3D, se ajustan los resultados de los encoders 3D y espectrales comparandolos con un objeto de ajuste. En evaluaciones en marcos de referencia públicos, se ha confirmado que las representaciones entrenadas superan los métodos actuales en la predicción de características de moléculas y la modelación de dinámicas.",
      "upvotes": 2,
      "discussionId": "67bfdbd1302c06f220658ece"
    },
    "publishedAt": "2025-02-26T22:29:40.056Z",
    "title": "MolSpectra: Pre-training 3D Molecular Representation with Multi-modal Energy Spectra",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.16284.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64e84ec6d41a68b065bf78a7",
      "avatarUrl": "/avatars/bae3c5e3210b40af6e4f113e85f3e206.svg",
      "fullname": "Liang Wang",
      "name": "AzureLeon1",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.17540",
      "authors": [
        {
          "_id": "67bff9608d761fc6a75e24ad",
          "user": {
            "_id": "657ccbf2869d5bb0e53b482f",
            "avatarUrl": "/avatars/2eae5a10bdc14814a04d9f255f16de6b.svg",
            "isPro": false,
            "fullname": "Rohit Saxena",
            "user": "rohitsaxena",
            "type": "user"
          },
          "name": "Rohit Saxena",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-27T09:13:54.284Z",
          "hidden": false
        },
        {
          "_id": "67bff9608d761fc6a75e24ae",
          "name": "Pasquale Minervini",
          "hidden": false
        },
        {
          "_id": "67bff9608d761fc6a75e24af",
          "name": "Frank Keller",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-24T18:35:39.000Z",
      "title": "\"Poster Summary Benchmark: A Multimodal Benchmark for Scientific Posters\"",
      "summary": "En el documento March Modern, la generación de resúmenes de texto precisos y sencillos es una tarea difícil. En particular, es especialmente complicado procesar contenido visualmente complejo como los pósteres científicos. Para abordar este desafío, se presenta un nuevo benchmark utilizando resúmenes de pósteres para que los modelos de visión-lengua (VLMs) puedan entender y resumir pósteres científicos como resúmenes de artículos científicos. El dataset incluye 16,305 pósteres de congresos, proporcionados en formato de imagen, que presentan diversos problemas visuales complejos, como ruteos densos, áreas de texto compactas, tablas y dibujos. El aplicar el benchmark a los resúmenes de pósteres permite evaluar los mejores modelos de visión-lengua (MLLMs) actuales, demostrando los desafíos en la precisión y resumen de los pósteres científicos. Se propone un método jerárquico llamado Segment & Summarize, que supera a los modelos MLLMs actuales, logrando un beneficio del 3.14% en el métrica ROUGE-L. Este resultado puede servir como punto de partida para futuras investigaciones en resúmenes de pósteres.",
      "upvotes": 1,
      "discussionId": "67bff96d8d761fc6a75e27a0"
    },
    "publishedAt": "2025-02-27T00:37:24.965Z",
    "title": "PosterSum: A Multimodal Benchmark for Scientific Poster Summarization",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.17540.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "657ccbf2869d5bb0e53b482f",
      "avatarUrl": "/avatars/2eae5a10bdc14814a04d9f255f16de6b.svg",
      "fullname": "Rohit Saxena",
      "name": "rohitsaxena",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 4
    },
    "isAuthorParticipating": true
  }
]