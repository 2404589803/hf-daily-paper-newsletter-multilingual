[
  {
    "paper": {
      "id": "2505.02550",
      "authors": [
        {
          "_id": "6819ef0b2ff435c58da4d860",
          "user": {
            "_id": "63ecbccac8827dd0f0f59579",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63ecbccac8827dd0f0f59579/kz-2F9Z0QKllifgZmr8tH.jpeg",
            "isPro": false,
            "fullname": "Chris Ociepa",
            "user": "chrisociepa",
            "type": "user"
          },
          "name": "Krzysztof Ociepa",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-12T09:03:56.213Z",
          "hidden": false
        },
        {
          "_id": "6819ef0b2ff435c58da4d861",
          "name": "Łukasz Flis",
          "hidden": false
        },
        {
          "_id": "6819ef0b2ff435c58da4d862",
          "user": {
            "_id": "61786d0b038518aa2827c6b7",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/61786d0b038518aa2827c6b7/d1UnfivoVreYebS5JM3P9.jpeg",
            "isPro": false,
            "fullname": "Remek Kinas",
            "user": "Remek",
            "type": "user"
          },
          "name": "Remigiusz Kinas",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-12T06:51:15.217Z",
          "hidden": false
        },
        {
          "_id": "6819ef0b2ff435c58da4d863",
          "user": {
            "_id": "5e47d3eb178ca95365287400",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1633554153914-5e47d3eb178ca95365287400.png",
            "isPro": true,
            "fullname": "Krzysztof Wróbel",
            "user": "djstrong",
            "type": "user"
          },
          "name": "Krzysztof Wróbel",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-12T09:03:54.135Z",
          "hidden": false
        },
        {
          "_id": "6819ef0b2ff435c58da4d864",
          "name": "Adrian Gwoździej",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-05T10:39:51.000Z",
      "submittedOnDailyAt": "2025-05-12T07:26:20.895Z",
      "title": "Bielik v3 Small: Informe Técnico",
      "submittedOnDailyBy": {
        "_id": "5e47d3eb178ca95365287400",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1633554153914-5e47d3eb178ca95365287400.png",
        "isPro": true,
        "fullname": "Krzysztof Wróbel",
        "user": "djstrong",
        "type": "user"
      },
      "summary": "Introduzco a la versión 3 de BEVERICK. Este modelo es parte de la serie de modelos generativos de texto eficientes en parámetros, optimizado para el procesamiento del polaco en tamaños de 1.5B y 4.5B. Estos modelos pueden alcanzar el rendimiento de grandes modelos con un tamaño relativamente pequeño, reduciendo significativamente la cantidad de recursos computacionales utilizados. Nuestro enfoque incluye varias innovaciones clave. Entre ellas se encuentra el Tokenizer Adaptado para el Polaco (APT4), diseñado para mejorar la eficiencia de los tokens, el equilibrio entre el aprendizaje de tipos de comando mediante el pérdida de entropía cruzada de comandos ponderados, y un aprendizaje de razón de aprendizaje adaptativo que se ajusta dinámicamente durante el proceso de entrenamiento. Se entrenó en un corpus de 292,000 millones de tokens filtrados, compuesto por 30,300,000 artículos. Estos modelos han obtenido excelentes resultados en varios benchmarks, incluyendo el Open PL LLM Leaderboard, el Benchmark de Comprensión del Texto Polski, el Benchmark EQ-Bench Polski y el Leaderboard de Medicina Polski. El modelo de 4.5B parámetros logró resultados competitivos frente a modelos de dos a tres veces su tamaño, mientras que el modelo de 1.5B ofrece un rendimiento fuerte incluso en perfiles muy pequeños. Estos avances establecen nuevos estándares de eficiencia en la modelación de lenguajes y facilitan la acceso a una AI de alta calidad en el polaco en aplicaciones con limitaciones de recursos.",
      "upvotes": 16,
      "discussionId": "6819ef0c2ff435c58da4d892",
      "projectPage": "https://bielik.ai/",
      "githubRepo": "https://github.com/speakleash",
      "ai_keywords": [
        "parameter-efficient",
        "generative text models",
        "token efficiency",
        "custom Polish tokenizer",
        "Weighted Instruction Cross-Entropy Loss",
        "Adaptive Learning Rate"
      ]
    },
    "publishedAt": "2025-05-05T06:39:51.000Z",
    "title": "Bielik v3 Small: Technical Report",
    "summary": "We introduce Bielik v3, a series of parameter-efficient generative text\nmodels (1.5B and 4.5B) optimized for Polish language processing. These models\ndemonstrate that smaller, well-optimized architectures can achieve performance\ncomparable to much larger counterparts while requiring substantially fewer\ncomputational resources. Our approach incorporates several key innovations: a\ncustom Polish tokenizer (APT4) that significantly improves token efficiency,\nWeighted Instruction Cross-Entropy Loss to balance learning across instruction\ntypes, and Adaptive Learning Rate that dynamically adjusts based on training\nprogress. Trained on a meticulously curated corpus of 292 billion tokens\nspanning 303 million documents, these models excel across multiple benchmarks,\nincluding the Open PL LLM Leaderboard, Complex Polish Text Understanding\nBenchmark, Polish EQ-Bench, and Polish Medical Leaderboard. The 4.5B parameter\nmodel achieves results competitive with models 2-3 times its size, while the\n1.5B model delivers strong performance despite its extremely compact profile.\nThese advances establish new benchmarks for parameter-efficient language\nmodeling in less-represented languages, making high-quality Polish language AI\nmore accessible for resource-constrained applications.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.02550.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "5e47d3eb178ca95365287400",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1633554153914-5e47d3eb178ca95365287400.png",
      "fullname": "Krzysztof Wróbel",
      "name": "djstrong",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 9
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.02410",
      "authors": [
        {
          "_id": "6819f19e5c7ea9f74284d3a3",
          "user": {
            "_id": "63ecbccac8827dd0f0f59579",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63ecbccac8827dd0f0f59579/kz-2F9Z0QKllifgZmr8tH.jpeg",
            "isPro": false,
            "fullname": "Chris Ociepa",
            "user": "chrisociepa",
            "type": "user"
          },
          "name": "Krzysztof Ociepa",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-12T09:03:52.265Z",
          "hidden": false
        },
        {
          "_id": "6819f19e5c7ea9f74284d3a4",
          "name": "Łukasz Flis",
          "hidden": false
        },
        {
          "_id": "6819f19e5c7ea9f74284d3a5",
          "user": {
            "_id": "5e47d3eb178ca95365287400",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1633554153914-5e47d3eb178ca95365287400.png",
            "isPro": true,
            "fullname": "Krzysztof Wróbel",
            "user": "djstrong",
            "type": "user"
          },
          "name": "Krzysztof Wróbel",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-12T09:03:50.340Z",
          "hidden": false
        },
        {
          "_id": "6819f19e5c7ea9f74284d3a6",
          "name": "Adrian Gwoździej",
          "hidden": false
        },
        {
          "_id": "6819f19e5c7ea9f74284d3a7",
          "user": {
            "_id": "61786d0b038518aa2827c6b7",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/61786d0b038518aa2827c6b7/d1UnfivoVreYebS5JM3P9.jpeg",
            "isPro": false,
            "fullname": "Remek Kinas",
            "user": "Remek",
            "type": "user"
          },
          "name": "Remigiusz Kinas",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-12T06:51:13.426Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-05T07:03:41.000Z",
      "submittedOnDailyAt": "2025-05-12T07:25:02.402Z",
      "title": "InternLM (书生·浦语) 翻译如下：\n\nInforme Técnico de Tecnología Biólica 11B v2",
      "submittedOnDailyBy": {
        "_id": "5e47d3eb178ca95365287400",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1633554153914-5e47d3eb178ca95365287400.png",
        "isPro": true,
        "fullname": "Krzysztof Wróbel",
        "user": "djstrong",
        "type": "user"
      },
      "summary": "BiELICK 11B v2, la más avanzada y optimizada para el procesamiento de texto en polaco, se presenta. Basado en la arquitectura Mistral 7B v0.2, se ha realizado una profunda escalado de parámetros para expandir la cantidad de parámetros hasta 11B. Muestra un excelente rendimiento en los benchmarks polacos y tiene una fuerte capacidad de cross-linguism. Se presentan dos innovaciones tecnológicas principales: 1. Pérdida de cruce de entropía de instancia con pesos: se asignan pesos basados en masa a los muestras de entrenamiento para optimizar el aprendizaje de diferentes tipos de instancias. 2. Aprendizaje de tasa adaptativa: se ajusta dinamicamente según la longitud del contexto. Una evaluación detallada en varios benchmarks muestra que Bielick 11B v2 supera a modelos con entre 2 a 6 veces más parámetros, y excede significativamente a modelos especializados en polaco en tareas desde la comprensión del lenguaje hasta la explicación de razones complejas. La eficiencia de parámetros y las funciones de dispersión del modelo permiten su introducción en diferentes configuraciones de hardware, estableciendo nuevos estándares de benchmark para el desarrollo de capacidades AI en polaco y la modelización de lenguaje de manera eficiente de recursos.",
      "upvotes": 16,
      "discussionId": "6819f19e5c7ea9f74284d3cc",
      "projectPage": "https://bielik.ai/",
      "githubRepo": "https://github.com/speakleash",
      "ai_keywords": [
        "Weighted Instruction Cross-Entropy Loss",
        "Adaptive Learning Rate",
        "depth up-scaling",
        "parameter efficiency",
        "quantization"
      ]
    },
    "publishedAt": "2025-05-05T03:03:41.000Z",
    "title": "Bielik 11B v2 Technical Report",
    "summary": "We present Bielik 11B v2, a state-of-the-art language model optimized for\nPolish text processing. Built on the Mistral 7B v0.2 architecture and scaled to\n11B parameters using depth up-scaling, this model demonstrates exceptional\nperformance across Polish language benchmarks while maintaining strong\ncross-lingual capabilities. We introduce two key technical innovations:\nWeighted Instruction Cross-Entropy Loss, which optimizes learning across\ndiverse instruction types by assigning quality-based weights to training\nexamples, and Adaptive Learning Rate, which dynamically adjusts based on\ncontext length. Comprehensive evaluation across multiple benchmarks\ndemonstrates that Bielik 11B v2 outperforms many larger models, including those\nwith 2-6 times more parameters, and significantly surpasses other specialized\nPolish language models on tasks ranging from linguistic understanding to\ncomplex reasoning. The model's parameter efficiency and extensive quantization\noptions enable deployment across various hardware configurations, advancing\nPolish language AI capabilities and establishing new benchmarks for\nresource-efficient language modeling in less-represented languages.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.02410.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "5e47d3eb178ca95365287400",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1633554153914-5e47d3eb178ca95365287400.png",
      "fullname": "Krzysztof Wróbel",
      "name": "djstrong",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 9
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.06046",
      "authors": [
        {
          "_id": "6821af48696b63e207ae8474",
          "user": {
            "_id": "64cb98c6f103036e23c69b1d",
            "avatarUrl": "/avatars/7ee33880ad39f5335b618dc53554124a.svg",
            "isPro": false,
            "fullname": "Harris",
            "user": "Joshua-Harris",
            "type": "user"
          },
          "name": "Joshua Harris",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-12T09:03:48.631Z",
          "hidden": false
        },
        {
          "_id": "6821af48696b63e207ae8475",
          "name": "Fan Grayson",
          "hidden": false
        },
        {
          "_id": "6821af48696b63e207ae8476",
          "name": "Felix Feldman",
          "hidden": false
        },
        {
          "_id": "6821af48696b63e207ae8477",
          "name": "Timothy Laurence",
          "hidden": false
        },
        {
          "_id": "6821af48696b63e207ae8478",
          "name": "Toby Nonnenmacher",
          "hidden": false
        },
        {
          "_id": "6821af48696b63e207ae8479",
          "name": "Oliver Higgins",
          "hidden": false
        },
        {
          "_id": "6821af48696b63e207ae847a",
          "name": "Leo Loman",
          "hidden": false
        },
        {
          "_id": "6821af48696b63e207ae847b",
          "name": "Selina Patel",
          "hidden": false
        },
        {
          "_id": "6821af48696b63e207ae847c",
          "name": "Thomas Finnie",
          "hidden": false
        },
        {
          "_id": "6821af48696b63e207ae847d",
          "name": "Samuel Collins",
          "hidden": false
        },
        {
          "_id": "6821af48696b63e207ae847e",
          "name": "Michael Borowitz",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-09T13:42:59.000Z",
      "submittedOnDailyAt": "2025-05-12T07:35:55.202Z",
      "title": "Salud de los LLMs? Marco de referencia de conocimiento de los LLMs para la información de salud pública del Gobierno de Reino Unido",
      "submittedOnDailyBy": {
        "_id": "64cb98c6f103036e23c69b1d",
        "avatarUrl": "/avatars/7ee33880ad39f5335b618dc53554124a.svg",
        "isPro": false,
        "fullname": "Harris",
        "user": "Joshua-Harris",
        "type": "user"
      },
      "summary": "El espalramiento de los LLM ha demostrado que un entendimiento detallado de la información es esencial para el éxito de su aplicación en ciertos campos. En particular, en la salud pública, la incapacidad de obtener información precisa y actual puede tener graves consecuencias para los ciudadanos de Reino Unido. Sin embargo, actualmente, poco se sabe sobre qué conocimientos los LLM tienen sobre la información sanitaria oficial del gobierno británico. Para abordar este problema, este artículo presenta un nuevo marco de referencia, llamado PubHealthBench, que evalúa la respuesta a preguntas de múltiples respuestas correctas (MCQA) y respuestas de tipo libre sobre salud pública, proporcionando más de 8.000 preguntas generadas automáticamente. Además, se ha lanzado un nuevo conjunto de datos para ser utilizado como texto fuente de PubHealthBench, que incluye guías sanitarias oficiales del gobierno británico. Los resultados de la evaluación de 24 LLM en PubHealthBench muestran que los últimos modelos públicos (GPT-4.5, GPT-4.1, o1) tienen altos niveles de conocimiento, alcanzando más del 90% en MCQA y superando a los humanos que utilizan un motor de búsqueda para responder a las preguntas y consultar el texto fuente. Sin embargo, no hay modelos que superen el 75% en respuestas de tipo libre. Por lo tanto, los mejores (SOTA) LLM tienen la posibilidad de ser un recurso preciso de información sanitaria; sin embargo, para proporcionar respuestas de tipo libre sobre temas de salud pública, se requieren medidas adicionales de seguridad y herramientas.",
      "upvotes": 6,
      "discussionId": "6821af49696b63e207ae84c6",
      "ai_keywords": [
        "Large Language Models (LLMs)",
        "Multiple Choice Question Answering (MCQA)",
        "PubHealthBench",
        "UK Government public health information",
        "automated pipeline",
        "extracted UK Government public health guidance documents",
        "SOTA (state of the art) LLMs",
        "GPT-4.5",
        "GPT-4.1",
        "o1"
      ]
    },
    "publishedAt": "2025-05-09T09:42:59.000Z",
    "title": "Healthy LLMs? Benchmarking LLM Knowledge of UK Government Public Health\n  Information",
    "summary": "As Large Language Models (LLMs) become widely accessible, a detailed\nunderstanding of their knowledge within specific domains becomes necessary for\nsuccessful real world use. This is particularly critical in public health,\nwhere failure to retrieve relevant, accurate, and current information could\nsignificantly impact UK residents. However, currently little is known about LLM\nknowledge of UK Government public health information. To address this issue,\nthis paper introduces a new benchmark, PubHealthBench, with over 8000 questions\nfor evaluating LLMs' Multiple Choice Question Answering (MCQA) and free form\nresponses to public health queries, created via an automated pipeline. We also\nrelease a new dataset of the extracted UK Government public health guidance\ndocuments used as source text for PubHealthBench. Assessing 24 LLMs on\nPubHealthBench we find the latest private LLMs (GPT-4.5, GPT-4.1 and o1) have a\nhigh degree of knowledge, achieving >90% in the MCQA setup, and outperform\nhumans with cursory search engine use. However, in the free form setup we see\nlower performance with no model scoring >75%. Therefore, whilst there are\npromising signs that state of the art (SOTA) LLMs are an increasingly accurate\nsource of public health information, additional safeguards or tools may still\nbe needed when providing free form responses on public health topics.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.06046.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "64cb98c6f103036e23c69b1d",
      "avatarUrl": "/avatars/7ee33880ad39f5335b618dc53554124a.svg",
      "fullname": "Harris",
      "name": "Joshua-Harris",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.06111",
      "authors": [
        {
          "_id": "68218b847202d193249511b6",
          "name": "Qingwen Bu",
          "hidden": false
        },
        {
          "_id": "68218b847202d193249511b7",
          "name": "Yanting Yang",
          "hidden": false
        },
        {
          "_id": "68218b847202d193249511b8",
          "name": "Jisong Cai",
          "hidden": false
        },
        {
          "_id": "68218b847202d193249511b9",
          "name": "Shenyuan Gao",
          "hidden": false
        },
        {
          "_id": "68218b847202d193249511ba",
          "user": {
            "_id": "646ec9b135f55eb49e405faa",
            "avatarUrl": "/avatars/a17194be585d20e2a021e77a5a20e213.svg",
            "isPro": false,
            "fullname": "Guanghui Ren",
            "user": "sundrops",
            "type": "user"
          },
          "name": "Guanghui Ren",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-12T06:50:15.305Z",
          "hidden": false
        },
        {
          "_id": "68218b847202d193249511bb",
          "name": "Maoqing Yao",
          "hidden": false
        },
        {
          "_id": "68218b847202d193249511bc",
          "name": "Ping Luo",
          "hidden": false
        },
        {
          "_id": "68218b847202d193249511bd",
          "name": "Hongyang Li",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-09T15:11:13.000Z",
      "submittedOnDailyAt": "2025-05-12T04:30:20.087Z",
      "title": "UniVLA: Usando acciones potenciales centradas en tareas para aprender a actuar en cualquier lugar.",
      "submittedOnDailyBy": {
        "_id": "64ac1f169dcc5787461468a4",
        "avatarUrl": "/avatars/c031a75989147009b7850df4eddfcb27.svg",
        "isPro": false,
        "fullname": "Qingwen Bu",
        "user": "qwbu",
        "type": "user"
      },
      "summary": "General robots must operate effectively in various environments. However, many current approaches focus on expanding operation manual-based data, which strongly relies on this data to enhance their capabilities. Consequently, they typically limit one physical characteristic and find it challenging to learn knowledge that is learnable across different robot bodies and environments. To counter these limitations, we propose a new framework called UniVLA. This is a new framework for learning visual language action (VLA) policies that are learnable across different robot bodies. Our main innovation is the ability to obtain task-oriented action representations from videos using potential action models. This allows for the utilization of a wide range of data from different robot bodies and perspectives. To mitigate the impact of task-agnostic dynamics, we adopt the inclusion of language instructions and the construction of potential action models within the DINO feature space. General policies trained on internet-scale videos can be efficiently deployed to various robots through mechanical potential action decoding. State-of-the-art results have been achieved in many action and navigation benchmarks, and real robot deployment has also been realized. UniVLA achieves higher performance than OpenVLA, with 1/20 or less training computation and 1/10 or less downstream data. The inclusion of human videos or other types of data on the exposed line is expected to lead to continuous performance improvements. These results demonstrate that UniVLA can contribute to the efficient learning of exchangeable robot policies.",
      "upvotes": 5,
      "discussionId": "68218b857202d19324951214",
      "githubRepo": "https://github.com/OpenDriveLab/UniVLA",
      "ai_keywords": [
        "UniVLA",
        "vision-language-action (VLA) policies",
        "latent action model",
        "DINO feature space",
        "latent action decoding",
        "manipulation benchmarks",
        "navigation benchmarks",
        "real-robot deployments",
        "OpenVLA"
      ]
    },
    "publishedAt": "2025-05-09T11:11:13.000Z",
    "title": "UniVLA: Learning to Act Anywhere with Task-centric Latent Actions",
    "summary": "A generalist robot should perform effectively across various environments.\nHowever, most existing approaches heavily rely on scaling action-annotated data\nto enhance their capabilities. Consequently, they are often limited to single\nphysical specification and struggle to learn transferable knowledge across\ndifferent embodiments and environments. To confront these limitations, we\npropose UniVLA, a new framework for learning cross-embodiment\nvision-language-action (VLA) policies. Our key innovation is to derive\ntask-centric action representations from videos with a latent action model.\nThis enables us to exploit extensive data across a wide spectrum of embodiments\nand perspectives. To mitigate the effect of task-irrelevant dynamics, we\nincorporate language instructions and establish a latent action model within\nthe DINO feature space. Learned from internet-scale videos, the generalist\npolicy can be deployed to various robots through efficient latent action\ndecoding. We obtain state-of-the-art results across multiple manipulation and\nnavigation benchmarks, as well as real-robot deployments. UniVLA achieves\nsuperior performance over OpenVLA with less than 1/20 of pretraining compute\nand 1/10 of downstream data. Continuous performance improvements are observed\nas heterogeneous data, even including human videos, are incorporated into the\ntraining pipeline. The results underscore UniVLA's potential to facilitate\nscalable and efficient robot policy learning.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.06111.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64ac1f169dcc5787461468a4",
      "avatarUrl": "/avatars/c031a75989147009b7850df4eddfcb27.svg",
      "fullname": "Qingwen Bu",
      "name": "qwbu",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2505.05026",
      "authors": [
        {
          "_id": "6821771ddf190eabf5f666d8",
          "user": {
            "_id": "655c44752205aab35222aca3",
            "avatarUrl": "/avatars/57900539952382de0ce6892faf50b401.svg",
            "isPro": false,
            "fullname": "Jaehyun Jeon",
            "user": "jeochris",
            "type": "user"
          },
          "name": "Jaehyun Jeon",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-05-12T06:50:17.832Z",
          "hidden": false
        },
        {
          "_id": "6821771ddf190eabf5f666d9",
          "name": "Jang Han Yoon",
          "hidden": false
        },
        {
          "_id": "6821771ddf190eabf5f666da",
          "name": "Min Soo Kim",
          "hidden": false
        },
        {
          "_id": "6821771ddf190eabf5f666db",
          "name": "Sumin Shim",
          "hidden": false
        },
        {
          "_id": "6821771ddf190eabf5f666dc",
          "name": "Yejin Choi",
          "hidden": false
        },
        {
          "_id": "6821771ddf190eabf5f666dd",
          "name": "Hanbin Kim",
          "hidden": false
        },
        {
          "_id": "6821771ddf190eabf5f666de",
          "name": "Youngjae Yu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-08T08:00:32.000Z",
      "submittedOnDailyAt": "2025-05-12T05:33:20.932Z",
      "title": "G-FOCUS: Esfuerzos para evaluar la persuasividad en el diseño de interfaces de usuario (UI)",
      "submittedOnDailyBy": {
        "_id": "655c44752205aab35222aca3",
        "avatarUrl": "/avatars/57900539952382de0ce6892faf50b401.svg",
        "isPro": false,
        "fullname": "Jaehyun Jeon",
        "user": "jeochris",
        "type": "user"
      },
      "summary": "La evaluación efectiva de diseños de usuario (UI) se centra en aspectos que pueden influir en el comportamiento del usuario, pasando por las propiedades artísticas. Esta evaluación se basa en los principios fundamentales de la persuasión del diseño. Las pruebas A/B son uno de los principales métodos para seleccionar un diseño de usuario que aumente la participación del usuario, aunque requieren costos y tiempo. Los modelos de Visión-Lenguaje (VLM) recientes han logrado analizar automáticamente diseños de usuario, pero su enfoque actual se centra en características de diseño independientes, en lugar de evaluar su persuasión. Para responder a esto, presentamos WiserUI-Bench, un marco de referencia para evaluar la persuasión de diseños de usuario pareados. Este marco incluye 300 pares de imágenes de diseños de usuario reales, etiquetados con motivos profesionales basados en resultados de pruebas A/B. Además, proponemos G-FOCUS, una estrategia de razonamiento que fortalece la evaluación de persuasión basada en VLM, reduce la bias de posición y mejora la precisión de la evaluación. Los resultados de las pruebas muestran que G-FOCUS supera las estrategias de inferencia actuales en términos de concordancia y precisión en la evaluación de diseños de usuario pareados. Nuestro estudio promueve la evaluación de la persuasión de diseños de usuario mediante VLM, proporcionando una aproximación que complementa las pruebas A/B y fomenta el modelado de preferencias de diseños de usuario intercambiables y la optimización del diseño. Los códigos y datos están disponibles públicamente.",
      "upvotes": 5,
      "discussionId": "68217722df190eabf5f66814",
      "ai_keywords": [
        "Vision-Language Models",
        "WiserUI-Bench",
        "Pairwise UI Design Persuasiveness Assessment",
        "G-FOCUS",
        "inference-time reasoning strategy",
        "position bias",
        "VLM-driven evaluation"
      ]
    },
    "publishedAt": "2025-05-08T04:00:32.000Z",
    "title": "G-FOCUS: Towards a Robust Method for Assessing UI Design Persuasiveness",
    "summary": "Evaluating user interface (UI) design effectiveness extends beyond aesthetics\nto influencing user behavior, a principle central to Design Persuasiveness. A/B\ntesting is the predominant method for determining which UI variations drive\nhigher user engagement, but it is costly and time-consuming. While recent\nVision-Language Models (VLMs) can process automated UI analysis, current\napproaches focus on isolated design attributes rather than comparative\npersuasiveness-the key factor in optimizing user interactions. To address this,\nwe introduce WiserUI-Bench, a benchmark designed for Pairwise UI Design\nPersuasiveness Assessment task, featuring 300 real-world UI image pairs labeled\nwith A/B test results and expert rationales. Additionally, we propose G-FOCUS,\na novel inference-time reasoning strategy that enhances VLM-based\npersuasiveness assessment by reducing position bias and improving evaluation\naccuracy. Experimental results show that G-FOCUS surpasses existing inference\nstrategies in consistency and accuracy for pairwise UI evaluation. Through\npromoting VLM-driven evaluation of UI persuasiveness, our work offers an\napproach to complement A/B testing, propelling progress in scalable UI\npreference modeling and design optimization. Code and data will be released\npublicly.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.05026.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "655c44752205aab35222aca3",
      "avatarUrl": "/avatars/57900539952382de0ce6892faf50b401.svg",
      "fullname": "Jaehyun Jeon",
      "name": "jeochris",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2505.02686",
      "authors": [
        {
          "_id": "6821acfb2808328b91c0e365",
          "name": "Xiaobao Wu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-05-05T14:33:49.000Z",
      "submittedOnDailyAt": "2025-05-12T06:41:36.276Z",
      "title": "El ascenso al cielo de un AI: Investigación sobre el aprendizaje compensatorio después del entrenamiento y la escalabilidad en el entrenamiento y prueba de modelos de lenguaje grandes",
      "submittedOnDailyBy": {
        "_id": "64cb02869e30a46f7b80b355",
        "avatarUrl": "/avatars/81ce4ba78826b54f0e1b53eeaff87ee6.svg",
        "isPro": false,
        "fullname": "Xiaobao Wu",
        "user": "bobxwu",
        "type": "user"
      },
      "summary": "El desarrollo reciente de los modelos de lenguaje grande (LLMs) se ha realizado a través de escalas de aprendizaje previo, aprendizaje y tiempo de prueba posterior. En esta evolución, una paradigma central y unificado ha surgido: el aprendizaje de compensación orienta las acciones de los LLMs de manera crucial. Este paradigma forma la base de una amplia gama de tecnologías introducidas, como el aprendizaje por refuerzo guiado (RLHF, DPO, GRPO), la decodificación guiada por compensación, y la corrección posterior. Un punto clave es que este paradigma permite que el aprendizaje pasivo a partir de datos estáticos se convierta en un aprendizaje activo a partir de retroalimentación dinámica. Esto confiere a los LLMs preferencias consistentes y capacidades teóricas profundas. En esta investigación, se proporciona una resumen detallado del paradigma de aprendizaje de compensación. Se clasifican y analizan las estrategias de aprendizaje, inferencia y posterior inferencia bajo este paradigma. Además, se discuten los marcos de referencia de los modelos de compensación y sus aplicaciones principales. Finalmente, se destacan los problemas y las direcciones futuras. La documentación de los artículos sobre el aprendizaje de los LLMs de compensación está disponible en https://github.com/bobxwu/learning-from-rewards-llm-papers.",
      "upvotes": 3,
      "discussionId": "6821acfd2808328b91c0e3e3",
      "githubRepo": "https://github.com/bobxwu/learning-from-rewards-llm-papers",
      "ai_keywords": [
        "reinforcement learning",
        "RLHF",
        "DPO",
        "GRPO",
        "reward-guided decoding",
        "post-hoc correction",
        "active learning",
        "reward models"
      ]
    },
    "publishedAt": "2025-05-05T10:33:49.000Z",
    "title": "Sailing AI by the Stars: A Survey of Learning from Rewards in\n  Post-Training and Test-Time Scaling of Large Language Models",
    "summary": "Recent developments in Large Language Models (LLMs) have shifted from\npre-training scaling to post-training and test-time scaling. Across these\ndevelopments, a key unified paradigm has arisen: Learning from Rewards, where\nreward signals act as the guiding stars to steer LLM behavior. It has\nunderpinned a wide range of prevalent techniques, such as reinforcement\nlearning (in RLHF, DPO, and GRPO), reward-guided decoding, and post-hoc\ncorrection. Crucially, this paradigm enables the transition from passive\nlearning from static data to active learning from dynamic feedback. This endows\nLLMs with aligned preferences and deep reasoning capabilities. In this survey,\nwe present a comprehensive overview of the paradigm of learning from rewards.\nWe categorize and analyze the strategies under this paradigm across training,\ninference, and post-inference stages. We further discuss the benchmarks for\nreward models and the primary applications. Finally we highlight the challenges\nand future directions. We maintain a paper collection at\nhttps://github.com/bobxwu/learning-from-rewards-llm-papers.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.02686.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64cb02869e30a46f7b80b355",
      "avatarUrl": "/avatars/81ce4ba78826b54f0e1b53eeaff87ee6.svg",
      "fullname": "Xiaobao Wu",
      "name": "bobxwu",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false
    },
    "isAuthorParticipating": false
  }
]