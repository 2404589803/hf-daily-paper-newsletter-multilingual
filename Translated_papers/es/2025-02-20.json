[
  {
    "paper": {
      "id": "2502.13923",
      "authors": [
        {
          "_id": "67b6b0688b56622e70b9e83e",
          "name": "Shuai Bai",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e83f",
          "name": "Keqin Chen",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e840",
          "name": "Xuejing Liu",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e841",
          "name": "Jialin Wang",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e842",
          "name": "Wenbin Ge",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e843",
          "name": "Sibo Song",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e844",
          "name": "Kai Dang",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e845",
          "name": "Peng Wang",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e846",
          "name": "Shijie Wang",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e847",
          "name": "Jun Tang",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e848",
          "name": "Humen Zhong",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e849",
          "name": "Yuanzhi Zhu",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e84a",
          "user": {
            "_id": "6417fa211f1f3b0fa811edc0",
            "avatarUrl": "/avatars/fa9e1ef1472a736c2ceebe12b77d6c89.svg",
            "isPro": false,
            "fullname": "Mingkun Yang",
            "user": "ayumiymk",
            "type": "user"
          },
          "name": "Mingkun Yang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-20T09:35:44.878Z",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e84b",
          "name": "Zhaohai Li",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e84c",
          "name": "Jianqiang Wan",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e84d",
          "name": "Pengfei Wang",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e84e",
          "name": "Wei Ding",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e84f",
          "name": "Zheren Fu",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e850",
          "name": "Yiheng Xu",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e851",
          "name": "Jiabo Ye",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e852",
          "name": "Xi Zhang",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e853",
          "name": "Tianbao Xie",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e854",
          "name": "Zesen Cheng",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e855",
          "name": "Hang Zhang",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e856",
          "name": "Zhibo Yang",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e857",
          "user": {
            "_id": "645b10e80c73ea27d13f7aca",
            "avatarUrl": "/avatars/95e565306472a15067440b5b43e07a6f.svg",
            "isPro": false,
            "fullname": "xuhaiyang",
            "user": "xhyandwyy",
            "type": "user"
          },
          "name": "Haiyang Xu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-20T09:35:42.372Z",
          "hidden": false
        },
        {
          "_id": "67b6b0688b56622e70b9e858",
          "name": "Junyang Lin",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-19T18:00:14.000Z",
      "title": "Reporte Técnico Qwen2.5-VL\n\nEl Reporte Técnico Qwen2.5-VL detalla exhaustivamente los aspectos técnicos del modelo Qwen2.5-VL, presentando su rendimiento, características y el contexto de su desarrollo. Este documento es de gran utilidad para expertos y investigadores en la área de IA y es fundamental para comprender las últimas tendencias tecnológicas y direcciones de desarrollo.",
      "summary": "Qwen2.5-VL es el modelo líder de la serie de lenguaje visual y ha experimentado un gran avance en sus capacidades básicas y funciones innovadoras. Qwen2.5-VL ha demostrado un gran avance en la reconocimiento visual, la precisión en la localización de objetos, el análisis de documentos y la comprensión de largos videos. Una de las características notables de Qwen2.5-VL es su habilidad para especificar la posición de objetos con precisión usando cajas delimitadoras o puntos. Además, puede extraer datos estructurados fuertemente de documentos contables, formularios y tablas, así como analizar detalladamente gráficos, diagramas y red de routers. Para manejar entradas complejas, Qwen2.5-VL introdujo procesamiento de resolución dinámica y codificación de tiempo absoluto, lo que le permite procesar imágenes de diferentes tamaños y videos de larga duración (hasta tiempos continuos) en eventos de evento por segundo. Esto permite que el modelo comprenda de manera natural la escala espacial y la dinámica temporal, sin depender de métodos de normalización tradicionales. Inicialmente, aprendió una Vision Transformer (ViT) de resolución dinámica, reduciendo el sobre-cargo de cálculos mediante la inclusión de atribuciones de ventana, mientras se mantuvo la resolución dinámica. Consequentemente, Qwen2.5-VL se destaca como un agente visual interactivo para el procesamiento de comandos, el uso de herramientas y la ejecución de tareas en escenarios reales, tanto para imágenes estáticas y documentos como para interacciones como el manejo de dispositivos. Qwen2.5-VL está disponible en tres tamaños para abordar diversas aplicaciones. Como modelo líder, Qwen2.5-VL-72B compete con modelos recientes como GPT-4o y Claude 3.5 Sonnet, especialmente en la comprensión de documentos y diagramas. Además, Qwen2.5-VL mantiene las capacidades lingüísticas esenciales de Qwen2.5 LLM y mantiene un rendimiento lingüístico fuerte.",
      "upvotes": 48,
      "discussionId": "67b6b0688b56622e70b9e875"
    },
    "publishedAt": "2025-02-19T23:35:06.194Z",
    "title": "Qwen2.5-VL Technical Report",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13923.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "63451cf0a05b51f7ded25505",
      "avatarUrl": "/avatars/dec4bbee4a82b773fc58dfc2dce9dbeb.svg",
      "fullname": "shuai bai",
      "name": "bluelike",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 11
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.13144",
      "authors": [
        {
          "_id": "67b55c7fba22c1ddbb8d5746",
          "user": {
            "_id": "6536187bd34e9f02b9df1c3b",
            "avatarUrl": "/avatars/0b34d62868b93053b0a05062a018b5bd.svg",
            "isPro": false,
            "fullname": "Hao Gao",
            "user": "Hao605",
            "type": "user"
          },
          "name": "Hao Gao",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-19T09:00:48.944Z",
          "hidden": false
        },
        {
          "_id": "67b55c7fba22c1ddbb8d5747",
          "name": "Shaoyu Chen",
          "hidden": false
        },
        {
          "_id": "67b55c7fba22c1ddbb8d5748",
          "name": "Bo Jiang",
          "hidden": false
        },
        {
          "_id": "67b55c7fba22c1ddbb8d5749",
          "name": "Bencheng Liao",
          "hidden": false
        },
        {
          "_id": "67b55c7fba22c1ddbb8d574a",
          "name": "Yiang Shi",
          "hidden": false
        },
        {
          "_id": "67b55c7fba22c1ddbb8d574b",
          "name": "Xiaoyang Guo",
          "hidden": false
        },
        {
          "_id": "67b55c7fba22c1ddbb8d574c",
          "name": "Yuechuan Pu",
          "hidden": false
        },
        {
          "_id": "67b55c7fba22c1ddbb8d574d",
          "name": "Haoran Yin",
          "hidden": false
        },
        {
          "_id": "67b55c7fba22c1ddbb8d574e",
          "name": "Xiangyu Li",
          "hidden": false
        },
        {
          "_id": "67b55c7fba22c1ddbb8d574f",
          "name": "Xinbang Zhang",
          "hidden": false
        },
        {
          "_id": "67b55c7fba22c1ddbb8d5750",
          "name": "Ying Zhang",
          "hidden": false
        },
        {
          "_id": "67b55c7fba22c1ddbb8d5751",
          "name": "Wenyu Liu",
          "hidden": false
        },
        {
          "_id": "67b55c7fba22c1ddbb8d5752",
          "name": "Qian Zhang",
          "hidden": false
        },
        {
          "_id": "67b55c7fba22c1ddbb8d5753",
          "name": "Xinggang Wang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-18T18:59:21.000Z",
      "title": "RAD: Entrenamiento de políticas de conducción desde punto de partida hasta destino utilizando aprendizaje reforzado basado en 3DGS",
      "summary": "Actualmente, el algoritmo de autonomous driving (AD) desde el punto final hasta el punto final se desarrolla generalmente siguiendo el paradigma de aprendizaje en entorno embbido (IL). Este método provoca problemas como confusión causal y errores de circuitos cerrados, entre otros. En este estudio, se construye un paradigma de entrenamiento de resistencia a circuitos cerrados basado en 3DGS. Mediante la utilización de la tecnología 3DGS, se construye una imágen digital de la realidad física y se exploran amplios áreas del espacio de estados, permitiendo abordar escenarios perturbadores con errores de intentos significativos. Para mejorar la seguridad, se diseña una recompensa especial para que la política se adapte efectivamente a eventos seguros y para que comprenda las relaciones causales en la realidad. Para mejorar la coincidencia con las acciones de conducción humana, se integra el IL como término normalizador de la resistencia a circuitos cerrados. Comparando con métodos basados en IL, el RAD muestra una gran mejora en varios métricas de circuitos cerrados, especialmente al lograr un ritmo de colisiones 3 veces menor. Para más detalles sobre los resultados de circuitos cerrados, puede consultar [https://hgao-cv.github.io/RAD](https://hgao-cv.github.io/RAD).",
      "upvotes": 22,
      "discussionId": "67b55c80ba22c1ddbb8d579c"
    },
    "publishedAt": "2025-02-19T22:13:49.764Z",
    "title": "RAD: Training an End-to-End Driving Policy via Large-Scale 3DGS-based Reinforcement Learning",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13144.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6536187bd34e9f02b9df1c3b",
      "avatarUrl": "/avatars/0b34d62868b93053b0a05062a018b5bd.svg",
      "fullname": "Hao Gao",
      "name": "Hao605",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.13128",
      "authors": [
        {
          "_id": "67b6c696e9b901edeaf320d5",
          "name": "Zihan Liu",
          "hidden": false
        },
        {
          "_id": "67b6c696e9b901edeaf320d6",
          "name": "Shuangrui Ding",
          "hidden": false
        },
        {
          "_id": "67b6c696e9b901edeaf320d7",
          "name": "Zhixiong Zhang",
          "hidden": false
        },
        {
          "_id": "67b6c696e9b901edeaf320d8",
          "name": "Xiaoyi Dong",
          "hidden": false
        },
        {
          "_id": "67b6c696e9b901edeaf320d9",
          "name": "Pan Zhang",
          "hidden": false
        },
        {
          "_id": "67b6c696e9b901edeaf320da",
          "name": "Yuhang Zang",
          "hidden": false
        },
        {
          "_id": "67b6c696e9b901edeaf320db",
          "name": "Yuhang Cao",
          "hidden": false
        },
        {
          "_id": "67b6c696e9b901edeaf320dc",
          "name": "Dahua Lin",
          "hidden": false
        },
        {
          "_id": "67b6c696e9b901edeaf320dd",
          "name": "Jiaqi Wang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-18T18:52:21.000Z",
      "title": "SongGen: Inferencia de canales para la generación de música a partir de texto en un paso automático",
      "summary": "La generación de canciones es el proceso de crear un borrallo y acompañamiento a partir de un texto de entrada. Este campo enfrenta grandes desafíos debido a su complejidad y la escasez de datos. Los métodos actuales utilizan principalmente procesos de generación multi-etapa, lo que implica complejos procesos de entrenamiento y inferencia. En este artículo, se propone un modelo de aprendizaje automático de única etapa completamente abierto-código, llamado Channel-Driving Tutoring Machine. Este modelo permite controlar de manera precisa diversas características musicales, como los textos de canción, la configuración de instrumentos, el género, el ambiente y la tonalidad. Además, se ha diseñado para seleccionar un clip de referencia de 3 segundos para clonar un borrallo. Dentro de un solo marco de trabajo de recuperación automática integrado, SongGen soporta modos de mezcla de borrallo y acompañamiento, así como un modo de doble trasero. En el modo de doble trasero, SongGen permite crear canciones con un doble trasero, ofreciendo una experiencia de creación musical más controlada y efectiva.",
      "upvotes": 20,
      "discussionId": "67b6c698e9b901edeaf321a7"
    },
    "publishedAt": "2025-02-20T01:07:44.785Z",
    "title": "SongGen: A Single Stage Auto-regressive Transformer for Text-to-Song Generation",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13128.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64b4eec4faa3181a5eab9c46",
      "avatarUrl": "/avatars/bcc9bf5cbf67546ad2b4c9ec8b96ac96.svg",
      "fullname": "Jiaqi Wang",
      "name": "myownskyW7",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isMod": false,
      "followerCount": 16
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.13685",
      "authors": [
        {
          "_id": "67b6dc1ba7567156c6547880",
          "name": "Jusen Du",
          "hidden": false
        },
        {
          "_id": "67b6dc1ba7567156c6547881",
          "user": {
            "_id": "6246bb33da617c00b48e4d92",
            "avatarUrl": "/avatars/0304a9f6eb7f5dee4d933d03222f94e9.svg",
            "isPro": false,
            "fullname": "Weigao Sun",
            "user": "weigao266",
            "type": "user"
          },
          "name": "Weigao Sun",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-02-20T07:39:08.547Z",
          "hidden": false
        },
        {
          "_id": "67b6dc1ba7567156c6547882",
          "name": "Disen Lan",
          "hidden": false
        },
        {
          "_id": "67b6dc1ba7567156c6547883",
          "name": "Jiaxi Hu",
          "hidden": false
        },
        {
          "_id": "67b6dc1ba7567156c6547884",
          "name": "Yu Cheng",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-19T12:53:55.000Z",
      "title": "MoM: Modelación de Secuencias Lineales con Memoria de Memoria Confusa",
      "summary": "Los métodos de modelado secuencial lineal, como por ejemplo la acción lineal, el modelado en espacio de estados y las redes neuronales recurrentes lineales, reducen la complejidad de la entrenamiento y la inferencia proporcionando una notable mejora de eficiencia. Sin embargo, estos métodos aprenden a mantener la capacidad de memoria a largo plazo del cerebro, reduciendo la interferencia de la memoria, al compressar la entrada completa de la secuencia en un estado de memoria de tamaño fijo y reducir la interferencia de la memoria, a través de la capacidad de mantener la memoria a largo plazo del cerebro.",
      "upvotes": 16,
      "discussionId": "67b6dc1ca7567156c65478b8"
    },
    "publishedAt": "2025-02-20T02:40:09.567Z",
    "title": "MoM: Linear Sequence Modeling with Mixture-of-Memories",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13685.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6246bb33da617c00b48e4d92",
      "avatarUrl": "/avatars/0304a9f6eb7f5dee4d933d03222f94e9.svg",
      "fullname": "Weigao Sun",
      "name": "weigao266",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.13347",
      "authors": [
        {
          "_id": "67b6a7e83ef3656c48f149b9",
          "user": {
            "_id": "6135eeeb5bc6ecdf86b60f0d",
            "avatarUrl": "/avatars/43cedcf20ab6b0801a662787400e1384.svg",
            "isPro": false,
            "fullname": "Shi Yu",
            "user": "yushi",
            "type": "user"
          },
          "name": "Shi Yu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-20T09:35:47.487Z",
          "hidden": false
        },
        {
          "_id": "67b6a7e83ef3656c48f149ba",
          "name": "Zhiyuan Liu",
          "hidden": false
        },
        {
          "_id": "67b6a7e83ef3656c48f149bb",
          "name": "Chenyan Xiong",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-19T00:31:43.000Z",
      "title": "Craw4LLM: Crawling Web para Aprendizaje Profesional de LLM",
      "summary": "El web scraping es una de las principales fuentes de datos para el entrenamiento previo de modelos de lenguaje grandes (LLMs). Sin embargo, muchos páginas web recopiladas con baja calidad son desechadas durante el entrenamiento previo. Este artículo presenta una metodología eficiente de web scraping, llamada Crawl4LLM, que se adapta a las preferencias del entrenamiento previo de LLMs. En particular, Crawl4LLM utiliza la influencia de las páginas web en el entrenamiento previo para determinar el orden de prioridad de la agenda de recopilación, reemplazando la prioridad basada en la conectividad de grafos estándar. Mediante experimentos en un grafo web de 900 millones de páginas, basados en el índice de un motor de búsqueda comercial, se demuestra que Crawl4LLM puede obtener datos de entrenamiento previo de alta calidad de manera eficiente. Con solo el 21% de las URL recopiladas, un LLM entrenado con datos de Crawl4LLM alcanza un rendimiento inferior a lo observado con recopilación anterior, reduciendo significativamente la consumo de energía y la carga de los sitios web. El código está disponible en GitHub: https://github.com/cxcscmu/Crawl4LLM.",
      "upvotes": 16,
      "discussionId": "67b6a7e93ef3656c48f149f1"
    },
    "publishedAt": "2025-02-19T22:57:23.298Z",
    "title": "Craw4LLM: Efficient Web Crawling for LLM Pretraining",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13347.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6135eeeb5bc6ecdf86b60f0d",
      "avatarUrl": "/avatars/43cedcf20ab6b0801a662787400e1384.svg",
      "fullname": "Shi Yu",
      "name": "yushi",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 7
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.13922",
      "authors": [
        {
          "_id": "67b6948dbef24bad725b5d4b",
          "name": "Guanzheng Chen",
          "hidden": false
        },
        {
          "_id": "67b6948dbef24bad725b5d4c",
          "name": "Xin Li",
          "hidden": false
        },
        {
          "_id": "67b6948dbef24bad725b5d4d",
          "name": "Michael Qizhe Shieh",
          "hidden": false
        },
        {
          "_id": "67b6948dbef24bad725b5d4e",
          "name": "Lidong Bing",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-19T17:59:03.000Z",
      "title": "LongPO: Evolución automática de largo contexto en modelos de lenguaje para optimizar el estilo de textos cortos a largos",
      "summary": "Los grandes modelos de lenguaje (LLMs) muestran capacidades sorprendentes gracias a la entrenamiento previo y el ajuste. Sin embargo, en casos de contextos largos, el ajuste de contexto largo no es suficiente, lo que puede llevar a una disminución del rendimiento de los LLMs de contexto corto a alto nivel. El ajuste de contexto largo sigue problemas debido a la ineficiencia humana en contextos largos y al desafío de equilibrar el rendimiento entre contextos cortos y largos. Para resolver estos problemas, se presenta LongPO. LongPO permite que los LLMs de contexto corto transmitan las capacidades internas de manejar contextos cortos, lo que les permite mostrar un excelente rendimiento en tareas de contexto largo. LongPO entrena a los LLMs utilizando datos preferentes generados a partir de contextos cortos, incluyendo pares de entradas de contexto largo y su correspondiente compresión a contexto corto. Esta preferencia muestra la capacidad y potencial de los LLMs entrenados en contextos cortos y la disminución que ocurre en contextos largos. Además, LongPO aplica una restricción de KL desde el contexto corto hasta el contexto largo para mitigar la pérdida de rendimiento en el contexto corto durante el ajuste de contexto largo. Al aplicar LongPO a Mistral-7B-Instruct-v0.2, desde un contexto de 128K hasta 512K, se mantiene el rendimiento en contextos cortos completamente, y se supera significativamente a los métodos de SFT y DPO. En particular, los modelos entrenados con LongPO pueden competir o superar los altos niveles de LLMs con grandes escalas de parámetros y amplios ajustes de contexto largo, como GPT-4-128K.",
      "upvotes": 16,
      "discussionId": "67b6948ebef24bad725b5d84"
    },
    "publishedAt": "2025-02-19T21:35:20.931Z",
    "title": "LongPO: Long Context Self-Evolution of Large Language Models through Short-to-Long Preference Optimization",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13922.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "645475e2548f22be59847604",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/645475e2548f22be59847604/EhSurrZ25u31qQ2TVXQXt.jpeg",
      "fullname": "Chen",
      "name": "Guanzheng",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.12143",
      "authors": [
        {
          "_id": "67b4d05a9f8a8ab661450397",
          "name": "Yuetai Li",
          "hidden": false
        },
        {
          "_id": "67b4d05a9f8a8ab661450398",
          "name": "Xiang Yue",
          "hidden": false
        },
        {
          "_id": "67b4d05a9f8a8ab661450399",
          "user": {
            "_id": "653df1323479e9ebbe3eb6cc",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/653df1323479e9ebbe3eb6cc/K_g-r1iMRNKj99LXPuYF3.jpeg",
            "isPro": true,
            "fullname": "Zhangchen Xu",
            "user": "flydust",
            "type": "user"
          },
          "name": "Zhangchen Xu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-20T09:37:32.715Z",
          "hidden": false
        },
        {
          "_id": "67b4d05a9f8a8ab66145039a",
          "name": "Fengqing Jiang",
          "hidden": false
        },
        {
          "_id": "67b4d05a9f8a8ab66145039b",
          "name": "Luyao Niu",
          "hidden": false
        },
        {
          "_id": "67b4d05a9f8a8ab66145039c",
          "name": "Bill Yuchen Lin",
          "hidden": false
        },
        {
          "_id": "67b4d05a9f8a8ab66145039d",
          "name": "Bhaskar Ramasubramanian",
          "hidden": false
        },
        {
          "_id": "67b4d05a9f8a8ab66145039e",
          "name": "Radha Poovendran",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-17T18:56:15.000Z",
      "title": "Pequeños modelos tienen dificultades para aprender de fuertes debaters.",
      "summary": "Los modelos de lenguaje grandes (LLMs) muestran excelente rendimiento en tareas teóricas complejas. El éxito experimental de que su capacidad teórica se absorba en pequeños modelos es interesante. Sin embargo, hemos encontrado un fenómeno intrigante que llamamos \"error de aprendizaje de pequeños modelos\". Los pequeños modelos (con menos de 3B parámetros) muestran mejores resultados en cadenas de razonamiento cortas y simples, en comparación con cadenas de razonamiento largas (Chain-of-Thought, CoT) o con modelos grandes. En cambio, proponemos una estrategia sencilla y efectiva llamada \"Mix Distillation\" para enfrentar este fenómeno. Esta estrategia combina razonamientos de largo y corto CoT, o de modelos grandes y pequeños, para equilibrar la complejidad de la razonamiento. Nuestras experimentaciones muestran que la Mix Distillation mejora significativamente el rendimiento teórico de pequeños modelos que dependen exclusivamente de datos entrenados. Estos hallazgos directamente destacan las limitaciones de los diseños de modelos grandes y subrayan la importancia de equilibrar la complejidad de la razonamiento para un movimiento hacia una capacidad teórica efectiva.",
      "upvotes": 12,
      "discussionId": "67b4d05b9f8a8ab6614503cb"
    },
    "publishedAt": "2025-02-19T21:38:13.468Z",
    "title": "Small Models Struggle to Learn from Strong Reasoners",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.12143.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "653df1323479e9ebbe3eb6cc",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/653df1323479e9ebbe3eb6cc/K_g-r1iMRNKj99LXPuYF3.jpeg",
      "fullname": "Zhangchen Xu",
      "name": "flydust",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isMod": false,
      "followerCount": 8
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.13965",
      "authors": [
        {
          "_id": "67b6a3fa09841367596a1db5",
          "name": "Michael Luo",
          "hidden": false
        },
        {
          "_id": "67b6a3fa09841367596a1db6",
          "name": "Xiaoxiang Shi",
          "hidden": false
        },
        {
          "_id": "67b6a3fa09841367596a1db7",
          "name": "Colin Cai",
          "hidden": false
        },
        {
          "_id": "67b6a3fa09841367596a1db8",
          "name": "Tianjun Zhang",
          "hidden": false
        },
        {
          "_id": "67b6a3fa09841367596a1db9",
          "name": "Justin Wong",
          "hidden": false
        },
        {
          "_id": "67b6a3fa09841367596a1dba",
          "user": {
            "_id": "626e3449e7914f0d5ea78ad1",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/626e3449e7914f0d5ea78ad1/pVzdmdPMpNcxuj94qiIvB.jpeg",
            "isPro": false,
            "fullname": "Yichuan",
            "user": "Chrisyichuan",
            "type": "user"
          },
          "name": "Yichuan Wang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-20T09:35:50.487Z",
          "hidden": false
        },
        {
          "_id": "67b6a3fa09841367596a1dbb",
          "name": "Chi Wang",
          "hidden": false
        },
        {
          "_id": "67b6a3fa09841367596a1dbc",
          "name": "Yanping Huang",
          "hidden": false
        },
        {
          "_id": "67b6a3fa09841367596a1dbd",
          "name": "Zhifeng Chen",
          "hidden": false
        },
        {
          "_id": "67b6a3fa09841367596a1dbe",
          "name": "Joseph E. Gonzalez",
          "hidden": false
        },
        {
          "_id": "67b6a3fa09841367596a1dbf",
          "name": "Ion Stoica",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-19T18:59:30.000Z",
      "title": "Oterrix: Motor de servicio eficiente de un agente de lenguaje grande (un programa general)",
      "summary": "Los aplicaciones de modelos de lenguaje grande (LLM) han evolucionado más allá de simples chatbots, desarrollando programación de agentes para tareas generales dinámicas. Estos programas ayudan a los agentes AI a explorar y resolver tareas complejas de manera racional, escalando llamadas a LLM y tokens de salida. Sin embargo, los sistemas de servicio actuales de LLM ignoran la dependencia entre programación y llamada, perdiendo oportunidades de optimización importantes. Según nuestro análisis, los programas que se presentan al motor de servicio de LLM suelen recibir largos tiempos de espera acumulados debido a solicitudes individuales de LLM y el broking de cabezas de programa. En respuesta a esto, presentamos \"Autellix\", un sistema que trata a los programas como ciudadanos de primera clase en el servicio de LLM. Autellix inserta llamadas a LLM desde los programas y asigna contexto al nivel del programa al scheduler. Proponemos dos algoritmos de scheduling para programas en solo-hilo y distribuido: priorizar y preparar previamente llamadas a LLM basadas en la completación anterior del programa. Nuestra evaluación muestra que, en tiempos de ejecución iguales, Autellix mejora las transacciones de programa en un 4 a 15 veces en diferentes LLM y cargas de trabajo de agente, comparado con los mejores sistemas (por ejemplo, vLLM).",
      "upvotes": 11,
      "discussionId": "67b6a3fb09841367596a1e06"
    },
    "publishedAt": "2025-02-19T22:42:06.502Z",
    "title": "Autellix: An Efficient Serving Engine for LLM Agents as General Programs",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13965.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "654037be97949fd2304aab7f",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/654037be97949fd2304aab7f/2cSME81gcwYa2OTeVlq5Q.jpeg",
      "fullname": "Michael Luo",
      "name": "michaelzhiluo",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.13946",
      "authors": [
        {
          "_id": "67b6b416b4ad845374143c31",
          "name": "Chak Tou Leong",
          "hidden": false
        },
        {
          "_id": "67b6b416b4ad845374143c32",
          "name": "Qingyu Yin",
          "hidden": false
        },
        {
          "_id": "67b6b416b4ad845374143c33",
          "name": "Jian Wang",
          "hidden": false
        },
        {
          "_id": "67b6b416b4ad845374143c34",
          "name": "Wenjie Li",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-19T18:42:45.000Z",
      "title": "¿Por qué no se hundien las embarcaciones protegidas? La estructura de seguridad de los grandes modelos de lenguaje arreglados está casi fijada en las regiones de templates.",
      "summary": "La seguridad de los modelos de lenguaje grande (LLMs) está en un estado débil y pueden ser fácilmente destruidos por ataques complejos. En los modelos existentes de LLMs, es común incluir un templado fijo entre las instrucciones de entrada y la primera salida del modelo, lo cual se supone que puede actuar como una clave vulnerable: la diseño de seguridad en los LLMs depende excesivamente de la información integrada en el área del templado, lo cual afecta significativamente el comportamiento seguro de estos modelos. Esta problemática se denomina \"seguridad del templado\". En este artículo, se realizan experimentos extendidos para demostrar que existe seguridad del templado en muchos modelos de LLMs. El análisis estructural muestra que este problema afecta la seguridad de los modelos de manera que los ataques destructivos puedan explotar sus vulnerabilidades. Además, se indica que es deseable separar las funciones de seguridad del área del templado para inhibir las vulnerabilidades frente a ataques destructivos. En futuras investigaciones, se buscarán métodos para reducir la dependencia del templado, lo que podría impulsar la desarrollo de tecnologías de seguridad más potentes.",
      "upvotes": 7,
      "discussionId": "67b6b416b4ad845374143c5b"
    },
    "publishedAt": "2025-02-19T23:54:57.669Z",
    "title": "Why Safeguarded Ships Run Aground? Aligned Large Language Models' Safety Mechanisms Tend to Be Anchored in The Template Region",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13946.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "631326d6289cf15634c52369",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/631326d6289cf15634c52369/lmPWGHLsQ36H556cqcXjT.jpeg",
      "fullname": "Cooper Leong",
      "name": "cooperleong00",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 5
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.13173",
      "authors": [
        {
          "_id": "67b6b014f7e569081326494f",
          "name": "Wang Yang",
          "hidden": false
        },
        {
          "_id": "67b6b014f7e5690813264950",
          "name": "Hongye Jin",
          "hidden": false
        },
        {
          "_id": "67b6b014f7e5690813264951",
          "name": "Jingfeng Yang",
          "hidden": false
        },
        {
          "_id": "67b6b014f7e5690813264952",
          "name": "Vipin Chaudhary",
          "hidden": false
        },
        {
          "_id": "67b6b014f7e5690813264953",
          "name": "Xiaotian Han",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-17T19:56:21.000Z",
      "title": "Preferencia de Pensamiento Optimización",
      "summary": "Supervised Fine-Tuning (SFT) es un método efectivo para mejorar la capacidad de largo CoT (Chain-of-Thought) en un pequeño LLM utilizando respuestas largas de CoT obtenidas de un grande LLM. Este método se complementa con la SFT. Para continuar mejorando la capacidad de largo CoT, se considera la recopilación de nuevos datos de SFT de alta calidad o la retrenamiento de los conjuntos de datos de SFT existentes. Sin embargo, obtener nuevos datos de SFT de largo CoT implica costos y limitaciones, y la retrenamiento repetitivo puede provocar patrones de desempeño o declinación. Se propone Thinking Preference Optimization (ThinkPO) como una forma de mejorar la calidad de los datos de SFT. ThinkPO selecciona respuestas de largo CoT para la misma pregunta, incluso cuando se eliminen respuestas de corto CoT. Además, se aplica una optimización directa de preferencias para incentivar al modelo a preferir largos resultados de lógica. Los experimentos muestran que ThinkPO mejora la capacidad de lógica de los modelos SFT, aumentando, por ejemplo, la tasa de respuestas correctas en matemáticas en un 8.6% y la longitud de la respuesta en un 25.9%. En particular, ThinkPO puede continuamente mejorar el desempeño de modelos SFT publicos, como aumentar la performance en MATH500 del modelo DeepSeek-R1-Distill-Qwen-7B de 87.4% a 91.2%.",
      "upvotes": 7,
      "discussionId": "67b6b015f7e56908132649a0"
    },
    "publishedAt": "2025-02-19T23:31:36.410Z",
    "title": "Thinking Preference Optimization",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13173.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 6149
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.13962",
      "authors": [
        {
          "_id": "67b691751f861500916ecd5d",
          "user": {
            "_id": "6372bc95c4267fd7cd77f4d0",
            "avatarUrl": "/avatars/17a24af68f45487e601687d777b352b6.svg",
            "isPro": false,
            "fullname": "William Jurayj",
            "user": "wjurayj",
            "type": "user"
          },
          "name": "William Jurayj",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-20T09:36:09.674Z",
          "hidden": false
        },
        {
          "_id": "67b691751f861500916ecd5e",
          "name": "Jeffrey Cheng",
          "hidden": false
        },
        {
          "_id": "67b691751f861500916ecd5f",
          "name": "Benjamin Van Durme",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-19T18:58:31.000Z",
      "title": "Esta es la respuesta final. La programación de tiempo mejora la respuesta a los problemas de elección.",
      "summary": "Los modelos de lenguaje de gran escala que han aumentado la cantidad de cálculos durante el tiempo de prueba han demostrado un desempeño sorprendente en los marcadores de lógica. Sin embargo, la evaluación de la escalabilidad en el tiempo de prueba actual asume que los sistemas de lógica necesitan responder a las preguntas proporcionadas. Esto evita preocupaciones sobre si el modelo tiene confianza en su respuesta y si proporcionar una respuesta siempre es adecuada. Para abordar estas preocupaciones, se extrae un Score de Confianza en el momento de la lógica para evaluar las respuestas del modelo. De esta manera, aumentar la carga de cálculo en el tiempo de inferencia puede aumentar la probabilidad de que el modelo responda correctamente y aumentar la confianza en las respuestas correctas. Además, se expande el patrón de respuestas sin riesgo actual y se propone un método para evaluar y reportar la evaluación considerando configuraciones donde el riesgo de la respuesta no es cero.",
      "upvotes": 6,
      "discussionId": "67b691761f861500916ecd8e"
    },
    "publishedAt": "2025-02-19T23:34:43.424Z",
    "title": "Is That Your Final Answer? Test-Time Scaling Improves Selective Question Answering",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13962.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 6149
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.13233",
      "authors": [
        {
          "_id": "67b689aeba514d2c2c969289",
          "user": {
            "_id": "64beb6b6140491ca9f803ebf",
            "avatarUrl": "/avatars/0daa2e813a13668b8b708cd8c12763d9.svg",
            "isPro": false,
            "fullname": "Yucheng SHi",
            "user": "YuchengShi",
            "type": "user"
          },
          "name": "Yucheng Shi",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-20T09:36:18.925Z",
          "hidden": false
        },
        {
          "_id": "67b689aeba514d2c2c96928a",
          "name": "Tianze Yang",
          "hidden": false
        },
        {
          "_id": "67b689aeba514d2c2c96928b",
          "name": "Canyu Chen",
          "hidden": false
        },
        {
          "_id": "67b689aeba514d2c2c96928c",
          "name": "Quanzheng Li",
          "hidden": false
        },
        {
          "_id": "67b689aeba514d2c2c96928d",
          "name": "Tianming Liu",
          "hidden": false
        },
        {
          "_id": "67b689aeba514d2c2c96928e",
          "name": "Xiang Li",
          "hidden": false
        },
        {
          "_id": "67b689aeba514d2c2c96928f",
          "name": "Ninghao Liu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-18T19:12:15.000Z",
      "title": "SearchRAG: ¿Puede un motor de búsqueda basado en el lenguaje natural (LLM) ayudar a proporcionar respuestas médicas basadas en la búsqueda?",
      "summary": "Los modelos de lenguaje generalizados (LLMs) muestran excelentes capacidades en diversas áreas, pero a menudo enfrentan desafíos cuando se trata de tareas que requieren conocimientos específicos. Los métodos comunes de generación de literatura y búsqueda (RAG) obtienen información externa de bases de conocimiento estáticas, pero son ineficientes y pueden faltar en detalles específicos que son necesarios para una consulta médica precisa. En este artículo, proponemos un nuevo marco de trabajo llamado \"SearchRAG\" que utiliza un motor de búsqueda en tiempo real para superar los límites de los métodos RAG. Nuestro enfoque crea un caché de síntesis para convertir consultas complejas de atención médica en preguntas que se pueden procesar por un motor de búsqueda, y utiliza un proceso de selección de conocimiento basado en probabilidades para filtrar la información más relevante para ser incluida en la entrada del LLM. Los resultados de los experimentos muestran que nuestro enfoque significativamente mejora la precisión de las respuestas a las consultas médicas y es especialmente efectivo para abordar problemas complejos que requieren información detallada y actualizada.",
      "upvotes": 6,
      "discussionId": "67b689aeba514d2c2c9692b9"
    },
    "publishedAt": "2025-02-19T22:27:22.403Z",
    "title": "SearchRAG: Can Search Engines Be Helpful for LLM-based Medical Question Answering?",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13233.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64beb6b6140491ca9f803ebf",
      "avatarUrl": "/avatars/0daa2e813a13668b8b708cd8c12763d9.svg",
      "fullname": "Yucheng SHi",
      "name": "YuchengShi",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.13943",
      "authors": [
        {
          "_id": "67b6a9a7c721bee91cac2888",
          "name": "Yuliang Liu",
          "hidden": false
        },
        {
          "_id": "67b6a9a7c721bee91cac2889",
          "name": "Junjie Lu",
          "hidden": false
        },
        {
          "_id": "67b6a9a7c721bee91cac288a",
          "name": "Zhaoling Chen",
          "hidden": false
        },
        {
          "_id": "67b6a9a7c721bee91cac288b",
          "name": "Chaofeng Qu",
          "hidden": false
        },
        {
          "_id": "67b6a9a7c721bee91cac288c",
          "name": "Jason Klein Liu",
          "hidden": false
        },
        {
          "_id": "67b6a9a7c721bee91cac288d",
          "name": "Chonghan Liu",
          "hidden": false
        },
        {
          "_id": "67b6a9a7c721bee91cac288e",
          "name": "Zefan Cai",
          "hidden": false
        },
        {
          "_id": "67b6a9a7c721bee91cac288f",
          "name": "Yunhui Xia",
          "hidden": false
        },
        {
          "_id": "67b6a9a7c721bee91cac2890",
          "name": "Li Zhao",
          "hidden": false
        },
        {
          "_id": "67b6a9a7c721bee91cac2891",
          "name": "Jiang Bian",
          "hidden": false
        },
        {
          "_id": "67b6a9a7c721bee91cac2892",
          "name": "Chuheng Zhang",
          "hidden": false
        },
        {
          "_id": "67b6a9a7c721bee91cac2893",
          "name": "Wei Shen",
          "hidden": false
        },
        {
          "_id": "67b6a9a7c721bee91cac2894",
          "name": "Zhouhan Lin",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-19T18:35:55.000Z",
      "title": "AdaptiveStep: Divide el proceso lógico de un modelo automáticamente mediante la confianza del modelo.",
      "summary": "Los actuales modelos de recompensa de proceso (PRMs) utilizan un enfoque de entrenamiento basado en reglas, y se decomponen las razones en varios pasos de teoría. Por ejemplo, se utilizan etiquetas de símbolos de divinación para establecer la longitud de los pasos de teoría de un tamaño fijo. Este enfoque falla en no reconocer que ciertos palabras marcan realmente puntos de decisión en la oración. En este sentido, proponemos AdaptiveStep. AdaptiveStep divide los pasos de teoría basándose en la predicción del próximo palabra por el modelo. Este método proporciona más información de decisión en cada paso, mejorando así el desempeño en tareas posteriores. Además, nuestro método no requiere anotaciones manuales. Hemos demostrado el efecto de entrenar PRMs con AdaptiveStep en tareas de razonamiento matemático y generación de código, mostrando los resultados experimentales. Los resultados muestran que los PRMs alcanzan el mejor rendimiento de \"mejor de N\" y superan la estrategia de búsqueda greedy utilizando decodificación de valores de token, además de reducir en al menos 30% los costos de implementación en comparación con PRMs abiertos. Además, proporcionamos un análisis detallado y estudios de casos sobre el rendimiento, transitividad y capacidad de generalización de los PRMs.",
      "upvotes": 5,
      "discussionId": "67b6a9a8c721bee91cac28e7"
    },
    "publishedAt": "2025-02-19T23:07:01.367Z",
    "title": "AdaptiveStep: Automatically Dividing Reasoning Step through Model Confidence",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13943.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6529f79e802e3d1a4f8ec662",
      "avatarUrl": "/avatars/d05320c370a6497d8792ef5acb563dd5.svg",
      "fullname": "Yuliang Liu",
      "name": "yuliang03181",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.12638",
      "authors": [
        {
          "_id": "67b6acdb3a3df2f965e7af0b",
          "name": "Zhiyuan Liu",
          "hidden": false
        },
        {
          "_id": "67b6acdb3a3df2f965e7af0c",
          "name": "Yanchen Luo",
          "hidden": false
        },
        {
          "_id": "67b6acdb3a3df2f965e7af0d",
          "name": "Han Huang",
          "hidden": false
        },
        {
          "_id": "67b6acdb3a3df2f965e7af0e",
          "name": "Enzhi Zhang",
          "hidden": false
        },
        {
          "_id": "67b6acdb3a3df2f965e7af0f",
          "name": "Sihang Li",
          "hidden": false
        },
        {
          "_id": "67b6acdb3a3df2f965e7af10",
          "name": "Junfeng Fang",
          "hidden": false
        },
        {
          "_id": "67b6acdb3a3df2f965e7af11",
          "name": "Yaorui Shi",
          "hidden": false
        },
        {
          "_id": "67b6acdb3a3df2f965e7af12",
          "user": {
            "_id": "65fca775fa59bdf4737b1a84",
            "avatarUrl": "/avatars/a161b510bde8f57e7686cbb0b4aa6a52.svg",
            "isPro": false,
            "fullname": "Xiang Wang",
            "user": "xiangwang1223",
            "type": "user"
          },
          "name": "Xiang Wang",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-02-20T04:17:33.860Z",
          "hidden": false
        },
        {
          "_id": "67b6acdb3a3df2f965e7af13",
          "name": "Kenji Kawaguchi",
          "hidden": false
        },
        {
          "_id": "67b6acdb3a3df2f965e7af14",
          "name": "Tat-Seng Chua",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-18T08:40:13.000Z",
      "title": "NExT-Mol: 3D Distribución y 1D Modelado de Lenguaje para la Generación de Moléculas 3D",
      "summary": "La generación de moléculas 3D es crucial en la descubrimiento de fármacos y diseño de materiales. Los esfuerzos previos han enfocado en los beneficios de los modelos de dispersión 3D, pero han ignorado los ventajas de los modelos de lenguaje basados en SELF-ATTENTION (SELF-ATTENTION) 1D. Los modelos de lenguaje pueden generar moléculas válidas y utilizan conjuntos de datos de moléculas 1D de un billón de moléculas. Combinando estos beneficios, proponemos NExT-Mol: una integración de modelos de dispersión 3D y de modelado de lenguaje 1D para la generación de moléculas 3D. NExT-Mol utiliza un modelo de lenguaje de moléculas 1D amplio para generar moléculas 1D y predice la estructura 3D de estas moléculas. Mejoramos el rendimiento de NExT-Mol al expandir el tamaño del modelo de lenguaje, mejorar la estructura del modelo de dispersión y aplicar entrenamiento de transición entre 1D y 3D. En particular, el modelo de lenguaje 1D garantiza la validez de las moléculas y supera los límites de la similitud dispersiva. Además, el modelo de dispersión 3D alcanza un rendimiento líder en la predicción de estructuras. Con el mejoramiento de los modelos 1D y 3D, NExT-Mol logra un aumento relativo del 26% en la generación de moléculas 3D en GEOM-DRUGS y un efecto relativo medio del 13% en la generación condicional de moléculas 3D en QM9-2014. Nuestro código y los chekpoints se publican en https://github.com/acharkq/NExT-Mol.",
      "upvotes": 3,
      "discussionId": "67b6acdd3a3df2f965e7af85"
    },
    "publishedAt": "2025-02-19T23:18:32.647Z",
    "title": "NExT-Mol: 3D Diffusion Meets 1D Language Modeling for 3D Molecule Generation",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.12638.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6310a3cd531cc21f9e06de6a",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6310a3cd531cc21f9e06de6a/aTGMx3O41lUARK9s3dAik.jpeg",
      "fullname": "Zhiyuan Liu",
      "name": "acharkq",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.13581",
      "authors": [
        {
          "_id": "67b6ee04412c9eccae5151f5",
          "user": {
            "_id": "64a62c2f500beb50968e5c9c",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/wfL3ojJmXqyzGUmCblPf4.jpeg",
            "isPro": false,
            "fullname": "Yupeng Hou",
            "user": "hyp1231",
            "type": "user"
          },
          "name": "Yupeng Hou",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-20T09:35:14.498Z",
          "hidden": false
        },
        {
          "_id": "67b6ee04412c9eccae5151f6",
          "name": "Jianmo Ni",
          "hidden": false
        },
        {
          "_id": "67b6ee04412c9eccae5151f7",
          "name": "Zhankui He",
          "hidden": false
        },
        {
          "_id": "67b6ee04412c9eccae5151f8",
          "name": "Noveen Sachdeva",
          "hidden": false
        },
        {
          "_id": "67b6ee04412c9eccae5151f9",
          "name": "Wang-Cheng Kang",
          "hidden": false
        },
        {
          "_id": "67b6ee04412c9eccae5151fa",
          "name": "Ed H. Chi",
          "hidden": false
        },
        {
          "_id": "67b6ee04412c9eccae5151fb",
          "name": "Julian McAuley",
          "hidden": false
        },
        {
          "_id": "67b6ee04412c9eccae5151fc",
          "name": "Derek Zhiyuan Cheng",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-19T09:45:29.000Z",
      "title": "ActionPiece: Tokenización secuencial de acciones basada en contexto para recomendación generativa",
      "summary": "La generación de recomendaciones (GR) es un nuevo paradigma que transforma las acciones del usuario en patrones de tokens dispersos para predecirlas automáticamente. Sin embargo, los modelos actuales de GR tokenizan independientemente cada acción y asignan el mismo token fijo para la misma acción en todos los secuencias, sin considerar las relaciones contextuales. Esta falta de conocimiento contextual hace que el modelo no pueda considerar que la misma acción puede tener diferentes significados según el contexto alrededor, lo que puede reducir su rendimiento. Para solucionar estos problemas, proponemos ActionPiece. En ActionPiece, se considera explícitamente el contexto al tokenizar secuencias de acciones. Cada acción se representa como un conjunto de vectores de características de los ítems, que se utilizan como tokens iniciales. Se combinan patrones de vectores de características a partir de los datos de corpus de secuencias de acciones, y se construye un diccionario considerando la frecuencia de coexistencia. Debido a que el orden de los vectores de características no importa, se introdujo la normalización de intercambio para generar múltiples particiones de secuencias de acciones con el mismo significado. Los resultados de los experimentos en conjuntos de datos publicos muestran que ActionPiece mejora significativamente el rendimiento comparado con los métodos de tokenización de acciones existentes, aumentando la NDCG@10 en un rango de 6.00% a 12.82%.",
      "upvotes": 2,
      "discussionId": "67b6ee04412c9eccae515223"
    },
    "publishedAt": "2025-02-20T03:56:54.121Z",
    "title": "ActionPiece: Contextually Tokenizing Action Sequences for Generative Recommendation",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13581.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64a62c2f500beb50968e5c9c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/wfL3ojJmXqyzGUmCblPf4.jpeg",
      "fullname": "Yupeng Hou",
      "name": "hyp1231",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 5
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.11995",
      "authors": [
        {
          "_id": "67b65bbe0d878eff1a6b111d",
          "name": "Siddhesh Pawar",
          "hidden": false
        },
        {
          "_id": "67b65bbe0d878eff1a6b111e",
          "name": "Arnav Arora",
          "hidden": false
        },
        {
          "_id": "67b65bbe0d878eff1a6b111f",
          "name": "Lucie-Aimée Kaffee",
          "hidden": false
        },
        {
          "_id": "67b65bbe0d878eff1a6b1120",
          "user": {
            "_id": "608918b7df398c3b285ce960",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1621507769190-608918b7df398c3b285ce960.jpeg",
            "isPro": false,
            "fullname": "Isabelle Augenstein",
            "user": "IAugenstein",
            "type": "user"
          },
          "name": "Isabelle Augenstein",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-20T09:36:32.278Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-17T16:35:15.000Z",
      "title": "La reconocida cultura: ¿Cómo afecta el nombre a las respuestas de un modelo de lenguaje?",
      "summary": "El nombre está profundamente vinculado con la identidad humana. Los nombres desempeñan el papel de marcadores de las características personales, el patrimonio cultural y la historia personal de las personas. Sin embargo, cuando se utilizan como indicadores centrales de identificación, se asocian con la simplificación de la identificación compleja. En la interacción con un Modelo de Lenguaje de Gran Tamaño (LLM), el nombre del usuario es una información fundamental para la personalización. El nombre ingresa al diálogo de chatbot a través de los datos directos del usuario (solicitados por el chatbot) y se almacena en la memoria interna para personalizar el contexto de trabajo (revisión de CV, etc.). Estamos investigando las biases relacionadas con los nombres y medimos la predicción cultural en las respuestas generadas a consultas que buscan sugerencias generales. Esta análisis muestra una fuerte predicción de la identidad cultural asociada con los nombres en la generación de los LLM en varias culturas. Nuestro estudio influye en el diseño de sistemas de procesamiento más complejos para evitar las biases mientras mantiene una personalización significativa.",
      "upvotes": 1,
      "discussionId": "67b65bbf0d878eff1a6b1174"
    },
    "publishedAt": "2025-02-20T01:20:46.431Z",
    "title": "Presumed Cultural Identity: How Names Shape LLM Responses",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.11995.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60c50f18754747f54fa37114",
      "avatarUrl": "/avatars/648ae58b81806dbd93a68546666047e3.svg",
      "fullname": "Siddhesh",
      "name": "sidicity",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.11573",
      "authors": [
        {
          "_id": "67b6f629d9da6999328e38f5",
          "name": "Congkai Xie",
          "hidden": false
        },
        {
          "_id": "67b6f629d9da6999328e38f6",
          "name": "Shuo Cai",
          "hidden": false
        },
        {
          "_id": "67b6f629d9da6999328e38f7",
          "name": "Wenjun Wang",
          "hidden": false
        },
        {
          "_id": "67b6f629d9da6999328e38f8",
          "name": "Pengxiang Li",
          "hidden": false
        },
        {
          "_id": "67b6f629d9da6999328e38f9",
          "name": "Zhijie Sang",
          "hidden": false
        },
        {
          "_id": "67b6f629d9da6999328e38fa",
          "name": "Kejing Yang",
          "hidden": false
        },
        {
          "_id": "67b6f629d9da6999328e38fb",
          "name": "Yiming Zhang",
          "hidden": false
        },
        {
          "_id": "67b6f629d9da6999328e38fc",
          "name": "Zhen Li",
          "hidden": false
        },
        {
          "_id": "67b6f629d9da6999328e38fd",
          "name": "Guanghao Zhu",
          "hidden": false
        },
        {
          "_id": "67b6f629d9da6999328e38fe",
          "name": "Zeyu Liu",
          "hidden": false
        },
        {
          "_id": "67b6f629d9da6999328e38ff",
          "name": "Yang Yu",
          "hidden": false
        },
        {
          "_id": "67b6f629d9da6999328e3900",
          "name": "Yuhang Liu",
          "hidden": false
        },
        {
          "_id": "67b6f629d9da6999328e3901",
          "name": "Su Lu",
          "hidden": false
        },
        {
          "_id": "67b6f629d9da6999328e3902",
          "name": "Baoyi He",
          "hidden": false
        },
        {
          "_id": "67b6f629d9da6999328e3903",
          "name": "Qi Zhou",
          "hidden": false
        },
        {
          "_id": "67b6f629d9da6999328e3904",
          "name": "Xiaotian Han",
          "hidden": false
        },
        {
          "_id": "67b6f629d9da6999328e3905",
          "name": "Jianbo Yuan",
          "hidden": false
        },
        {
          "_id": "67b6f629d9da6999328e3906",
          "name": "Shengyu Zhang",
          "hidden": false
        },
        {
          "_id": "67b6f629d9da6999328e3907",
          "name": "Fei Wu",
          "hidden": false
        },
        {
          "_id": "67b6f629d9da6999328e3908",
          "name": "Hongxia Yang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-17T09:07:32.000Z",
      "title": "InfiR : Método de Creación de Modelos de Lenguaje Pequeños Efectivos y de Modelos de Lenguaje Pequeños Multimodelo Basado en Causas",
      "summary": "Los Grandes Modelos de Lenguaje (GMLs) y los Grandes Modelos de Lenguaje Multimodal (GMLMs) han marcado un gran avance en el desarrollo de la inteligencia artificial. Sin embargo, estos modelos presentan problemas como altas demandas computacionales y problemas de privacidad, entre otros. En este artículo, nos centramos en el desarrollo de Modelos de Lenguaje Pequeños (MLPs) y Modelos de Lenguaje Multimodal Pequeños (MLMPs) para mantener una fuerte inteligencia artificial. Presentamos un nuevo proceso de entrenamiento para mejorar la inteligencia artificial, con el objetivo de alcanzar los mejores resultados posibles mientras minimizamos los costos de desarrollo. InfR establece como objetivo el fomento del desarrollo de sistemas de inteligencia artificial, mejorando la inteligencia artificial, reduciendo la incidencia de discapacidad de trabajo y resolver problemas de privacidad, al utilizar modelos de pequeño tamaño. Los recursos están disponibles en https://github.com/Reallm-Labs/InfiR.",
      "upvotes": 0,
      "discussionId": "67b6f62ad9da6999328e3955"
    },
    "publishedAt": "2025-02-20T04:32:22.011Z",
    "title": "InfiR : Crafting Effective Small Language Models and Multimodal Small Language Models in Reasoning",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.11573.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "618c1ad1c74578e0a4a4d074",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/618c1ad1c74578e0a4a4d074/8u_AkeHt4d6xtQ8hzaffU.jpeg",
      "fullname": "Drishti Sharma",
      "name": "DrishtiSharma",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 60
    },
    "isAuthorParticipating": false
  }
]