[
  {
    "paper": {
      "id": "2502.01506",
      "authors": [
        {
          "_id": "67a4214f12b90b15dc5a648e",
          "name": "Yuzhe Yang",
          "hidden": false
        },
        {
          "_id": "67a4214f12b90b15dc5a648f",
          "name": "Yifei Zhang",
          "hidden": false
        },
        {
          "_id": "67a4214f12b90b15dc5a6490",
          "name": "Minghao Wu",
          "hidden": false
        },
        {
          "_id": "67a4214f12b90b15dc5a6491",
          "name": "Kaidi Zhang",
          "hidden": false
        },
        {
          "_id": "67a4214f12b90b15dc5a6492",
          "name": "Yunmiao Zhang",
          "hidden": false
        },
        {
          "_id": "67a4214f12b90b15dc5a6493",
          "name": "Honghai Yu",
          "hidden": false
        },
        {
          "_id": "67a4214f12b90b15dc5a6494",
          "name": "Yan Hu",
          "hidden": false
        },
        {
          "_id": "67a4214f12b90b15dc5a6495",
          "name": "Benyou Wang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-03T16:39:48.000Z",
      "title": "Twinmark: Comportamiento de intercambio en el mercado financiero y socialización",
      "summary": "La investigación de fenómenos sociales ha sido un foco central en la sociología durante mucho tiempo. Los métodos tradicionales de modelado, como los Agent-Based Models (ABMs) basados en reglas, no pudieron capturar la diversidad y complejidad de los comportamientos humanos, que incluían elementos irracionales. Recientemente, los modelos de lenguaje de gran tamaño (LLM) han sido introducidos como herramientas de simulación para modelar y desempeñar roles en la sociología. Estos modelos muestran que pueden considerar efectos cognitivos, cambios emocionales y otros factores irracionales, contribuyendo a la simulación de dinámicas sociales y económicas más realistas. En este artículo, se presenta un nuevo marco de trabajo multi-agente llamado TwinMarket, que utiliza LLM para simular sistemas socioeconómicos. Específicamente, se observa cómo los comportamientos individuales interactúan y forman estructuras de retroalimentación, generando fenómenos colectivos. Las experimentos realizados en un entorno de mercado de acciones muestran cómo los comportamientos individuales pueden llevar a la emergencia de comportamientos colectivos, como crisis financieras y desbalances, proporcionando valiosas insights sobre la compleja interacción entre decisiones individuales y patrones socioeconómicos colectivos.",
      "upvotes": 21,
      "discussionId": "67a4215212b90b15dc5a650a"
    },
    "publishedAt": "2025-02-05T21:44:36.248Z",
    "title": "TwinMarket: A Scalable Behavioral and Social Simulation for Financial Markets",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01506.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "643c047326f177a3e41627b6",
      "avatarUrl": "/avatars/ade75cebd049daf080ba80a80d516240.svg",
      "fullname": "Yifei Zhang",
      "name": "amstrongzyf",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.03373",
      "authors": [
        {
          "_id": "67a42c079a4fb11b11cc4f6f",
          "name": "Edward Yeo",
          "hidden": false
        },
        {
          "_id": "67a42c079a4fb11b11cc4f70",
          "name": "Yuxuan Tong",
          "hidden": false
        },
        {
          "_id": "67a42c079a4fb11b11cc4f71",
          "name": "Morry Niu",
          "hidden": false
        },
        {
          "_id": "67a42c079a4fb11b11cc4f72",
          "name": "Graham Neubig",
          "hidden": false
        },
        {
          "_id": "67a42c079a4fb11b11cc4f73",
          "name": "Xiang Yue",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-05T17:13:32.000Z",
      "title": "El descifrado del misterio de la memoria del cuerpo humano por un LLM",
      "summary": "El cálculo de influencias de escala en la inferencia de modelos de lenguaje grandes (LLMs) fortalece la base lógica de la inferención. Utilizando cadenas largas de objetos conscientes (CoTs), se pueden realizar estrategias como retroceso o corrección de errores. El aprendizaje por refuerzo (RL) aparece como una de las métodos importantes para desarrollar estas capacidades, pero no siempre se producen CoTs largas. Además, el entrenamiento con RL requiere diseños cuidadosos. En este estudio, se investiga sistemáticamente la estructura de la base lógica de los CoTs largos y se identifican las causas por las que los modelos generan sus trayectorias retroalimentadas largas. A través de varios experimentos de entrenamiento supervisado (SFT) y RL, se obtienen los siguientes cuatro hallazgos principales: 1. El SFT no es necesario con rigor, pero puede simplificar el entrenamiento y aumentar la eficiencia. 2. La capacidad de base lógica se desarrolla a medida que se aumenta la cantidad de cálculos de entrenamiento, pero su desarrollo no es certero. Por lo tanto, la regulación de la recompensa es crucial para mantener la estabilidad al crecer la longitud de los CoTs. 3. La escala de recompensas es un prometedor campo en RL. Se utilizan soluciones resumidas de web que incluyen ruido para generar señales de recompensa y estructuras de filtrado para potenciar esto, especialmente efectivo en tareas fuera de distribución (OOD). 4. Capacidades básicas como corrección de errores son inherentes al modelo original, pero se requieren grandes aumentos de cálculos para desarrollarlas efectivamente en tareas complejas, lo que requiere un enfoque complejo. Estas observaciones proporcionan una guía práctica para optimizar las estrategias de entrenamiento necesarias para fortalecer la base lógica de los CoTs largos en LLMs. El código está disponible en la siguiente URL: https://github.com/eddycmu/demystify-long-cot.",
      "upvotes": 15,
      "discussionId": "67a42c089a4fb11b11cc4fae"
    },
    "publishedAt": "2025-02-05T22:27:48.348Z",
    "title": "Demystifying Long Chain-of-Thought Reasoning in LLMs",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.03373.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "6230d750d93e84e233882dbc",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6230d750d93e84e233882dbc/4MGEekLW3oWzqeFWDWvIK.jpeg",
      "fullname": "Xiang Yue",
      "name": "yuexiang96",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 26
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.03387",
      "authors": [
        {
          "_id": "67a445ccbdd74b63b4e52a7d",
          "name": "Yixin Ye",
          "hidden": false
        },
        {
          "_id": "67a445ccbdd74b63b4e52a7e",
          "name": "Zhen Huang",
          "hidden": false
        },
        {
          "_id": "67a445ccbdd74b63b4e52a7f",
          "name": "Yang Xiao",
          "hidden": false
        },
        {
          "_id": "67a445ccbdd74b63b4e52a80",
          "name": "Ethan Chern",
          "hidden": false
        },
        {
          "_id": "67a445ccbdd74b63b4e52a81",
          "name": "Shijie Xia",
          "hidden": false
        },
        {
          "_id": "67a445ccbdd74b63b4e52a82",
          "name": "Pengfei Liu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-05T17:23:45.000Z",
      "title": "Por razones razonables, sería mejor un menor número de palabras.",
      "summary": "Aquí abordamos el problema de entender cómo aparecen las teorías complejas en modelos de lenguaje de gran escala. La generalización es que las tareas de teoría de razonamiento compleja requieren de datos de entrenamiento complejos (superiores a 100,000 ejemplos), pero demostramos que se puede desarrollar una capacidad efectiva de razonamiento matemático complejo con solo 817 ejemplos temáticos. Los experimentos específicos muestran que el modelo LIMO proporciona un rendimiento matemático de teoría de razonamiento sin precedentes. Con 817 datos de entrenamiento, LIMO alcanzó una precisión del 57.1% en AIME y del 94.8% en MATH, mejorando significativamente sobre los modelos basados en SFT anteriores, que alcanzaban solo un 6.5% y un 59.2% en estos benchmarks, utilizando solo el 1% de los datos de entrenamiento necesarios anteriormente. LIMO mejoró absolutamente en 40.5% en 10 diferentes evaluaciones y superó a modelos entrenados con mucha más información, planteando dudas sobre si el aprendizaje por reflexión (SFT) es más efectivo que la generalización. Basándonos en estos resultados, presentamos dos factores clave para determinar la precisión crítica de la teoría de razonamiento compleja: 1) la completitud de la base de conocimiento del modelo completamente codificado antes del entrenamiento, y 2) la efectividad de los \"templados de reconocimiento\" en mostrar cómo el modelo utiliza su base de conocimiento para resolver tareas de teoría de razonamiento compleja.",
      "upvotes": 9,
      "discussionId": "67a445cdbdd74b63b4e52af7"
    },
    "publishedAt": "2025-02-06T00:26:02.483Z",
    "title": "LIMO: Less is More for Reasoning",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.03387.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5956
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.02737",
      "authors": [
        {
          "_id": "67a446a9430e358f5d5ac4c3",
          "name": "Loubna Ben Allal",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4c4",
          "name": "Anton Lozhkov",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4c5",
          "name": "Elie Bakouch",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4c6",
          "name": "Gabriel Martín Blázquez",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4c7",
          "name": "Guilherme Penedo",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4c8",
          "name": "Lewis Tunstall",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4c9",
          "name": "Andrés Marafioti",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4ca",
          "name": "Hynek Kydlíček",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4cb",
          "name": "Agustín Piqueres Lajarín",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4cc",
          "name": "Vaibhav Srivastav",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4cd",
          "name": "Joshua Lochner",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4ce",
          "name": "Caleb Fahlgren",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4cf",
          "name": "Xuan-Son Nguyen",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4d0",
          "name": "Clémentine Fourrier",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4d1",
          "name": "Ben Burtenshaw",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4d2",
          "name": "Hugo Larcher",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4d3",
          "name": "Haojun Zhao",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4d4",
          "name": "Cyril Zakka",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4d5",
          "name": "Mathieu Morlon",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4d6",
          "name": "Colin Raffel",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4d7",
          "user": {
            "_id": "6284b359eac6d6ca13879514",
            "avatarUrl": "/avatars/2dcca0f0d21cbe1a54eedac759adc61c.svg",
            "isPro": false,
            "fullname": "evaluate-bot",
            "user": "evaluate-bot",
            "type": "user"
          },
          "name": "Leandro von Werra",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-02-06T05:20:41.925Z",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4d8",
          "name": "Thomas Wolf",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-04T21:43:16.000Z",
      "title": "スモルLM2: Cuando el Smorl se expande, se entrena en el centro de datos para aprender un pequeño modelo de lenguaje.",
      "summary": "En este artículo se registra el desarrollo de \"SmolLM2\", el más avanzado modelo de lenguaje \"pequeño\" (170 millones de parámetros). SmolLM2 aprende mediante un proceso de entrenamiento multinivel de texto de red, matemáticas, código y datos de comandos, aprendiendo aproximadamente 110 billones de tokens. Además, cuando los conjuntos de datos existentes son problemáticamente pequeños o de baja calidad, se agregan nuevos conjuntos de datos específicamente diseñados (FineMath, Stack-Edu, SmolTalk). Para actualizar la proporción de los conjuntos de datos, se realizan pruebas de eliminación a pequeña escala basadas en el rendimiento de cada etapa y procesos de mejora manual. Finalmente, SmolLM2 muestra un rendimiento que supera a otros pequeños modelos de lenguaje recientes (Qwen2.5-1.5B, Llama3.2-1B). Para fomentar la investigación en el desarrollo de modelos de lenguaje y las aplicaciones de los pequeños modelos de lenguaje, se publican SmolLM2 y todos los conjuntos de datos preparados en este proyecto.",
      "upvotes": 9,
      "discussionId": "67a446a9430e358f5d5ac4f8"
    },
    "publishedAt": "2025-02-06T00:20:51.704Z",
    "title": "SmolLM2: When Smol Goes Big -- Data-Centric Training of a Small Language Model",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.02737.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5956
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.02339",
      "authors": [
        {
          "_id": "67a3262873bdaf626f1e9eab",
          "name": "Jinyang Wu",
          "hidden": false
        },
        {
          "_id": "67a3262873bdaf626f1e9eac",
          "name": "Mingkuan Feng",
          "hidden": false
        },
        {
          "_id": "67a3262873bdaf626f1e9ead",
          "name": "Shuai Zhang",
          "hidden": false
        },
        {
          "_id": "67a3262873bdaf626f1e9eae",
          "name": "Ruihan Jin",
          "hidden": false
        },
        {
          "_id": "67a3262873bdaf626f1e9eaf",
          "name": "Feihu Che",
          "hidden": false
        },
        {
          "_id": "67a3262873bdaf626f1e9eb0",
          "name": "Zengqi Wen",
          "hidden": false
        },
        {
          "_id": "67a3262873bdaf626f1e9eb1",
          "name": "Jianhua Tao",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-04T14:18:29.000Z",
      "title": "Utilizando MCTS para mejorar la lógica de múltiples modelos con pensamiento estructurado",
      "summary": "Los modelos de lenguaje multimodal (MLLMs) muestran capacidades sorprendentes, pero aún presentan problemas en la inferencia visual compleja. Los esfuerzos recientes intentan mejorar la inferencia de los MLLMs mediante estructuras de pensamiento explícitas como búsquedas estructuradas o secuencias de entrenamiento guiadas por un profesor, pero estos enfoques presentan desafíos para mantener un equilibrio entre rendimiento y eficiencia, enfatizando datos y espacios de búsqueda diversos, lo que limita la eficiencia en la extracción de entradas y el uso de datos. Para resolver estos problemas, proponemos un paradigma de pensamiento estructurado autónomo basado en Monte Carlo Tree Search (MCTS), llamado AStar. AStar utiliza MCTS para deducir patrones cognitivos de alto nivel a partir de datos limitados, utilizando estructuras jerárquicas. Basándonos en estos patrones explícitos, diseñamos un marco de inferencia que integre de manera autónoma los capacidades de pensamiento interno del modelo y las pautas de pensamiento externas, llamado unified inference framework. Este marco permite eficientes inferencias a través de una mínima cantidad de iteraciones de árbol. Este nuevo paradigma maneja de manera fuerte el equilibrio entre rendimiento y eficiencia, demostrando su efectividad en el benchmark MathVerse, al alcanzar una precisión superior al 54.0% y superando al GPT-4o (50.2%), mientras mantiene la eficiencia con grandes conjuntos de datos y cálculos.",
      "upvotes": 7,
      "discussionId": "67a3262973bdaf626f1e9edb"
    },
    "publishedAt": "2025-02-05T21:45:32.304Z",
    "title": "Boosting Multimodal Reasoning with MCTS-Automated Structured Thinking",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.02339.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6747de57f8cab58c22ec94a2",
      "avatarUrl": "/avatars/5bae0341862fac24564781c0fa32aac5.svg",
      "fullname": "Jinyang Wu",
      "name": "Jinyang23",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 4
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.01154",
      "authors": [
        {
          "_id": "67a4609af2e553c1d0da914d",
          "name": "Yu-Ling Hsu",
          "hidden": false
        },
        {
          "_id": "67a4609af2e553c1d0da914e",
          "name": "Hsuan Su",
          "hidden": false
        },
        {
          "_id": "67a4609af2e553c1d0da914f",
          "name": "Shang-Tse Chen",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-03T08:44:24.000Z",
      "title": "El único brake con un único prompt",
      "summary": "Los modelos de lenguaje grande (LLMs) han experimentado un rápido crecimiento reciente y han tenido un impacto innovador en diversas áreas de aplicación, mejorando significativamente la conveniencia y la productividad. Sin embargo, estos avances han surgido asociados a preocupaciones éticas y nuevos tipos de ataques, como el \"jailbreaking\". La tecnología de prompting se centra principalmente en optimizar entradas adversarias en situaciones personales, lo que aumenta los costos computacionales cuando se trata de grandes conjuntos de datos. Por otro lado, la investigación en entornos más generales, donde se entrena a un atacante común y se adapta a tareas no vistas, es insuficiente y no se investiga. En este artículo, se presenta un método basado en prompting generalizado para llevar a cabo un \"jailbreaking\" en LLMs. Este método se denomina DUMP. A través de los resultados experimentales, se muestra que nuestro método de optimización de prompting generalizado supera a las técnicas existentes.",
      "upvotes": 3,
      "discussionId": "67a4609bf2e553c1d0da9181"
    },
    "publishedAt": "2025-02-06T02:11:41.374Z",
    "title": "Jailbreaking with Universal Multi-Prompts",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01154.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "608abf1272b50b02c4b02865",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1619708309549-608abf1272b50b02c4b02865.jpeg",
      "fullname": "Hsuan Su",
      "name": "jacksukk",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.01105",
      "authors": [
        {
          "_id": "67a45c85e73ad243c0b9529e",
          "name": "Yiren Song",
          "hidden": false
        },
        {
          "_id": "67a45c85e73ad243c0b9529f",
          "name": "Danze Chen",
          "hidden": false
        },
        {
          "_id": "67a45c85e73ad243c0b952a0",
          "user": {
            "_id": "63a55320ce5763e06f78519c",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1671779060549-noauth.jpeg",
            "isPro": false,
            "fullname": "Mike Shou",
            "user": "mikeshou",
            "type": "user"
          },
          "name": "Mike Zheng Shou",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-02-06T06:54:02.195Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-03T06:49:58.000Z",
      "title": "LayerTracer: Implementa la síntesis de SVG de estructuras de capas correspondientes a la cognición mediante división y Transformer.",
      "summary": "La generación de SVGs de capas por computadora es considerada actualmente como demasiado simplificada, lo que resulta en salidas de una sola capa o en la falta de necesidad de formas en la optimización. Proponemos LayerTracer para llenar este vacío. Este marco de trabajo se basa en transformadores distribuidos. Nuestro enfoque se compone de dos etapas: primero, DiT condicionado por texto genera estructuras planificadoras multiniveles que mimetizan el flujo de trabajo de diseño humano. Segundo, se realiza la vectorización y reducción de pasos por capas para crear SVGs limpios y editables. Durante el proceso de vectorización, codificamos las imágenes de referencia como tokens de potencia para introducir una estructura de dispersión condicional que guie la reconfiguración capa a capa, manteniendo la estructuralidad. Los experimentos de dispersión muestran mejoras en la calidad de la generación y la edicionalidad, y prueban que los vectores generados por el AI pueden ser reconocidos por los diseñadores profesionales.",
      "upvotes": 3,
      "discussionId": "67a45c8ae73ad243c0b953ea"
    },
    "publishedAt": "2025-02-06T01:55:37.207Z",
    "title": "LayerTracer: Cognitive-Aligned Layered SVG Synthesis via Diffusion Transformer",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01105.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64311a95034ecbefddd141ef",
      "avatarUrl": "/avatars/b6dc5ca373bedbaa368208517954c375.svg",
      "fullname": "Yiren Song",
      "name": "yiren98",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.01618",
      "authors": [
        {
          "_id": "67a438d26bb8caaab06f5a5e",
          "user": {
            "_id": "64c2abe8c43875b438efef25",
            "avatarUrl": "/avatars/6efda081f52cf56db2d29a5ec05cb557.svg",
            "isPro": false,
            "fullname": "isha",
            "user": "ishapuri-mit",
            "type": "user"
          },
          "name": "Isha Puri",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-02-06T04:21:39.202Z",
          "hidden": false
        },
        {
          "_id": "67a438d26bb8caaab06f5a5f",
          "name": "Shivchander Sudalairaj",
          "hidden": false
        },
        {
          "_id": "67a438d26bb8caaab06f5a60",
          "name": "Guangxuan Xu",
          "hidden": false
        },
        {
          "_id": "67a438d26bb8caaab06f5a61",
          "name": "Kai Xu",
          "hidden": false
        },
        {
          "_id": "67a438d26bb8caaab06f5a62",
          "name": "Akash Srivastava",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-03T18:50:50.000Z",
      "title": "Metodo de inferencia probabilistica para escalado en la prediccion de modelos de lenguaje grandes basados en particulas",
      "summary": "Los modelos de lenguaje grande (LLMs) han logrado una notable mejora en su rendimiento a través del crecimiento del tamaño del modelo y la expansión de los datos. Sin embargo, recientes evidencias indican que el efecto de estas estrategias está disminuyendo y sugieren la necesidad de ampliar el cálculo de tiempo de inferencia. Los métodos actuales para ampliar el tiempo de inferencia generalmente utilizan modelos de recompensa para tratar las tareas como problemas de búsqueda, lo que puede hacerlos vulnerables a hacking de recompensa debido a errores de aproximación en los modelos de recompensa. En este artículo, se aborda el ampliar el tiempo de inferencia como un problema de inferencia probabilística y se utiliza un enfoque basado en muestras para explorar una amplia gama de distribuciones de estado de modelos de espacio de estados que utilizan aproximaciones. De esta manera, se evita optimizar directamente los modos del modelo. En este artículo, se aplica el método de Monte Carlo basado en bases tridimensionales para este problema y se propone un nuevo enfoque para ampliar el tiempo de inferencia. Las evaluaciones experimentales muestran un aumento del 4-16 veces en diferentes tareas lógicas matemáticas difíciles, comparado con exploraciones deterministas. Con este enfoque, Qwen2.5-Math-1.5B-Instruct supera la precisión de GPT-4o con 4 salidas de retroalimentación, y Qwen2.5-Math-7B-Instruct alcanza un nivel de precisión similar a o1 con 32 salidas de retroalimentación. Este artículo proporciona métodos efectivos para ampliar el tiempo de inferencia y contribuye a la desarrollo de algoritmos más robustos en futuras investigaciones, al integrar la abundante literatura de inferencia probabilística con la expansión del tiempo de inferencia en LLMs. Los códigos y información adicionales están disponibles en https://probabilistic-inference-scaling.github.io.",
      "upvotes": 3,
      "discussionId": "67a438d36bb8caaab06f5a87"
    },
    "publishedAt": "2025-02-05T23:23:08.428Z",
    "title": "A Probabilistic Inference Approach to Inference-Time Scaling of LLMs using Particle-Based Monte Carlo Methods",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/648b3f3208c4a9d807a90a99/gwgJD14Bd0fdz7xpcHdHe.mp4",
      "https://cdn-uploads.huggingface.co/production/uploads/648b3f3208c4a9d807a90a99/KHcaqxZL3wiloAm7x-7nA.mp4"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01618.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "648b3f3208c4a9d807a90a99",
      "avatarUrl": "/avatars/03634b4e7f8afe9b589a2d7370e29960.svg",
      "fullname": "Akash Srivastava",
      "name": "akashsri",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 8
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.03275",
      "authors": [
        {
          "_id": "67a448b69ca42c642a723a7d",
          "name": "DiJia Su",
          "hidden": false
        },
        {
          "_id": "67a448b69ca42c642a723a7e",
          "name": "Hanlin Zhu",
          "hidden": false
        },
        {
          "_id": "67a448b69ca42c642a723a7f",
          "name": "Yingchen Xu",
          "hidden": false
        },
        {
          "_id": "67a448b69ca42c642a723a80",
          "name": "Jiantao Jiao",
          "hidden": false
        },
        {
          "_id": "67a448b69ca42c642a723a81",
          "name": "Yuandong Tian",
          "hidden": false
        },
        {
          "_id": "67a448b69ca42c642a723a82",
          "name": "Qinqing Zheng",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-05T15:33:00.000Z",
      "title": "Combinación de Tokens: Motivos para Mejorar la Lógica Lógica del Modelo de Lenguaje a través de la Mixtura de Tokens Potenciales y de Texto",
      "summary": "Los modelos de lenguaje grande (LLMs) se entrenan con datos de \"chain-of-thought\" (CoT), lo que permite a los modelos mostrar claramente los procesos de pensamiento en cada paso, haciéndolos especializados en lógica y planeación. Sin embargo, muchas palabras contribuyen con información lógica esencial para la continuidad de la oración, y su procesamiento requiere recursos computacionales complejos. En este artículo, se propone una representación híbrida para el procesamiento de lógica, utilizando tokens discretos generados por VQ-VAE para abstractar parcialmente los primeros pasos de lógica y reducir significativamente la longitud del procesamiento lógico. El uso de la abstracción de trazas potenciales se examina en dos escenarios: 1) el entrenamiento desde el principio del modelo para el problema de \"Maze Keys-Finding\", y 2) el ajuste micro de los LLMs para datos híbridos, ambos que pueden incluir problemas lógicos y matemáticos. Para promover un aprendizaje efectivo, se introduce un simple procedimiento de entrenamiento que mezcla aleatoriamente los tokens potenciales y contextuales, lo que permite que el modelo adapte rápidamente a nuevos tokens potenciales. Nuestro enfoque no coincide ni supera a los métodos de base línea consistentes en diferentes marcos de evaluación.",
      "upvotes": 2,
      "discussionId": "67a448b89ca42c642a723ac6"
    },
    "publishedAt": "2025-02-06T00:29:44.686Z",
    "title": "Token Assorted: Mixing Latent and Text Tokens for Improved Language Model Reasoning",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.03275.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5956
    },
    "isAuthorParticipating": false
  }
]