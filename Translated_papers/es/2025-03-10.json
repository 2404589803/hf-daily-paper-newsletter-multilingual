[
  {
    "paper": {
      "id": "2503.05236",
      "authors": [
        {
          "_id": "67ce37239f9aaaae837f3894",
          "user": {
            "_id": "654c6845bac6e6e49895a5b5",
            "avatarUrl": "/avatars/ed1f140abcd4d76669e2e48db1d1193f.svg",
            "isPro": false,
            "fullname": "Yibin Wang",
            "user": "CodeGoat24",
            "type": "user"
          },
          "name": "Yibin Wang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-10T09:37:51.835Z",
          "hidden": false
        },
        {
          "_id": "67ce37239f9aaaae837f3895",
          "user": {
            "_id": "63859cf3b2906edaf83af9f0",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63859cf3b2906edaf83af9f0/iUQm5FAomzqYi6fkqIn9F.jpeg",
            "isPro": false,
            "fullname": "Yuhang Zang",
            "user": "yuhangzang",
            "type": "user"
          },
          "name": "Yuhang Zang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-03-10T08:01:24.660Z",
          "hidden": false
        },
        {
          "_id": "67ce37239f9aaaae837f3896",
          "name": "Hao Li",
          "hidden": false
        },
        {
          "_id": "67ce37239f9aaaae837f3897",
          "name": "Cheng Jin",
          "hidden": false
        },
        {
          "_id": "67ce37239f9aaaae837f3898",
          "user": {
            "_id": "64638c4d51fa6e63060521b5",
            "avatarUrl": "/avatars/c863ace5b1dc788a341bcf4ddbdfaec1.svg",
            "isPro": false,
            "fullname": "JIaqi",
            "user": "Jiaqiwang",
            "type": "user"
          },
          "name": "Jiaqi Wang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-10T09:38:17.938Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-03-07T08:36:05.000Z",
      "title": "Modelo de premios integrado: comprensión y generación de múltiples modos",
      "summary": "Durante el ajuste actual de las actividades humanas, se ha visto un gran desarrollo en la generación y comprensión de modelos multimodelos. Una de las principales formas de abordar este tema es mediante el entrenamiento de modelos de recompensa para optimizar las actividades. Sin embargo, actualmente los modelos son generalmente especializados en tareas específicas, lo que limita su adaptación a aplicaciones visuales diversas. También se ha argumentado que evaluar varias tareas simultáneamente puede fomentar la interacción. En este sentido, este artículo propone el primer modelo de unidad mínima, \"UnifiedReward\". Este modelo permite la comprensión y evaluación de múltiples modelos, así como la realización de ranking parcial y puntuación. Concretamente, (1) hemos desarrollado un modelo de unidad mínima en un conjunto de datos humanos de actividades de gran escala, que incluye tareas de generación y comprensión de imágenes y videos. (2) A continuación, se construyeron de manera automática altos calidad datos de parejas de actividades, que se filtran mediante ranking parcial y puntuación. (3) Finalmente, se utilizan estos datos directamente para la optimización de las actividades (DPO) para ajustar las actividades. Los resultados de los experimentos muestran que se puede obtener un gran beneficio mutuo a través de la evaluación de diferentes tareas visuales, y que aplicando este proceso a la comprensión y generación de imágenes y videos se mejora significativamente el rendimiento en cada área.",
      "upvotes": 72,
      "discussionId": "67ce37259f9aaaae837f3948",
      "projectPage": "https://codegoat24.github.io/UnifiedReward/",
      "githubRepo": "https://github.com/CodeGoat24/UnifiedReward"
    },
    "publishedAt": "2025-03-09T22:20:09.137Z",
    "title": "Unified Reward Model for Multimodal Understanding and Generation",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.05236.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "654c6845bac6e6e49895a5b5",
      "avatarUrl": "/avatars/ed1f140abcd4d76669e2e48db1d1193f.svg",
      "fullname": "Yibin Wang",
      "name": "CodeGoat24",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2503.05179",
      "authors": [
        {
          "_id": "67ce4bff5847e4787a7ebedd",
          "user": {
            "_id": "65f4060754ecda1ecb5797a0",
            "avatarUrl": "/avatars/f8b44524d36b505673cb538fd7895a82.svg",
            "isPro": false,
            "fullname": "Simon Aytes",
            "user": "saytes",
            "type": "user"
          },
          "name": "Simon A. Aytes",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-03-10T08:01:10.363Z",
          "hidden": false
        },
        {
          "_id": "67ce4bff5847e4787a7ebede",
          "user": {
            "_id": "63036b6c5c70c21d0ea79d48",
            "avatarUrl": "/avatars/a7eb03f5cbd4eaa09fe807bbed8bc0f7.svg",
            "isPro": false,
            "fullname": "Jinheon Baek",
            "user": "jinheon",
            "type": "user"
          },
          "name": "Jinheon Baek",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-03-10T08:01:13.328Z",
          "hidden": false
        },
        {
          "_id": "67ce4bff5847e4787a7ebedf",
          "name": "Sung Ju Hwang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-03-07T06:57:17.000Z",
      "title": "El esquema de esqui: un modelo basado en la cognición adaptativa mediante lógica de modelos grandes de lenguaje eficientes",
      "summary": "El reciente desarrollo de modelos de lenguaje grande ha demostrado una impresionante capacidad lógica mediante la técnica de Prompting Chain of Thought (CoT), pero la longitud excesiva de los resultados intermedios ha aumentado el sobrecarga computacional. Presentamos un nuevo marco de Prompting llamado Sketch-of-Thought (SoT). Este marco tiene como objetivo minimizar la cantidad de tokens utilizados mientras mantiene la precisión lógica, combinando paradigmas lógicos basados en ciencias cognitivas con restricciones lingüísticas. SoT es un marco flexible diseñado para incluir cualquier paradigma lógico definido por el usuario basado en ciencias cognitivas. Hemos implementado tres paradigmas lógicos: Conceptual Chaining, Chunked Symbolism y Expert Lexicons, cada uno ajustado a tareas lógicas específicas y seleccionables dinámicamente por modelos ligeros. SoT ha sido validado en múltiples escenarios de lenguajes y modelos, compuestos de 15 conjuntos de datos lógicos, y ha demostrado reducir la cantidad de tokens en un 76%, sin afectar la tasa de errores. En áreas específicas como matemáticas o lógica multinivel, puede mejorar la precisión con un mínimo número de tokens. Nuestro código está disponible para uso público: https://www.github.com/SimonAytes/SoT.",
      "upvotes": 27,
      "discussionId": "67ce4c035847e4787a7ebf4c",
      "projectPage": "https://huggingface.co/saytes/SoT_DistilBERT",
      "githubRepo": "https://github.com/SimonAytes/SoT"
    },
    "publishedAt": "2025-03-09T22:25:52.244Z",
    "title": "Sketch-of-Thought: Efficient LLM Reasoning with Adaptive Cognitive-Inspired Sketching",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.05179.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "63036b6c5c70c21d0ea79d48",
      "avatarUrl": "/avatars/a7eb03f5cbd4eaa09fe807bbed8bc0f7.svg",
      "fullname": "Jinheon Baek",
      "name": "jinheon",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 8
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2503.05500",
      "authors": [
        {
          "_id": "67ce9626e5cdfda52b9e8839",
          "user": {
            "_id": "62be186a5f59ff2320e6e32b",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62be186a5f59ff2320e6e32b/W_emoC2uItM-MJZyCfIKI.png",
            "isPro": false,
            "fullname": "Nicolas-BZRD",
            "user": "Nicolas-BZRD",
            "type": "user"
          },
          "name": "Nicolas Boizard",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-10T09:42:06.860Z",
          "hidden": false
        },
        {
          "_id": "67ce9626e5cdfda52b9e883a",
          "user": {
            "_id": "65fa95405355a52c784633fc",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65fa95405355a52c784633fc/rSfBUHPa7eSAsLd8DuOq4.png",
            "isPro": false,
            "fullname": "Hippolyte Gisserot-Boukhlef",
            "user": "hgissbkh",
            "type": "user"
          },
          "name": "Hippolyte Gisserot-Boukhlef",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-10T09:42:13.176Z",
          "hidden": false
        },
        {
          "_id": "67ce9626e5cdfda52b9e883b",
          "user": {
            "_id": "64132452d8a418df415a6ded",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64132452d8a418df415a6ded/qkjL5G89uldHUXlCI3n4f.jpeg",
            "isPro": false,
            "fullname": "Duarte Alves",
            "user": "DuarteMRAlves",
            "type": "user"
          },
          "name": "Duarte M. Alves",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-10T09:42:23.055Z",
          "hidden": false
        },
        {
          "_id": "67ce9626e5cdfda52b9e883c",
          "name": "André Martins",
          "hidden": false
        },
        {
          "_id": "67ce9626e5cdfda52b9e883d",
          "user": {
            "_id": "63937b399762cdd66be2a32f",
            "avatarUrl": "/avatars/7aefd888a3c54673d5881dcef61f771b.svg",
            "isPro": false,
            "fullname": "Ayoub Hammal",
            "user": "ayoubhammal",
            "type": "user"
          },
          "name": "Ayoub Hammal",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-10T09:42:42.527Z",
          "hidden": false
        },
        {
          "_id": "67ce9626e5cdfda52b9e883e",
          "user": {
            "_id": "677bedd522ca8585ede98470",
            "avatarUrl": "/avatars/54bca410c446610f02aca55918c74518.svg",
            "isPro": false,
            "fullname": "Caio Corro",
            "user": "caiocorro",
            "type": "user"
          },
          "name": "Caio Corro",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-10T09:42:48.603Z",
          "hidden": false
        },
        {
          "_id": "67ce9626e5cdfda52b9e883f",
          "user": {
            "_id": "61efea03a57920a251ec19b8",
            "avatarUrl": "/avatars/f47c8e3cb17a2bf7d43f2c152bb86885.svg",
            "isPro": false,
            "fullname": "Celine Hudelot",
            "user": "CelineH",
            "type": "user"
          },
          "name": "Céline Hudelot",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-10T09:51:41.273Z",
          "hidden": false
        },
        {
          "_id": "67ce9626e5cdfda52b9e8840",
          "user": {
            "_id": "66f2d6a684a241caac8e16dc",
            "avatarUrl": "/avatars/81acb87c2b07bea938251b40a2139911.svg",
            "isPro": false,
            "fullname": "Emmanuel Malherbe",
            "user": "emmanuelmalherbe",
            "type": "user"
          },
          "name": "Emmanuel Malherbe",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-10T09:51:47.996Z",
          "hidden": false
        },
        {
          "_id": "67ce9626e5cdfda52b9e8841",
          "name": "Etienne Malaboeuf",
          "hidden": false
        },
        {
          "_id": "67ce9626e5cdfda52b9e8842",
          "user": {
            "_id": "6708db59caf70ddea8e1355d",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6708db59caf70ddea8e1355d/C6T16AdpqoeWCk7Gg9wSH.jpeg",
            "isPro": false,
            "fullname": "Fanny Jourdan",
            "user": "Fannyjrd",
            "type": "user"
          },
          "name": "Fanny Jourdan",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-10T09:52:09.223Z",
          "hidden": false
        },
        {
          "_id": "67ce9626e5cdfda52b9e8843",
          "user": {
            "_id": "67cafedda972115e89972cd7",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/P_xComqG9IttvluN-6tyB.png",
            "isPro": false,
            "fullname": "Gabriel Hautreux",
            "user": "GabrielHau",
            "type": "user"
          },
          "name": "Gabriel Hautreux",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-10T09:52:15.512Z",
          "hidden": false
        },
        {
          "_id": "67ce9626e5cdfda52b9e8844",
          "user": {
            "_id": "6772bde5c997eeb5550e80ea",
            "avatarUrl": "/avatars/8134a4d9330317e748dc7b33e1bb25f6.svg",
            "isPro": false,
            "fullname": "João Alves",
            "user": "albusonrails",
            "type": "user"
          },
          "name": "João Alves",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-10T09:52:22.630Z",
          "hidden": false
        },
        {
          "_id": "67ce9626e5cdfda52b9e8845",
          "user": {
            "_id": "66e2c22d7cc3edd60d725267",
            "avatarUrl": "/avatars/b217c5708c7dba8b1c220f37984ccc1e.svg",
            "isPro": false,
            "fullname": "Kevin El Haddad",
            "user": "kelhad",
            "type": "user"
          },
          "name": "Kevin El-Haddad",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-10T09:52:31.191Z",
          "hidden": false
        },
        {
          "_id": "67ce9626e5cdfda52b9e8846",
          "user": {
            "_id": "60f2e021adf471cbdf8bb660",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1654090481550-60f2e021adf471cbdf8bb660.jpeg",
            "isPro": false,
            "fullname": "Manuel Faysse",
            "user": "manu",
            "type": "user"
          },
          "name": "Manuel Faysse",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-10T09:52:38.114Z",
          "hidden": false
        },
        {
          "_id": "67ce9626e5cdfda52b9e8847",
          "user": {
            "_id": "6369394dd322a76e1ea4bdf6",
            "avatarUrl": "/avatars/a4e5ab0167025fbbfc970d54630ce754.svg",
            "isPro": false,
            "fullname": "Maxime Peyrard",
            "user": "peyrardm",
            "type": "user"
          },
          "name": "Maxime Peyrard",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-10T09:52:44.389Z",
          "hidden": false
        },
        {
          "_id": "67ce9626e5cdfda52b9e8848",
          "user": {
            "_id": "67b622d2df3a86fbca306c43",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/lNlshrl56oaKslArMzSzj.png",
            "isPro": false,
            "fullname": "Nuno  Guerreiro",
            "user": "nunogj",
            "type": "user"
          },
          "name": "Nuno M. Guerreiro",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-10T09:52:54.367Z",
          "hidden": false
        },
        {
          "_id": "67ce9626e5cdfda52b9e8849",
          "name": "Patrick Fernandes",
          "hidden": false
        },
        {
          "_id": "67ce9626e5cdfda52b9e884a",
          "name": "Ricardo Rei",
          "hidden": false
        },
        {
          "_id": "67ce9626e5cdfda52b9e884b",
          "user": {
            "_id": "644a900e3a619fe72b14af0f",
            "avatarUrl": "/avatars/e2d5dac3d92757ed48e37e126a3464a3.svg",
            "isPro": false,
            "fullname": "Colombo",
            "user": "PierreColombo",
            "type": "user"
          },
          "name": "Pierre Colombo",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-10T09:41:26.353Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-03-07T15:13:58.000Z",
      "title": "Eurobert: Eurobert: Método para expandir el encoder de lenguaje oriental europeo",
      "summary": "La representación vectorial multilingüe generalmente se utiliza en búsquedas, regresión y clasificación. Estos pueden obtenerse de modelos de codificadores bidireccionales. Además, son ampliamente aplicables. Sin embargo, recientemente, los codificadores han demostrado excelentes resultados debido al desarrollo de modelos de decodificadores generativos. Sin embargo, la mayoría de este progreso está directamente relacionado con los decodificadores. En este artículo, se reevalúa el desarrollo de codificadores multilingües centrandose en EuroBERT, una familia de codificadores multilingües que cubre varios idiomas de Europa y el mundo. Nuestro modelo ha mejorado la capacidad multilingüe, matemática y código en diferentes tareas de diversas áreas. Además, soporta secuencias de 8,192 tokens. Además, se revisan las decisiones de diseño de EuroBERT, proporcionando retroalimentación sobre la configuración del conjunto de datos y el proceso de entrenamiento. Se publica el modelo EuroBERT, incluyendo puntos intermedios de entrenamiento y el marco de trabajo de entrenamiento.",
      "upvotes": 26,
      "discussionId": "67ce9627e5cdfda52b9e88a4"
    },
    "publishedAt": "2025-03-10T03:42:45.848Z",
    "title": "EuroBERT: Scaling Multilingual Encoders for European Languages",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/62be186a5f59ff2320e6e32b/NxwS9WJrRc9D3q9awbn_X.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.05500.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "62be186a5f59ff2320e6e32b",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62be186a5f59ff2320e6e32b/W_emoC2uItM-MJZyCfIKI.png",
      "fullname": "Nicolas-BZRD",
      "name": "Nicolas-BZRD",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 14
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2503.02130",
      "authors": [
        {
          "_id": "67cc697fa029f09af72cca01",
          "user": {
            "_id": "6694cc1009326cb83f2d11bb",
            "avatarUrl": "/avatars/1ddaaed70a16ac475a9404848aef5d48.svg",
            "isPro": false,
            "fullname": "Zhixuan Lin",
            "user": "zhixuan-lin",
            "type": "user"
          },
          "name": "Zhixuan Lin",
          "status": "extracted_confirmed",
          "statusLastChangedAt": "2025-03-08T16:00:21.933Z",
          "hidden": false
        },
        {
          "_id": "67cc697fa029f09af72cca02",
          "user": {
            "_id": "64234eadd654afd6931a288b",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/UTU-XcO_ssKpIYr5MBujK.jpeg",
            "isPro": false,
            "fullname": "Evgenii Nikishin",
            "user": "nikishin",
            "type": "user"
          },
          "name": "Evgenii Nikishin",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-10T09:54:09.945Z",
          "hidden": false
        },
        {
          "_id": "67cc697fa029f09af72cca03",
          "user": {
            "_id": "66906c4e37eadb9c577984d3",
            "avatarUrl": "/avatars/b81765472942fdf94c0ee885ca62df2d.svg",
            "isPro": false,
            "fullname": "Owen He",
            "user": "littleowen",
            "type": "user"
          },
          "name": "Xu Owen He",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-03-08T16:00:01.392Z",
          "hidden": false
        },
        {
          "_id": "67cc697fa029f09af72cca04",
          "name": "Aaron Courville",
          "hidden": false
        }
      ],
      "publishedAt": "2025-03-03T23:35:23.000Z",
      "title": "Forgetting Transformer: Attención Softmax con una Puerta de Olvido",
      "summary": "Una de los componentes importantes de la secuencia de modelos de ricarent modernos es la gate de olvido. El Transformer no tiene una forma explícita de ricarent, pero puede insertar de manera natural una gate de olvido reduciendo de manera data-dependent la nota de atención no normalizada. Este proceso se llama \"gate de olvido en nota de atención\" y el modelo resultante se llama \"Transformer con gate de olvido (FoX)\". FoX muestra un rendimiento mejor que el Transformer en la modelación de largas secuencias de lenguaje, la estimación de largo de secuencia y en tareas de flujo de trabajo con cortas secuencias, y también muestra un rendimiento comparable al Transformer en tareas de flujo de trabajo con largas secuencias. Además, es compatible con el algoritmo FlashAttention y no requiere vectores de posición. Mediante análisis como el \"test de nid de la pila de alto nivel\", FoX demuestra que mantiene la excelente capacidad de manejo de largas secuencias del Transformer, comparándose con otros modelos de secuencias de ricarent como Mamba-2, HGRN2 y DeltaNet. Además, se ha introducido un diseño de bloque \"pro\" y se han insertado componentes arquitectónicos comunes en los modelos de secuencias de ricarent, lo que ha mejorado significativamente el rendimiento de FoX y el Transformer. El código está disponible en la siguiente URL.\nhttps://github.com/zhixuan-lin/forgetting-transformer",
      "upvotes": 12,
      "discussionId": "67cc6981a029f09af72ccac1",
      "githubRepo": "https://github.com/zhixuan-lin/forgetting-transformer"
    },
    "publishedAt": "2025-03-09T22:02:39.842Z",
    "title": "Forgetting Transformer: Softmax Attention with a Forget Gate",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.02130.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6694cc1009326cb83f2d11bb",
      "avatarUrl": "/avatars/1ddaaed70a16ac475a9404848aef5d48.svg",
      "fullname": "Zhixuan Lin",
      "name": "zhixuan-lin",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2503.05639",
      "authors": [
        {
          "_id": "67ce5ad85847e4787a82242d",
          "user": {
            "_id": "650447dd52ca06fef957f05d",
            "avatarUrl": "/avatars/511c11ac9b3cc7a162bda5e07f6ee0a3.svg",
            "isPro": true,
            "fullname": "Yuxuan BIAN",
            "user": "BianYx",
            "type": "user"
          },
          "name": "Yuxuan Bian",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-03-10T03:22:04.947Z",
          "hidden": false
        },
        {
          "_id": "67ce5ad85847e4787a82242e",
          "name": "Zhaoyang Zhang",
          "hidden": false
        },
        {
          "_id": "67ce5ad85847e4787a82242f",
          "user": {
            "_id": "62d4577bc85b0fcf7fde39bb",
            "avatarUrl": "/avatars/a3a5729e33ae89ce9ba408830db3c835.svg",
            "isPro": false,
            "fullname": "Xuan Ju",
            "user": "juxuan27",
            "type": "user"
          },
          "name": "Xuan Ju",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-10T09:57:06.955Z",
          "hidden": false
        },
        {
          "_id": "67ce5ad85847e4787a822430",
          "user": {
            "_id": "6374a02d0856ac905bfc6113",
            "avatarUrl": "/avatars/2cbe75c9cc818a647ca6e416f129c96f.svg",
            "isPro": false,
            "fullname": "Mingdeng Cao",
            "user": "Ljzycmd",
            "type": "user"
          },
          "name": "Mingdeng Cao",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-10T09:56:45.412Z",
          "hidden": false
        },
        {
          "_id": "67ce5ad85847e4787a822431",
          "name": "Liangbin Xie",
          "hidden": false
        },
        {
          "_id": "67ce5ad85847e4787a822432",
          "user": {
            "_id": "63ca3ddc04c979828310bfcb",
            "avatarUrl": "/avatars/615e0d8622950b4408b40d550f02a894.svg",
            "isPro": false,
            "fullname": "Ying Shan",
            "user": "yshan2u",
            "type": "user"
          },
          "name": "Ying Shan",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-10T09:56:34.001Z",
          "hidden": false
        },
        {
          "_id": "67ce5ad85847e4787a822433",
          "name": "Qiang Xu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-03-07T17:59:46.000Z",
      "title": "VideoPainter: Inyección y edición de videos de longitud de navegación con plugins, control de contexto",
      "summary": "Video inpainting, la tecnología de video inpainting se ha desarrollado para recuperar vídeos, pero sigue evolucionando. A pesar de este progreso, los métodos actuales tienen dificultades para expandir los píxeles de las regiones ocultas utilizando flujos ópticos y conocimientos previos de áreas de recepción, o extendiendo modelos de inpainting de imágenes temporalmente para crear objetos completamente ocultos y mantener el contexto de fondo. Para resolver estos limitaciones, proponemos un nuevo modelo llamado VideoPainter. Este método incluye un eficiente encoder de contexto con solo 6% de parámetros, procesa vídeos ocultos, y introduce información de contexto de fondo basada en el fondo para generar contenido coherente. Esta arquitectura separada reduce significativamente la complejidad del entrenamiento y permite una integración compleja del contexto del fondo. Además, introducimos una nueva técnica de resampling de regiones de objetivo para mejorar la aplicación práctica del video inpainting y procesar vídeos largos. Además, construimos una pipeline de datos escalables utilizando modelos de comprensión visual actuales, proporcionando VPData y VPBench para fomentar el entrenamiento y evaluación de inpainting basado en segmentación, y ofrecendo el más grande conjunto de datos de video inpainting hasta el momento, que incluye más de 390K clips de diferentes tipos. Basándonos en el inpainting como base del flujo, revisamos aplicaciones descendentes como edición de vídeo y la generación de pares de datos de edición de vídeo, presentando evidencias de competencia y viabilidad práctica. Los experimentos extendidos muestran excelente desempeño en 8 métricas principales de VideoPainter y aplicaciones efectivas tanto en video inpainting como en edición de vídeo.",
      "upvotes": 10,
      "discussionId": "67ce5adc5847e4787a822524",
      "projectPage": "https://yxbian23.github.io/project/video-painter/",
      "githubRepo": "https://github.com/TencentARC/VideoPainter"
    },
    "publishedAt": "2025-03-10T04:30:00.983Z",
    "title": "VideoPainter: Any-length Video Inpainting and Editing with Plug-and-Play Context Control",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/650447dd52ca06fef957f05d/VSg-Ti5epQJbVp20s1ILN.mp4"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.05639.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "650447dd52ca06fef957f05d",
      "avatarUrl": "/avatars/511c11ac9b3cc7a162bda5e07f6ee0a3.svg",
      "fullname": "Yuxuan BIAN",
      "name": "BianYx",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2503.05592",
      "authors": [
        {
          "_id": "67ce5fd2e5cdfda52b9123a4",
          "user": {
            "_id": "66163dc8c7f45b3f893ff40b",
            "avatarUrl": "/avatars/801043dac0caae90bbca8c9d3e2e203b.svg",
            "isPro": false,
            "fullname": "Song Huatong",
            "user": "XXsongLALA",
            "type": "user"
          },
          "name": "Huatong Song",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-10T10:03:49.730Z",
          "hidden": false
        },
        {
          "_id": "67ce5fd2e5cdfda52b9123a5",
          "user": {
            "_id": "61b8405b516a20acdf3b85ff",
            "avatarUrl": "/avatars/3d2eae7c163a80b73260087b05a4230b.svg",
            "isPro": false,
            "fullname": "Jinhao Jiang",
            "user": "Boru",
            "type": "user"
          },
          "name": "Jinhao Jiang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-10T10:04:22.446Z",
          "hidden": false
        },
        {
          "_id": "67ce5fd2e5cdfda52b9123a6",
          "user": {
            "_id": "6703ac76ea890f0ca5b225eb",
            "avatarUrl": "/avatars/5f56c49a1940143d47dd484782a4abbf.svg",
            "isPro": false,
            "fullname": "Yingqian Min",
            "user": "EliverQ",
            "type": "user"
          },
          "name": "Yingqian Min",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-03-10T09:40:54.171Z",
          "hidden": false
        },
        {
          "_id": "67ce5fd2e5cdfda52b9123a7",
          "name": "Jie Chen",
          "hidden": false
        },
        {
          "_id": "67ce5fd2e5cdfda52b9123a8",
          "name": "Zhipeng Chen",
          "hidden": false
        },
        {
          "_id": "67ce5fd2e5cdfda52b9123a9",
          "name": "Wayne Xin Zhao",
          "hidden": false
        },
        {
          "_id": "67ce5fd2e5cdfda52b9123aa",
          "name": "Lei Fang",
          "hidden": false
        },
        {
          "_id": "67ce5fd2e5cdfda52b9123ab",
          "user": {
            "_id": "64b8c89052b7353d8c6a1013",
            "avatarUrl": "/avatars/cd59fffe81f6b07b4519540b8ff3d95f.svg",
            "isPro": false,
            "fullname": "Ji-Rong Wen",
            "user": "jrwen",
            "type": "user"
          },
          "name": "Ji-Rong Wen",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-10T10:04:33.194Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-03-07T17:14:44.000Z",
      "title": "R1-Searcher: Mejora de la capacidad de búsqueda de un LLM mediante aprendizaje por refuerzo",
      "summary": "Los actuales modelos de inferencia a gran escala (LRMs) demuestran la posibilidad de que el aprendizaje por refuerzo (RL) pueda fortalecer las capacidades de inferencia compleja de los modelos de lenguaje a gran escala (LLMs). Estos modelos muestran excelentes resultados en tareas difíciles como la matemática o el programación, pero presentan limitaciones cuando se trata de resolver problemas que dependen de conocimientos internos, especialmente en situaciones de urgencia temporal o en preguntas de tipo conocimiento concentrado. Para abordar estos desafíos, proponemos el R1-Searcher. Este es un nuevo enfoque de aprendizaje por refuerzo basado en dos etapas diseñado para fortalecer las capacidades de búsqueda de los LLMs. Este método permite la auto-llamada automática a sistemas de búsqueda externos durante el proceso de inferencia. Nuestro marco de trabajo no requiere de iniciales de proceso de recompensa o de la modelización de la distribución gaussiana. Este método generaliza efectivamente en conjuntos de datos perturbados y apoya tanto modelos de base como modelos de comando. Nuestros experimentos muestran resultados significativamente mejores que los métodos de RAG existentes, y obtienen resultados equivalentes a los de GPT-4o-mini.",
      "upvotes": 9,
      "discussionId": "67ce5fd3e5cdfda52b912436",
      "githubRepo": "https://github.com/SsmallSong/R1-Searcher"
    },
    "publishedAt": "2025-03-09T23:43:27.151Z",
    "title": "R1-Searcher: Incentivizing the Search Capability in LLMs via Reinforcement Learning",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.05592.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 6317
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2503.05638",
      "authors": [
        {
          "_id": "67ce8388764226f050ad18b3",
          "name": "Mark YU",
          "hidden": false
        },
        {
          "_id": "67ce8388764226f050ad18b4",
          "user": {
            "_id": "657a7458afbb0117ba15c59f",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/657a7458afbb0117ba15c59f/8_iwTS1UG_mKnfylFbLsY.jpeg",
            "isPro": false,
            "fullname": "Wenbo Hu",
            "user": "wbhu-tc",
            "type": "user"
          },
          "name": "Wenbo Hu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-03-10T08:00:42.681Z",
          "hidden": false
        },
        {
          "_id": "67ce8388764226f050ad18b5",
          "user": {
            "_id": "64770e86d7cf39f2e937ae9a",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64770e86d7cf39f2e937ae9a/pLqGg2z1KzQxCGpMwds-9.jpeg",
            "isPro": false,
            "fullname": "Jinbo Xing",
            "user": "Doubiiu",
            "type": "user"
          },
          "name": "Jinbo Xing",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-03-10T08:00:40.328Z",
          "hidden": false
        },
        {
          "_id": "67ce8388764226f050ad18b6",
          "user": {
            "_id": "63ca3ddc04c979828310bfcb",
            "avatarUrl": "/avatars/615e0d8622950b4408b40d550f02a894.svg",
            "isPro": false,
            "fullname": "Ying Shan",
            "user": "yshan2u",
            "type": "user"
          },
          "name": "Ying Shan",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-03-10T10:06:56.510Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-03-07T17:57:53.000Z",
      "title": "Traductor: Líder del Proyecto: Redirecciona el trayecto de cámara de vídeo monolítico mediante un modelo de difusión.",
      "summary": "Aquí se presenta un nuevo enfoque llamado TrajectoryCrafter. Este método permite redireccionar los caminos de la cámara de vídeos con defectos. Separa claramente la transformación visual y la generación de contenido estridente, y permite al usuario controlar rigurosamente el camino de la cámara que elija. Se propone un nuevo modelo de difusor de vídeo con condiciones de doble streaming. Este modelo integra el rendering de nubes puntuales y el vídeo original, asegurando una transformación visual precisa y el generación de contenido 4D colorido. Aunque se utiliza vídeo de múltiples puntos, se combina con vídeos de defecto de tamaño de red de redes y conjuntos de datos estáticos de múltiples puntos para crear un conjunto de datos de entrenamiento híbrido. Esto fomenta una fortaleza generalizada a diferentes escalas a través de nuestra estrategia de doble reprojección. Los evaluaciones en vídeos de múltiples puntos y de grandes defectos muestran el alto rendimiento de nuestro método, lo que demuestra su excelencia.",
      "upvotes": 8,
      "discussionId": "67ce838a764226f050ad1952",
      "projectPage": "https://trajectorycrafter.github.io/",
      "githubRepo": "https://github.com/TrajectoryCrafter/TrajectoryCrafter"
    },
    "publishedAt": "2025-03-10T02:24:39.763Z",
    "title": "TrajectoryCrafter: Redirecting Camera Trajectory for Monocular Videos via Diffusion Models",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/657a7458afbb0117ba15c59f/lpXbCmGz-upwRVSEUzBjV.mp4"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.05638.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "657a7458afbb0117ba15c59f",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/657a7458afbb0117ba15c59f/8_iwTS1UG_mKnfylFbLsY.jpeg",
      "fullname": "Wenbo Hu",
      "name": "wbhu-tc",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 3
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2503.05652",
      "authors": [
        {
          "_id": "67ce524ee969bc5fd69c9388",
          "user": {
            "_id": "61e9f5398c237a147a3f4ab5",
            "avatarUrl": "/avatars/afd4ec17cb132b5ab56e50a678c4786d.svg",
            "isPro": false,
            "fullname": "Yunfan Jiang",
            "user": "yunfanj",
            "type": "user"
          },
          "name": "Yunfan Jiang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-03-10T08:01:07.901Z",
          "hidden": false
        },
        {
          "_id": "67ce524ee969bc5fd69c9389",
          "name": "Ruohan Zhang",
          "hidden": false
        },
        {
          "_id": "67ce524ee969bc5fd69c938a",
          "name": "Josiah Wong",
          "hidden": false
        },
        {
          "_id": "67ce524ee969bc5fd69c938b",
          "name": "Chen Wang",
          "hidden": false
        },
        {
          "_id": "67ce524ee969bc5fd69c938c",
          "user": {
            "_id": "63509bc859bfa9a85d4220aa",
            "avatarUrl": "/avatars/ca2cc9b87f5ca5cd51606b2f9edf89d0.svg",
            "isPro": false,
            "fullname": "Yanjie Ze",
            "user": "yjze",
            "type": "user"
          },
          "name": "Yanjie Ze",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-03-10T08:01:05.242Z",
          "hidden": false
        },
        {
          "_id": "67ce524ee969bc5fd69c938d",
          "name": "Hang Yin",
          "hidden": false
        },
        {
          "_id": "67ce524ee969bc5fd69c938e",
          "name": "Cem Gokmen",
          "hidden": false
        },
        {
          "_id": "67ce524ee969bc5fd69c938f",
          "name": "Shuran Song",
          "hidden": false
        },
        {
          "_id": "67ce524ee969bc5fd69c9390",
          "name": "Jiajun Wu",
          "hidden": false
        },
        {
          "_id": "67ce524ee969bc5fd69c9391",
          "name": "Li Fei-Fei",
          "hidden": false
        }
      ],
      "publishedAt": "2025-03-07T18:15:21.000Z",
      "title": "Boy Autrobotto Suit: Permite realizar movimientos de la vida diaria con facilidad.",
      "summary": "La vida cotidiana de hogares en la realidad presenta grandes desafíos para los robots móviles. En el análisis de los marcos de referencia de la tecnología de robots, se ha demostrado que la ejecución de tareas exitosas depende de tres principales capacidades de control corporal general: la manipulación de objetos, la navegación estable y precisa, y la accesibilidad de los extremos distribuidos. Para alcanzar estas capacidades, es necesario diseñar hardware exigente, pero el resultado es que el aprendizaje de políticas empresariales se vuelve más complejo. Para enfrentar estos desafíos, presentamos un marco riguroso para el funcionamiento general en diversas tareas de hogar, denominado Suit de Robot Behavior (BRS). La manipulación de objetos se realiza a través de un robot de soporte (holder robot) con un brazo de 4 grados de libertad, lo que integra una interfaz eficiente para la recolección de datos y la teleoperación, y se utiliza un algoritmo nuevo para integrar algoritmos para el aprendizaje de políticas empresariales. La BRS destaca tres capacidades clave: navegación a larga distancia, interacción con objetos de arquitectura y variabilidad, y trabajo en espacios estrechos, evaluándose en cinco tareas de hogar adicionalmente complejas. La integración de la interfaz de colección de datos, el robot Efemeba, y el marco de aprendizaje de la BRS permite un funcionamiento general en tareas cotidianas de hogar, considerado un paso importante. La BRS está disponible como código abierto en https://behavior-robot-suite.github.io/.",
      "upvotes": 7,
      "discussionId": "67ce5294e969bc5fd69c9a2c",
      "projectPage": "https://behavior-robot-suite.github.io/",
      "githubRepo": "https://github.com/behavior-robot-suite/brs-algo"
    },
    "publishedAt": "2025-03-09T22:51:04.616Z",
    "title": "BEHAVIOR Robot Suite: Streamlining Real-World Whole-Body Manipulation for Everyday Household Activities",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/61e9f5398c237a147a3f4ab5/WD3cV-QLiHRgh4IUOrikN.mp4"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.05652.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "61e9f5398c237a147a3f4ab5",
      "avatarUrl": "/avatars/afd4ec17cb132b5ab56e50a678c4786d.svg",
      "fullname": "Yunfan Jiang",
      "name": "yunfanj",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2503.05379",
      "authors": [
        {
          "_id": "67ce5f2389663abdbc364495",
          "name": "Jiaxing Zhao",
          "hidden": false
        },
        {
          "_id": "67ce5f2389663abdbc364496",
          "name": "Xihan Wei",
          "hidden": false
        },
        {
          "_id": "67ce5f2389663abdbc364497",
          "name": "Liefeng Bo",
          "hidden": false
        }
      ],
      "publishedAt": "2025-03-07T12:46:42.000Z",
      "title": "R1-Omni: Reconocimiento de emociones omnimodal interpretable y aprendizaje por refuerzo utilizados",
      "summary": "En este estudio, se aplica por primera vez una aplicación de aprendizaje reforzado (RLVR) que tiene un recompensa comprobable en el centro del reconocimiento de emociones, aplicando-la a un modelo multimodal Omni-lingüístico. En este trabajo, los modelos visuales y sonoros desempeñan un papel importante. Utilizando RLVR, se optimiza el modelo Omni, mejorando significativamente su capacidad de lógica, precisión en el reconocimiento de emociones y su capacidad de generalización en tres aspectos principales. La introducción de RLVR no solo mejora la calidad general de los datos internos, sino que también muestra una excelente robustez en conjuntos de datos externos. Lo más importante es que el aumento de la capacidad de lógica permite analizar de manera clara la influencia que tiene el proceso de reconocimiento de emociones en diferentes modelos. Esto contribuye a la optimización general del modelo multimodal lingüístico.",
      "upvotes": 6,
      "discussionId": "67ce5f2489663abdbc3644d0"
    },
    "publishedAt": "2025-03-09T23:40:46.906Z",
    "title": "R1-Omni: Explainable Omni-Multimodal Emotion Recognition with Reinforcing Learning",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.05379.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 6317
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2503.04872",
      "authors": [
        {
          "_id": "67ce5deedb623d45a95deb72",
          "user": {
            "_id": "632c30576bcb864974cc40a8",
            "avatarUrl": "/avatars/96aa948ad1dd35d355e20b5765a2563a.svg",
            "isPro": false,
            "fullname": "sunlin",
            "user": "lincharliesun",
            "type": "user"
          },
          "name": "Lin Sun",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-03-10T08:00:47.601Z",
          "hidden": false
        },
        {
          "_id": "67ce5deedb623d45a95deb73",
          "name": "Guangxiang Zhao",
          "hidden": false
        },
        {
          "_id": "67ce5deedb623d45a95deb74",
          "name": "Xiaoqi Jian",
          "hidden": false
        },
        {
          "_id": "67ce5deedb623d45a95deb75",
          "name": "Yuhan Wu",
          "hidden": false
        },
        {
          "_id": "67ce5deedb623d45a95deb76",
          "name": "Weihong Lin",
          "hidden": false
        },
        {
          "_id": "67ce5deedb623d45a95deb77",
          "name": "Yongfu Zhu",
          "hidden": false
        },
        {
          "_id": "67ce5deedb623d45a95deb78",
          "name": "Change Jia",
          "hidden": false
        },
        {
          "_id": "67ce5deedb623d45a95deb79",
          "name": "Linglin Zhang",
          "hidden": false
        },
        {
          "_id": "67ce5deedb623d45a95deb7a",
          "name": "Jinzhu Wu",
          "hidden": false
        },
        {
          "_id": "67ce5deedb623d45a95deb7b",
          "name": "Junfeng Ran",
          "hidden": false
        },
        {
          "_id": "67ce5deedb623d45a95deb7c",
          "name": "Sai-er Hu",
          "hidden": false
        },
        {
          "_id": "67ce5deedb623d45a95deb7d",
          "name": "Zihan Jiang",
          "hidden": false
        },
        {
          "_id": "67ce5deedb623d45a95deb7e",
          "name": "Junting Zhou",
          "hidden": false
        },
        {
          "_id": "67ce5deedb623d45a95deb7f",
          "name": "Wenrui Liu",
          "hidden": false
        },
        {
          "_id": "67ce5deedb623d45a95deb80",
          "name": "Bin Cui",
          "hidden": false
        },
        {
          "_id": "67ce5deedb623d45a95deb81",
          "name": "Tong Yang",
          "hidden": false
        },
        {
          "_id": "67ce5deedb623d45a95deb82",
          "name": "Xiangzheng Zhang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-03-06T16:25:53.000Z",
      "title": "TinyR1-32B-Preview: Mejora de la precisión mediante entrenamiento de ajuste de equipos de branch",
      "summary": "Se enfoca en el problema de reducir el tamaño de un LLM mientras mantiene su rendimiento. Sin embargo, actualmente, las métodos tienen dificultades para alcanzar altas precisión en modelos que requieren entrenamiento de calentamiento y transeño. Para resolver esta limitación, se propone un enfoque de calentamiento con Branch-Merge. Este enfoque fortalece la compresión del modelo en dos pasos. Primero, en la fase de Branch, se seleccionan conocimientos de un gran modelo de entrenamiento y se calientan específicamente los modelos estudiantes a través de un aprendizaje observacional especializado (SFT). Luego, en la fase de Merge, se integran estos modelos estudiantes para facilitar la transferencia de conocimientos entre dominios y mejorar la generalización. Se valida este enfoque usando DeepSeek-R1 como modelo de entrenamiento y DeepSeek-R1-Distill-Qwen-32B como modelo estudiante. El resultado es que el modelo sintetizado, TinyR1-32B-Preview, supera a DeepSeek-R1-Distill-Qwen-32B en múltiples benchmarks, incluyendo matemáticas (+5.5 puntos), programación (+4.4 puntos) y ciencias (+2.9 puntos). Además, en el AIME 2024, logró un rendimiento similar a DeepSeek-R1. El enfoque de calentamiento con Branch-Merge proporciona una solución escalable para crear pequeños LLMs de alto rendimiento, reduciendo costos computacionales y tiempo.",
      "upvotes": 5,
      "discussionId": "67ce5df0db623d45a95dec1f"
    },
    "publishedAt": "2025-03-09T23:35:58.424Z",
    "title": "TinyR1-32B-Preview: Boosting Accuracy with Branch-Merge Distillation",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.04872.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 6317
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2503.05447",
      "authors": [
        {
          "_id": "67ceab4132a6585cecad2c36",
          "user": {
            "_id": "6246bb33da617c00b48e4d92",
            "avatarUrl": "/avatars/0304a9f6eb7f5dee4d933d03222f94e9.svg",
            "isPro": false,
            "fullname": "Weigao Sun",
            "user": "weigao266",
            "type": "user"
          },
          "name": "Weigao Sun",
          "status": "extracted_confirmed",
          "statusLastChangedAt": "2025-03-10T09:09:22.436Z",
          "hidden": false
        },
        {
          "_id": "67ceab4132a6585cecad2c37",
          "name": "Disen Lan",
          "hidden": false
        },
        {
          "_id": "67ceab4132a6585cecad2c38",
          "name": "Tong Zhu",
          "hidden": false
        },
        {
          "_id": "67ceab4132a6585cecad2c39",
          "name": "Xiaoye Qu",
          "hidden": false
        },
        {
          "_id": "67ceab4132a6585cecad2c3a",
          "name": "Yu Cheng",
          "hidden": false
        }
      ],
      "publishedAt": "2025-03-07T14:17:45.000Z",
      "title": "Linear-MoE: Modelo de secuencia lineal y mezcla de fuentes",
      "summary": "Linear-MoE es un sistema de producción para modelar y entrenar grandes modelos que integran el Linear-Sequence Modeling (LSM) y el Mixture of Experts (MoE). Este sistema se beneficia de la excelente capacidad de modelar secuencias de baja complejidad lineal y la eficiencia de activación esparsa proporcionada por la capa MoE, lo que permite entrenar de manera eficiente y obtener altos rendimientos. El sistema Linear-MoE está constituido por dos sub-sistemas: el sub-sistema de modelado, que ofrece un marco integrado que soporta todas las instancias de LSM, y el sub-sistema de entrenamiento, que promueve la entrenamiento eficiente a través de técnicas de paralelización progresiva. En particular, se diseñó la paralelización de secuencias para el modelo Linear-MoE. Además, se revisaron modelos híbridos que combinan las capas Linear-MoE y las capas Transformer-MoE estándares, lo que permite mejorar la flexibilidad y el rendimiento del modelo utilizando la paralelización de secuencias. Las evaluaciones de dos series de modelos, A0.3B-2B y A1B-7B, muestran que Linear-MoE mejora la eficiencia del entrenamiento mientras mantiene un rendimiento competitivo en diferentes marcos de referencia, demostrando la posibilidad de la arquitectura básica de modelos futuros. El código está disponible en https://github.com/OpenSparseLLMs/Linear-MoE.",
      "upvotes": 3,
      "discussionId": "67ceab4232a6585cecad2c82",
      "githubRepo": "https://github.com/OpenSparseLLMs/Linear-MoE"
    },
    "publishedAt": "2025-03-10T05:05:22.522Z",
    "title": "Linear-MoE: Linear Sequence Modeling Meets Mixture-of-Experts",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.05447.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6246bb33da617c00b48e4d92",
      "avatarUrl": "/avatars/0304a9f6eb7f5dee4d933d03222f94e9.svg",
      "fullname": "Weigao Sun",
      "name": "weigao266",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 3
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2503.01713",
      "authors": [
        {
          "_id": "67c75e18cb29e2a4b0eb0293",
          "user": {
            "_id": "66c0a08bac74db25de8427ec",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/66c0a08bac74db25de8427ec/9D-piDBZqSt6KNkHImmkv.jpeg",
            "isPro": false,
            "fullname": "Jintao Zhang",
            "user": "jt-zhang",
            "type": "user"
          },
          "name": "Jintao Zhang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-03-07T09:26:50.367Z",
          "hidden": false
        },
        {
          "_id": "67c75e18cb29e2a4b0eb0294",
          "name": "Guoliang Li",
          "hidden": false
        },
        {
          "_id": "67c75e18cb29e2a4b0eb0295",
          "name": "Jinyang Su",
          "hidden": false
        }
      ],
      "publishedAt": "2025-03-03T16:25:58.000Z",
      "title": "SAGE: Marco de evaluación adecuado",
      "summary": "El Retórico de la Lectura (RAG) muestra significativos resultados en tareas de respuesta a preguntas (QA) dentro de un corpus específico. Sin embargo, existen muchos casos de fracaso en la implementación de RAG. Estos fracasos no son debidos a las limitaciones de los modelos de lenguaje grandes (LLMs), sino a dos limitaciones principales: 1. Los métodos actuales de RAG dividen el corpus sin considerar la semántica, lo que perde la relación entre la pregunta y los segmentos divididos, dificultando la identificación de contextos relevantes. 2. Existe una discrepancia entre la cantidad de contexto y la cantidad de contexto extraído. En este artículo, se presenta un nuevo framework de RAG llamado SAGE para superar estas limitaciones. Primero, se propone un modelo de división semántica para resolver el problema de la división sin considerar la semántica. Este modelo se ha entrenado para dividir el corpus en contextos completamente basados en semántica. 2. Para obtener solo el contexto más adecuado y ignorar contextos irrelevantes, se diseña un algoritmo de selección de contexto que decide el contexto basándose en la velocidad de declive del puntaje de relevancia. 3. Para mejorar la precisión del contexto, se propone evaluar si el contexto obtenido por los LLMs es excesivo o insuficiente y ajusta su cantidad. Las experimentaciones muestran que SAGE mejora la calidad de la respuesta en un promedio del 61.25%. Además, evita obtener contextos con ruido, reduciendo los costos de tokens utilizados en la inferencia de los LLMs y logrando una mejora de costo eficiencia del 49.41%. Nuestro estudio ofrece una visión valiosa para el fortalecimiento de RAG.",
      "upvotes": 3,
      "discussionId": "67c75e1ccb29e2a4b0eb03a9"
    },
    "publishedAt": "2025-03-10T03:23:51.482Z",
    "title": "SAGE: A Framework of Precise Retrieval for RAG",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.01713.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "66c0a08bac74db25de8427ec",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/66c0a08bac74db25de8427ec/9D-piDBZqSt6KNkHImmkv.jpeg",
      "fullname": "Jintao Zhang",
      "name": "jt-zhang",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 3
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2503.05315",
      "authors": [
        {
          "_id": "67ce6db07110b8bedb3344a7",
          "name": "Saumya Chaturvedi",
          "hidden": false
        },
        {
          "_id": "67ce6db07110b8bedb3344a8",
          "user": {
            "_id": "63a4754927f1f64ed7238dac",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63a4754927f1f64ed7238dac/aH-eJF-31g4vof9jv2gmI.jpeg",
            "isPro": false,
            "fullname": "Aman Chadha",
            "user": "amanchadha",
            "type": "user"
          },
          "name": "Aman Chadha",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-03-10T08:00:45.150Z",
          "hidden": false
        },
        {
          "_id": "67ce6db07110b8bedb3344a9",
          "name": "Laurent Bindschaedler",
          "hidden": false
        }
      ],
      "publishedAt": "2025-03-07T10:50:45.000Z",
      "title": "LoRACode: Adapters para Código para Código 🔗\n\n(Nota: El texto original \"LoRA アダプターズ for Code エンベディング\" se tradujo como \"LoRA 어댑터즈 for Code 엮기\" para mantener el significado más cercano en el idioma coreano. El término \"エンベディング\" se tradujo como \"엮기\" ya que es un término común en el contexto del código de enrolamiento o integración en el coreano.)",
      "summary": "Cómo el codificamiento es crucial para búsquedas de código semántica, pero la actual metodología a menudo no logra fácilmente capturar la gramática precisa y el contexto nuevo de un código. Modelos como CodeBERT y UniXcoder de código abierto tienen limitaciones en escalabilidad y eficiencia, y sistemas de propiedad con alto rendimiento incurren en altos costos computacionales. Introducimos un método de adaptación basado en LoRA (Low-Rank Adaptation) para fines de parámetros eficientes, y construimos adaptadores de tarea para aplicarlo en búsquedas de código. Nuestro enfoque restringe el número de parámetros de entrenamiento del modelo base a menos del 2%, permitiendo un ajuste eficiente en un corpus de código amplio de 2 millones de muestras en solo 25 minutos con dos GPU H100. Los experimentos mostraron un aumento del Mean Reciprocal Rank (MRR) en búsquedas de Código2Code del 9.1% y un aumento del 86.69% en tareas de búsqueda de Código2Text en varios lenguajes de programación. Investigamos las diferencias en adaptación según la tarea y el lenguaje, así como la sensibilidad a cambios gramaticales y lingüísticos en búsquedas de código.",
      "upvotes": 2,
      "discussionId": "67ce6db17110b8bedb3344c5"
    },
    "publishedAt": "2025-03-10T00:51:02.203Z",
    "title": "LoRACode: LoRA Adapters for Code Embeddings",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.05315.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "63a4754927f1f64ed7238dac",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63a4754927f1f64ed7238dac/aH-eJF-31g4vof9jv2gmI.jpeg",
      "fullname": "Aman Chadha",
      "name": "amanchadha",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 3
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2503.05132",
      "authors": [
        {
          "_id": "67ce5ec17c6e6ea1cc5649c2",
          "name": "Hengguang Zhou",
          "hidden": false
        },
        {
          "_id": "67ce5ec17c6e6ea1cc5649c3",
          "name": "Xirui Li",
          "hidden": false
        },
        {
          "_id": "67ce5ec17c6e6ea1cc5649c4",
          "name": "Ruochen Wang",
          "hidden": false
        },
        {
          "_id": "67ce5ec17c6e6ea1cc5649c5",
          "name": "Minhao Cheng",
          "hidden": false
        },
        {
          "_id": "67ce5ec17c6e6ea1cc5649c6",
          "name": "Tianyi Zhou",
          "hidden": false
        },
        {
          "_id": "67ce5ec17c6e6ea1cc5649c7",
          "name": "Cho-Jui Hsieh",
          "hidden": false
        }
      ],
      "publishedAt": "2025-03-07T04:21:47.000Z",
      "title": "\"R1-Zero's 'Ahaモーメント' y el estudio de la teoría de la visión en modelos 2B no SFT\"",
      "summary": "Recientemente, DeepSeek R1 ha demostrado que un aprendizaje por refuerzo que utiliza recompensas basadas en reglas simples puede automaticamente desarrollar complejas teorías de razonamiento en modelos de lenguaje grandes, mostrando una característica llamada \"agent moment\". Sin embargo, los intentos de extender estos éxitos a más teorías de razonamiento han fallado en recrear esas características importantes. En este informe, se reporta el primer éxito significativo en recrear esta característica en un modelo no SFT de 2B. A partir de Qwen2-VL-2B, se aplicó el aprendizaje por refuerzo directamente en el conjunto de datos SAT, logrando una precisión de 59.47% en CVBench, mejorando significativamente (más de 30%) sobre el modelo base y (aproximadamente 2%) sobre los ajustes de SFT. Además, se comparte el fracaso y retroalimentación de los intentos de utilizar el aprendizaje por refuerzo para lograr la teoría de R1, y se realizaron esfuerzos para clarificar los problemas. Las principales observaciones son: (1) la acumulación lógica en modelos de instrucciones que introduciron el aprendizaje por refuerzo puede ser leve, y (2) la recompensa por longitud aleatoria no tiene efecto en la capacidad de la razonamiento. El código del proyecto está disponible en https://github.com/turningpoint-ai/VisualThinker-R1-Zero.",
      "upvotes": 2,
      "discussionId": "67ce5ec27c6e6ea1cc564a01"
    },
    "publishedAt": "2025-03-09T23:39:12.374Z",
    "title": "R1-Zero's \"Aha Moment\" in Visual Reasoning on a 2B Non-SFT Model",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.05132.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 6317
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2503.04808",
      "authors": [
        {
          "_id": "67ce5c7065b141ae6b0d3957",
          "name": "Stephen Chung",
          "hidden": false
        },
        {
          "_id": "67ce5c7065b141ae6b0d3958",
          "name": "Wenyu Du",
          "hidden": false
        },
        {
          "_id": "67ce5c7065b141ae6b0d3959",
          "name": "Jie Fu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-03-04T02:53:39.000Z",
      "title": "Repetición del aprendizaje como respuesta al fracaso del aprendizaje",
      "summary": "Recientemente, el desarrollo de aprendizaje reforzado (RL) en los grandes modelos de lenguaje (LLM) ha mostrado notables mejoras, como en el caso de DeepSeek R1, que ha demostrado un gran aumento en la capacidad lógica de los LLM incluso en tareas de respuesta a preguntas simples. En este artículo, se extiende esta metodología para cambiar a un enfoque multi-attempt. En lugar de responder directamente a las preguntas, el modelo puede realizar varias intentaciones y recibir retroalimentación después de cada fallo. Esta aproximación es especialmente útil para tareas multi-attempt, donde el modelo puede mejorar sus intentos anteriores y aumentar la eficiencia de la búsqueda. Los resultados de los experimentos muestran que la precisión se ha incrementado significativamente en el marco de un benchmark de matemáticas, desde un 45.6% en el enfoque de un intento hasta un 52.5% con el enfoque de dos intentos. De manera interesante, al comparar con un LLM que ha sido entrenado en tareas estándar de un intento, no se observa esta mejora al proporcionar más intentos durante la evaluación. Estos resultados indican que un LLM entrenado en tareas multi-attempt puede alcanzar un rendimiento mejor en los benchmarks de matemáticas y, al mismo tiempo, puede mejorar eficazmente su respuesta según la retroalimentación del usuario. El código completo está disponible en: https://github.com/DualityRL/multi-attempt.",
      "upvotes": 2,
      "discussionId": "67ce5c7165b141ae6b0d39c6"
    },
    "publishedAt": "2025-03-09T23:29:35.505Z",
    "title": "Learning from Failures in Multi-Attempt Reinforcement Learning",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.04808.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 6317
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2503.04548",
      "authors": [
        {
          "_id": "67cbff8e4dedec48bdec8a99",
          "name": "Zhipeng Chen",
          "hidden": false
        },
        {
          "_id": "67cbff8e4dedec48bdec8a9a",
          "user": {
            "_id": "6703ac76ea890f0ca5b225eb",
            "avatarUrl": "/avatars/5f56c49a1940143d47dd484782a4abbf.svg",
            "isPro": false,
            "fullname": "Yingqian Min",
            "user": "EliverQ",
            "type": "user"
          },
          "name": "Yingqian Min",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-03-10T08:02:04.349Z",
          "hidden": false
        },
        {
          "_id": "67cbff8e4dedec48bdec8a9b",
          "name": "Beichen Zhang",
          "hidden": false
        },
        {
          "_id": "67cbff8e4dedec48bdec8a9c",
          "name": "Jie Chen",
          "hidden": false
        },
        {
          "_id": "67cbff8e4dedec48bdec8a9d",
          "name": "Jinhao Jiang",
          "hidden": false
        },
        {
          "_id": "67cbff8e4dedec48bdec8a9e",
          "name": "Daixuan Cheng",
          "hidden": false
        },
        {
          "_id": "67cbff8e4dedec48bdec8a9f",
          "name": "Wayne Xin Zhao",
          "hidden": false
        },
        {
          "_id": "67cbff8e4dedec48bdec8aa0",
          "name": "Zheng Liu",
          "hidden": false
        },
        {
          "_id": "67cbff8e4dedec48bdec8aa1",
          "name": "Xu Miao",
          "hidden": false
        },
        {
          "_id": "67cbff8e4dedec48bdec8aa2",
          "name": "Yang Lu",
          "hidden": false
        },
        {
          "_id": "67cbff8e4dedec48bdec8aa3",
          "name": "Lei Fang",
          "hidden": false
        },
        {
          "_id": "67cbff8e4dedec48bdec8aa4",
          "name": "Zhongyuan Wang",
          "hidden": false
        },
        {
          "_id": "67cbff8e4dedec48bdec8aa5",
          "name": "Ji-Rong Wen",
          "hidden": false
        }
      ],
      "publishedAt": "2025-03-06T15:34:27.000Z",
      "title": "「Estudio sobre la producción y mejora del R1 modelo」",
      "summary": "Este informe presenta el tercer tipo de informe técnico sobre el desarrollo del modelo de \"slow thinking\" del proyecto STILL. Con el patrón de la tecnología se ha definido, la escalado de entrenamiento de RL (Reinforcement Learning) se ha convertido en el centro de la implementación de este modelo lógico. Se ha experimentado y registrado el efecto de varios factores que influyen en el entrenamiento de RL de manera sistemática. Se han probado tanto modelos básicos como modelos fine-tunados. En particular, se ha demostrado que nuestro enfoque de entrenamiento de RL mejora de manera coherente el modelo básico Qwen2.5-32B, aumentando la longitud de las respuestas y la precisión en pruebas. Además, se ha mostrado que modelos como DeepSeek-R1-Distill-Qwen-1.5B, al desarrollarse con RL, alcanzan niveles de rendimiento altos, como la precisión del 39.33% en el AIME 2024. Al más allá del entrenamiento de RL, se ha revisado el uso de herramientas y se ha descubierto que estas mejoran significativamente el rendimiento lógico de modelos grandes. Este enfoque ha demostrado su eficacia en el AIME 2024, al alcanzar una precisión del 86.67% utilizando búsqueda estratégica, mostrando claramente el potencial de mejorar la capacidad del modelo. Se publican los recursos del proyecto STILL en su sitio web: https://github.com/RUCAIBox/Slow_Thinking_with_LLMs.",
      "upvotes": 1,
      "discussionId": "67cbff8f4dedec48bdec8af3"
    },
    "publishedAt": "2025-03-10T05:23:26.375Z",
    "title": "An Empirical Study on Eliciting and Improving R1-like Reasoning Models",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.04548.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6703ac76ea890f0ca5b225eb",
      "avatarUrl": "/avatars/5f56c49a1940143d47dd484782a4abbf.svg",
      "fullname": "Yingqian Min",
      "name": "EliverQ",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2503.04504",
      "authors": [
        {
          "_id": "67cb8e882cfa481bcee9455e",
          "user": {
            "_id": "66a07c07b7f0bb64d3b35497",
            "avatarUrl": "/avatars/c38af1ddb7a5b625e26b7ff05957ff7c.svg",
            "isPro": false,
            "fullname": "SunghyunAhn",
            "user": "SkiddieAhn",
            "type": "user"
          },
          "name": "Sunghyun Ahn",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-03-10T08:02:12.798Z",
          "hidden": false
        },
        {
          "_id": "67cb8e882cfa481bcee9455f",
          "user": {
            "_id": "673d7b70713e4b8db2d5ca94",
            "avatarUrl": "/avatars/b9e89eba62eb939ddd93c1cb91744e93.svg",
            "isPro": false,
            "fullname": "Youngwan Jo",
            "user": "jyy1551",
            "type": "user"
          },
          "name": "Youngwan Jo",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-03-10T08:02:08.710Z",
          "hidden": false
        },
        {
          "_id": "67cb8e882cfa481bcee94560",
          "name": "Kijung Lee",
          "hidden": false
        },
        {
          "_id": "67cb8e882cfa481bcee94561",
          "name": "Sein Kwon",
          "hidden": false
        },
        {
          "_id": "67cb8e882cfa481bcee94562",
          "name": "Inpyo Hong",
          "hidden": false
        },
        {
          "_id": "67cb8e882cfa481bcee94563",
          "name": "Sanghyun Park",
          "hidden": false
        }
      ],
      "publishedAt": "2025-03-06T14:52:34.000Z",
      "title": "AnyAnomaly: Detección de anomalías en vídeos basada en 0-shot con LVLM para personalización del usuario",
      "summary": "El detección de anomalías en video (VAD) es crucial para el análisis de vídeos computacionales y la salud del consumidor. Sin embargo, los modelos actuales de VAD dependen de patrones normales entrenados y tienen dificultades para aplicarse en diferentes entornos. Como resultado, los usuarios deben reentrenar el modelo o desarrollar otros modelos de IA para adaptarse a nuevos entornos. Esto requiere conocimientos profesionales en aprendizaje automático, hardware de alta eficiencia y métodos de recolección de datos ampliados, lo que limita la utilización práctica de VAD. Para resolver estos problemas, en este estudio se propone la tecnología de detección de anomalías en video (C-VAD) y el modelo AnyAnomaly. C-VAD procesa eventos anormales basándose en textos definidos por el usuario y detecta los frames que incluyen eventos específicos dentro del video. AnyAnomaly se implementa eficazmente mediante ajustes de modelos de lenguaje de vídeo a gran escala, excluyendo ajustes de finetuning. Para probar la efectividad de los modelos propuestos, se construyó un conjunto de datos C-VAD y se demostró la superioridad de AnyAnomaly. Además, nuestro enfoque demostró un rendimiento competitivo en los conjuntos de datos de benchmark de VAD, alcanzó los resultados más avanzados en el conjunto de datos UBnormal, y mostró una superioridad en términos de escalabilidad en todos los conjuntos de datos. Nuestro código está disponible en github.com/SkiddieAhn/Paper-AnyAnomaly.",
      "upvotes": 0,
      "discussionId": "67cb8e8a2cfa481bcee945cd",
      "githubRepo": "https://github.com/SkiddieAhn/Paper-AnyAnomaly"
    },
    "publishedAt": "2025-03-10T04:06:49.447Z",
    "title": "AnyAnomaly: Zero-Shot Customizable Video Anomaly Detection with LVLM",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/66a07c07b7f0bb64d3b35497/TNPrQD3FdFBVVW2pUoEnU.gif",
      "https://cdn-uploads.huggingface.co/production/uploads/66a07c07b7f0bb64d3b35497/cA30QnSF_7AeHciWhCFSN.gif",
      "https://cdn-uploads.huggingface.co/production/uploads/66a07c07b7f0bb64d3b35497/T9EwE4Ea7DrH3XVZ_eJ1g.gif",
      "https://cdn-uploads.huggingface.co/production/uploads/66a07c07b7f0bb64d3b35497/Duuqk_Ph1GNfz6HW2Qv5g.gif",
      "https://cdn-uploads.huggingface.co/production/uploads/66a07c07b7f0bb64d3b35497/-Dze7JwIaBTbCfXUetsCd.gif"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.04504.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "66a07c07b7f0bb64d3b35497",
      "avatarUrl": "/avatars/c38af1ddb7a5b625e26b7ff05957ff7c.svg",
      "fullname": "SunghyunAhn",
      "name": "SkiddieAhn",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  }
]