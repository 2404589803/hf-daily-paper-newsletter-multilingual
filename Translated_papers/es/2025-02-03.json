[
  {
    "paper": {
      "id": "2501.19393",
      "authors": [
        {
          "_id": "67a02dd80e751b0476a1bcc6",
          "name": "Niklas Muennighoff",
          "hidden": false
        },
        {
          "_id": "67a02dd80e751b0476a1bcc7",
          "name": "Zitong Yang",
          "hidden": false
        },
        {
          "_id": "67a02dd80e751b0476a1bcc8",
          "name": "Weijia Shi",
          "hidden": false
        },
        {
          "_id": "67a02dd80e751b0476a1bcc9",
          "name": "Xiang Lisa Li",
          "hidden": false
        },
        {
          "_id": "67a02dd80e751b0476a1bcca",
          "name": "Li Fei-Fei",
          "hidden": false
        },
        {
          "_id": "67a02dd80e751b0476a1bccb",
          "name": "Hannaneh Hajishirzi",
          "hidden": false
        },
        {
          "_id": "67a02dd80e751b0476a1bccc",
          "name": "Luke Zettlemoyer",
          "hidden": false
        },
        {
          "_id": "67a02dd80e751b0476a1bccd",
          "name": "Percy Liang",
          "hidden": false
        },
        {
          "_id": "67a02dd80e751b0476a1bcce",
          "name": "Emmanuel Candès",
          "hidden": false
        },
        {
          "_id": "67a02dd80e751b0476a1bccf",
          "name": "Tatsunori Hashimoto",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-31T18:48:08.000Z",
      "title": "s1: Programación de tiempos simples de prueba",
      "summary": "El escalado durante el test es un método para mejorar la eficiencia de un modelo de lenguaje nuevo al agregar más capacidades de cálculo durante el entrenamiento. Recientemente, el modelo o1 de OpenAI ha demostrado esta capacidad, pero por no haber publicado los métodos, varios esfuerzos de replicación han sido realizados. Buscamos encontrar la manera más sencilla para implementar el escalado durante el test y un potente rendimiento teórico.\n\nPrimero, seleccionamos un conjunto de datos s1K de 1,000 conjuntos, evaluados en dificultad, diversidad y calidad. Este conjunto incluye combinaciones de problemas que incluyen trazas teóricas y sus respuestas. Luego, desarrollamos una gestión para controlar la cantidad de cálculos durante el test, haciendo que el modelo termine su proceso de pensamiento forzadamente. Esto permite añadir múltiples \"pesos\" al modelo cuando intenta terminar su respuesta, extendiendo su proceso de pensamiento. De esta manera, el modelo puede revisar su respuesta y corregir los pasos teóricos incorrectos.\n\nEl modelo de lenguaje Qwen2.5-32B-Instruct, normalizado con s1K y con la gestión añadida, se denomina modelo s1. Este modelo ha mejorado en problemas de Mayores competencias en un porcentaje aproximado de 27% más que el modelo o1-preview (MATH y AIME24). Además, el uso de la gestión permite expandir el rendimiento del modelo s1 sin necesidad de responder a las pruebas, alcanzando mejoras del 50% a 57% en AIME24. Nuestro modelo, datos y código están disponibles en https://github.com/simplescaling/s1.",
      "upvotes": 21,
      "discussionId": "67a02dd90e751b0476a1bd02"
    },
    "publishedAt": "2025-02-02T21:45:49.841Z",
    "title": "s1: Simple test-time scaling",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.19393.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5912
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.19324",
      "authors": [
        {
          "_id": "67a04151dd7b3a4aba880589",
          "name": "Baohao Liao",
          "hidden": false
        },
        {
          "_id": "67a04151dd7b3a4aba88058a",
          "name": "Yuhui Xu",
          "hidden": false
        },
        {
          "_id": "67a04151dd7b3a4aba88058b",
          "name": "Hanze Dong",
          "hidden": false
        },
        {
          "_id": "67a04151dd7b3a4aba88058c",
          "name": "Junnan Li",
          "hidden": false
        },
        {
          "_id": "67a04151dd7b3a4aba88058d",
          "name": "Christof Monz",
          "hidden": false
        },
        {
          "_id": "67a04151dd7b3a4aba88058e",
          "name": "Silvio Savarese",
          "hidden": false
        },
        {
          "_id": "67a04151dd7b3a4aba88058f",
          "name": "Doyen Sahoo",
          "hidden": false
        },
        {
          "_id": "67a04151dd7b3a4aba880590",
          "name": "Caiming Xiong",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-31T17:19:57.000Z",
      "title": "La utilización de la decodificación de la guía de Ribeiro para Doripeki en cálculos eficientes de modelos de lenguaje grandes (LLM)",
      "summary": "Introducimos un nuevo marco de trabajo para mejorar la eficiencia: el Decodificación Predictiva Orientada a la Recompensa (RSD). El RSD combina un modelo ligero de draft con un modelo más potente de objetivo, introduciendo una inclinación controlada que prioriza las salidas con altas recompensas, sin imponer una estricta no-bias. Utiliza un modelo de recompensa para evaluar las etapas de decodificación intermedias y decide dinámicamente si llama al modelo de objetivo, optimizando el equilibrio entre costos de cálculo y calidad de salida. Teóricamente, se ha demostrado que una estrategia de mezcla basada en umbrales logra el equilibrio óptimo entre uso de recursos y rendimiento. En evaluaciones variadas, que incluyen tareas de alto nivel como el Olimpiada, el RSD consume hasta 4.4 veces menos FLOPs que el decodificador solo utilizando el modelo de objetivo, y logra una precisión promedio del 3.5% más alta que el método de decodificación paralelo. Estos resultados subrayan que el RSD es una forma efectiva y rentable de implementar LLMs en entornos con muchos recursos.",
      "upvotes": 15,
      "discussionId": "67a04152dd7b3a4aba8805c0"
    },
    "publishedAt": "2025-02-02T23:10:16.068Z",
    "title": "Reward-Guided Speculative Decoding for Efficient LLM Reasoning",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.19324.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6602869253a0518b2a98cafd",
      "avatarUrl": "/avatars/c14b5953a716f42c83ad28147f8308ae.svg",
      "fullname": "Yuhui Xu",
      "name": "yuhuixu",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.18837",
      "authors": [
        {
          "_id": "67a04e7ab6fd93f91c65457b",
          "name": "Mrinank Sharma",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c65457c",
          "name": "Meg Tong",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c65457d",
          "name": "Jesse Mu",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c65457e",
          "name": "Jerry Wei",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c65457f",
          "name": "Jorrit Kruthoff",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c654580",
          "name": "Scott Goodfriend",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c654581",
          "name": "Euan Ong",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c654582",
          "name": "Alwin Peng",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c654583",
          "name": "Raj Agarwal",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c654584",
          "name": "Cem Anil",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c654585",
          "name": "Amanda Askell",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c654586",
          "name": "Nathan Bailey",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c654587",
          "name": "Joe Benton",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c654588",
          "name": "Emma Bluemke",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c654589",
          "name": "Samuel R. Bowman",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c65458a",
          "name": "Eric Christiansen",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c65458b",
          "name": "Hoagy Cunningham",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c65458c",
          "name": "Andy Dau",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c65458d",
          "name": "Anjali Gopal",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c65458e",
          "name": "Rob Gilson",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c65458f",
          "name": "Logan Graham",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c654590",
          "name": "Logan Howard",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c654591",
          "user": {
            "_id": "66fc4c692408eb3bdeba876f",
            "avatarUrl": "/avatars/66ba18ccb95d150e66d7b6930d4eb938.svg",
            "isPro": false,
            "fullname": "Nimit Kalra",
            "user": "nimitkalra",
            "type": "user"
          },
          "name": "Nimit Kalra",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-03T08:14:42.317Z",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c654592",
          "name": "Taesung Lee",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c654593",
          "name": "Kevin Lin",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c654594",
          "name": "Peter Lofgren",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c654595",
          "name": "Francesco Mosconi",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c654596",
          "name": "Clare O'Hara",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c654597",
          "name": "Catherine Olsson",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c654598",
          "name": "Linda Petrini",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c654599",
          "name": "Samir Rajani",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c65459a",
          "name": "Nikhil Saxena",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c65459b",
          "name": "Alex Silverstein",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c65459c",
          "name": "Tanya Singh",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c65459d",
          "name": "Theodore Sumers",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c65459e",
          "name": "Leonard Tang",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c65459f",
          "name": "Kevin K. Troy",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c6545a0",
          "name": "Constantin Weisser",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c6545a1",
          "name": "Ruiqi Zhong",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c6545a2",
          "name": "Giulio Zhou",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c6545a3",
          "name": "Jan Leike",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c6545a4",
          "name": "Jared Kaplan",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c6545a5",
          "name": "Ethan Perez",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-31T01:09:32.000Z",
      "title": "Constitución de la Ciudad de Seseña: Diversas pruebas de frenos para evitar accidentes en el municipio, probadas por un equipo de pruebas locales.",
      "summary": "Los grandes modelos de lenguaje (LLMs) son vulnerables a los jailbreaks universales generales. Esto permite a los usuarios que eviten sistemáticamente las disposiciones de seguridad del modelo y pueden realizar procesos perjudiciales a través de múltiples interfaces de modelo. Por ejemplo, la producción illegal de grandes cantidades de materiales. Para enfrentar estas amenazas, presentamos al modelo contenidos permitidos y limitados, según las reglas gramaticales establecidas en la constitución, para entrenar un dispositivo de vigilancia de seguridad denominado \"Constitución Class Filter\". Durante aproximadamente 3,000 horas de prueba por el equipo rojo, los participantes del equipo rojo no pudieron encontrar jailbreaks generales que permitieran la extracción de información en el LLM inicial que estaba vigilado por el Class Filter. En la evaluación automática, el Class Filter reforzado demostró una fuerte defensa frente a determinados jailbreaks generales fuera del rango. Estos Class Filters aumentaron la tasa de rechazo de datos producidos en absoluto en un 0.38% y aumentaron el sobrecargado de inferencia en un 23.7%, pero mantuvieron su funcionalidad efectiva. Nuestro estudio demuestra que es posible prevenir los jailbreaks generales mientras mantiene la funcionalidad efectiva.",
      "upvotes": 2,
      "discussionId": "67a04e7bb6fd93f91c6545bc"
    },
    "publishedAt": "2025-02-03T00:05:21.087Z",
    "title": "Constitutional Classifiers: Defending against Universal Jailbreaks across Thousands of Hours of Red Teaming",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.18837.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5912
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.18841",
      "authors": [
        {
          "_id": "67a02c75221b701e4c04da7f",
          "name": "Wojciech Zaremba",
          "hidden": false
        },
        {
          "_id": "67a02c75221b701e4c04da80",
          "name": "Evgenia Nitishinskaya",
          "hidden": false
        },
        {
          "_id": "67a02c75221b701e4c04da81",
          "name": "Boaz Barak",
          "hidden": false
        },
        {
          "_id": "67a02c75221b701e4c04da82",
          "name": "Stephanie Lin",
          "hidden": false
        },
        {
          "_id": "67a02c75221b701e4c04da83",
          "name": "Sam Toyer",
          "hidden": false
        },
        {
          "_id": "67a02c75221b701e4c04da84",
          "name": "Yaodong Yu",
          "hidden": false
        },
        {
          "_id": "67a02c75221b701e4c04da85",
          "name": "Rachel Dias",
          "hidden": false
        },
        {
          "_id": "67a02c75221b701e4c04da86",
          "name": "Eric Wallace",
          "hidden": false
        },
        {
          "_id": "67a02c75221b701e4c04da87",
          "name": "Kai Xiao",
          "hidden": false
        },
        {
          "_id": "67a02c75221b701e4c04da88",
          "name": "Johannes Heidecke",
          "hidden": false
        },
        {
          "_id": "67a02c75221b701e4c04da89",
          "name": "Amelia Glaese",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-31T01:20:44.000Z",
      "title": "Transcripción en español:\n\nInfraestructura de transacciones Tiempo Computo y Cambio de Fortaleza de Defensa",
      "summary": "Se realizan experimentos para investigar la robustez frente a ataques de modelos de inferencia (especialmente OpenAI o1-preview y o1-mini). Aumentar la cantidad de cálculos durante la inferencia mejora la robustez. En la mayoría de los casos (excluyendo algunos casos importantes), aumentando la cantidad de cálculos durante el test, la proporción de modelos que el ataque logra éxito se acerca a cero. La investigación no realiza entrenamiento contrario. Además, para aumentar la cantidad de cálculos durante la inferencia, el modelo debe usar mucho tiempo de cálculo. Este resultado muestra la posibilidad de mejorar la robustez contrario de modelos de lenguaje grandes al aumentar la cantidad de cálculos. Además, se investiga nuevos ataques a modelos de inferencia, se examina si la cantidad de cálculos durante la inferencia no se conecta con la mejora de la confianza, y se revisan los motivos y métodos de respuesta.",
      "upvotes": 2,
      "discussionId": "67a02c76221b701e4c04daf5"
    },
    "publishedAt": "2025-02-02T21:40:11.158Z",
    "title": "Trading Inference-Time Compute for Adversarial Robustness",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.18841.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5912
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2404.07097",
      "authors": [
        {
          "_id": "67a07a4b605a6c919dea84ec",
          "name": "Yoni Kasten",
          "hidden": false
        },
        {
          "_id": "67a07a4b605a6c919dea84ed",
          "name": "Wuyue Lu",
          "hidden": false
        },
        {
          "_id": "67a07a4b605a6c919dea84ee",
          "name": "Haggai Maron",
          "hidden": false
        }
      ],
      "publishedAt": "2024-04-10T15:37:00.000Z",
      "title": "Fast Encoder-Based 3D from Casual Videos via Point Track Processing\n\nGeneración de 3D rápida basada en encoder a partir de videos casuales mediante procesamiento de rastros puntuales",
      "summary": "Este artículo aborda un largo desafío: reconstruir la estructura 3D en contenidos dinámicos de vídeos. Los métodos actuales funcionan con vídeos grabados por cámaras estándar y no requieren tiempos de optimización largos.\n\nEn este artículo, proponemos una nueva aproximación basada en aprendizaje llamada TracksTo4D, con el objetivo de mejorar significativamente la eficiencia de los métodos anteriores. TracksTo4D utiliza una sola pasada hacia adelante eficiente para estimar la estructura 3D y la posición de las cámaras a partir del contenido dinámico del vídeo. Para lograr esto, manipulamos directamente el trazamiento de puntos 2D y proponemos una arquitectura adecuada para este tipo de trazamiento. La arquitectura propuesta se basa en dos principios clave: 1. Considera la simetría inherente en los datos de trazamiento de puntos 2D. 2. Asume que los patrones de movimiento pueden ser efectivamente representados mediante aproximaciones de bajo rango. TracksTo4D se entrena sin límites utilizando conjuntos de datos de vídeos personalizados que incluyen etiquetas de subobjetos 3D extraídas de los puntos 2D del vídeo. Los resultados de los experimentos muestran que TracksTo4D reconstruye la estructura 3D y la posición de las cámaras con la precisión de los mejores métodos actuales, reduciendo el tiempo de ejecución en un 95%. Además, TracksTo4D es capacaz de responder a categorías de significado no vistas en vídeos no vistos durante la fase de inferencia.",
      "upvotes": 1,
      "discussionId": "67a07a4d605a6c919dea8555"
    },
    "publishedAt": "2025-02-03T03:12:19.292Z",
    "title": "Fast Encoder-Based 3D from Casual Videos via Point Track Processing",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.07097.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "5f1158120c833276f61f1a84",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1608042047613-5f1158120c833276f61f1a84.jpeg",
      "fullname": "Niels Rogge",
      "name": "nielsr",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 742
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2411.04983",
      "authors": [
        {
          "_id": "67a0783a1b24595484396c4d",
          "name": "Gaoyue Zhou",
          "hidden": false
        },
        {
          "_id": "67a0783a1b24595484396c4e",
          "name": "Hengkai Pan",
          "hidden": false
        },
        {
          "_id": "67a0783a1b24595484396c4f",
          "name": "Yann LeCun",
          "hidden": false
        },
        {
          "_id": "67a0783a1b24595484396c50",
          "name": "Lerrel Pinto",
          "hidden": false
        }
      ],
      "publishedAt": "2024-11-07T18:54:37.000Z",
      "title": "DINO-WM: DINO-WM utiliza un modelo de características visuais pre-entrenado sobre un modelo de mundo construido para realizar planificación de 0 shot.",
      "summary": "La capacidad de predecir resultados futuros es fundamentalmente importante por razones físicas. Sin embargo, estos modelos de predicción, generalmente llamados 'World Model', son difíciles de entrenar y se utilizan frecuentemente para resolver tareas específicas y realizar aprendizaje en línea. Afirmamos que el potencial fundamental de un World Model es la capacidad de planificar para resolver diversos problemas. Concretamente, un World Model necesita tres características: 1) ser capaz de entrenarse con trajes recopilados previamente en el entorno, 2) apoyar la optimización de acciones durante el test, y 3) fomentar soluciones que no dependan de la tarea. Para lograr esto, proponemos el World Model DINO (DINO-WM). El DINO-WM introduce una nueva forma de modelar acciones visuales y modela el mundo visual sin reconstruirlo. Utilizando las características de los patches espaciales predecidas con DINOv2, el DINO-WM puede entrenarse con trajes de acciones en el entorno y predecir las características de los patches futuros. Este diseño permite que el DINO-WM optimice las secuencias de acciones para alcanzar objetivos observacionales y estime las características de los patches objetivos para promover planes de acción independientes de la tarea. El DINO-WM ha sido evaluado en diversas áreas, como exploración de laberintos, posicionamiento sobre mesas y manipulación de partículas, y ha demostrado la capacidad de generar soluciones de acción en cero-shot. Comparado con otros World Models avanzados, el DINO-WM muestra una fuerte capacidad de generalización y se adapta a diferentes familias de tareas, incluyendo diseños arbitrarios de laberintos, manipulaciones de posiciones y escenarios con múltiples partículas.",
      "upvotes": 1,
      "discussionId": "67a0783d1b24595484396cca"
    },
    "publishedAt": "2025-02-03T03:10:08.761Z",
    "title": "DINO-WM: World Models on Pre-trained Visual Features enable Zero-shot Planning",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.04983.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "5f1158120c833276f61f1a84",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1608042047613-5f1158120c833276f61f1a84.jpeg",
      "fullname": "Niels Rogge",
      "name": "nielsr",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 742
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.18128",
      "authors": [
        {
          "_id": "679e04b792d873dfa23d0ba6",
          "user": {
            "_id": "647d79a736e109abce419102",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/647d79a736e109abce419102/S8Hby6eO4WdPQrct0Ix3c.png",
            "isPro": false,
            "fullname": "Abdurrahman Odabaşı",
            "user": "odabashi",
            "type": "user"
          },
          "name": "Abdurrahman Odabaşı",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-03T08:14:51.873Z",
          "hidden": false
        },
        {
          "_id": "679e04b792d873dfa23d0ba7",
          "name": "Göksel Biricik",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-30T04:20:16.000Z",
      "title": "El objetivo de la resumen de noticias sobre la capacidad de modelos de lenguaje es proporcionar una visión concisa y precisa de los avances y desarrollos en el campo de los modelos de lenguaje, permitiendo a los lectores comprender rápidamente los principios y aplicaciones de estos modelos en diversos campos, como el procesamiento del lenguaje natural, el aprendizaje automático y la inteligencia artificial.",
      "summary": "Recientemente, la introducción de varios modelos de lenguaje y la mejora de tareas de procesamiento del lenguaje natural (NLP) han sido el escenario en el que se ha desarrollado esta investigación. Esta investigación proporciona una evaluación detallada de 20 modelos de lenguaje recientes, con un enfoque especial en la evaluación de modelos pequeños para abordar el problema de resumen de noticias. En esta investigación, se verifica sistemáticamente la capacidad y eficiencia de estos modelos para resumir artículos de noticias de diferentes estilos, basados en tres diferentes conjuntos de datos. En particular, se centra en la configuración de entrenamiento sin ejemplos (zero-shot) y con pocos ejemplos (few-shot), aplicando un método de evaluación robusto que integra indicadores de evaluación automática, evaluación humana y la utilización de LLM como jurado. Interesantemente, incluir ejemplos en la configuración de pocos ejemplos no solo puede mejorar el rendimiento del modelo, sino que también puede deteriorar la calidad de los resúmenes generados. Este problema se atribuye principalmente a la calidad reducida de los resúmenes de referencia, lo que tiene un impacto negativo en el rendimiento del modelo. Además, los resultados de esta investigación muestran especiales rendimientos de GPT-3.5-Turbo y GPT-4, que se han consolidado en un dominio de capacidades avanzadas. Sin embargo, en la evaluación general de modelos, Qwen1.5-7B, SOLAR-10.7B-Instruct-v1.0, Meta-Llama-3-8B y Zephyr-7B-Beta muestran resultados esperados y presentan una gran potencial para competir con modelos más grandes en el problema de resumen de noticias.",
      "upvotes": 0,
      "discussionId": "679e04b892d873dfa23d0bd3"
    },
    "publishedAt": "2025-02-03T04:01:13.509Z",
    "title": "Unraveling the Capabilities of Language Models in News Summarization",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.18128.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "647d79a736e109abce419102",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/647d79a736e109abce419102/S8Hby6eO4WdPQrct0Ix3c.png",
      "fullname": "Abdurrahman Odabaşı",
      "name": "odabashi",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  }
]