[
  {
    "paper": {
      "id": "2501.19393",
      "authors": [
        {
          "_id": "67a02dd80e751b0476a1bcc6",
          "name": "Niklas Muennighoff",
          "hidden": false
        },
        {
          "_id": "67a02dd80e751b0476a1bcc7",
          "name": "Zitong Yang",
          "hidden": false
        },
        {
          "_id": "67a02dd80e751b0476a1bcc8",
          "name": "Weijia Shi",
          "hidden": false
        },
        {
          "_id": "67a02dd80e751b0476a1bcc9",
          "name": "Xiang Lisa Li",
          "hidden": false
        },
        {
          "_id": "67a02dd80e751b0476a1bcca",
          "name": "Li Fei-Fei",
          "hidden": false
        },
        {
          "_id": "67a02dd80e751b0476a1bccb",
          "name": "Hannaneh Hajishirzi",
          "hidden": false
        },
        {
          "_id": "67a02dd80e751b0476a1bccc",
          "name": "Luke Zettlemoyer",
          "hidden": false
        },
        {
          "_id": "67a02dd80e751b0476a1bccd",
          "name": "Percy Liang",
          "hidden": false
        },
        {
          "_id": "67a02dd80e751b0476a1bcce",
          "name": "Emmanuel Candès",
          "hidden": false
        },
        {
          "_id": "67a02dd80e751b0476a1bccf",
          "name": "Tatsunori Hashimoto",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-31T18:48:08.000Z",
      "title": "s1: Pruebas de tiempo sencillo de programación",
      "summary": "El escalamiento durante el test es un enfoque novedoso para modelos de lenguaje. Este método puede mejorar el rendimiento al utilizar un cálculo adicional durante el test. Recientemente, el modelo o1 de OpenAI ha demostrado esta capacidad, pero no se publicó el método. Esto llevó a varios esfuerzos de replicación. Buscamos el enfoque más sencillo para lograr un escalamiento durante el test y un excelente rendimiento lógico.\n\nPrimero, seleccionamos un pequeño conjunto de datos s1K, combinando 1,000 problemas y trazas de inferencia lógica, basándonos en 3 criterios: dificultad, diversidad y calidad. Probamos este conjunto con pruebas de eliminación. Luego, controlamos el cálculo durante el test, forzando el proceso de pensamiento del modelo a terminar o agregando múltiples \"Wait\" para hacerlo tardar, de esta manera, el modelo puede revisar su respuesta y corregir errores en las fases lógicas incorrectas. Tras entrenar el modelo Qwen2.5-32B-Instruct con s1K y añadir controles, el modelo s1 mejoró significativamente en problemas matemáticos, superando a o1-preview en 27% en MATH y AIME24. Además, utilizando el control para escalar s1 y reducir la interferencia durante el test, estimamos su rendimiento en AIME24 de 50% a 57%. Nuestro modelo, datos y código están disponibles en open source en https://github.com/simplescaling/s1.",
      "upvotes": 21,
      "discussionId": "67a02dd90e751b0476a1bd02"
    },
    "publishedAt": "2025-02-02T21:45:49.841Z",
    "title": "s1: Simple test-time scaling",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.19393.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5912
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.19324",
      "authors": [
        {
          "_id": "67a04151dd7b3a4aba880589",
          "name": "Baohao Liao",
          "hidden": false
        },
        {
          "_id": "67a04151dd7b3a4aba88058a",
          "name": "Yuhui Xu",
          "hidden": false
        },
        {
          "_id": "67a04151dd7b3a4aba88058b",
          "name": "Hanze Dong",
          "hidden": false
        },
        {
          "_id": "67a04151dd7b3a4aba88058c",
          "name": "Junnan Li",
          "hidden": false
        },
        {
          "_id": "67a04151dd7b3a4aba88058d",
          "name": "Christof Monz",
          "hidden": false
        },
        {
          "_id": "67a04151dd7b3a4aba88058e",
          "name": "Silvio Savarese",
          "hidden": false
        },
        {
          "_id": "67a04151dd7b3a4aba88058f",
          "name": "Doyen Sahoo",
          "hidden": false
        },
        {
          "_id": "67a04151dd7b3a4aba880590",
          "name": "Caiming Xiong",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-31T17:19:57.000Z",
      "title": "El uso del espectro de Venezia para decodificar eficientemente cálculos de modelos de lenguaje grandes (LLM)",
      "summary": "RSD (Reward-Guided Speculative Decoding) es un nuevo marco de trabajo que busca optimizar la eficiencia de la inferencia en modelos de lenguaje grandes (LLMs). RSD combina de manera colaborativa un modelo básico ligero y un modelo más potente de objetivo, adoptando una visión controlada que prioriza los resultados con altos recompensamientos, y difiere de los métodos de decodificación actuales en que no impone una estricta imparcialidad. RSD utiliza modelos de evaluación de proceso para evaluar las etapas de decodificación intermedias, decide dinámicamente las llamadas al modelo de objetivo, y optimiza el equilibrio entre costos de cálculo y calidad de salida. Teóricamente, se ha mostrado que la estrategia de micros de umbral de paso es la más adecuada para alcanzar el equilibrio óptimo entre escala y rendimiento. Las pruebas en marcos de referencia difíciles (por ejemplo, tareas de nivel olímpico) demuestran que RSD proporciona una mejoría de eficiencia significativa en la decodificación única del modelo de objetivo, y en promedio, logra una precisión notablemente mejor que los métodos de decodificación paralelos (máximo +3.5). Estos resultados demuestran la importancia de RSD como una forma eficiente de costo de introducir LLMs en escenarios ricos en recursos.",
      "upvotes": 15,
      "discussionId": "67a04152dd7b3a4aba8805c0"
    },
    "publishedAt": "2025-02-02T23:10:16.068Z",
    "title": "Reward-Guided Speculative Decoding for Efficient LLM Reasoning",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.19324.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6602869253a0518b2a98cafd",
      "avatarUrl": "/avatars/c14b5953a716f42c83ad28147f8308ae.svg",
      "fullname": "Yuhui Xu",
      "name": "yuhuixu",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.18837",
      "authors": [
        {
          "_id": "67a04e7ab6fd93f91c65457b",
          "name": "Mrinank Sharma",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c65457c",
          "name": "Meg Tong",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c65457d",
          "name": "Jesse Mu",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c65457e",
          "name": "Jerry Wei",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c65457f",
          "name": "Jorrit Kruthoff",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c654580",
          "name": "Scott Goodfriend",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c654581",
          "name": "Euan Ong",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c654582",
          "name": "Alwin Peng",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c654583",
          "name": "Raj Agarwal",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c654584",
          "name": "Cem Anil",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c654585",
          "name": "Amanda Askell",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c654586",
          "name": "Nathan Bailey",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c654587",
          "name": "Joe Benton",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c654588",
          "name": "Emma Bluemke",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c654589",
          "name": "Samuel R. Bowman",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c65458a",
          "name": "Eric Christiansen",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c65458b",
          "name": "Hoagy Cunningham",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c65458c",
          "name": "Andy Dau",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c65458d",
          "name": "Anjali Gopal",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c65458e",
          "name": "Rob Gilson",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c65458f",
          "name": "Logan Graham",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c654590",
          "name": "Logan Howard",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c654591",
          "user": {
            "_id": "66fc4c692408eb3bdeba876f",
            "avatarUrl": "/avatars/66ba18ccb95d150e66d7b6930d4eb938.svg",
            "isPro": false,
            "fullname": "Nimit Kalra",
            "user": "nimitkalra",
            "type": "user"
          },
          "name": "Nimit Kalra",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-03T08:14:42.317Z",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c654592",
          "name": "Taesung Lee",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c654593",
          "name": "Kevin Lin",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c654594",
          "name": "Peter Lofgren",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c654595",
          "name": "Francesco Mosconi",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c654596",
          "name": "Clare O'Hara",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c654597",
          "name": "Catherine Olsson",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c654598",
          "name": "Linda Petrini",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c654599",
          "name": "Samir Rajani",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c65459a",
          "name": "Nikhil Saxena",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c65459b",
          "name": "Alex Silverstein",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c65459c",
          "name": "Tanya Singh",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c65459d",
          "name": "Theodore Sumers",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c65459e",
          "name": "Leonard Tang",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c65459f",
          "name": "Kevin K. Troy",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c6545a0",
          "name": "Constantin Weisser",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c6545a1",
          "name": "Ruiqi Zhong",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c6545a2",
          "name": "Giulio Zhou",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c6545a3",
          "name": "Jan Leike",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c6545a4",
          "name": "Jared Kaplan",
          "hidden": false
        },
        {
          "_id": "67a04e7ab6fd93f91c6545a5",
          "name": "Ethan Perez",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-31T01:09:32.000Z",
      "title": "Construccional Clasificadores: Para prevenir diferentes Universal Jailbreaks, la lucha entre los equipos de prueba de distritos.",
      "summary": "Los grandes modelos de lenguaje (LLMs) son vulnerables a los generalizados jailbreaks. Esto se debe a que los modelos evitan sistemáticamente las funciones de vigilancia de seguridad y que los usuarios utilizan múltiples interfaces de modelo para realizar procesos nocivos. Para enfrentar estas amenazas, presentamos los \"clasificadores constitucionales\" (Constitutional Classifiers). Estos son dispositivos de vigilancia de seguridad que se entrenan con datos sintéticos generados basados en reglas de lenguaje natural (es decir, la constitución), y que permiten a los usuarios evitar la vigilancia inicial. A través de los resultados de 3,000 horas de red teaming, casi en todos los casos, los usuarios no pudieron encontrar un jailbreak generalizado que permitiera extraer la misma información detallada que los LLMs monitorizados inicialmente. En evaluaciones automáticas, los clasificadores ampliados demostraron fuertes defensas frente a jailbreaks en específicos. Estos clasificadores también mantuvieron una tasa de rechazo absoluta de datos producidos de 0.38% y un sobrecargo de inferencia de 23.7%, mientras mantuvieron una funcionalidad práctica. Nuestro estudio demuestra que es posible prevenir los jailbreaks generalizados mientras se mantiene una funcionalidad práctica.",
      "upvotes": 2,
      "discussionId": "67a04e7bb6fd93f91c6545bc"
    },
    "publishedAt": "2025-02-03T00:05:21.087Z",
    "title": "Constitutional Classifiers: Defending against Universal Jailbreaks across Thousands of Hours of Red Teaming",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.18837.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5912
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.18841",
      "authors": [
        {
          "_id": "67a02c75221b701e4c04da7f",
          "name": "Wojciech Zaremba",
          "hidden": false
        },
        {
          "_id": "67a02c75221b701e4c04da80",
          "name": "Evgenia Nitishinskaya",
          "hidden": false
        },
        {
          "_id": "67a02c75221b701e4c04da81",
          "name": "Boaz Barak",
          "hidden": false
        },
        {
          "_id": "67a02c75221b701e4c04da82",
          "name": "Stephanie Lin",
          "hidden": false
        },
        {
          "_id": "67a02c75221b701e4c04da83",
          "name": "Sam Toyer",
          "hidden": false
        },
        {
          "_id": "67a02c75221b701e4c04da84",
          "name": "Yaodong Yu",
          "hidden": false
        },
        {
          "_id": "67a02c75221b701e4c04da85",
          "name": "Rachel Dias",
          "hidden": false
        },
        {
          "_id": "67a02c75221b701e4c04da86",
          "name": "Eric Wallace",
          "hidden": false
        },
        {
          "_id": "67a02c75221b701e4c04da87",
          "name": "Kai Xiao",
          "hidden": false
        },
        {
          "_id": "67a02c75221b701e4c04da88",
          "name": "Johannes Heidecke",
          "hidden": false
        },
        {
          "_id": "67a02c75221b701e4c04da89",
          "name": "Amelia Glaese",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-31T01:20:44.000Z",
      "title": "Proponemos un método para intercambiar el infraestructura de negocios y la robustez contrapartida.",
      "summary": "Se realizan experimentos para investigar el impacto que la aumentación del cálculo en la inferencia tiene sobre la robustez frente a ataques de combate en modelos lógicos (específicamente OpenAI o1-preview y o1-mini). Para diversos ataques, se ha confirmado que la aumentación del cálculo en la inferencia mejora la robustez. En la mayoría de los casos (excluyendo algunas excepciones importantes), la proporción de modelos que son atacados con éxito disminuye significativamente cuando el cálculo aumenta. No se ha realizado entrenamiento de combate para las tareas que se están estudiando. Para aumentar el cálculo en la inferencia, se hace que el modelo calcule la cantidad de cálculo necesariamente. Finalmente, se muestra que la aumentación del cálculo en la inferencia puede ser un factor potencial para mejorar la robustez de los modelos de lenguaje de alto nivel. Además, se están investigando nuevos ataques, simulando la eficacia del aumento del cálculo en la inferencia para mejorar la confiabilidad y revisando las razones y soluciones para ello.",
      "upvotes": 2,
      "discussionId": "67a02c76221b701e4c04daf5"
    },
    "publishedAt": "2025-02-02T21:40:11.158Z",
    "title": "Trading Inference-Time Compute for Adversarial Robustness",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.18841.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5912
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2404.07097",
      "authors": [
        {
          "_id": "67a07a4b605a6c919dea84ec",
          "name": "Yoni Kasten",
          "hidden": false
        },
        {
          "_id": "67a07a4b605a6c919dea84ed",
          "name": "Wuyue Lu",
          "hidden": false
        },
        {
          "_id": "67a07a4b605a6c919dea84ee",
          "name": "Haggai Maron",
          "hidden": false
        }
      ],
      "publishedAt": "2024-04-10T15:37:00.000Z",
      "title": "Un encoder rápido basado en 3D se extrae a través de trazas de puntos a partir de videos capturados de manera aleatoria.",
      "summary": "Este artículo se centra en el desafío de reconstruir la estructura 3D en contenidos dinámicos de videos. Los métodos actuales no solo procesan videos capturados con cámaras estándar, sino que también requieren tiempos de optimización largos.\n\nPara mejorar significativamente la eficiencia de los métodos anteriores, se propone un enfoque basado en aprendizaje llamado TracksTo4D. Este método permite una estimación eficiente de la estructura 3D y la posición de la cámara a partir de contenido dinámico en videos capturados con cámaras estándar. Para lograrlo, se manipula el traslado de puntos 2D directamente y se diseña una arquitectura adecuada para este tipo de traslado. La arquitectura propuesta se ha diseñado considerando dos aspectos clave: (1) la simetría inherente en los datos de traslado de puntos 2D, y (2) se asume que patrones dinámicos pueden ser representados eficientemente mediante aproximaciones de bajo rango. TracksTo4D se puede entrenar sin limitaciones en conjuntos de datos de videos Cassu, y se entrena utilizando solo los traslados de puntos 2D extraídos del video, sin necesidad de supervisión 3D. Los resultados de los experimentos muestran que TracksTo4D tiene la misma precisión que el método de referencia, permite reconstruir el polidoral de tiempo y la posición de la cámara, y reduce significativamente el tiempo de ejecución (reducción del 95%). Además, en el momento de la inferencia, se muestra una mejor generalización a categorías y videos no vistos previamente.",
      "upvotes": 1,
      "discussionId": "67a07a4d605a6c919dea8555"
    },
    "publishedAt": "2025-02-03T03:12:19.292Z",
    "title": "Fast Encoder-Based 3D from Casual Videos via Point Track Processing",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.07097.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "5f1158120c833276f61f1a84",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1608042047613-5f1158120c833276f61f1a84.jpeg",
      "fullname": "Niels Rogge",
      "name": "nielsr",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 742
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2411.04983",
      "authors": [
        {
          "_id": "67a0783a1b24595484396c4d",
          "name": "Gaoyue Zhou",
          "hidden": false
        },
        {
          "_id": "67a0783a1b24595484396c4e",
          "name": "Hengkai Pan",
          "hidden": false
        },
        {
          "_id": "67a0783a1b24595484396c4f",
          "name": "Yann LeCun",
          "hidden": false
        },
        {
          "_id": "67a0783a1b24595484396c50",
          "name": "Lerrel Pinto",
          "hidden": false
        }
      ],
      "publishedAt": "2024-11-07T18:54:37.000Z",
      "title": "DINO-WM: Planificación de 0-shot basada en características visuais previamente entrenadas",
      "summary": "El comportamiento de control basado en los resultados predecidos es una habilidad básica basada en razones físicas. Sin embargo, estos modelos de predicción, generalmente llamados 'modelos del mundo', son difíciles de entrenar, se adaptan a soluciones especializadas para tareas específicas y utilizan aprendizaje de políticas en línea. Afirmamos que el potencial fundamental de un 'modelo del mundo' es la capacidad de planificar por causas para abordar diversas problemas. Específicamente, un 'modelo del mundo' debe tener las siguientes tres características: 1) seanable en línea basado en trayectorias recopiladas previamente, 2) apoyar la optimización de acciones durante el test, y 3) promover causas independientes de la tarea. Para lograr esto, presentamos el 'Modelo del Mundo DINO' (DINO-WM). El DINO-WM modela la dinámica visual sin reconstruir el mundo visual. Utiliza características de patrones espaciales predecidas a partir de DINOv2 para entrenar en línea de trayectorias de acción. Este diseño permite optimizar secuencias de acciones para alcanzar objetivos observacionales y promover planes de acción independientes de la tarea mediante la predicción de características de patrones objetivos. El DINO-WM ha sido evaluado en diversas áreas, como exploración de laberintos, manejo de posiciones sobre una mesa y manipulación de partículas. Los experimentos demuestran que el DINO-WM puede generar soluciones de acción sin ejecución previa, independientemente de la orientación de guías expertas, modelado de recompensas o modelos inversos previamente entrenados. En particular, comparado con la mejor investigación actual, muestra una fuerte capacidad de generalización y su capacidad para abordar familias de tareas diferentes. Por ejemplo, exploración de laberintos arbitrarios, manipulación de objetos de formas diferentes o escenarios multi-partícula.",
      "upvotes": 1,
      "discussionId": "67a0783d1b24595484396cca"
    },
    "publishedAt": "2025-02-03T03:10:08.761Z",
    "title": "DINO-WM: World Models on Pre-trained Visual Features enable Zero-shot Planning",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.04983.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "5f1158120c833276f61f1a84",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1608042047613-5f1158120c833276f61f1a84.jpeg",
      "fullname": "Niels Rogge",
      "name": "nielsr",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 742
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.18128",
      "authors": [
        {
          "_id": "679e04b792d873dfa23d0ba6",
          "user": {
            "_id": "647d79a736e109abce419102",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/647d79a736e109abce419102/S8Hby6eO4WdPQrct0Ix3c.png",
            "isPro": false,
            "fullname": "Abdurrahman Odabaşı",
            "user": "odabashi",
            "type": "user"
          },
          "name": "Abdurrahman Odabaşı",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-03T08:14:51.873Z",
          "hidden": false
        },
        {
          "_id": "679e04b792d873dfa23d0ba7",
          "name": "Göksel Biricik",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-30T04:20:16.000Z",
      "title": "Comprendiendo la noticia de resumen de modelos de lenguaje\n\n(Nota: La traducción se proporciona como solicitado, sin agregar ninguna explicación o texto adicional.)",
      "summary": "Recientemente, la introducción de modelos multilingües y la demanda continua de mejoras en tareas de procesamiento del lenguaje natural (NLP) han sido constantes. En este contexto, este estudio proporciona detallados benchmarks para 20 modelos de lenguaje recientes, con un enfoque especial en el problema de resumen de noticias. En este estudio, se verifica sistemáticamente la capacidad y efectividad de estos modelos para resumir textos de artículos de noticias escritos en diferentes estilos. En particular, se centra en la evaluación de los modelos en entornos de aprendizaje a partir de cero (zero-shot learning) y con pocos ejemplos (few-shot learning), utilizando métricas de evaluación automática, evaluación humana y la concepto de \"LLM-as-a-judge\" como métodos de evaluación robustos. Interesantemente, se ha encontrado que incluir ejemplos en el entrenamiento en el entorno de few-shot learning no mejora el rendimiento del modelo, sino que, en cambio, disminuye la calidad de los resúmenes generados. Este problema es principalmente causado por la calidad reducida de los resúmenes generados, lo que tiene un impacto negativo en el rendimiento del modelo. Además, los resultados del estudio revelan que modelos como GPT-3.5-Turbo y GPT-4, con sus capacidades desarrolladas, han ocupado una posición dominante en el campo de la NLP. Sin embargo, entre los modelos evaluados, se destacan Qwen1.5-7B, SOLAR-10.7B-Instruct-v1.0, Meta-Llama-3-8B y Zephyr-7B-Beta, que muestran resultados esperados y compiten con los grandes modelos, siendo posibles alternativas prometedoras para abordar el problema de resumen de noticias.",
      "upvotes": 0,
      "discussionId": "679e04b892d873dfa23d0bd3"
    },
    "publishedAt": "2025-02-03T04:01:13.509Z",
    "title": "Unraveling the Capabilities of Language Models in News Summarization",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.18128.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "647d79a736e109abce419102",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/647d79a736e109abce419102/S8Hby6eO4WdPQrct0Ix3c.png",
      "fullname": "Abdurrahman Odabaşı",
      "name": "odabashi",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  }
]