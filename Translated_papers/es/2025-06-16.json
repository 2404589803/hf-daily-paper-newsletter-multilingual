[
  {
    "paper": {
      "id": "2506.11924",
      "authors": [
        {
          "_id": "684faeba60b4a34dbe007ae2",
          "name": "Min-Seop Kwak",
          "hidden": false
        },
        {
          "_id": "684faeba60b4a34dbe007ae3",
          "name": "Junho Kim",
          "hidden": false
        },
        {
          "_id": "684faeba60b4a34dbe007ae4",
          "name": "Sangdoo Yun",
          "hidden": false
        },
        {
          "_id": "684faeba60b4a34dbe007ae5",
          "name": "Dongyoon Han",
          "hidden": false
        },
        {
          "_id": "684faeba60b4a34dbe007ae6",
          "name": "Taekyoung Kim",
          "hidden": false
        },
        {
          "_id": "684faeba60b4a34dbe007ae7",
          "name": "Seungryong Kim",
          "hidden": false
        },
        {
          "_id": "684faeba60b4a34dbe007ae8",
          "name": "Jin-Hwa Kim",
          "hidden": false
        }
      ],
      "publishedAt": "2025-06-13T16:19:00.000Z",
      "submittedOnDailyAt": "2025-06-16T04:13:42.201Z",
      "title": "Construcción de Imágenes y Jeitmoritos mediante la Fusión de Imágenes Nuevas y Jeitmoritos Usando la Construcción de Atención Cruzada Modal",
      "submittedOnDailyBy": {
        "_id": "642673f185f26ab94af4b422",
        "avatarUrl": "/avatars/289d611e0907f02f72d4e489468e039c.svg",
        "isPro": false,
        "fullname": "Bracio",
        "user": "bracio9623",
        "type": "user"
      },
      "summary": "Este documento presenta un marco de trabajo basado en adición de capas. Este marco utiliza técnicas de espejamiento y inpainting para generar imágenes y géneros genéricos de nuevas perspectivas. Los métodos existentes utilizaban imágenes con posturas densas o modelos generativos para limitar la perspectiva específica. Sin embargo, nuestro método utiliza un predictor genérico sencillo para predecir el género genérico de las partes observadas en una imagen de referencia y configura la síntesis de nuevas perspectivas de la imagen y el género genérico como tarea de inpainting. Para garantizar la correspondencia precisa entre la imagen generada y el género genérico, entrenamos y inferimos una mapa de atención en la rama de adición de capas de la imagen, y introducimos una rama de adición de capas genérica en paralelo. Proponemos un desdilluvio de atención cruzado modal. Esta abordaje multitarea promueve la síntesis de imágenes resistentes al género genérico y una precisa predicción del género genérico. Además, introducimos una asignación de condiciones basada en puntos cercanos para integrar la profundidad y el positivo, y filtramos puntos censurados y predicciones incorrectas del género genérico para no afectar el proceso de generación. Experimentalmente, nuestro método logra realizar una síntesis de vistas externas de alta precisión y proporciona una reconstrucción de la correspondencia en el espacio de interpolación, creando puntos de color simétricos en detalles 3D del género genérico. La página del proyecto está disponible en https://cvlab-kaist.github.io/MoAI.",
      "upvotes": 22,
      "discussionId": "684faebb60b4a34dbe007ae9",
      "projectPage": "https://cvlab-kaist.github.io/MoAI/",
      "githubRepo": "https://github.com/cvlab-kaist/MoAI",
      "ai_summary": "A diffusion-based framework generates aligned novel views of images and geometry using warping-and-inpainting with cross-modal attention distillation and proximity-based mesh conditioning, achieving high-fidelity synthesis and 3D completion.",
      "ai_keywords": [
        "diffusion-based framework",
        "warping-and-inpainting",
        "off-the-shelf geometry predictors",
        "cross-modal attention distillation",
        "proximity-based mesh conditioning",
        "novel-view synthesis",
        "multi-task approach",
        "geometrically robust image synthesis",
        "well-defined geometry prediction",
        "extrapolative view synthesis",
        "3D completion"
      ]
    },
    "publishedAt": "2025-06-13T12:19:00.000Z",
    "title": "Aligned Novel View Image and Geometry Synthesis via Cross-modal\n  Attention Instillation",
    "summary": "We introduce a diffusion-based framework that performs aligned novel view\nimage and geometry generation via a warping-and-inpainting methodology. Unlike\nprior methods that require dense posed images or pose-embedded generative\nmodels limited to in-domain views, our method leverages off-the-shelf geometry\npredictors to predict partial geometries viewed from reference images, and\nformulates novel-view synthesis as an inpainting task for both image and\ngeometry. To ensure accurate alignment between generated images and geometry,\nwe propose cross-modal attention distillation, where attention maps from the\nimage diffusion branch are injected into a parallel geometry diffusion branch\nduring both training and inference. This multi-task approach achieves\nsynergistic effects, facilitating geometrically robust image synthesis as well\nas well-defined geometry prediction. We further introduce proximity-based mesh\nconditioning to integrate depth and normal cues, interpolating between point\ncloud and filtering erroneously predicted geometry from influencing the\ngeneration process. Empirically, our method achieves high-fidelity\nextrapolative view synthesis on both image and geometry across a range of\nunseen scenes, delivers competitive reconstruction quality under interpolation\nsettings, and produces geometrically aligned colored point clouds for\ncomprehensive 3D completion. Project page is available at\nhttps://cvlab-kaist.github.io/MoAI.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.11924.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "642673f185f26ab94af4b422",
      "avatarUrl": "/avatars/289d611e0907f02f72d4e489468e039c.svg",
      "fullname": "Bracio",
      "name": "bracio9623",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 4
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2506.09600",
      "authors": [
        {
          "_id": "684fca8160b4a34dbe007b4f",
          "name": "Itay Nakash",
          "hidden": false
        },
        {
          "_id": "684fca8160b4a34dbe007b50",
          "name": "George Kour",
          "hidden": false
        },
        {
          "_id": "684fca8160b4a34dbe007b51",
          "name": "Koren Lazar",
          "hidden": false
        },
        {
          "_id": "684fca8160b4a34dbe007b52",
          "name": "Matan Vetzler",
          "hidden": false
        },
        {
          "_id": "684fca8160b4a34dbe007b53",
          "name": "Guy Uziel",
          "hidden": false
        },
        {
          "_id": "684fca8160b4a34dbe007b54",
          "name": "Ateret Anaby-Tavor",
          "hidden": false
        }
      ],
      "mediaUrls": [
        "https://cdn-uploads.huggingface.co/production/uploads/671f8106d677d3a764a6f9a5/99oCW2IrMaCeLyuyfgvbG.png"
      ],
      "publishedAt": "2025-06-11T10:59:47.000Z",
      "submittedOnDailyAt": "2025-06-16T06:16:02.507Z",
      "title": "Tematización efectiva de agentes de cumplimiento de políticas",
      "submittedOnDailyBy": {
        "_id": "671f8106d677d3a764a6f9a5",
        "avatarUrl": "/avatars/90b4b00058aac30c060c5eac8debb1c7.svg",
        "isPro": false,
        "fullname": "itay nakash",
        "user": "itaynakash",
        "type": "user"
      },
      "summary": "Los agentes basados en LLM orientados hacia la tarea están aumentando en áreas que rigen estrictamente políticas como reembolsos con anuncios y reglas de cancelación. Este desafío consiste en mantener una interacción natural mientras los agentes ejecutan estos reglamentos de manera coherente y rechazan solicitaciones que infringen las mismas. Para lograr esto, es necesario desarrollar métodos de diseño y evaluación que permitan a los agentes mantener su resistencia frente a acciones maliciosas de usuarios. Proponemos un nuevo modelo de turno para enfrentar a usuarios hostiles con el objetivo de cumplir con las políticas. Para ello, presentamos el sistema CRAFT, un equipo de agentes rojos que utiliza estrategias persuasivas relacionadas con las políticas para destruir los servicios. Esto supera métodos tradicionales como el DAN, la manipulación emocional y la coercción. Basado en el tau-bench, introducimos el tau-break como un marco de evaluación para medir la resistencia de los agentes frente a acciones manipuladas por usuarios. Finalmente, evaluamos varias estrategias de defensa sencillas pero efectivas. Aunque estas medidas proporcionan cierta protección, se requiere una fuerte base de investigación para obtener una certeza de seguridad.",
      "upvotes": 15,
      "discussionId": "684fca8160b4a34dbe007b55",
      "ai_summary": "CRAFT, a multi-agent system using policy-aware persuasive strategies, challenges policy-adherent LLM-based agents in customer service to assess and improve their robustness against adversarial attacks.",
      "ai_keywords": [
        "LLM-based agents",
        "policy-adherence",
        "adversarial users",
        "CRAFT",
        "multi-agent red-teaming",
        "policy-aware persuasive strategies",
        "DAN prompts",
        "emotional manipulation",
        "coercive",
        "tau-break",
        "defense strategies",
        "adversarial attacks"
      ]
    },
    "publishedAt": "2025-06-11T06:59:47.000Z",
    "title": "Effective Red-Teaming of Policy-Adherent Agents",
    "summary": "Task-oriented LLM-based agents are increasingly used in domains with strict\npolicies, such as refund eligibility or cancellation rules. The challenge lies\nin ensuring that the agent consistently adheres to these rules and policies,\nappropriately refusing any request that would violate them, while still\nmaintaining a helpful and natural interaction. This calls for the development\nof tailored design and evaluation methodologies to ensure agent resilience\nagainst malicious user behavior. We propose a novel threat model that focuses\non adversarial users aiming to exploit policy-adherent agents for personal\nbenefit. To address this, we present CRAFT, a multi-agent red-teaming system\nthat leverages policy-aware persuasive strategies to undermine a\npolicy-adherent agent in a customer-service scenario, outperforming\nconventional jailbreak methods such as DAN prompts, emotional manipulation, and\ncoercive. Building upon the existing tau-bench benchmark, we introduce\ntau-break, a complementary benchmark designed to rigorously assess the agent's\nrobustness against manipulative user behavior. Finally, we evaluate several\nstraightforward yet effective defense strategies. While these measures provide\nsome protection, they fall short, highlighting the need for stronger,\nresearch-driven safeguards to protect policy-adherent agents from adversarial\nattacks",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/671f8106d677d3a764a6f9a5/99oCW2IrMaCeLyuyfgvbG.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.09600.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "671f8106d677d3a764a6f9a5",
      "avatarUrl": "/avatars/90b4b00058aac30c060c5eac8debb1c7.svg",
      "fullname": "itay nakash",
      "name": "itaynakash",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2506.10892",
      "authors": [
        {
          "_id": "684fb2f060b4a34dbe007aeb",
          "name": "Subham Sekhar Sahoo",
          "hidden": false
        },
        {
          "_id": "684fb2f060b4a34dbe007aec",
          "name": "Justin Deschenaux",
          "hidden": false
        },
        {
          "_id": "684fb2f060b4a34dbe007aed",
          "name": "Aaron Gokaslan",
          "hidden": false
        },
        {
          "_id": "684fb2f060b4a34dbe007aee",
          "name": "Guanghan Wang",
          "hidden": false
        },
        {
          "_id": "684fb2f060b4a34dbe007aef",
          "name": "Justin Chiu",
          "hidden": false
        },
        {
          "_id": "684fb2f060b4a34dbe007af0",
          "name": "Volodymyr Kuleshov",
          "hidden": false
        }
      ],
      "mediaUrls": [
        "https://cdn-uploads.huggingface.co/production/uploads/661839d73b412cdc851299c1/GmIlLMVIuyWjydykQPOt2.png",
        "https://cdn-uploads.huggingface.co/production/uploads/661839d73b412cdc851299c1/TjIhoD3hxygzenitTi75x.qt"
      ],
      "publishedAt": "2025-06-12T16:55:35.000Z",
      "submittedOnDailyAt": "2025-06-16T04:40:29.065Z",
      "title": "Diffusion Duality\n\nDualidad de la Difusión",
      "submittedOnDailyBy": {
        "_id": "661839d73b412cdc851299c1",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/661839d73b412cdc851299c1/xicwANPQPTFdWfblisL2-.png",
        "isPro": false,
        "fullname": "Subham Sekhar Sahoo",
        "user": "s-sahoo",
        "type": "user"
      },
      "summary": "El modelo de difusión discreto en estado unificado tiene la capacidad de ajuste automático para generar frases rápidamente, pero generalmente presenta un desempeño inferior en comparación con los modelos automáticos secuenciales y los modelos de difusión con mascara. En este artículo, se utilizan puntos clave importantes para reducir esta diferencia de rendimiento. El proceso de difusión en estado unificado se desarrolla de manera natural bajo la difusión bayesiana, lo cual es poco valorado. Nuestro método, Duo, transmite tecnologías potentes desde la difusión bayesiana y mejora tanto el entrenamiento como la muestreo. Primero, mediante la estrategia de entrenamiento del corredor, que utiliza el proceso bayesiano para reducir la varianza, se aumentó la velocidad del entrenamiento en un factor de 2. El modelo entrenado mediante el corredor supera al modelo automático secuencial en 3 de los 7 benchmarks en el perplexidad de 0 shot. Además, se propone un algoritmo de estilización discreto aplicable, que acelera la muestreo en dos etapas, facilitando la generación de pocos pasos en modelos de lenguaje de difusión. El sitio web del proyecto ofrece código y checkpoints del modelo: http://s-sahoo.github.io/duo",
      "upvotes": 8,
      "discussionId": "684fb2f060b4a34dbe007af1",
      "projectPage": "https://s-sahoo.com/duo/",
      "githubRepo": "https://github.com/s-sahoo/duo",
      "ai_summary": "Duo improves uniform-state discrete diffusion models by transferring techniques from Gaussian diffusion, enhancing training speed and enabling fast few-step text generation.",
      "ai_keywords": [
        "discrete diffusion models",
        "Gaussian diffusion",
        "curriculum learning",
        "Discrete Consistency Distillation",
        "zero-shot perplexity",
        "few-step generation"
      ]
    },
    "publishedAt": "2025-06-12T12:55:35.000Z",
    "title": "The Diffusion Duality",
    "summary": "Uniform-state discrete diffusion models hold the promise of fast text\ngeneration due to their inherent ability to self-correct. However, they are\ntypically outperformed by autoregressive models and masked diffusion models. In\nthis work, we narrow this performance gap by leveraging a key insight:\nUniform-state diffusion processes naturally emerge from an underlying Gaussian\ndiffusion. Our method, Duo, transfers powerful techniques from Gaussian\ndiffusion to improve both training and sampling. First, we introduce a\ncurriculum learning strategy guided by the Gaussian process, doubling training\nspeed by reducing variance. Models trained with curriculum learning surpass\nautoregressive models in zero-shot perplexity on 3 of 7 benchmarks. Second, we\npresent Discrete Consistency Distillation, which adapts consistency\ndistillation from the continuous to the discrete setting. This algorithm\nunlocks few-step generation in diffusion language models by accelerating\nsampling by two orders of magnitude. We provide the code and model checkpoints\non the project page: http://s-sahoo.github.io/duo",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/661839d73b412cdc851299c1/GmIlLMVIuyWjydykQPOt2.png",
      "https://cdn-uploads.huggingface.co/production/uploads/661839d73b412cdc851299c1/TjIhoD3hxygzenitTi75x.qt"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.10892.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "661839d73b412cdc851299c1",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/661839d73b412cdc851299c1/xicwANPQPTFdWfblisL2-.png",
      "fullname": "Subham Sekhar Sahoo",
      "name": "s-sahoo",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2506.11928",
      "authors": [
        {
          "_id": "684fae8d60b4a34dbe007acd",
          "name": "Zihan Zheng",
          "hidden": false
        },
        {
          "_id": "684fae8d60b4a34dbe007ace",
          "name": "Zerui Cheng",
          "hidden": false
        },
        {
          "_id": "684fae8d60b4a34dbe007acf",
          "name": "Zeyu Shen",
          "hidden": false
        },
        {
          "_id": "684fae8d60b4a34dbe007ad0",
          "name": "Shang Zhou",
          "hidden": false
        },
        {
          "_id": "684fae8d60b4a34dbe007ad1",
          "name": "Kaiyuan Liu",
          "hidden": false
        },
        {
          "_id": "684fae8d60b4a34dbe007ad2",
          "name": "Hansen He",
          "hidden": false
        },
        {
          "_id": "684fae8d60b4a34dbe007ad3",
          "name": "Dongruixuan Li",
          "hidden": false
        },
        {
          "_id": "684fae8d60b4a34dbe007ad4",
          "name": "Stanley Wei",
          "hidden": false
        },
        {
          "_id": "684fae8d60b4a34dbe007ad5",
          "name": "Hangyi Hao",
          "hidden": false
        },
        {
          "_id": "684fae8d60b4a34dbe007ad6",
          "name": "Jianzhu Yao",
          "hidden": false
        },
        {
          "_id": "684fae8d60b4a34dbe007ad7",
          "name": "Peiyao Sheng",
          "hidden": false
        },
        {
          "_id": "684fae8d60b4a34dbe007ad8",
          "name": "Zixuan Wang",
          "hidden": false
        },
        {
          "_id": "684fae8d60b4a34dbe007ad9",
          "name": "Wenhao Chai",
          "hidden": false
        },
        {
          "_id": "684fae8d60b4a34dbe007ada",
          "name": "Aleksandra Korolova",
          "hidden": false
        },
        {
          "_id": "684fae8d60b4a34dbe007adb",
          "name": "Peter Henderson",
          "hidden": false
        },
        {
          "_id": "684fae8d60b4a34dbe007adc",
          "name": "Sanjeev Arora",
          "hidden": false
        },
        {
          "_id": "684fae8d60b4a34dbe007add",
          "name": "Pramod Viswanath",
          "hidden": false
        },
        {
          "_id": "684fae8d60b4a34dbe007ade",
          "name": "Jingbo Shang",
          "hidden": false
        },
        {
          "_id": "684fae8d60b4a34dbe007adf",
          "name": "Saining Xie",
          "hidden": false
        }
      ],
      "publishedAt": "2025-06-13T16:29:09.000Z",
      "submittedOnDailyAt": "2025-06-16T04:13:30.111Z",
      "title": "LiveCodeBench Pro: Lista de Medallas del Olimpiada sobre cómo los competidores de programación evalúan los LLMs",
      "submittedOnDailyBy": {
        "_id": "637c7503fe115289cfecbe6b",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1676361945047-637c7503fe115289cfecbe6b.jpeg",
        "isPro": false,
        "fullname": "Wenhao Chai",
        "user": "wchai",
        "type": "user"
      },
      "summary": "Según un informe reciente, los modelos de lenguaje grandes (LLMs) superan a los ganadores de la programación competitiva. Se está revisando esta afirmación basándose en el conocimiento de los grupos de medallistas de los eventos internacionales de algoritmos. Se investiga qué diferencias existen entre los LLMs y los expertos humanos, así como cuáles son sus limitaciones. Se presenta LiveCodeBench Pro, un marco de prueba basado en problemas de Codeforces, ICPC y IOI, actualizado de manera continua para reducir la contaminación de datos. Los equipos de medallistas anotan los problemas por categoría de algoritmos y presentan modelos que fallan. Con este nuevo conjunto de datos y marco de prueba, los modelos de líder alcanzan un 53% de paso en problemas difíciles sin utilizar herramientas externas, lo que es un dominio de los expertos humanos. Además, los LLMs pueden realizarse con problemas complejos pero suelen fallar en la análisis de razones y crear razones incorrectas. El alto rendimiento se debe a la precisión de la implementación y la extensión de las herramientas, pero no a la razón correcta. LiveCodeBench Pro claramente demuestra las diferencias con los Grand Masters humanos y continuamente proporciona orientación para la mejora futura de las razones de los LLMs en los centros de código.",
      "upvotes": 6,
      "discussionId": "684fae8d60b4a34dbe007ae0",
      "ai_summary": "LLMs perform well on implementation-heavy competitive programming problems but struggle with nuanced algorithmic reasoning, as highlighted by LiveCodeBench Pro.",
      "ai_keywords": [
        "large language models",
        "LLMs",
        "competitive programming",
        "LiveCodeBench Pro",
        "Codeforces",
        "ICPC",
        "IOI",
        "algorithmic categories",
        "algorithmic reasoning",
        "case analysis"
      ]
    },
    "publishedAt": "2025-06-13T12:29:09.000Z",
    "title": "LiveCodeBench Pro: How Do Olympiad Medalists Judge LLMs in Competitive\n  Programming?",
    "summary": "Recent reports claim that large language models (LLMs) now outperform elite\nhumans in competitive programming. Drawing on knowledge from a group of\nmedalists in international algorithmic contests, we revisit this claim,\nexamining how LLMs differ from human experts and where limitations still\nremain. We introduce LiveCodeBench Pro, a benchmark composed of problems from\nCodeforces, ICPC, and IOI that are continuously updated to reduce the\nlikelihood of data contamination. A team of Olympiad medalists annotates every\nproblem for algorithmic categories and conducts a line-by-line analysis of\nfailed model-generated submissions. Using this new data and benchmark, we find\nthat frontier models still have significant limitations: without external\ntools, the best model achieves only 53% pass@1 on medium-difficulty problems\nand 0% on hard problems, domains where expert humans still excel. We also find\nthat LLMs succeed at implementation-heavy problems but struggle with nuanced\nalgorithmic reasoning and complex case analysis, often generating confidently\nincorrect justifications. High performance appears largely driven by\nimplementation precision and tool augmentation, not superior reasoning.\nLiveCodeBench Pro thus highlights the significant gap to human grandmaster\nlevels, while offering fine-grained diagnostics to steer future improvements in\ncode-centric LLM reasoning.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.11928.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "637c7503fe115289cfecbe6b",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1676361945047-637c7503fe115289cfecbe6b.jpeg",
      "fullname": "Wenhao Chai",
      "name": "wchai",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 34
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2506.11997",
      "authors": [
        {
          "_id": "684fd0cb60b4a34dbe007b70",
          "user": {
            "_id": "6333650673c07e8aebb2e941",
            "avatarUrl": "/avatars/bfcc236641671e88c2fe5426740071d3.svg",
            "isPro": false,
            "fullname": "Korbinian Poeppel",
            "user": "korbip",
            "type": "user"
          },
          "name": "Korbinian Pöppel",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-16T08:35:40.461Z",
          "hidden": false
        },
        {
          "_id": "684fd0cb60b4a34dbe007b71",
          "name": "Richard Freinschlag",
          "hidden": false
        },
        {
          "_id": "684fd0cb60b4a34dbe007b72",
          "name": "Thomas Schmied",
          "hidden": false
        },
        {
          "_id": "684fd0cb60b4a34dbe007b73",
          "name": "Wei Lin",
          "hidden": false
        },
        {
          "_id": "684fd0cb60b4a34dbe007b74",
          "name": "Sepp Hochreiter",
          "hidden": false
        }
      ],
      "publishedAt": "2025-06-13T17:51:37.000Z",
      "submittedOnDailyAt": "2025-06-16T06:38:46.139Z",
      "title": "pLSTM: Red de Marcadores de Movimiento de Fuente Lineal Paralelizable",
      "submittedOnDailyBy": {
        "_id": "64c3849269b1a6796052eac7",
        "avatarUrl": "/avatars/9f0c832d5b51b659c7bb83074f02a648.svg",
        "isPro": false,
        "fullname": "Thomas Schmied",
        "user": "thomasschmied",
        "type": "user"
      },
      "summary": "Recientemente, arquitecturas recientes como xLSTM y Mamba están desafiando al Transformer en el campo de modelado de lenguajes. Sin embargo, estas estructuras solo se aplican a secuencias y necesitan procesar datos de estructuras multidimensionales como imágenes o grafos moleculares de manera predefinida. Por otro lado, las Redes Recurrentes Multidimensionales (MDRNNs) son adecuadas para datos de alta dimensión, como grífons 2D, árboles y grafos acíclicos dirigidos (DAG). En este artículo, se extiende la linearidad de las redes recurrentes para incorporar multidimensionalidad. Usando Source, Transition y Mark gates que actúan sobre gráficos lineales generales de DAG, se introducen las Redes Lineales Source Transition Mark paralelizables (pLSTMs). Así, se logra una paralelización similar a la de RNN lineales secuenciales, pero aplicable también a DAG. Se pueden implementar eficientemente para grífons 1D y 2D utilizando operaciones einsum, combinación y relleno lógico de tiempo. Para resolver problemas de activación y desaceleración/aceleración a larga distancia en DAG, los pLSTMs utilizan dos modos diferentes: el modo de propagación dirigida (P-mode) y el modo de distribución difusiva (D-mode). Para demostrar su capacidad a larga distancia, se introducen tareas complejas de computación gráfica que incluyen información dirigida a larga distancia, como \"la pronunciación de los marcadores\". Los pLSTMs se adaptan bien a datos de gran tamaño de imágenes y son más eficientes que los Transformers en términos de pronunciación. También muestran excelentes resultados en benchmarks de grafos moleculares y computación gráfica. El código y los conjuntos de datos están disponibles en la siguiente URL: https://github.com/ml-jku/plstm_experiments.",
      "upvotes": 4,
      "discussionId": "684fd0cb60b4a34dbe007b75",
      "ai_summary": "pLSTMs are parallelizable linear RNNs designed for DAGs, demonstrating superior performance on long-range tasks and benchmarks compared to Transformers.",
      "ai_keywords": [
        "xLSTM",
        "Mamba",
        "Transformer",
        "Multi-Dimensional RNNs",
        "MDRNNs",
        "parallelizable Linear Source Transition Mark networks",
        "pLSTMs",
        "Source gates",
        "Transition gates",
        "Mark gates",
        "line graph",
        "DAGs",
        "parallel associative scans",
        "chunkwise-recurrent",
        "einsum operations",
        "concatenations",
        "padding",
        "vanishing/exploding activation/gradient problem",
        "directed propagation mode",
        "diffusive distribution mode",
        "arrow-pointing extrapolation",
        "computer vision task",
        "molecular graph",
        "performance benchmarks"
      ]
    },
    "publishedAt": "2025-06-13T13:51:37.000Z",
    "title": "pLSTM: parallelizable Linear Source Transition Mark networks",
    "summary": "Modern recurrent architectures, such as xLSTM and Mamba, have recently\nchallenged the Transformer in language modeling. However, their structure\nconstrains their applicability to sequences only or requires processing\nmulti-dimensional data structures, such as images or molecular graphs, in a\npre-defined sequential order. In contrast, Multi-Dimensional RNNs (MDRNNs) are\nwell suited for data with a higher level structure, like 2D grids, trees, and\ndirected acyclic graphs (DAGs). In this work, we extend the notion of\nmulti-dimensionality to linear RNNs. We introduce parallelizable Linear Source\nTransition Mark networks (pLSTMs) using Source, Transition, and Mark gates that\nact on the line graph of a general DAG. This enables parallelization in analogy\nto parallel associative scans and the chunkwise-recurrent form of sequential\nlinear RNNs, but for DAGs. For regular grids (1D and 2D), like images, this\nscheme can be efficiently implemented using einsum operations, concatenations,\nand padding in logarithmic time. pLSTMs tackle the vanishing/exploding\nactivation/gradient problem for long distances in DAGs via two distinct modes:\na directed propagation mode (P-mode) and a diffusive distribution mode\n(D-mode). To showcase the long-range capabilities of pLSTM, we introduce\narrow-pointing extrapolation as a synthetic computer vision task that contains\nlong-distance directional information. We demonstrate that pLSTMs generalize\nwell to larger image sizes, whereas Transformers struggle to extrapolate. On\nestablished molecular graph and computer vision benchmarks, pLSTMs also show\nstrong performance. Code and Datasets are available at:\nhttps://github.com/ml-jku/plstm_experiments.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.11997.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64c3849269b1a6796052eac7",
      "avatarUrl": "/avatars/9f0c832d5b51b659c7bb83074f02a648.svg",
      "fullname": "Thomas Schmied",
      "name": "thomasschmied",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 4
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2506.09427",
      "authors": [
        {
          "_id": "684fa6d060b4a34dbe007aa7",
          "user": {
            "_id": "66d94f2a36aa5055694dfe04",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/grAN83brH0E4_S0__yLdv.jpeg",
            "isPro": false,
            "fullname": "fengyukang",
            "user": "finyorko",
            "type": "user"
          },
          "name": "Yukang Feng",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-06-16T07:48:14.381Z",
          "hidden": false
        },
        {
          "_id": "684fa6d060b4a34dbe007aa8",
          "name": "Jianwen Sun",
          "hidden": false
        },
        {
          "_id": "684fa6d060b4a34dbe007aa9",
          "user": {
            "_id": "6533f7ecb3852ed1ceb48e47",
            "avatarUrl": "/avatars/5d767c093e73f06a89f625c3a5903902.svg",
            "isPro": false,
            "fullname": "Chuanhao Li",
            "user": "cyrilli",
            "type": "user"
          },
          "name": "Chuanhao Li",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-06-16T07:48:30.156Z",
          "hidden": false
        },
        {
          "_id": "684fa6d060b4a34dbe007aaa",
          "name": "Zizhen Li",
          "hidden": false
        },
        {
          "_id": "684fa6d060b4a34dbe007aab",
          "name": "Jiaxin Ai",
          "hidden": false
        },
        {
          "_id": "684fa6d060b4a34dbe007aac",
          "user": {
            "_id": "665305eff0c8c891cae7fe01",
            "avatarUrl": "/avatars/1f372e3bc6a4eb19ef702ec96a391c96.svg",
            "isPro": false,
            "fullname": "Fanrui Zhang",
            "user": "fanrui00",
            "type": "user"
          },
          "name": "Fanrui Zhang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-06-16T07:49:04.386Z",
          "hidden": false
        },
        {
          "_id": "684fa6d060b4a34dbe007aad",
          "name": "Yifan Chang",
          "hidden": false
        },
        {
          "_id": "684fa6d060b4a34dbe007aae",
          "name": "Sizhuo Zhou",
          "hidden": false
        },
        {
          "_id": "684fa6d060b4a34dbe007aaf",
          "user": {
            "_id": "6674d02914e2aebef893779e",
            "avatarUrl": "/avatars/acdbe3820462b87126c8f1e14f0d1a60.svg",
            "isPro": false,
            "fullname": "ZhangShenglin",
            "user": "ZhangShenglin",
            "type": "user"
          },
          "name": "Shenglin Zhang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-06-16T07:49:28.741Z",
          "hidden": false
        },
        {
          "_id": "684fa6d060b4a34dbe007ab0",
          "name": "Yu Dai",
          "hidden": false
        },
        {
          "_id": "684fa6d060b4a34dbe007ab1",
          "user": {
            "_id": "63527f4e7d071f23d085ad45",
            "avatarUrl": "/avatars/99a51adef5673b3ac1a8c02eb47759c4.svg",
            "isPro": false,
            "fullname": "KAIPENG ZHANG",
            "user": "kpzhang",
            "type": "user"
          },
          "name": "Kaipeng Zhang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-06-16T07:49:35.126Z",
          "hidden": false
        }
      ],
      "mediaUrls": [
        "https://cdn-uploads.huggingface.co/production/uploads/65f1713552c38a91e0a445e8/1FHKfzv4w4VzV4nhqKCJ7.png"
      ],
      "publishedAt": "2025-06-11T06:21:20.000Z",
      "submittedOnDailyAt": "2025-06-16T03:49:15.860Z",
      "title": "Generación en tiempo real de imágenes de personajes basada en conjuntos de datos de alta calidad y evaluaciones confiables",
      "submittedOnDailyBy": {
        "_id": "65f1713552c38a91e0a445e8",
        "avatarUrl": "/avatars/47ab3ada51c9b9976ac1cd0c4301c373.svg",
        "isPro": false,
        "fullname": "kaipeng",
        "user": "kpzhang996",
        "type": "user"
      },
      "summary": "El desarrollo reciente de grandes modelos multimodal (LMMs) ha logrado notables mejoras en la comprensión y generación de estos modelos. Sin embargo, estos modelos encuentran dificultades en la creación de imágenes-texto que se repiten debido a limitaciones en la escala, calidad y riqueza de los conjuntos de datos de entrenamiento actuales. Para abordar estas limitaciones, presentamos un grande conjunto de datos de modelos multimodal (LMMs) construido utilizando el método de Autoevaluación con Refinamiento Iterativo (SEIR). InterSyn es caracterizado por respuestas que incluyen imágenes-texto repetidas, diálogos dirigidos por instrucciones, una gran diversidad de objetos y un estricto control de la edición automática de la masa, lo que lo adapta para el entrenamiento de LMMs en instrucciones futuras. Además, en respuesta a la falta de herramientas confiables para evaluar los resultados multimodales repetidos, presentamos SynJudge. SynJudge es un modelo de evaluación automática que cuantifica de manera cuadrada el contenido textual, el contenido de la imagen, la calidad de la imagen y la armonía entre la imagen y el texto.\n\nA través de estudios de experimentación, se ha demostrado que el método SEIR logra un significativo aumento en la calidad del conjunto de datos sin necesidad de ediciones. Además, los LMMs entrenados con InterSyn muestran una mejora consistente en todos los indicadores de evaluación y confirman la adecuación de su desarrollo como sistema multimodal.",
      "upvotes": 4,
      "discussionId": "684fa6d060b4a34dbe007ab2",
      "ai_summary": "InterSyn, a large-scale dataset with tightly interleaved image-text outputs and automated quality refinement, improves multimodal understanding and generation through the SEIR method and SynJudge, an automatic evaluation tool.",
      "ai_keywords": [
        "Large Multimodal Models (LMMs)",
        "multimodal understanding",
        "multimodal generation",
        "Self-Evaluation with Iterative Refinement (SEIR)",
        "InterSyn",
        "image-text outputs",
        "SynJudge",
        "text content",
        "image content",
        "image quality",
        "image-text synergy"
      ]
    },
    "publishedAt": "2025-06-11T02:21:20.000Z",
    "title": "A High-Quality Dataset and Reliable Evaluation for Interleaved\n  Image-Text Generation",
    "summary": "Recent advancements in Large Multimodal Models (LMMs) have significantly\nimproved multimodal understanding and generation. However, these models still\nstruggle to generate tightly interleaved image-text outputs, primarily due to\nthe limited scale, quality and instructional richness of current training\ndatasets. To address this, we introduce InterSyn, a large-scale multimodal\ndataset constructed using our Self-Evaluation with Iterative Refinement (SEIR)\nmethod. InterSyn features multi-turn, instruction-driven dialogues with tightly\ninterleaved imagetext responses, providing rich object diversity and rigorous\nautomated quality refinement, making it well-suited for training\nnext-generation instruction-following LMMs. Furthermore, to address the lack of\nreliable evaluation tools capable of assessing interleaved multimodal outputs,\nwe introduce SynJudge, an automatic evaluation model designed to quantitatively\nassess multimodal outputs along four dimensions: text content, image content,\nimage quality, and image-text synergy.\n  Experimental studies show that the SEIR method leads to substantially higher\ndataset quality compared to an otherwise identical process without refinement.\n  Moreover, LMMs trained on InterSyn achieve uniform performance gains across\nall evaluation metrics, confirming InterSyn's utility for advancing multimodal\nsystems.",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/65f1713552c38a91e0a445e8/1FHKfzv4w4VzV4nhqKCJ7.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.09427.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "65f1713552c38a91e0a445e8",
      "avatarUrl": "/avatars/47ab3ada51c9b9976ac1cd0c4301c373.svg",
      "fullname": "kaipeng",
      "name": "kpzhang996",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 3
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2506.09366",
      "authors": [
        {
          "_id": "684ae246dbd21a9cc27b111c",
          "user": {
            "_id": "62359088a17d7271859c88f4",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1647677549197-noauth.jpeg",
            "isPro": false,
            "fullname": "Yuxuan Kuang",
            "user": "yxK",
            "type": "user"
          },
          "name": "Yuxuan Kuang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-16T07:17:03.322Z",
          "hidden": false
        },
        {
          "_id": "684ae246dbd21a9cc27b111d",
          "name": "Haoran Geng",
          "hidden": false
        },
        {
          "_id": "684ae246dbd21a9cc27b111e",
          "user": {
            "_id": "64da71311d19239f50483005",
            "avatarUrl": "/avatars/d97a7177adca180d795bf0f9ec66c65c.svg",
            "isPro": false,
            "fullname": "Amine Elhafsi",
            "user": "AmineElhafsi",
            "type": "user"
          },
          "name": "Amine Elhafsi",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-06-16T07:50:59.675Z",
          "hidden": false
        },
        {
          "_id": "684ae246dbd21a9cc27b111f",
          "name": "Tan-Dzung Do",
          "hidden": false
        },
        {
          "_id": "684ae246dbd21a9cc27b1120",
          "name": "Pieter Abbeel",
          "hidden": false
        },
        {
          "_id": "684ae246dbd21a9cc27b1121",
          "user": {
            "_id": "65369a95605a07338de78ab0",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/sGFjOjLT2akN-sn5beVWL.jpeg",
            "isPro": false,
            "fullname": "Jitendra Malik ",
            "user": "jitendra1995",
            "type": "user"
          },
          "name": "Jitendra Malik",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-06-16T07:51:18.391Z",
          "hidden": false
        },
        {
          "_id": "684ae246dbd21a9cc27b1122",
          "name": "Marco Pavone",
          "hidden": false
        },
        {
          "_id": "684ae246dbd21a9cc27b1123",
          "name": "Yue Wang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-06-11T03:24:26.000Z",
      "submittedOnDailyAt": "2025-06-16T04:37:55.714Z",
      "title": "Skill Bridging: Se aplica para la manipulación general de diferentes Homenoides utilizando técnicas de bridging de habilidades.",
      "submittedOnDailyBy": {
        "_id": "62359088a17d7271859c88f4",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1647677549197-noauth.jpeg",
        "isPro": false,
        "fullname": "Yuxuan Kuang",
        "user": "yxK",
        "type": "user"
      },
      "summary": "Los robots de pequeños animales tienen un potencial importante debido a su flexibilidad y forma humanoide, lo que les permite realizar tareas diarias en diferentes entornos. Recientemente, los estudios han utilizado control óptimo y aprendizaje por refuerzo para avanzar en el control completo y movimiento de los robots. Sin embargo, estos métodos requieren una ajuste complejo para cada tarea y limitan la diversidad y escalabilidad para varias tareas. Por lo tanto, presentamos un nuevo marco de aprendizaje por refuerzo en etapas llamado SkillBlender, que garantiza la diversidad en las tareas de movimiento de los robots. SkillBlender inicialmente aprende habilidades básicas independientes de la tarea y combina estas habilidades dinámicamente, evitando la necesidad de diseñar recompensas específicas para cada tarea. Además, presentamos SkillBench, una batería de pruebas para evaluar diferentes tipos de cuerpos, que incluye 3 cuerpos, 4 habilidades básicas y 8 tareas de movimiento difíciles, proporcionando un criterio científico equilibrado de precisión y posibilidad. Los resultados de los pruebas de robotes de pequeños animales muestran que nuestros métodos superan significativamente los límites de los baselines, normalizan el comportamiento y evitan el refuerzo de la recompensa, demostrando una mejora en la precisión del movimiento en escenarios cotidianos. Nuestro código y los benchmarks se publicarán para fomentar futuras investigaciones. Página del proyecto: https://usc-gvl.github.io/SkillBlender-web/",
      "upvotes": 3,
      "discussionId": "684ae246dbd21a9cc27b1124",
      "projectPage": "https://usc-gvl.github.io/SkillBlender-web/",
      "githubRepo": "https://github.com/Humanoid-SkillBlender/SkillBlender",
      "ai_summary": "SkillBlender is a hierarchical reinforcement learning framework that uses pretrained primitive skills to efficiently solve diverse loco-manipulation tasks for humanoid robots.",
      "ai_keywords": [
        "reinforcement learning",
        "SkillBlender",
        "goal-conditioned",
        "task-agnostic primitive skills",
        "hierarchical reinforcement learning",
        "SkillBench",
        "cross-embodiment",
        "simulated benchmark",
        "loco-manipulation tasks",
        "reward engineering",
        "reward hacking"
      ]
    },
    "publishedAt": "2025-06-10T23:24:26.000Z",
    "title": "SkillBlender: Towards Versatile Humanoid Whole-Body Loco-Manipulation\n  via Skill Blending",
    "summary": "Humanoid robots hold significant potential in accomplishing daily tasks\nacross diverse environments thanks to their flexibility and human-like\nmorphology. Recent works have made significant progress in humanoid whole-body\ncontrol and loco-manipulation leveraging optimal control or reinforcement\nlearning. However, these methods require tedious task-specific tuning for each\ntask to achieve satisfactory behaviors, limiting their versatility and\nscalability to diverse tasks in daily scenarios. To that end, we introduce\nSkillBlender, a novel hierarchical reinforcement learning framework for\nversatile humanoid loco-manipulation. SkillBlender first pretrains\ngoal-conditioned task-agnostic primitive skills, and then dynamically blends\nthese skills to accomplish complex loco-manipulation tasks with minimal\ntask-specific reward engineering. We also introduce SkillBench, a parallel,\ncross-embodiment, and diverse simulated benchmark containing three embodiments,\nfour primitive skills, and eight challenging loco-manipulation tasks,\naccompanied by a set of scientific evaluation metrics balancing accuracy and\nfeasibility. Extensive simulated experiments show that our method significantly\noutperforms all baselines, while naturally regularizing behaviors to avoid\nreward hacking, resulting in more accurate and feasible movements for diverse\nloco-manipulation tasks in our daily scenarios. Our code and benchmark will be\nopen-sourced to the community to facilitate future research. Project page:\nhttps://usc-gvl.github.io/SkillBlender-web/.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.09366.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "62359088a17d7271859c88f4",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1647677549197-noauth.jpeg",
      "fullname": "Yuxuan Kuang",
      "name": "yxK",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2506.08477",
      "authors": [
        {
          "_id": "684fb8cb60b4a34dbe007b05",
          "name": "Fengjun Pan",
          "hidden": false
        },
        {
          "_id": "684fb8cb60b4a34dbe007b06",
          "name": "Anh Tuan Luu",
          "hidden": false
        },
        {
          "_id": "684fb8cb60b4a34dbe007b07",
          "user": {
            "_id": "64cb02869e30a46f7b80b355",
            "avatarUrl": "/avatars/81ce4ba78826b54f0e1b53eeaff87ee6.svg",
            "isPro": false,
            "fullname": "Xiaobao Wu",
            "user": "bobxwu",
            "type": "user"
          },
          "name": "Xiaobao Wu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-16T07:16:04.938Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-06-10T06:10:45.000Z",
      "submittedOnDailyAt": "2025-06-16T04:59:02.024Z",
      "title": "Detección de Memes Pésimos y Guías de Práctica\n\nModelo de Aprendizaje Automático desarrollado en la Investigación Institucional de Inteligencia Artificial de Shanghai. Este modelo utiliza explicaciones y guías de práctica para detectar eficazmente memes perjudiciales.",
      "submittedOnDailyBy": {
        "_id": "64cb02869e30a46f7b80b355",
        "avatarUrl": "/avatars/81ce4ba78826b54f0e1b53eeaff87ee6.svg",
        "isPro": false,
        "fullname": "Xiaobao Wu",
        "user": "bobxwu",
        "type": "user"
      },
      "summary": "La percepción de mensajes perjudiciales es esencial para mantener la integridad de los entornos en línea. Sin embargo, los métodos actuales de acceso presentan deficiencias en eficiencia de recursos, flexibilidad y explicabilidad, limitando la aplicación práctica del sistema de modelado de contenido. Para enfrentar estas desafíos, presentamos U-CoT+, un nuevo marco de trabajo para la percepción de mensajes perjudiciales. Este marco de trabajo desarrolla, por primera vez, una pipeline desde mensajes perjudiciales de alta precisión a texto, manteniendo casi intacto el entrenamiento o fine-tuning del modelo. Este diseño separa la interpretación y clasificación de los mensajes, evitando así la conexión inmediata de contenidos complejos con sus razones y permitiendo una percepción de mensajes perjudiciales eficiente en recursos utilizando grandes modelos de lenguaje natural (LLMs). Basándose en estos textos explicativos, se realizan guías más específicas y interpretables creadas por seres humanos, guiando el razonamiento del modelo en un procesamiento de razonamiento de cotas (CoT) sin ejemplos (0-shot). Este marco de trabajo permite una simple adaptación a diferentes estándares de percepción de perjuicios según plataforma, región y tiempo, ofreciendo alta flexibilidad y explicabilidad. Los experimentos extendidos en 7 conjuntos de datos de benchmark demuestran la efectividad de este marco de trabajo y destacan la posibilidad de una percepción de mensajes perjudiciales explicativa y eficiente en recursos utilizando pequeños modelos de LLMs. El código y los datos están disponibles en la siguiente URL: https://anonymous.4open.science/r/HMC-AF2B/README.md.",
      "upvotes": 2,
      "discussionId": "684fb8cb60b4a34dbe007b08",
      "ai_summary": "U-CoT+ is a novel framework for detecting harmful memes by converting them into textual descriptions and using human-crafted guidelines with zero-shot CoT prompting to achieve high flexibility and explainability with small-scale LLMs.",
      "ai_keywords": [
        "U-CoT+",
        "meme-to-text pipeline",
        "high-fidelity",
        "zero-shot CoT prompting",
        "human-crafted guidelines",
        "large language models (LLMs)",
        "harmful meme detection",
        "explainability",
        "flexibility",
        "benchmark datasets"
      ]
    },
    "publishedAt": "2025-06-10T02:10:45.000Z",
    "title": "Detecting Harmful Memes with Decoupled Understanding and Guided CoT\n  Reasoning",
    "summary": "Detecting harmful memes is essential for maintaining the integrity of online\nenvironments. However, current approaches often struggle with resource\nefficiency, flexibility, or explainability, limiting their practical deployment\nin content moderation systems. To address these challenges, we introduce\nU-CoT+, a novel framework for harmful meme detection. Instead of relying solely\non prompting or fine-tuning multimodal models, we first develop a high-fidelity\nmeme-to-text pipeline that converts visual memes into detail-preserving textual\ndescriptions. This design decouples meme interpretation from meme\nclassification, thus avoiding immediate reasoning over complex raw visual\ncontent and enabling resource-efficient harmful meme detection with general\nlarge language models (LLMs). Building on these textual descriptions, we\nfurther incorporate targeted, interpretable human-crafted guidelines to guide\nmodels' reasoning under zero-shot CoT prompting. As such, this framework allows\nfor easy adaptation to different harmfulness detection criteria across\nplatforms, regions, and over time, offering high flexibility and\nexplainability. Extensive experiments on seven benchmark datasets validate the\neffectiveness of our framework, highlighting its potential for explainable and\nlow-resource harmful meme detection using small-scale LLMs. Codes and data are\navailable at: https://anonymous.4open.science/r/HMC-AF2B/README.md.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.08477.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64cb02869e30a46f7b80b355",
      "avatarUrl": "/avatars/81ce4ba78826b54f0e1b53eeaff87ee6.svg",
      "fullname": "Xiaobao Wu",
      "name": "bobxwu",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2506.07464",
      "authors": [
        {
          "_id": "684fd9a160b4a34dbe007b93",
          "name": "Jinyoung Park",
          "hidden": false
        },
        {
          "_id": "684fd9a160b4a34dbe007b94",
          "name": "Jeehye Na",
          "hidden": false
        },
        {
          "_id": "684fd9a160b4a34dbe007b95",
          "name": "Jinyoung Kim",
          "hidden": false
        },
        {
          "_id": "684fd9a160b4a34dbe007b96",
          "name": "Hyunwoo J. Kim",
          "hidden": false
        }
      ],
      "publishedAt": "2025-06-09T06:15:54.000Z",
      "submittedOnDailyAt": "2025-06-16T07:17:50.892Z",
      "title": "Dificultad-basada Política Global para Ajustar Aprendizaje por Refuerzo en Video",
      "submittedOnDailyBy": {
        "_id": "64b6eae88ba7d6c922c0434a",
        "avatarUrl": "/avatars/6adac8242106ab12abeaa3584346c0cd.svg",
        "isPro": false,
        "fullname": "Jinyoung Park",
        "user": "jinypark",
        "type": "user"
      },
      "summary": "Recientes investigaciones han demostrado que el aprendizaje por refuerzo (RL) basado en procesamiento posterior mejora la capacidad de comprensión de los modelos de lenguaje grandes (LLMs). En particular, el Group Relative Policy Optimization (GRPO) utiliza un algoritmo de aprendizaje por refuerzo de tipo PPO que emplea una normalización de recompensas basada en grupos y ha tenido un éxito notable. Sin embargo, la aplicación de GRPO en los Video Large Language Models (Video LLMs) ha sido menos estudiada. En este artículo, se revisa el GRPO en los Video LLMs y se identifican dos problemas principales que pueden impidir un aprendizaje efectivo: (1) la dependencia en juegos seguros y (2) el problema de desaparición de la prioridad. Para mitigar estos problemas, se propone DeepVideo-R1. DeepVideo-R1 es un Video Large Language Model entrenado utilizando el Reg-GRPO (Región de GRPO) que proponemos y una estrategia de expansión de datos en función de la dificultad. El Reg-GRPO reconstruye el objetivo de GRPO como un tarea de regresión y directamente predice las prioridades de GRPO. Esta disección elimina la necesidad de juegos seguros como ClipPING y min, ajusta el modelo a los valores de prioridad y proporciona una guía más directa para la política. Además, se diseñó una estrategia de expansión de datos en función de la dificultad, que expande los muestras de entrenamiento dinámicamente en niveles de dificultad resolubles y fomenta señales de recompensa con diversas informaciones. Nuestros resultados detallados muestran que DeepVideo-R1 mejora significativamente el rendimiento de Video Reasoning en varios benchmarks de Video Reasoning.",
      "upvotes": 2,
      "discussionId": "684fd9a160b4a34dbe007b97",
      "ai_summary": "DeepVideo-R1 enhances video reasoning performance using Reg-GRPO, a regression-based GRPO approach, and difficulty-aware data augmentation for video large language models.",
      "ai_keywords": [
        "reinforcement learning",
        "Group Relative Policy Optimization",
        "GRPO",
        "Policy Optimization",
        "PPO",
        "Video Large Language Models",
        "Video LLMs",
        "DeepVideo-R1",
        "Reg-GRPO",
        "regression task",
        "advantage values",
        "difficulty-aware data augmentation",
        "video reasoning benchmarks"
      ]
    },
    "publishedAt": "2025-06-09T02:15:54.000Z",
    "title": "DeepVideo-R1: Video Reinforcement Fine-Tuning via Difficulty-aware\n  Regressive GRPO",
    "summary": "Recent works have demonstrated the effectiveness of reinforcement learning\n(RL)-based post-training in enhancing the reasoning capabilities of large\nlanguage models (LLMs). In particular, Group Relative Policy Optimization\n(GRPO) has shown impressive success by employing a PPO-style reinforcement\nalgorithm with group-based normalized rewards. However, the application of GRPO\nto Video Large Language Models (Video LLMs) has been less studied. In this\npaper, we explore GRPO for video LLMs and identify two primary issues that\nimpede its effective learning: (1) reliance on safeguards, and (2) the\nvanishing advantage problem. To mitigate these challenges, we propose\nDeepVideo-R1, a video large language model trained with our proposed Reg-GRPO\n(Regressive GRPO) and difficulty-aware data augmentation strategy. Reg-GRPO\nreformulates the GRPO objective as a regression task, directly predicting the\nadvantage in GRPO. This design eliminates the need for safeguards like clipping\nand min functions, thereby facilitating more direct policy guidance by aligning\nthe model with the advantage values. We also design the difficulty-aware data\naugmentation strategy that dynamically augments training samples at solvable\ndifficulty levels, fostering diverse and informative reward signals. Our\ncomprehensive experiments show that DeepVideo-R1 significantly improves video\nreasoning performance across multiple video reasoning benchmarks.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.07464.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64b6eae88ba7d6c922c0434a",
      "avatarUrl": "/avatars/6adac8242106ab12abeaa3584346c0cd.svg",
      "fullname": "Jinyoung Park",
      "name": "jinypark",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2506.11702",
      "authors": [
        {
          "_id": "684fae8360b4a34dbe007ac9",
          "user": {
            "_id": "5fad8602b8423e1d80b8a965",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/5fad8602b8423e1d80b8a965/tRqTwcZmrGka8c1vFq2wX.jpeg",
            "isPro": false,
            "fullname": "Victor Gallego",
            "user": "vicgalle",
            "type": "user"
          },
          "name": "Víctor Gallego",
          "status": "extracted_confirmed",
          "statusLastChangedAt": "2025-06-16T05:42:55.745Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-06-13T12:17:38.000Z",
      "submittedOnDailyAt": "2025-06-16T04:12:09.638Z",
      "title": "Preferencia de ajuste variable basada en datos con palabras clave",
      "submittedOnDailyBy": {
        "_id": "5fad8602b8423e1d80b8a965",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/5fad8602b8423e1d80b8a965/tRqTwcZmrGka8c1vFq2wX.jpeg",
        "isPro": false,
        "fullname": "Victor Gallego",
        "user": "vicgalle",
        "type": "user"
      },
      "summary": "En la propuesta de ajuste de modelos de retroalimentación humana, los métodos como la Direct Preference Optimization (DPO) incluyen a menudo conjuntos estáticos de preferencias coherentes, limitando la adaptabilidad. En este artículo, sin asumir la coherencia de las preferencias, se introduce Configurable Preference Tuning (CPT) para proponer un nuevo marco que permita ajustar de manera dinámica los modelos de lenguaje basándose en instrucciones explícitas que pueden ser entendidas por humanos. CPT utiliza datos de preferencias generados a partir de sistemas de preguntas estructuradas y reglas delicadas, para ajustar micro con las preferencias guiadas por estas reglas y entrenar para ajustar las salidas que responden a los sistemas de preguntas. Este enfoque proporciona un control más detallado mientras ofrece una estructura más compleja para modelar retroalimentación más avanzada. Código de entrenamiento, conjuntos de datos generados y modelos ajustados, entre otros archivos experimentales, están disponibles en https://github.com/vicgalle/configurable-preference-tuning.",
      "upvotes": 1,
      "discussionId": "684fae8460b4a34dbe007aca",
      "ai_summary": "Configurable Preference Tuning enables language models to dynamically adjust their behavior based on human-interprettable directives, using rubric-guided preference data for fine-tuning and inference-time modulation.",
      "ai_keywords": [
        "Configurable Preference Tuning",
        "Direct Preference Optimization",
        "language models",
        "fine-grained control",
        "rubric-guided preferences",
        "inference-time modulation"
      ]
    },
    "publishedAt": "2025-06-13T08:17:38.000Z",
    "title": "Configurable Preference Tuning with Rubric-Guided Synthetic Data",
    "summary": "Models of human feedback for AI alignment, such as those underpinning Direct\nPreference Optimization (DPO), often bake in a singular, static set of\npreferences, limiting adaptability. This paper challenges the assumption of\nmonolithic preferences by introducing Configurable Preference Tuning (CPT), a\nnovel framework for endowing language models with the ability to dynamically\nadjust their behavior based on explicit, human-interpretable directives. CPT\nleverages synthetically generated preference data, conditioned on system\nprompts derived from structured, fine-grained rubrics that define desired\nattributes like writing style. By fine-tuning with these rubric-guided\npreferences, the LLM learns to modulate its outputs at inference time in\nresponse to the system prompt, without retraining. This approach not only\noffers fine-grained control but also provides a mechanism for modeling more\nnuanced and context-dependent human feedback. Several experimental artifacts,\nsuch as training code, generated datasets and fine-tuned models are released at\nhttps://github.com/vicgalle/configurable-preference-tuning",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.11702.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "5fad8602b8423e1d80b8a965",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/5fad8602b8423e1d80b8a965/tRqTwcZmrGka8c1vFq2wX.jpeg",
      "fullname": "Victor Gallego",
      "name": "vicgalle",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 129
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2506.10128",
      "authors": [
        {
          "_id": "684fed081d9b438aa3957a50",
          "name": "Xiyao Wang",
          "hidden": false
        },
        {
          "_id": "684fed081d9b438aa3957a51",
          "name": "Zhengyuan Yang",
          "hidden": false
        },
        {
          "_id": "684fed081d9b438aa3957a52",
          "name": "Chao Feng",
          "hidden": false
        },
        {
          "_id": "684fed081d9b438aa3957a53",
          "name": "Yongyuan Liang",
          "hidden": false
        },
        {
          "_id": "684fed081d9b438aa3957a54",
          "name": "Yuhang Zhou",
          "hidden": false
        },
        {
          "_id": "684fed081d9b438aa3957a55",
          "name": "Xiaoyu Liu",
          "hidden": false
        },
        {
          "_id": "684fed081d9b438aa3957a56",
          "name": "Ziyi Zang",
          "hidden": false
        },
        {
          "_id": "684fed081d9b438aa3957a57",
          "name": "Ming Li",
          "hidden": false
        },
        {
          "_id": "684fed081d9b438aa3957a58",
          "name": "Chung-Ching Lin",
          "hidden": false
        },
        {
          "_id": "684fed081d9b438aa3957a59",
          "name": "Kevin Lin",
          "hidden": false
        },
        {
          "_id": "684fed081d9b438aa3957a5a",
          "name": "Linjie Li",
          "hidden": false
        },
        {
          "_id": "684fed081d9b438aa3957a5b",
          "name": "Furong Huang",
          "hidden": false
        },
        {
          "_id": "684fed081d9b438aa3957a5c",
          "name": "Lijuan Wang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-06-11T19:16:54.000Z",
      "submittedOnDailyAt": "2025-06-16T08:39:17.071Z",
      "title": "ViCrit: Tarea de un agente de aprendizaje reforzado verificable para proyectos visuales",
      "submittedOnDailyBy": {
        "_id": "655fed9fdef5905d38b84af3",
        "avatarUrl": "/avatars/2cda4182dfd11a1e94743639e62328ea.svg",
        "isPro": false,
        "fullname": "Xiyao Wang",
        "user": "russwang",
        "type": "user"
      },
      "summary": "El aprendizaje por refuerzo (RL) se ha utilizado con éxito en tareas como la lógica matemática o la generación de código, demostrando resultados efectivos en el ajuste de modelos de lenguaje grandes (LLMs). Sin embargo, extender este éxito a la reconocimiento visual ha sido retrasado debido a la escasez de tareas centradas en la visión. Para abordar este desafío, se propone ViCrit (Critic de Hallucinación de Capturas Visuales), una solución basada en la representación de trabajos delegados del RL. ViCrit modela los modelos de lenguaje y visión (VLMs) y se entrena para localizar los pequeños y sintéticos errores visuales que se insertan en las capturas de imágenes escritas por humanos. Comienza con una captura de 200 palabras, cambiando objetos, características, números o relaciones espaciales para introducir un error visual, y proporcionando la captura modificada y la imagen al modelo, el modelo debe identificar el error introducido. Esta configuración mantiene completamente el desafío visual y proporciona una compensación binaria clara y fácil de calcular. Los modelos entrenados con el trabajo de ViCrit muestran notables mejoras en diferentes benchmarks de VL. Un punto importante es que estas mejoras se aplican tanto a la lógica abstracta de imágenes en conjunto de datos de imágenes naturales como a la matemática visual, demostrando que se puede entrenar la percepción visual. Para evaluar estos resultados, se añade ViCrit-Bench, un benchmark diagnóstico equilibrado de categorías, para investigar de manera integral las diferentes tipos de errores visuales. Estos resultados demuestran que la evaluación de la hallucinación visual es un objetivo eficaz y generalizable para fortalecer la percepción visual de los VLMs.",
      "upvotes": 1,
      "discussionId": "684fed081d9b438aa3957a5d",
      "githubRepo": "https://github.com/si0wang/ViCrit",
      "ai_summary": "ViCrit, an RL task for fine-tuning VLMs, improves visual perception by training models to detect subtle hallucinations in image captions, with gains transferable to various visual domains.",
      "ai_keywords": [
        "reinforcement learning (RL)",
        "large language models (LLMs)",
        "vision-language models (VLMs)",
        "visual caption hallucination critic",
        "perceptual difficulty",
        "binary reward",
        "exact-match reward",
        "ViCrit-Bench",
        "abstract image reasoning",
        "visual math"
      ]
    },
    "publishedAt": "2025-06-11T15:16:54.000Z",
    "title": "ViCrit: A Verifiable Reinforcement Learning Proxy Task for Visual\n  Perception in VLMs",
    "summary": "Reinforcement learning (RL) has shown great effectiveness for fine-tuning\nlarge language models (LLMs) using tasks that are challenging yet easily\nverifiable, such as math reasoning or code generation. However, extending this\nsuccess to visual perception in vision-language models (VLMs) has been impeded\nby the scarcity of vision-centric tasks that are simultaneously challenging and\nunambiguously verifiable. To this end, we introduce ViCrit (Visual Caption\nHallucination Critic), an RL proxy task that trains VLMs to localize a subtle,\nsynthetic visual hallucination injected into paragraphs of human-written image\ncaptions. Starting from a 200-word captions, we inject a single, subtle visual\ndescription error-altering a few words on objects, attributes, counts, or\nspatial relations-and task the model to pinpoint the corrupted span given the\nimage and the modified caption. This formulation preserves the full perceptual\ndifficulty while providing a binary, exact-match reward that is easy to compute\nand unambiguous. Models trained with the ViCrit Task exhibit substantial gains\nacross a variety of VL benchmarks. Crucially, the improvements transfer beyond\nnatural-image training data to abstract image reasoning and visual math,\nshowing promises of learning to perceive rather than barely memorizing seen\nobjects. To facilitate evaluation, we further introduce ViCrit-Bench, a\ncategory-balanced diagnostic benchmark that systematically probes perception\nerrors across diverse image domains and error types. Together, our results\ndemonstrate that fine-grained hallucination criticism is an effective and\ngeneralizable objective for enhancing visual perception in VLMs.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.10128.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "655fed9fdef5905d38b84af3",
      "avatarUrl": "/avatars/2cda4182dfd11a1e94743639e62328ea.svg",
      "fullname": "Xiyao Wang",
      "name": "russwang",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 4
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2506.11130",
      "authors": [
        {
          "_id": "684fdd8e1d9b438aa39579c6",
          "name": "Cheng Kang Chou",
          "hidden": false
        },
        {
          "_id": "684fdd8e1d9b438aa39579c7",
          "name": "Chan-Jan Hsu",
          "hidden": false
        },
        {
          "_id": "684fdd8e1d9b438aa39579c8",
          "name": "Ho-Lam Chung",
          "hidden": false
        },
        {
          "_id": "684fdd8e1d9b438aa39579c9",
          "name": "Liang-Hsuan Tseng",
          "hidden": false
        },
        {
          "_id": "684fdd8e1d9b438aa39579ca",
          "name": "Hsi-Chun Cheng",
          "hidden": false
        },
        {
          "_id": "684fdd8e1d9b438aa39579cb",
          "name": "Yu-Kuan Fu",
          "hidden": false
        },
        {
          "_id": "684fdd8e1d9b438aa39579cc",
          "name": "Kuan Po Huang",
          "hidden": false
        },
        {
          "_id": "684fdd8e1d9b438aa39579cd",
          "name": "Hung-Yi Lee",
          "hidden": false
        }
      ],
      "publishedAt": "2025-06-10T17:30:32.000Z",
      "submittedOnDailyAt": "2025-06-16T07:32:50.759Z",
      "title": "Utilizando el marco de trabajo transformado para la generación de datos de TTS para el aprendizaje de la ASR fortalecido",
      "submittedOnDailyBy": {
        "_id": "6213410828005421265b27d3",
        "avatarUrl": "/avatars/930ac20daf640ca31fab713bf00c3268.svg",
        "isPro": false,
        "fullname": "許湛然",
        "user": "Splend1dchan",
        "type": "user"
      },
      "summary": "Proponemos un marco de mejora automática para mejorar el rendimiento de la ASR utilizando conjuntos de datos sin etiquetas. El proceso comienza con la generación de etiquetas virtuales por parte del modelo ASR para datos de voz sin etiquetas, lo cual se utiliza para entrenar un sistema de conversión de texto a voz (TTS) de alta calidad. A continuación, las parejas de voz sintética y texto se reutilizan en el sistema original de ASR, completando el ciclo de mejora automática en un ciclo cerrado. Demostramos el efecto de este marco de trabajo utilizando voz generalizada en el taingó. Utilizamos 6,000 horas de datos de señal sin etiquetas, una cantidad significativa de datos de texto y contenido generado por un modelo de IA para especializar Whisper-large-v2 y crear el modelo Twister. Twister redujo el error de 20% en el taingó en comparación con Whisper y el benchmark de cambio de código entre el taingó y el inglés en un 50%. Estos resultados demuestran la efectividad del método de adaptación de etiquetas virtuales y proporcionan una contraseña efectiva para mejorar el rendimiento de la ASR en entornos con bajo recursos o configuraciones específicas.",
      "upvotes": 1,
      "discussionId": "684fdd8f1d9b438aa39579ce",
      "ai_summary": "A self-refining framework enhances ASR performance using unlabeled datasets by integrating pseudo-labeling, TTS, and synthesized speech to create a specialized model.",
      "ai_keywords": [
        "self-refining framework",
        "ASR",
        "pseudo-labels",
        "TTS",
        "synthesized speech",
        "Whisper-large-v2",
        "Twister",
        "error rates",
        "Mandarin",
        "Mandarin-English code-switching"
      ]
    },
    "publishedAt": "2025-06-10T13:30:32.000Z",
    "title": "A Self-Refining Framework for Enhancing ASR Using TTS-Synthesized Data",
    "summary": "We propose a self-refining framework that enhances ASR performance with only\nunlabeled datasets. The process starts with an existing ASR model generating\npseudo-labels on unannotated speech, which are then used to train a\nhigh-fidelity text-to-speech (TTS) system. Then, synthesized speech text pairs\nare bootstrapped into the original ASR system, completing the closed-loop\nself-improvement cycle. We demonstrated the effectiveness of the framework on\nTaiwanese Mandarin speech. Leveraging 6,000 hours of unlabeled speech, a\nmoderate amount of text data, and synthetic content from the AI models, we\nadapt Whisper-large-v2 into a specialized model, Twister. Twister reduces error\nrates by up to 20% on Mandarin and 50% on Mandarin-English code-switching\nbenchmarks compared to Whisper. Results highlight the framework as a compelling\nalternative to pseudo-labeling self-distillation approaches and provides a\npractical pathway for improving ASR performance in low-resource or\ndomain-specific settings.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.11130.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6213410828005421265b27d3",
      "avatarUrl": "/avatars/930ac20daf640ca31fab713bf00c3268.svg",
      "fullname": "許湛然",
      "name": "Splend1dchan",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 13
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2506.08592",
      "authors": [
        {
          "_id": "684cfefc3b733ba3336873a6",
          "user": {
            "_id": "650f0fac11f3210cf7a8a849",
            "avatarUrl": "/avatars/687d56c3a6d4f5cdb34e424cdcff954d.svg",
            "isPro": false,
            "fullname": "Leon Xu",
            "user": "lxucs",
            "type": "user"
          },
          "name": "Liyan Xu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-16T07:50:16.178Z",
          "hidden": false
        },
        {
          "_id": "684cfefc3b733ba3336873a7",
          "name": "Zhenlin Su",
          "hidden": false
        },
        {
          "_id": "684cfefc3b733ba3336873a8",
          "name": "Mo Yu",
          "hidden": false
        },
        {
          "_id": "684cfefc3b733ba3336873a9",
          "name": "Jiangnan Li",
          "hidden": false
        },
        {
          "_id": "684cfefc3b733ba3336873aa",
          "name": "Fandong Meng",
          "hidden": false
        },
        {
          "_id": "684cfefc3b733ba3336873ab",
          "name": "Jie Zhou",
          "hidden": false
        }
      ],
      "publishedAt": "2025-06-10T09:00:33.000Z",
      "submittedOnDailyAt": "2025-06-16T06:09:56.672Z",
      "title": "Dense Retrievers Can Fail on Simple Queries: Revealing The Granularity Dilemma of Embeddings",
      "submittedOnDailyBy": {
        "_id": "650f0fac11f3210cf7a8a849",
        "avatarUrl": "/avatars/687d56c3a6d4f5cdb34e424cdcff954d.svg",
        "isPro": false,
        "fullname": "Leon Xu",
        "user": "lxucs",
        "type": "user"
      },
      "summary": "Este estudio enfoca las limitaciones observadas en los encoders de texto: los embeddings no pueden reconocer entidades o eventos muy pequeñas o delicadas dentro de un contexto de significado, lo que puede llevar a fallas en busquedas cercanas incluso en casos sencillos. Para investigar estas condiciones, se presenta primero un nuevo conjunto de datos de evaluación. Este conjunto de datos consiste en capturas de imágenes, con preguntas formuladas en forma de oraciones que plantean entidades o eventos. Según la evaluación de 0 shot, el encoder tiene un alto riesgo de fallar en estas pequeñas coincidencias. Para mejorar esta situación, se propone una estrategia de generación de datos para ajustar minuciosamente el encoder y alcanzar el mejor rendimiento en CapRetrieval. Durante este proceso, se identificaron dos problemas complejos: el embedding debe representar señales muy pequeñas de manera que coincidan con el significado general, lo que requiere una granularidad alta. Los conjuntos de datos, código y modelos utilizados en este estudio están disponibles en https://github.com/lxucs/CapRetrieval.",
      "upvotes": 1,
      "discussionId": "684cfefc3b733ba3336873ac",
      "ai_summary": "A new dataset named CapRetrieval is introduced to evaluate the ability of text encoders to recognize fine-grained entities and events, highlighting challenges in dense retrieval tasks.",
      "ai_keywords": [
        "text encoders",
        "embeddings",
        "fine-grained entities",
        "events",
        "dense retrieval",
        "zero-shot evaluation",
        "data generation strategies",
        "granularity dilemma"
      ]
    },
    "publishedAt": "2025-06-10T05:00:33.000Z",
    "title": "Dense Retrievers Can Fail on Simple Queries: Revealing The Granularity\n  Dilemma of Embeddings",
    "summary": "This work focuses on an observed limitation of text encoders: embeddings may\nnot be able to recognize fine-grained entities or events within the semantics,\nresulting in failed dense retrieval on even simple cases. To examine such\nbehaviors, we first introduce a new evaluation dataset in Chinese, named\nCapRetrieval, whose passages are image captions, and queries are phrases\ninquiring entities or events in various forms. Zero-shot evaluation suggests\nthat encoders may fail on these fine-grained matching, regardless of training\nsources or model sizes. Aiming for enhancement, we proceed to finetune encoders\nwith our proposed data generation strategies, which obtains the best\nperformance on CapRetrieval. Within this process, we further identify an issue\nof granularity dilemma, a challenge for embeddings to express fine-grained\nsalience while aligning with overall semantics. Our dataset, code and models in\nthis work are publicly released at https://github.com/lxucs/CapRetrieval.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.08592.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "650f0fac11f3210cf7a8a849",
      "avatarUrl": "/avatars/687d56c3a6d4f5cdb34e424cdcff954d.svg",
      "fullname": "Leon Xu",
      "name": "lxucs",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2506.08915",
      "authors": [
        {
          "_id": "684fe3711d9b438aa39579da",
          "user": {
            "_id": "6508647f0c87331947c4a46d",
            "avatarUrl": "/avatars/9ddaf4ec53729cb69f65b314a7f4a9a0.svg",
            "isPro": false,
            "fullname": "Ananthu Aniraj",
            "user": "ananthu-aniraj",
            "type": "user"
          },
          "name": "Ananthu Aniraj",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-16T09:52:38.316Z",
          "hidden": false
        },
        {
          "_id": "684fe3711d9b438aa39579db",
          "name": "Cassio F. Dantas",
          "hidden": false
        },
        {
          "_id": "684fe3711d9b438aa39579dc",
          "name": "Dino Ienco",
          "hidden": false
        },
        {
          "_id": "684fe3711d9b438aa39579dd",
          "name": "Diego Marcos",
          "hidden": false
        }
      ],
      "publishedAt": "2025-06-10T15:41:22.000Z",
      "submittedOnDailyAt": "2025-06-16T08:04:59.344Z",
      "title": "Mapeo de Atención con Confianza en la Raza para Visión Transformers",
      "submittedOnDailyBy": {
        "_id": "6508647f0c87331947c4a46d",
        "avatarUrl": "/avatars/9ddaf4ec53729cb69f65b314a7f4a9a0.svg",
        "isPro": false,
        "fullname": "Ananthu Aniraj",
        "user": "ananthu-aniraj",
        "type": "user"
      },
      "summary": "Aquí se presenta un método basado en atención que utiliza un máscara de atención binaria entrenada para que solo afecte la predicción a las áreas de la imagen encontradas. El contexto tiene un impacto significativo en la reconocimiento de objetos. A veces llama a expresiones que pueden causar sesgos, especialmente cuando los objetos aparecen en fondos diferentes a su distribución natural. Por otro lado, en problemas de nivel de imagen que se centran en objetos, es necesario especificar áreas relacionadas. Para resolver esto, proponemos un marco de trabajo en dos etapas: la etapa 1 procesa la imagen completa para detectar partes de los objetos y especificar las áreas relacionadas con el problema. La etapa 2 utiliza la máscara de atención de entrada para concentrar el análisis en estas áreas y filtrar información potencialmente de paso corto. Ambas etapas se entrenan juntas, y la etapa 2 puede refinar la etapa 1. Experimentos en diferentes benchmarks muestran que nuestro enfoque mejora significativamente la robustez frente a correlaciones indirectas perdidas y a fondos diferentes a la distribución natural.",
      "upvotes": 0,
      "discussionId": "684fe3711d9b438aa39579de",
      "githubRepo": "https://github.com/ananthu-aniraj/ifam",
      "ai_summary": "An attention-based method using learned binary masks improves robustness in object perception by focusing on relevant image regions while filtering out spurious information.",
      "ai_keywords": [
        "attention-based method",
        "learned binary attention masks",
        "object perception",
        "context",
        "out-of-distribution backgrounds",
        "image-level object-centric tasks",
        "task-relevant regions",
        "two-stage framework",
        "receptive field",
        "joint training",
        "robustness",
        "spurious correlations"
      ]
    },
    "publishedAt": "2025-06-10T11:41:22.000Z",
    "title": "Inherently Faithful Attention Maps for Vision Transformers",
    "summary": "We introduce an attention-based method that uses learned binary attention\nmasks to ensure that only attended image regions influence the prediction.\nContext can strongly affect object perception, sometimes leading to biased\nrepresentations, particularly when objects appear in out-of-distribution\nbackgrounds. At the same time, many image-level object-centric tasks require\nidentifying relevant regions, often requiring context. To address this\nconundrum, we propose a two-stage framework: stage 1 processes the full image\nto discover object parts and identify task-relevant regions, while stage 2\nleverages input attention masking to restrict its receptive field to these\nregions, enabling a focused analysis while filtering out potentially spurious\ninformation. Both stages are trained jointly, allowing stage 2 to refine stage\n1. Extensive experiments across diverse benchmarks demonstrate that our\napproach significantly improves robustness against spurious correlations and\nout-of-distribution backgrounds.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.08915.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6508647f0c87331947c4a46d",
      "avatarUrl": "/avatars/9ddaf4ec53729cb69f65b314a7f4a9a0.svg",
      "fullname": "Ananthu Aniraj",
      "name": "ananthu-aniraj",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  }
]