[
  {
    "paper": {
      "id": "2502.12152",
      "authors": [
        {
          "_id": "67b41ed52867282b4eb37ce4",
          "name": "Xialin He",
          "hidden": false
        },
        {
          "_id": "67b41ed52867282b4eb37ce5",
          "user": {
            "_id": "6201fc5d91d53938a6432fbf",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6201fc5d91d53938a6432fbf/VLs8ZYaZrop4KBpZn53fH.jpeg",
            "isPro": false,
            "fullname": "Runpei Dong",
            "user": "RunpeiDong",
            "type": "user"
          },
          "name": "Runpei Dong",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-18T09:31:13.178Z",
          "hidden": false
        },
        {
          "_id": "67b41ed52867282b4eb37ce6",
          "name": "Zixuan Chen",
          "hidden": false
        },
        {
          "_id": "67b41ed52867282b4eb37ce7",
          "name": "Saurabh Gupta",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-17T18:59:06.000Z",
      "title": "Aprendizaje de Políticas para el Deslizarse en Robots Humanoides de la Real Mundo",
      "summary": "Automáticamente, el polikaría es una condición asumida importante para el robot de pequeños cuerpos de confianza. Debido a las varias estructuras y las dificultades de funcionamiento en diversas superficies, diseñar un controlador manual es complejo. En este artículo, se desarrolla un marco de aprendizaje para crear un controlador que permita que el robot de pequeños cuerpos se mueva suavemente en diferentes estructuras y superficies. Una diferencia con los anteriores ensayos de movimiento del robot de pequeños cuerpos es que los trabajos suaves incluyen patrones de contacto complejos, lo que requiere modelización geométrica de colisiones y descripción de recompensas escasas. Para abordar estos desafíos, se emplea un enfoque de dos etapas. La primera etapa se centra en encontrar una tarleta suave y efectiva bajo restricciones de estabilidad y velocidad/carga, mientras la segunda etapa mejora la acción encontrada para hacerla realmente usable (es decir, suave y progresiva) y hacerla más resistente a cambios iniciales de la estructura y superficie. Demostramos que esta innovación permite que los robots de pequeños cuerpos de tipo G1 puedan realizar dos estados suaves en el mundo real: a) el estado suave en la cara y b) el estado suave debajo de la cara, ambos planos, flexibles y probados en superficies suaves y inclinadas (por ejemplo, superficies de deslizamiento y campos de visión). Esto representa el primer experimento exitoso de una política para que un robot de pequeños cuerpos de tamaño humano se mueva suavemente en el mundo real. Página del proyecto: https://humanoid-getup.github.io/",
      "upvotes": 23,
      "discussionId": "67b41edb2867282b4eb37ddf"
    },
    "publishedAt": "2025-02-18T00:49:53.124Z",
    "title": "Learning Getting-Up Policies for Real-World Humanoid Robots",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/6201fc5d91d53938a6432fbf/x35BuXOhc6ubukxLfiVzt.mp4"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.12152.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6201fc5d91d53938a6432fbf",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6201fc5d91d53938a6432fbf/VLs8ZYaZrop4KBpZn53fH.jpeg",
      "fullname": "Runpei Dong",
      "name": "RunpeiDong",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 3
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.11190",
      "authors": [
        {
          "_id": "67b420dfb2528c023491f455",
          "name": "Haoming Xu",
          "hidden": false
        },
        {
          "_id": "67b420dfb2528c023491f456",
          "name": "Ningyuan Zhao",
          "hidden": false
        },
        {
          "_id": "67b420dfb2528c023491f457",
          "name": "Liming Yang",
          "hidden": false
        },
        {
          "_id": "67b420dfb2528c023491f458",
          "name": "Sendong Zhao",
          "hidden": false
        },
        {
          "_id": "67b420dfb2528c023491f459",
          "name": "Shumin Deng",
          "hidden": false
        },
        {
          "_id": "67b420dfb2528c023491f45a",
          "name": "Mengru Wang",
          "hidden": false
        },
        {
          "_id": "67b420dfb2528c023491f45b",
          "name": "Bryan Hooi",
          "hidden": false
        },
        {
          "_id": "67b420dfb2528c023491f45c",
          "name": "Nay Oo",
          "hidden": false
        },
        {
          "_id": "67b420dfb2528c023491f45d",
          "name": "Huajun Chen",
          "hidden": false
        },
        {
          "_id": "67b420dfb2528c023491f45e",
          "user": {
            "_id": "620b3bbb0668e435407c8d0a",
            "avatarUrl": "/avatars/e0fccbb2577d76088e09f054c35cffbc.svg",
            "isPro": false,
            "fullname": "Ningyu Zhang",
            "user": "Ningyu",
            "type": "user"
          },
          "name": "Ningyu Zhang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-18T09:31:11.243Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-16T16:31:00.000Z",
      "title": "ReLearn: Aprendizaje por olvidar mediante modelos de lenguaje grande.",
      "summary": "Los métodos de olvidación en los modelos de lenguaje grandes actuales se realizan mediante optimización de retro-replicación para reducir la probabilidad de los tokens objetivo. Sin embargo, este paradigma destruye la predicción de los tokens posteriores y disminuye el rendimiento y la coherencia gramatical del modelo. Además, los indicadores de evaluación actuales exigen un olvido contextual excesivo y evaluan poco el flujo y la relación del respuesta. Para resolver estos problemas, proponemos ReLearn. ReLearn incluye una pipeline de expansión de datos y ajuste fino para realizar un olvidación efectiva, así como un marco de evaluación detallado. Este marco introduce la Retención del Conocimiento Rate (KFR) y la Retención del Conocimiento Ratio (KRR) para evaluar la conservación del conocimiento, y la Puntuación del Lenguaje (LS) para evaluar la calidad de la generación. Nuestros experimentos demuestran que ReLearn logra olvidar los objetivos mientras mantiene alta calidad en los resultados. Un análisis estructural refuerza que ReLearn mantiene estas capacidades básicas, destruyendo así la coherencia contextual que la optimización de retro-replicación destruye. El código está disponible en https://github.com/zjunlp/unlearn.",
      "upvotes": 11,
      "discussionId": "67b420e2b2528c023491f506"
    },
    "publishedAt": "2025-02-18T00:58:24.094Z",
    "title": "ReLearn: Unlearning via Learning for Large Language Models",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/620b3bbb0668e435407c8d0a/A4YB7t6hDVty6QrvLN0a7.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.11190.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "620b3bbb0668e435407c8d0a",
      "avatarUrl": "/avatars/e0fccbb2577d76088e09f054c35cffbc.svg",
      "fullname": "Ningyu Zhang",
      "name": "Ningyu",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 17
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.12115",
      "authors": [
        {
          "_id": "67b41a72a38d04cc6148d80e",
          "name": "Samuel Miserendino",
          "hidden": false
        },
        {
          "_id": "67b41a72a38d04cc6148d80f",
          "name": "Michele Wang",
          "hidden": false
        },
        {
          "_id": "67b41a72a38d04cc6148d810",
          "name": "Tejal Patwardhan",
          "hidden": false
        },
        {
          "_id": "67b41a72a38d04cc6148d811",
          "name": "Johannes Heidecke",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-17T18:41:16.000Z",
      "title": "SWE-Lancer: ¿Los FRONTEND LLMs podrán ganar 1 millón de dólares como profesionales de software de forma independiente?",
      "summary": "Introducimos SWE-Lancer. Este estándar consta de más de 1,400 tareas gratuitas de software ingeniería disponibles en Upwork. La compensación total real de esta colección de tareas es de un millón de dólares. SWE-Lancer está compuesto por tareas de ingeniería independiente y tareas de gestión. Las tareas independientes incluyen un amplio rango de actividades, desde la corrección de 50 errores hasta la implementación de funciones con un valor de 32,000 dólares. Las tareas de gestión se centran en la selección entre propuestas técnicas de implementación. Las tareas independientes son evaluadas por experienciados ingenieros de software que han pasado por tres pruebas de testing end-to-end. Las decisiones de gestión se evalúan comparandolas con las elecciones de los gerentes de ingeniería empleados originalmente. Se evaluó el rendimiento del modelo y se descubrió que el modelo frontera no puede resolver la mayoría de las tareas. Para futuras investigaciones, publicamos en código abierto la imagen Docker integrada y la división de evaluación pública de SWE-Lancer diamante (https://github.com/openai/SWELancer-Benchmark). Mapeamos el rendimiento del modelo a la valoración económica, y aporamos la expansión de la investigación sobre el impacto económico de la desarrollo de modelos de IA con SWE-Lancer.",
      "upvotes": 9,
      "discussionId": "67b41a74a38d04cc6148d84b"
    },
    "publishedAt": "2025-02-18T00:28:31.293Z",
    "title": "SWE-Lancer: Can Frontier LLMs Earn $1 Million from Real-World Freelance Software Engineering?",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.12115.png",
    "numComments": 3,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 6128
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.12148",
      "authors": [
        {
          "_id": "67b40c8cdb88dfd19ab917f3",
          "name": "Ling Yang",
          "hidden": false
        },
        {
          "_id": "67b40c8cdb88dfd19ab917f4",
          "user": {
            "_id": "653e5d31ffd60206c8b64bb5",
            "avatarUrl": "/avatars/5076795722ec1f9e031654f301d30e8f.svg",
            "isPro": false,
            "fullname": "Xinchen Zhang",
            "user": "comin",
            "type": "user"
          },
          "name": "Xinchen Zhang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-18T09:31:31.841Z",
          "hidden": false
        },
        {
          "_id": "67b40c8cdb88dfd19ab917f5",
          "name": "Ye Tian",
          "hidden": false
        },
        {
          "_id": "67b40c8cdb88dfd19ab917f6",
          "name": "Chenming Shang",
          "hidden": false
        },
        {
          "_id": "67b40c8cdb88dfd19ab917f7",
          "name": "Minghao Xu",
          "hidden": false
        },
        {
          "_id": "67b40c8cdb88dfd19ab917f8",
          "name": "Wentao Zhang",
          "hidden": false
        },
        {
          "_id": "67b40c8cdb88dfd19ab917f9",
          "name": "Bin Cui",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-17T18:57:51.000Z",
      "title": "\"Herimas Flow: El método de cerrar la distancia infinitamente entre comprensión y generación\"",
      "summary": "El gran éxito de los modelos de gramática seguida ha llevado a un claro desarrollo en los modelos de lenguaje multimodal de alto nivel (MLLMs). Modelos como Show-o, Transfusion, Emu3 han logrado un desarrollo sorprendente, recibiendo especial atención en la comprensión y generación de imágenes. Primero, se ha descubierto que la capacidad de comprensión de los MLLMs es generalmente mucho más fuerte que su capacidad de generación. Desde esta perspectiva, se propone un simple y general framework llamado HermesFlow. Este framework tiene como objetivo facilitar la conexión entre la comprensión y la generación. En particular, utilizando el mismo conjunto de datos, se extrae información con la misma inclinación tanto para la comprensión como para la generación, y se ajusta la comprensión y generación multimodal apropiadamente utilizando Pair-DPO y juegos de auto-entrenamiento con datos de la misma inclinación. Los experimentos extendidos muestran claramente la ventaja de nuestro enfoque frente a los métodos existentes, especialmente en la reducción del gap entre la comprensión y la generación multimodal. Estos hallazgos revelan la posibilidad de que HermesFlow pueda ser un framework general para ajuste de los próximos modelos fundamentales de lenguaje multimodal. Código: https://github.com/Gen-Verse/HermesFlow",
      "upvotes": 9,
      "discussionId": "67b40c8edb88dfd19ab9183f"
    },
    "publishedAt": "2025-02-17T23:29:29.396Z",
    "title": "HermesFlow: Seamlessly Closing the Gap in Multimodal Understanding and Generation",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.12148.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "653e5d31ffd60206c8b64bb5",
      "avatarUrl": "/avatars/5076795722ec1f9e031654f301d30e8f.svg",
      "fullname": "Xinchen Zhang",
      "name": "comin",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 13
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.11167",
      "authors": [
        {
          "_id": "67b4221bbc387d2eda6f8637",
          "user": {
            "_id": "650267e7e751d03da933a24a",
            "avatarUrl": "/avatars/f047a047d1de304cd97027463541bdf3.svg",
            "isPro": false,
            "fullname": "Bohan22",
            "user": "Bohan22",
            "type": "user"
          },
          "name": "Bohan Lyu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-18T09:31:06.388Z",
          "hidden": false
        },
        {
          "_id": "67b4221bbc387d2eda6f8638",
          "name": "Siqiao Huang",
          "hidden": false
        },
        {
          "_id": "67b4221bbc387d2eda6f8639",
          "user": {
            "_id": "67286718746a95c09d04cb1d",
            "avatarUrl": "/avatars/317efa8459cca08c2ff56c3ab116e15c.svg",
            "isPro": false,
            "fullname": "Zichen Liang",
            "user": "zcliang22",
            "type": "user"
          },
          "name": "Zichen Liang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-18T09:31:08.469Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-16T15:38:19.000Z",
      "title": "SURGE: La posibilidad de hacer que funcionen las funciones de ejecución de código generales de los modelos de lenguaje de gran escala",
      "summary": "Los grandes modelos de lenguaje (LLMs) muestran una excelente capacidad en tareas relacionadas con el código, como la comprensión y la generación de código. Sin embargo, una investigación sistemática sobre su potencial como ayudantes generales para la ejecución de código ha sido insuficiente. Para abordar esta cuestión, se introduce SURGE, un marco de referencia detallado. SURGE está constituido por 8 puntos clave: tareas de programación multilenguaje, problemas de programación del nivel de competencia, análisis de códigos a nivel de repositorio, cálculo científico de alto costo, algoritmos con alta complejidad en tiempo, análisis de códigos con errores, programas que dependen de un compilador o entorno de ejecución específico, y la verificación de demostraciones matemáticas formales. Se evaluan en SURGE múltiples modelos de lenguaje de código abierto y propietario, y se realizan estudios de escalabilidad analizando el impacto del tamaño del modelo y del conjunto de datos de entrenamiento. Además, se clasifican los errores de predicción del modelo y se exploran áreas que pueden ser mejoradas. Nuestros hallazgos muestran que LLMs pueden predecir resultados de ejecución de código en ciertas situaciones. Sin embargo, se han identificado deficiencias en su funcionalidad como ejecutadores generales de código. Esta investigación ofrece una perspectiva empírica sobre la posibilidad de reemplazar a los ejecutadores de código con LLMs. Los códigos y datasets están disponibles en https://github.com/Imbernoulli/SURGE.",
      "upvotes": 7,
      "discussionId": "67b4221ebc387d2eda6f8717"
    },
    "publishedAt": "2025-02-18T01:01:24.331Z",
    "title": "SURGE: On the Potential of Large Language Models as General-Purpose Surrogate Code Executors",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.11167.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "650267e7e751d03da933a24a",
      "avatarUrl": "/avatars/f047a047d1de304cd97027463541bdf3.svg",
      "fullname": "Bohan22",
      "name": "Bohan22",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.12146",
      "authors": [
        {
          "_id": "67b40ce4d3c5f50aa9b71df5",
          "name": "Ye Tian",
          "hidden": false
        },
        {
          "_id": "67b40ce4d3c5f50aa9b71df6",
          "name": "Ling Yang",
          "hidden": false
        },
        {
          "_id": "67b40ce4d3c5f50aa9b71df7",
          "user": {
            "_id": "653e5d31ffd60206c8b64bb5",
            "avatarUrl": "/avatars/5076795722ec1f9e031654f301d30e8f.svg",
            "isPro": false,
            "fullname": "Xinchen Zhang",
            "user": "comin",
            "type": "user"
          },
          "name": "Xinchen Zhang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-18T09:31:29.697Z",
          "hidden": false
        },
        {
          "_id": "67b40ce4d3c5f50aa9b71df8",
          "name": "Yunhai Tong",
          "hidden": false
        },
        {
          "_id": "67b40ce4d3c5f50aa9b71df9",
          "name": "Mengdi Wang",
          "hidden": false
        },
        {
          "_id": "67b40ce4d3c5f50aa9b71dfa",
          "name": "Bin Cui",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-17T18:57:26.000Z",
      "title": "Difusión Sharpening: Ajuste de ruido en la difusión de modelos de difusión\n\n(Tenga en cuenta que, aunque el traducción se esfuerza por ser precisa, puede haber pequeñas diferencias en la expresión de términos técnicos, que dependen del contexto y de los términos comunes dentro del campo.)",
      "summary": "Propongo la técnica de Difusión-Sharpening. Esta es un enfoque de ajuste micro para optimizar el proyecto de la proceso de muestreo y mejorar la disposición en la parte inferior. Los métodos actuales de ajuste micro basados en RL se centran en un solo paso de entrenamiento, superando el disposición a nivel de proyecto, pero los últimos métodos de optimización de proyectos de muestreo sufren de un costo de NFE de inferencia excesivo. La Difusión-Sharpening utiliza un marco de integración paso a paso para elegir el mejor proyecto durante el entrenamiento y utiliza retroalimentación de recompensas para superar los costos de inferencia. Nuestro método muestra una eficiencia de inferencia óptima sin necesidad de adicionales NFE, demostrando una eficiencia de aprendizaje y un rápido convergencia. Los experimentos extendidos muestran resultados superiores a los métodos de ajuste micro basados en RL (por ejemplo, Diffusion-DPO) y a los métodos de optimización de proyectos de muestreo (por ejemplo, escalado de inferencia) mediante métricas variadas, como el arranque de texto, la capacidad de configuración y las preferencias humanas. Código: https://github.com/Gen-Verse/Diffusion-Sharpening",
      "upvotes": 6,
      "discussionId": "67b40ce8d3c5f50aa9b71f9a"
    },
    "publishedAt": "2025-02-17T23:30:53.097Z",
    "title": "Diffusion-Sharpening: Fine-tuning Diffusion Models with Denoising Trajectory Sharpening",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.12146.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "653e5d31ffd60206c8b64bb5",
      "avatarUrl": "/avatars/5076795722ec1f9e031654f301d30e8f.svg",
      "fullname": "Xinchen Zhang",
      "name": "comin",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 13
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.10458",
      "authors": [
        {
          "_id": "67b3ea0f4dd7ea0538ce589d",
          "user": {
            "_id": "6354bda206d707b33249c4c2",
            "avatarUrl": "/avatars/bbd9f76274ac52214df92084d50bc7b5.svg",
            "isPro": false,
            "fullname": "Zhenxing Mi",
            "user": "Mifucius",
            "type": "user"
          },
          "name": "Zhenxing Mi",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-18T09:31:52.837Z",
          "hidden": false
        },
        {
          "_id": "67b3ea0f4dd7ea0538ce589e",
          "name": "Kuan-Chieh Wang",
          "hidden": false
        },
        {
          "_id": "67b3ea0f4dd7ea0538ce589f",
          "name": "Guocheng Qian",
          "hidden": false
        },
        {
          "_id": "67b3ea0f4dd7ea0538ce58a0",
          "name": "Hanrong Ye",
          "hidden": false
        },
        {
          "_id": "67b3ea0f4dd7ea0538ce58a1",
          "name": "Runtao Liu",
          "hidden": false
        },
        {
          "_id": "67b3ea0f4dd7ea0538ce58a2",
          "name": "Sergey Tulyakov",
          "hidden": false
        },
        {
          "_id": "67b3ea0f4dd7ea0538ce58a3",
          "name": "Kfir Aberman",
          "hidden": false
        },
        {
          "_id": "67b3ea0f4dd7ea0538ce58a4",
          "name": "Dan Xu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-12T05:30:08.000Z",
      "title": "「Recuerda y difundia eso: teoría de razones para casos individuales en modelos de difusión」",
      "summary": "En este artículo se presenta un nuevo paradigma de alineamiento denominado ThinkDiff. Este paradigma integra las fortalezas de los modelos de lenguaje visual (VLMs) para proporcionar a los modelos de difusión de imágenes desde texto una variedad de entendimientos de contexto y capacidades de inferencia. Los métodos actuales de ajuste para diferentes tipos de difusión se centran principalmente en la reconstrucción de píxeles, pero no en la inferencia de contexto, lo cual está limitado por la complejidad y la restricción de los conjuntos de datos de inferencia. ThinkDiff aborda estas desafíos al utilizar la entrenamiento visual como tarea falsa y al alinear los decodificadores de VLMs y grandes modelos de lenguaje (LLM). Esta tarea falsa permite que el decodificador de LLM observe que el espacio de características de entrada se comparta con el espacio de la codificación de LLM, lo que facilita la alineación de VLMs y decodificadores de difusión. Esto requiere menos entrenamiento complejo o conjuntos de datos, permitiendo que ThinkDiff desarrolle eficazmente habilidades de comprensión, inferencia y constitución. Los experimentos en el marco de CoBSAT mejoraron significativamente la precisión, del 19.2% al 46.3%, y se logró entrenar en 4 GPUs A100 durante 5 horas. Además, ThinkDiff muestra excelentes resultados en la configuración de imágenes y textos en forma lógicamente coherente. Página del proyecto: https://mizhenxing.github.io/ThinkDiff.",
      "upvotes": 5,
      "discussionId": "67b3ea124dd7ea0538ce592d"
    },
    "publishedAt": "2025-02-18T04:33:41.120Z",
    "title": "I Think, Therefore I Diffuse: Enabling Multimodal In-Context Reasoning in Diffusion Models",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.10458.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6354bda206d707b33249c4c2",
      "avatarUrl": "/avatars/bbd9f76274ac52214df92084d50bc7b5.svg",
      "fullname": "Zhenxing Mi",
      "name": "Mifucius",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.11196",
      "authors": [
        {
          "_id": "67b42223c2fe54b8d43efed6",
          "name": "Yixin Ou",
          "hidden": false
        },
        {
          "_id": "67b42223c2fe54b8d43efed7",
          "name": "Yunzhi Yao",
          "hidden": false
        },
        {
          "_id": "67b42223c2fe54b8d43efed8",
          "user": {
            "_id": "620b3bbb0668e435407c8d0a",
            "avatarUrl": "/avatars/e0fccbb2577d76088e09f054c35cffbc.svg",
            "isPro": false,
            "fullname": "Ningyu Zhang",
            "user": "Ningyu",
            "type": "user"
          },
          "name": "Ningyu Zhang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-18T09:31:04.227Z",
          "hidden": false
        },
        {
          "_id": "67b42223c2fe54b8d43efed9",
          "name": "Hui Jin",
          "hidden": false
        },
        {
          "_id": "67b42223c2fe54b8d43efeda",
          "name": "Jiacheng Sun",
          "hidden": false
        },
        {
          "_id": "67b42223c2fe54b8d43efedb",
          "name": "Shumin Deng",
          "hidden": false
        },
        {
          "_id": "67b42223c2fe54b8d43efedc",
          "name": "Zhenguo Li",
          "hidden": false
        },
        {
          "_id": "67b42223c2fe54b8d43efedd",
          "name": "Huajun Chen",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-16T16:55:43.000Z",
      "title": "LLM se pregunta cómo obtiene nuevos conocimientos? Desde la perspectiva del ciclo de conocimiento de aprendizaje de predicción continua.",
      "summary": "Los grandes modelos de lenguaje (LLMs) han mostrado una falta importante en la capacidad de incorporar nuevos conocimientos para tareas de densidad de conocimiento ampliada. En particular, es difícil comprender cómo los conocimientos entrenados están estructuralmente incorporados en la computación neural. Hemos abordado este problema en la evolución de los circuitos de conocimiento, identificando subgráficas computacionales que fomentan la almacenamiento y procesamiento de conocimiento. A través de un análisis sistemático de la evolución de los circuitos, hemos obtenido los siguientes hallazgos cruciales: 1) la adquisición de nuevos conocimientos está influenciada por la conexión con el conocimiento existente; 2) la evolución de los circuitos de conocimiento muestra diferentes etapas desde la formación hasta la optimización; 3) la evolución de los circuitos de conocimiento sigue patrones profundos. Estos puntos proporcionan una comprensión teórica del estructura de la adquisición de nuevos conocimientos en los LLMs y tienen el potencial de mejorar la estrategia de entrenamiento predictivo continuo, lo que puede mejorar el rendimiento del modelo. Los códigos y datos están disponibles en https://github.com/zjunlp/DynamicKnowledgeCircuits.",
      "upvotes": 5,
      "discussionId": "67b42225c2fe54b8d43eff9b"
    },
    "publishedAt": "2025-02-18T01:02:25.236Z",
    "title": "How Do LLMs Acquire New Knowledge? A Knowledge Circuits Perspective on Continual Pre-Training",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/620b3bbb0668e435407c8d0a/_LGnwvwslWc3YDIirfOKS.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.11196.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "620b3bbb0668e435407c8d0a",
      "avatarUrl": "/avatars/e0fccbb2577d76088e09f054c35cffbc.svg",
      "fullname": "Ningyu Zhang",
      "name": "Ningyu",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 17
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.11438",
      "authors": [
        {
          "_id": "67b406993d0f54ab381594f5",
          "name": "Jimin Lee",
          "hidden": false
        },
        {
          "_id": "67b406993d0f54ab381594f6",
          "name": "Ingeol Baek",
          "hidden": false
        },
        {
          "_id": "67b406993d0f54ab381594f7",
          "name": "Byeongjeong Kim",
          "hidden": false
        },
        {
          "_id": "67b406993d0f54ab381594f8",
          "name": "Hwanhee Lee",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-17T04:52:24.000Z",
      "title": "SAFE-SQL: Aprendizaje de retroalimentación en el interior del formato de texto mediante muestreo de píxeles automatizado a partir de texto.",
      "summary": "Text-to-SQL tiene como objetivo convertir preguntas en lenguaje natural en consultas SQL ejecutables. En los métodos anteriores, se utilizaron técnicas como la selección de ejemplos similares y la estructura de mascarado para buscar ejemplos similares y guiar un gran modelo de lenguaje (LLM) para demostrar un rendimiento fuerte. Sin embargo, en escenarios reales y muy populares, se enfrentan dificultades cuando estos ejemplos no existen. Para superar estas limitaciones, proponemos un nuevo marco de trabajo \"Self-Augmentation in-context learning with Fine-grained Example selection for Text-to-SQL (SAFE-SQL)\" para mejorar la generación de SQL en Text-to-SQL. SAFE-SQL genera y filtra ejemplos automaticamente para construir ejemplos de aprendizaje en contexto de alta calidad. Usando estos ejemplos, SAFE-SQL supera a los frameworks de Text-to-SQL previos de 0-shot y few-shot y mejora la precisión de ejecución. En particular, nuestro enfoque proporciona una mejora adicional en escenarios donde el simple método falla con una alta probabilidad y los ejemplos son casi imposibles de encontrar.",
      "upvotes": 5,
      "discussionId": "67b4069a3d0f54ab38159520"
    },
    "publishedAt": "2025-02-17T23:06:03.562Z",
    "title": "SAFE-SQL: Self-Augmented In-Context Learning with Fine-grained Example Selection for Text-to-SQL",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.11438.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "63f6f245e94ed998c46316df",
      "avatarUrl": "/avatars/9c0ec8682d4a85b96d2180602b1bbe6c.svg",
      "fullname": "ingeolbaek",
      "name": "ingeol",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 3
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.09061",
      "authors": [
        {
          "_id": "67b401de3995f28d45c212d6",
          "name": "Debangshu Banerjee",
          "hidden": false
        },
        {
          "_id": "67b401de3995f28d45c212d7",
          "name": "Tarun Suresh",
          "hidden": false
        },
        {
          "_id": "67b401de3995f28d45c212d8",
          "name": "Shubham Ugare",
          "hidden": false
        },
        {
          "_id": "67b401de3995f28d45c212d9",
          "name": "Sasa Misailovic",
          "hidden": false
        },
        {
          "_id": "67b401de3995f28d45c212da",
          "name": "Gagandeep Singh",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-13T08:23:42.000Z",
      "title": "CRANE: Inferencia basada en la generación de LLMs con restricciones",
      "summary": "LLM debe generar salidas que mantengan la sintaxis y precisión semántica en tareas como generación de código, lógica matemática simbólica y otros. Forzar la generación de LLM a seguir lenguajes formales puede reducir su capacidad de pensamiento lógico, ya que esto es un fenómeno común en experimentos. En este estudio, primero se explica teóricamente por qué limitar la salida de un LLM a un lenguaje muy restringido puede disminuir su capacidad de pensamiento lógico. Luego, se propone un enfoque que garantiza la sintaxis y precisión semántica mientras mantiene la capacidad de pensamiento lógico. Basado en estas teorías, se propone un algoritmo de decodificación restringida que fortalece el pensamiento lógico, llamado CRANE. CRANE equilibra la precisión de la generación restringida con la flexibilidad de la generación no restringida, y mejora en un 10% la precisión en los benchmarks difíciles de lógica simbólica como GSM-symbolic y FOLIO en varios códigos abiertos y benchmarks.",
      "upvotes": 4,
      "discussionId": "67b401e03995f28d45c21354"
    },
    "publishedAt": "2025-02-17T22:43:51.555Z",
    "title": "CRANE: Reasoning with constrained LLM generation",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.09061.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "65e7bb35e5e78134ab049942",
      "avatarUrl": "/avatars/3c0972f0d59e51ebb5c218ee736d4458.svg",
      "fullname": "Tarun Suresh",
      "name": "tarsur909",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.11275",
      "authors": [
        {
          "_id": "67b3fa2862838a378b21860d",
          "name": "Letian Peng",
          "hidden": false
        },
        {
          "_id": "67b3fa2862838a378b21860e",
          "name": "Zilong Wang",
          "hidden": false
        },
        {
          "_id": "67b3fa2862838a378b21860f",
          "name": "Feng Yao",
          "hidden": false
        },
        {
          "_id": "67b3fa2862838a378b218610",
          "name": "Jingbo Shang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-16T21:32:20.000Z",
      "title": "Cooker: El antiguo hogar de los grandes redes de computación que dio lugar al nacimiento de los libres de IE LLM",
      "summary": "Los datos de alta calidad y alta demanda, es decir, textos de plantilla para entrenamiento previo y anotaciones después del entrenamiento, están preparados con cuidado y promueven el desarrollo de grandes modelos de lenguaje (LLMs). Además, en la extracción de información (IE), las secuencias con etiquetas BIO como las de datos previos de entrenamiento son difíciles de expandir. Mostramos cómo los modelos de IE pueden actuar libres de recursos de datos de LLM. Concretamente, reconstruimos la siguiente predicción de texto. En particular, el paradigma de extracción de texto propuesto (NTE) transforma 102.6M de datos de extracción a partir de datos de entrenamiento previo y de datos después del entrenamiento para entrenar diferentes modelos de IE como Cuckoo. En escenarios de pocos ejemplos, Cuckoo aplica mejores resultados que los modelos de IE basados en comandos complejos, comparados con modelos de IE previamente entrenados. Naturalmente, Cuckoo evoluciona junto con la mejora en la preparación de datos de LLM, beneficiando así la mejora de la cadena de trabajo de entrenamiento de LLM. No se necesita ningún esfuerzo manual adicional.",
      "upvotes": 4,
      "discussionId": "67b3fa2962838a378b21867b"
    },
    "publishedAt": "2025-02-17T22:10:49.900Z",
    "title": "Cuckoo: An IE Free Rider Hatched by Massive Nutrition in LLM's Nest",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.11275.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64323dd503d81fa4d26deaf9",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64323dd503d81fa4d26deaf9/x3ES8VXEZJljxDWvFWaAf.png",
      "fullname": "Letian Peng",
      "name": "KomeijiForce",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 7
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.11901",
      "authors": [
        {
          "_id": "67b3f8cc1bfe04e82830b752",
          "name": "Dylan Zhang",
          "hidden": false
        },
        {
          "_id": "67b3f8cc1bfe04e82830b753",
          "name": "Justin Wang",
          "hidden": false
        },
        {
          "_id": "67b3f8cc1bfe04e82830b754",
          "name": "Tianran Sun",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-17T15:24:11.000Z",
      "title": "El desarrollo de un programador dedicado a la orientación de pruebas con el 64% de la posición en respuesta a la falta de datos.",
      "summary": "Los actuales modelos de lenguaje (LM) enfrentan problemas debido a la falta de datos en programación basada en pruebas, lo cual se reduce a dos puntos principales.",
      "upvotes": 3,
      "discussionId": "67b3f8cd1bfe04e82830b77f"
    },
    "publishedAt": "2025-02-17T22:05:54.047Z",
    "title": "Building A Proof-Oriented Programmer That Is 64% Better Than GPT-4o Under Data Scarsity",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.11901.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "642b8add48f67b6f21d4eb20",
      "avatarUrl": "/avatars/f15025b39248daa19a18e6ccb2eaaa0c.svg",
      "fullname": "Dylan",
      "name": "shizhuo2",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.12054",
      "authors": [
        {
          "_id": "67b44a6888813676da9f8239",
          "name": "Xinyu Zhang",
          "hidden": false
        },
        {
          "_id": "67b44a6888813676da9f823a",
          "name": "Yuxuan Dong",
          "hidden": false
        },
        {
          "_id": "67b44a6888813676da9f823b",
          "name": "Yanrui Wu",
          "hidden": false
        },
        {
          "_id": "67b44a6888813676da9f823c",
          "name": "Jiaxing Huang",
          "hidden": false
        },
        {
          "_id": "67b44a6888813676da9f823d",
          "user": {
            "_id": "6602548a68d519ed324b47c5",
            "avatarUrl": "/avatars/5ab411f87440cc2a98c7a1c6a3ed5548.svg",
            "isPro": false,
            "fullname": "ChengyouJia",
            "user": "ChengyouJia",
            "type": "user"
          },
          "name": "Chengyou Jia",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-18T09:30:47.313Z",
          "hidden": false
        },
        {
          "_id": "67b44a6888813676da9f823e",
          "name": "Basura Fernando",
          "hidden": false
        },
        {
          "_id": "67b44a6888813676da9f823f",
          "name": "Mike Zheng Shou",
          "hidden": false
        },
        {
          "_id": "67b44a6888813676da9f8240",
          "name": "Lingling Zhang",
          "hidden": false
        },
        {
          "_id": "67b44a6888813676da9f8241",
          "name": "Jun Liu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-17T17:24:14.000Z",
      "title": "Física: Base física del razonamiento fundamental",
      "summary": "Los modelos de lenguaje de alto nivel muestran capacidades especializadas en matemáticas o inferencia lógica, pero los evaluaciones actuales superan la lógica física. La lógica física es un trabajo complejo que exige teoremas y restricciones de la física. Proponemos un marco de evaluación llamado \"PhysReason\", que incluye 1,200 problemas que combinan problemas basados en conocimiento (25%) y problemas basados en lógica (75%). Los problemas basados en lógica se pueden clasificar en tres niveles de dificultad: fácil, intermedio y difícil. En particular, los problemas requieren, en promedio, 8.1 pasos para resolverlos, mientras que los más difíciles requieren 15.6 pasos, reflejando la complejidad de la lógica física. Proponemos un marco de evaluación automático para respuestas físicas que incluye evaluaciones detalladas de nivel de respuesta y configuración. Modelos excelentes como Deepseek-R1, Gemini-2.0-Flash-Thinking y o3-mini-high alcanzan menos del 60% en la evaluación de nivel de respuesta, y su rendimiento decae desde problemas de conocimiento (75.11%) hasta problemas difíciles (31.95%). A través de la evaluación de nivel de pasos, hemos identificado cuatro keywords clave: aplicación de teoremas de física, comprensión de procesos físicos, cálculos y análisis de condiciones físicas. Estos hallazgos establecen el papel de \"PhysReason\" como un nuevo y integral marco de evaluación para la capacidad de lógica física. Nuestro código y datos están disponibles en https://dxzxy12138.github.io/PhysReason.",
      "upvotes": 2,
      "discussionId": "67b44a6988813676da9f82d0"
    },
    "publishedAt": "2025-02-18T03:53:47.570Z",
    "title": "PhysReason: A Comprehensive Benchmark towards Physics-Based Reasoning",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.12054.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6602548a68d519ed324b47c5",
      "avatarUrl": "/avatars/5ab411f87440cc2a98c7a1c6a3ed5548.svg",
      "fullname": "ChengyouJia",
      "name": "ChengyouJia",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 3
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.11330",
      "authors": [
        {
          "_id": "67b42c5632929e97a92dee90",
          "name": "Minbyul Jeong",
          "hidden": false
        },
        {
          "_id": "67b42c5632929e97a92dee91",
          "name": "Jungho Cho",
          "hidden": false
        },
        {
          "_id": "67b42c5632929e97a92dee92",
          "name": "Minsoo Khang",
          "hidden": false
        },
        {
          "_id": "67b42c5632929e97a92dee93",
          "name": "Dawoon Jung",
          "hidden": false
        },
        {
          "_id": "67b42c5632929e97a92dee94",
          "name": "Teakgyu Hong",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-17T01:05:31.000Z",
      "title": "Utilización de modelos abierto-código para la generación de mensajes de sistema basada en las preferencias del usuario",
      "summary": "Los mensajes de sistema desempeñan un papel crucial en la interacción con modelos de lenguaje grande escala (LLM). Estos mensajes se utilizan para iniciar conversaciones, permiten a los usuarios realizar tareas específicas, determinan las acciones y incluyen información de contexto. Además, pueden especificar el formato de salida y el estilo de comunicación. Esta diversidad es añadida porque los datos públicos, que son casi inexistentes, están limitados por estrictas restricciones de licencia. Automaticamente etiquetar los mensajes de sistema en los datos públicos para que los usuarios los generen de manera que deseen es un proceso que requiere significativas recursos. Para resolver estos problemas, nuestro estudio introdujo una pipeline para generar mensajes de sistema llamada \"SysGen\". Este pipeline permite generar mensajes de sistema a partir de conjuntos de datos que no incluyen mensajes de sistema, y utilizando mensajes de sistema generados a partir de conjuntos de datos de características subconjunto, obtener respuestas más adecuadas de asistentes. El entrenamiento con datos de SysGen mejoró significativamente la coincidencia entre las respuestas del modelo, los mensajes de sistema y las instrucciones del usuario en los benchmarks multifacet, y tuvo un impacto mínimo en otros benchmarks no vistos (por ejemplo, Open LLM Leaderboard). Nuestra análisis cualitativo destaca la importancia de diferentes mensajes de sistema para garantizar una mejor adaptación en diferentes contextos.",
      "upvotes": 2,
      "discussionId": "67b42c5732929e97a92deed7"
    },
    "publishedAt": "2025-02-18T01:45:36.359Z",
    "title": "System Message Generation for User Preferences using Open-Source Models",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.11330.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64587be872b60ae7a3817858",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64587be872b60ae7a3817858/BbdOOxOCEzWTvEpkWp8MM.png",
      "fullname": "Minbyul Jeong",
      "name": "Minbyul",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 3
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.09083",
      "authors": [
        {
          "_id": "67b30726d4665a0448e6436d",
          "user": {
            "_id": "6698cffdb2ebada9f4a7e7d7",
            "avatarUrl": "/avatars/e66d946c14595d3b008185f2be8d2f57.svg",
            "isPro": false,
            "fullname": "Greta Warren",
            "user": "gretawarren",
            "type": "user"
          },
          "name": "Greta Warren",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-18T09:32:34.585Z",
          "hidden": false
        },
        {
          "_id": "67b30726d4665a0448e6436e",
          "name": "Irina Shklovski",
          "hidden": false
        },
        {
          "_id": "67b30726d4665a0448e6436f",
          "name": "Isabelle Augenstein",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-13T08:56:25.000Z",
      "title": "「Demuestra cómo funciona: Problemas de verificación automática de hechos explicables」",
      "summary": "Los lenguajes de programación y el AI generativo han expandido ampliamente en los medios online, lo que ha llevado a un aumento de la inseguridad y la complejidad, y a la necesidad de un efectivo sistema de verificación de la verdad. Debido a las características complejas de la verificación de la verdad, es crucial que los sistemas de verificación de la verdad proporcionen explicaciones a los verificadores de la verdad para que puedan revisar los resultados. Sin embargo, estas explicaciones no están claras sobre cómo se integran mejor en la función de decisión y el proceso lógico de los verificadores de la verdad. A través de entrevistas no estructuradas con expertos en verificación de la verdad, hemos podido identificar los siguientes puntos que necesitan mejora: (i) la manera en que los verificadores de la verdad evalúan la evidencia y toman decisiones, explicando el proceso; (ii) cómo los verificadores de la verdad realmente utilizan las herramientas automáticas; (iii) las explicaciones que deben proporcionar los sistemas de verificación de la verdad a los verificadores de la verdad. Estos resultados demuestran la necesidad de mejoras en las explicaciones y establecen importantes criterios para las explicaciones de la verificación de la verdad iterativa, mostrando cómo se pueden cambiar las razones del modelo, referirse a evidencias específicas, y mostrar cómo las incertidumbres y faltas de información son características particulares de la verificación de la verdad.",
      "upvotes": 1,
      "discussionId": "67b30727d4665a0448e6438d"
    },
    "publishedAt": "2025-02-18T04:37:21.573Z",
    "title": "Show Me the Work: Fact-Checkers' Requirements for Explainable Automated Fact-Checking",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/6698cffdb2ebada9f4a7e7d7/55xAEeg9Xsk87DXHTH9gM.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.09083.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6698cffdb2ebada9f4a7e7d7",
      "avatarUrl": "/avatars/e66d946c14595d3b008185f2be8d2f57.svg",
      "fullname": "Greta Warren",
      "name": "gretawarren",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.12135",
      "authors": [
        {
          "_id": "67b4028237db78705fb256e1",
          "user": {
            "_id": "64fb31a34c8924c4fe7498bc",
            "avatarUrl": "/avatars/6c8e4a66e1b8b3c786a4000210089392.svg",
            "isPro": false,
            "fullname": "Chaoyue Song",
            "user": "chaoyue7",
            "type": "user"
          },
          "name": "Chaoyue Song",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-18T09:31:40.771Z",
          "hidden": false
        },
        {
          "_id": "67b4028237db78705fb256e2",
          "name": "Jianfeng Zhang",
          "hidden": false
        },
        {
          "_id": "67b4028237db78705fb256e3",
          "name": "Xiu Li",
          "hidden": false
        },
        {
          "_id": "67b4028237db78705fb256e4",
          "name": "Fan Yang",
          "hidden": false
        },
        {
          "_id": "67b4028237db78705fb256e5",
          "name": "Yiwen Chen",
          "hidden": false
        },
        {
          "_id": "67b4028237db78705fb256e6",
          "name": "Zhongcong Xu",
          "hidden": false
        },
        {
          "_id": "67b4028237db78705fb256e7",
          "name": "Jun Hao Liew",
          "hidden": false
        },
        {
          "_id": "67b4028237db78705fb256e8",
          "name": "Xiaoyang Guo",
          "hidden": false
        },
        {
          "_id": "67b4028237db78705fb256e9",
          "name": "Fayao Liu",
          "hidden": false
        },
        {
          "_id": "67b4028237db78705fb256ea",
          "name": "Jiashi Feng",
          "hidden": false
        },
        {
          "_id": "67b4028237db78705fb256eb",
          "name": "Guosheng Lin",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-17T18:53:27.000Z",
      "title": "MagicArticulate: Se está preparando la arquitectura del modelo 3D.",
      "summary": "El crecimiento explosivo del contenido 3D ha llevado a un aumento en la demanda de convertir versiones de modelos 3D estáticos en articulaciones dinámicas de manera automática. Los enfoques tradicionales requieren más tiempo y trabajo debido a la anotación automática y la falta de marcos de referencia de gran escala ha impidido el desarrollo de soluciones basadas en aprendizaje. En este artículo, se propone el framework efectivo MagicArticulate para realizar la conversión automática de modelos 3D estáticos a versiones con articulaciones dinámicas. Nuestras principales contribuciones son tres: primero, se propone el marco de referencia Articulation-XL, que selecciona 3D modelos con más de 33,000 anotaciones de alta calidad de articulación; segundo, se propone un nuevo método de generación de escenarios para abordar el problema de modelado secuencial, utilizando un motor de conversión de colaboración automática para manejar la variación en el número de esqueletos o articulaciones y las relaciones específicas entre modelos 3D; y finalmente, se utiliza un proceso de dispersión funcional que incluye cálculos de distancia geométrica para predecir los pesos de texturización. Los experimentos extensos muestran que MagicArticulate supera significativamente los métodos actuales, permitiendo la realización de altas calidades de articulación y la creación de animaciones prácticas. Página del proyecto: https://chaoyuesong.github.io/MagicArticulate.",
      "upvotes": 1,
      "discussionId": "67b4028437db78705fb25726"
    },
    "publishedAt": "2025-02-18T04:34:15.786Z",
    "title": "MagicArticulate: Make Your 3D Models Articulation-Ready",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.12135.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64fb31a34c8924c4fe7498bc",
      "avatarUrl": "/avatars/6c8e4a66e1b8b3c786a4000210089392.svg",
      "fullname": "Chaoyue Song",
      "name": "chaoyue7",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.11831",
      "authors": [
        {
          "_id": "67b450cf315f7b69956df3d6",
          "name": "Quentin Garrido",
          "hidden": false
        },
        {
          "_id": "67b450cf315f7b69956df3d7",
          "name": "Nicolas Ballas",
          "hidden": false
        },
        {
          "_id": "67b450cf315f7b69956df3d8",
          "name": "Mahmoud Assran",
          "hidden": false
        },
        {
          "_id": "67b450cf315f7b69956df3d9",
          "name": "Adrien Bardes",
          "hidden": false
        },
        {
          "_id": "67b450cf315f7b69956df3da",
          "name": "Laurent Najman",
          "hidden": false
        },
        {
          "_id": "67b450cf315f7b69956df3db",
          "name": "Michael Rabbat",
          "hidden": false
        },
        {
          "_id": "67b450cf315f7b69956df3dc",
          "name": "Emmanuel Dupoux",
          "hidden": false
        },
        {
          "_id": "67b450cf315f7b69956df3dd",
          "name": "Yann LeCun",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-17T14:27:14.000Z",
      "title": "Intuición física se desarrolla a través del aprendizaje previo de reglas naturales en videos de la naturaleza.",
      "summary": "Estamos investigando la aparición del reconocimiento físico intuitivo utilizando un modelo de red neuronal profunda general para predecir regiones ocultas en películas naturales. Un modelo que predice resultados en un espacio de representación aprendida mediante el marco de trabajo de destrucción de expectativas ha descubierto la comprensión de características físicas intuitivas como la identidad y la consistencia de forma de objetos. Por otro lado, modelos de lenguaje de diferentes escalas que buscan razones a través de predicciones de imágenes y texto alcanzan rendimientos cercanos. Al comparar estas arquitecturas, se destaca que el aprendizaje de espacios de representación abstractos, mientras predecimos codificaciones, permite obtener el reconocimiento físico intuitivo. También se encuentra que modelos entrenados en películas personales alcanzan un rendimiento superior a la de la fortuna. Esto plantea la idea de que el conocimiento esencial (un sistema genético dependiente para entender el mundo) es necesario para comprender el reconocimiento físico intuitivo.",
      "upvotes": 1,
      "discussionId": "67b450d0315f7b69956df3f9"
    },
    "publishedAt": "2025-02-18T04:20:25.916Z",
    "title": "Intuitive physics understanding emerges from self-supervised pretraining on natural videos",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.11831.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "5f1158120c833276f61f1a84",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1608042047613-5f1158120c833276f61f1a84.jpeg",
      "fullname": "Niels Rogge",
      "name": "nielsr",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 763
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.11085",
      "authors": [
        {
          "_id": "67b44f44620ae0bad17d6699",
          "name": "Yasir Ghunaim",
          "hidden": false
        },
        {
          "_id": "67b44f44620ae0bad17d669a",
          "user": {
            "_id": "642b51385bf2355d02a23d15",
            "avatarUrl": "/avatars/87985347643b2647555f2453fa4d94fb.svg",
            "isPro": true,
            "fullname": "Hasan Abed Al Kader Hammoud",
            "user": "hammh0a",
            "type": "user"
          },
          "name": "Hasan Abed Al Kader Hammoud",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-18T09:30:43.057Z",
          "hidden": false
        },
        {
          "_id": "67b44f44620ae0bad17d669b",
          "name": "Bernard Ghanem",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-16T11:46:23.000Z",
      "title": "Predicción de características de átomos mediante aprendizaje previo para optimizar la eficiencia de datos",
      "summary": "Este artículo desafía el último paradigma para predecir las propiedades de los materiales átomicos. Este paradigma se relaciona con el desarrollo, el tamaño y la cantidad de datos y los recursos computacionales. Mostramos que, al elegir un conjunto de datos adecuado, se puede sobrepasar el aprendizaje previo a gran escala, reduciendo los costos de computación en un 1/24. Aplicamos un nuevo índice basado en la Fréchet Inception Distance de la visión computacional, llamado CSI (Índice de Similaridad Química), a grafos moleculares para cuantificar la coincidencia entre conjuntos de datos de aprendizaje previo y tareas posteriores. Al seleccionar el conjunto de datos con la mayor relevancia, el modelo de aprendizaje previo realizado en pequeños conjuntos de datos puede superar experiencialmente a los modelos de aprendizaje previo en conjuntos de datos mixtos grandes (por ejemplo, JMP). Por otro lado, la adición de datos irrelevantes puede deteriorar el rendimiento del modelo. Nuestro hallazgo demuestra que la pregunta sobre el aprendizaje previo en la predicción de las propiedades de los materiales átomicos es más valiosa que la cantidad de datos.",
      "upvotes": 1,
      "discussionId": "67b44f45620ae0bad17d66b0"
    },
    "publishedAt": "2025-02-18T04:16:28.219Z",
    "title": "Towards Data-Efficient Pretraining for Atomic Property Prediction",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/642b51385bf2355d02a23d15/bLvTbh56AkUmcmRst8mT3.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.11085.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "642b51385bf2355d02a23d15",
      "avatarUrl": "/avatars/87985347643b2647555f2453fa4d94fb.svg",
      "fullname": "Hasan Abed Al Kader Hammoud",
      "name": "hammh0a",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isMod": false,
      "followerCount": 4
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.11775",
      "authors": [
        {
          "_id": "67b4147f7721b4fe4d2bd466",
          "name": "Guangzhi Sun",
          "hidden": false
        },
        {
          "_id": "67b4147f7721b4fe4d2bd467",
          "name": "Yudong Yang",
          "hidden": false
        },
        {
          "_id": "67b4147f7721b4fe4d2bd468",
          "name": "Jimin Zhuang",
          "hidden": false
        },
        {
          "_id": "67b4147f7721b4fe4d2bd469",
          "name": "Changli Tang",
          "hidden": false
        },
        {
          "_id": "67b4147f7721b4fe4d2bd46a",
          "name": "Yixuan Li",
          "hidden": false
        },
        {
          "_id": "67b4147f7721b4fe4d2bd46b",
          "name": "Wei Li",
          "hidden": false
        },
        {
          "_id": "67b4147f7721b4fe4d2bd46c",
          "name": "Zejun MA",
          "hidden": false
        },
        {
          "_id": "67b4147f7721b4fe4d2bd46d",
          "name": "Chao Zhang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-17T13:07:40.000Z",
      "title": "video-SALMONN-o1: Fuerte motivación para el modelo de video audio multilingüe",
      "summary": "El progreso de la optimización de razonamiento en modelos de lenguaje grandes (LLMs) ha considerablemente aumentado las capacidades de estos modelos, pero actualmente, los esfuerzos se centran en la resolución de problemas matemáticos y en la entrada gráfica visual, sin prestar mucha atención a las amplias aplicaciones de la comprensión general de videos. En este trabajo, proponemos el primer modelo de lenguaje abierto de código (open-source) que fortalece el razonamiento en tareas de comprensión de videos generales. Se denomina a este modelo video-SALMONN-o1. Para mejorar su capacidad de razonamiento, desarrollamos un conjunto de datos que tiene características de resolución paso a paso, incluyendo videos de voz complejos. Además, proponemos un proceso de optimización directa de preferencias de pasos (pDPO) que utiliza una selección relativamente estricta de pasos, y implementamos un modelo de recompensa del nivel de pasos que es eficiente en adaptarse a diferentes entradas. También introducimos RivaBench, un marco de evaluación de comprensión de videos que fortalece el razonamiento, que contiene más de 4,000 pares de preguntas y respuestas de alta calidad y editadas por expertos, abordando escenarios como comedias de estudio, discursos académicos y detección de videos sintéticos. Video-SALMONN-o1 logró un aumento de precisión del 3-8% en diferentes marcos de evaluación de razonamiento de videos, comparado con LLaVA-OneVision. Además, pDPO logró un aumento del 6-8% en el modelo de ajuste de subobjetos de RivaBench. La mejora en el razonamiento permitió que video-SALMONN-o1 realice la capacidad de detección de videos sintéticos en 0 shot.",
      "upvotes": 1,
      "discussionId": "67b414827721b4fe4d2bd534"
    },
    "publishedAt": "2025-02-18T00:06:55.671Z",
    "title": "video-SALMONN-o1: Reasoning-enhanced Audio-visual Large Language Model",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.11775.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 6128
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.11098",
      "authors": [
        {
          "_id": "67b411e45e634139c0d86a1e",
          "name": "Zhao Wang",
          "hidden": false
        },
        {
          "_id": "67b411e45e634139c0d86a1f",
          "name": "Sota Moriyama",
          "hidden": false
        },
        {
          "_id": "67b411e45e634139c0d86a20",
          "name": "Wei-Yao Wang",
          "hidden": false
        },
        {
          "_id": "67b411e45e634139c0d86a21",
          "name": "Briti Gangopadhyay",
          "hidden": false
        },
        {
          "_id": "67b411e45e634139c0d86a22",
          "name": "Shingo Takamatsu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-16T12:26:58.000Z",
      "title": "Estructuralmente narrado y accionando estratégicamente: El Multi-Agent System del Framework de Colaboración de LLM",
      "summary": "Recientemente, se espera que se produzca un desarrollo significativo en los sistemas de autoría basados en modelos de lenguaje profundo (LLM-MA), pero siguen existiendo problemas graves en la comunicación y la mejora entre los autores en tareas complejas. En este artículo, se propone un nuevo marco de trabajo llamado \"Talk Structurally, Act Hierarchically (TalkHier)\", que incluye un protocolo de comunicación estructurado para facilitar la comunicación efectiva en tareas complejas, así como un sistema de mejora jerárquica para abordar problemas como salidas negativas, caras y prejuicios. TalkHier supera a los modelos de LLM y a los sistemas de línea de trabajo basados en solo un autor (por ejemplo, ReAct, GPT4o) y a modelos de autoría abiertos (por ejemplo, AgentVerse), incluyendo también modelos de escalado de inferencia para sistemas de autoría basados en LLM (OpenAI-o1). Esto permite que los sistemas de autoría basados en LLM (LLM-MA) alcancen un nuevo estándar de rendimiento efectivo, adaptable y colaborativo en diferentes tareas. Los resultados de este trabajo abren caminos para el desarrollo de nuevos marcos de autoría más efectivos, adaptables y colaborativos. El código está disponible en https://github.com/sony/talkhier.",
      "upvotes": 1,
      "discussionId": "67b411e55e634139c0d86a4c"
    },
    "publishedAt": "2025-02-17T23:51:50.821Z",
    "title": "Talk Structurally, Act Hierarchically: A Collaborative Framework for LLM Multi-Agent Systems",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.11098.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 6128
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.10454",
      "authors": [
        {
          "_id": "67b40e56bffd44cc85976ecd",
          "name": "Yinghui Li",
          "hidden": false
        },
        {
          "_id": "67b40e56bffd44cc85976ece",
          "name": "Jiayi Kuang",
          "hidden": false
        },
        {
          "_id": "67b40e56bffd44cc85976ecf",
          "name": "Haojing Huang",
          "hidden": false
        },
        {
          "_id": "67b40e56bffd44cc85976ed0",
          "name": "Zhikun Xu",
          "hidden": false
        },
        {
          "_id": "67b40e56bffd44cc85976ed1",
          "name": "Xinnian Liang",
          "hidden": false
        },
        {
          "_id": "67b40e56bffd44cc85976ed2",
          "name": "Yi Yu",
          "hidden": false
        },
        {
          "_id": "67b40e56bffd44cc85976ed3",
          "name": "Wenlian Lu",
          "hidden": false
        },
        {
          "_id": "67b40e56bffd44cc85976ed4",
          "name": "Yangning Li",
          "hidden": false
        },
        {
          "_id": "67b40e56bffd44cc85976ed5",
          "name": "Xiaoyu Tan",
          "hidden": false
        },
        {
          "_id": "67b40e56bffd44cc85976ed6",
          "name": "Chao Qu",
          "hidden": false
        },
        {
          "_id": "67b40e56bffd44cc85976ed7",
          "name": "Ying Shen",
          "hidden": false
        },
        {
          "_id": "67b40e56bffd44cc85976ed8",
          "name": "Hai-Tao Zheng",
          "hidden": false
        },
        {
          "_id": "67b40e56bffd44cc85976ed9",
          "name": "Philip S. Yu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-12T02:01:10.000Z",
      "title": "Un ejemplo muestra que muchos conceptos se conocen! En la lógica conceptual de los LLM de matemática, se presentan contraejemplos.",
      "summary": "La utilización de modelos de lenguaje grande (LLMs) para la generación de demostraciones es uno de los temas fundamentales en la investigación de LLMs. La capacidad de los actuales LLMs para realizar demostraciones depende significativamente de la experiencia que tienen con procesos de demostración relacionados durante el proceso de entrenamiento. Esta dependencia limita la comprensión profunda de conceptos relacionados con teoremas matemáticos. En la educación matemática generalmente utilizada por los humanos, existe un método educativo de \"demostración por excepción\", y nuestra investigación busca mejorar la capacidad de lógica matemática y demostración de los LLMs utilizando excepciones. Concretamente, hemos creado directamente un alto nivel de benchmark de matemáticas universitarias de alta calidad llamado CounterMATH, lo que nos permite exigir a los LLMs que utilicen excepciones para realizar y comprender demostraciones. Además, hemos desarrollado un marco de datos científico y se han establecido objetivos para obtener datos de entrenamiento automáticamente para el desarrollo del modelo. Los experimentos ampliados y el análisis detallado muestran que CounterMATH es difícil y revelan que capacidades de demostración utilizando excepciones en modelos de LLMs como OpenAI o1 no son suficientes. Además, la revisión durante el proceso de entrenamiento muestra la importancia de fortalecer la capacidad lógica conceptual utilizando excepciones en la memoria matemática completa de los LLMs. Confiamos en que nuestra investigación ofrece una nueva perspectiva a la comunidad de LLMs de matemáticas.",
      "upvotes": 1,
      "discussionId": "67b40e57bffd44cc85976f0e"
    },
    "publishedAt": "2025-02-17T23:37:16.770Z",
    "title": "One Example Shown, Many Concepts Known! Counterexample-Driven Conceptual Reasoning in Mathematical LLMs",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.10454.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 6128
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.11574",
      "authors": [
        {
          "_id": "67b435c29e5685b308a8edac",
          "user": {
            "_id": "65bcbc01d6d0ffbceb8b2e6e",
            "avatarUrl": "/avatars/73edb2d6b7b11208439ac88b365079e8.svg",
            "isPro": false,
            "fullname": "Johan Boye",
            "user": "jboye",
            "type": "user"
          },
          "name": "Johan Boye",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-02-18T07:24:50.956Z",
          "hidden": false
        },
        {
          "_id": "67b435c29e5685b308a8edad",
          "user": {
            "_id": "6033e34a9aa44495c80dd043",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1614079701740-6033e34a9aa44495c80dd043.jpeg",
            "isPro": false,
            "fullname": "Birger Moell",
            "user": "birgermoell",
            "type": "user"
          },
          "name": "Birger Moell",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-18T09:30:49.328Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-17T09:07:32.000Z",
      "title": "El fracaso de los grandes modelos de lenguaje y las razones matemáticas",
      "summary": "Este artículo utiliza 50 nuevos problemas de nivel de secundaria para investigar la capacidad de inferencia matemática de los modelos de lenguaje grandes (LLMs). En los estudios anteriores, se centraba en la precisión de las respuestas, pero en este trabajo, analizamos rigurosamente tanto la respuesta final como los pasos para llegar a la solución, identificando fallos en la inferencia. Evaluamos 8 modelos más recientes (Mixtral, Llama, Gemini, GPT-4o, la versión o1 de OpenAI y otros modelos), y encontramos que nuevos modelos como o3-mini y deepseek-r1 logran altas precisiones, pero todos presentan errores en la inferencia espacial, la planificación estratégica y el cálculo, a veces generando respuestas correctas basadas en lógica equivocada. Los modos de fracaso generales incluyen suposiciones inútiles, un exceso de dependencia en patrones numéricos, y el difícil traducción de intuiciones físicas y etapas matemáticas. El análisis manual muestra que los modelos tienen dificultades en problemas que requieren inferencia multinível y conocimientos del mundo real, y que cuando tienen una amplia base de conocimientos matemáticos, es más difícil que se adapten a estos problemas. Nuestros resultados subrayan la importancia de la evaluación de razonamiento y alertan contra la sobreavaluación de la capacidad de resolución de problemas de los LLMs. Este estudio revela las deficiencias residuales en la capacidad de generalización de los LLMs y subraya la necesidad de mejoras estructurales y específicas en el tratamiento de limitaciones.",
      "upvotes": 0,
      "discussionId": "67b435c29e5685b308a8edf1"
    },
    "publishedAt": "2025-02-18T02:26:18.856Z",
    "title": "Large Language Models and Mathematical Reasoning Failures",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.11574.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6033e34a9aa44495c80dd043",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1614079701740-6033e34a9aa44495c80dd043.jpeg",
      "fullname": "Birger Moell",
      "name": "birgermoell",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 36
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.11578",
      "authors": [
        {
          "_id": "67b435475bff5f34c1ebee1b",
          "user": {
            "_id": "6033e34a9aa44495c80dd043",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1614079701740-6033e34a9aa44495c80dd043.jpeg",
            "isPro": false,
            "fullname": "Birger Moell",
            "user": "birgermoell",
            "type": "user"
          },
          "name": "Birger Moell",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-02-18T09:30:52.639Z",
          "hidden": false
        },
        {
          "_id": "67b435475bff5f34c1ebee1c",
          "user": {
            "_id": "65bcbc01d6d0ffbceb8b2e6e",
            "avatarUrl": "/avatars/73edb2d6b7b11208439ac88b365079e8.svg",
            "isPro": false,
            "fullname": "Johan Boye",
            "user": "jboye",
            "type": "user"
          },
          "name": "Johan Boye",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-02-18T07:22:48.554Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-17T09:09:58.000Z",
      "title": "La medida de la complejidad del lenguaje se utiliza como un proxy para eliminar el ruido en la evaluación del rendimiento de los modelos de lenguaje grandes.",
      "summary": "Los modelos de lenguaje grande (LLMs) han logrado importantes avances en la generación de texto natural, pero presentan problemas en tareas que requieren alta precisión, como cálculos o análisis estructurales. En este artículo, mediante el cálculo de la puntuación de dificultad de lectura LIX y la distancia de dependencia promedio (ADD), se investiga el rendimiento de los más recientes LLMs en la medida de la complejidad lingüística. Utilizando artículos de nivel de escuela y universidad suecos, se evalúa la capacidad de los modelos para calcular la puntuación LIX y analizar la dependencia, comparándolos con los estándares existentes. Nuestros hallazgos muestran que todos los modelos muestran diferentes capacidades en estas tareas, con ChatGPT-o1-mini alcanzando la mayor precisión consistente y la mejor precisión en la cálcula de LIX y el análisis de dependencia. Además, se encuentra una fuerte correlación significativa entre la precisión de la cálcula de LIX del modelo y el rendimiento general en el benchmark Massive Multitask Language Understanding (MMLU) (-0.875, p 0.026, N=6). Estos resultados demuestran que la capacidad de medir la complejidad lingüística puede actuar como un representante 0 shot que incluye ruido en la evaluación general de los LLMs. Además, proporciona métodos útiles para evaluar modelos cuando se dispone de amplias colecciones de datos de benchmark.",
      "upvotes": 0,
      "discussionId": "67b435485bff5f34c1ebee52"
    },
    "publishedAt": "2025-02-18T02:23:29.869Z",
    "title": "Language Complexity Measurement as a Noisy Zero-Shot Proxy for Evaluating LLM Performance",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.11578.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6033e34a9aa44495c80dd043",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1614079701740-6033e34a9aa44495c80dd043.jpeg",
      "fullname": "Birger Moell",
      "name": "birgermoell",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 36
    },
    "isAuthorParticipating": true
  }
]